---
title: JAX principles
author: Marie-Hélène Burle
---

Composable transformations:

- `grad` transform: turn a loss function (e.g. `mse_loss`) and turn it into a function that computes the gradients
- `jit` transform: just-in-time compilation
- `vmap` transform: work in a **v**ectorized fashion across elements of a batch
- `pmap` transform: work in **p**arallel across processing units



```{dot}
//| echo: false
//| fig-height: 800px

strict digraph {

bgcolor="transparent"
node [fontname="Inconsolata, sans-serif"]
edge [color=deepskyblue3]

"tracer\nvalues" [shape=rectangle, color=deepskyblue3, fontcolor=deepskyblue3]
"jit\ncompilation" [shape=rectangle, color=deepskyblue3, fontcolor=deepskyblue3]
"Accelerated\nLinear Algebra\n(XLA)" [shape=rectangle, color=deepskyblue3, fontcolor=deepskyblue3]
"transforms" [shape=rectangle, color=deepskyblue3, fontcolor=deepskyblue3]

CPU [shape=octagon, color=gray55, fontcolor=gray55]
GPU [shape=octagon, color=gray55, fontcolor=gray55]
TPU [shape=octagon, color=gray55, fontcolor=gray55]

"Python code\nwith only pure\nfunctions" [color=burlywood3, fontcolor=burlywood3]
"Intermediate\nRepresentation\n(IR)" [color=darkorange4, fontcolor=darkorange4]
"High Level\nOptimized code\n(HLO)" [color=chocolate, fontcolor=chocolate]

"Python code\nwith only pure\nfunctions" -> "tracer\nvalues" [dir=none]
"tracer\nvalues" -> "Intermediate\nRepresentation\n(IR)"
"Intermediate\nRepresentation\n(IR)" -> "jit\ncompilation" [dir=none]
"jit\ncompilation" -> "High Level\nOptimized code\n(HLO)"
"High Level\nOptimized code\n(HLO)" -> "Accelerated\nLinear Algebra\n(XLA)" [dir=none]

"Accelerated\nLinear Algebra\n(XLA)" -> CPU [shape=doubleoctagon]
"Accelerated\nLinear Algebra\n(XLA)" -> GPU
"Accelerated\nLinear Algebra\n(XLA)" -> TPU

"Intermediate\nRepresentation\n(IR)" -> "transforms" [dir=both, minlen=3]

{rank=same; "Intermediate\nRepresentation\n(IR)" "transforms"}

}
```

