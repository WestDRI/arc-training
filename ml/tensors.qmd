---
title: PyTorch tensors
author: Marie-Hélène Burle
---

:::{.def}

Before information can be processed by algorithms, it needs to be converted to floating point numbers. Indeed, you don't pass a sentence or an image through a model; instead you input numbers representing a sequence of words or pixel values.

All these floating point numbers need to be stored in a data structure. The most suited structure is multidimensional (to hold several layers of information) and homogeneous—all data of the same type—for efficiency.

Python already has several multidimensional array structures (e.g. [NumPy](https://numpy.org/)'s ndarray) but the particularities of deep learning call for special characteristics such as the ability to run operations on GPUs and/or in a distributed fashion, the ability to keep track of computation graphs for [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation), and different defaults (lower precision for improved training performance).

The PyTorch tensor is a Python data structure with these characteristics that can easily be converted to/from NumPy's ndarray and integrates well with other Python libraries such as [Pandas](https://pandas.pydata.org/).

In this section, we will explore the basics of PyTorch tensors.

:::


