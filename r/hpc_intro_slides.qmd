---
title: Introduction to high-performance research computing in R
frontlogo: /img/sfudrac.png
author: Marie-Hélène Burle
date: 2023-01-31
date-format: long
execute:
  error: true
  echo: true
format:
  revealjs:
    # embed-resources: true
    theme: [default, ../revealjs.scss]
    logo: /img/sfudrac_logo.png
    highlight-style: monokai
    code-line-numbers: false
    code-overflow: wrap
    template-partials:
      - ../title-slide.html
    pointer:
      color: "#b5111b"
      pointerSize: 32
    link-external-newwindow: true
    footer: <a href="hpc_intro.html"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="rgb(153, 153, 153)" class="bi bi-arrow-90deg-up" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4.854 1.146a.5.5 0 0 0-.708 0l-4 4a.5.5 0 1 0 .708.708L4 2.707V12.5A2.5 2.5 0 0 0 6.5 15h8a.5.5 0 0 0 0-1h-8A1.5 1.5 0 0 1 5 12.5V2.707l3.146 3.147a.5.5 0 1 0 .708-.708l-4-4z"/></svg>&nbsp;Back to workshop page</a>
revealjs-plugins:
  - pointer
---

# Running R on Alliance clusters

## Loading modules: Intel vs GCC compilers

To compile R packages, you need a C compiler.

In theory, you could use the proprietary Intel compiler which is loaded by default on the Alliance clusters, but it is recommended to replace it with the GCC compiler (R packages can even be compiled with Clang and LLVM, but the default GCC compiler is the best way to avoid headaches).

It is thus much simpler to always load a `gcc` module before loading an `r` module.

## Loading modules: R module

To see what versions of R are available on a cluster, run:

```{.bash}
$ module spider r
```

To see the dependencies of a particular version (e.g. `r/4.2.1`), run:

```{.bash}
$ module spider r/4.2.1
```

:::{.note}

`StdEnv/2020` is a required module.

On most Alliance clusters, it is automatically loaded, so you don't need to include it. You can double-check with `module list` or you can include it just to be sure.

:::

Finally, load your modules:

```{.bash}
$ module load StdEnv/2020 gcc/11.3.0 r/4.2.1
```

## Installing R packages

To install a package, launch the interactive R console with:

```{.bash}
$ R
```

In the R console, run:

```{.r}
install.packages('<package_name>', repos='<url-cran-mirror>')
```

:::{.note}


You have to select a CRAN mirror from [this list](https://cran.r-project.org/mirrors.html){target="_blank"}. Ideally, use a mirror close to the location of the cluster you are using or use <https://cloud.r-project.org/>. \
<https://mirror.rcg.sfu.ca/mirror/CRAN/> is the closest mirror for Cedar.

:::

:::{.note}

The first time you install a package, R will ask you whether you want to create a personal library in your home directory. Answer `yes` to both questions. Your packages will now install under `~/`.

:::

:::{.note}

A handful of packages require additional modules to be loaded before they can be installed. This will be indicated in the error messages you will get when you try to install them.

:::

## Running R jobs

:::{.note}

While it is totally fine to run R on the login node when you install packages, you **must start a SLURM job before any heavy computation**.

:::

### Interactive jobs

To run R interactively, you should launch an `salloc` session before launching R:

```{.bash}
$ salloc --time=1:00:00 --mem-per-cpu=3000M --cpus-per-task=4
$ R
```

---

### Scripts

To run an R script called `<your_script>.R`, you first need to write a job script.

:::{.example}

Example:

```{.bash filename="<your_job>.sh"}
#!/bin/bash
#SBATCH --account=def-<your_account>
#SBATCH --time=15
#SBATCH --mem-per-cpu=3000M
#SBATCH --cpus-per-task=4
#SBATCH --job-name="<your_job>"
module load StdEnv/2020 gcc/11.3.0 r/4.2.1
Rscript <your_script>.R
```

:::{.note}

Note that R scripts are run with the command `Rscript`.

:::

:::

Then launch your job with:

```{.bash}
$ sbatch <your_job>.sh
```

You can monitor your job with `sq` (an alias for `squeue -u $USER $@`).

# Performance

## Profiling

The first thing to do if you want to improve your code efficiency is to identify bottlenecks.

We will use the package [profvis](https://cran.r-project.org/web/packages/profvis/index.html):

```{.r}
library(profvis)
```



## Benchmarking

We will use the [bench](https://cran.r-project.org/web/packages/bench/index.html) package described by Jim Hester in a [Tidyverse blog](https://www.tidyverse.org/blog/2018/06/bench-1.0.1/):

```{r}
library(bench)
```






# Parallel R

<!-- https://towardsdatascience.com/getting-started-with-parallel-programming-in-r-d5f801d43745 -->
<!-- https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html -->
<!-- https://yxue-me.com/post/2019-05-12-a-glossary-of-parallel-computing-packages-in-r-2019/ -->
<!-- https://subscription.packtpub.com/book/big-data-and-business-intelligence/9781784394004/1/ch01lvl1sec09/the-r-parallel-package -->
<!-- https://www.r-bloggers.com/2017/08/implementing-parallel-processing-in-r/ -->
<!-- https://www.stat.umn.edu/geyer/3701/notes/parallel.html -->
<!-- https://www.stat.umn.edu/geyer/8054/notes/parallel.html -->
<!-- https://blog.esciencecenter.nl/parallel-r-in-a-nutshell-4391d45b5461 -->
<!-- https://dept.stat.lsa.umich.edu/~jerrick/courses/stat701/notes/parallel.html -->
<!-- https://bookdown.org/rdpeng/rprogdatascience/parallel-computation.html -->
<!-- https://docs.alliancecan.ca/wiki/R#doParallel_and_foreach -->
<!-- https://www.r-bloggers.com/2016/01/strategies-to-speedup-r-code/ -->
<!-- https://www.datacamp.com/tutorial/r-tutorial-apply-family -->
<!-- https://bookdown.org/rdpeng/rprogdatascience/profiling-r-code.html -->

<!-- Start large (4GB) on a test script. Then: -->
<!-- While the script is running, check how much memory is used in real time by typing: sstat yourjobID.batch --format="JobID,MaxRSS" -->
<!-- Or -->
<!-- When the script is done running, check how much was used by typing: sacct -o MaxRSS -j yourjobID -->
<!-- If you check the slurm.out file and you’re getting “oom-kill” errors, you need to request more memory -->
<!-- If you’re using less than you asked for, it’s beneficial to reduce the memory in --mem or --mem-per-cpu (this way your job will get scheduled sooner) -->
<!-- Resubmit your job with your new estimate. -->


<!-- Independent repeats of computations (e.g. bootstrapping) -->

<!-- No communication needed between computations. -->

## Built-in parallel package

<!-- (a) Start up M ‘worker’ processes, and do any initialization needed on the workers. -->
<!-- (b) Send any data required for each task to the workers. -->
<!-- (c) Split the task into M roughly equally-sized chunks, and send the chunks (including the R -->
<!-- code needed) to the workers. -->
<!-- (d) Wait for all the workers to complete their tasks, and ask them for their results. -->
<!-- (e) Repeat steps (b–d) for any further tasks. -->
<!-- (f) Shut down the worker processes. -->

## furrr package



## doParallel package

and foreach package


## boot package

# Using C++

# Questions?
