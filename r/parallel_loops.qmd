---
title: Parallel loops with foreach & doFuture
author: Marie-Hélène Burle
---

## `foreach` package

The [`foreach`](https://cran.r-project.org/web/packages/foreach/index.html) package implements a looping construct without an explicit counter. It doesn't require the preallocation of an output container, it brings to R an equivalent of the Python or Julia list comprehensions, and mostly, it allows for an easy execution of loops in parallel.

Unlike loops, it creates variables (loops are used for their side-effect).

Let's look at an example to calculate the sum of 1e4 random vectors of length 3. We will use `foreach` and `iterators` (which creates convenient iterators for `foreach`):

```{r}
library(foreach)
library(iterators)
```

- Classic while loop:

```{r}
set.seed(2)
result1 <- numeric(3)            # Preallocate output container
i <- 0                           # Initialise counter variable

while(i < 1e4) {
  result1 <- result1 + runif(3)  # Calculate the sum
  i <- i + 1                     # Update the counter
}
```

- With foreach:

```{r}
set.seed(2)
result2 <- foreach(icount(1e4), .combine = '+') %do% runif(3)
```

We can verify that both expressions returned the same result:

```{r}
all.equal(result1, result2)
```

The best part of `foreach` is that you can turn sequential loops into parallel ones by registering a parallel backend and replacing `%do%` with `%dopar%`.

There are many parallelization backends available: `doFuture`, `doMC`, `doMPI`, `doFuture`, `doParallel`, `doRedis`, `doRNG`, `doSNOW`, and `doAzureParallel`.

In this lesson, I will use [`doFuture`](https://cran.r-project.org/web/packages/doFuture/index.html) which allows to evaluate `foreach` expressions following any of the strategies of the [`future`](https://cran.r-project.org/web/packages/future/index.html) package.

So first, what is the [`future`](https://cran.r-project.org/web/packages/future/index.html) package?

## `future` package

A [future](https://en.wikipedia.org/wiki/Futures_and_promises) is an object that acts as an abstract representation for a value in the future. A future can be *resolved* (if the value has been computed) or *unresolved*. If the value is queried while the future is unresolved, the process is blocked until the future is resolved. Futures thus allow for asynchronous and parallel evaluations.

The [`future`](https://cran.r-project.org/web/packages/future/index.html) package allows to evaluate futures sequentially or in various forms of parallelism while keeping code simple and consistent. The evaluation strategy is set thanks to the `plan` function:

- `plan(sequential)`: \
Futures are evaluated sequentially in the current R session.

- `plan(multisession)`: \
Futures are evaluated by new R sessions spawned in the background (*multi-processing in shared memory*).

- `plan(multicore)`: \
Futures are evaluated in processes forked from the existing process (*multi-processing in shared memory*).

- `plan(cluster)`: \
Futures are evaluated on an ad-hoc cluster (*distributed parallelism* across multiple nodes).

:::{.note}

###### Consistency

To ensure a consistent behaviour across plans, all evaluations are done in a local environment:

```{r}
library(future)

a <- 1

b %<-% {
  a <- 2
}

a
```

:::

## `doFuture` package

The [`doFuture`](https://cran.r-project.org/web/packages/doFuture/index.html) package allows to evaluate `foreach` expressions across the evaluation strategies of the [`future`](https://cran.r-project.org/web/packages/future/index.html) package.

Let's go back to our `foreach` example. We had:

```{.r}
library(foreach)

set.seed(2)
result2 <- foreach(icount(1e4), .combine = '+') %do% runif(3)
```

We can replace `%do%` with `%dopar%`:

```{.r}
library(foreach)

set.seed(2)
result3 <- foreach(icount(1e4), .combine = '+') %dopar% runif(3)
```

Since we haven't registered any parallel backend, the expression will still be evaluated sequentially. To run this in parallel, we need to load `doFuture`, register it as a backend (with `registerDoFuture()`), and choose a parallel strategy (e.g. `plan(multicore)`):

```{.r}
library(foreach)
library(doFuture)

registerDoFuture()
plan(multicore)

set.seed(2)
result3 <- foreach(icount(1e4), .combine = '+') %dopar% runif(3)
```

With the overhead of parallelization, it actually doesn't make sense to parallelize such a short code, so let's go over a toy example and do some benchmarking.

## Toy example

### Load packages

For this toy example, I will use a modified version of one of the examples in the [foreach vignette](https://cran.r-project.org/web/packages/foreach/vignettes/foreach.html): I will build a classification model made of a forest of decision trees thanks to the [`randomForest`](https://cran.r-project.org/web/packages/randomForest/index.html) package.

Because the code includes randomly generated numbers, I will use the [`doRNG`](https://cran.r-project.org/web/packages/doRNG/index.html) package which replaces `foreach::%dopar%` with `doRNG::%dorng%`. This follows the recommendations of Pierre L'Ecuyer (1999)[^1] and ensures reproducibility.

[^1]: [L'Ecuyer, P. (1999). Good parameters and implementations for combined multiple recursive random number generators. Operations Research, 47, 159–164.](https://pubsonline.informs.org/doi/10.1287/opre.47.1.159)

```{.r}
library(doFuture)       # This will also load the `future` package
library(doRNG)          # This will also load the `foreach` package
library(randomForest)
library(bench)          # To do some benchmarking
```

```
Loading required package: foreach
Loading required package: future
Loading required package: rngtools
```

### The code to parallelize

The goal is to create a classifier based on some data (here a matrix of random numbers for simplicity) and a response variable (as factor). This model could then be passed in the `predict()` function with novel data to generate predictions of classification. But here we are only interested in the creation of the model as this is the part that is computationally intensive. We aren't interested in actually using it.

```{.r}
set.seed(11)
traindata <- matrix(runif(1e5), 100)
fac <- gl(2, 50)

rf <- foreach(ntree = rep(250, 8), .combine = combine) %do%
  randomForest(x = traindata, y = fac, ntree = ntree)

rf
```

```
Call:
 randomForest(x = traindata, y = fac, ntree = ntree)
               Type of random forest: classification
                     Number of trees: 2000
No. of variables tried at each split: 31
```

### Reference timing

This is the non parallelizable code with `%do%`:

```{.r}
tref <- mark(
  rf1 <- foreach(ntree = rep(250, 8), .combine = combine) %do%
    randomForest(x = traindata, y = fac, ntree = ntree),
  memory=F
)

tref$median
```

```
[1] 5.66s
```

### Plan sequential

This is the parallelizable `foreach` code, but run sequentially:

```{.r}
registerDoFuture()   # Set the parallel backend
plan(sequential)     # Set the evaluation strategy

# Using bench::mark()
tseq <- mark(
  rf2 <- foreach(ntree = rep(250, 8), .combine = combine) %dorng%
    randomForest(x = traindata, y = fac, ntree = ntree),
  memory=F
)

tseq$median
```

```
[1] 5.78s
```

:::{.note}

No surprise: those are similar.

:::

### Multi-processing in shared memory

`future` provides `availableCores()` to detect the number of available cores:

```{.r}
availableCores()
```

```
system
     4
```

:::{.note}

Similar to `parallel::detectCores()`.

:::

This detects the number of CPU cores available to me on the current compute node, that is, what I can use for shared memory multi-processing.

### Plan multisession

Shared memory multi-processing can be run with `plan(multisession)` that will spawn new R sessions in the background to evaluate futures:

```{.r}
plan(multisession)

tms <- mark(
  rf2 <- foreach(ntree = rep(250, 8), .combine = combine) %dorng%
    randomForest(x = traindata, y = fac, ntree = ntree),
  memory=F
)

tms$median
```

```
[1] 2s
```

:::{.note}

We got a speedup of `5.78 / 2 = 2.9`. Not bad considering that we have 4 CPU cores (the ideal speedup would be 4, but there is always some overhead to parallelization).

:::

### Plan multicore

Shared memory multi-processing can also be run with `plan(multicore)` (except on Windows) that will fork the current R process to evaluate futures:

```{.r}
plan(multicore)

tmc <- mark(
  rf2 <- foreach(ntree = rep(250, 8), .combine = combine) %dorng%
    randomForest(x = traindata, y = fac, ntree = ntree),
  memory=F
)

tmc$median
```

```
[1] 1.9s
```

:::{.note}

We got a very similar speedup of `5.78 / 1.9 = 3.0`.

:::

### Multi-processing in distributed memory

For this lesson, I requested 8 tasks from [Slurm](https://en.wikipedia.org/wiki/Slurm_Workload_Manager) on a training cluster made of nodes with 4 CPU cores each.

Let's verify that I did get 8 tasks by accessing the `SLURM_NTASKS` environment variable from within R:

```{.r}
as.numeric(Sys.getenv("SLURM_NTASKS"))
```

```
[1] 8
```

I can create a character vector with the name of the node each task is running on:

```{.r}
(hosts <- system("srun hostname | cut -f 1 -d '.'", intern = T))
```

```
chr [1:8] "node1" "node1" "node1" "node1" "node2" "node2" "node2" "node2"
```

This allows me to create a cluster of workers:

```{.r}
(cl <- parallel::makeCluster(hosts))      # Defaults to type="PSOCK"
```

```
socket cluster with 8 nodes on hosts ‘node1’, ‘node2’
```

:::{.note}

The notation used in the last two expressions (running an assignment inside a set of parentheses) allows to print to standard output the assigned value. It is equivalent to running:

```{.r}
cl <- parallel::makeCluster(hosts)
cl
```

:::

### Plan cluster

I can now try the code with distributed parallelism using all 8 CPU cores across both nodes:

```{.r}
plan(cluster, workers = cl)

tdis <- mark(
  rf2 <- foreach(ntree = rep(250, 8), .combine = combine) %dorng%
    randomForest(x = traindata, y = fac, ntree = ntree),
  memory=F
)

tdis$median
```

```
[1] 1.14s
```

:::{.note}

Speedup: `5.78 / 1.14 = 5.1`. Here again, this is not bad with 8 CPU cores, considering the added overhead of message passing between both nodes.

:::

The cluster of workers can be stopped with:

```{.r}
parallel::stopCluster(cl)
```
