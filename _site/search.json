[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About this site",
    "section": "",
    "text": "This site contains Marie-H√©l√®ne Burle‚Äôs latest content.\nHer older training material can be found on the archived sites:"
  },
  {
    "objectID": "about.html#main-westdri-training-website",
    "href": "about.html#main-westdri-training-website",
    "title": "About this site",
    "section": "Main WestDRI training website",
    "text": "Main WestDRI training website\nThis is the mint (‚Äúmint is not training‚Äù) WestDRI website.\nTo view all WestDRI training material, please visit training."
  },
  {
    "objectID": "about.html#other-websites",
    "href": "about.html#other-websites",
    "title": "About this site",
    "section": "Other websites",
    "text": "Other websites\nIn addition, here are a few of our websites for various training events:\n\nAutumn School 2022\nTraining Modules 2022\nTraining Modules 2021\nSummer School 2020\nCoding Fundamentals for Humanists 20221\nCoding Fundamentals for Humanists 2021\n\n\n\n1¬†For the Digital Humanities Summer Institute"
  },
  {
    "objectID": "bash/tools1.html",
    "href": "bash/tools1.html",
    "title": "Fun tools to simplify your life in the command line",
    "section": "",
    "text": "Working in the command-line has many advantages and it is often necessary, but can it be fun?\nIn this webinar, aimed at any command-line user, I intend to demonstrate that yes, it can! by introducing three free and open source utilities which make navigating your system and your outputs a lot easier:\n\nfzf is a simple, yet extremely powerful interactive fuzzy finder allowing for incremental completion and narrowing selection of any command line output. I will show you how to build simple shell functions which harvest its power to instantly refresh your memory on your custom keybindings or aliases, navigate your command history, find and kill processes, and explore and checkout your git commits. After this, you will be able to use fzf for any number of other applications in your work in the command-line.\nautojump lets you jump anywhere you want in your directories in just a few keystrokes (no more of this painful navigation writing down long paths).\nWith the ranger file manager, you can browse (with preview!), open, copy, move, delete, etc. your files and directories in a friendly way from the command line. Added bonus: you can use fzf and autojump within ranger!\n\nWarning: too much fun in the command-line can lead to addiction and geek behaviours. Use in moderation."
  },
  {
    "objectID": "bash/tools2.html",
    "href": "bash/tools2.html",
    "title": "A few of our favourite tools",
    "section": "",
    "text": "In a previous webinar, we presented three of our favourite command line tools. Today, we will introduce other tools we find really useful in our daily workflow:\n\nlazygit: a wonderful terminal UI for Git,\nbat: a great syntax highlighter,\nripgrep: a fast alternative to grep,\nfd: a /really/ fast alternative to find,\npass: a command line password manager.\n\nAlong the way, I will use a few other neat command line tools such as hyperfine‚Äîfor sophisticated benchmarking‚Äîand diff-so-fancy‚Äîwhich makes your diffs a lot more readable.\nFor the Emacs users among you, we will finish the workshop with two Emacs utilities:\n\nTRAMP: a remote file access system,\nHelm: a ‚Äúframework for incremental completions and narrowing selections‚Äù."
  },
  {
    "objectID": "calendar.html",
    "href": "calendar.html",
    "title": "Upcoming training events",
    "section": "",
    "text": "Our training events also get posted in our main site."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Please email us at: training at westdri dot ca."
  },
  {
    "objectID": "git/intro.html",
    "href": "git/intro.html",
    "title": "Version control with Git & GitHub",
    "section": "",
    "text": "Git is a free and open source version control system (a software that tracks changes to your files, allowing you to revisit or revert to older versions).\nUsing Internet hosting services such as GitHub, Git is also a powerful collaboration tool.\nIn this introductory workshop you will learn the basics of working with Git on the command line."
  },
  {
    "objectID": "git/intro.html#introduction",
    "href": "git/intro.html#introduction",
    "title": "Version control with Git & GitHub",
    "section": "Introduction",
    "text": "Introduction\n\nWhat is a version control system?\n\n\n\n\nfrom PhD\n\n\nWhenever we work on an important document, we intuitively realize that it is important to keep key versions (e.g.¬†the version of a manuscript that we sent to our supervisor, the revised version after we addressed their comments, the revised version after we addressed reviewer comments, etc.). We have all been there ‚Ä¶ The versions accumulate with names that are often less than helpful ‚Ä¶\n\n\n\n\n\nfrom Geek&Poke\n\n\n‚Ä¶ and soon enough, it is hell. This is a form of versioning, but a terribly messy and inefficient one. Version control systems are software that allow to handle this much more effectively.\n\n\n\n\n\nWhich version control system should I use?\nIf the trends of Google searches of the existing version control systems are any indication of their popularity, we can say that Git has crushed the competition since 2010.\n\n\nNowadays, it is indeed extremely rare to come across any other version control system.\nGit is simply that good üôÇ"
  },
  {
    "objectID": "git/intro.html#installation-and-setup",
    "href": "git/intro.html#installation-and-setup",
    "title": "Version control with Git & GitHub",
    "section": "Installation and setup",
    "text": "Installation and setup\n\nInstalling Git\n\nMacOS & Linux users\nInstall Git from the official website.\n\n\nWindows users\nInstall Git for Windows. This will also install Git Bash, a Bash emulator.\n\n\n\nUsing Git\nWe will use Git from the command line throughout this workshop.\nMacOS users: ‚ÄÉ‚ÄÉ‚ÄÇopen Terminal.\nWindows users: ‚ÄÉ‚ÄÇopen Git Bash.\nLinux users: ‚ÄÉ‚ÄÉ‚ÄÉopen the terminal emulator of your choice.\n\n\nConfiguring Git\nBefore you can use Git, you need to set some basic configuration. You will do this in the terminal you just opened.\n\nUser identity\ngit config --global user.name \"<Your Name>\"\ngit config --global user.email \"<your@email>\"\n\nExample:\n\ngit config --global user.name \"John Doe\"\ngit config --global user.email \"john.doe@gmail.com\"\n\n\nText editor\ngit config --global core.editor \"<text-editor>\"\n\nExample for nano:\n\ngit config --global core.editor \"nano\"\n\n\nLine ending\n\nmacOS, Linux, or WSL\ngit config --global core.autocrlf input\n\n\nWindows\ngit config --global core.autocrlf true\n\n\n\nList settings\ngit config --list"
  },
  {
    "objectID": "git/intro.html#documentation",
    "href": "git/intro.html#documentation",
    "title": "Version control with Git & GitHub",
    "section": "Documentation",
    "text": "Documentation\n\nInternal documentation\n\nMan pages\ngit <command> --help\ngit help <command>\nman git-<command>\n\nExample:\n\ngit commit --help\ngit help commit\nman git-commit\n\nUseful keybindings when you are in the pager\nSPACE      scroll one screen down\nb          scroll one screen up\nq          quit\n\n\n\nCommand options\ngit <command> -h\n\nExample:\n\ngit commit -h\n\n\n\nOnline documentation\n\nOfficial Git manual\nOpen source Pro Git book\n\n\nCourses & workshops\n\nWestern Canada Research Computing Git workshops\nWestGrid Summer School 2020 Git course\nWestGrid Autumn School 2020 Git course\nSoftware Carpentry Git lesson\n\n\n\nQ & A\n\nStack Overflow [git] tag"
  },
  {
    "objectID": "git/intro.html#lets-get-started-with-an-example",
    "href": "git/intro.html#lets-get-started-with-an-example",
    "title": "Version control with Git & GitHub",
    "section": "Let‚Äôs get started with an example",
    "text": "Let‚Äôs get started with an example\n\nMock project\nLet‚Äôs imagine that you have been working on chapter 3 of your thesis for some time, without using a version control system. We will put that chapter under version control and see how you should work from now on.\nFirst, we need to create a mock set of documents.\n\nNavigate to a suitable location\n\ncd </some/suitable/location/in/your/computer>\n\nCreate the directory at the root of chapter 3\n\nmkdir chapter3\n\nMake sure not to use any spaces in the name: Git doesn‚Äôt work well with spaces.\n\n\nCreate a number of subdirectories\n\nmkdir chapter3/src chapter3/ms chapter3/data chapter3/results\n\nCreate a mock manuscript\n\necho \"# Chapter 3\n## Introduction\nBla bla bla bla bla.\n## Methods\nBla bla bla.\" > chapter3/ms/chapter3.md\n\nGit can only version text files. If you write your papers or thesis chapter in text files (e.g.¬†markdown, LaTeX, org-mode), you will be able to put them under version control, which is really convenient. If you use a word processor, you won‚Äôt be able to.\n\n\nCreate a mock R script\n\necho \"library(ggplot2)\nlibrary(dplyr)\n\ndf <- data.frame(\n  x = (1:5),\n  y = (1:5)\n)\n\nggplot(df, aes(x, y)) + geom_point()\" > chapter3/src/chapter3.R\n\nEven if you use a word processor for your writing, your scripts (e.g.¬†in Python, R, etc.) will be written in text files. So you will always be able to put at least those files under version control.\n\n\n\nInitializing a Git repository\n!! Make sure to enter the project before initializing the repository.\ncd chapter3\nNow, you can run the command that will turn your chapter3 directory into a Git repository:\ngit init\nInitialized empty Git repository in chapter3/.git/\n\nGit is very verbose: you will often get useful feed-back after running commands.\n\nWhen you run this command, Git creates a .git repository. This is where it will store all its files.\nYou can see that this repository was created by running:\nls -a\n.\n..\n.git\ndata\nms\nresults\nsrc\n\nIf you run git init in the wrong location, you can easily fix this: simply delete the .git directory that you created!\n\n\n\nCreating commits\nYou can think of a commit as a snapshot of a particular version of your project.\nYou should create a new commit whenever you think that your project is at a point to which you might want to go back to.\nLet‚Äôs create a first commit with the state of our chapter 3 before we do any more work to it:\ngit add .\ngit commit -m \"Initial commit\"\n[main (root-commit) 7f94f8e] Initial commit\n 2 files changed, 18 insertions(+)\n create mode 100644 ms/chapter3.md\n create mode 100644 src/chapter3.R\nTo create a commit, we first need to add the file(s) we want to add to our commit to the staging area (also called ‚Äúindex‚Äù). This is done with the command git add. To add all the files, we can use git add . (. represents the current directory).\nOnce we have added some files to the staging area, we can create a commit. But each commit has a message associated to it. One way to add this message is to use the command to create commits (git commit) with the -m flag (for ‚Äúmessage‚Äù). Here, our message is simply ‚ÄúInitial commit‚Äù.\n\nGit saves the history of a project as a series of snapshots:\n\nThose snapshots are called commits:\n\nEach commit is identified by a unique hash:\n\nEach commit contains these metadata:\n\nauthor,\ndate and time,\nthe hash of parent commit(s),\na message.\n\nAs soon as you create the first commit, a pointer called a branch is created and it points to that commit. By default, that first branch is called main:\n\nAnother pointer (HEAD) points to the branch main.\nHEAD indicates where we are in the project history.\n\n\nWe can now do some work in our chapter 3. For instance, let‚Äôs imagine that we are adding a result section to our chapter3.md file.\necho \"\n## Results\n\nWe now have a bunch of results in our markdown manuscript.\" >> ms/chapter3.md\n!! Make sure to use >> here and not >: >> prepends content while > replaces any existing content.\nIf this new addition is important enough to justify making a new commit (how often you commit is up to you), we can do so:\ngit add ms/chapter3.md\ngit commit -m \"Add result section to manuscript\"\n[main 451c47b] Add result section to manuscript\n 1 file changed, 4 insertions(+)\n\nAs you create more commits, the history of your project grows ‚Ä¶\n\n‚Ä¶ and the pointers HEAD and main automatically move to the last commit:\n\nFor simplicity, the diagrams can be simplified this way:\n\n\n\n\nUnderstanding the staging area\nNew Git users are often confused about the two-step commit process (first, you stage with git add, then you commit with git commit). This intermediate step seems, at first, totally unnecessary. In fact, it is very useful: without it, commits would always include all new changes made to a project and they would thus be very messy. The staging area allows to prepare (‚Äústage‚Äù) the next commit. This way, you only commit what you want when you want.\n\nLet‚Äôs go over a simple example:\n\nWe don‚Äôt always work linearly. Maybe you are working on a section of your manuscript when you realize by chance that there is a mistake in your script. You fix that mistake. On your next commit, it might make little sense to commit together that fix and your manuscript changes since they are not related. If your commits are random bag of changes, it will be very hard for future you to navigate your project history.\nIt is a lot better to only stage your script fix, commit it, then only stage your manuscript update, and commit this in a different commit.\nThe staging area allows you to pick and chose the changes from one or various files that constitute some coherent change to the project and that make sense to commit together.\n\n\nInspecting changes\n\nList of modified files\nOne command you will run often when working with Git is git status:\ngit status\nOn branch main\nnothing to commit, working tree clean\nThis means that we are on the branch main (that‚Äôs the only branch in our repo at this point) and that all changes to our project have been committed.\nLet‚Äôs modify a file and see what happens:\necho \"\n## Conclusion\n\nAnd finally, the great conclusion of our paper.\" >> ms/chapter3.md\ngit status\nOn branch main\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n        modified:   ms/chapter3.md\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\nLet‚Äôs modify another file:\necho \"\na = 23\" >> src/chapter3.R\ngit status\nOn branch main\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n        modified:   ms/chapter3.md\n        modified:   src/chapter3.R\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\nMaybe we don‚Äôt want to create a commit with all those changes, so we only stage the changes made to the manuscript:\ngit add ms/chapter3.md\nThen we check the status of our repository again:\ngit status\nOn branch main\nChanges to be committed:\n  (use \"git restore --staged <file>...\" to unstage)\n        modified:   ms/chapter3.md\n\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n        modified:   src/chapter3.R\nIf we ran git commit at this point, we would create a new commit with the changes made to the manuscript.\n\n\nList of actual changes\nWhile git status gives us the list of new files and files with changes, it doesn‚Äôt allow us to see what those changes are. For this, we need a new command: git diff.\n\nDifference between the working directory and the index\ngit diff shows the difference between the working directory (our actual files) and the index (staging area):\ngit diff\ndiff --git a/src/chapter3.R b/src/chapter3.R\nindex 95f1592..2bf030d 100644\n--- a/src/chapter3.R\n+++ b/src/chapter3.R\n@@ -7,3 +7,5 @@ df <- data.frame(\n )\n\n ggplot(df, aes(x, y)) + geom_point()\n+\n+a = 23\nThis allows us to see that src/chapter3.R has a new line (a = 23) and that it is not yet staged.\n\n\nDifference between the index and your last commit\nTo see what would be committed if you ran git commit (so, to see the difference between the index and the last commit), you need to run instead:\ngit diff --cached\ndiff --git a/ms/chapter3.md b/ms/chapter3.md\nindex 9408f32..80d2c5c 100644\n--- a/ms/chapter3.md\n+++ b/ms/chapter3.md\n@@ -11,3 +11,7 @@ Bla bla bla.\n ## Results\n\n We now have a bunch of results in our markdown manuscript.\n+\n+## Conclusion\n+\n+And finally, the great conclusion of our paper.\nThis shows us the changes that we have staged but not yet committed (the changes to our manuscript).\n\n\nDifference between the working directory and your last commit\nThis means, both of the above. This can been displayed with:\ngit diff HEAD\ndiff --git a/ms/chapter3.md b/ms/chapter3.md\nindex 9408f32..80d2c5c 100644\n--- a/ms/chapter3.md\n+++ b/ms/chapter3.md\n@@ -11,3 +11,7 @@ Bla bla bla.\n ## Results\n\n We now have a bunch of results in our markdown manuscript.\n+\n+## Conclusion\n+\n+And finally, the great conclusion of our paper.\ndiff --git a/src/chapter3.R b/src/chapter3.R\nindex 95f1592..2bf030d 100644\n--- a/src/chapter3.R\n+++ b/src/chapter3.R\n@@ -7,3 +7,5 @@ df <- data.frame(\n )\n\n ggplot(df, aes(x, y)) + geom_point()\n+\n+a = 23\nNow, let‚Äôs clean up our working directory by creating two new commits:\ngit commit -m \"Add conclusion to the manuscript\"\n[main c7fc9c1] Add conclusion to the manuscript\n 1 file changed, 4 insertions(+)\ngit add .\ngit commit -m \"Define the variable a in R script\"\n[main a049a2f] Define the variable a in R script\n 1 file changed, 2 insertions(+)\nIf we look at the status of our repository now, we can see that it is clean again:\ngit status\nOn branch main\nnothing to commit, working tree clean\n\n\n\n\nIgnoring\nNot everything should be under version control. For instance, you don‚Äôt want to put under version control non-text files or your initial data. You also shouldn‚Äôt put under version control documents that can be easily recreated such as graphs and script outputs.\nHowever, you don‚Äôt want to have such documents constantly showing up when you run git status. In order to have a clean working directory while keeping them out of version control, you can create a file called .gitignore and add to it a list of files or patterns that you want Git to disregard.\nFor instance:\necho \"/data/\n/results/\" > .gitignore\nThis creates a .gitignore file with two entries (/data/ and /results/) and from now on, any file in either of these directories will be ignored by Git.\nThe .gitignore is a file like any other file, so you‚Äôll want to stage and commit it:\ngit status\nOn branch main\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n        .gitignore\n\nnothing added to commit but untracked files present (use \"git add\" to track)\ngit add .gitignore\ngit commit -m \"Add .gitignore file with data and results\"\n[main a1df8e5] Add .gitignore file with data and results\n 1 file changed, 2 insertions(+)\n create mode 100644 .gitignore\ngit status\nOn branch main\nnothing to commit, working tree clean\n\n\nDisplaying the commit history\nSo far, we have created 5 commits. To display them, you use the command git log:\ngit log\ncommit a1df8e56ad45ddd514ff951f2d65e4e1d40a641c (HEAD -> main)\nAuthor: Marie-Helene Burle <xxx@xxx>\nDate:   Mon Oct 3 22:57:59 2022 -0700\n\n    Add .gitignore file with data and results\n\ncommit a049a2f6834801bf76fa3c2c191a59a3ec589d6e\nAuthor: Marie-Helene Burle <xxx@xxx>\nDate:   Mon Oct 3 21:17:23 2022 -0700\n\n    Define the variable a in R script\n\ncommit c7fc9c1743d8a40c3f72d9450b9440dca1cb5922\nAuthor: Marie-Helene Burle <xxx@xxx>\nDate:   Mon Oct 3 21:16:43 2022 -0700\n\n    Add conclusion to the manuscript\n\ncommit 451c47b386895b8b0b5bdd1a8734ef1d51f9ccc9\nAuthor: Marie-Helene Burle <xxx@xxx>\nDate:   Mon Oct 3 18:35:51 2022 -0700\n\n    Add result section to manuscript\n\ncommit 7f94f8ed631a7390a910fa13cd4954cf9e8a3061\nAuthor: Marie-Helene Burle <xxx@xxx>\nDate:   Mon Oct 3 18:19:28 2022 -0700\n\n    Initial commit\nAs you can see, commits are listed from the bottom up. You can customize the output of git log by playing with the many existing flags (you can run man git-log to get the list of all flags).\nFor instance, you can display each commit as a one-liner:\ngit log --oneline\na1df8e5 (HEAD -> main) Add .gitignore file with data and results\na049a2f Define the variable a in R script\nc7fc9c1 Add conclusion to the manuscript\n451c47b Add result section to manuscript\n7f94f8e Initial commit\nYou can display it as a graph:\ngit log --graph\n* commit a1df8e56ad45ddd514ff951f2d65e4e1d40a641c (HEAD -> main)\n| Author: Marie-Helene Burle <xxx@xxx>\n| Date:   Mon Oct 3 22:57:59 2022 -0700\n|\n|     Add .gitignore file with data and results\n|\n* commit a049a2f6834801bf76fa3c2c191a59a3ec589d6e\n| Author: Marie-Helene Burle <xxx@xxx>\n| Date:   Mon Oct 3 21:17:23 2022 -0700\n|\n|     Define the variable a in R script\n|\n* commit c7fc9c1743d8a40c3f72d9450b9440dca1cb5922\n| Author: Marie-Helene Burle <xxx@xxx>\n| Date:   Mon Oct 3 21:16:43 2022 -0700\n|\n|     Add conclusion to the manuscript\n|\n* commit 451c47b386895b8b0b5bdd1a8734ef1d51f9ccc9\n| Author: Marie-Helene Burle <xxx@xxx>\n| Date:   Mon Oct 3 18:35:51 2022 -0700\n|\n|     Add result section to manuscript\n|\n* commit 7f94f8ed631a7390a910fa13cd4954cf9e8a3061\n  Author: Marie-Helene Burle <xxx@xxx>\n  Date:   Mon Oct 3 18:19:28 2022 -0700\n\n      Initial commit\n\nHere is an example of more complex customization:\n\ngit log \\\n    --graph \\\n    --date=short \\\n    --pretty=format:'%C(cyan)%h %C(blue)%ar %C(auto)%d'`\n                   `'%C(yellow)%s%+b %C(magenta)%ae'\n* a1df8e5 88 seconds ago  (HEAD -> main)Add .gitignore file with data and results xxx@xxx\n* a049a2f 2 hours ago Define the variable a in R script xxx@xxx\n* c7fc9c1 2 hours ago Add conclusion to the manuscript xxx@xxx\n* 451c47b 4 hours ago Add result section to manuscript xxx@xxx\n* 7f94f8e 5 hours ago Initial commit xxx@xxx\n\n\nGetting information about a commit\ngit log is useful to get an overview of our project history, but the information we get about each commit is limited. To get additional information about a particular commit, you can use git show followed by the hash of the commit you are interested about.\nFor instance, let‚Äôs explore our second commit:\ngit show 451c47b  # Replace the hash by the hash of your second commit\ncommit 451c47b386895b8b0b5bdd1a8734ef1d51f9ccc9 (HEAD -> main)\nAuthor: Marie-Helene Burle <xxx@xxx>\nDate:   Mon Oct 3 18:35:51 2022 -0700\n\n    Add result section to manuscript\n\ndiff --git a/ms/chapter3.md b/ms/chapter3.md\nindex b88424b..9408f32 100644\n--- a/ms/chapter3.md\n+++ b/ms/chapter3.md\n@@ -7,3 +7,7 @@ Bla bla bla bla bla.\n ## Methods\n\n Bla bla bla.\n+\n+## Results\n+\n+We now have a bunch of results in our markdown manuscript.\nIn addition to displaying the commit metadata, this also displays the difference with the previous commit.\n\n\nRevisiting old commits\nThe pointer HEAD, which normally points to the branch main which itself points to latest commit, can be moved around. By moving HEAD to any commit, you can revisit the state of your project at that particular version.\nThe command for this is git checkout followed by the hash of the commit you want to revisit.\n\nFor instance, we could revisit the first commit in our example with:\n\ngit checkout 7f94f8e  # Replace the hash by the hash of your first commit\nNote: switching to '7f94f8e'.\n\nYou are in 'detached HEAD' state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by switching back to a branch.\n\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -c with the switch command. Example:\n\n  git switch -c <new-branch-name>\n\nOr undo this operation with:\n\n  git switch -\n\nTurn off this advice by setting config variable advice.detachedHead to false\n\nHEAD is now at 7f94f8e Initial commit\n\nThis is the same as the command git switch --detach 7f94f8e: git switch is a command introduced a few years ago because git checkout can be used for many things in Git and it was confusing many users. git switch allows to switch from one branch to another or, with the --detach flag, to switch to a commit as is the case here.\n\nOnce you have seen what you wanted to see, you can go back to your branch main with:\ngit checkout main\nPrevious HEAD position was 7f94f8e Initial commit\nSwitched to branch 'main'\n\nThis is the same as the command git switch main.\n\n!! Be careful not to forget to go back to your branch main before making changes to your project. If you want to move the project to a new direction from some old commit, you need to create a new branch before doing so. When HEAD points directly to a commit (and not to a branch), this is called ‚ÄúDetached HEAD‚Äù and it is not a position from which you want to modify the project.\n\nIt is totally fine to move HEAD around and have it point directly to a commit (instead of a branch) as long as you are only looking at a version of your project and get back to a branch before doing some work:\n\n\n\n\n\n\nBranches\nOne of the reasons Git has become so popular is its branch system.\nRemember that little pointer called main? That‚Äôs our main branch: the one Git creates automatically when we create our first commit.\nA branch in Git is just that: a little pointer. This makes creating branches extremely quick and cheap. But they are extremely convenient.\nInstead of checking out a commit as we just saw (which creates a detached HEAD state), we can instead create a new branch on that commit with:\ngit switch -c newbranch 7f94f8e  # Replace the hash by the hash of your first commit\nSwitched to a new branch 'newbranch'\nThis creates a new branch called newbranch on our first commit and switches HEAD to it. If you do this instead of entering a detached HEAD state, it is totally safe to make changes and create commits from there. You can easily switch HEAD back and forth between the two branches with:\ngit switch main        # Moves HEAD back to the branch main\nSwitched to branch 'main'\ngit switch newbranch\nSwitched to branch 'newbranch'\ngit status\nOn branch newbranch\nnothing to commit, working tree clean\nIf you already checked out the commit 7f94f8e with git checkout 7f94f8e, you can create the new branch newbranch on that commit and switch to it with:\ngit switch -c newbranch\nSwitched to a new branch 'newbranch'\nThose are equivalent workflows. Just don‚Äôt forget never to work from a detached HEAD state. You can look around in that state, but that‚Äôs it. Why? Because commits that are not part of a branch get automatically deleted on a regular basis when Git runs its garbage collection. So any commits you make from a detached HEAD will eventually be lost. And that‚Äôs probably not what you want.\nIn short, git switch allows you to switch HEAD from one branch to another. With the -c flag, you can create a new branch before switching to it. And by adding some starting point such as a commit, the new branch gets created on that commit rather than on the position of HEAD.\nNow, have a look at what happens if you run git log from newbranch:\ngit log\ncommit 7f94f8ed631a7390a910fa13cd4954cf9e8a3061 (HEAD -> newbranch)\nAuthor: Marie-Helene Burle <xxx@xxx>\nDate:   Mon Oct 3 18:19:28 2022 -0700\n\n    Initial commit\nHorror! It looks like all our commits except for the first one are gone!\nIn fact, they still exist, but by default, git log only shows what is on the current branch. To see all the commits that are on any branch in your project, you need to add the --all flag:\ngit log --all\ncommit 863afd650ecaeab85da2f8ed0d3c88a778754727 (main)\nAuthor: Marie-Helene Burle <xxx@xxx>\nDate:   Tue Oct 4 10:32:39 2022 -0700\n\n    Add .gitignore file with data and results\n\ncommit dc780c75c76220a39f7c89a76bebb670dad25b8e\nAuthor: Marie-Helene Burle <xxx@xxx>\nDate:   Tue Oct 4 10:32:12 2022 -0700\n\n    Define the variable a in R script\n\ncommit 5ba96b254b505f7d04f59f988a621a746a0c6896\nAuthor: Marie-Helene Burle <xxx@xxx>\nDate:   Tue Oct 4 10:28:51 2022 -0700\n\n    Add conclusion to the manuscript\n\ncommit 451c47b386895b8b0b5bdd1a8734ef1d51f9ccc9\nAuthor: Marie-Helene Burle <xxx@xxx>\nDate:   Mon Oct 3 18:35:51 2022 -0700\n\n    Add result section to manuscript\n\ncommit 7f94f8ed631a7390a910fa13cd4954cf9e8a3061 (HEAD -> newbranch)\nAuthor: Marie-Helene Burle <xxx@xxx>\nDate:   Mon Oct 3 18:19:28 2022 -0700\n\n    Initial commit\n\nIn this log, we can now see main, but that HEAD points to newbranch.\n\n\nListing branches\ngit branch\n  main\n* newbranch\nThe * shows the branch you are currently on (i.e.¬†the branch to which HEAD points to).\n\n\nComparing branches\nYou can use git diff to compare branches:\ngit diff newbranch main\ndiff --git a/.gitignore b/.gitignore\nnew file mode 100644\nindex 0000000..e85f44a\n--- /dev/null\n+++ b/.gitignore\n@@ -0,0 +1,2 @@\n+/data/\n+/results/\ndiff --git a/ms/chapter3.md b/ms/chapter3.md\nindex b88424b..80d2c5c 100644\n--- a/ms/chapter3.md\n+++ b/ms/chapter3.md\n@@ -7,3 +7,11 @@ Bla bla bla bla bla.\n ## Methods\n\n Bla bla bla.\n+\n+## Results\n+\n+We now have a bunch of results in our markdown manuscript.\n+\n+## Conclusion\n+\n+And finally, the great conclusion of our paper.\ndiff --git a/src/chapter3.R b/src/chapter3.R\nindex 95f1592..2bf030d 100644\n--- a/src/chapter3.R\n+++ b/src/chapter3.R\n@@ -7,3 +7,5 @@ df <- data.frame(\n )\n\n ggplot(df, aes(x, y)) + geom_point()\n+\n+a = 23\nThis shows all the lines that have been modified (added or deleted) between the commits both branches point to.\n\n\nMerging branches\nIf you want to merge branches, switch to the branch you want to merge into the other one, then run git merge.\nFor instance, if we want to merge newbranch onto main, we would first switch to newbranch (we are already on it, so nothing to do here), then:\ngit merge main\nUpdating 7f94f8e..863afd6\nFast-forward\n .gitignore     | 2 ++\n ms/chapter3.md | 8 ++++++++\n src/chapter3.R | 2 ++\n 3 files changed, 12 insertions(+)\n create mode 100644 .gitignore\nThis merge is called a ‚Äúfast-forward‚Äù merge because main and newbranch had not diverged. It was simply a question of having newbranch catch up to main.\nIf you run git log again, you will see that newbrach has now caught up with main:\ngit log\ncommit 863afd650ecaeab85da2f8ed0d3c88a778754727 (HEAD -> newbranch, main)\nAuthor: Marie-Helene Burle <xxx@xxx>\nDate:   Tue Oct 4 10:32:39 2022 -0700\n\n    Add .gitignore file with data and results\n\ncommit dc780c75c76220a39f7c89a76bebb670dad25b8e\nAuthor: Marie-Helene Burle <xxx@xxx>\nDate:   Tue Oct 4 10:32:12 2022 -0700\n\n    Define the variable a in R script\n\ncommit 5ba96b254b505f7d04f59f988a621a746a0c6896\nAuthor: Marie-Helene Burle <xxx@xxx>\nDate:   Tue Oct 4 10:28:51 2022 -0700\n\n    Add conclusion to the manuscript\n\ncommit 451c47b386895b8b0b5bdd1a8734ef1d51f9ccc9\nAuthor: Marie-Helene Burle <xxx@xxx>\nDate:   Mon Oct 3 18:35:51 2022 -0700\n\n    Add result section to manuscript\n\ncommit 7f94f8ed631a7390a910fa13cd4954cf9e8a3061\nAuthor: Marie-Helene Burle <xxx@xxx>\nDate:   Mon Oct 3 18:19:28 2022 -0700\n\n    Initial commit\n\nHere is a classic situation of fast-forward merge.\nInstead of working on your branch main, you create a test branch and work on it (so HEAD is on the branch test and both move along as you create commits):\n\nWhen you are happy with the changes you made on your test branch, you decide to merge main onto it.\nFirst, you switch to main:\n\nThen you do the fast-forward merge from main onto test (so main catches up to test):\n\nThen, usually, you delete the branch test as it has served its purpose (with git branch -d test). Alternatively, you can switch back to it and do the next bit of experimental work in it. This allows to keep main free of possible mishaps and bad developments (if you aren‚Äôt happy with the work you did on your test branch, you can simply delete it and Git will clean the commits that are on it but not on main during the next garbage collection.\n\n\nIf both branches have diverged (you created commits from both main and newbranch), the merge would require the creation of an additional commit called a ‚Äúmerge commit‚Äù.\n\nHere is a classic situation of merge with a commit.\n\nYou create a test branch and switch to it:\n\n\nThen you create some commits:\n\n\nNow you switch back to main:\n\nAnd you create commits from main too:\n\n\nTo merge your main branch and your test branch, a new commit is now required (note that the command is the same as in the case of a fast-forward merge: git merge. Git will create the new commit automatically. As long as there is no conflict, it is just as easy as a fast-forward merge. We will talk later about resolving conflicts).\n\nAfter which, you can delete the (now useless) test branch (with git branch -d test2):"
  },
  {
    "objectID": "git/intro.html#remotes",
    "href": "git/intro.html#remotes",
    "title": "Version control with Git & GitHub",
    "section": "Remotes",
    "text": "Remotes\n\nWhat are remotes?\nRemotes are copies of a project and its history.\nThey can be located anywhere, including on external drive or on the same machine as the project, although they are often on a different machine to serve as backup, or on a network (e.g.¬†internet) to serve as a syncing hub for collaborations.\nPopular online Git repository managers & hosting services:\n\nGitHub\nGitLab\nBitbucket\n\n\n\nCreating a remote on GitHub\n\nCreate a free GitHub account\nSign up for a free GitHub account.\nLater on, to avoid having to type your password all the time, you should set up SSH for your account.\n\n\nCreate an empty repository on GitHub\n\nGo to the GitHub website, login, and go to your home page.\nLook for the Repositories tab & click the green New button.\nEnter the name you want for your repo, without spaces.\nMake the repository public or private.\n\n\n\nLink empty repository to your repo\nClick on the Code green drop-down button, select SSH if you have set SSH for your GitHub account or HTTPS and copy the address.\nIn the command line, cd inside your project, and add the remote:\ngit remote add <remote-name> <remote-address>\nremote-name is a convenience name to identify that remote. You can choose any name, but since Git automatically call the remote origin when you clone a repo, it is common practice to use origin as the name for the first remote.\n\nExample (using an SSH address):\n\ngit remote add origin git@github.com:<user>/<repo>.git\n\nExample (using an HTTPS address):\n\ngit remote add origin https://github.com/<user>/<repo>.git\n\n\n\nGetting information on remotes\nList remotes:\ngit remote\nList remotes with their addresses:\ngit remote -v\nGet more information on a remote:\ngit remote show <remote-name>\n\nExample:\n\ngit remote show origin\n\n\nManaging remotes\nRename a remote:\ngit remote rename <old-remote-name> <new-remote-name>\nDelete a remote:\ngit remote remove <remote-name>\nChange the address of a remote:\ngit remote set-url <remote-name> <new-url> [<old-url>]\n\n\nGetting data from a remote\nIf you collaborate on a project, you have to get the data added by your teammates to keep your local project up to date.\nTo download new data from a remote, you have 2 options:\n\ngit fetch\ngit pull\n\n\nFetching changes\nFetching downloads the data from a remote that you don‚Äôt already have in your local version of the project:\ngit fetch <remote-name>\nThe branches on the remote are now accessible locally as <remote-name>/<branch>. You can inspect them or you can merge them into your local branches.\n\nExample:\n\ngit fetch origin\n\n\nPulling changes\nPulling fetches the changes & merges them onto your local branches:\ngit pull <remote-name> <branch>\n\nExample:\n\ngit pull origin main\nIf your branch is already tracking a remote branch, you can omit the arguments:\ngit pull\n\n\n\nPushing to a remote\nUploading data to the remote is called pushing:\ngit push <remote-name> <branch-name>\n\nExample:\n\ngit push origin main\nYou can set an upstream branch to track a local branch with the -u flag:\ngit push -u <remote-name> <branch-name>\n\nExample:\n\ngit push -u origin main\nFrom now on, all you have to run when you are on main is:\ngit push\n \n\nby jscript"
  },
  {
    "objectID": "git/intro.html#collaborating-with-git-and-github",
    "href": "git/intro.html#collaborating-with-git-and-github",
    "title": "Version control with Git & GitHub",
    "section": "Collaborating with Git and GitHub",
    "text": "Collaborating with Git and GitHub\n\nSetup\nWhen you collaborate with others using Git and GitHub, there are three possible situations:\n\nYou create a project on your machine and want others to contribute to it (1).\nYou want to contribute to a project started by others & ‚Ä¶\n‚ÄÉ‚ÄÉ‚Ä¶ you have write access to it (2).\n‚ÄÉ‚ÄÉ‚Ä¶ you do not have write access to it (3).\n\n\n(1) You start the project\n\nCreate a remote on GitHub\nThese are the steps we already saw earlier.\n\n1. Create an empty repository on GitHub\n\nGo to the GitHub website, login, and go to your home page.\nLook for the Repositories tab & click the green New button.\nEnter the name you want for your repo, without spaces.\nMake the repository public or private.\n\n\n\n2. Link empty repository to your repo\nClick on the Code green drop-down button, select SSH if you have set SSH for your GitHub account or HTTPS and copy the address.\nIn the command line, cd inside your project, and add the remote:\ngit remote add <remote-name> <remote-address>\nremote-name is a convenience name to identify that remote. You can choose any name, but since Git automatically call the remote origin when you clone a repo, it is common practice to use origin as the name for the first remote.\n\nExample (using an SSH address):\n\ngit remote add origin git@github.com:<user>/<repo>.git\n\nExample (using an HTTPS address):\n\ngit remote add origin https://github.com/<user>/<repo>.git\nIf you are working alone on this project and you only wanted to have a remote for backup, you are set.\nIf you don‚Äôt want to grant others write access to the project, and you only accept contributions through pull requests, you are also set.\nIf you want to grant your collaborators write access to the project however, you need to add them to it.\n\n\n\nInvite collaborators\n\nGo to your GitHub project page.\nClick on the Settings tab.\nClick on the Manage access section on the left-hand side (you will be prompted for your GitHub password).\nClick on the Invite a collaborator green button.\nInvite your collaborators with one of their GitHub user name, their email address, or their full name.\n\n\n\n\n(2) Write access to project\n\nClone project\ncd to location where you want your local copy, then:\ngit clone <remote-address> <local-name>\nThis sets the project as a remote to your new local copy and that remote is automatically called origin.\nWithout <local-name>, the repo will have the name of the last part of the remote address.\n\n\n\n(3) No write access to project\n\nCollaborate without write access\nIn that case, you will have to submit a pull request:\n\nFork the project on GitHub.\nClone your fork on your machine.\nAdd the initial project as a second remote & call it upstream.\nPull from upstream to update your local project.\nCreate & checkout a new branch.\nMake & commit your changes on that branch.\nPush that branch to your fork (i.e.¬†origin ‚Äî remember that you do not have write access to upstream).\nGo to the original project GitHub‚Äôs page & open a pull request.\n\n\n\n\n\nWorkflow\nWhen you collaborate with others using GitHub (or other equivalent service), you and others will work simultaneously on some project. How does this work?\nRemember that to upload your changes to the remote on GitHub you push to it with git push.\nIf one of your collaborators has made changes to the remote (pushing from their own machine), you won‚Äôt be able to push. Instead, you will get the following message:\nTo xxx.git\n ! [rejected]        main -> main (fetch first)\nerror: failed to push some refs to 'xxx.git'\nhint: Updates were rejected because the remote contains work that you do\nhint: not have locally. This is usually caused by another repository pushing\nhint: to the same ref. You may want to first integrate the remote changes\nhint: (e.g., 'git pull ...') before pushing again.\nhint: See the 'Note about fast-forwards' in 'git push --help' for details.\nThe solution?\nYou first have to download (git pull) their work onto your machine, merge it with yours (which will happen automatically if there are no conflicts), before you can push your work to GitHub.\nNow‚Ä¶ what if there are conflicts?\n\n\nResolving conflicts\nGit works line by line. As long as your collaborators and you aren‚Äôt working on the same line(s) of the same file(s) at the same time, there will not be any problem. If however you modified one or more of the same line(s) of the same file(s), Git will not be able to decide which version should be kept. When you git pull their work on your machine, the automatic merging will get interrupted and Git will ask you to resolve the conflict(s) before the merge can resume. It will conveniently tell you which file(s) contain the conflict(s).\nThere are fancy tools to resolve conflicts, but you can do it in any text editor: simply open the file(s) listed by Git as having conflicts and look for the following markers:\n<<<<<<< HEAD\nThis is your version.\n=======\nThis is the alternative version of the same section of the file.\n>>>>>>> alternative version\nThese markers are added by Git to signal the areas of conflict. It is up to you to choose between the two versions (or create a third one) and remove the conflict markers. After that, you can stage the file(s) which contained the conflicts to finish the merge (and then you can commit)."
  },
  {
    "objectID": "git/intro.html#conclusion",
    "href": "git/intro.html#conclusion",
    "title": "Version control with Git & GitHub",
    "section": "Conclusion",
    "text": "Conclusion\nGit is a powerful and fairly complex tool, but you don‚Äôt have to master it entirely to start using it. Start by putting your projects (e.g.¬†thesis chapters, papers) under version control and by creating commits whenever you reach important stages in your work.\nThings will grow from there.\n\n\nfrom xkcd.com"
  },
  {
    "objectID": "git/search.html",
    "href": "git/search.html",
    "title": "Searching the Git history",
    "section": "",
    "text": "What is the point of creating all these commits if you are unable to make use of them because you can‚Äôt find the information you need in them?\nIn this workshop, we will learn how to search your files at any of their versions and search your commits logs.\nBy the end of the workshop, you should be able to retrieve anything you need from your versioned history.\nPrerequisites:\nThis special Git topic is suitable for people who already use Git. You don‚Äôt need to be an expert, but you will need to bring a project under version control with several commits. We expect that you are able to run basic Git commands in the command line."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "WestDRI",
    "section": "",
    "text": "Git\nVersion control with Git and collaboration with GitHub/GitLab\n\n\n\n\nR\nResearch computing in R\n\n\n\n\nJulia\nResearch computing in the Julia programming language\n\n\n\n\nPython\nResearch computing in Python\n\n\n\n\n\n\nMachine learning\nDeep learning with the PyTorch framework\n\n\n\n\nBash\nBash/Zsh scripting, Unix commands, and useful CLI utilities\n\n\n\n\nResearch tools\nOpen source tools for computing and publishing\n\n\n\n¬†\n\n\n\n\n\nMain WestDRI website:\nThis site contains content by Marie-H√©l√®ne Burle. To view all training material, please visit WestDRI‚Äôs main website."
  },
  {
    "objectID": "julia/firstdab.html",
    "href": "julia/firstdab.html",
    "title": "First dab at Julia",
    "section": "",
    "text": "Julia is fast: just-in-time (JIT) compilation and multiple dispatch bring efficiency to interactivity. People often say that using Julia feels like running R or python with a speed almost comparable to that of C.\nBut Julia also comes with parallel computing and multi-threading capabilities.\nIn this webinar, after a quickly presentation of some of the key features of Julia‚Äôs beautifully concise syntax, I will dive into using Julia for HPC."
  },
  {
    "objectID": "julia/flux.html",
    "href": "julia/flux.html",
    "title": "Machine learning in Julia with Flux",
    "section": "",
    "text": "This webinar, aimed at users with no experience in machine learning, is an introduction to the basic concepts of neural networks, followed by a simple example‚Äîthe classic classification of the MNIST database of handwritten digits‚Äîusing the Julia package Flux."
  },
  {
    "objectID": "julia/makie.html",
    "href": "julia/makie.html",
    "title": "Makie",
    "section": "",
    "text": "There are several popular data visualization libraries for the Julia programming language (e.g.¬†Plots, Gadfly, VegaLite, Makie). They vary in their precompilation time, time to first plot, layout capabilities, ability to handle 3D data, ease of use, and syntax style. In this landscape, Makie focuses on high performance, fancy layouts, and extensibility.\nMakie comes with multiple backends. In this workshop, we will cover:\n\nGLMakie (ideal for interactive 2D and 3D plotting)\nWGLMakie (an equivalent that runs within browsers)\nCairoMakie (best for high-quality vector graphics)\n\nWe will also see how to run Makie in the Alliance clusters.\n\nSlides"
  },
  {
    "objectID": "julia/makie_slides.html#plotting-in-julia",
    "href": "julia/makie_slides.html#plotting-in-julia",
    "title": "Makie",
    "section": "Plotting in Julia",
    "text": "Plotting in Julia\n\n\nMany options:\n\nPlots.jl: high-level API for working with different back-ends (GR, Pyplot, Plotly‚Ä¶)\nPyPlot.jl: Julia interface to Matplotlib‚Äôs matplotlib.pyplot\nPlotlyJS.jl: Julia interface to plotly.js\nPlotlyLight.jl: the fastest plotting option in Julia by far, but limited features\nGadfly.jl: following the grammar of graphics popularized by Hadley Wickham in R\nVegaLite.jl: grammar of interactive graphics\nPGFPlotsX.jl: Julia interface to the PGFPlots LaTeX package\nUnicodePlots.jl: plots in the terminal üôÇ\n\n\n\n\nMakie.jl: powerful plotting ecosystem: animation, 3D, GPU optimization"
  },
  {
    "objectID": "julia/makie_slides.html#makie-ecosystem",
    "href": "julia/makie_slides.html#makie-ecosystem",
    "title": "Makie",
    "section": "Makie ecosystem",
    "text": "Makie ecosystem\n\n\n\nMain package:\n\nMakie: plots functionalities. Backend needed to render plots into images or vector graphics\n\n\n\n\n\nBackends:\n\nCairoMakie: vector graphics or high-quality 2D plots. Creates, but does not display plots (you need an IDE that does or you can use ElectronDisplay.jl)\nGLMakie: based on OpenGL; 3D rendering and interactivity in GLFW window (no vector graphics)\nWGLMakie: web version of GLMakie (plots rendered in a browser instead of a window)"
  },
  {
    "objectID": "julia/makie_slides.html#extensions",
    "href": "julia/makie_slides.html#extensions",
    "title": "Makie",
    "section": "Extensions",
    "text": "Extensions\n\nGeoMakie.jl add geographical plotting utilities to Makie\nAlgebraOfGraphics.jl turns plotting into a simple algebra of building blocks\nGraphMakie.jl to create network graphs"
  },
  {
    "objectID": "julia/makie_slides.html#cheatsheet-2d",
    "href": "julia/makie_slides.html#cheatsheet-2d",
    "title": "Makie",
    "section": "Cheatsheet 2D",
    "text": "Cheatsheet 2D\n\nFrom: Storopoli, Huijzer and Alonso (2021). Julia Data Science. https://juliadatascience.io. ISBN: 97984898"
  },
  {
    "objectID": "julia/makie_slides.html#cheatsheet-3d",
    "href": "julia/makie_slides.html#cheatsheet-3d",
    "title": "Makie",
    "section": "Cheatsheet 3D",
    "text": "Cheatsheet 3D\n\nFrom: Storopoli, Huijzer and Alonso (2021). Julia Data Science. https://juliadatascience.io. ISBN: 97984898"
  },
  {
    "objectID": "julia/makie_slides.html#resources",
    "href": "julia/makie_slides.html#resources",
    "title": "Makie",
    "section": "Resources",
    "text": "Resources\n\n\nOfficial documentation\nJulia Data Science book, chapter 5\nMany examples in the project Beautiful Makie"
  },
  {
    "objectID": "julia/makie_slides.html#troubleshooting",
    "href": "julia/makie_slides.html#troubleshooting",
    "title": "Makie",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nInstalling GLMakie can be challenging. This page may lead you towards solutions\nCairoMakie and WGLMakie should install without issues"
  },
  {
    "objectID": "julia/makie_slides.html#figure",
    "href": "julia/makie_slides.html#figure",
    "title": "Makie",
    "section": "Figure",
    "text": "Figure\n\nLoad the package\nHere, we are using CairoMakie\n\nusing CairoMakie                        # no need to import Makie itself\n\n\n\n Create a Figure (container object)\n\nfig = Figure()\n\n\n\n\n\n\n\n \n\ntypeof(fig)\n\nFigure"
  },
  {
    "objectID": "julia/makie_slides.html#axis",
    "href": "julia/makie_slides.html#axis",
    "title": "Makie",
    "section": "Axis",
    "text": "Axis\n\n\n Then, you can create an Axis\n\nax = Axis(Figure()[1, 1])\n\nAxis with 0 plots:\n\n\n\n\n\n \n\ntypeof(ax)\n\nAxis"
  },
  {
    "objectID": "julia/makie_slides.html#plot",
    "href": "julia/makie_slides.html#plot",
    "title": "Makie",
    "section": "Plot",
    "text": "Plot\nFinally, we can add a plot\n\nfig = Figure()\nax = Axis(fig[1, 1])\nx = LinRange(-10, 10, 20)\ny = x\nscatter!(ax, x, y)  # Functions with ! transform their arguments\nfig"
  },
  {
    "objectID": "julia/makie_slides.html#d",
    "href": "julia/makie_slides.html#d",
    "title": "Makie",
    "section": "2D",
    "text": "2D\n\n\nusing CairoMakie\nusing StatsBase, LinearAlgebra\nusing Interpolations, OnlineStats\nusing Distributions\nCairoMakie.activate!(type = \"png\")\n\nfunction eq_hist(matrix; nbins = 256 * 256)\n    h_eq = fit(Histogram, vec(matrix), nbins = nbins)\n    h_eq = normalize(h_eq, mode = :density)\n    cdf = cumsum(h_eq.weights)\n    cdf = cdf / cdf[end]\n    edg = h_eq.edges[1]\n    interp_linear = LinearInterpolation(edg, [cdf..., cdf[end]])\n    out = reshape(interp_linear(vec(matrix)), size(matrix))\n    return out\nend\n\nfunction getcounts!(h, fn; n = 100)\n    for _ in 1:n\n        vals = eigvals(fn())\n        x0 = real.(vals)\n        y0 = imag.(vals)\n        fit!(h, zip(x0,y0))\n    end\nend\n\nm(;a=10rand()-5, b=10rand()-5) = [0 0 0 a; -1 -1 1 0; b 0 0 0; -1 -1 -1 -1]\n\nh = HeatMap(range(-3.5,3.5,length=1200), range(-3.5,3.5, length=1200))\ngetcounts!(h, m; n=2_000_000)\n\nwith_theme(theme_black()) do\n    fig = Figure(figure_padding=0,resolution=(600,600))\n    ax = Axis(fig[1,1]; aspect = DataAspect())\n    heatmap!(ax,-3.5..3.5, -3.5..3.5, eq_hist(h.counts); colormap = :bone_1)\n    hidedecorations!(ax)\n    hidespines!(ax)\n    fig\nend"
  },
  {
    "objectID": "julia/makie_slides.html#d-output",
    "href": "julia/makie_slides.html#d-output",
    "title": "Makie",
    "section": "2D",
    "text": "2D"
  },
  {
    "objectID": "julia/makie_slides.html#d-1",
    "href": "julia/makie_slides.html#d-1",
    "title": "Makie",
    "section": "3D",
    "text": "3D\n\nusing GLMakie, Random\nGLMakie.activate!()\n\nRandom.seed!(13)\nx = -6:0.5:6\ny = -6:0.5:6\nz = 6exp.( -(x.^2 .+ y' .^ 2)./4)\n\nbox = Rect3(Point3f(-0.5), Vec3f(1))\nn = 100\ng(x) = x^(1/10)\nalphas = [g(x) for x in range(0,1,length=n)]\ncmap_alpha = resample_cmap(:linear_worb_100_25_c53_n256, n, alpha = alphas)\n\nwith_theme(theme_dark()) do\n    fig, ax, = meshscatter(x, y, z;\n                           marker=box,\n                           markersize = 0.5,\n                           color = vec(z),\n                           colormap = cmap_alpha,\n                           colorrange = (0,6),\n                           axis = (;\n                                   type = Axis3,\n                                   aspect = :data,\n                                   azimuth = 7.3,\n                                   elevation = 0.189,\n            perspectiveness = 0.5),\n        figure = (;\n            resolution =(1200,800)))\n    meshscatter!(ax, x .+ 7, y, z./2;\n        markersize = 0.25,\n        color = vec(z./2),\n        colormap = cmap_alpha,\n        colorrange = (0, 6),\n        ambient = Vec3f(0.85, 0.85, 0.85),\n        backlight = 1.5f0)\n    xlims!(-5.5,10)\n    ylims!(-5.5,5.5)\n    hidedecorations!(ax; grid = false)\n    hidespines!(ax)\n    fig\nend"
  },
  {
    "objectID": "julia/makie_slides.html#d-1-output",
    "href": "julia/makie_slides.html#d-1-output",
    "title": "Makie",
    "section": "3D",
    "text": "3D"
  },
  {
    "objectID": "julia/makie_slides.html#cairomakie",
    "href": "julia/makie_slides.html#cairomakie",
    "title": "Makie",
    "section": "CairoMakie",
    "text": "CairoMakie\n\nCairoMakie will run without problem on the Alliance clusters\nIt is not designed for interactivity, so saving to file is what makes the most sense\n Example\nsave(\"graph.png\", fig)\n Remember however that CairoMakie is 2D only (for now)"
  },
  {
    "objectID": "julia/makie_slides.html#glmakie",
    "href": "julia/makie_slides.html#glmakie",
    "title": "Makie",
    "section": "GLMakie",
    "text": "GLMakie\n\nGLMakie relies on GLFW to create windows with OpenGL\nGLFW doesn‚Äôt support creating contexts without an associated window\nThe dependency GLFW.jl will thus not install in the clusters‚Äîeven with X11 forwarding‚Äîunless you use VDI nodes, VNC, or Virtual GL"
  },
  {
    "objectID": "julia/makie_slides.html#wglmakie",
    "href": "julia/makie_slides.html#wglmakie",
    "title": "Makie",
    "section": "WGLMakie",
    "text": "WGLMakie\n\nYou can setup a server with JSServe.jl as per the documentation\nHowever, this method is intended at creating interactive widget, e.g.¬†for a website\nWhile this is really cool, it isn‚Äôt optimized for performance\nThere might also be a way to create an SSH tunnel to your local browser, although there is no documentation on this\nBest probably is to save to file"
  },
  {
    "objectID": "julia/makie_slides.html#conclusion-about-the-makie-ecosystem-on-production-clusters",
    "href": "julia/makie_slides.html#conclusion-about-the-makie-ecosystem-on-production-clusters",
    "title": "Makie",
    "section": "Conclusion about the Makie ecosystem on production clusters",
    "text": "Conclusion about the Makie ecosystem on production clusters\n\n2D plots: use CairoMakie and save to file\n3D plots: use WGLMakie and save to file"
  },
  {
    "objectID": "ml/fastai.html",
    "href": "ml/fastai.html",
    "title": "fastai",
    "section": "",
    "text": "fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library. fastai includes:\nA new type dispatch system for Python along with a semantic type hierarchy for tensors A GPU-optimized computer vision library which can be extended in pure Python An optimizer which refactors out the common functionality of modern optimizers into two basic pieces, allowing optimization algorithms to be implemented in 4‚Äì5 lines of code A novel 2-way callback system that can access any part of the data, model, or optimizer and change it at any point during training A new data block API And much more‚Ä¶ fastai is organized around two main design goals: to be approachable and rapidly productive, while also being deeply hackable and configurable. It is built on top of a hierarchy of lower-level APIs which provide composable building blocks. This way, a user wanting to rewrite part of the high-level API or add particular behavior to suit their needs does not have to learn how to use the lowest level.\n\nfastai"
  },
  {
    "objectID": "ml/flux.html",
    "href": "ml/flux.html",
    "title": "Machine learning in Julia with Flux",
    "section": "",
    "text": "Find this webinar in the Julia section."
  },
  {
    "objectID": "ml/overview.html",
    "href": "ml/overview.html",
    "title": "Introduction to machine learning",
    "section": "",
    "text": "We hear about it all the time, but what really is machine learning? And what about deep learning? Neural networks?? How can any of this help me with my work? And how? Which tools do I need to make use of the transformative advances happening in that field??\nThis workshop will answer these questions in a non-technical manner to give you a high level overview of a discipline that has become crucial in all fields of research."
  },
  {
    "objectID": "ml/pretrained_models.html",
    "href": "ml/pretrained_models.html",
    "title": "Finding pretrained models for transfer learning",
    "section": "",
    "text": "Training models from scratch requires way too much data, time, and computing power (or money) to be a practical option. This is why transfer learning has become such a common practice: by starting with models trained on related problems, you are saving time and achieving good results with little data.\nNow, where do you find such models?\nIn this workshop, we will have a look at some of the most popular pre-trained models repositories and libraries (Model Zoo, PyTorch Hub, and Hugging Face); see how you can also search models in the literature and on GitHub; and finally learn how to import models into PyTorch.\nPrerequisites:\nIf you want to follow the hands-on part of this workshop, please make sure to have an up-to-date version of PyTorch (https://pytorch.org/get-started/locally/) on your laptop."
  },
  {
    "objectID": "ml/torchtensors.html",
    "href": "ml/torchtensors.html",
    "title": "Everything you wanted to know (and more) about PyTorch tensors",
    "section": "",
    "text": "Before information can be fed to artificial neural networks (ANNs), it needs to be converted to a form ANNs can process: floating point numbers. Indeed, you don‚Äôt pass a sentence or an image through an ANN; you input numbers representing a sequence of words or pixel values.\nAll these floating point numbers need to be stored in a data structure. The most suited structure is multidimensional (to hold several layers of information) and since all data is of the same type, it is an array.\nPython already has several multidimensional array structures‚Äîthe most popular of which being NumPy‚Äôs ndarray‚Äîbut the particularities of deep learning call for special characteristics: ability to run operations on GPUs and/or in a distributed fashion, as well as the ability to keep track of computation graphs for automatic differentiation.\nThe PyTorch tensor is a Python data structure with these characteristics that can also easily be converted to/from NumPy‚Äôs ndarray and integrates well with other Python libraries such as Pandas.\nIn this webinar, suitable for users of all levels, we will have a deep look at this data structure and go much beyond a basic introduction.\nIn particular, we will:\n\nsee how tensors are stored in memory,\nlook at the metadata which allows this efficient memory storage,\ncover the basics of working with tensors (indexing, vectorized operations‚Ä¶),\nmove tensors to/from GPUs,\nconvert tensors to/from NumPy ndarrays,\nsee how tensors work in distributed frameworks,\nsee how linear algebra can be done with PyTorch tensors."
  },
  {
    "objectID": "ml/upscaling.html",
    "href": "ml/upscaling.html",
    "title": "Image upscaling",
    "section": "",
    "text": "Super-resolution‚Äîthe process of (re)creating high resolution images from low resolution ones‚Äîis an old field, but deep neural networks have seen a sudden surge of new and very impressive methods over the past 10 years, from SRCCN to SRGAN to Transformers.\nIn this webinar, I will give a quick overview of these methods and show how the latest state-of-the-art model‚ÄîSwinIR‚Äîperforms on a few test images. We will use PyTorch as our framework.\n\nSlides"
  },
  {
    "objectID": "ml/upscaling_slides.html#definitions",
    "href": "ml/upscaling_slides.html#definitions",
    "title": "Super-resolution with PyTorch",
    "section": "Definitions",
    "text": "Definitions\nLR: ‚ÄÇ‚ÄÇ¬†low resolution\nHR: ‚ÄÇ‚ÄÇ¬†high resolution\nSR: ‚ÄÇ‚ÄÇ¬†super-resolution = reconstruction of HR images from LR images\nSISR: ¬†¬†single-image super-resolution = SR using a single input image"
  },
  {
    "objectID": "ml/upscaling_slides.html#history-of-super-resolution",
    "href": "ml/upscaling_slides.html#history-of-super-resolution",
    "title": "Super-resolution with PyTorch",
    "section": "History of super-resolution",
    "text": "History of super-resolution\nCan be broken down into 2 main periods:\n\nA rather slow history with various interpolation algorithms of increasing complexity before deep neural networks\nAn incredibly fast evolution since the advent of deep learning (DL)"
  },
  {
    "objectID": "ml/upscaling_slides.html#sr-history-pre-dl",
    "href": "ml/upscaling_slides.html#sr-history-pre-dl",
    "title": "Super-resolution with PyTorch",
    "section": "SR history Pre-DL",
    "text": "SR history Pre-DL\nPixel-wise interpolation prior to DL\nVarious methods ranging from simple (e.g.¬†nearest-neighbour, bicubic) to complex (e.g.¬†Gaussian process regression, iterative FIR Wiener filter) algorithms"
  },
  {
    "objectID": "ml/upscaling_slides.html#sr-history-pre-dl-1",
    "href": "ml/upscaling_slides.html#sr-history-pre-dl-1",
    "title": "Super-resolution with PyTorch",
    "section": "SR history Pre-DL",
    "text": "SR history Pre-DL\nNearest-neighbour interpolation\nSimplest method of interpolation\nSimply uses the value of the nearest pixel\nBicubic interpolation\nConsists of determining the 16 coefficients \\(a_{ij}\\) in:\n\\[p(x, y) = \\sum_{i=0}^3\\sum_{i=0}^3 a\\_{ij} x^i y^j\\]"
  },
  {
    "objectID": "ml/upscaling_slides.html#sr-history-with-dl",
    "href": "ml/upscaling_slides.html#sr-history-with-dl",
    "title": "Super-resolution with PyTorch",
    "section": "SR history with DL",
    "text": "SR history with DL\nDeep learning has seen a fast evolution marked by the successive emergence of various frameworks and architectures over the past 10 years\nSome key network architectures and frameworks:\n\nCNN\nGAN\nTransformers\n\nThese have all been applied to SR"
  },
  {
    "objectID": "ml/upscaling_slides.html#sr-history-with-dl-1",
    "href": "ml/upscaling_slides.html#sr-history-with-dl-1",
    "title": "Super-resolution with PyTorch",
    "section": "SR history with DL",
    "text": "SR history with DL\nSR using (amongst others):\n\nConvolutional Neural Networks (SRCNN) ‚Äî 2014\nRandom Forests ‚Äî 2015\nPerceptual loss ‚Äî 2016\nSub-pixel CNN ‚Äî 2016\nResNet (SRResNet) & Generative Adversarial Network (SRGAN) ‚Äî 2017\nEnhanced SRGAN (ESRGAN) ‚Äî 2018\nPredictive Filter Flow (PFF) ‚Äî 2018\nDensely Residual Laplacian attention Network (DRLN) ‚Äî 2019\nSecond-order Attention Network (SAN) ‚Äî 2019\nLearned downscaling with Content Adaptive Resampler (CAR) ‚Äî 2019\nHolistic Attention Network (HAN) ‚Äî 2020\nSwin Transformer ‚Äî 2021"
  },
  {
    "objectID": "ml/upscaling_slides.html#srcnn",
    "href": "ml/upscaling_slides.html#srcnn",
    "title": "Super-resolution with PyTorch",
    "section": "SRCNN",
    "text": "SRCNN\n\n\nDong, C., Loy, C. C., He, K., & Tang, X. (2015). Image super-resolution using deep convolutional networks. IEEE transactions on pattern analysis and machine intelligence, 38(2), 295-307\n\n\nGiven a low-resolution image Y, the first convolutional layer of the SRCNN extracts a set of feature maps. The second layer maps these feature maps nonlinearly to high-resolution patch representations. The last layer combines the predictions within a spatial neighbourhood to produce the final high-resolution image F(Y)"
  },
  {
    "objectID": "ml/upscaling_slides.html#srcnn-1",
    "href": "ml/upscaling_slides.html#srcnn-1",
    "title": "Super-resolution with PyTorch",
    "section": "SRCNN",
    "text": "SRCNN\nCan use sparse-coding-based methods\n\n\nDong, C., Loy, C. C., He, K., & Tang, X. (2015). Image super-resolution using deep convolutional networks. IEEE transactions on pattern analysis and machine intelligence, 38(2), 295-307"
  },
  {
    "objectID": "ml/upscaling_slides.html#srgan",
    "href": "ml/upscaling_slides.html#srgan",
    "title": "Super-resolution with PyTorch",
    "section": "SRGAN",
    "text": "SRGAN\nDo not provide the best PSNR, but can give more realistic results by providing more texture (less smoothing)"
  },
  {
    "objectID": "ml/upscaling_slides.html#gan",
    "href": "ml/upscaling_slides.html#gan",
    "title": "Super-resolution with PyTorch",
    "section": "GAN",
    "text": "GAN\n\n\nStevens E., Antiga L., & Viehmann T. (2020). Deep Learning with PyTorch"
  },
  {
    "objectID": "ml/upscaling_slides.html#srgan-1",
    "href": "ml/upscaling_slides.html#srgan-1",
    "title": "Super-resolution with PyTorch",
    "section": "SRGAN",
    "text": "SRGAN\n\n\nLedig, C., Theis, L., Husz√°r, F., Caballero, J., Cunningham, A., Acosta, A., ‚Ä¶ & Shi, W. (2017). Photo-realistic single image super-resolution using a generative adversarial network. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp.¬†4681-4690)"
  },
  {
    "objectID": "ml/upscaling_slides.html#srgan-2",
    "href": "ml/upscaling_slides.html#srgan-2",
    "title": "Super-resolution with PyTorch",
    "section": "SRGAN",
    "text": "SRGAN\nFollowed by the ESRGAN and many other flavours of SRGANs"
  },
  {
    "objectID": "ml/upscaling_slides.html#swinir",
    "href": "ml/upscaling_slides.html#swinir",
    "title": "Super-resolution with PyTorch",
    "section": "SwinIR",
    "text": "SwinIR"
  },
  {
    "objectID": "ml/upscaling_slides.html#attention",
    "href": "ml/upscaling_slides.html#attention",
    "title": "Super-resolution with PyTorch",
    "section": "Attention",
    "text": "Attention\n\nMnih, V., Heess, N., & Graves, A. (2014). Recurrent models of visual attention. In Advances in neural information processing systems (pp.¬†2204-2212)\n\n(cited 2769 times)\n\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ‚Ä¶ & Polosukhin, I. (2017). Attention is all you need. In Advances in neural information processing systems (pp.¬†5998-6008)\n\n(cited 30999 times‚Ä¶)"
  },
  {
    "objectID": "ml/upscaling_slides.html#transformers",
    "href": "ml/upscaling_slides.html#transformers",
    "title": "Super-resolution with PyTorch",
    "section": "Transformers",
    "text": "Transformers\n\n\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ‚Ä¶ & Polosukhin, I. (2017). Attention is all you need. In Advances in neural information processing systems (pp.¬†5998-6008)"
  },
  {
    "objectID": "ml/upscaling_slides.html#transformers-1",
    "href": "ml/upscaling_slides.html#transformers-1",
    "title": "Super-resolution with PyTorch",
    "section": "Transformers",
    "text": "Transformers\nInitially used for NLP to replace RNN as they allow parallelization Now entering the domain of vision and others Very performant with relatively few parameters"
  },
  {
    "objectID": "ml/upscaling_slides.html#swin-transformer",
    "href": "ml/upscaling_slides.html#swin-transformer",
    "title": "Super-resolution with PyTorch",
    "section": "Swin Transformer",
    "text": "Swin Transformer\nThe Swin Transformer improved the use of transformers to the vision domain\nSwin = Shifted WINdows"
  },
  {
    "objectID": "ml/upscaling_slides.html#swin-transformer-1",
    "href": "ml/upscaling_slides.html#swin-transformer-1",
    "title": "Super-resolution with PyTorch",
    "section": "Swin Transformer",
    "text": "Swin Transformer\nSwin transformer (left) vs transformer as initially applied to vision (right):\n\n\nLiu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., ‚Ä¶ & Guo, B. (2021). Swin transformer: Hierarchical vision transformer using shifted windows. arXiv preprint arXiv:2103.14030"
  },
  {
    "objectID": "ml/upscaling_slides.html#swinir-1",
    "href": "ml/upscaling_slides.html#swinir-1",
    "title": "Super-resolution with PyTorch",
    "section": "SwinIR",
    "text": "SwinIR\n\n\nLiang, J., Cao, J., Sun, G., Zhang, K., Van Gool, L., & Timofte, R. (2021). SwinIR: Image restoration using swin transformer. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp.¬†1833-1844)"
  },
  {
    "objectID": "ml/upscaling_slides.html#training-sets-used",
    "href": "ml/upscaling_slides.html#training-sets-used",
    "title": "Super-resolution with PyTorch",
    "section": "Training sets used",
    "text": "Training sets used\nDIV2K, Flickr2K, and other datasets"
  },
  {
    "objectID": "ml/upscaling_slides.html#models-assessment",
    "href": "ml/upscaling_slides.html#models-assessment",
    "title": "Super-resolution with PyTorch",
    "section": "Models assessment",
    "text": "Models assessment\n3 metrics commonly used:\nPeak sign-to-noise ratio (PSNR) measured in dB\n\\(\\frac{\\text{Maximum possible power of signal}}{\\text{Power of noise (calculated as the mean squared error)}}\\)\nCalculated at the pixel level\nStructural similarity index measure (SSIM)\nPrediction of perceived image quality based on a ‚Äúperfect‚Äù reference image\nMean opinion score (MOS)\nMean of subjective quality ratings"
  },
  {
    "objectID": "ml/upscaling_slides.html#models-assessment-1",
    "href": "ml/upscaling_slides.html#models-assessment-1",
    "title": "Super-resolution with PyTorch",
    "section": "Models assessment",
    "text": "Models assessment\nPeak sign-to-noise ratio (PSNR) measured in dB\n\\[PSNR = 10\\,\\cdot\\,log_{10}\\,\\left(\\frac{MAX_I^2}{MSE}\\right)\\]\nStructural similarity index measure (SSIM)\n\\[SSIM(x,y) = \\frac{(2\\mu_x\\mu_y + c_1) + (2 \\sigma _{xy} + c_2)}\n    {(\\mu_x^2 + \\mu_y^2+c_1) (\\sigma_x^2 + \\sigma_y^2+c_2)}\\]\nMean opinion score (MOS)\n\\[MOS = \\frac{\\sum_{n=1}^N R\\_n}{N}\\]"
  },
  {
    "objectID": "ml/upscaling_slides.html#metrics-implementation",
    "href": "ml/upscaling_slides.html#metrics-implementation",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics implementation",
    "text": "Metrics implementation\n\nImplement them yourself (using torch.log10, etc.)\nUse some library that implements them (e.g.¬†kornia)\nUse code of open source project with good implementation (e.g.¬†SwinIR)\nUse some higher level library that provides them (e.g.¬†ignite)"
  },
  {
    "objectID": "ml/upscaling_slides.html#metrics-implementation-1",
    "href": "ml/upscaling_slides.html#metrics-implementation-1",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics implementation",
    "text": "Metrics implementation\n\nImplement them yourself (using torch.log10, etc.)\nUse some library that implements them (e.g.¬†kornia)\nUse code of open source project with good implementation (e.g.¬†SwinIR)\nUse some higher level library that provides them (e.g.¬†ignite)"
  },
  {
    "objectID": "ml/upscaling_slides.html#metrics-implementation-2",
    "href": "ml/upscaling_slides.html#metrics-implementation-2",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics implementation",
    "text": "Metrics implementation\nimport kornia\n\npsnr_value = kornia.metrics.psnr(input, target, max_val)\nssim_value = kornia.metrics.ssim(img1, img2, window_size, max_val=1.0, eps=1e-12)\nSee the Kornia documentation for more info on kornia.metrics.psnr & kornia.metrics.ssim"
  },
  {
    "objectID": "ml/upscaling_slides.html#benchmark-datasets",
    "href": "ml/upscaling_slides.html#benchmark-datasets",
    "title": "Super-resolution with PyTorch",
    "section": "Benchmark datasets",
    "text": "Benchmark datasets\nSet5\n\nSet14\n\nBSD100 (Berkeley Segmentation Dataset)"
  },
  {
    "objectID": "ml/upscaling_slides.html#benchmark-datasets-1",
    "href": "ml/upscaling_slides.html#benchmark-datasets-1",
    "title": "Super-resolution with PyTorch",
    "section": "Benchmark datasets",
    "text": "Benchmark datasets\nSet5\n\nSet14\n\nBSD100 (Berkeley Segmentation Dataset)"
  },
  {
    "objectID": "ml/upscaling_slides.html#the-set5-dataset",
    "href": "ml/upscaling_slides.html#the-set5-dataset",
    "title": "Super-resolution with PyTorch",
    "section": "The Set5 dataset",
    "text": "The Set5 dataset\nA dataset consisting of 5 images which has been used for at least 18 years to assess SR methods"
  },
  {
    "objectID": "ml/upscaling_slides.html#how-to-get-the-dataset",
    "href": "ml/upscaling_slides.html#how-to-get-the-dataset",
    "title": "Super-resolution with PyTorch",
    "section": "How to get the dataset?",
    "text": "How to get the dataset?\nFrom the HuggingFace Datasets Hub with the HuggingFace datasets package:\nfrom datasets import load_dataset\n\nset5 = load_dataset('eugenesiow/Set5', 'bicubic_x4', split='validation')"
  },
  {
    "objectID": "ml/upscaling_slides.html#dataset-exploration",
    "href": "ml/upscaling_slides.html#dataset-exploration",
    "title": "Super-resolution with PyTorch",
    "section": "Dataset exploration",
    "text": "Dataset exploration\nprint(set5)\nlen(set5)\nset5[0]\nset5.shape\nset5.column_names\nset5.features\nset5.set_format('torch', columns=['hr', 'lr'])\nset5.format"
  },
  {
    "objectID": "ml/upscaling_slides.html#benchmarks",
    "href": "ml/upscaling_slides.html#benchmarks",
    "title": "Super-resolution with PyTorch",
    "section": "Benchmarks",
    "text": "Benchmarks\nA 2012 review of interpolation methods for SR gives the metrics for a series of interpolation methods (using other datasets)"
  },
  {
    "objectID": "ml/upscaling_slides.html#interpolation-methods",
    "href": "ml/upscaling_slides.html#interpolation-methods",
    "title": "Super-resolution with PyTorch",
    "section": "Interpolation methods",
    "text": "Interpolation methods"
  },
  {
    "objectID": "ml/upscaling_slides.html#dl-methods",
    "href": "ml/upscaling_slides.html#dl-methods",
    "title": "Super-resolution with PyTorch",
    "section": "DL methods",
    "text": "DL methods\nThe Papers with Code website lists available benchmarks on Set5"
  },
  {
    "objectID": "ml/upscaling_slides.html#lets-use-swinir",
    "href": "ml/upscaling_slides.html#lets-use-swinir",
    "title": "Super-resolution with PyTorch",
    "section": "Let‚Äôs use SwinIR",
    "text": "Let‚Äôs use SwinIR\n# Get the model\ngit clone git@github.com:JingyunLiang/SwinIR.git\ncd SwinIR\n\n# Copy our test images in the repo\ncp -r <some/path>/my_tests /testsets/my_tests\n\n# Run the model on our images\npython main_test_swinir.py --tile 400 --task real_sr --scale 4 --large_model --model_path model_zoo/swinir/003_realSR_BSRGAN_DFOWMFC_s64w8_SwinIR-L_x4_GAN.pth --folder_lq testsets/my_tests\nRan in 9 min on my machine with one GPU and 32GB of RAM"
  },
  {
    "objectID": "ml/upscaling_slides.html#results",
    "href": "ml/upscaling_slides.html#results",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ml/upscaling_slides.html#results-1",
    "href": "ml/upscaling_slides.html#results-1",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ml/upscaling_slides.html#results-2",
    "href": "ml/upscaling_slides.html#results-2",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ml/upscaling_slides.html#results-3",
    "href": "ml/upscaling_slides.html#results-3",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ml/upscaling_slides.html#results-4",
    "href": "ml/upscaling_slides.html#results-4",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ml/upscaling_slides.html#results-5",
    "href": "ml/upscaling_slides.html#results-5",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ml/upscaling_slides.html#results-6",
    "href": "ml/upscaling_slides.html#results-6",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ml/upscaling_slides.html#results-7",
    "href": "ml/upscaling_slides.html#results-7",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ml/upscaling_slides.html#results-8",
    "href": "ml/upscaling_slides.html#results-8",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ml/upscaling_slides.html#results-9",
    "href": "ml/upscaling_slides.html#results-9",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ml/upscaling_slides.html#metrics",
    "href": "ml/upscaling_slides.html#metrics",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics",
    "text": "Metrics\nWe could use the PSNR and SSIM implementations from SwinIR, but let‚Äôs try the Kornia functions we mentioned earlier:\n\nkornia.metrics.psnr\nkornia.metrics.ssim"
  },
  {
    "objectID": "ml/upscaling_slides.html#metrics-1",
    "href": "ml/upscaling_slides.html#metrics-1",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics",
    "text": "Metrics\nLet‚Äôs load the libraries we need: tut\nimport kornia\nfrom PIL import Image\nimport torch\nfrom torchvision import transforms"
  },
  {
    "objectID": "ml/upscaling_slides.html#metrics-2",
    "href": "ml/upscaling_slides.html#metrics-2",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics",
    "text": "Metrics\nThen, we load one pair images (LR and HR):\nberlin1_lr = Image.open(\"<some/path>/lr/berlin_1945_1.jpg\")\nberlin1_hr = Image.open(\"<some/path>/hr/berlin_1945_1.png\")\nWe can display these images with:\nberlin1_lr.show()\nberlin1_hr.show()"
  },
  {
    "objectID": "ml/upscaling_slides.html#metrics-3",
    "href": "ml/upscaling_slides.html#metrics-3",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics",
    "text": "Metrics\nNow, we need to resize them so that they have identical dimensions and turn them into tensors:\npreprocess = transforms.Compose([\n        transforms.Resize(256),\n        transforms.ToTensor()\n        ])\n\nberlin1_lr_t = preprocess(berlin1_lr)\nberlin1_hr_t = preprocess(berlin1_hr)"
  },
  {
    "objectID": "ml/upscaling_slides.html#metrics-4",
    "href": "ml/upscaling_slides.html#metrics-4",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics",
    "text": "Metrics\nberlin1_lr_t.shape\nberlin1_hr_t.shape\n\n[Out]\n\ntorch.Size([3, 267, 256])\ntorch.Size([3, 267, 256])\nWe now have tensors with 3 dimensions:\n\nthe channels (RGB)\nthe height of the image (in pixels)\nthe width of the image (in pixels)"
  },
  {
    "objectID": "ml/upscaling_slides.html#metrics-5",
    "href": "ml/upscaling_slides.html#metrics-5",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics",
    "text": "Metrics\nAs data processing is done in batch in ML, we need to add a 4th dimension: the batch size\n(It will be equal to 1 since we have a batch size of a single image)\nbatch_berlin1_lr_t = torch.unsqueeze(berlin1_lr_t, 0)\nbatch_berlin1_hr_t = torch.unsqueeze(berlin1_hr_t, 0)"
  },
  {
    "objectID": "ml/upscaling_slides.html#metrics-6",
    "href": "ml/upscaling_slides.html#metrics-6",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics",
    "text": "Metrics\nOur new tensors are now ready:\nbatch_berlin1_lr_t.shape\nbatch_berlin1_hr_t.shape\n\n[Out]\n\ntorch.Size([1, 3, 267, 256])\ntorch.Size([1, 3, 267, 256])"
  },
  {
    "objectID": "ml/upscaling_slides.html#psnr",
    "href": "ml/upscaling_slides.html#psnr",
    "title": "Super-resolution with PyTorch",
    "section": "PSNR",
    "text": "PSNR\npsnr_value = kornia.metrics.psnr(batch_berlin1_lr_t, batch_berlin1_hr_t, max_val=1.0)\npsnr_value.item()\n\n[Out]\n\n33.379642486572266"
  },
  {
    "objectID": "ml/upscaling_slides.html#ssim",
    "href": "ml/upscaling_slides.html#ssim",
    "title": "Super-resolution with PyTorch",
    "section": "SSIM",
    "text": "SSIM\nssim_map = kornia.metrics.ssim(batch_berlin1_lr_t, batch_berlin1_hr_t, window_size=5, max_val=1.0, eps=1e-12)\nssim_map.mean().item()\n\n[Out]\n\n0.9868119359016418\n\n\n\n¬†Back to workshop page"
  },
  {
    "objectID": "newsletter.html",
    "href": "newsletter.html",
    "title": "Training events mailing list",
    "section": "",
    "text": "If you want to get informed about upcoming training events, please subscribe to our mailing list: \n(We will only email you about training events.)"
  },
  {
    "objectID": "r/basics.html",
    "href": "r/basics.html",
    "title": "R: the basics",
    "section": "",
    "text": "For some general documentation on R, you can run:\nhelp.start()\nTo get help on a function (e.g.¬†sum), you can run:\nhelp(sum)\nDepending on your settings, this will open a documentation for sum in a pager or in your browser."
  },
  {
    "objectID": "r/basics.html#r-settings",
    "href": "r/basics.html#r-settings",
    "title": "R: the basics",
    "section": "R settings",
    "text": "R settings\nSettings are saved in a .Rprofile file. You can edit the file directly in any text editor or from within R.\nList all options:\noptions()\nReturn the value of a particular option:\n\ngetOption(\"help_type\")\n\n[1] \"html\"\n\n\nSet an option:\noptions(help_type = \"html\")"
  },
  {
    "objectID": "r/basics.html#assignment",
    "href": "r/basics.html#assignment",
    "title": "R: the basics",
    "section": "Assignment",
    "text": "Assignment\nR can accept the equal sign (=) for assignments, but it is more idiomatic to use the assignment sign (<-) whenever you bind a name to a value and to use the equal sign everywhere else.\n\na <- 3\n\nOnce you have bound a name to a value, you can recall the value with that name:\n\na  # Note that you do not need to use a print() function in R\n\n[1] 3\n\n\nYou can remove an object from the environment by deleting its name:\n\nrm(a)\na\n\nError in eval(expr, envir, enclos): object 'a' not found\n\n\nThe garbage collector will take care of deleting the object itself from memory."
  },
  {
    "objectID": "r/basics.html#data-types-and-structures",
    "href": "r/basics.html#data-types-and-structures",
    "title": "R: the basics",
    "section": "Data types and structures",
    "text": "Data types and structures\n\n\n\nDimension\nHomogeneous\nHeterogeneous\n\n\n\n\n1 d\nAtomic vector\nList\n\n\n2 d\nMatrix\nData frame\n\n\n3 d\nArray\n\n\n\n\n\nAtomic vectors\n\nWith a single element\n\na <- 2\na\n\n[1] 2\n\ntypeof(a)\n\n[1] \"double\"\n\nstr(a)\n\n num 2\n\nlength(a)\n\n[1] 1\n\ndim(a)\n\nNULL\n\n\nThe dim attribute of a vector doesn‚Äôt exist (hence the NULL). This makes vectors different from one-dimensional arrays which have a dim of 1.\nYou might have noticed that 2 is a double (double precision floating point number, equivalent of ‚Äúfloat‚Äù in other languages). In R, this is the default, even if you don‚Äôt type 2.0. This prevents the kind of weirdness you can find in, for instance, Python.\nIn Python:\n>>> 2 == 2.0\nTrue\n>>> type(2) == type(2.0)\nFalse\n>>> type(2)\n<class 'int'>\n>>> type(2.0)\n<class 'float'>\nIn R:\n> 2 == 2.0\n[1] TRUE\n> typeof(2) == typeof(2.0)\n[1] TRUE\n> typeof(2)\n[1] \"double\"\n> typeof(2.0)\n[1] \"double\"\nIf you want to define an integer variable, you use:\n\nb <- 2L\nb\n\n[1] 2\n\ntypeof(b)\n\n[1] \"integer\"\n\nmode(b)\n\n[1] \"numeric\"\n\nstr(b)\n\n int 2\n\n\nThere are six vector types:\n\nlogical\ninteger\ndouble\ncharacter\ncomplex\nraw\n\n\n\nWith multiple elements\n\nc <- c(2, 4, 1)\nc\n\n[1] 2 4 1\n\ntypeof(c)\n\n[1] \"double\"\n\nmode(c)\n\n[1] \"numeric\"\n\nstr(c)\n\n num [1:3] 2 4 1\n\n\n\nd <- c(TRUE, TRUE, NA, FALSE)\nd\n\n[1]  TRUE  TRUE    NA FALSE\n\ntypeof(d)\n\n[1] \"logical\"\n\nstr(d)\n\n logi [1:4] TRUE TRUE NA FALSE\n\n\nNA (‚ÄúNot Available‚Äù) is a logical constant of length one. It is an indicator for a missing value.\nVectors are homogeneous, so all elements need to be of the same type.\nIf you use elements of different types, R will convert some of them to ensure that they become of the same type:\n\ne <- c(\"This is a string\", 3, \"test\")\ne\n\n[1] \"This is a string\" \"3\"                \"test\"            \n\ntypeof(e)\n\n[1] \"character\"\n\nstr(e)\n\n chr [1:3] \"This is a string\" \"3\" \"test\"\n\n\n\nf <- c(TRUE, 3, FALSE)\nf\n\n[1] 1 3 0\n\ntypeof(f)\n\n[1] \"double\"\n\nstr(f)\n\n num [1:3] 1 3 0\n\n\n\ng <- c(2L, 3, 4L)\ng\n\n[1] 2 3 4\n\ntypeof(g)\n\n[1] \"double\"\n\nstr(g)\n\n num [1:3] 2 3 4\n\n\n\nh <- c(\"string\", TRUE, 2L, 3.1)\nh\n\n[1] \"string\" \"TRUE\"   \"2\"      \"3.1\"   \n\ntypeof(h)\n\n[1] \"character\"\n\nstr(h)\n\n chr [1:4] \"string\" \"TRUE\" \"2\" \"3.1\"\n\n\nThe binary operator : is equivalent to the seq() function and generates a regular sequence of integers:\n\ni <- 1:5\ni\n\n[1] 1 2 3 4 5\n\ntypeof(i)\n\n[1] \"integer\"\n\nstr(i)\n\n int [1:5] 1 2 3 4 5\n\nidentical(2:8, seq(2, 8))\n\n[1] TRUE\n\n\n\n\n\nMatrices\n\nj <- matrix(1:12, nrow = 3, ncol = 4)\nj\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12\n\ntypeof(j)\n\n[1] \"integer\"\n\nstr(j)\n\n int [1:3, 1:4] 1 2 3 4 5 6 7 8 9 10 ...\n\nlength(j)\n\n[1] 12\n\ndim(j)\n\n[1] 3 4\n\n\nThe default is byrow = FALSE. If you want the matrix to be filled in by row, you need to set this argument to TRUE:\n\nk <- matrix(1:12, nrow = 3, ncol = 4, byrow = TRUE)\nk\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    5    6    7    8\n[3,]    9   10   11   12\n\n\n\n\nArrays\n\nl <- array(as.double(1:24), c(3, 2, 4))\nl\n\n, , 1\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\n, , 2\n\n     [,1] [,2]\n[1,]    7   10\n[2,]    8   11\n[3,]    9   12\n\n, , 3\n\n     [,1] [,2]\n[1,]   13   16\n[2,]   14   17\n[3,]   15   18\n\n, , 4\n\n     [,1] [,2]\n[1,]   19   22\n[2,]   20   23\n[3,]   21   24\n\ntypeof(l)\n\n[1] \"double\"\n\nstr(l)\n\n num [1:3, 1:2, 1:4] 1 2 3 4 5 6 7 8 9 10 ...\n\nlength(l)\n\n[1] 24\n\ndim(l)\n\n[1] 3 2 4\n\n\n\n\nLists\n\nm <- list(2, 3)\nm\n\n[[1]]\n[1] 2\n\n[[2]]\n[1] 3\n\ntypeof(m)\n\n[1] \"list\"\n\nstr(m)\n\nList of 2\n $ : num 2\n $ : num 3\n\nlength(m)\n\n[1] 2\n\ndim(m)\n\nNULL\n\n\nAs with atomic vectors, lists do not have a dim attribute. Lists are in fact a different type of vectors.\nLists can be heterogeneous:\n\nn <- list(2L, 3, c(2, 1), FALSE, \"string\")\nn\n\n[[1]]\n[1] 2\n\n[[2]]\n[1] 3\n\n[[3]]\n[1] 2 1\n\n[[4]]\n[1] FALSE\n\n[[5]]\n[1] \"string\"\n\ntypeof(n)\n\n[1] \"list\"\n\nstr(n)\n\nList of 5\n $ : int 2\n $ : num 3\n $ : num [1:2] 2 1\n $ : logi FALSE\n $ : chr \"string\"\n\nlength(n)\n\n[1] 5\n\n\n\n\nData frames\nData frames contain tabular data. Under the hood, a data frame is a list of vectors.\n\no <- data.frame(\n  country = c(\"Canada\", \"USA\", \"Mexico\"),\n  var = c(2.9, 3.1, 4.5)\n)\no\n\n  country var\n1  Canada 2.9\n2     USA 3.1\n3  Mexico 4.5\n\ntypeof(o)\n\n[1] \"list\"\n\nstr(o)\n\n'data.frame':   3 obs. of  2 variables:\n $ country: chr  \"Canada\" \"USA\" \"Mexico\"\n $ var    : num  2.9 3.1 4.5\n\nlength(o)\n\n[1] 2\n\ndim(o)\n\n[1] 3 2"
  },
  {
    "objectID": "r/basics.html#indexing",
    "href": "r/basics.html#indexing",
    "title": "R: the basics",
    "section": "Indexing",
    "text": "Indexing\nIndexing in R starts at 1.\n\na\n\n[1] 2\n\na[1]\n\n[1] 2\n\na[2]\n\n[1] NA\n\nc\n\n[1] 2 4 1\n\nc[2]\n\n[1] 4\n\nc[2:4]\n\n[1]  4  1 NA\n\nj\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12\n\nj[2, 3]\n\n[1] 8\n\nl\n\n, , 1\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\n, , 2\n\n     [,1] [,2]\n[1,]    7   10\n[2,]    8   11\n[3,]    9   12\n\n, , 3\n\n     [,1] [,2]\n[1,]   13   16\n[2,]   14   17\n[3,]   15   18\n\n, , 4\n\n     [,1] [,2]\n[1,]   19   22\n[2,]   20   23\n[3,]   21   24\n\nl[2, 1, 3]\n\n[1] 14\n\nn\n\n[[1]]\n[1] 2\n\n[[2]]\n[1] 3\n\n[[3]]\n[1] 2 1\n\n[[4]]\n[1] FALSE\n\n[[5]]\n[1] \"string\"\n\nn[3]\n\n[[1]]\n[1] 2 1\n\ntypeof(n[3])\n\n[1] \"list\"\n\nn[3][1]\n\n[[1]]\n[1] 2 1\n\nn[[3]]\n\n[1] 2 1\n\ntypeof(n[[3]])\n\n[1] \"double\"\n\nn[[3]][1]\n\n[1] 2\n\no\n\n  country var\n1  Canada 2.9\n2     USA 3.1\n3  Mexico 4.5\n\no[1]\n\n  country\n1  Canada\n2     USA\n3  Mexico\n\ntypeof(o[1])\n\n[1] \"list\"\n\nstr(o[1])\n\n'data.frame':   3 obs. of  1 variable:\n $ country: chr  \"Canada\" \"USA\" \"Mexico\"\n\no[[1]]\n\n[1] \"Canada\" \"USA\"    \"Mexico\"\n\ntypeof(o[[1]])\n\n[1] \"character\"\n\no$country\n\n[1] \"Canada\" \"USA\"    \"Mexico\"\n\ntypeof(o$country)\n\n[1] \"character\""
  },
  {
    "objectID": "r/basics.html#copy-on-modify",
    "href": "r/basics.html#copy-on-modify",
    "title": "R: the basics",
    "section": "Copy-on-modify",
    "text": "Copy-on-modify\nWhile some languages (e.g.¬†Python) do not make a copy if you modify a mutable object, R does.\nLet‚Äôs have a look at Python:\n>>> a = [1, 2, 3]\n>>> b = a\n>>> b\n[1, 2, 3]\n>>> a[0] = 4\n>>> a\n[4, 2, 3]\n>>> b\n[4, 2, 3]\nModifying a also modifies b. If you want to keep b unchanged, you need to explicitly make a copy of a.\nNow, let‚Äôs see what happens in R:\n> a <- c(1, 2, 3)\n> b <- a\n> b\n[1] 1 2 3\n> a[1] <- 4\n> a\n[1] 4 2 3\n> b\n[1] 1 2 3\nHere, the default is to create a new copy in memory when a is transformed so that b remains unchanged. This is more intuitive, but more memory intensive."
  },
  {
    "objectID": "r/basics.html#function-definition",
    "href": "r/basics.html#function-definition",
    "title": "R: the basics",
    "section": "Function definition",
    "text": "Function definition\n\ncompare <- function(x, y) {\n  x == y\n}\n\nWe can now use our function:\n\ncompare(2, 3)\n\n[1] FALSE\n\n\nNote that the result of the last statement is printed automatically:\n\ntest <- function(x, y) {\n  x\n  y\n}\ntest(2, 3)\n\n[1] 3\n\n\nIf you want to return other results, you need to explicitly use the print() function:\n\ntest <- function(x, y) {\n  print(x)\n  y\n}\ntest(2, 3)\n\n[1] 2\n\n\n[1] 3"
  },
  {
    "objectID": "r/basics.html#control-flow",
    "href": "r/basics.html#control-flow",
    "title": "R: the basics",
    "section": "Control flow",
    "text": "Control flow\n\nConditionals\n\ntest_sign <- function(x) {\n  if (x > 0) {\n    \"x is positif\"\n  } else if (x < 0) {\n    \"x is negatif\"\n  } else {\n    \"x is equal to zero\"\n  }\n}\n\n\ntest_sign(3)\n\n[1] \"x is positif\"\n\ntest_sign(-2)\n\n[1] \"x is negatif\"\n\ntest_sign(0)\n\n[1] \"x is equal to zero\"\n\n\n\n\nLoops\n\nfor (i in 1:10) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n\n\nNotice that here we need to use the print() function."
  },
  {
    "objectID": "r/gis_mapping.html",
    "href": "r/gis_mapping.html",
    "title": "GIS mapping in R",
    "section": "",
    "text": "In this webinar, we will create inset maps, faceted maps, animated maps, interactive mapping applications, cartograms, raster maps, and bridge over from R to QGIS thanks to the packages sf, tmap, raster, leaflet, shiny, ggplot2, ggmap, grid, mapview, cartogram, and qgisprocess.\nWe will create inset maps, faceted maps, animated maps, cartograms, and raster maps. We will also add basemaps from OpenStreetMap and Google Maps.\nAll this thanks to the packages sf, tmap, raster, ggplot2, ggmap, grid, mapview, cartogram, and RgoogleMaps.\nSlides"
  },
  {
    "objectID": "r/gis_mapping.html#getting-the-data",
    "href": "r/gis_mapping.html#getting-the-data",
    "title": "GIS mapping in R",
    "section": "Getting the data",
    "text": "Getting the data\n\nDatasets\nFor this webinar, we will use:\n\nthe Alaska as well as the Western Canada and USA subsets of the Randolph Glacier Inventory version 6.01\nthe USGS time series of the named glaciers of Glacier National Park2 The datasets can be downloaded as zip files from these websites.\n\n1¬†RGI Consortium (2017). Randolph Glacier Inventory ‚Äì A Dataset of Global Glacier Outlines: Version 6.0: Technical Report, Global Land Ice Measurements from Space, Colorado, USA. Digital Media. DOI: https://doi.org/10.7265/N5-RGI-60.2¬†Fagre, D.B., McKeon, L.A., Dick, K.A., and Fountain, A.G., 2017, Glacier margin time series (1966, 1998, 2005, 2015) of the named glaciers of Glacier National Park, MT, USA: U.S. Geological Survey data release, https://doi.org/10.5066/F7P26WB1.\n\nBasemaps\nFor our basemaps, we will use data from:\n\nNatural Earth: this dataset can be accessed direction from within R thanks to the packages rnaturalearth (which provides the functions) and rnaturalearthdata (which provides the data)"
  },
  {
    "objectID": "r/gis_mapping.html#loading-and-exploring-data",
    "href": "r/gis_mapping.html#loading-and-exploring-data",
    "title": "GIS mapping in R",
    "section": "Loading and exploring data",
    "text": "Loading and exploring data\nFirst, let‚Äôs load the necessary packages for this webinar:\nlibrary(sf)\nlibrary(tmap)\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(purrr)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\nlibrary(mapview)\nlibrary(grid) # part of base R (already installed), but needs to be explicitly loaded\nWe will start by mapping all the glaciers of Western North America thanks to:\n\nthe Alaska subset of the Randolph Glacier Inventory\nthe Western Canada and USA subset of the Randolph Glacier Inventory\n\nDownload and unzip 02_rgi60_WesternCanadaUS and 01_rgi60_Alaska from the Randolph Glacier Inventory version 6.0.\nData get imported and turned into sf objects by the function sf::st_read():\nak <- st_read(\"01_rgi60_Alaska\")\nwes <- st_read(\"02_rgi60_WesternCanadaUS\")\n\nMake sure to use the absolute paths or the proper paths relative to your working directory (which can be obtained with getwd() and modified with setwd()).\n\nYou can print and explore your new objects:\nak\nwes\n\nstr(ak)\nstr(wes)\nsf objects are data.frame-like objects with a geometry list-column as their last column. That column is itself an object of class sfc (simple feature geometry list column)."
  },
  {
    "objectID": "r/gis_mapping.html#mapping-with-tmap",
    "href": "r/gis_mapping.html#mapping-with-tmap",
    "title": "GIS mapping in R",
    "section": "Mapping with tmap",
    "text": "Mapping with tmap\ntmap follows a grammar of graphic similar to that of ggplot2: you first need to set a shape (a spatial data object) by passing an sf object to tm_shape(). Then you plot one or several layers with one of several tmap functions and you use the + sign between each element.\nTo see the available options, run:\n?tmap-element\nWe could thus plot the glaciers of Alaska with any of the options below:\ntm_shape(ak) +\n  tm_borders()\n\ntm_shape(ak) +\n  tm_fill()\n\ntm_shape(ak) +\n  tm_polygons()      # shows both borders and fill\nHere, we will use tm_polygons() which combines tm_borders() and tm_fill()."
  },
  {
    "objectID": "r/gis_mapping.html#layout-elements-and-attribute-layers",
    "href": "r/gis_mapping.html#layout-elements-and-attribute-layers",
    "title": "GIS mapping in R",
    "section": "Layout elements and attribute layers",
    "text": "Layout elements and attribute layers\nA map without title, compass, or scale bars is not very useful though. We need to add layout elements and attribute layers to the map.\nYou can loop up the many arguments of the tmap functions in the help pages to see how you can customize your maps:\n?tm_layout\n?tm_compass\n?tm_scale_bar\nLet‚Äôs now map the glaciers of Alaska:\ntm_shape(ak) +\n  tm_polygons() +\n  tm_layout(\n    title = \"Glaciers of Alaska\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 500, 1000),\n    position = c(\"right\", \"BOTTOM\")\n  )"
  },
  {
    "objectID": "r/gis_mapping.html#union-of-bounding-boxes",
    "href": "r/gis_mapping.html#union-of-bounding-boxes",
    "title": "GIS mapping in R",
    "section": "Union of bounding boxes",
    "text": "Union of bounding boxes\nNow, if we want to plot all the glaciers of Western North America, we want to combine both sf objects in the same map. A map can contain multiple shapes: you only need to ‚Äúadd‚Äù a tm_shape and its element(s). Before doing so however, it is very important to ensure that they have the same coordinate reference system (CRS):\nst_crs(ak)\nst_crs(wes)\n\nst_crs(ak) == st_crs(wes)\nThey do, so we are good to go.\n\nAs with ggplot2 or GIS graphical user interfaces, the order matters since the layers stack up on top of each other.\n\ntm_shape(ak) +\n  tm_polygons() +\n  tm_shape(wes) +\n  tm_polygons()\nIf you run the code above however, you may be surprised that you are still only plotting the map of Alaska.\nThis is because each map comes with a spatial bounding box (bbox).\nst_bbox(ak)\nst_bbox(wes)\nIn the code above, the bbox is set by the first shape, i.e.¬†our entire map uses the bbox of the Alaska sf object.\nWe first need to create a new bounding box encompassing both bounding boxes:\nnwa_bbox <- st_bbox(\n  st_union(\n    st_as_sfc(st_bbox(wes)),\n    st_as_sfc(st_bbox(ak))\n  )\n)\nWe can now plot the glaciers of Western North America:\ntm_shape(ak, bbox = nwa_bbox) +\n  tm_polygons() +\n  tm_shape(wes) +\n  tm_polygons() +\n  tm_layout(\n    title = \"Glaciers of Western North America\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 1000, 2000),\n    position = c(\"right\", \"BOTTOM\")\n  )"
  },
  {
    "objectID": "r/gis_mapping.html#maps-based-on-an-attribute-variable",
    "href": "r/gis_mapping.html#maps-based-on-an-attribute-variable",
    "title": "GIS mapping in R",
    "section": "Maps based on an attribute variable",
    "text": "Maps based on an attribute variable\nWhat is interesting about glacier maps is to see their evolution through time as glaciers retreat due to climate change. While the Randolph Glacier Inventory (RGI) has an amazing map in terms of spacial coverage, it doesn‚Äôt yet have much temporal data.\nTo look at glacier retreat, we will look at the USGS time series of the named glaciers of Glacier National Park3. These 4 datasets have the contour lines of 39 glaciers for the years 1966, 1998, 2005, and 2015.3¬†Fagre, D.B., McKeon, L.A., Dick, K.A., and Fountain, A.G., 2017, Glacier margin time series (1966, 1998, 2005, 2015) of the named glaciers of Glacier National Park, MT, USA: U.S. Geological Survey data release, https://doi.org/10.5066/F7P26WB1.\nWe could load and clean these datasets one by one. Copying and pasting code however is inefficient and error-prone. A better approach is to do this in a functional programming framework: create a function which does all the data loading and cleaning, then pass each element of a vector of the paths of all 4 datasets to it using purrr::map().\n‚ÄúCleaning‚Äù here consists of selecting the variables we are interested in, putting them in the same order in each dataset (they were not initially) and giving the exact same name across all datasets (there were case inconsistencies between datasets and R is case sensitive).\n## create a function that reads and cleans the data\nprep <- function(dir) {\n  g <- st_read(dir)\n  g %<>% rename_with(~ tolower(gsub(\"Area....\", \"area\", .x)))\n  g %<>% select(\n    year,\n    objectid,\n    glacname,\n    area,\n    shape_leng,\n    x_coord,\n    y_coord,\n    source_sca,\n    source\n  )\n}\n\n## create a vector of dataset names\ndirs <- grep(\"GNPglaciers_.*\", list.dirs(), value = T)\n\n## pass each element of that vector through prep() thanks to map()\ngnp <- map(dirs, prep)\nmap() returns a list, so we now have a list (gnp) of 4 elements: the 4 sf objects containing our cleaned datasets. A list is not really convenient and we will turn it into a single sf object.\nBefore doing so however, we want to make sure that they all have the same CRS:\nst_crs(gnp[[1]]) == st_crs(gnp[[2]])\nst_crs(gnp[[1]]) == st_crs(gnp[[3]])\nst_crs(gnp[[1]]) == st_crs(gnp[[4]])\nThey do, so we can turn gnp into a single sf object:\ngnp <- do.call(\"rbind\", gnp)\n\ngnp\nstr(gnp)\nWe can now map the data:\ntm_shape(gnp) +\n  tm_polygons(\"year\", palette = \"Blues\") +\n  tm_layout(\n    title = \"Glaciers of Glacier National Park\",\n    title.position = c(\"center\", \"top\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 10, 20),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )\n\nI didn‚Äôt want to show the legend title and because there is no option to remove it, I set its color to that of the background."
  },
  {
    "objectID": "r/gis_mapping.html#crs-transformation",
    "href": "r/gis_mapping.html#crs-transformation",
    "title": "GIS mapping in R",
    "section": "CRS transformation",
    "text": "CRS transformation\nWouldn‚Äôt it be nice to have this map as an inset of the previous map so that we can situate it within North America?\nBefore we can do this, we need to make sure that both maps use the same CRS:\nst_crs(ak)\nst_crs(gnp)\n\nWe could use wes instead of ak since we know that both sf objects have the same CRS.\n\nThey don‚Äôt have the same CRS, so we reproject gnp by transforming its data from its current CRS to that of ak.\ngnp <- st_transform(gnp, st_crs(ak))\nst_crs(gnp)"
  },
  {
    "objectID": "r/gis_mapping.html#inset-map",
    "href": "r/gis_mapping.html#inset-map",
    "title": "GIS mapping in R",
    "section": "Inset map",
    "text": "Inset map\nNow we can create our map with an inset: the map of the Western North America glaciers (from the sf object nwa) will be our main map and the map of Glacier National Park (from the sf object gnp) will be the inset.\nIf the goal of this new map is to show the location of the gnp map within the nwa one, we need to add a rectangle showing the bounding box of gnp in the nwa map as a new layer.\nFor this, we create a new sfc_POLYGON from the bounding box of gnp:\ngnp_zone <- st_bbox(gnp) %>%\n  st_as_sfc()\nWe will use it as the following layer within the new map:\ntm_shape(gnp_zone) +\n  tm_borders(lwd = 1.5, col = \"#ff9900\")\nWe assign our new map (with an updated suitable title) to the object main_map:\nmain_map <- tm_shape(ak, bbox = nwa_bbox) +\n  tm_polygons() +\n  tm_shape(wes) +\n  tm_polygons() +\n  tm_shape(gnp_zone) +\n  tm_borders(lwd = 1.5, col = \"#ff9900\") +\n  tm_layout(\n    title = \"Glaciers of Glacier National Park\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 500, 1000),\n    position = c(\"right\", \"BOTTOM\")\n  )\nNext, we will change the frame of the gnp inset to match the color of this new rectangle (to make it visually clear that this is a close-up view of that rectangle). We can also remove the title, compass and scale bar since this is an inset within a map which already have them. We assign this new map to the object inset_map:\ninset_map <- tm_shape(gnp) +\n  tm_polygons(\"year\", palette = \"Blues\") +\n  tm_layout(\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 0.7,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.03, 0.03, 0.03, 0.03),\n    outer.margins = 0,\n    frame = \"#ff9900\",\n    frame.lwd = 3\n  )\nFinally, we combine the two maps with grid::viewport():\nmain_map\nprint(inset_map, vp = viewport(0.41, 0.26, width = 0.5, height = 0.5))"
  },
  {
    "objectID": "r/gis_mapping.html#tiled-web-maps-with-leaflet",
    "href": "r/gis_mapping.html#tiled-web-maps-with-leaflet",
    "title": "GIS mapping in R",
    "section": "Tiled web maps with Leaflet",
    "text": "Tiled web maps with Leaflet\nTiled web maps are interactive maps in a browser using web servers such as Google Maps or OpenStreetMap. Several packages allow to use Leaflet (an open-source JavaScript library for interactive maps) to create tile maps.\n\nWith mapview\nThe simplest option is to use mapview::mapview():\nmapview(gnp)\nThis will open a page in your browser in which you can pan, zoom, select/deselect data layers, and choose from a number of basemap layer options:\n CartoDB.Positron\n OpenTopoMap\n OpenStreetMap\n Esri.WorldImagery\n\n\nWith tmap\ntmap has similar capabilities.\nThe package has 2 modes:\n\nplot is the default mode for static maps that we used earlier.\nview is an interactive viewing mode using Leaflet in a browser. There, as with mapview, you can zoom in/out, select/deselect the different layers, and choose to display one of Esri.WorldGrayCanvas, OpenStreetMap, or Esri.WorldTopoMap basemaps.\n\nYou can toggle between the plot and view modes with ttm(), after which you can re-plot your last plot in the new mode with tmap_last(). You can also do both of these at once with ttmp().\nAlternatively, you can switch to either mode with tmap_mode(\"view\") and tmap_mode(\"plot\").\n\nExample:\n\nEarlier, we plotted all the glaciers of Western North America using tmap:\n\nAfter displaying this map, we could have run:\ntmap_mode(\"view\")\ntmap_last()\nAnd Leaflet would have open the following interactive map in our browser:\n\n\nAfterwards, if you want to create new static plots, don‚Äôt forget to get back to plot mode with tmap_mode(\"plot\")."
  },
  {
    "objectID": "r/gis_mapping.html#mapping-a-subset-of-the-data",
    "href": "r/gis_mapping.html#mapping-a-subset-of-the-data",
    "title": "GIS mapping in R",
    "section": "Mapping a subset of the data",
    "text": "Mapping a subset of the data\nEach glacier has 4 borders: one for each year of survey. They are however quite hard to see on such a large map.\nLet‚Äôs zoom on the Agassiz glacier:\n## select the data points corresponding to the Agassiz Glacier\nag <- g %>% filter(glacname == \"Agassiz Glacier\")\nAnd map it:\ntm_shape(ag) +\n  tm_polygons(\"year\", palette = \"Blues\") +\n  tm_layout(\n    title = \"Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )\n\nNow we can clearly see the retreat of the Agassiz Glacier between 1966 and 2015."
  },
  {
    "objectID": "r/gis_mapping.html#faceted-map",
    "href": "r/gis_mapping.html#faceted-map",
    "title": "GIS mapping in R",
    "section": "Faceted map",
    "text": "Faceted map\nInstead of having all temporal data in a single map however, it can be split across facets:\ntm_shape(ag) +\n  tm_polygons(col = \"#86baff\") +\n  tm_layout(\n    main.title = \"Agassiz Glacier\",\n    main.title.position = c(\"center\", \"top\"),\n    main.title.size = 1.2,\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    ## inner.margins = c(0, 0.03, 0, 0.03),\n    outer.margins = 0,\n    panel.label.bg.color = \"#fcfcfc\",\n    frame = F,\n    asp = 0.6\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 0.6\n  ) +\n  tm_facets(\n    by = \"year\",\n    free.coords = F,\n    ncol = 4\n  )"
  },
  {
    "objectID": "r/gis_mapping.html#animated-map",
    "href": "r/gis_mapping.html#animated-map",
    "title": "GIS mapping in R",
    "section": "Animated map",
    "text": "Animated map\nThe temporal data of the Agassiz Glacier retreat can also be conveyed through an animation:\nagassiz_anim <- tm_shape(ag) +\n  tm_borders() +\n  tm_fill(col = \"#86baff\") +\n  tm_layout(\n    title = \"Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.08, 0, 0.08, 0),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  ) +\n  tm_facets(\n    along = \"year\",\n    free.coords = F\n  )\n\ntmap_animation(\n  agassiz_anim,\n  filename = \"ag.gif\",\n  dpi = 300,\n  inner.margins = c(0.08, 0, 0.08, 0),\n  delay = 100\n)"
  },
  {
    "objectID": "r/gis_mapping.html#additional-resources",
    "href": "r/gis_mapping.html#additional-resources",
    "title": "GIS mapping in R",
    "section": "Additional resources",
    "text": "Additional resources\nOpen GIS data:\nFree GIS Data: list of free GIS datasets\nBooks\nGeocomputation with R by Robin Lovelace, Jakub Nowosad, and Jannes Muenchow\nSpatial Data Science by Edzer Pebesma, Roger Bivand\nSpatial Data Science with R by Robert J. Hijmans\nUsing Spatial Data with R by Claudia A. Engel\nTutorial\nAn Introduction to Spatial Data Analysis and Visualisation in R by the CDRC\nWebsite\nr-spatial by Edzer Pebesma, Marius Appel, and Daniel N√ºst\nCRAN package list\nAnalysis of Spatial Data\nMailing list\nR Special Interest Group on using Geographical data and Mapping"
  },
  {
    "objectID": "r/gis_mapping_slides.html#types-of-spatial-data",
    "href": "r/gis_mapping_slides.html#types-of-spatial-data",
    "title": "GIS mapping in R",
    "section": "Types of spatial data",
    "text": "Types of spatial data\n\nVector data\n\nDiscrete objects\nContain: ‚ÄÇ- geometry:‚ÄÇ shape & location of the objects\n‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ- attributes:‚ÄÇ additional variables (e.g.¬†name, year, type)\nCommon file format:‚ÄÇ GeoJSON, shapefile\n\nExamples: countries, roads, rivers, towns\n\n\nRaster data\n\nContinuous phenomena or spatial fields\nCommon file formats:‚ÄÇ TIFF, GeoTIFF, NetCDF, Esri grid\n\nExamples: temperature, air quality, elevation, water depth"
  },
  {
    "objectID": "r/gis_mapping_slides.html#vector-data-1",
    "href": "r/gis_mapping_slides.html#vector-data-1",
    "title": "GIS mapping in R",
    "section": "Vector data",
    "text": "Vector data\n\nTypes\n\npoint:‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇ¬† single set of coordinates\nmulti-point:‚ÄÉ‚ÄÉ multiple sets of coordinates\npolyline:‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇ¬† multiple sets for which the order matters\nmulti-polyline:‚ÄÉ multiple of the above\npolygon:‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇ¬† same as polyline but first & last sets are the same\nmulti-polygon:‚ÄÉ multiple of the above"
  },
  {
    "objectID": "r/gis_mapping_slides.html#raster-data-1",
    "href": "r/gis_mapping_slides.html#raster-data-1",
    "title": "GIS mapping in R",
    "section": "Raster data",
    "text": "Raster data\n\nGrid of equally sized rectangular cells containing values for some variables\nSize of cells = resolution\nFor computing efficiency, rasters do not have coordinates of each cell, but the bounding box & the number of rows & columns"
  },
  {
    "objectID": "r/gis_mapping_slides.html#coordinate-reference-systems-crs",
    "href": "r/gis_mapping_slides.html#coordinate-reference-systems-crs",
    "title": "GIS mapping in R",
    "section": "Coordinate Reference Systems (CRS)",
    "text": "Coordinate Reference Systems (CRS)\nA location on Earth‚Äôs surface can be identified by its coordinates & some reference system called CRS\nThe coordinates (x, y) are called longitude & latitude\nThere can be a 3rd coordinate (z) for elevation or other measurement‚Äîusually a vertical one\nAnd a 4th (m) for some other data attribute‚Äîusually a horizontal measurement\nIn 3D, longitude & latitude are expressed in angular units (e.g.¬†degrees) & the reference system needed is an angular CRS or geographic coordinate system (GCS)\nIn 2D, they are expressed in linear units (e.g.¬†meters) & the reference system needed is a planar CRS or projected coordinate system (PCS)"
  },
  {
    "objectID": "r/gis_mapping_slides.html#datums",
    "href": "r/gis_mapping_slides.html#datums",
    "title": "GIS mapping in R",
    "section": "Datums",
    "text": "Datums\nSince the Earth is not a perfect sphere, we use spheroidal models to represent its surface. Those are called geodetic datums\nSome datums are global, others local (more accurate in a particular area of the globe, but only useful there) \n\nExamples of commonly used global datums:\n\nWGS84 (World Geodesic System 1984)\nNAD83 (North American Datum of 1983)"
  },
  {
    "objectID": "r/gis_mapping_slides.html#angular-crs",
    "href": "r/gis_mapping_slides.html#angular-crs",
    "title": "GIS mapping in R",
    "section": "Angular CRS",
    "text": "Angular CRS\nAn angular CRS contains a datum, an angular unit & references such as a prime meridian (e.g.¬†the Royal Observatory, Greenwich, England)\nIn an angular CRS or GCS:\n\nLongitude (\\(\\lambda\\)) represents the angle between the prime meridian & the meridian that passes through that location\nLatitude (\\(\\phi\\)) represents the angle between the line that passes through the center of the Earth & that location & its projection on the equatorial plane\n\nLongitude & latitude are thus angular coordinates"
  },
  {
    "objectID": "r/gis_mapping_slides.html#projections",
    "href": "r/gis_mapping_slides.html#projections",
    "title": "GIS mapping in R",
    "section": "Projections",
    "text": "Projections\nTo create a two-dimensional map, you need to project this 3D angular CRS into a 2D one\nVarious projections offer different characteristics. For instance:\n\nsome respect areas (equal-area)\nsome respect the shape of geographic features (conformal)\nsome almost respect both for small areas\n\nIt is important to choose one with sensible properties for your goals\n\nExamples of projections:\n\nMercator\nUTM\nRobinson"
  },
  {
    "objectID": "r/gis_mapping_slides.html#planar-crs",
    "href": "r/gis_mapping_slides.html#planar-crs",
    "title": "GIS mapping in R",
    "section": "Planar CRS",
    "text": "Planar CRS\nA planar CRS is defined by a datum, a projection & a set of parameters such as a linear unit & the origins\nCommon planar CRS have been assigned a unique ID called EPSG code which is much more convenient to use\nIn a planar CRS, coordinates will not be in degrees anymore but in meters (or other length unit)"
  },
  {
    "objectID": "r/gis_mapping_slides.html#resources",
    "href": "r/gis_mapping_slides.html#resources",
    "title": "GIS mapping in R",
    "section": "Resources",
    "text": "Resources\n\nOpen GIS data\nFree GIS Data: list of free GIS datasets\nBooks\nGeocomputation with R by Robin Lovelace, Jakub Nowosad & Jannes Muenchow\nSpatial Data Science by Edzer Pebesma & Roger Bivand\nSpatial Data Science with R by Robert J. Hijmans\nUsing Spatial Data with R by Claudia A. Engel\nTutorial\nAn Introduction to Spatial Data Analysis and Visualisation in R by the CDRC"
  },
  {
    "objectID": "r/gis_mapping_slides.html#resources-1",
    "href": "r/gis_mapping_slides.html#resources-1",
    "title": "GIS mapping in R",
    "section": "Resources",
    "text": "Resources\n\nWebsite\nr-spatial by Edzer Pebesma, Marius Appel & Daniel N√ºst\nCRAN package list\nAnalysis of Spatial Data ¬†\nMailing list\nR Special Interest Group on using Geographical data and Mapping"
  },
  {
    "objectID": "r/gis_mapping_slides.html#data-manipulation",
    "href": "r/gis_mapping_slides.html#data-manipulation",
    "title": "GIS mapping in R",
    "section": "Data manipulation",
    "text": "Data manipulation\nOlder packages\n\nsp\nraster\nrgdal\nrgeos \n\nNewer generation\n\nsf: vector data\nterra: raster data (also has vector data capabilities)"
  },
  {
    "objectID": "r/gis_mapping_slides.html#mapping",
    "href": "r/gis_mapping_slides.html#mapping",
    "title": "GIS mapping in R",
    "section": "Mapping",
    "text": "Mapping\nStatic maps\n\nggplot2 + ggspatial\ntmap \n\nDynamic maps\n\nleaflet\nggplot2 + gganimate\nmapview\nggmap\ntmap"
  },
  {
    "objectID": "r/gis_mapping_slides.html#simple-features-in-r",
    "href": "r/gis_mapping_slides.html#simple-features-in-r",
    "title": "GIS mapping in R",
    "section": "Simple Features in R",
    "text": "Simple Features in R\nGeospatial vectors: points, lines, polygons"
  },
  {
    "objectID": "r/gis_mapping_slides.html#simple-features",
    "href": "r/gis_mapping_slides.html#simple-features",
    "title": "GIS mapping in R",
    "section": "Simple Features",
    "text": "Simple Features\nSimple Features‚Äîdefined by the Open Geospatial Consortium (OGC) & formalized by ISO‚Äîis a set of standards now used by most GIS libraries\nWell-known text (WKT) is a markup language for representing vector geometry objects according to those standards\nA compact computer version also exists‚Äîwell-known binary (WKB)‚Äîused by spatial databases\nThe package sp predates Simple Features\nsf‚Äîlaunched in 2016‚Äîimplements these standards in R in the form of sf objects: data.frames (or tibbles) containing the attributes, extended by sfc objects or simple feature geometries list-columns"
  },
  {
    "objectID": "r/gis_mapping_slides.html#sf-1",
    "href": "r/gis_mapping_slides.html#sf-1",
    "title": "GIS mapping in R",
    "section": "sf",
    "text": "sf\n\nUseful links\n\nGitHub repo\nPaper\nResources\nCheatsheet\n6 vignettes: 1, 2, 3, 4, 5, 6"
  },
  {
    "objectID": "r/gis_mapping_slides.html#sf-objects",
    "href": "r/gis_mapping_slides.html#sf-objects",
    "title": "GIS mapping in R",
    "section": "sf objects",
    "text": "sf objects"
  },
  {
    "objectID": "r/gis_mapping_slides.html#sf-objects-1",
    "href": "r/gis_mapping_slides.html#sf-objects-1",
    "title": "GIS mapping in R",
    "section": "sf objects",
    "text": "sf objects"
  },
  {
    "objectID": "r/gis_mapping_slides.html#sf-objects-2",
    "href": "r/gis_mapping_slides.html#sf-objects-2",
    "title": "GIS mapping in R",
    "section": "sf objects",
    "text": "sf objects"
  },
  {
    "objectID": "r/gis_mapping_slides.html#sf-objects-3",
    "href": "r/gis_mapping_slides.html#sf-objects-3",
    "title": "GIS mapping in R",
    "section": "sf objects",
    "text": "sf objects"
  },
  {
    "objectID": "r/gis_mapping_slides.html#sf-objects-4",
    "href": "r/gis_mapping_slides.html#sf-objects-4",
    "title": "GIS mapping in R",
    "section": "sf objects",
    "text": "sf objects"
  },
  {
    "objectID": "r/gis_mapping_slides.html#sf-functions",
    "href": "r/gis_mapping_slides.html#sf-functions",
    "title": "GIS mapping in R",
    "section": "sf functions",
    "text": "sf functions\n\nMost functions start with st_ (which refers to ‚Äúspatial type‚Äù)"
  },
  {
    "objectID": "r/gis_mapping_slides.html#geospatial-rasters",
    "href": "r/gis_mapping_slides.html#geospatial-rasters",
    "title": "GIS mapping in R",
    "section": "Geospatial rasters",
    "text": "Geospatial rasters\nFaster and simpler replacement for the raster package by the same team\nMostly implemented in C++\nCan work with datasets too large to be loaded into memory"
  },
  {
    "objectID": "r/gis_mapping_slides.html#terra-1",
    "href": "r/gis_mapping_slides.html#terra-1",
    "title": "GIS mapping in R",
    "section": "terra",
    "text": "terra\n\nUseful links\n\nGitHub repo\nResources\nFull manual"
  },
  {
    "objectID": "r/gis_mapping_slides.html#layered-grammar-of-graphics-gis-maps",
    "href": "r/gis_mapping_slides.html#layered-grammar-of-graphics-gis-maps",
    "title": "GIS mapping in R",
    "section": "Layered grammar of graphics GIS maps",
    "text": "Layered grammar of graphics GIS maps"
  },
  {
    "objectID": "r/gis_mapping_slides.html#tmap-1",
    "href": "r/gis_mapping_slides.html#tmap-1",
    "title": "GIS mapping in R",
    "section": "tmap",
    "text": "tmap\n\nUseful links\n\nGitHub repo\nResources\n\nHelp pages and vignettes\n\n?tmap-element\nvignette(\"tmap-getstarted\")\n# All the usual help pages, e.g.:\n?tm_layout"
  },
  {
    "objectID": "r/gis_mapping_slides.html#tmap-functions",
    "href": "r/gis_mapping_slides.html#tmap-functions",
    "title": "GIS mapping in R",
    "section": "tmap functions",
    "text": "tmap functions\nMain functions start with tmap_\nFunctions creating map elements start with tm_"
  },
  {
    "objectID": "r/gis_mapping_slides.html#tmap-functioning",
    "href": "r/gis_mapping_slides.html#tmap-functioning",
    "title": "GIS mapping in R",
    "section": "tmap functioning",
    "text": "tmap functioning\nVery similar to ggplot2\nTypically, a map contains:\n\nOne or multiple layer(s) (the order matters as they stack on top of each other)\nSome layout (e.g.¬†customization of title, background, margins): tm_layout\nA compass: tm_compass\nA scale bar: tm_scale_bar\n\nEach layer contains:\n\nSome data: tm_shape\nHow that data will be represented: e.g.¬†tm_polygons, tm_lines, tm_raster"
  },
  {
    "objectID": "r/gis_mapping_slides.html#tmap-example",
    "href": "r/gis_mapping_slides.html#tmap-example",
    "title": "GIS mapping in R",
    "section": "tmap example",
    "text": "tmap example"
  },
  {
    "objectID": "r/gis_mapping_slides.html#tmap-example-1",
    "href": "r/gis_mapping_slides.html#tmap-example-1",
    "title": "GIS mapping in R",
    "section": "tmap example",
    "text": "tmap example"
  },
  {
    "objectID": "r/gis_mapping_slides.html#tmap-example-2",
    "href": "r/gis_mapping_slides.html#tmap-example-2",
    "title": "GIS mapping in R",
    "section": "tmap example",
    "text": "tmap example"
  },
  {
    "objectID": "r/gis_mapping_slides.html#tmap-example-3",
    "href": "r/gis_mapping_slides.html#tmap-example-3",
    "title": "GIS mapping in R",
    "section": "tmap example",
    "text": "tmap example"
  },
  {
    "objectID": "r/gis_mapping_slides.html#tmap-example-4",
    "href": "r/gis_mapping_slides.html#tmap-example-4",
    "title": "GIS mapping in R",
    "section": "tmap example",
    "text": "tmap example"
  },
  {
    "objectID": "r/gis_mapping_slides.html#tmap-example-5",
    "href": "r/gis_mapping_slides.html#tmap-example-5",
    "title": "GIS mapping in R",
    "section": "tmap example",
    "text": "tmap example"
  },
  {
    "objectID": "r/gis_mapping_slides.html#tmap-example-6",
    "href": "r/gis_mapping_slides.html#tmap-example-6",
    "title": "GIS mapping in R",
    "section": "tmap example",
    "text": "tmap example"
  },
  {
    "objectID": "r/gis_mapping_slides.html#tmap-example-7",
    "href": "r/gis_mapping_slides.html#tmap-example-7",
    "title": "GIS mapping in R",
    "section": "tmap example",
    "text": "tmap example"
  },
  {
    "objectID": "r/gis_mapping_slides.html#ggplot2",
    "href": "r/gis_mapping_slides.html#ggplot2",
    "title": "GIS mapping in R",
    "section": "ggplot2",
    "text": "ggplot2\n\nUseful links\n\nGitHub repo\nResources\nCheatsheet"
  },
  {
    "objectID": "r/gis_mapping_slides.html#ggplot2-1",
    "href": "r/gis_mapping_slides.html#ggplot2-1",
    "title": "GIS mapping in R",
    "section": "ggplot2",
    "text": "ggplot2\ngeom_sf allows to plot sf objects (i.e.¬†make maps)"
  },
  {
    "objectID": "r/gis_mapping_slides.html#data",
    "href": "r/gis_mapping_slides.html#data",
    "title": "GIS mapping in R",
    "section": "Data",
    "text": "Data\nFor this workshop, we will use:\n\nthe Alaska as well as the Western Canada & USA subsets of the Randolph Glacier Inventory version 6.01\nthe USGS time series of the named glaciers of Glacier National Park2\nthe Alaska as well as the Western Canada & USA subsets of the consensus estimate for the ice thickness distribution of all glaciers on Earth dataset3\n\nThe datasets can be downloaded as zip files from these websites\nRGI Consortium (2017). Randolph Glacier Inventory ‚Äì A Dataset of Global Glacier Outlines: Version 6.0: Technical Report, Global Land Ice Measurements from Space, Colorado, USA. Digital Media. DOI: https://doi.org/10.7265/N5-RGI-60.Fagre, D.B., McKeon, L.A., Dick, K.A. & Fountain, A.G., 2017, Glacier margin time series (1966, 1998, 2005, 2015) of the named glaciers of Glacier National Park, MT, USA: U.S. Geological Survey data release. DOI: https://doi.org/10.5066/F7P26WB1.Farinotti, Daniel, 2019, A consensus estimate for the ice thickness distribution of all glaciers on Earth - dataset, Zurich. ETH Zurich. DOI: https://doi.org/10.3929/ethz-b-000315707."
  },
  {
    "objectID": "r/gis_mapping_slides.html#packages-1",
    "href": "r/gis_mapping_slides.html#packages-1",
    "title": "GIS mapping in R",
    "section": "Packages",
    "text": "Packages\nPackages need to be installed before they can be loaded in a session\nPackages on CRAN can be installed with:\ninstall.packages(\"<package-name>\")\n basemaps is not on CRAN & needs to be installed from GitHub thanks to devtools:\ninstall.packages(\"devtools\")\ndevtools::install_github(\"16EAGLE/basemaps\")"
  },
  {
    "objectID": "r/gis_mapping_slides.html#packages-2",
    "href": "r/gis_mapping_slides.html#packages-2",
    "title": "GIS mapping in R",
    "section": "Packages",
    "text": "Packages\nWe load all the packages that we will need at the top of the script:\nlibrary(sf)                 # spatial vector data manipulation\nlibrary(tmap)               # map production & tiled web map\nlibrary(dplyr)              # non GIS specific (tabular data manipulation)\nlibrary(magrittr)           # non GIS specific (pipes)\nlibrary(purrr)              # non GIS specific (functional programming)\nlibrary(rnaturalearth)      # basemap data access functions\nlibrary(rnaturalearthdata)  # basemap data\nlibrary(mapview)            # tiled web map\nlibrary(grid)               # (part of base R) used to create inset map\nlibrary(ggplot2)            # alternative to tmap for map production\nlibrary(ggspatial)          # spatial framework for ggplot2\nlibrary(terra)              # gridded spatial data manipulation\nlibrary(ggmap)              # download basemap data\nlibrary(basemaps)           # download basemap data\nlibrary(magick)             # wrapper around ImageMagick STL\nlibrary(leaflet)            # integrate Leaflet JS in R"
  },
  {
    "objectID": "r/gis_mapping_slides.html#randolph-glacier-inventory",
    "href": "r/gis_mapping_slides.html#randolph-glacier-inventory",
    "title": "GIS mapping in R",
    "section": "Randolph Glacier Inventory",
    "text": "Randolph Glacier Inventory\nThis dataset contains the contour of all glaciers on Earth \nWe will focus on glaciers in Western North America \nYou can download & unzip 02_rgi60_WesternCanadaUS & 01_rgi60_Alaska from the Randolph Glacier Inventory version 6.0"
  },
  {
    "objectID": "r/gis_mapping_slides.html#reading-in-data-1",
    "href": "r/gis_mapping_slides.html#reading-in-data-1",
    "title": "GIS mapping in R",
    "section": "Reading in data",
    "text": "Reading in data\n\nak <- st_read(\"data/01_rgi60_Alaska\")\n\n[Out]\n\nReading layer `01_rgi60_Alaska' from data source `./data/01_rgi60_Alaska'\n               using driver `ESRI Shapefile'\nSimple feature collection with 27108 features and 22 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -176.1425 ymin: 52.05727 xmax: -126.8545 ymax: 69.35167\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "r/gis_mapping_slides.html#reading-in-data-2",
    "href": "r/gis_mapping_slides.html#reading-in-data-2",
    "title": "GIS mapping in R",
    "section": "Reading in data",
    "text": "Reading in data\n\n\n\nYour turn:\n\nRead in the data for the rest of north western America (from 02_rgi60_WesternCanadaUS) and create an sf object called wes"
  },
  {
    "objectID": "r/gis_mapping_slides.html#first-look-at-the-data",
    "href": "r/gis_mapping_slides.html#first-look-at-the-data",
    "title": "GIS mapping in R",
    "section": "First look at the data",
    "text": "First look at the data\nak\n\n[Out]\n\nSimple feature collection with 27108 features and 22 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -176.1425 ymin: 52.05727 xmax: -126.8545 ymax: 69.35167\nGeodetic CRS:  WGS 84\nFirst 10 features:\n           RGIId        GLIMSId  BgnDate  EndDate    CenLon   CenLat O1Region\n1  RGI60-01.00001 G213177E63689N 20090703 -9999999 -146.8230 63.68900        1\n2  RGI60-01.00002 G213332E63404N 20090703 -9999999 -146.6680 63.40400        1\n3  RGI60-01.00003 G213920E63376N 20090703 -9999999 -146.0800 63.37600        1\n4  RGI60-01.00004 G213880E63381N 20090703 -9999999 -146.1200 63.38100        1\n5  RGI60-01.00005 G212943E63551N 20090703 -9999999 -147.0570 63.55100        1\n6  RGI60-01.00006 G213756E63571N 20090703 -9999999 -146.2440 63.57100        1\n7  RGI60-01.00007 G213771E63551N 20090703 -9999999 -146.2295 63.55085        1\n8  RGI60-01.00008 G213704E63543N 20090703 -9999999 -146.2960 63.54300        1\n9  RGI60-01.00009 G212400E63659N 20090703 -9999999 -147.6000 63.65900        1\n10 RGI60-01.00010 G212830E63513N 20090703 -9999999 -147.1700 63.51300        1\nO2Region   Area Zmin Zmax Zmed Slope Aspect  Lmax Status Connect Form\n1         2  0.360 1936 2725 2385    42    346   839      0       0    0\n2         2  0.558 1713 2144 2005    16    162  1197      0       0    0\n3         2  1.685 1609 2182 1868    18    175  2106      0       0    0\n4         2  3.681 1273 2317 1944    19    195  4175      0       0    0\n5         2  2.573 1494 2317 1914    16    181  2981      0       0    0\n6         2 10.470 1201 3547 1740    22     33 10518      0       0    0\n7         2  0.649 1918 2811 2194    23    151  1818      0       0    0\n8         2  0.200 2826 3555 3195    45     80   613      0       0    0\n9         2  1.517 1750 2514 1977    18    274  2255      0       0    0\n10        2  3.806 1280 1998 1666    17     35  3332      0       0    0\nTermType Surging Linkages Name                       geometry\n1         0       9        9 <NA> POLYGON ((-146.818 63.69081...\n2         0       9        9 <NA> POLYGON ((-146.6635 63.4076...\n3         0       9        9 <NA> POLYGON ((-146.0723 63.3834...\n4         0       9        9 <NA> POLYGON ((-146.149 63.37919...\n5         0       9        9 <NA> POLYGON ((-147.0431 63.5502...\n6         0       9        9 <NA> POLYGON ((-146.2436 63.5562...\n7         0       9        9 <NA> POLYGON ((-146.2495 63.5531...\n8         0       9        9 <NA> POLYGON ((-146.2992 63.5443...\n9         0       9        9 <NA> POLYGON ((-147.6147 63.6643...\n10        0       9        9 <NA> POLYGON ((-147.1494 63.5098..."
  },
  {
    "objectID": "r/gis_mapping_slides.html#structure-of-the-data",
    "href": "r/gis_mapping_slides.html#structure-of-the-data",
    "title": "GIS mapping in R",
    "section": "Structure of the data",
    "text": "Structure of the data\nstr(ak)\n\n[Out]\n\nClasses ‚Äòsf‚Äô and 'data.frame':  27108 obs. of  23 variables:\n$ RGIId   : chr  \"RGI60-01.00001\" \"RGI60-01.00002\" \"RGI60-01.00003\" ...\n$ GLIMSId : chr  \"G213177E63689N\" \"G213332E63404N\" \"G213920E63376N\" ...\n$ BgnDate : chr  \"20090703\" \"20090703\" \"20090703\" \"20090703\" ...\n$ EndDate : chr  \"-9999999\" \"-9999999\" \"-9999999\" \"-9999999\" ...\n$ CenLon  : num  -147 -147 -146 -146 -147 ...\n$ CenLat  : num  63.7 63.4 63.4 63.4 63.6 ...\n$ O1Region: chr  \"1\" \"1\" \"1\" \"1\" ...\n$ O2Region: chr  \"2\" \"2\" \"2\" \"2\" ...\n$ Area    : num  0.36 0.558 1.685 3.681 2.573 ...\n$ Zmin    : int  1936 1713 1609 1273 1494 1201 1918 2826 1750 1280 ...\n$ Zmax    : int  2725 2144 2182 2317 2317 3547 2811 3555 2514 1998 ...\n$ Zmed    : int  2385 2005 1868 1944 1914 1740 2194 3195 1977 1666 ...\n$ Slope   : num  42 16 18 19 16 22 23 45 18 17 ...\n$ Aspect  : int  346 162 175 195 181 33 151 80 274 35 ...\n$ Lmax    : int  839 1197 2106 4175 2981 10518 1818 613 2255 3332 ...\n$ Status  : int  0 0 0 0 0 0 0 0 0 0 ...\n$ Connect : int  0 0 0 0 0 0 0 0 0 0 ...\n$ Form    : int  0 0 0 0 0 0 0 0 0 0 ...\n$ TermType: int  0 0 0 0 0 0 0 0 0 0 ...\n$ Surging : int  9 9 9 9 9 9 9 9 9 9 ...\n$ Linkages: int  9 9 9 9 9 9 9 9 9 9 ...\n$ Name    : chr  NA NA NA NA ...\n$ geometry:sfc_POLYGON of length 27108; first list element: List of 1\n..$ : num [1:65, 1:2] -147 -147 -147 -147 -147 ...\n..- attr(*, \"class\")= chr [1:3] \"XY\" \"POLYGON\" \"sfg\"\n- attr(*, \"sf_column\")= chr \"geometry\"\n- attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA ...\n..- attr(*, \"names\")= chr [1:22] \"RGIId\" \"GLIMSId\" \"BgnDate\" \"EndDate\" ..."
  },
  {
    "objectID": "r/gis_mapping_slides.html#inspect-your-data",
    "href": "r/gis_mapping_slides.html#inspect-your-data",
    "title": "GIS mapping in R",
    "section": "Inspect your data",
    "text": "Inspect your data\n\n\nYour turn:\n\nInspect the wes object you created."
  },
  {
    "objectID": "r/gis_mapping_slides.html#read-in-and-clean-datasets",
    "href": "r/gis_mapping_slides.html#read-in-and-clean-datasets",
    "title": "GIS mapping in R",
    "section": "Read in and clean datasets",
    "text": "Read in and clean datasets\n## create a function that reads and cleans the data\nprep <- function(dir) {\n  g <- st_read(dir)\n  g %<>% rename_with(~ tolower(gsub(\"Area....\", \"area\", .x)))\n  g %<>% dplyr::select(\n    year,\n    objectid,\n    glacname,\n    area,\n    shape_leng,\n    x_coord,\n    y_coord,\n    source_sca,\n    source\n  )\n}\n\n## create a vector of dataset names\ndirs <- grep(\"data/GNPglaciers_.*\", list.dirs(), value = T)\n\n## pass each element of that vector through prep() thanks to map()\ngnp <- map(dirs, prep)\n\nWe use dplyr::select because terra also has a select function"
  },
  {
    "objectID": "r/gis_mapping_slides.html#combine-datasets-into-one-sf-object",
    "href": "r/gis_mapping_slides.html#combine-datasets-into-one-sf-object",
    "title": "GIS mapping in R",
    "section": "Combine datasets into one sf object",
    "text": "Combine datasets into one sf object\nCheck that the CRS are all the same:\nall(sapply(\n  list(st_crs(gnp[[1]]),\n       st_crs(gnp[[2]]),\n       st_crs(gnp[[3]]),\n       st_crs(gnp[[4]])),\n  function(x) x == st_crs(gnp[[1]])\n))\n\n[Out]\n\n[1] TRUE"
  },
  {
    "objectID": "r/gis_mapping_slides.html#combine-datasets-into-one-sf-object-1",
    "href": "r/gis_mapping_slides.html#combine-datasets-into-one-sf-object-1",
    "title": "GIS mapping in R",
    "section": "Combine datasets into one sf object",
    "text": "Combine datasets into one sf object\nWe can rbind the elements of our list:\ngnp <- do.call(\"rbind\", gnp)\nYou can inspect your new sf object by calling it or with str"
  },
  {
    "objectID": "r/gis_mapping_slides.html#estimate-for-ice-thickness",
    "href": "r/gis_mapping_slides.html#estimate-for-ice-thickness",
    "title": "GIS mapping in R",
    "section": "Estimate for ice thickness",
    "text": "Estimate for ice thickness\nThis dataset contains an estimate for the ice thickness of all glaciers on Earth\nThe nomenclature follows the Randolph Glacier Inventory\nIce thickness being a spatial field, this is raster data\nWe will use data in RGI60-02.16664_thickness.tif from the ETH Z√ºrich Research Collection which corresponds to one of the glaciers (Agassiz) of Glacier National Park"
  },
  {
    "objectID": "r/gis_mapping_slides.html#load-raster-data",
    "href": "r/gis_mapping_slides.html#load-raster-data",
    "title": "GIS mapping in R",
    "section": "Load raster data",
    "text": "Load raster data\nRead in data and create a SpatRaster object:\nras <- rast(\"data/RGI60-02/RGI60-02.16664_thickness.tif\")"
  },
  {
    "objectID": "r/gis_mapping_slides.html#inspect-our-spatraster-object",
    "href": "r/gis_mapping_slides.html#inspect-our-spatraster-object",
    "title": "GIS mapping in R",
    "section": "Inspect our SpatRaster object",
    "text": "Inspect our SpatRaster object\nras\n\n[Out]\n\nclass       : SpatRaster \ndimensions  : 93, 74, 1  (nrow, ncol, nlyr)\nresolution  : 25, 25  (x, y)\nextent      : 707362.5, 709212.5, 5422962, 5425288  (xmin, xmax, ymin, ymax)\ncoord. ref. : +proj=utm +zone=11 +datum=WGS84 +units=m +no_defs \nsource      : RGI60-02.16664_thickness.tif \nname        : RGI60-02.16664_thickness \nnlyr gives us the number of bands (a single one here). You can also run str(ras)"
  },
  {
    "objectID": "r/gis_mapping_slides.html#our-data",
    "href": "r/gis_mapping_slides.html#our-data",
    "title": "GIS mapping in R",
    "section": "Our data",
    "text": "Our data\nWe now have 3 sf objects & 1 SpatRaster object:\n\nak: ‚ÄÉcontour of glaciers in AK\nwes: ‚ÄÇcontour of glaciers in the rest of Western North America\ngnp: ‚ÄÇtime series of 39 glaciers in Glacier National Park, MT, USA\nras: ‚ÄÇice thickness of the Agassiz Glacier from Glacier National Park"
  },
  {
    "objectID": "r/gis_mapping_slides.html#lets-map-our-sf-object-ak",
    "href": "r/gis_mapping_slides.html#lets-map-our-sf-object-ak",
    "title": "GIS mapping in R",
    "section": "Let‚Äôs map our sf object ak",
    "text": "Let‚Äôs map our sf object ak\nAt a bare minimum, we need tm_shape with the data & some info as to how to represent that data:\ntm_shape(ak) +\n  tm_polygons()"
  },
  {
    "objectID": "r/gis_mapping_slides.html#we-need-to-label-customize-it",
    "href": "r/gis_mapping_slides.html#we-need-to-label-customize-it",
    "title": "GIS mapping in R",
    "section": "We need to label & customize it",
    "text": "We need to label & customize it\ntm_shape(ak) +\n  tm_polygons() +\n  tm_layout(\n    title = \"Glaciers of Alaska\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 500, 1000),\n    position = c(\"right\", \"BOTTOM\")\n  )"
  },
  {
    "objectID": "r/gis_mapping_slides.html#make-a-map-of-the-wes-object",
    "href": "r/gis_mapping_slides.html#make-a-map-of-the-wes-object",
    "title": "GIS mapping in R",
    "section": "Make a map of the wes object",
    "text": "Make a map of the wes object\n\n\nYour turn:\n\nMake a map with the wes object you created with the data for Western North America excluding AK"
  },
  {
    "objectID": "r/gis_mapping_slides.html#now-lets-make-a-map-with-ak-wes",
    "href": "r/gis_mapping_slides.html#now-lets-make-a-map-with-ak-wes",
    "title": "GIS mapping in R",
    "section": "Now, let‚Äôs make a map with ak & wes",
    "text": "Now, let‚Äôs make a map with ak & wes\n\nThe Coordinate Reference Systems (CRS) must be the same\n\n\nsf has a function to retrieve the CRS of an sf object: st_crs\n\n\nst_crs(ak) == st_crs(wes)\n\n[Out]\n\n[1] TRUE\n\n\nSo we‚Äôre good (we will see later what to do if this is not the case)"
  },
  {
    "objectID": "r/gis_mapping_slides.html#our-combined-map",
    "href": "r/gis_mapping_slides.html#our-combined-map",
    "title": "GIS mapping in R",
    "section": "Our combined map",
    "text": "Our combined map\nLet‚Äôs start again with a minimum map without any layout to test things out:\ntm_shape(ak) +\n  tm_polygons() +\n  tm_shape(wes) +\n  tm_polygons()\n\n\nUh ‚Ä¶ oh ‚Ä¶"
  },
  {
    "objectID": "r/gis_mapping_slides.html#what-went-wrong",
    "href": "r/gis_mapping_slides.html#what-went-wrong",
    "title": "GIS mapping in R",
    "section": "What went wrong?",
    "text": "What went wrong?\nMaps are bound by ‚Äúbounding boxes‚Äù. In tmap, they are called bbox\ntmap sets the bbox the first time tm_shape is called. In our case, the bbox was thus set to the bbox of the ak object\nWe need to create a new bbox for our new map"
  },
  {
    "objectID": "r/gis_mapping_slides.html#retrieving-bounding-boxes",
    "href": "r/gis_mapping_slides.html#retrieving-bounding-boxes",
    "title": "GIS mapping in R",
    "section": "Retrieving bounding boxes",
    "text": "Retrieving bounding boxes\nsf has a function to retrieve the bbox of an sf object: st_bbox\nThe bbox of ak is:\nst_bbox(ak)\n\n[Out]\n\nxmin         ymin       xmax         ymax\n-176.14247   52.05727   -126.85450   69.35167"
  },
  {
    "objectID": "r/gis_mapping_slides.html#combining-bounding-boxes",
    "href": "r/gis_mapping_slides.html#combining-bounding-boxes",
    "title": "GIS mapping in R",
    "section": "Combining bounding boxes",
    "text": "Combining bounding boxes\nbbox objects can‚Äôt be combined directly\nHere is how we can create a new bbox encompassing both of our bboxes:\n\nFirst, we transform our bboxes to sfc objects with st_as_sfc\nThen we combine those objects into a new sfc object with st_union\nFinally, we retrieve the bbox of that object with st_bbox:\n\nnwa_bbox <- st_bbox(\n  st_union(\n    st_as_sfc(st_bbox(wes)),\n    st_as_sfc(st_bbox(ak))\n  )\n)"
  },
  {
    "objectID": "r/gis_mapping_slides.html#back-to-our-map",
    "href": "r/gis_mapping_slides.html#back-to-our-map",
    "title": "GIS mapping in R",
    "section": "Back to our map",
    "text": "Back to our map\nWe can now use our new bounding box for the map of Western North America:\ntm_shape(ak, bbox = nwa_bbox) +\n  tm_polygons() +\n  tm_shape(wes) +\n  tm_polygons() +\n  tm_layout(\n    title = \"Glaciers of Western North America\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 1000, 2000),\n    position = c(\"right\", \"BOTTOM\")\n  )"
  },
  {
    "objectID": "r/gis_mapping_slides.html#lets-add-a-basemap",
    "href": "r/gis_mapping_slides.html#lets-add-a-basemap",
    "title": "GIS mapping in R",
    "section": "Let‚Äôs add a basemap",
    "text": "Let‚Äôs add a basemap\nWe will use data from Natural Earth, a public domain map dataset\nThere are much more fancy options, but they usually involve creating accounts (e.g.¬†with Google) to access some API\nIn addition, this dataset can be accessed direction from within R thanks to the rOpenSci packages:\n\nrnaturalearth: provides the functions\nrnaturalearthdata: provides the data"
  },
  {
    "objectID": "r/gis_mapping_slides.html#create-an-sf-object-with-statesprovinces",
    "href": "r/gis_mapping_slides.html#create-an-sf-object-with-statesprovinces",
    "title": "GIS mapping in R",
    "section": "Create an sf object with states/provinces",
    "text": "Create an sf object with states/provinces\n\nstates_all <- ne_states(\n  country = c(\"canada\", \"united states of america\"),\n  returnclass = \"sf\"\n)\n\nne_ stands for ‚ÄúNatural Earth‚Äù"
  },
  {
    "objectID": "r/gis_mapping_slides.html#select-relevant-statesprovinces",
    "href": "r/gis_mapping_slides.html#select-relevant-statesprovinces",
    "title": "GIS mapping in R",
    "section": "Select relevant states/provinces",
    "text": "Select relevant states/provinces\n\nstates <- states_all %>%\n  filter(name_en == \"Alaska\" |\n           name_en == \"British Columbia\" |\n           name_en == \"Yukon\" |\n           name_en == \"Northwest Territories\" |\n           name_en ==  \"Alberta\" |\n           name_en == \"California\" |\n           name_en == \"Washington\" |\n           name_en == \"Oregon\" |\n           name_en == \"Idaho\" |\n           name_en == \"Montana\" |\n           name_en == \"Wyoming\" |\n           name_en == \"Colorado\" |\n           name_en == \"Nevada\" |\n           name_en == \"Utah\"\n         )"
  },
  {
    "objectID": "r/gis_mapping_slides.html#add-the-basemap-to-our-map",
    "href": "r/gis_mapping_slides.html#add-the-basemap-to-our-map",
    "title": "GIS mapping in R",
    "section": "Add the basemap to our map",
    "text": "Add the basemap to our map\n\n\nWhat do we need to make sure of first?\n\n\n\nst_crs(states) == st_crs(ak)\n\n[Out]\n\n[1] TRUE"
  },
  {
    "objectID": "r/gis_mapping_slides.html#add-the-basemap-to-our-map-1",
    "href": "r/gis_mapping_slides.html#add-the-basemap-to-our-map-1",
    "title": "GIS mapping in R",
    "section": "Add the basemap to our map",
    "text": "Add the basemap to our map\nWe add the basemap as a 3rd layer\nMind the order! If you put the basemap last, it will cover your data\nOf course, we will use our nwa_bbox bounding box again\nWe will also break tm_polygons into tm_borders and tm_fill for ak and wes in order to colourise them with slightly different colours"
  },
  {
    "objectID": "r/gis_mapping_slides.html#add-the-basemap-to-our-map-2",
    "href": "r/gis_mapping_slides.html#add-the-basemap-to-our-map-2",
    "title": "GIS mapping in R",
    "section": "Add the basemap to our map",
    "text": "Add the basemap to our map\ntm_shape(states, bbox = nwa_bbox) +\n  tm_polygons(col = \"#f2f2f2\", lwd = 0.2) +\n  tm_shape(ak) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_shape(wes) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_layout(\n    title = \"Glaciers of Western North America\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 1000, 2000),\n    position = c(\"right\", \"BOTTOM\")\n  )"
  },
  {
    "objectID": "r/gis_mapping_slides.html#tmap-styles",
    "href": "r/gis_mapping_slides.html#tmap-styles",
    "title": "GIS mapping in R",
    "section": "tmap styles",
    "text": "tmap styles\ntmap has a number of styles that you can try\nFor instance, to set the style to ‚Äúclassic‚Äù, run the following before making your map:\ntmap_style(\"classic\")\n\nOther options are: \n‚Äúwhite‚Äù (default), ‚Äúgray‚Äù, ‚Äúnatural‚Äù, ‚Äúcobalt‚Äù, ‚Äúcol_blind‚Äù, ‚Äúalbatross‚Äù, ‚Äúbeaver‚Äù, ‚Äúbw‚Äù, ‚Äúwatercolor‚Äù"
  },
  {
    "objectID": "r/gis_mapping_slides.html#tmap-styles-1",
    "href": "r/gis_mapping_slides.html#tmap-styles-1",
    "title": "GIS mapping in R",
    "section": "tmap styles",
    "text": "tmap styles\nTo return to the default, you need to run\ntmap_style(\"white\")\nor\ntmap_options_reset()\nwhich will reset every tmap option"
  },
  {
    "objectID": "r/gis_mapping_slides.html#inset-maps",
    "href": "r/gis_mapping_slides.html#inset-maps",
    "title": "GIS mapping in R",
    "section": "Inset maps",
    "text": "Inset maps\nNow, how can we combine this with our gnp object?\nWe could add it as an inset of our Western North America map"
  },
  {
    "objectID": "r/gis_mapping_slides.html#first-lets-map-it",
    "href": "r/gis_mapping_slides.html#first-lets-map-it",
    "title": "GIS mapping in R",
    "section": "First, let‚Äôs map it",
    "text": "First, let‚Äôs map it\nLet‚Äôs use the same tm_borders and tm_fill we just used:\ntm_shape(gnp) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_layout(\n    title = \"Glaciers of Glacier National Park\",\n    title.position = c(\"center\", \"top\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 10, 20),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )"
  },
  {
    "objectID": "r/gis_mapping_slides.html#create-an-inset-map",
    "href": "r/gis_mapping_slides.html#create-an-inset-map",
    "title": "GIS mapping in R",
    "section": "Create an inset map",
    "text": "Create an inset map\nAs always, first we check that the CRS are the same:\nst_crs(gnp) == st_crs(ak)\n\n[Out]\n\n[1] FALSE\n\nAH!"
  },
  {
    "objectID": "r/gis_mapping_slides.html#crs-transformation",
    "href": "r/gis_mapping_slides.html#crs-transformation",
    "title": "GIS mapping in R",
    "section": "CRS transformation",
    "text": "CRS transformation\nWe need to reproject gnp into the CRS of our other sf objects (e.g.¬†ak):\ngnp <- st_transform(gnp, st_crs(ak))\n\nWe can verify that the CRS are now the same:\nst_crs(gnp) == st_crs(ak)\n\n[Out]\n\n[1] TRUE"
  },
  {
    "objectID": "r/gis_mapping_slides.html#inset-maps-first-step",
    "href": "r/gis_mapping_slides.html#inset-maps-first-step",
    "title": "GIS mapping in R",
    "section": "Inset maps: first step",
    "text": "Inset maps: first step\nAdd a rectangle showing the location of the GNP map in the main North America map\nWe need to create a new sfc object from the gnp bbox so that we can add it to our previous map as a new layer:\ngnp_zone <- st_bbox(gnp) %>%\n  st_as_sfc()"
  },
  {
    "objectID": "r/gis_mapping_slides.html#inset-maps-second-step",
    "href": "r/gis_mapping_slides.html#inset-maps-second-step",
    "title": "GIS mapping in R",
    "section": "Inset maps: second step",
    "text": "Inset maps: second step\nCreate a tmap object of the main map. Of course, we need to edit the title. Also, note the presence of our new layer:lala\nmain_map <- tm_shape(states, bbox = nwa_bbox) +\n  tm_polygons(col = \"#f2f2f2\", lwd = 0.2) +\n  tm_shape(ak) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_shape(wes) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_shape(gnp_zone) +\n  tm_borders(lwd = 1.5, col = \"#ff9900\") +\n  tm_layout(\n    title = \"Glaciers of Glacier National Park\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 500, 1000),\n    position = c(\"right\", \"BOTTOM\")\n  )"
  },
  {
    "objectID": "r/gis_mapping_slides.html#inset-maps-third-step",
    "href": "r/gis_mapping_slides.html#inset-maps-third-step",
    "title": "GIS mapping in R",
    "section": "Inset maps: third step",
    "text": "Inset maps: third step\nCreate a tmap object of the inset map\nWe make sure to matching colours & edit the layouts for better readability:\ninset_map <- tm_shape(gnp) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_layout(\n    legend.show = F,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.03, 0.03, 0.03, 0.03),\n    outer.margins = 0,\n    frame = \"#ff9900\",\n    frame.lwd = 3\n  )"
  },
  {
    "objectID": "r/gis_mapping_slides.html#inset-maps-final-step",
    "href": "r/gis_mapping_slides.html#inset-maps-final-step",
    "title": "GIS mapping in R",
    "section": "Inset maps: final step",
    "text": "Inset maps: final step\nCombine the two tmap objects\nWe print the main map & add the inset map with grid::viewport:\nmain_map\nprint(inset_map, vp = viewport(0.41, 0.26, width = 0.5, height = 0.5))"
  },
  {
    "objectID": "r/gis_mapping_slides.html#mapping-a-subset-of-the-data",
    "href": "r/gis_mapping_slides.html#mapping-a-subset-of-the-data",
    "title": "GIS mapping in R",
    "section": "Mapping a subset of the data",
    "text": "Mapping a subset of the data\n\nTo see the retreat of the ice, we need to zoom in\nLet‚Äôs focus on a single glacier: Agassiz Glacier"
  },
  {
    "objectID": "r/gis_mapping_slides.html#map-of-the-agassiz-glacier",
    "href": "r/gis_mapping_slides.html#map-of-the-agassiz-glacier",
    "title": "GIS mapping in R",
    "section": "Map of the Agassiz Glacier",
    "text": "Map of the Agassiz Glacier\nSelect the data points corresponding to the Agassiz Glacier:\nag <- gnp %>% filter(glacname == \"Agassiz Glacier\")"
  },
  {
    "objectID": "r/gis_mapping_slides.html#map-of-the-agassiz-glacier-1",
    "href": "r/gis_mapping_slides.html#map-of-the-agassiz-glacier-1",
    "title": "GIS mapping in R",
    "section": "Map of the Agassiz Glacier",
    "text": "Map of the Agassiz Glacier\ntm_shape(ag) +\n  tm_polygons() +\n  tm_layout(\n    title = \"Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )\n\n\nNot great ‚Ä¶"
  },
  {
    "objectID": "r/gis_mapping_slides.html#map-based-on-attribute-variables",
    "href": "r/gis_mapping_slides.html#map-based-on-attribute-variables",
    "title": "GIS mapping in R",
    "section": "Map based on attribute variables",
    "text": "Map based on attribute variables\ntm_shape(ag) +\n  tm_polygons(\"year\", palette = \"Blues\") +\n  tm_layout(\n    title = \"Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )"
  },
  {
    "objectID": "r/gis_mapping_slides.html#using-ggplot2-instead-of-tmap",
    "href": "r/gis_mapping_slides.html#using-ggplot2-instead-of-tmap",
    "title": "GIS mapping in R",
    "section": "Using ggplot2 instead of tmap",
    "text": "Using ggplot2 instead of tmap\nAs an alternative to tmap, ggplot2 can plot maps with the geom_sf function:\nggplot(ag) +\n  geom_sf(aes(fill = year)) +\n  scale_fill_brewer(palette = \"Blues\") +\n  labs(title = \"Agassiz Glacier\") +\n  annotation_scale(location = \"bl\", width_hint = 0.4) +\n  annotation_north_arrow(location = \"tr\", which_north = \"true\",\n                         pad_x = unit(0.75, \"in\"), pad_y = unit(0.5, \"in\"),\n                         style = north_arrow_fancy_orienteering) +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5))\nThe package ggspatial adds a lot of functionality to ggplot2 for spatial data"
  },
  {
    "objectID": "r/gis_mapping_slides.html#faceted-map-of-the-retreat-of-agassiz",
    "href": "r/gis_mapping_slides.html#faceted-map-of-the-retreat-of-agassiz",
    "title": "GIS mapping in R",
    "section": "Faceted map of the retreat of Agassiz",
    "text": "Faceted map of the retreat of Agassiz\ntm_shape(ag) +\n  tm_polygons(col = \"#86baff\") +\n  tm_layout(\n    main.title = \"Agassiz Glacier\",\n    main.title.position = c(\"center\", \"top\"),\n    main.title.size = 1.2,\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0, 0.03, 0, 0.03),\n    outer.margins = 0,\n    panel.label.bg.color = \"#fcfcfc\",\n    frame = F,\n    asp = 0.6\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 0.6\n  ) +\n  tm_facets(\n    by = \"year\",\n    free.coords = F,\n    ncol = 4\n  )"
  },
  {
    "objectID": "r/gis_mapping_slides.html#animated-map-of-the-retreat-of-agassiz",
    "href": "r/gis_mapping_slides.html#animated-map-of-the-retreat-of-agassiz",
    "title": "GIS mapping in R",
    "section": "Animated map of the Retreat of Agassiz",
    "text": "Animated map of the Retreat of Agassiz\nFirst, we need to create a tmap object with facets:\nagassiz_anim <- tm_shape(ag) +\n  tm_polygons(col = \"#86baff\") +\n  tm_layout(\n    title = \"Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.08, 0, 0.08, 0),\n    outer.margins = 0,\n    panel.label.bg.color = \"#fcfcfc\"\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  ) +\n  tm_facets(\n    along = \"year\",\n    free.coords = F\n  )"
  },
  {
    "objectID": "r/gis_mapping_slides.html#animated-map-of-the-retreat-of-agassiz-1",
    "href": "r/gis_mapping_slides.html#animated-map-of-the-retreat-of-agassiz-1",
    "title": "GIS mapping in R",
    "section": "Animated map of the Retreat of Agassiz",
    "text": "Animated map of the Retreat of Agassiz\nThen we can pass that object to tmap_animation:\ntmap_animation(\n  agassiz_anim,\n  filename = \"ag.gif\",\n  dpi = 300,\n  inner.margins = c(0.08, 0, 0.08, 0),\n  delay = 100\n)"
  },
  {
    "objectID": "r/gis_mapping_slides.html#map-of-ice-thickness-of-agassiz",
    "href": "r/gis_mapping_slides.html#map-of-ice-thickness-of-agassiz",
    "title": "GIS mapping in R",
    "section": "Map of ice thickness of Agassiz",
    "text": "Map of ice thickness of Agassiz\nNow, let‚Äôs map the estimated ice thickness on Agassiz Glacier\nThis time, we use tm_raster:\ntm_shape(ras) +\n  tm_raster(title = \"\") +\n  tm_layout(\n    title = \"Ice thickness (m) of Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.bg.color = \"#ffffff\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )"
  },
  {
    "objectID": "r/gis_mapping_slides.html#combining-with-randolph-data",
    "href": "r/gis_mapping_slides.html#combining-with-randolph-data",
    "title": "GIS mapping in R",
    "section": "Combining with Randolph data",
    "text": "Combining with Randolph data\nAs always, we check whether the CRS are the same:\nst_crs(ag) == st_crs(ras)\n\n[Out]\n\n[1] FALSE\nWe need to reproject ag (remember that it is best to avoid reprojecting raster data):\nag %<>% st_transform(st_crs(ras))"
  },
  {
    "objectID": "r/gis_mapping_slides.html#combining-with-randolph-data-1",
    "href": "r/gis_mapping_slides.html#combining-with-randolph-data-1",
    "title": "GIS mapping in R",
    "section": "Combining with Randolph data",
    "text": "Combining with Randolph data\nThe retreat & ice thickness layers will hide each other (the order matters!)\nOne option is to use tm_borders for one of them, but we can also use transparency (alpha)\nWe also adjust the legend:\ntm_shape(ras) +\n  tm_raster(title = \"Ice (m)\") +\n  tm_shape(ag) +\n  tm_polygons(\"year\", palette = \"Blues\", alpha = 0.2, title = \"Contour\") +\n  tm_layout(\n    title = \"Ice thickness (m) and retreat of Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.bg.color = \"#ffffff\",\n    legend.text.size = 0.7,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )"
  },
  {
    "objectID": "r/gis_mapping_slides.html#refining-raster-maps",
    "href": "r/gis_mapping_slides.html#refining-raster-maps",
    "title": "GIS mapping in R",
    "section": "Refining raster maps",
    "text": "Refining raster maps\nLet‚Äôs go back to our ice thickness map:"
  },
  {
    "objectID": "r/gis_mapping_slides.html#basemap-with-ggmap",
    "href": "r/gis_mapping_slides.html#basemap-with-ggmap",
    "title": "GIS mapping in R",
    "section": "Basemap with ggmap",
    "text": "Basemap with ggmap\nbasemap <- get_map(\n  bbox = c(\n    left = st_bbox(ag)[1],\n    bottom = st_bbox(ag)[2],\n    right = st_bbox(ag)[3],\n    top = st_bbox(ag)[4]\n  ),\n  source = \"osm\"\n)\n\nggmap is a powerful package, but Google now requires an API key obtained through registration"
  },
  {
    "objectID": "r/gis_mapping_slides.html#basemap-with-basemaps",
    "href": "r/gis_mapping_slides.html#basemap-with-basemaps",
    "title": "GIS mapping in R",
    "section": "Basemap with basemaps",
    "text": "Basemap with basemaps\nThe package basemaps allows to download open source basemap data from several sources, but those cannot easily be combined with sf objects\nThis plots a satellite image of the Agassiz Glacier:\nbasemap_plot(ag, map_service = \"esri\", map_type = \"world_imagery\")"
  },
  {
    "objectID": "r/gis_mapping_slides.html#satellite-image-of-the-agassiz-glacier",
    "href": "r/gis_mapping_slides.html#satellite-image-of-the-agassiz-glacier",
    "title": "GIS mapping in R",
    "section": "Satellite image of the Agassiz Glacier",
    "text": "Satellite image of the Agassiz Glacier"
  },
  {
    "objectID": "r/gis_mapping_slides.html#mapview",
    "href": "r/gis_mapping_slides.html#mapview",
    "title": "GIS mapping in R",
    "section": "mapview",
    "text": "mapview\nmapview(gnp)"
  },
  {
    "objectID": "r/gis_mapping_slides.html#mapview-1",
    "href": "r/gis_mapping_slides.html#mapview-1",
    "title": "GIS mapping in R",
    "section": "mapview",
    "text": "mapview\n\n\n\n<div class=\"column\">\n  <img style=\"box-shadow: 0px 0px 6px rgba(0,0,0,0.3)\" src=\"img/mapview4.jpg\">\n  <div align=\"right\" style=\"font-size: 1.3rem; color: #978282; line-height: 1rem\">\n<figcaption>\n  <em>\n    CartoDB.Positron\n  </em>\n</figcaption>\n  \n\n<div class=\"column\">\n  <img style=\"box-shadow: 0px 0px 6px rgba(0,0,0,0.3)\" src=\"img/mapview1.jpg\"  >\n  <div align=\"right\" style=\"font-size: 1.3rem; color: #978282; line-height: 1rem\">\n<figcaption>\n  <em>\n    OpenTopoMap\n  </em>\n</figcaption>\n  \n\n<div class=\"column\">\n  <img style=\"box-shadow: 0px 0px 6px rgba(0,0,0,0.3)\" src=\"img/mapview3.jpg\" margin=\"5rem\" >\n  <div align=\"right\" style=\"font-size: 1.3rem; color: #978282; line-height: 1rem\">\n<figcaption>\n  <em>\n    OpenStreetMap\n  </em>\n</figcaption>\n  \n\n<div class=\"column\">\n  <img style=\"box-shadow: 0px 0px 6px rgba(0,0,0,0.3)\" src=\"img/mapview2.jpg\" margin=\"5rem\" >\n  <div align=\"right\" style=\"font-size: 1.3rem; color: #978282; line-height: 1rem\">\n<figcaption>\n  <em>\n    Esri.WorldImagery\n  </em>\n</figcaption>"
  },
  {
    "objectID": "r/gis_mapping_slides.html#tmap-2",
    "href": "r/gis_mapping_slides.html#tmap-2",
    "title": "GIS mapping in R",
    "section": "tmap",
    "text": "tmap\nSo far, we have used the plot mode of tmap. There is also a view mode which allows interactive viewing in a browser through Leaflet\nChange to view mode:\ntmap_mode(\"view\")\n\nYou can also toggle between modes with ttm\n\nRe-plot the last map we plotted with tmap:\ntmap_last()"
  },
  {
    "objectID": "r/gis_mapping_slides.html#leaflet",
    "href": "r/gis_mapping_slides.html#leaflet",
    "title": "GIS mapping in R",
    "section": "leaflet",
    "text": "leaflet\nleaflet creates a map widget to which you add layers\nmap <- leaflet()\naddTiles(map)"
  },
  {
    "objectID": "r/hpc_intro.html",
    "href": "r/hpc_intro.html",
    "title": "Introduction to high-performance research computing in R",
    "section": "",
    "text": "This talk is an introduction to heavy computations in R.\nIt will cover:\n\nrunning R on the Alliance clusters,\nbenchmarking R code,\nprofiling R code,\nan introduction to parallel R,\nan introduction to using C++ through the Rcpp package."
  },
  {
    "objectID": "r/hpc_intro_slides.html#loading-the-r-module",
    "href": "r/hpc_intro_slides.html#loading-the-r-module",
    "title": "Introduction to high-performance research computing in R",
    "section": "Loading the R module",
    "text": "Loading the R module\nIn this webinar, I am using a virtual training cluster mimicking the Alliance clusters. The only differences reside in the loading of modules and I will make clear what they are.\nTo see what versions of R are available on a cluster, run:\n$ module spider r\nFor this webinar, I will load version 4.2.1.\nOn the Alliance clusters, StdEnv/2020 is automatically loaded, so you don‚Äôt have to include it in the line below (although it doesn‚Äôt hurt to have it). On our training cluster, this is the first module I need to run.\n$ module load StdEnv/2020 gcc/11.3.0 r/4.2.1\n\nNote that, in theory, you could run R using the proprietary Intel module which is loaded by default on the Alliance clusters, but it is recommended to replace it by the gcc module to compile R packages as some packages will need tweaking before they can be compiled by the Intel compiler (R packages can even be compiled with clang and LLVM, but the default GCC compiler is the best way to avoid headaches).\nIt is thus much simpler to always load the gcc module before loading the R module."
  },
  {
    "objectID": "r/hpc_intro_slides.html#installing-r-packages",
    "href": "r/hpc_intro_slides.html#installing-r-packages",
    "title": "Introduction to high-performance research computing in R",
    "section": "Installing R packages",
    "text": "Installing R packages\nTo install a package, launch the interactive R console with:\n$ R\nThen, in the R console, run:\ninstall.packages('<package_name>', repos='https://mirror.rcg.sfu.ca/mirror/CRAN/')  # Best CRAN mirror for Cedar\n{{}} You have to select a CRAN mirror from this list. Ideally, use a mirror close to the location of the cluster you are using or use https://cloud.r-project.org/. {{}}\n{{}} The first time you install a package, R will ask you whether you want to create a personal library in your home directory. Answer yes to both questions. All your packages will now install under ~/. {{}}\n{{}} A handful of packages require additional modules to be loaded before they can be installed. This will be indicated in the error messages you will get when you try to install them. {{}}"
  },
  {
    "objectID": "r/hpc_intro_slides.html#running-r-jobs",
    "href": "r/hpc_intro_slides.html#running-r-jobs",
    "title": "Introduction to high-performance research computing in R",
    "section": "Running R jobs",
    "text": "Running R jobs\nWhile it is totally fine to run R on the login node when you install packages, you must start a SLURM job before any heavy computation.\nInteractive jobs\nTo run R interactively, you should launch an salloc session before launching R:\n$ salloc --time=1:00:00 --mem-per-cpu=3000M --cpus-per-task=4\n$ R\nScripts\nTo run an R script called <your_script>.R, first, you need to write a job file.\n{{}} Example of sbatch job file called <your_job>.sh (note that R scripts are run with the command Rscript): {{}}\n#!/bin/bash\n#SBATCH --account=def-<your_account>\n#SBATCH --time=15\n#SBATCH --mem-per-cpu=3000M\n#SBATCH --cpus-per-task=4\n#SBATCH --job-name=\"<your_job>\"\nmodule load StdEnv/2020 gcc/11.3.0 r/4.2.1\nRscript <your_script>.R\nThen launch your job with:\n$ sbatch <your_job>.sh\nYou can monitor your job with sq."
  },
  {
    "objectID": "r/hpc_intro_slides.html#benchmarking",
    "href": "r/hpc_intro_slides.html#benchmarking",
    "title": "Introduction to high-performance research computing in R",
    "section": "Benchmarking",
    "text": "Benchmarking"
  },
  {
    "objectID": "r/hpc_intro_slides.html#profiling",
    "href": "r/hpc_intro_slides.html#profiling",
    "title": "Introduction to high-performance research computing in R",
    "section": "Profiling",
    "text": "Profiling"
  },
  {
    "objectID": "r/hpc_intro_slides.html#parallel-r",
    "href": "r/hpc_intro_slides.html#parallel-r",
    "title": "Introduction to high-performance research computing in R",
    "section": "Parallel R",
    "text": "Parallel R\nhttps://towardsdatascience.com/getting-started-with-parallel-programming-in-r-d5f801d43745 https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html https://yxue-me.com/post/2019-05-12-a-glossary-of-parallel-computing-packages-in-r-2019/ https://subscription.packtpub.com/book/big-data-and-business-intelligence/9781784394004/1/ch01lvl1sec09/the-r-parallel-package https://www.r-bloggers.com/2017/08/implementing-parallel-processing-in-r/ https://www.stat.umn.edu/geyer/3701/notes/parallel.html https://www.stat.umn.edu/geyer/8054/notes/parallel.html https://blog.esciencecenter.nl/parallel-r-in-a-nutshell-4391d45b5461 https://dept.stat.lsa.umich.edu/~jerrick/courses/stat701/notes/parallel.html https://bookdown.org/rdpeng/rprogdatascience/parallel-computation.html https://docs.alliancecan.ca/wiki/R#doParallel_and_foreach https://www.r-bloggers.com/2016/01/strategies-to-speedup-r-code/ https://www.datacamp.com/tutorial/r-tutorial-apply-family https://bookdown.org/rdpeng/rprogdatascience/profiling-r-code.html\nStart large (4GB) on a test script. Then: While the script is running, check how much memory is used in real time by typing: sstat yourjobID.batch ‚Äìformat=‚ÄúJobID,MaxRSS‚Äù Or When the script is done running, check how much was used by typing: sacct -o MaxRSS -j yourjobID If you check the slurm.out file and you‚Äôre getting ‚Äúoom-kill‚Äù errors, you need to request more memory If you‚Äôre using less than you asked for, it‚Äôs beneficial to reduce the memory in ‚Äìmem or ‚Äìmem-per-cpu (this way your job will get scheduled sooner) Resubmit your job with your new estimate.\nIndependent repeats of computations (e.g.¬†bootstrapping)\nNo communication needed between computations.\nParallel package\n\nStart up M ‚Äòworker‚Äô processes, and do any initialization needed on the workers.\nSend any data required for each task to the workers.\nSplit the task into M roughly equally-sized chunks, and send the chunks (including the R code needed) to the workers.\nWait for all the workers to complete their tasks, and ask them for their results.\nRepeat steps (b‚Äìd) for any further tasks.\nShut down the worker processes.\n\n\n\n\n¬†Back to workshop page"
  },
  {
    "objectID": "r/intro.html",
    "href": "r/intro.html",
    "title": "Introduction to R",
    "section": "",
    "text": "R is a free and open-source programming language for statistical computing, modelling, and graphics, with an unbeatable collection of statistical packages. It is extremely popular in some academic fields such as statistics, biology, bioinformatics, data mining, data analysis, and linguistics.\nThis introductory course does not assume any prior knowledge: it will take you through the first steps of importing, cleaning, and visualizing your data. Along the way, we will get familiar with R data types, functions writing, and control flow."
  },
  {
    "objectID": "r/webscraping.html",
    "href": "r/webscraping.html",
    "title": "Web scraping with R",
    "section": "",
    "text": "The internet is a trove of information. A lot of it is publicly available and thus suitable for use in research. Extracting that information and putting it in an organized format for analysis can, however, be extremely tedious. Web scraping tools allow to automate parts of that process and R is a popular language for the task.\nIn this workshop, we will guide you through a simple example using the package rvest."
  },
  {
    "objectID": "tools/help.html",
    "href": "tools/help.html",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "",
    "text": "Stack Overflow, Stack Exchange, Discourse forums, and other online platforms ‚Ä¶ the internet is a treasure trove of online communities where you can find solutions to your coding problems. To have a positive experience and get the answers you need however, you have to know where to ask, how to ask, and when not to ask: if countless people are willing to give you their time for free, they usually expect that you do your part.\nIn this workshop, I will present key online sites, their functioning, and their culture; then I will go over the magic trick to get answers to your questions: knowing how to create minimum reproducible examples. I will not focus on any particular language as the principles (how to create a minimal dataset, how to deal with private data, how to create self-sufficient code, how to reproduce the problem, etc.) can apply to any language.\n\nSlides"
  },
  {
    "objectID": "tools/help_slides.html#when-you-are-stuck-tut",
    "href": "tools/help_slides.html#when-you-are-stuck-tut",
    "title": "Tips & tricks to get help in any programming language",
    "section": "When you are stuck tut",
    "text": "When you are stuck tut\n\nFirst, look for information that is already out there\n\n\nThen, ask for help"
  },
  {
    "objectID": "tools/help_slides.html#look-for-information",
    "href": "tools/help_slides.html#look-for-information",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Look for information",
    "text": "Look for information\n\n\nRead carefully any error message\nRead the documentation (local or online)\nMake sure you have up-to-date versions\nGoogle (using carefully selected keywords or the error message)\nLook for open issues & bug reports"
  },
  {
    "objectID": "tools/help_slides.html#error-messages",
    "href": "tools/help_slides.html#error-messages",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Error messages",
    "text": "Error messages\n\n\nRead them!\n\n\nFamiliarise yourself with the error types in the languages you use\n‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉExample: Python‚Äôs syntax errors vs exceptions.\n\n\nWarnings ‚â† errors\n\n\nLook for bits you understand (don‚Äôt get put off by what you don‚Äôt understand)\n\n\nIdentify the locations of the errors to go investigate that part of the code"
  },
  {
    "objectID": "tools/help_slides.html#documentation",
    "href": "tools/help_slides.html#documentation",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Documentation",
    "text": "Documentation\n\n\nYou need to find it\n\n\nYou need to understand it"
  },
  {
    "objectID": "tools/help_slides.html#finding-documentation-online",
    "href": "tools/help_slides.html#finding-documentation-online",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Finding documentation online",
    "text": "Finding documentation online\n\nTake the time to look for the official documentation & other high quality sources for the languages & tools you use.\n\n\n‚ÄÉExamples:\n‚ÄÉ‚ÄÉPython: Reference manual, Standard library manual, Tutorial\n‚ÄÉ‚ÄÉNumPy: Tutorial\n‚ÄÉ‚ÄÉR: Open source book ‚ÄúR for Data Science‚Äù, Open source book ‚ÄúAdvanced R‚Äù\n‚ÄÉ‚ÄÉJulia: Documentation\n‚ÄÉ‚ÄÉBash: Manual\n‚ÄÉ‚ÄÉGit: Manual, Open source book"
  },
  {
    "objectID": "tools/help_slides.html#finding-documentation-locally",
    "href": "tools/help_slides.html#finding-documentation-locally",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Finding documentation locally",
    "text": "Finding documentation locally"
  },
  {
    "objectID": "tools/help_slides.html#understanding-the-documentation",
    "href": "tools/help_slides.html#understanding-the-documentation",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Understanding the documentation",
    "text": "Understanding the documentation"
  },
  {
    "objectID": "tools/help_slides.html#up-to-date-versions",
    "href": "tools/help_slides.html#up-to-date-versions",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Up-to-date versions",
    "text": "Up-to-date versions\n\n\nFirst, you need to know what needs to be updated.\n\n\nKeeping a system up to date includes updating:\n\nthe OS\nthe program\n(any potential IDE)\npackages\n\n\n\nThen, you need to update regularly."
  },
  {
    "objectID": "tools/help_slides.html#google",
    "href": "tools/help_slides.html#google",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Google",
    "text": "Google\n\nGoogle‚Äôs algorithms are great at guessing what we are looking for.\n\nBut there is a frequency problem:\nSearches relating to programming-specific questions represent too small ‚ÄÉ‚ÄÉ‚ÄÉa fraction of the overall searches for results to be relevant unless you use key vocabulary.\n\n\nBe precise.\n\n\nLearn the vocabulary of your language/tool to know what to search for."
  },
  {
    "objectID": "tools/help_slides.html#open-issues-bug-reports",
    "href": "tools/help_slides.html#open-issues-bug-reports",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Open issues & bug reports",
    "text": "Open issues & bug reports\n\nIf the tool you are using is open source, look for issues matching your problem in the source repository (e.g.¬†on GitHub or GitLab)."
  },
  {
    "objectID": "tools/help_slides.html#what-if-the-answer-isnt-out-there",
    "href": "tools/help_slides.html#what-if-the-answer-isnt-out-there",
    "title": "Tips & tricks to get help in any programming language",
    "section": "What if the answer isn‚Äôt out there?",
    "text": "What if the answer isn‚Äôt out there?\n\nWhen everything has failed & you have to ask for help, you need to know:"
  },
  {
    "objectID": "tools/help_slides.html#where-to-ask",
    "href": "tools/help_slides.html#where-to-ask",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Where to ask",
    "text": "Where to ask"
  },
  {
    "objectID": "tools/help_slides.html#how-to-ask",
    "href": "tools/help_slides.html#how-to-ask",
    "title": "Tips & tricks to get help in any programming language",
    "section": "How to ask",
    "text": "How to ask"
  },
  {
    "objectID": "tools/help_slides.html#where-to-ask-1",
    "href": "tools/help_slides.html#where-to-ask-1",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Where to ask",
    "text": "Where to ask"
  },
  {
    "objectID": "tools/help_slides.html#qa-sites",
    "href": "tools/help_slides.html#qa-sites",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Q&A sites",
    "text": "Q&A sites\nMostly, Stack Overflow & the Stack Exchange network.\nCo-founded in 2008 & 2009 by Jeff Atwood & Joel Spolsky."
  },
  {
    "objectID": "tools/help_slides.html#forums",
    "href": "tools/help_slides.html#forums",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Forums",
    "text": "Forums\nMostly, Discourse.\nCo-founded in 2013 by Jeff Atwood, Robin Ward & Sam Saffron.\nA few other older forums."
  },
  {
    "objectID": "tools/help_slides.html#where-to-ask-2",
    "href": "tools/help_slides.html#where-to-ask-2",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Where to ask",
    "text": "Where to ask\nWhich one to choose is a matter of personal preference.\nPossible considerations:\n\nSome niche topics have very active communities on Discourse\nStack Overflow & some older forums can be intimidating with higher expectations for the questions quality & a more direct handling of mistakes\nFor conversations, advice, or multiple step questions, go to Discourse\nStack Overflow has over 13 million users\nStack Overflow & co have a very efficient approach"
  },
  {
    "objectID": "tools/help_slides.html#stack-overflow-co",
    "href": "tools/help_slides.html#stack-overflow-co",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Stack Overflow & co",
    "text": "Stack Overflow & co\nPick the best site to ask your question.\nA few of the Stack Exchange network sites:\nStack Overflow: programming\nSuper User: computer hardware & software\nUnix & Linux: *nix OS TEX: TeX/LaTeX\nCross Validated: stats; data mining, collecting, analysis & visualization; ML\nData Science: focus on implementation & processes\nOpen Data\nGIS"
  },
  {
    "objectID": "tools/help_slides.html#how-to-ask-1",
    "href": "tools/help_slides.html#how-to-ask-1",
    "title": "Tips & tricks to get help in any programming language",
    "section": "How to ask",
    "text": "How to ask\n\nFamiliarize yourself with the site by reading posts\n\n\nRead the ‚ÄúTour‚Äù page (SO/SE) or take the ‚ÄúNew user tutorial‚Äù (Discourse)\n\n\nMake sure the question has not already been asked\n\n\nFormat the question properly\n\n\nGive a minimum reproducible example\n\n\nDo not share sensitive data\n\n\nShow your attempts\n\n\nAvoid cross-posting. If you really have to, make sure to cross-reference"
  },
  {
    "objectID": "tools/help_slides.html#how-to-ask-so-co",
    "href": "tools/help_slides.html#how-to-ask-so-co",
    "title": "Tips & tricks to get help in any programming language",
    "section": "How to ask: SO & co",
    "text": "How to ask: SO & co\n\nDon‚Äôt ask opinion-based questions\n\n\nDon‚Äôt ask for package, tool, or service recommendations\n\n\nDon‚Äôt ask more than one question in a single post\n\n\nCheck your spelling, grammar, punctuation, capitalized sentences, etc.\n\n\nAvoid greetings, signatures, thank-yous; keep it to the point\n\n\nAvoid apologies about being a beginner, this being your first post, the question being stupid, etc: do the best you can & skip the personal, self-judgmental & irrelevant bits"
  },
  {
    "objectID": "tools/help_slides.html#formatting-your-question",
    "href": "tools/help_slides.html#formatting-your-question",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Formatting your question",
    "text": "Formatting your question\nNowadays, most sites (including Stack Overflow & Discourse) allow markdown rendering.\nSome older forums implement other markup languages (e.g.¬†BBCode).\nThe information is always easy to find. Spend the time to format your question properly. People will be much less inclined to help you if you don‚Äôt show any effort & if your question is a nightmare to read."
  },
  {
    "objectID": "tools/help_slides.html#example-of-a-typical-downvoted-question",
    "href": "tools/help_slides.html#example-of-a-typical-downvoted-question",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Example of a typical downvoted question",
    "text": "Example of a typical downvoted question\nhowdy!!\ni am new to R sorry for a very silly question.i looked all oever the itnernwet, but i dint find\nanyanswer. i tried to use ggplot i get the error: Error in loadNamespace(i, c(lib.loc, .libPaths()),\nversionCheck = vI[[i]]) : there is no package called 'stringi'\nthank youu very much!!!!!\nmarie\n\n[Out]"
  },
  {
    "objectID": "tools/help_slides.html#same-question-fixed",
    "href": "tools/help_slides.html#same-question-fixed",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Same question, fixed",
    "text": "Same question, fixed\nWhen I try to load the package `ggplot2` with:\n\n```{r}\nlibrary(ggplot2)\n```\nI get the error:\n\n> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :\nthere is no package called 'stringi'\n\nWhat am I doing wrong?"
  },
  {
    "objectID": "tools/help_slides.html#still-not-good-enough",
    "href": "tools/help_slides.html#still-not-good-enough",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Still not good enough",
    "text": "Still not good enough\n\nThis question is actually a duplicate of a question asked which is itself a duplicate of another question."
  },
  {
    "objectID": "tools/help_slides.html#creating-a-minimal-reproducible-example",
    "href": "tools/help_slides.html#creating-a-minimal-reproducible-example",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Creating a minimal reproducible example",
    "text": "Creating a minimal reproducible example\n\nThere are great posts on how to create a good minimal reproducible example. In particular:\n‚ÄÉHow to create a Minimal, Reproducible Example  For R (but concepts apply to any language):\n‚ÄÉHow to make a great R reproducible example\n‚ÄÉWhat‚Äôs a reproducible example (reprex) and how do I do one?"
  },
  {
    "objectID": "tools/help_slides.html#creating-a-minimal-reproducible-example-1",
    "href": "tools/help_slides.html#creating-a-minimal-reproducible-example-1",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Creating a minimal reproducible example",
    "text": "Creating a minimal reproducible example\n\n\nLoad all necessary packages\nLoad or create necessary data\nSimplify the data & the code as much as possible while still reproducing the problem\nUse simple variable names"
  },
  {
    "objectID": "tools/help_slides.html#data-for-your-reproducible-example-your-own-data",
    "href": "tools/help_slides.html#data-for-your-reproducible-example-your-own-data",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Data for your reproducible example: your own data",
    "text": "Data for your reproducible example: your own data\n\nDo not upload data somewhere on the web to be downloaded.\nMake sure that the data is anonymised.\nDon‚Äôt keep more variables & more data points than are necessary to reproduce the problem.\nSimplify the variable names.\nIn R, you can use functions such as dput() to turn your reduced, anonymised data into text that is easy to copy/paste & can then be used to recreate the data."
  },
  {
    "objectID": "tools/help_slides.html#data-for-your-reproducible-example-create-a-toy-dataset",
    "href": "tools/help_slides.html#data-for-your-reproducible-example-create-a-toy-dataset",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Data for your reproducible example: create a toy dataset",
    "text": "Data for your reproducible example: create a toy dataset\n\nYou can also create a toy dataset.\nFunctions that create random data, series, or repetitions are very useful here."
  },
  {
    "objectID": "tools/help_slides.html#data-for-your-reproducible-example-pre-packaged-datasets",
    "href": "tools/help_slides.html#data-for-your-reproducible-example-pre-packaged-datasets",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Data for your reproducible example: pre-packaged datasets",
    "text": "Data for your reproducible example: pre-packaged datasets\n\nSome languages/packages come with pre-packaged datasets. If your code involves such languages/packages, you can make use of these datasets to create your reproducible example.\nFor example, R comes with many datasets directly available, including iris, mtcars, trees, airquality. In the R console, try: \n?iris\n?mtcars"
  },
  {
    "objectID": "tools/help_slides.html#additional-considerations",
    "href": "tools/help_slides.html#additional-considerations",
    "title": "Tips & tricks to get help in any programming language",
    "section": "Additional considerations",
    "text": "Additional considerations\n\nEven if you always find answers to your questions without having to post yourself, consider signing up to these sites:\n\nIt allows you to upvote (SO/SE) or like (Discourse) the questions & answers that help you‚Äîand why not thank in this fashion those that are making your life easier?\nIt makes you a part of these communities.\nOnce you are signed up, maybe you will start being more involved & contribute with questions & answers of your own."
  },
  {
    "objectID": "tools/help_slides.html#a-last-word",
    "href": "tools/help_slides.html#a-last-word",
    "title": "Tips & tricks to get help in any programming language",
    "section": "A last word",
    "text": "A last word\n\nWhile it takes some work to ask a good question, do not let this discourage you from posting on Stack Overflow: if you ask a good question, you will get many great answers.\nYou will learn in the process of developing your question (you may actually find the answer in that process) & you will learn from the answers.\nIt is forth the effort.\nHere is the Stack Overflow documentation on how to ask a good question.\n\n\n\n¬†Back to workshop page"
  },
  {
    "objectID": "tools/quarto.html",
    "href": "tools/quarto.html",
    "title": "Authoring scientific documents with Markdown and Quarto",
    "section": "",
    "text": "This workshop will show you how to easily create beautiful scientific documents (html, pdf, websites, books‚Ä¶)‚Äîcomplete with formatted text, dynamic code, and figures with Quarto, an open-source tool combining the powers of Jupyter or knitr with Pandoc to turn your text and code blocks into fully dynamic and formatted documents."
  },
  {
    "objectID": "tools/quarto.html#markup-and-markdown",
    "href": "tools/quarto.html#markup-and-markdown",
    "title": "Authoring scientific documents with Markdown and Quarto",
    "section": "Markup and Markdown",
    "text": "Markup and Markdown\n\nMarkup languages\nMarkup languages control the formatting of text documents. They are powerful but complex and the raw text (before it is rendered into its formatted version) is visually cluttered and hard to read.\nExamples of markup languages include LaTeX and HTML.\n\nTex (often with the macro package LaTeX) is used to create pdf.\n\n\nExample LaTeX:\n\n\\documentclass{article}\n\\title{My title}\n\\author{My name}\n\\usepackage{datetime}\n\\newdate{date}{24}{11}{2022}\n\\date{\\displaydate{date}}\n\\begin{document}\n \\maketitle\n \\section{First section}\n Some text in the first section.\n\\end{document}\n\nHTML (often with css or scss files to customize the format) is used to create webpages.\n\n\nExample HTML:\n\n<!DOCTYPE html>\n<html lang=\"en-US\">\n  <head>\n    <meta charset=\"utf-8\" />\n    <meta name=\"viewport\" content=\"width=device-width\" />\n    <title>My title</title>\n    <address class=\"author\">My name</address>\n    <input type=\"date\" value=\"2022-11-24\" />\n  </head>\n  <h1>First section</h1>\n  <body>\n    Some text in the first section.\n  </body>\n</html>\n\n\nMarkdown\nA number of minimalist markup languages intend to remove all the visual clutter and complexity to create raw texts that are readable prior to rendering. Markdown (note the pun with ‚Äúmarkup‚Äù), created in 2004, is the most popular of them. Due to its simplicity, it has become quasi-ubiquitous. Many implementations exist which add a varying number of features (as you can imagine, a very simple markup language is also fairly limited).\nMarkdown files are simply text files and they use the .md extension.\n\n\nBasic Markdown syntax\nIn its basic form, Markdown is mostly used to create webpages. Conveniently, raw HTML can be included whenever the limited markdown syntax isn‚Äôt sufficient.\nHere is an overview of the Markdown syntax supported by many applications.\n\n\nPandoc and its extended Markdown syntax\nWhile the basic syntax is good enough for HTML outputs, it is very limited for other formats.\nPandoc is a free and open-source markup format converter. Pandoc supports an extended Markdown syntax with functionality for figures, tables, callout blocks, LaTeX mathematical equations, citations, and YAML metadata blocks. In short, everything needed for the creation of scientific documents.\nSuch documents remain as readable as basic Markdown documents (thus respecting the Markdown philosophy), but they can now be rendered in sophisticated pdf, books, entire websites, Word documents, etc.\nAnd of course, as such documents remain text files, you can put them under version control with Git.\n\nPrevious example using Pandoc‚Äôs Markdown:\n\n---\ntitle: My title\nauthor: My name\ndate: 2022-11-24\n---\n# First section\nSome text in the first section."
  },
  {
    "objectID": "tools/quarto.html#literate-programming",
    "href": "tools/quarto.html#literate-programming",
    "title": "Authoring scientific documents with Markdown and Quarto",
    "section": "Literate programming",
    "text": "Literate programming\nLiterate programming is a methodology that combines snippets of code and written text. While first introduced in 1984, this approach to the creation of documents has truly exploded in popularity in recent years thanks to the development of new tools such as R Markdown and, later, Jupyter notebooks."
  },
  {
    "objectID": "tools/quarto.html#quarto",
    "href": "tools/quarto.html#quarto",
    "title": "Authoring scientific documents with Markdown and Quarto",
    "section": "Quarto",
    "text": "Quarto\n\nHow it works\nQuarto files are transformed into Pandoc‚Äôs extended Markdown by Jupyter (when used with Python or Julia) or by knitr (when used with R), then pandoc turns the Markdown document into the output of your choice.\n\nJulia and Python make use of the Jupyter engine:\n\n From Quarto documentation\n\nR uses the knitr engine:\n\n From Quarto documentation\nQuarto files use the extension .qmd.\nWhen using R, you can use Quarto directly from RStudio: if you are used to R Markdown, Quarto is the new and better R Markdown.\nWhen using Python or Julia, you can use Quarto directly from a Jupyter notebook (with .ipynb extension).\n\nUsing Quarto directly from a Jupyter notebook:\n\n From Quarto documentation\nIn this workshop, we will see the most general workflow: simply using a text editor.\n\n\nSupported languages\nQuarto renders highlighting in countless languages and generates dynamic output for code blocks in:\n\nPython\nR\nJulia\nObservable JS\n\nYou can render documents in a wide variety of formats:\n\nHTML\nPDF\nMS Word\nOpenOffice\nePub\nRevealjs\nPowerPoint\nBeamer\nGitHub Markdown\nCommonMark\nHugo\nDocusaurus\nMarkua\nMediaWiki\nDokuWiki\nZimWiki\nJira Wiki\nXWiki\nJATS\nJupyter\nConTeXt\nRTF\nreST\nAsciiDoc\nOrg-Mode\nMuse\nGNU\nGroff\n\n\n\nInstallation\n\nDownload Quarto here.\nDownload the language(s) (R, Python, or Julia) you will want to use with Quarto as well as their corresponding engine (knitr for R; Jupyter for Python and Julia):\n\nIf you want to use Quarto with R, you will need:\n\nR (download here if you don‚Äôt have R already on your system),\nthe rmarkdown package. For this, launch R and run:\n\ninstall.packages(\"rmarkdown\")\nIf you want to use it with Python, you will need:\n\nPython 3 (download here if don‚Äôt have it on your system),\nJupyterLab. For this, open a terminal and run:\n\npython3 -m pip install jupyterlab  # if you are on MacOS or Linux\npy -m pip install jupyterlab       # if you are on Windows\nFinally, if you want to use Quarto with Julia, you will need:\n\nJulia (download here if you don‚Äôt have Julia),\nthe IJulia and Revise packages. For this, launch Julia and run:\n\n] add IJulia Revise\n# <Backspace>\nusing IJulia\nnotebook()      # to install a minimal Python+Jupyter distribution\nRunning notebook() allows you to install Jupyter if you don‚Äôt already have it.\n\n\nDocument structure and syntax\n\nFront matter\nWritten in YAML. Sets the options for the document. Let‚Äôs see a few examples.\n\nHTML output:\n\n---\ntitle: \"My title\"\nauthor: \"My name\"\nformat: html\n---\n\nHTML output with a few options:\n\n---\ntitle: \"My title\"\nauthor: \"My name\"\nformat:\n  html:\n    toc: true\n    css: <my_file>.css\n---\nThe above examples would work if you don‚Äôt use any code blocks or if you use R code blocks. If you use Python or Julia however, you need to add a jupyter entry with the name of the language that should run in Jupyter.\n\nMS Word output with Python code blocks:\n\n---\ntitle: \"My title\"\nauthor: \"My name\"\nformat: docx\njupyter: python3\n---\n\nrevealjs output with some options and Julia code blocks:\n\n---\ntitle: \"Some title\"\nsubtitle: \"Some subtitle\"\ninstitute: \"Simon Fraser University\"\ndate: \"2022-11-24\"\nexecute:\n  error: true\n  echo: true\nformat:\n  revealjs:\n    theme: [default, custom.scss]\n    highlight-style: monokai\n    code-line-numbers: false\n    embed-resources: true\njupyter: julia-1.8\n---\nSee the Quarto documentation for an exhaustive list of options for all formats.\n\n\nWritten sections\nWritten sections are written in Pandoc‚Äôs extended Markdown.\n\n\nCode blocks\nIf all you want is syntax highlighting of the code blocks, use this syntax:\n```{.language}\n<some code>\n```\nIf you want syntax highlighting of the blocks and for the code to run, use instead:\n```{language}\n<some code>\n```\nIn addition, options can be added to individual code blocks:\n```{language}\n#| <some option>: <some option value>\n\n<some code>\n```\n\n\n\nRendering\nUsing Quarto is very simple: there are only two commands you need to know.\nIn a terminal, simply run either of:\nquarto render <file>.qmd     # this will render the document\nquarto preview <file>.qmd    # this will display live preview as you work on your document"
  },
  {
    "objectID": "tools/quarto.html#lets-give-this-a-try",
    "href": "tools/quarto.html#lets-give-this-a-try",
    "title": "Authoring scientific documents with Markdown and Quarto",
    "section": "Let‚Äôs give this a try",
    "text": "Let‚Äôs give this a try\nCreate a file called test.qmd with the text editor of your choice.\n\nExample:\n\nnano test.qmd\nAdd a minimal front matter with the output format.\n\nExample:\n\n---\ntitle: \"Some title\"\nformat: revealjs\n---\nThen open a new terminal, cd to the location of the file, and run the command:\nquarto preview test.qmd\nThis will open the rendered document in your browser.\nWe will play with this test.qmd file and see how it is rendered by Quarto as we go."
  },
  {
    "objectID": "tools/quarto.html#examples",
    "href": "tools/quarto.html#examples",
    "title": "Authoring scientific documents with Markdown and Quarto",
    "section": "Examples",
    "text": "Examples\nBelow are a few basic example files and their outputs.\n\nRevealjs presentation\n---\ntitle: \"My title\"\nauthor: \"My name\"\ninstitute: \"Simon Fraser University\"\nformat:\n  revealjs:\n    highlight-style: monokai\n    code-line-numbers: false\n    embed-resources: true\n---\n\n## First section\n\nWhen exporting to revealjs, second level sections mark the start of new slides,\nwith a slide title.\n\nThis can be changed in options.\n\n---\n\nNew slides can be started without titles this way.\n\n# There are title slides\n\n## Formatting\n\nText can be rendered *in italic* or **in bold** as well as [underlined]{.underline}.\n\nYou can use superscripts^2^, subscripts~test~, ~~strikethrough~~, and `inline code`.\n\n> This is a quote.\n\n## Columns\n\n:::: {.columns}\n\n::: {.column width=\"30%\"}\n\nYou can create columns.\n\n:::\n\n::: {.column width=\"70%\"}\n\nAnd you can set their respective width.\n\n:::\n\n::::\n\n## Lists\n\n::: {.incremental}\n\n- List can happen one line at a time\n- like\n- this\n\n:::\n\n## Lists\n\n- Or all at the same time\n- like\n- that\n\n## Ordered lists\n\n1. Item 1\n2. Item 2\n3. Item 3\n\n## Images\n\n![Example image](qmd_jupyter.png)\n\n## Tables\n\n| Col 1 | Col 2 | Col 3  |\n|------ |-------|--------|\n| a     | 1     | red    |\n| b     | 2     | orange | \n| c     | 3     | yellow |\n\n:::{.callout-note}\n\nTables can be fully customized (or you could use raw html).\n\n:::\n\n## Equations\n\n$$\n\\frac{\\partial \\mathrm C}{ \\partial \\mathrm t } + \\frac{1}{2}\\sigma^{2} \\mathrm S^{2}\n\\frac{\\partial^{2} \\mathrm C}{\\partial \\mathrm C^2}\n  + \\mathrm r \\mathrm S \\frac{\\partial \\mathrm C}{\\partial \\mathrm S}\\ =\n  \\mathrm r \\mathrm C \n$$\n\n\n\n\n\n\n\npdf\n---\ntitle: \"My title\"\nauthor: \"My name\"\nformat:\n  pdf:\n    toc: true\n---\n\n# Header 1\n\nSome text.\n\n## Header 2\n\nMore text.\n\n## Formatting\n\nText can be rendered *in italic* or **in bold** as well as [underlined]{.underline}.\n\nYou can use superscripts^2^, subscripts~test~, ~~strikethrough~~, and `inline code`.\n\n> This is a quote.\n\n## Lists\n\n### Unordered\n\n- Item 1\n- Item 2\n- Item 3\n\n### Ordered\n\n1. Item 1\n2. Item 2\n3. Item 3\n\n## Images\n\n![Example image](qmd_jupyter.png)\n\n## Tables\n\n| Col 1 | Col 2 | Col 3  |\n|------ |-------|--------|\n| a     | 1     | red    |\n| b     | 2     | orange | \n| c     | 3     | yellow |\n\n:::{.callout-note}\n\nTables can be fully customized (or you could use raw html).\n\n:::\n\n## Equations\n\n$$\n\\frac{\\partial \\mathrm C}{ \\partial \\mathrm t } + \\frac{1}{2}\\sigma^{2} \\mathrm S^{2}\n\\frac{\\partial^{2} \\mathrm C}{\\partial \\mathrm C^2}\n  + \\mathrm r \\mathrm S \\frac{\\partial \\mathrm C}{\\partial \\mathrm S}\\ =\n  \\mathrm r \\mathrm C \n$$\n\n\n\n\n\n\nIn order to export to pdf, you need a TeX distribution. You probably already have one installed on your machine, so you should first try to render or preview a document to pdf to see whether it works. If it doesn‚Äôt work, you can install the minimalist distribution TinyTex by running in your terminal:\n\nquarto install tool tinytex\n\n\nHTML with R code blocks\n---\ntitle: \"My title\"\nauthor: \"My name\"\ninstitute: \"Simon Fraser University\"\nformat: html\n---\n\n# Header 1\n\n## Header 2\n\nSome text.\n\n## Formatting  {#sec-formatting}\n\n::: aside\n\nNote that each header automatically creates an anchor,\nmaking it easy to link to specific sections of your documents.\n\n:::\n\nText can be rendered *in italic* or **in bold** as well as [underlined]{.underline}.\n\nYou can use superscripts^2^, subscripts~test~, ~~strikethrough~~, and `inline code`.\n\n> This is a quote.\n\n## Columns\n\n:::: {.columns}\n\n::: {.column width=\"30%\"}\n\nYou can create columns.\n\n:::\n\n::: {.column width=\"70%\"}\n\nAnd you can set their respective width.\n\n:::\n\n::::\n\n## Lists\n\n- Item 1\n- Item 2\n- Item 3\n\n## Ordered lists\n\n1. Item 1\n2. Item 2\n3. Item 3\n\n## Images\n\n![Example image](qmd_jupyter.png)\n\n## Tables\n\n| Col 1 | Col 2 | Col 3  |\n|------ |-------|--------|\n| a     | 1     | red    |\n| b     | 2     | orange | \n| c     | 3     | yellow |\n\n:::{.callout-note}\n\nTables can be fully customized (or you could use raw html).\n\n:::\n\n## Equations\n\n$$\n\\frac{\\partial \\mathrm C}{ \\partial \\mathrm t } + \\frac{1}{2}\\sigma^{2} \\mathrm S^{2}\n\\frac{\\partial^{2} \\mathrm C}{\\partial \\mathrm C^2}\n  + \\mathrm r \\mathrm S \\frac{\\partial \\mathrm C}{\\partial \\mathrm S}\\ =\n  \\mathrm r \\mathrm C \n$$\n\n## Cross-references\n\nSee @sec-formatting.\n\n*Note that you can add bibliographies, flow charts, the equivalent of HTML \"div\",\nand just so much more. Remember that this is a tiny overview.*\n\n## Let's try some code blocks now\n\n```{r}\n# This is a block that runs\n2 + 3\n```\n\n::: aside\n\nDid you notice that the content of your code blocks can be copied with a click?\nOf course, this is customizable.\n\n:::\n\n```{.r}\n# This is a block that doesn't run\n2 + 3\n```\n\n```{r}\n#| echo: false\n# And this is a block showing only the output\ndata.frame(\n  country = c(\"Canada\", \"USA\", \"Mexico\"),\n  var = c(2.9, 3.1, 4.5)\n)\n```\n\n## Plots\n\n```{r}\nplot(cars)\n```\n\n<br>\nYou can play with options to add a title:\n\n```{r}\n#| fig-cap: \"Stopping distance as a function of speed in cars\"\n\nplot(cars)\n```\n\n<br>\nYou can have more complex multi-plot layouts:\n\n```{r}\n#| layout-ncol: 2\n#| fig-cap: \n#|   - \"Stopping distance as a function of speed in cars\"\n#|   - \"Vapor pressure of mercury as a function of temperature\"\n\nplot(cars)\nplot(pressure)\n```\n\nFor those who have `ggplot2`[^1], you can try that too:\n\n```{r}\nlibrary(ggplot2)\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(mapping = aes(color = class)) + \n  geom_smooth()\n```\n\n[^1]: You can install it with:\n    ```{.r}\n    install.packages(\"ggplot2\")\n    ```\n\n\n\n\n\n\n\nBeamer with Python code blocks\nBeamer is LaTeX presentation framework: a way to create beautiful pdf slides.\n---\ntitle: \"Some title\"\nauthor: \"Some name\"\nformat: beamer\njupyter: python3\n---\n\n## First slide\n\nWith some content\n\n## Formatting\n\nText can be rendered *in italic* or **in bold** as well as [underlined]{.underline}.\n\nYou can use superscripts^2^, subscripts~test~, ~~strikethrough~~, and `inline code`.\n\n## Lists\n\n- Item 1\n- Item 2\n- Item 3\n\n## Ordered lists\n\n1. Item 1\n2. Item 2\n3. Item 3\n\n## Images\n\n![Example image](qmd_jupyter.png)\n\n## Tables\n\n| Col 1 | Col 2 | Col 3  |\n|------ |-------|--------|\n| a     | 1     | red    |\n| b     | 2     | orange | \n| c     | 3     | yellow |\n\n:::{.callout-note}\n\nTables can be fully customized (or you could use raw html).\n\n:::\n\n## Equations\n\n$$\n\\frac{\\partial \\mathrm C}{ \\partial \\mathrm t } + \\frac{1}{2}\\sigma^{2} \\mathrm S^{2}\n\\frac{\\partial^{2} \\mathrm C}{\\partial \\mathrm C^2}\n  + \\mathrm r \\mathrm S \\frac{\\partial \\mathrm C}{\\partial \\mathrm S}\\ =\n  \\mathrm r \\mathrm C \n$$\n\n## Some basic code block\n\n```{python}\n#| echo: true\n\n2 + 3\n```\n\n## Some plot\n\n```{python}\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Data for plotting\nt = np.arange(0.0, 2.0, 0.01)\ns = 1 + np.sin(2 * np.pi * t)\n\nfig, ax = plt.subplots()\nax.plot(t, s)\n\nax.set(xlabel='time (s)', ylabel='voltage (mV)',\n       title='Here goes the title')\nax.grid()\n\nfig.savefig(\"test.png\")\nplt.show()\n```"
  },
  {
    "objectID": "ml/upscaling_slides.html#sr-using-amongst-others",
    "href": "ml/upscaling_slides.html#sr-using-amongst-others",
    "title": "Super-resolution with PyTorch",
    "section": "SR using (amongst others):",
    "text": "SR using (amongst others):\n\nConvolutional Neural Networks (SRCNN) ‚Äî 2014\nRandom Forests ‚Äî 2015\nPerceptual loss ‚Äî 2016\nSub-pixel CNN ‚Äî 2016\nResNet (SRResNet) & Generative Adversarial Network (SRGAN) ‚Äî 2017\nEnhanced SRGAN (ESRGAN) ‚Äî 2018\nPredictive Filter Flow (PFF) ‚Äî 2018\nDensely Residual Laplacian attention Network (DRLN) ‚Äî 2019\nSecond-order Attention Network (SAN) ‚Äî 2019\nLearned downscaling with Content Adaptive Resampler (CAR) ‚Äî 2019\nHolistic Attention Network (HAN) ‚Äî 2020\nSwin Transformer ‚Äî 2021"
  },
  {
    "objectID": "ml/upscaling_slides.html#can-be-broken-down-into-2-main-periods",
    "href": "ml/upscaling_slides.html#can-be-broken-down-into-2-main-periods",
    "title": "Super-resolution with PyTorch",
    "section": "Can be broken down into 2 main periods:",
    "text": "Can be broken down into 2 main periods:\n\nA rather slow history with various interpolation algorithms of increasing complexity before deep neural networks\nAn incredibly fast evolution since the advent of deep learning (DL)"
  }
]