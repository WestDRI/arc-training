[
  {
    "objectID": "tools/ws_quarto.html",
    "href": "tools/ws_quarto.html",
    "title": "Authoring scientific documents with Markdown and Quarto",
    "section": "",
    "text": "This workshop will show you how to easily create beautiful scientific documents (html, pdf, websites, books‚Ä¶)‚Äîcomplete with formatted text, dynamic code, and figures with Quarto, an open-source tool combining the powers of Jupyter or knitr with Pandoc to turn your text and code blocks into fully dynamic and formatted documents.",
    "crumbs": [
      "Tools",
      "<em><b>Workshops</b></em>"
    ]
  },
  {
    "objectID": "tools/ws_quarto.html#markup-and-markdown",
    "href": "tools/ws_quarto.html#markup-and-markdown",
    "title": "Authoring scientific documents with Markdown and Quarto",
    "section": "Markup and Markdown",
    "text": "Markup and Markdown\n\nMarkup languages\nMarkup languages control the formatting of text documents. They are powerful but complex and the raw text (before it is rendered into its formatted version) is visually cluttered and hard to read.\nExamples of markup languages include LaTeX and HTML.\n\nTex (often with the macro package LaTeX) is used to create pdf.\n\n\nExample LaTeX:\n\n\\documentclass{article}\n\\title{My title}\n\\author{My name}\n\\usepackage{datetime}\n\\newdate{date}{24}{11}{2022}\n\\date{\\displaydate{date}}\n\\begin{document}\n \\maketitle\n \\section{First section}\n Some text in the first section.\n\\end{document}\n\nHTML (often with css or scss files to customize the format) is used to create webpages.\n\n\nExample HTML:\n\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en-US\"&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"utf-8\" /&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width\" /&gt;\n    &lt;title&gt;My title&lt;/title&gt;\n    &lt;address class=\"author\"&gt;My name&lt;/address&gt;\n    &lt;input type=\"date\" value=\"2022-11-24\" /&gt;\n  &lt;/head&gt;\n  &lt;h1&gt;First section&lt;/h1&gt;\n  &lt;body&gt;\n    Some text in the first section.\n  &lt;/body&gt;\n&lt;/html&gt;\n\n\nMarkdown\nA number of minimalist markup languages intend to remove all the visual clutter and complexity to create raw texts that are readable prior to rendering. Markdown (note the pun with ‚Äúmarkup‚Äù), created in 2004, is the most popular of them. Due to its simplicity, it has become quasi-ubiquitous. Many implementations exist which add a varying number of features (as you can imagine, a very simple markup language is also fairly limited).\nMarkdown files are simply text files and they use the .md extension.\n\n\nBasic Markdown syntax\nIn its basic form, Markdown is mostly used to create webpages. Conveniently, raw HTML can be included whenever the limited markdown syntax isn‚Äôt sufficient.\nHere is an overview of the Markdown syntax supported by many applications.\n\n\nPandoc and its extended Markdown syntax\nWhile the basic syntax is good enough for HTML outputs, it is very limited for other formats.\nPandoc is a free and open-source markup format converter. Pandoc supports an extended Markdown syntax with functionality for figures, tables, callout blocks, LaTeX mathematical equations, citations, and YAML metadata blocks. In short, everything needed for the creation of scientific documents.\nSuch documents remain as readable as basic Markdown documents (thus respecting the Markdown philosophy), but they can now be rendered in sophisticated pdf, books, entire websites, Word documents, etc.\nAnd of course, as such documents remain text files, you can put them under version control with Git.\n\nPrevious example using Pandoc‚Äôs Markdown:\n\n---\ntitle: My title\nauthor: My name\ndate: 2022-11-24\n---\n# First section\nSome text in the first section.",
    "crumbs": [
      "Tools",
      "<em><b>Workshops</b></em>"
    ]
  },
  {
    "objectID": "tools/ws_quarto.html#literate-programming",
    "href": "tools/ws_quarto.html#literate-programming",
    "title": "Authoring scientific documents with Markdown and Quarto",
    "section": "Literate programming",
    "text": "Literate programming\nLiterate programming is a methodology that combines snippets of code and written text. While first introduced in 1984, this approach to the creation of documents has truly exploded in popularity in recent years thanks to the development of new tools such as R Markdown and, later, Jupyter notebooks.",
    "crumbs": [
      "Tools",
      "<em><b>Workshops</b></em>"
    ]
  },
  {
    "objectID": "tools/ws_quarto.html#quarto",
    "href": "tools/ws_quarto.html#quarto",
    "title": "Authoring scientific documents with Markdown and Quarto",
    "section": "Quarto",
    "text": "Quarto\n\nHow it works\nQuarto files are transformed into Pandoc‚Äôs extended Markdown by Jupyter (when used with Python or Julia) or by knitr (when used with R), then pandoc turns the Markdown document into the output of your choice.\n\nJulia and Python make use of the Jupyter engine:\n\n\n\n\nfrom Quarto documentation\n\n\n\nR uses the knitr engine:\n\n\n\n\nfrom Quarto documentation\n\n\nQuarto files use the extension .qmd.\nWhen using R, you can use Quarto directly from RStudio: if you are used to R Markdown, Quarto is the new and better R Markdown.\nWhen using Python or Julia, you can use Quarto directly from a Jupyter notebook (with .ipynb extension).\n\nUsing Quarto directly from a Jupyter notebook:\n\n\n\n\nfrom Quarto documentation\n\n\nIn this workshop, we will see the most general workflow: simply using a text editor.\n\n\n\n\n\n\nNoteSupported languages\n\n\n\n\n\nQuarto renders highlighting in countless languages and generates dynamic output for code blocks in:\n\nPython\nR\nJulia\nObservable JS\n\nYou can render documents in a wide variety of formats:\n\nHTML\nPDF\nMS Word\nOpenOffice\nePub\nRevealjs\nPowerPoint\nBeamer\nGitHub Markdown\nCommonMark\nHugo\nDocusaurus\nMarkua\nMediaWiki\nDokuWiki\nZimWiki\nJira Wiki\nXWiki\nJATS\nJupyter\nConTeXt\nRTF\nreST\nAsciiDoc\nOrg-Mode\nMuse\nGNU\nGroff\n\nThis training website is actually built with Quarto!\n\n\n\n\n\nInstallation\n\nDownload Quarto here.\nDownload the language(s) (R, Python, or Julia) you will want to use with Quarto as well as their corresponding engine (knitr for R; Jupyter for Python and Julia):\n\nIf you want to use Quarto with R, you will need:\n\nR (download here if you don‚Äôt have R already on your system),\nthe rmarkdown package. For this, launch R and run:\n\ninstall.packages(\"rmarkdown\")\nIf you want to use it with Python, you will need:\n\nPython 3 (download here if don‚Äôt have it on your system),\nJupyterLab. For this, open a terminal and run:\n\npython3 -m pip install jupyter  # if you are on macOS or Linux\npython -m pip install jupyter   # if you are on Windows\nFinally, if you want to use Quarto with Julia, you will need:\n\nJulia (download here if you don‚Äôt have Julia),\nthe IJulia and Revise packages. For this, launch Julia and run:\n\n] add IJulia Revise\n# &lt;Backspace&gt;\nusing IJulia\nnotebook()      # to install a minimal Python+Jupyter distribution\nRunning notebook() allows you to install Jupyter if you don‚Äôt already have it.\n\n\nDocument structure and syntax\n\nFront matter\nWritten in YAML. Sets the options for the document. Let‚Äôs see a few examples.\n\nHTML output:\n\n---\ntitle: \"My title\"\nauthor: \"My name\"\nformat: html\n---\n\nHTML output with a few options:\n\n---\ntitle: \"My title\"\nauthor: \"My name\"\nformat:\n  html:\n    toc: true\n    css: &lt;my_file&gt;.css\n---\n\nMS Word output with Python code blocks:\n\n---\ntitle: \"My title\"\nauthor: \"My name\"\nformat: docx\njupyter: python3\n---\n\nrevealjs output with some options and Julia code blocks:\n\n---\ntitle: \"Some title\"\nsubtitle: \"Some subtitle\"\ninstitute: \"Simon Fraser University\"\ndate: \"2022-11-24\"\nexecute:\n  error: true\n  echo: true\nformat:\n  revealjs:\n    theme: [default, custom.scss]\n    highlight-style: monokai\n    code-line-numbers: false\n    embed-resources: true\njupyter: julia-1.8\n---\nSee the Quarto documentation for an exhaustive list of options for all formats.\n\n\nWritten sections\nWritten sections are written in Pandoc‚Äôs extended Markdown.\n\n\nCode blocks\nIf all you want is syntax highlighting of the code blocks, use this syntax:\n```{.language}\n&lt;some code&gt;\n```\nIf you want syntax highlighting of the blocks and for the code to run, use instead:\n```{language}\n&lt;some code&gt;\n```\nIn addition, options can be added to individual code blocks:\n```{language}\n#| &lt;some option name&gt;: &lt;some option value&gt;\n\n&lt;some code&gt;\n```\n\n\n\nRendering\nUsing Quarto is very simple: there are only two commands you need to know.\nIn a terminal, simply run either of:\nquarto render &lt;file&gt;.qmd     # Render the document\nquarto preview &lt;file&gt;.qmd    # Display a live preview",
    "crumbs": [
      "Tools",
      "<em><b>Workshops</b></em>"
    ]
  },
  {
    "objectID": "tools/ws_quarto.html#lets-create-a-webpage-together",
    "href": "tools/ws_quarto.html#lets-create-a-webpage-together",
    "title": "Authoring scientific documents with Markdown and Quarto",
    "section": "Let‚Äôs create a webpage together",
    "text": "Let‚Äôs create a webpage together\nFirst, create a file called test.qmd with the text editor of your choice.\n\nExample:\n\nnano test.qmd\nAdd a minimal front matter with the title of your document and the output format (html here since we are creating a webpage):\n---\ntitle: Test webpage\nformat: html\n---\nThen open a new terminal, cd to the location of the file, and run the command:\nquarto preview test.qmd\nThis will open the rendered document in your browser.\nWe will play with this test.qmd file and see how it is rendered by Quarto as we go.",
    "crumbs": [
      "Tools",
      "<em><b>Workshops</b></em>"
    ]
  },
  {
    "objectID": "tools/ws_quarto.html#examples",
    "href": "tools/ws_quarto.html#examples",
    "title": "Authoring scientific documents with Markdown and Quarto",
    "section": "Examples",
    "text": "Examples\nBelow are a few basic example files and their outputs.\n\nRevealjs presentation\n\n\n\n\n\n\nNoteCode\n\n\n\n\n\n---\ntitle: \"My title\"\nauthor: \"My name\"\ninstitute: \"Simon Fraser University\"\nformat:\n  revealjs:\n    highlight-style: monokai\n    code-line-numbers: false\n    embed-resources: true\n---\n\n## First section\n\nWhen exporting to revealjs, second level sections mark the start of new slides,\nwith a slide title.\n\nThis can be changed in options.\n\n---\n\nNew slides can be started without titles this way.\n\n# There are title slides\n\n## Formatting\n\nText can be rendered *in italic* or **in bold** as well as [underlined]{.underline}.\n\nYou can use superscripts^2^, subscripts~test~, ~~strikethrough~~, and `inline code`.\n\n&gt; This is a quote.\n\n## Columns\n\n:::: {.columns}\n\n::: {.column width=\"30%\"}\n\nYou can create columns.\n\n:::\n\n::: {.column width=\"70%\"}\n\nAnd you can set their respective width.\n\n:::\n\n::::\n\n## Lists\n\n::: {.incremental}\n\n- List can happen one line at a time\n- like\n- this\n\n:::\n\n## Lists\n\n- Or all at the same time\n- like\n- that\n\n## Ordered lists\n\n1. Item 1\n2. Item 2\n3. Item 3\n\n## Images\n\n![Example image](qmd_jupyter.png)\n\n## Tables\n\n| Col 1 | Col 2 | Col 3  |\n|-------|-------|--------|\n| a     | 1     | red    |\n| b     | 2     | orange | \n| c     | 3     | yellow |\n\n:::{.callout-note}\n\nTables can be fully customized (or you could use raw html).\n\n:::\n\n## Equations\n\n$$\n\\frac{\\partial \\mathrm C}{ \\partial \\mathrm t } + \\frac{1}{2}\\sigma^{2} \\mathrm S^{2}\n\\frac{\\partial^{2} \\mathrm C}{\\partial \\mathrm C^2}\n  + \\mathrm r \\mathrm S \\frac{\\partial \\mathrm C}{\\partial \\mathrm S}\\ =\n  \\mathrm r \\mathrm C \n$$\n\n\n\nRendered document (click on it to open it in a new tab):\n\n\n\npdf\n\n\n\n\n\n\nNoteCode\n\n\n\n\n\n---\ntitle: \"My title\"\nauthor: \"My name\"\nformat:\n  pdf:\n    toc: true\n---\n\n## Heading\n\nSome text.\n\n### Subheading\n\nMore text.\n\n## Formatting\n\nText can be rendered *in italic* or **in bold** as well as [underlined]{.underline}.\n\nYou can use superscripts^2^, subscripts~test~, ~~strikethrough~~, and `inline code`.\n\n&gt; This is a quote.\n\n## Lists\n\n### Unordered\n\n- Item 1\n- Item 2\n- Item 3\n\n### Ordered\n\n1. Item 1\n2. Item 2\n3. Item 3\n\n## Images\n\n![Example image](qmd_jupyter.png)\n\n## Tables\n\n| Col 1 | Col 2 | Col 3  |\n|-------|-------|--------|\n| a     | 1     | red    |\n| b     | 2     | orange | \n| c     | 3     | yellow |\n\n:::{.callout-note}\n\nTables can be fully customized (or you could use raw html).\n\n:::\n\n## Equations\n\n$$\n\\frac{\\partial \\mathrm C}{ \\partial \\mathrm t } + \\frac{1}{2}\\sigma^{2} \\mathrm S^{2}\n\\frac{\\partial^{2} \\mathrm C}{\\partial \\mathrm C^2}\n  + \\mathrm r \\mathrm S \\frac{\\partial \\mathrm C}{\\partial \\mathrm S}\\ =\n  \\mathrm r \\mathrm C \n$$\n\n\n\nRendered document (click on it to open it in a new tab):\n\n\nIn order to export to pdf, you need a TeX distribution. You probably already have one installed on your machine, so you should first try to render or preview a document to pdf to see whether it works. If it doesn‚Äôt work, you can install the minimalist distribution TinyTex by running in your terminal:\n\nquarto install tool tinytex\n\n\nHTML with R code blocks\n\n\n\n\n\n\nNoteCode\n\n\n\n\n\n---\ntitle: \"My title\"\nauthor: \"My name\"\ninstitute: \"Simon Fraser University\"\nformat: html\n---\n\n## Heading\n\n### Subheading\n\nSome text.\n\n## Formatting  {#sec-formatting}\n\n::: aside\n\nNote that each heading automatically creates an anchor, making it easy to link to specific sections of your documents.\n\n:::\n\nText can be rendered *in italic* or **in bold** as well as [underlined]{.underline}.\n\nYou can use superscripts^2^, subscripts~test~, ~~strikethrough~~, and `inline code`.\n\n&gt; This is a quote.\n\n## Columns\n\n:::: {.columns}\n\n::: {.column width=\"30%\"}\n\nYou can create columns.\n\n:::\n\n::: {.column width=\"70%\"}\n\nAnd you can set their respective width.\n\n:::\n\n::::\n\n## Lists\n\n- Item 1\n- Item 2\n- Item 3\n\n## Ordered lists\n\n1. Item 1\n2. Item 2\n3. Item 3\n\n## Images\n\n![Example image](qmd_jupyter.png)\n\n## Tables\n\n| Col 1 | Col 2 | Col 3  |\n|-------|-------|--------|\n| a     | 1     | red    |\n| b     | 2     | orange | \n| c     | 3     | yellow |\n\n:::{.callout-note}\n\nTables can be fully customized (or you could use raw html).\n\n:::\n\n## Equations\n\n$$\n\\frac{\\partial \\mathrm C}{ \\partial \\mathrm t } + \\frac{1}{2}\\sigma^{2} \\mathrm S^{2}\n\\frac{\\partial^{2} \\mathrm C}{\\partial \\mathrm C^2}\n  + \\mathrm r \\mathrm S \\frac{\\partial \\mathrm C}{\\partial \\mathrm S}\\ =\n  \\mathrm r \\mathrm C \n$$\n\n## Cross-references\n\nSee @sec-formatting.\n\n*Note that you can add bibliographies, flow charts, the equivalent of HTML \"div\",\nand just so much more. Remember that this is a tiny overview.*\n\n## Let's try some code blocks now\n\n```{r}\n# This is a block that runs\n2 + 3\n```\n\n::: aside\n\nDid you notice that the content of your code blocks can be copied with a click?\nOf course, this is customizable.\n\n:::\n\n```{.r}\n# This is a block that doesn't run\n2 + 3\n```\n\n```{r}\n#| echo: false\n# And this is a block showing only the output\ndata.frame(\n  country = c(\"Canada\", \"USA\", \"Mexico\"),\n  var = c(2.9, 3.1, 4.5)\n)\n```\n\n## Plots\n\n```{r}\nplot(cars)\n```\n\n&lt;br&gt;\nYou can play with options to add a title:\n\n```{r}\n#| fig-cap: \"Stopping distance as a function of speed in cars\"\n\nplot(cars)\n```\n\n&lt;br&gt;\nYou can have more complex multi-plot layouts:\n\n```{r}\n#| layout-ncol: 2\n#| fig-cap: \n#|   - \"Stopping distance as a function of speed in cars\"\n#|   - \"Vapor pressure of mercury as a function of temperature\"\n\nplot(cars)\nplot(pressure)\n```\n\nFor those who have `ggplot2`[^1], you can try that too:\n\n```{r}\nlibrary(ggplot2)\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(mapping = aes(color = class)) + \n  geom_smooth()\n```\n\n[^1]: You can install it with:\n    ```{.r}\n    install.packages(\"ggplot2\")\n    ```\n\n\n\nRendered document (click on it to open it in a new tab):\n\n\n\nBeamer with Python code blocks\nBeamer is LaTeX presentation framework: a way to create beautiful pdf slides.\n\n\n\n\n\n\nNoteCode\n\n\n\n\n\n---\ntitle: \"Some title\"\nauthor: \"Some name\"\nformat: beamer\njupyter: python3\n---\n\n## First slide\n\nWith some content\n\n## Formatting\n\nText can be rendered *in italic* or **in bold** as well as [underlined]{.underline}.\n\nYou can use superscripts^2^, subscripts~test~, ~~strikethrough~~, and `inline code`.\n\n## Lists\n\n- Item 1\n- Item 2\n- Item 3\n\n## Ordered lists\n\n1. Item 1\n2. Item 2\n3. Item 3\n\n## Images\n\n![Example image](qmd_jupyter.png)\n\n## Tables\n\n| Col 1 | Col 2 | Col 3  |\n|-------|-------|--------|\n| a     | 1     | red    |\n| b     | 2     | orange | \n| c     | 3     | yellow |\n\n:::{.callout-note}\n\nTables can be fully customized (or you could use raw html).\n\n:::\n\n## Equations\n\n$$\n\\frac{\\partial \\mathrm C}{ \\partial \\mathrm t } + \\frac{1}{2}\\sigma^{2} \\mathrm S^{2}\n\\frac{\\partial^{2} \\mathrm C}{\\partial \\mathrm C^2}\n  + \\mathrm r \\mathrm S \\frac{\\partial \\mathrm C}{\\partial \\mathrm S}\\ =\n  \\mathrm r \\mathrm C \n$$\n\n## Some basic code block\n\n```{python}\n#| echo: true\n\n2 + 3\n```\n\n## Some plot\n\n```{python}\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Data for plotting\nt = np.arange(0.0, 2.0, 0.01)\ns = 1 + np.sin(2 * np.pi * t)\n\nfig, ax = plt.subplots()\nax.plot(t, s)\n\nax.set(xlabel='time (s)', ylabel='voltage (mV)',\n       title='Here goes the title')\nax.grid()\n\nfig.savefig(\"test.png\")\nplt.show()\n```\n\n\n\nRendered document (click on it to open it in a new tab):",
    "crumbs": [
      "Tools",
      "<em><b>Workshops</b></em>"
    ]
  },
  {
    "objectID": "tools/ws_quarto.html#recording",
    "href": "tools/ws_quarto.html#recording",
    "title": "Authoring scientific documents with Markdown and Quarto",
    "section": "Recording",
    "text": "Recording",
    "crumbs": [
      "Tools",
      "<em><b>Workshops</b></em>"
    ]
  },
  {
    "objectID": "tools/wb_uv_content.html",
    "href": "tools/wb_uv_content.html",
    "title": "A tool to rule them all",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_uv_content.html#context",
    "href": "tools/wb_uv_content.html#context",
    "title": "A tool to rule them all",
    "section": "Context",
    "text": "Context\n\nA cluttered toolkit\n\n\n\n\nAge of Rust\n\n\n\n\nuv\n\nUniversal tool.\nReally fast.\nExcellent dependency resolution with PubGrub (you guessed it, also written in Rust).\nDependency deduplication.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_uv_content.html#warning",
    "href": "tools/wb_uv_content.html#warning",
    "title": "A tool to rule them all",
    "section": "Warning",
    "text": "Warning\n\nDo not use uv on the Alliance clusters. This is for your local computer only.\nFollowing is a recap of a good workflow on the Alliance clusters.\n\n\nPython versions on Alliance clusters\nUse module (uv).\nList available Python versions:\nmodule spider python\nCheck how to load a particular version:\nmodule spider python/3.12.4\nLoad a particular version:\nmodule load python/3.12.4\nCreate a Python virtual environment:\npython -m venv ~/env\nActivate it:\nsource ~/env/bin/activate\nUpdate pip from wheel:\npython -m pip install --upgrade pip --no-index\nUse pip with --no-index to use wheels whenever possible:\npython -m pip install --no-index jax[cuda12] jax-ai-stack[grain]",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_uv_content.html#getting-started-with-uv",
    "href": "tools/wb_uv_content.html#getting-started-with-uv",
    "title": "A tool to rule them all",
    "section": "Getting started with uv",
    "text": "Getting started with uv\n\nInstall uv\n\n\n\n\nHelp\nList of commands and options:\nuv\nList of options:\nuv &lt;command&gt; -h    # e.g. uv init -h\nMan page:\nuv help &lt;command&gt;  # e.g. uv help init",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_uv_content.html#stuck-in-a-rut",
    "href": "tools/wb_uv_content.html#stuck-in-a-rut",
    "title": "A tool to rule them all",
    "section": "Stuck in a rut",
    "text": "Stuck in a rut\n(When you can‚Äôt change your workflow.)\n\nDrop-in replacement\nYou can add uv in front of your usual venv and pip commands.\nThis actually runs uv (and neither pip nor venv) so you get the speedup, but it keeps everything compatible.\n\n\nCreate a virtual env\nuv venv\n\nWith specific Python version:\n\nuv venv --python 3.12\nBy default, the virtual env is called .venv. If you don‚Äôt change its name, uv will use it automatically so you don‚Äôt need to source it.\n\n\nInstall packages in virtual env\nuv pip install jax flax\n\nFrom GitHub repo:\n\nuv pip install \"git+https://github.com/jax-ml/jax\"\nuv pip install \"git+https://github.com/jax-ml/jax@main\"\nuv pip install \"git+https://github.com/jax-ml/jax@766e68c4813a30e29b4fcefaa3253a42d0e197be\"\n\nFrom requirements.txt or pyproject.toml files:\n\nuv pip install -r requirements.txt\nuv pip install -r pyproject.toml\n\n\nAll your usual commands work\nuv pip uninstall jax\nuv pip list\nuv pip freeze\n‚Ä¶",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_uv_content.html#python-versions",
    "href": "tools/wb_uv_content.html#python-versions",
    "title": "A tool to rule them all",
    "section": "Python versions",
    "text": "Python versions\n\nAutomatic installation\nMissing Python versions are automatically installed when required.\n\nExample:\n\nuv venv --python 3.12\n\nIf Python 3.12 is missing, uv will install it during the creation of this virtual env.\n\n\n\nInstall Python\nPython versions can also be installed explicitly:\nuv python install 3.12.3\nuv python install '&gt;=3.8,&lt;3.10'\n\nSpecific implementations (default is cpython):\n\nuv python install pypy\nuv python install 'pypy&gt;=3.8,&lt;3.10'\n\n\nManage versions\nView installed and available versions:\nuv python list\nUninstall Python version:\nuv python uninstall 3.10\n\nNoe that this is a lot more convenient than pyenv which requires the exact Python version number to uninstall (e.g.¬†pyenv uninstall 3.10.6).",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_uv_content.html#python-projects",
    "href": "tools/wb_uv_content.html#python-projects",
    "title": "A tool to rule them all",
    "section": "Python projects",
    "text": "Python projects\n\nInitialize projects\nuv init my_project\nInitialized project `my-project` at `/home/marie/my_project`\n\nWith specific Python version:\n\nuv init --python 3.12 my_project\n\nCustomize which files get created:\n\nuv init --no-readme --no-description\n\n\nProject structure\n\neza -aT my_project\n\nmy_project\n‚îú‚îÄ‚îÄ .python-version\n‚îú‚îÄ‚îÄ main.py\n‚îú‚îÄ‚îÄ pyproject.toml\n‚îú‚îÄ‚îÄ README.md\n‚îî‚îÄ‚îÄ uv.lock\n\n\n\nbat -p my_project/pyproject.toml\n\n[project]\nname = \"my-project\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nreadme = \"README.md\"\nrequires-python = \"&gt;=3.13\"\ndependencies = []\n\n\n\n\nAdd dependencies\nYou need to cd into the project, then you can add dependencies:\ncd my_project\nuv add polars matplotlib\nThis creates a virtual env called .venv and a uv.lock:\neza -aTL 1\n\n\nmy_project\n‚îú‚îÄ‚îÄ .python-version\n‚îú‚îÄ‚îÄ main.py\n‚îú‚îÄ‚îÄ pyproject.toml\n‚îú‚îÄ‚îÄ README.md\n‚îî‚îÄ‚îÄ uv.lock\n\n\nHere again, no need to source the virtual env as long as you use uv.\n\n\nProject file\nGets populated automatically with dependencies:\nbat -p pyproject.toml\n\n\n[project]\nname = \"my-project\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nreadme = \"README.md\"\nrequires-python = \"&gt;=3.13\"\ndependencies = []\n\n\n\n\nList installed dependencies\nTo list explicitly installed dependencies:\nuv tree -d 1\n\n\nUsing CPython 3.13.7 interpreter at: /usr/bin/python3.13\nResolved 1 package in 0.53ms\nmy-project v0.1.0\n\n\n\n\nList all dependencies\nuv pip list\n\n\nUsing Python 3.12.10 environment at: /home/marie/.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu\nPackage Version\n------- -------\npip     24.3.1\n\n\n\n\nManage dependencies\nUpdate all dependencies in lock file and virtual env:\nuv sync -U\nRemove dependencies:\nuv remove matplotlib",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_uv_content.html#did-you-say-fast",
    "href": "tools/wb_uv_content.html#did-you-say-fast",
    "title": "A tool to rule them all",
    "section": "Did you say fast?",
    "text": "Did you say fast?\n\nPython versions pyenv vs uv\n\npyenv\npyenv install 3.10\n\n\n\n\n\n\nThis is really taking forever ü•±\n\n\n\n\n\nuv\nuv python install 3.10\nInstalled Python 3.10.17 in 1.49s\n\nYes, uv brags about how fast it installs things‚Ä¶ but it can!\n\n\n\n\nPackages: pip vs uv pip\n\npip\nCreate virtual env:\npython -m venv .venv\nActivate it:\nsource .venv/bin/activate\nUpdate pip:\npython -m pip install --upgrade pip\nInstall package:\npython -m pip install jax-ai-stack\n\n\nuv pip\nCreate virtual env:\nuv venv\n\nI am deleting my entire uv cache to make sure that I am not cheating in the comparison. You normally never do that since the cache prevents deduplication (saves space) and makes installations much faster.\nrm -rf ~/.cache/uv\n\nInstall package:\nuv pip install jax-ai-stack\nTo use the virtual env, I can activate it but I can also access it directly by running commands preceded by uv run.\n\nFor instance, I can launch a JupyterLab with access to the project virtual env with:\n\nuv run --with jupyter jupyter lab\n\nor run a script with:\n\nuv run script.py",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_uv_content.html#convenience",
    "href": "tools/wb_uv_content.html#convenience",
    "title": "A tool to rule them all",
    "section": "Convenience",
    "text": "Convenience\nHere is a real world use case: I needed to install a number of packages for a deep learning course with JAX, including Grain which still requires Python 3.12. So I needed a virtual environment with a specific Python version.\nFollowing are the workflows with classic tools vs uv.\n\npyenv, venv, and pip\nInstall Python 3.12:\npyenv install 3.12\nCreate virtual env with Python 3.12 (requires identifying the path):\n~/.pyenv/versions/3.12.10/bin/python -m venv .venv\nActivate it:\nsource .venv/bin/activate\nUpdate pip:\npython -m pip install --upgrade pip\nInstall packages:\npython -m pip install datasets jax-ai-stack[grain] matplotlib tqdm transformers\n\n\nuv\nuv init --python 3.12 demo\n\nAutomatically installs Python 3.12 if missing.\n\ncd demo\nuv add datasets jax-ai-stack[grain] matplotlib tqdm transformers\n\n\nuv advantages\nMuch simpler.\nMuch (much!) faster.\nLeaves me with a nice pyproject.toml file:\n[project]\nname = \"fl\"\nversion = \"0.1.0\"\nrequires-python = \"&gt;=3.12\"\ndependencies = [\n    \"datasets&gt;=3.5.0\",\n    \"jax-ai-stack[grain]&gt;=2025.2.5\",\n    \"matplotlib&gt;=3.10.1\",\n    \"tqdm&gt;=4.67.1\",\n    \"transformers&gt;=4.50.3\",\n]\nand a uv.lock file that I can put under version control and share for reproducibility.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_uv_content.html#tools",
    "href": "tools/wb_uv_content.html#tools",
    "title": "A tool to rule them all",
    "section": "Tools",
    "text": "Tools\n\npipx replacement\nPython tools are packages used for convenience (e.g.¬†linters, formatters) across projects, but not necessary for running your code.\nThey are commonly installed via your Linux distribution package manager, Homebrew, or pipx.\nThey can also be installed by uv:\nuv tool install ruff\n\n\nUse tools without installation\nTools can even be used without installation (from a temporary install).\nuvx ruff\n\nuvx is an alias for uv tool run.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_uv_content.html#resources",
    "href": "tools/wb_uv_content.html#resources",
    "title": "A tool to rule them all",
    "section": "Resources",
    "text": "Resources\n\nGitHub repo\nWebsite",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_tools3_slides.html#how-to-choose-tools",
    "href": "tools/wb_tools3_slides.html#how-to-choose-tools",
    "title": "Modern shell utilities",
    "section": "How to choose tools?",
    "text": "How to choose tools?\n\nPopularity (GitHub stars)\nIs it maintained? (date of last commit)\nHow polished is the documentation?\nHow fast is it? (what language is it written in?)\n\nShell/Python will be slower\nCompiled languages (Rust, C, Go) will be faster"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#what-is-eza",
    "href": "tools/wb_tools3_slides.html#what-is-eza",
    "title": "Modern shell utilities",
    "section": "What is eza?",
    "text": "What is eza?\neza is a replacement for ls\n\nAdds colours\nBetter default options\nAdd tree feature"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#installation",
    "href": "tools/wb_tools3_slides.html#installation",
    "title": "Modern shell utilities",
    "section": "Installation",
    "text": "Installation\nOn your machine\nInstructions here\nOn the Alliance clusters\neza is not installed on the Alliance clusters, so you have to install it locally under your own user. This is easy to do because it is written in Rust and can be installed with the Rust package manager\nLoad a Rust module, install eza, and make sure ~/.cargo/bin is in your path:\nmodule load rust/1.76.0\ncargo install eza\n\nYou only need to do this once. Once installed, eza will be accessible on subsequent sessions"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#usage",
    "href": "tools/wb_tools3_slides.html#usage",
    "title": "Modern shell utilities",
    "section": "Usage",
    "text": "Usage\neza\n‚ûî Different colours for directories, symlinks, and different types of files and better defaults (compare ls -al with eza -al)\neza by default shows the output in a human readable format and without the group\nThe flags are similar to those of ls with the additional -T, equivalent to running the tree utility:\neza -T python/"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#alias",
    "href": "tools/wb_tools3_slides.html#alias",
    "title": "Modern shell utilities",
    "section": "Alias",
    "text": "Alias\nYou can alias it to ls by adding to your .bashrc or .zshrc file:\nalias ls=eza\nIf you ever want to use the true ls utility, you can do so with \\ls"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#alternative",
    "href": "tools/wb_tools3_slides.html#alternative",
    "title": "Modern shell utilities",
    "section": "Alternative",
    "text": "Alternative\nIf you want a simpler and more lightweight way to add colours to your ls outputs, you can look at LS_COLORS (I did this for years until I found eza)\nTo install it locally in the Alliance clusters, you download and uncompress a script, and copy it to a proper location:\nmkdir ./LS_COLORS &&\n    curl -L https://api.github.com/repos/trapd00r/LS_COLORS/tarball/master |\n        tar xzf - --directory=./LS_COLORS --strip=1 &&\n    mkdir -p ~/.local/share &&\n    cp ~/LS_COLORS/lscolors.sh ~/.local/share &&\n    rm -r ~/LS_COLORS\nThen you add to your .bashrc/.zshrc file the sourcing of the script and an alias to ls:\nsource ~/.local/share/lscolors.sh\nalias ls='ls --color'"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#what-is-bat",
    "href": "tools/wb_tools3_slides.html#what-is-bat",
    "title": "Modern shell utilities",
    "section": "What is bat?",
    "text": "What is bat?\nbat is a replacement for cat\n\nAdds syntax highlighting for most programming languages\nAdds line numbers\nAdds pager-like search\nAdds pager-like navigation"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#installation-1",
    "href": "tools/wb_tools3_slides.html#installation-1",
    "title": "Modern shell utilities",
    "section": "Installation",
    "text": "Installation\nOn your machine\nInstructions here\nOn the Alliance clusters\nbat is already installed on the Alliance clusters"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#usage-1",
    "href": "tools/wb_tools3_slides.html#usage-1",
    "title": "Modern shell utilities",
    "section": "Usage",
    "text": "Usage\nUse bat as you would use cat:\nbat /home/marie/parvus/prog/progpy/pydoc/basics.py\nthen you are in your default pager\nAmong other options, you can disable the frame with -n\nand also remove the line numbers with -p"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#what-is-fd",
    "href": "tools/wb_tools3_slides.html#what-is-fd",
    "title": "Modern shell utilities",
    "section": "What is fd?",
    "text": "What is fd?\nfd is a replacement for find\n\nWritten in Rust, automatic parallelism ‚ûî with vastly improved performance\nMore friendly syntax\nBy default excludes binaries as well as hidden files and directories\nBy default excludes patterns from .gitignore or other .ignore files"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#installation-2",
    "href": "tools/wb_tools3_slides.html#installation-2",
    "title": "Modern shell utilities",
    "section": "Installation",
    "text": "Installation\nOn your machine\nInstructions here\nOn the Alliance clusters\nfd is already installed on the Alliance clusters"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#basic-usage",
    "href": "tools/wb_tools3_slides.html#basic-usage",
    "title": "Modern shell utilities",
    "section": "Basic usage",
    "text": "Basic usage\nSearch file names for a pattern recursively in current directory:\nfd jx\n\nfd uses regexp by default, so you can use pattern symbols:\nfd jx.*txt\n\n Search file names recursively in another directory:\nfd top bash/"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#print-all-files-in-some-directory-to-stdout",
    "href": "tools/wb_tools3_slides.html#print-all-files-in-some-directory-to-stdout",
    "title": "Modern shell utilities",
    "section": "Print all files in some directory to stdout",
    "text": "Print all files in some directory to stdout\nCurrent directory:\nfd\nAnother directory:\nfd . bash/"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#options",
    "href": "tools/wb_tools3_slides.html#options",
    "title": "Modern shell utilities",
    "section": "Options",
    "text": "Options\nSearch for files with a particular file extension:\nfd -e txt\nUse a globbing pattern instead of regexp:\nfd -g wb* bash/\nExecute command for each result of fd in parallel:\nfd top bash/ -x rg layout\nExecute command once with all results of fd as arguments:\nfd top bash/ -X rg layout"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#excluded-files-and-directories",
    "href": "tools/wb_tools3_slides.html#excluded-files-and-directories",
    "title": "Modern shell utilities",
    "section": "Excluded files and directories",
    "text": "Excluded files and directories\nBy default, fd excludes hidden files/directories and patterns in .gitignore (you can disable this with -H and -I respectively)\nThis makes fd combined with tree sometimes more useful than tree alone\nCompare tree bash/ with:\nfd . bash/ | tree --fromfile\n\nYou can make this a function:\nft () { fd $@ | tree --fromfile }\n\nExclude additional directories or patterns:\nfd -E *.txt -E img/ . bash/"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#my-personal-alias",
    "href": "tools/wb_tools3_slides.html#my-personal-alias",
    "title": "Modern shell utilities",
    "section": "My personal alias",
    "text": "My personal alias\nI prefer to disable the default settings and exclude patterns based on a file I created:\nalias fd='fd -u --ignore-file /home/marie/.fdignore'"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#what-is-ripgrep",
    "href": "tools/wb_tools3_slides.html#what-is-ripgrep",
    "title": "Modern shell utilities",
    "section": "What is ripgrep?",
    "text": "What is ripgrep?\nripgrep provides the rg utility‚Äîa replacement for grep\n\nWritten in Rust, automatic parallelism ‚ûî with vastly improved performance\nBy default excludes patterns from .gitignore or other .ignore files\nBy default excludes binaries as well as hidden files and directories\nBy default doesn‚Äôt follow symlinks"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#installation-3",
    "href": "tools/wb_tools3_slides.html#installation-3",
    "title": "Modern shell utilities",
    "section": "Installation",
    "text": "Installation\nOn your machine\nInstructions here\nOn the Alliance clusters\nrg is already installed on the Alliance clusters"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#usage-2",
    "href": "tools/wb_tools3_slides.html#usage-2",
    "title": "Modern shell utilities",
    "section": "Usage",
    "text": "Usage\nSearch lines in a file matching a pattern:\nrg colour /home/marie/parvus/prog/mint/bash/wb_tools3_slides.qmd\nSearch lines matching pattern in all files in current directory (recursively):\nrg colour\nrg and fd follow the same principles:\n\nUse regexp by default\nUse globbing pattern instead with -g\nSearch recursively by default\nSame excluded files"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#what-is-zoxide",
    "href": "tools/wb_tools3_slides.html#what-is-zoxide",
    "title": "Modern shell utilities",
    "section": "What is zoxide?",
    "text": "What is zoxide?\nzoxide allows to easily jump to any directory"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#installation-4",
    "href": "tools/wb_tools3_slides.html#installation-4",
    "title": "Modern shell utilities",
    "section": "Installation",
    "text": "Installation\nOn your machine\nInstructions here\n\nfzf (see below) adds cool functionality to it, so you might want to install it as well"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#choose-a-different-command-name",
    "href": "tools/wb_tools3_slides.html#choose-a-different-command-name",
    "title": "Modern shell utilities",
    "section": "Choose a different command name",
    "text": "Choose a different command name\nUse this instead to use the command of your choice (e.g.¬†j and ji)\ninstead of the default z and zi:\neval \"$(zoxide init --cmd j bash)\""
  },
  {
    "objectID": "tools/wb_tools3_slides.html#usage-3",
    "href": "tools/wb_tools3_slides.html#usage-3",
    "title": "Modern shell utilities",
    "section": "Usage",
    "text": "Usage\nType z (or whatever command you chose) instead of cd\nYou can simplify the path to just a few characters\nIf there are multiple locations matching your entry, the algorithm will chose the highest ranking one based on your visit frequency and how recently you visited a path\nThis means that you can visit your usual places with a few key strokes. For less frequent places, add more info\nFinally, if you want to choose amongst all possible options in a completion framework, use zi instead and zoxide will open fzf"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#alternative-1",
    "href": "tools/wb_tools3_slides.html#alternative-1",
    "title": "Modern shell utilities",
    "section": "Alternative",
    "text": "Alternative\nA tool that served me well until someone pointed zoxide to me is autojump\nInstallation\nInstructions here for your machine\nautojump is installed on the Alliance clusters, but you need add to your .bashrc or .zshrc:\n[[ -s $EPREFIX/etc/profile.d/autojump.sh ]] && source $EPREFIX/etc/profile.d/autojump.sh\nUsage\nSimilar to zoxide but you first need to visit directories so that they get entered in a database\nj is a wrapper for autojump, jc jumps to subdirectories of current directory"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#what-is-fzf",
    "href": "tools/wb_tools3_slides.html#what-is-fzf",
    "title": "Modern shell utilities",
    "section": "What is fzf?",
    "text": "What is fzf?\nfzf allows to find elements of any list through incremental completion and fuzzy matching. It can be paired with any number of commands"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#installation-6",
    "href": "tools/wb_tools3_slides.html#installation-6",
    "title": "Modern shell utilities",
    "section": "Installation",
    "text": "Installation\nOn your machine\nInstructions here\nOn the Alliance clusters\nfzf is already installed on the Alliance clusters\nTo get fzf kbds and fuzzy completion in your shell, add to your .bashrc:\neval \"$(fzf --bash)\"\nand/or your .zshrc:\nsource &lt;(fzf --zsh)"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#direct-usage",
    "href": "tools/wb_tools3_slides.html#direct-usage",
    "title": "Modern shell utilities",
    "section": "Direct usage",
    "text": "Direct usage\nIf you run fzf directly, it will search the current directory recursively, do a narrowing selection, and print the result:\nfzf\nYou can make use of fd to remove unnecessary entries:\nexport FZF_DEFAULT_COMMAND='fd -u --ignore-file /home/marie/.fdignore'"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#fzf-kbds",
    "href": "tools/wb_tools3_slides.html#fzf-kbds",
    "title": "Modern shell utilities",
    "section": "fzf kbds",
    "text": "fzf kbds\nThere are 3 default kbds:\n\nCtl+t ‚ûî paste selected file/dir into the command\nCtl+r ‚ûî paste selected command from history into the command\nAlt+c ‚ûî cd into selected dir"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#pipe-to-fzf",
    "href": "tools/wb_tools3_slides.html#pipe-to-fzf",
    "title": "Modern shell utilities",
    "section": "Pipe to fzf",
    "text": "Pipe to fzf\nYou can also pipe the output of any command that returns a list of elements into fzf\nLook for a file/directory:\nls | fzf\n Many flags to select order of entries, type of completion, preview, case-sensitivity, and more\nLook for a running process:\nps -ef | fzf --cycle -i -e +s --tac --reverse"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#what-is-a-tui",
    "href": "tools/wb_tools3_slides.html#what-is-a-tui",
    "title": "Modern shell utilities",
    "section": "What is a TUI?",
    "text": "What is a TUI?\nTerminal user interfaces (TUIs) are the predecessors to graphical user interfaces (GUIs) which are entirely text based and run in terminals\nThey have remained very popular among command line aficionados because they are fast, efficient, powerful, and keyboard-driven, while being friendly and visual\nFantastic modern ones keep being built for tasks as diverse as interfaces to Git, music players, games, emails, dashboards, and, for our purpose here, file system management"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#formerly-most-popular-file-system-tuis",
    "href": "tools/wb_tools3_slides.html#formerly-most-popular-file-system-tuis",
    "title": "Modern shell utilities",
    "section": "Formerly most popular file system TUIs",
    "text": "Formerly most popular file system TUIs\nThere are many file system TUIs and all of them are actually really good. The two most notable ones used to be:\n\nranger\n\nExtremely sophisticated, easy to customize, tons of features\n\nBuilt in Python, it can be slow for operations in directories with thousands of files\n\n\nnnn\n\nMinimalist and very fast (written in C)\n\nNot easy to customize (many customizations require compiling from source). Most functionalities rely on plugins that need to be installed. Not easy to get started with"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#the-new-kid-yazi",
    "href": "tools/wb_tools3_slides.html#the-new-kid-yazi",
    "title": "Modern shell utilities",
    "section": "The new kid: yazi",
    "text": "The new kid: yazi\nyazi is a brand new fs TUI that has quickly become the most popular\nIt is extremely modern, very fast (written in Rust), very well documented, intuitive, easy to customize, and integrates with modern utilities such as fd, rg, zoxide, and fzf out of the box\nOnly at version 0.4, it is not fully mature yet, but it has already more stars on GitHub than ranger and nnn because it combines ease of customization and sophistication with speed"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#alternatives",
    "href": "tools/wb_tools3_slides.html#alternatives",
    "title": "Modern shell utilities",
    "section": "Alternatives",
    "text": "Alternatives\nIn decreasing number of stars on GitHub:\n\nbroot\nsuperfile\nlf\nxplr\nfff (now archived)\nvifm\nmc"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#my-3-favourite-plugins",
    "href": "tools/wb_tools3_slides.html#my-3-favourite-plugins",
    "title": "Modern shell utilities",
    "section": "My 3 favourite plugins",
    "text": "My 3 favourite plugins\nThere are many plugins for Z shell and the (very bloated) Oh My Zsh, but I am sticking to 3 great plugins inspired or directly coming from the Fish shell:\n\nSyntax highlighting\nAutosuggestions\nHistory substring search"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#installation-7",
    "href": "tools/wb_tools3_slides.html#installation-7",
    "title": "Modern shell utilities",
    "section": "Installation",
    "text": "Installation\nAll plugins can be installed (info in their README) or simply Git cloned. zsh-syntax-highlighting is already installed on the Alliance clusters, so you only need to clone the other two:\n# create a directory to store the scripts\nmkdir ~/.zsh_plugins\n# autosuggestions\ngit clone https://github.com/zsh-users/zsh-autosuggestions.git ~/.zsh_plugins/zsh-autosuggestions\n# history substring search\ngit clone https://github.com/zsh-users/zsh-history-substring-search.git ~/.zsh_plugins/zsh-history-substring-search\nThen you need to source them (including zsh-syntax-highlighting), so add to your .zshrc file:\nsource $EPREFIX/usr/share/zsh/site-functions/zsh-syntax-highlighting.zsh\nsource ~/.zsh_plugins/zsh-history-substring-search/zsh-history-substring-search.zsh\nsource ~/.zsh_plugins/zsh-autosuggestions/zsh-autosuggestions.zsh"
  },
  {
    "objectID": "tools/wb_tools3_slides.html#usage-5",
    "href": "tools/wb_tools3_slides.html#usage-5",
    "title": "Modern shell utilities",
    "section": "Usage",
    "text": "Usage\nYou now have syntax highlighting in your shell inputs\nTo use the history substring search, start typing some command\nthen press Alt+p or Alt+n\nIt will cycle through all entries in your history that start that way\nFinally, the autosuggestion will suggest commands based on your history and/or classic suggestions\nAccept the whole command with Ctl+e or a single word with Alt+f"
  },
  {
    "objectID": "tools/wb_tools3.html",
    "href": "tools/wb_tools3.html",
    "title": "Modern shell utilities",
    "section": "",
    "text": "In recent years, a number of open-source utilities for the Unix shell have emerged. Some are meant as replacements for classic tools with improved performance, better defaults, or nicer-looking outputs; others add novel functionality. Several of them were recently installed on the Alliance clusters.\nIn this webinar I will cover a selection of tools that are very popular, well-maintained, and that have served me well in my daily workflows:\n\nls in colours: eza,\nsmart cd: zoxide,\na cat with wings: bat,\nRIP grep: ripgrep,\nfaster find: fd,\nfuzzy finder: fzf,\nfile system TUIs.\n\nI will also talk about three useful Zsh plugins:\n\na syntax highlighter,\nautosuggestions,\nan improved history searcher.\n\nFor each tool/plugin, I will talk about installation on a personal computer and on the Alliance clusters and I will give live demos.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities"
    ]
  },
  {
    "objectID": "tools/wb_tools1.html",
    "href": "tools/wb_tools1.html",
    "title": "Fun tools to simplify your life in the shell",
    "section": "",
    "text": "Working in the command-line has many advantages and it is often necessary, but can it be fun?\nIn this webinar, aimed at any command-line user, I intend to demonstrate that yes, it can! by introducing three free and open source utilities which make navigating your system and your outputs a lot easier:\n\nfzf is a simple, yet extremely powerful interactive fuzzy finder allowing for incremental completion and narrowing selection of any command line output. I will show you how to build simple shell functions which harvest its power to instantly refresh your memory on your custom keybindings or aliases, navigate your command history, find and kill processes, and explore and checkout your git commits. After this, you will be able to use fzf for any number of other applications in your work in the command-line.\nautojump lets you jump anywhere you want in your directories in just a few keystrokes (no more of this painful navigation writing down long paths).\nWith the ranger file manager, you can browse (with preview!), open, copy, move, delete, etc. your files and directories in a friendly way from the command line. Added bonus: you can use fzf and autojump within ranger!\n\nWarning: too much fun in the command-line can lead to addiction and geek behaviours. Use in moderation.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Fun tools for the command line"
    ]
  },
  {
    "objectID": "tools/wb_quarto_content.html",
    "href": "tools/wb_quarto_content.html",
    "title": "The new R Markdown:",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Quarto: the new R Markdown",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_quarto_content.html#markup-markdown",
    "href": "tools/wb_quarto_content.html#markup-markdown",
    "title": "The new R Markdown:",
    "section": "Markup & markdown",
    "text": "Markup & markdown\n\nMarkup languages\n\nControl the formatting of text documents.\nPowerful but the unrendered text is visually cluttered and hard to read.\n\n\nExample: Tex‚Äîoften with macro package LaTeX‚Äîto create pdfs.\n\n\\documentclass{article}\n\\title{My title}\n\\author{My name}\n\\usepackage{datetime}\n\\newdate{date}{24}{11}{2022}\n\\date{\\displaydate{date}}\n\\begin{document}\n \\maketitle\n \\section{First section}\n Some text in the first section.\n\\end{document}\n\nExample: HTML‚Äîoften with css/scss files‚Äîto create webpages.\n\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en-US\"&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"utf-8\" /&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width\" /&gt;\n    &lt;title&gt;My title&lt;/title&gt;\n    &lt;address class=\"author\"&gt;My name&lt;/address&gt;\n    &lt;input type=\"date\" value=\"2022-11-24\" /&gt;\n  &lt;/head&gt;\n  &lt;h1&gt;First section&lt;/h1&gt;\n  &lt;body&gt;\n    Some text in the first section.\n  &lt;/body&gt;\n&lt;/html&gt;\n\n\nMarkdown\n\nRemoves the visual clutter and makes texts readable prior to rendering.\nCreated in 2004.\nBy now quasi-ubiquitous.\nInitially created for webpages.\nRaw HTML can be inserted when easy syntax falls short.\n\n\nPandoc‚Äôs extended Markdown\nPandoc (free and open-source markup formats converter) supports an extended Markdown syntax with functionality for figures, tables, callout blocks, LaTeX equations, citations‚Ä¶\nRemains as readable as basic Markdown, but can be rendered in any format (pdf, books, entire websites, Word documents‚Ä¶)\n\nRemoves the visual clutter and makes texts readable prior to rendering.\nCreated in 2004.\nBy now quasi-ubiquitous.\nInitially created for webpages.\nRaw HTML can be inserted when easy syntax falls short.\n\n\nPrevious example using Pandoc‚Äôs Markdown:\n\n---\ntitle: My title\nauthor: My name\n---\n# First section\nSome text in the first section.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Quarto: the new R Markdown",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_quarto_content.html#literate-programming",
    "href": "tools/wb_quarto_content.html#literate-programming",
    "title": "The new R Markdown:",
    "section": "Literate programming",
    "text": "Literate programming\nLiterate programming is a methodology that combines snippets of code and written text.\nFirst introduced in 1984, this approach to the creation of documents has truly exploded in popularity in recent years thanks to the development of new tools such as R Markdown and, later, Jupyter notebooks.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Quarto: the new R Markdown",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_quarto_content.html#quarto",
    "href": "tools/wb_quarto_content.html#quarto",
    "title": "The new R Markdown:",
    "section": "Quarto",
    "text": "Quarto\n\nHow it works\nCode blocks are executed by Jupyter (Python or Julia) or knitr (R), then pandoc renders the document into any format.\n\nJulia/Python:\n From Quarto documentation\n\n\nR:\n From Quarto documentation\nCode blocks are executed by Jupyter (Python or Julia) or knitr (R), then pandoc renders the document into any format.\nCan be used from .qmd text files or directly from RStudio or Jupyter notebooks.\n\n\n\nSupported languages\nSyntax highlighting in pretty much any language.\nExecutable code blocks in Python, R, Julia, Observable JS.\nOutput formats:\n- HTML\n- PDF\n- MS Word\n- OpenOffice\n- ePub\n- Revealjs\n- PowerPoint\n- Beamer\n- GitHub Markdown\n- CommonMark\n- Hugo\n- Docusaurus\n- Markua\n- MediaWiki\n- DokuWiki\n- ZimWiki\n- Jira Wiki\n- XWiki\n- JATS\n- Jupyter\n- ConTeXt\n- RTF\n- reST\n- AsciiDoc\n- Org-Mode\n- Muse\n- GNU\n- Groff\n\n\nDocument structure & syntax\n\nFront matter\nWritten in YAML.\nSets the options for the document. Let‚Äôs see a few examples.\n\nCan be very basic:\n\n---\ntitle: \"My title\"\nauthor: \"My name\"\n---\n\nOr more sophisticated:\n\n---\ntitle: \"Some title\"\nsubtitle: \"Some subtitle\"\ninstitute: \"Simon Fraser University\"\n---\n\n\nText\nWritten in Pandoc‚Äôs extended Markdown.\n\n\nCode blocks\nSyntax highlighting only:\n```{.language}\ncode\n```\nSyntax highlighting and code execution:\n```{language}\ncode\n```\nOptions can be added to individual blocks:\n```{language}\n#| option: value\n\ncode\n```\n\n\n\nRendering\nTwo commands:\nquarto render file.qmd     # Renders the document\nquarto preview file.qmd    # Displays a live preview\n\n\nSome advantages of Quarto\n\nGeneral considerations\n\nExtremely well documented.\nSolid team behind the work.\nFree and open source.\nUses only well established and well tested tools.\n\n\n\nWebpages/websites\n\nFast, easy, and clean.\nSites work on screens of any size out of the box (uses Bootstrap 5).\nCan be customized with CSS/SCSS, but good out of the box.\nCode blocks can have a copy button.\nGreat search functionality.\nSite/pages can be hosted anywhere easily.\n\n\n\nAdvantages of code execution\n\nPeople can see code outputs without running code.\nForces to test every bit of code.\nNo need for a complex system linking code scripts with publishing documents.\n\n\n\n\nResources\n\nOfficial sites\n\nWebsite\nRepo\nDocumentation index\n\n\n\nInstallation\nYou can find information in the Quarto documentation or in our previous workshop on Quarto.\n\n\nBasic examples\nYou can find several examples in our previous workshop on Quarto.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Quarto: the new R Markdown",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_marimo_slides.html#notes",
    "href": "tools/wb_marimo_slides.html#notes",
    "title": "The next generation of Python notebooks",
    "section": "Notes",
    "text": "Notes\n\nI am making an opinionated decision to use uv for installation\nNotebooks are great for prototyping but not at scale\nmarimo is not available on the Alliance clusters at this point"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#whats-wrong-with-jupyter",
    "href": "tools/wb_marimo_slides.html#whats-wrong-with-jupyter",
    "title": "The next generation of Python notebooks",
    "section": "What‚Äôs wrong with Jupyter?",
    "text": "What‚Äôs wrong with Jupyter?\nJupyter notebooks are very popular but they come with downsides:\n\nVersion control nightmare\nAwkward JSON file format\nReproducibility issues"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#dag-dataflow",
    "href": "tools/wb_marimo_slides.html#dag-dataflow",
    "title": "The next generation of Python notebooks",
    "section": "DAG dataflow",
    "text": "DAG dataflow\nmarimo notebooks automatically generate an intermediate representation (IR) in the form of a directed acyclic graph (DAG) of:\n\ndefinitions (defs) of global variables\nreferences (refs) of global variables\n\nEach cell is parsed into an abstract syntax tree (AST)\nStatically inferred (no runtime tracing)"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#python-files",
    "href": "tools/wb_marimo_slides.html#python-files",
    "title": "The next generation of Python notebooks",
    "section": "Python files",
    "text": "Python files\n\n\nNotebooks are saved as .py files\nEach cell is stored as a function\nPure functions can be reused as modules\n\n\n\n\n\n\n\n\n\n\n ‚ûî\n\nEasy version control\nDirectly executable as scripts or web apps\nReadable in text editors"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#interactive-elements",
    "href": "tools/wb_marimo_slides.html#interactive-elements",
    "title": "The next generation of Python notebooks",
    "section": "Interactive elements",
    "text": "Interactive elements\nmarimo.ui creates interactive user interface (UI) elements with first-class support\nNotebooks are automatically updated when values are changed via interactions"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#cool-features",
    "href": "tools/wb_marimo_slides.html#cool-features",
    "title": "The next generation of Python notebooks",
    "section": "Cool features",
    "text": "Cool features\n\nTurn notebooks into apps\nIntegrated AI\nDocstrings on hover"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#the-constraints",
    "href": "tools/wb_marimo_slides.html#the-constraints",
    "title": "The next generation of Python notebooks",
    "section": "The constraints",
    "text": "The constraints\nAll this comes at the cost of some constraints:\n\nGlobal variables must be unique\nIn-place transformations are not allowed\nMutations and attributes are not tracked\n\n\nAll this is good practice for strict functional programming (and JAX)!"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#computation-cost",
    "href": "tools/wb_marimo_slides.html#computation-cost",
    "title": "The next generation of Python notebooks",
    "section": "Computation cost",
    "text": "Computation cost\nThere is a cost to updating the DAG at each change\nRuntime configurations and cell settings allow to control when re-runs happen"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#installation",
    "href": "tools/wb_marimo_slides.html#installation",
    "title": "The next generation of Python notebooks",
    "section": "Installation",
    "text": "Installation\nCreate a uv project:\nuv init --bare\nInstall marimo in it as a development dependency:\nuv add --dev marimo\n(Optional) add tools marimo can make use of:\nuv add --dev ruff basedpyright mcp"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#launch-a-notebook",
    "href": "tools/wb_marimo_slides.html#launch-a-notebook",
    "title": "The next generation of Python notebooks",
    "section": "Launch a notebook",
    "text": "Launch a notebook\nmarimo edit notebook.py\n\nIf you installed with uv, first activate the virtual env or run instead:\nuv run marimo edit notebook.py"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#configuration",
    "href": "tools/wb_marimo_slides.html#configuration",
    "title": "The next generation of Python notebooks",
    "section": "Configuration",
    "text": "Configuration\nVia GUI\n top right corner (Notebook settings) ‚ûî User settings"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#official-website",
    "href": "tools/wb_marimo_slides.html#official-website",
    "title": "The next generation of Python notebooks",
    "section": "Official website",
    "text": "Official website\nExcellent documentation:\nUser guides\nAPI reference"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#tutorials",
    "href": "tools/wb_marimo_slides.html#tutorials",
    "title": "The next generation of Python notebooks",
    "section": "Tutorials",
    "text": "Tutorials\nmarimo tutorial intro\nFor more tutorials, replace intro with any of:\ndataflow\nui\nmarkdown\nplots\nsql\nlayout\nfileformat\nmarkdown-format\nfor-jupyter-users\n\nIf you installed with uv, first activate the virtual env or run instead:\nuv run marimo tutorial intro"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#key-bindings",
    "href": "tools/wb_marimo_slides.html#key-bindings",
    "title": "The next generation of Python notebooks",
    "section": "Key bindings",
    "text": "Key bindings\nVim kbd available\nCommand mode\nEsc\nWith vim keybindings are enabled or other issues, use Ctrl+Esc or Shift+Esc instead\nNavigation between cells, copy/cut/paste cells\nEdit mode\nEnter or click on a cell\nEdit content"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#key-bindings-1",
    "href": "tools/wb_marimo_slides.html#key-bindings-1",
    "title": "The next generation of Python notebooks",
    "section": "Key bindings",
    "text": "Key bindings\nCustomizable. List displayed by Ctrl-Shift-h"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#ipynb-notebooks-conversion",
    "href": "tools/wb_marimo_slides.html#ipynb-notebooks-conversion",
    "title": "The next generation of Python notebooks",
    "section": "ipynb notebooks conversion",
    "text": "ipynb notebooks conversion\nmarimo convert notebook.ipynb -o notebook.py\n\nIPython magics are replaced by Python functions\n\n\nAfter a uv install, run (or activate the virtual env):\nuv run marimo convert notebook.ipynb -o notebook.py"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#installing-python-packages",
    "href": "tools/wb_marimo_slides.html#installing-python-packages",
    "title": "The next generation of Python notebooks",
    "section": "Installing Python packages",
    "text": "Installing Python packages\nDirectly in the notebook following a pop-up when trying to use uninstalled package\n\nOf course this can also be done via the command line:\nuv add &lt;package&gt;\n\nExample:\n\nuv add numpy"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#outputs-displays",
    "href": "tools/wb_marimo_slides.html#outputs-displays",
    "title": "The next generation of Python notebooks",
    "section": "Outputs displays",
    "text": "Outputs displays\n\n\nConsole outputs\nText written to stdout/stderr\n‚ûî displayed below cells by default\n‚ûî hidden in app mode\n\nExample:\n\n\n\ncell\n\nprint(\"This is a console output.\")\n\n\n\n\nCell outputs\n\n‚ûî displayed above cells by default\n‚ûî shown in app mode\n\nExample:\n\n\n\ncell\n\n\"This is a cell output.\""
  },
  {
    "objectID": "tools/wb_marimo_slides.html#forbidden-re-assignments",
    "href": "tools/wb_marimo_slides.html#forbidden-re-assignments",
    "title": "The next generation of Python notebooks",
    "section": "Forbidden re-assignments",
    "text": "Forbidden re-assignments\nVariables re-assignments are OK within cells, but not across cells\nThe cells with re-assignments will not run\n\nReusing i in loops across cells won‚Äôt work\n+=, -=, etc. won‚Äôt run"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#mutations-do-not-call-re-runs",
    "href": "tools/wb_marimo_slides.html#mutations-do-not-call-re-runs",
    "title": "The next generation of Python notebooks",
    "section": "Mutations do not call re-runs",
    "text": "Mutations do not call re-runs\nLet‚Äôs consider:\n\n\ncell 0\n\nl = [1, 2, 3]\n\n\n\ncell 1\n\nlen(l)\n\n\n\ncell 2\n\nl.append(4)\n\nrunning the cell 2 will not update cell 1"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#deleting-cells",
    "href": "tools/wb_marimo_slides.html#deleting-cells",
    "title": "The next generation of Python notebooks",
    "section": "Deleting cells",
    "text": "Deleting cells\nAutomatically deletes variables defined in them (and cells with refs to them are re-run)"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#no-cycles-permitted",
    "href": "tools/wb_marimo_slides.html#no-cycles-permitted",
    "title": "The next generation of Python notebooks",
    "section": "No cycles permitted",
    "text": "No cycles permitted\nThis would make the DAG impossible:\n\n\ncell 0\n\nvar1 = 4\nprint(var2)\n\n\n\ncell 1\n\nvar2 = 7\nprint(var1)"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#attributes-are-not-tracked",
    "href": "tools/wb_marimo_slides.html#attributes-are-not-tracked",
    "title": "The next generation of Python notebooks",
    "section": "Attributes are not tracked",
    "text": "Attributes are not tracked\nAssignments to attributes aren‚Äôt tracked:\n\n\ncell 0\n\nclass Object(object):\n    pass\n\nobj = Object()\nobj.somefield = \"somevalue\"\n\n\n\ncell 1\n\nprint(obj.somefield)\n\n\n\ncell 2\n\nobj.somefield = \"newvalue\"\n\ncell 1 is not re-run and updated automatically"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#dataflow-programming",
    "href": "tools/wb_marimo_slides.html#dataflow-programming",
    "title": "The next generation of Python notebooks",
    "section": "Dataflow programming",
    "text": "Dataflow programming\nExecution order \\(\\neq\\) cell order\nThe execution order is determined by the DAG\nThis is a totally valid notebook:\n\n\ncell 0\n\nprint(new_var)\n\n\n\ncell 1\n\nnew_var = 8"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#dataflow-programming-1",
    "href": "tools/wb_marimo_slides.html#dataflow-programming-1",
    "title": "The next generation of Python notebooks",
    "section": "Dataflow programming",
    "text": "Dataflow programming\nThese are perfectly equivalent notebooks (they have the same DAG):\n\n\n\n\ncell 0\n\na = 3\n\n\n\ncell 1\n\na1 = 8.9\na2 = 8.3\n\n\n\ncell 2\n\na3 = 3.0\n\n\n\ncell 3\n\na4 = 1.2\n\n\n\ncell 4\n\nmy_list = [a1, a2, a3, a4]\n\n\n\n\n\n\ncell 0\n\nmy_list = [a1, a2, a3, a4]\n\n\n\ncell 1\n\na = 3\n\n\n\ncell 2\n\na3 = 3.0\n\n\n\ncell 3\n\na1 = 8.9\na2 = 8.3\n\n\n\ncell 4\n\na4 = 1.2"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#dataflow-navigation",
    "href": "tools/wb_marimo_slides.html#dataflow-navigation",
    "title": "The next generation of Python notebooks",
    "section": "Dataflow navigation",
    "text": "Dataflow navigation\n\n\nHere is our notebook:\n\n\ncell 0\n\na = 3\n\n\n\ncell 1\n\na1 = 8.9\na2 = 8.3\n\n\n\ncell 2\n\na3 = 3.0\n\n\n\ncell 3\n\na4 = 1.2\n\n\n\ncell 4\n\nmy_list = [a1, a2, a3, a4]\n\n\n\n\n‚ÄÉ‚ÄÉThis is the corresponding DAG:\n\n\n\n\n\n\n\n\n\n0\n\ncell 0\n\n\n\n1\n\ncell 1\n\n\n\n\n2\n\ncell 2\n\n\n\n\n4\n\ncell 4\n\n\n\n1-&gt;4\n\n\n\n\n\n3\n\ncell 3\n\n\n\n\n2-&gt;4\n\n\n\n\n\n3-&gt;4"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#dataflow-navigation-1",
    "href": "tools/wb_marimo_slides.html#dataflow-navigation-1",
    "title": "The next generation of Python notebooks",
    "section": "Dataflow navigation",
    "text": "Dataflow navigation\nNavigating and understanding the dataflow is made easy by a number of tools:\n\nMinimap (Ctrl-Shift-i)\nDependency explorer (left menu)\nReference highlighting and jumping (hover on underlined refs, Ctrl+click to jump to defs)"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#managing-runs",
    "href": "tools/wb_marimo_slides.html#managing-runs",
    "title": "The next generation of Python notebooks",
    "section": "Managing runs",
    "text": "Managing runs\nRe-running heavy computations to update the notebooks can be costly\nThis can be controlled by disabling/enabling:\n\nautorun on startup\nautorun on cell change (lazy execution)\nspecific cells"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#markdown",
    "href": "tools/wb_marimo_slides.html#markdown",
    "title": "The next generation of Python notebooks",
    "section": "Markdown",
    "text": "Markdown\nYou can turn cells into markdown and select raw strings and/or f-string\n\n\n\n\n\n\nat the bottom right corner of every cell"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#markdown-extensions",
    "href": "tools/wb_marimo_slides.html#markdown-extensions",
    "title": "The next generation of Python notebooks",
    "section": "Markdown extensions",
    "text": "Markdown extensions\n\n\ncell\n\n/// details | Click for details.\n\nYou can create accordion blocks.\n///\n\n\n\ncell\n\n/// admonition | Tips\n\nYou can create info blocks.\n///\n\n\n\ncell\n\n/// attention | Be careful!\n\nYou can create warning blocks.\n///"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#plots",
    "href": "tools/wb_marimo_slides.html#plots",
    "title": "The next generation of Python notebooks",
    "section": "Plots",
    "text": "Plots\nPlotting works as you would expect\nJavaScript interactivity also works\n\n\ncell\n\nimport plotly.express as px\ndf = px.data.tips()\n\nfig = px.density_contour(df, x=\"total_bill\", y=\"tip\")\nfig.update_traces(contours_coloring=\"fill\", contours_showlabels = True)\nfig.show()"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#script",
    "href": "tools/wb_marimo_slides.html#script",
    "title": "The next generation of Python notebooks",
    "section": "Script",
    "text": "Script\nYou can run a notebook as a script, without having to do any conversion, with:\npython notebook.py"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#apps",
    "href": "tools/wb_marimo_slides.html#apps",
    "title": "The next generation of Python notebooks",
    "section": "Apps",
    "text": "Apps\nYou can run a notebook as an app with:\nmarimo run notebook.py"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#ai",
    "href": "tools/wb_marimo_slides.html#ai",
    "title": "The next generation of Python notebooks",
    "section": "AI",
    "text": "AI\nCompletion\nProvided out of the box with GitHub Copilot. Tab to complete\nGenerate cells with AI\nBox at the bottom of notebook\nCells refactoring\nIn the menu of each cell"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#ai-1",
    "href": "tools/wb_marimo_slides.html#ai-1",
    "title": "The next generation of Python notebooks",
    "section": "AI",
    "text": "AI\nChat\nButton on the left menu opens a chat panel\nGoing crazy\nmarimo new asks an LLM to generate a full notebook from scratch:\n\nExample:\n\nmarimo new \"Create a cool-looking 3D plot with matplotlib.\""
  },
  {
    "objectID": "tools/wb_marimo_slides.html#the-marimo-module",
    "href": "tools/wb_marimo_slides.html#the-marimo-module",
    "title": "The next generation of Python notebooks",
    "section": "The marimo module",
    "text": "The marimo module\nEvery notebook loads the marimo module automatically\nInteractive elements make use of the module, so it is convenient to create an alias:\n\n\ncell 0\n\nimport marimo as mo"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#create-an-interactive-element",
    "href": "tools/wb_marimo_slides.html#create-an-interactive-element",
    "title": "The next generation of Python notebooks",
    "section": "Create an interactive element",
    "text": "Create an interactive element\nYou create an element with one of the mo.ui methods\nCall it at the end of the cell to display it:\n\n\ncell 1\n\nslider = mo.ui.slider(start=1, stop=10, step=1)\nslider\n\n\nUI elements are defs\n\nYou can embed it in a markdown output and format it with an f-string:\n\n\ncell 1\n\nslider = mo.ui.slider(start=1, stop=10, step=1)\nmo.md(f\"Pick a value: {slider}\")"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#access-the-value",
    "href": "tools/wb_marimo_slides.html#access-the-value",
    "title": "The next generation of Python notebooks",
    "section": "Access the value",
    "text": "Access the value\nYou then need to access its value in another cell:\n\n\ncell 2\n\nslider.value\n\nWhich you can also embed in some markdown:\n\n\ncell 2\n\nmo.md(f\"You picked the value: {slider.value}\")"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#example",
    "href": "tools/wb_marimo_slides.html#example",
    "title": "The next generation of Python notebooks",
    "section": "Example",
    "text": "Example\nCreate a date selector element:\n\n\ncell 0\n\ndate = mo.ui.date()\nmo.md(f\"Select a date: {date}\")\n\nPrint the selected date:\n\n\ncell 1\n\nmo.md(f\"Your selected date is: {date.value}\")"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#progress-bars",
    "href": "tools/wb_marimo_slides.html#progress-bars",
    "title": "The next generation of Python notebooks",
    "section": "Progress bars",
    "text": "Progress bars\nSimilar to tqdm:\n\n\ncell\n\nimport time\n\nfor i in mo.status.progress_bar(range(50)):\n    print(i)\n    time.sleep(0.1)"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#python-files-for-notebooks",
    "href": "tools/wb_marimo_slides.html#python-files-for-notebooks",
    "title": "The next generation of Python notebooks",
    "section": "Python files for notebooks",
    "text": "Python files for notebooks\nNotebooks get written in Python as:\n\n\nnotebook.py\n\nimport marimo\n\n__generated_with = \"&lt;some version&gt;\"\napp = marimo.App()\n\n\"&lt;your cells go here&gt;\"\n\nif __name__ == \"__main__\":\n    app.run()"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#notebook-settings",
    "href": "tools/wb_marimo_slides.html#notebook-settings",
    "title": "The next generation of Python notebooks",
    "section": "Notebook settings",
    "text": "Notebook settings\nAdded as:\n\n\nnotebook.py\n\nimport marimo\n\n__generated_with = \"&lt;some version&gt;\"\napp = marimo.App(width=\"medium\", css_file=\"custom.css\", auto_download=[\"html\"])\n\n\"&lt;your cells go here&gt;\"\n\nif __name__ == \"__main__\":\n    app.run()"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#what-are-cells-really",
    "href": "tools/wb_marimo_slides.html#what-are-cells-really",
    "title": "The next generation of Python notebooks",
    "section": "What are cells really?",
    "text": "What are cells really?\nCells are functions wrapped by an @app.cell decorator\nThis makes them easy to turn into apps\nWhen you create an empty cell, your .py file (let‚Äôs call it notebook.py) sees the following added:\n\n\nnotebook.py\n\n@app.cell\ndef _():\n    return"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#what-are-cells-really-1",
    "href": "tools/wb_marimo_slides.html#what-are-cells-really-1",
    "title": "The next generation of Python notebooks",
    "section": "What are cells really?",
    "text": "What are cells really?\nNow, add in the cell:\n\n\ncell 0\n\nx = 8\ny = 9\n\nand you get in your .py file:\n\n\nnotebook.py\n\n@app.cell\ndef _():\n    x = 8\n    y = 9\n    return"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#what-are-cells-really-2",
    "href": "tools/wb_marimo_slides.html#what-are-cells-really-2",
    "title": "The next generation of Python notebooks",
    "section": "What are cells really?",
    "text": "What are cells really?\nHide the code and the script turns into:\n\n\nnotebook.py\n\n@app.cell(hide_code=True)\ndef _():\n    x = 8\n    y = 9\n    return"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#references",
    "href": "tools/wb_marimo_slides.html#references",
    "title": "The next generation of Python notebooks",
    "section": "References",
    "text": "References\nCell dependencies are passed as arguments to the function:\n\n\nNotebook cells:\n\n\ncell 1\n\nprint(x)\n\n\n\n\ncell 2\n\nprint(x, y)\n\n\n\n\nCorresponding Python file:\n\n\nnotebook.py\n\n@app.cell\ndef _(x):\n    print(x)\n    return\n\n\n\nnotebook.py\n\n@app.cell\ndef _(x, y):\n    print(x, y)\n    return"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#print-refs-and-defs",
    "href": "tools/wb_marimo_slides.html#print-refs-and-defs",
    "title": "The next generation of Python notebooks",
    "section": "Print refs and defs",
    "text": "Print refs and defs\nmo.defs and mo.refs output the defs and refs of a cell:\n\n\ncell 0\n\nvar = 8\nprint(f\"The defs are: {mo.defs()} and the refs are: {mo.refs()}\")\n\n\n\ncell 1\n\nvar + 7\nprint(f\"The defs are: {mo.defs()} and the refs are: {mo.refs()}\")"
  },
  {
    "objectID": "tools/wb_marimo_slides.html#how-is-md-turned-into-python",
    "href": "tools/wb_marimo_slides.html#how-is-md-turned-into-python",
    "title": "The next generation of Python notebooks",
    "section": "How is md turned into Python?",
    "text": "How is md turned into Python?\nMarkdown text is wrapped in mo.md functions:\n\n\nnotebook.py\n\n@app.cell\ndef _(mo):\n    mo.md(\n        r\"\"\"\n    ## Heading\n\n    Some markdown with some *italic* formatting.\n    \"\"\"\n    )\n    return"
  },
  {
    "objectID": "tools/wb_marimo.html",
    "href": "tools/wb_marimo.html",
    "title": "The next generation of Python notebooks",
    "section": "",
    "text": "Project Jupyter was extremely innovative when, back in 2011, they built an open source Notebook on top of the IPython shell (itself an improvement over the Python shell). Notebooks proved an extremely popular tool for literate programming and are widely used today.\nThey do however come with two major issues:\n\nThey are a nightmare for version control.\nThe JSON-like format of the .ipynb files used by Jupyter makes versioning a challenge without the use of proprietary tools or hacky back and forth conversions with, for instance, jupytext.\nIt is easy to forget to rerun cells in order and publish a non-reproducible notebook.\nA study of 10 million notebooks published on GitHub found that 36% of them had been run in a non-linear fashion.\n\nmarimo is a new generation of open source notebook for Python that addresses these problems by using a dataflow graph under the hood ensuring that cells remain up to date and using .py as its file format. marimo notebooks also provide excellent interactivity with direct synchronization with the Python kernel. Consequently, these new notebooks have seen a surge in popularity since their launch in 2023.\nIn this webinar, I will demo the installation and usage of marimo notebooks.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Next gen Python notebooks"
    ]
  },
  {
    "objectID": "tools/wb_lazygit_content.html",
    "href": "tools/wb_lazygit_content.html",
    "title": "A great Git TUI: lazygit",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "A great Git TUI: lazygit",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_lazygit_content.html#git-interfaces",
    "href": "tools/wb_lazygit_content.html#git-interfaces",
    "title": "A great Git TUI: lazygit",
    "section": "Git interfaces",
    "text": "Git interfaces\nThere are 3 main ways to use Git:\n\nThrough a Git GUI.\nFrom the command line.\nIntegrated within IDE.\n\nThey all have downsides:\n\n\n\n\nThrough a Git GUI\nFrom the command line\nIntegrated within IDE\n\n\n\n‚ûî\n‚ûî\n‚ûî\n\n\nSlow and buggy\nAustere and unintuitive\nLimited",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "A great Git TUI: lazygit",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_lazygit_content.html#on-the-beauty-of-tuis",
    "href": "tools/wb_lazygit_content.html#on-the-beauty-of-tuis",
    "title": "A great Git TUI: lazygit",
    "section": "On the beauty of TUIs",
    "text": "On the beauty of TUIs\nTerminal user interfaces (TUIs) were precursors to graphical user interfaces (GUIs), but they did not disappear. People continue to build TUIs because they uniquely provide the speed of the command line and the easy of use of GUIs.\nGitHub is full of sleek, modern, open source TUIs for all sorts of applications.\nSeveral of them provide an interface to Git. lazygit is my favourite one.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "A great Git TUI: lazygit",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_lazygit_content.html#lazygit",
    "href": "tools/wb_lazygit_content.html#lazygit",
    "title": "A great Git TUI: lazygit",
    "section": "lazygit",
    "text": "lazygit\nWith over 52k stars on GitHub, lazygit, created and maintained by Jesse Duffield is probably the most polished Git TUI.\nI followed it as it grew and developed over the past 5 years. It was great from the start, but by now, it is a truly beautiful mature tool.\nIt is cross-platform. You can find installation instructions in the README.\nGet command options:\nlazygit -h\nPrint default configurations with:\nlazygit -c\n\nlazygit is fully customizable.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "A great Git TUI: lazygit",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_lazygit_content.html#resources",
    "href": "tools/wb_lazygit_content.html#resources",
    "title": "A great Git TUI: lazygit",
    "section": "Resources",
    "text": "Resources\n\nRepo\nDefault kbds\nConfiguration options",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "A great Git TUI: lazygit",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_lazygit_content.html#time-for-a-demo",
    "href": "tools/wb_lazygit_content.html#time-for-a-demo",
    "title": "A great Git TUI: lazygit",
    "section": "Time for a demo!",
    "text": "Time for a demo!\nI will spend the rest of this webinar showing you how to use Git through lazygit.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "A great Git TUI: lazygit",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_help_slides.html#when-you-are-stuck-1",
    "href": "tools/wb_help_slides.html#when-you-are-stuck-1",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "When you are stuck",
    "text": "When you are stuck\n\nFirst, look for information that is already out there\n\n\nThen, ask for help"
  },
  {
    "objectID": "tools/wb_help_slides.html#look-for-information",
    "href": "tools/wb_help_slides.html#look-for-information",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Look for information",
    "text": "Look for information\n\nRead carefully any error message\nRead the documentation (local or online)\nMake sure you have up-to-date versions\nGoogle (using carefully selected keywords or the error message)\nLook for open issues & bug reports"
  },
  {
    "objectID": "tools/wb_help_slides.html#error-messages",
    "href": "tools/wb_help_slides.html#error-messages",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Error messages",
    "text": "Error messages\nRead them!\nFamiliarise yourself with the error types in the languages you use\n\nExample: Python‚Äôs syntax errors vs exceptions\n\nWarnings ‚â† errors\nLook for bits you understand (don‚Äôt get put off by what you don‚Äôt understand)\nIdentify the locations of the errors to go investigate that part of the code"
  },
  {
    "objectID": "tools/wb_help_slides.html#documentation",
    "href": "tools/wb_help_slides.html#documentation",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Documentation",
    "text": "Documentation\n\nYou need to find it\n\n\nYou need to understand it"
  },
  {
    "objectID": "tools/wb_help_slides.html#finding-documentation",
    "href": "tools/wb_help_slides.html#finding-documentation",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Finding documentation",
    "text": "Finding documentation\n\nOnline:\nTake the time to look for the official documentation & other high quality sources for the languages & tools you use.\n\n\n\nExamples:\nPython: Reference manual, Standard library manual, Tutorial\nNumPy: Tutorial\nR: Open source book ‚ÄúR for Data Science‚Äù, Open source book ‚ÄúAdvanced R‚Äù\nJulia: Documentation\nBash: Manual\nGit: Manual, Open source book\n\n\n\nIn the program itself\n\n\nUnderstanding the documentation"
  },
  {
    "objectID": "tools/wb_help_slides.html#up-to-date-versions",
    "href": "tools/wb_help_slides.html#up-to-date-versions",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Up-to-date versions",
    "text": "Up-to-date versions\n\nFirst, you need to know what needs to be updated.\n\n\nKeeping a system up to date includes updating:\n\nthe OS\nthe program\n(any potential IDE)\npackages\n\n\n\nThen, you need to update regularly."
  },
  {
    "objectID": "tools/wb_help_slides.html#google",
    "href": "tools/wb_help_slides.html#google",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Google",
    "text": "Google\nGoogle‚Äôs algorithms are great at guessing what we are looking for.\n\nBut there is a frequency problem:\nSearches relating to programming-specific questions represent too small a fraction of the overall searches for results to be relevant unless you use key vocabulary.\n\n\nBe precise.\n\n\nLearn the vocabulary of your language/tool to know what to search for."
  },
  {
    "objectID": "tools/wb_help_slides.html#open-issues-bug-reports",
    "href": "tools/wb_help_slides.html#open-issues-bug-reports",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Open issues & bug reports",
    "text": "Open issues & bug reports\nIf the tool you are using is open source, look for issues matching your problem in the source repository (e.g.¬†on GitHub or GitLab)."
  },
  {
    "objectID": "tools/wb_help_slides.html#what-if-the-answer-isnt-out-there",
    "href": "tools/wb_help_slides.html#what-if-the-answer-isnt-out-there",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "What if the answer isn‚Äôt out there?",
    "text": "What if the answer isn‚Äôt out there?\nWhen everything has failed & you have to ask for help, you need to know:\n\n\nWhere to ask\n\n\n\n\nHow to ask"
  },
  {
    "objectID": "tools/wb_help_slides.html#where-to-ask-1",
    "href": "tools/wb_help_slides.html#where-to-ask-1",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Where to ask",
    "text": "Where to ask\nQ&A sites\nMostly, Stack Overflow & the Stack Exchange network.\nCo-founded in 2008 & 2009 by Jeff Atwood & Joel Spolsky.\nForums\nMostly, Discourse.\nCo-founded in 2013 by Jeff Atwood, Robin Ward & Sam Saffron.\nA few other older forums."
  },
  {
    "objectID": "tools/wb_help_slides.html#where-to-ask-2",
    "href": "tools/wb_help_slides.html#where-to-ask-2",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Where to ask",
    "text": "Where to ask\nWhich one to choose is a matter of personal preference.\nPossible considerations:\n\nSome niche topics have very active communities on Discourse\nStack Overflow & some older forums can be intimidating with higher expectations for the questions quality & a more direct handling of mistakes\nFor conversations, advice, or multiple step questions, go to Discourse\nStack Overflow has over 13 million users\nStack Overflow & co have a very efficient approach"
  },
  {
    "objectID": "tools/wb_help_slides.html#stack-overflow-co",
    "href": "tools/wb_help_slides.html#stack-overflow-co",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Stack Overflow & co",
    "text": "Stack Overflow & co\nPick the best site to ask your question.\nA few of the Stack Exchange network sites:\nStack Overflow: programming\nSuper User: computer hardware & software\nUnix & Linux: *nix OS TEX: TeX/LaTeX\nCross Validated: stats; data mining, collecting, analysis & visualization; ML\nData Science: focus on implementation & processes\nOpen Data\nGIS"
  },
  {
    "objectID": "tools/wb_help_slides.html#how-to-ask-1",
    "href": "tools/wb_help_slides.html#how-to-ask-1",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "How to ask",
    "text": "How to ask\n\nFamiliarize yourself with the site by reading posts\n\n\nRead the ‚ÄúTour‚Äù page (SO/SE) or take the ‚ÄúNew user tutorial‚Äù (Discourse)\n\n\nMake sure the question has not already been asked\n\n\nFormat the question properly\n\n\nGive a minimum reproducible example\n\n\nDo not share sensitive data\n\n\nShow your attempts\n\n\nAvoid cross-posting. If you really have to, make sure to cross-reference"
  },
  {
    "objectID": "tools/wb_help_slides.html#how-to-ask-so-co",
    "href": "tools/wb_help_slides.html#how-to-ask-so-co",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "How to ask: SO & co",
    "text": "How to ask: SO & co\n\nDon‚Äôt ask opinion-based questions\n\n\nDon‚Äôt ask for package, tool, or service recommendations\n\n\nDon‚Äôt ask more than one question in a single post\n\n\nCheck your spelling, grammar, punctuation, capitalized sentences, etc.\n\n\nAvoid greetings, signatures, thank-yous; keep it to the point\n\n\nAvoid apologies about being a beginner, this being your first post, the question being stupid, etc: do the best you can & skip the personal, self-judgmental & irrelevant bits"
  },
  {
    "objectID": "tools/wb_help_slides.html#formatting-your-question",
    "href": "tools/wb_help_slides.html#formatting-your-question",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Formatting your question",
    "text": "Formatting your question\nNowadays, most sites (including Stack Overflow & Discourse) allow markdown rendering.\nSome older forums implement other markup languages (e.g.¬†BBCode).\nThe information is always easy to find. Spend the time to format your question properly. People will be much less inclined to help you if you don‚Äôt show any effort & if your question is a nightmare to read."
  },
  {
    "objectID": "tools/wb_help_slides.html#example-of-a-typical-downvoted-question",
    "href": "tools/wb_help_slides.html#example-of-a-typical-downvoted-question",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Example of a typical downvoted question",
    "text": "Example of a typical downvoted question\nCode:\nhowdy!!\ni am new to R sorry for a very silly question.i looked all oever the itnernwet, but i dint find\nanyanswer. i tried to use ggplot i get the error: Error in loadNamespace(i, c(lib.loc, .libPaths()),\nversionCheck = vI[[i]]) : there is no package called 'stringi'\nthank youu very much!!!!!\nmarie\nRendered output:"
  },
  {
    "objectID": "tools/wb_help_slides.html#same-question-fixed",
    "href": "tools/wb_help_slides.html#same-question-fixed",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Same question, fixed",
    "text": "Same question, fixed\nWhen I try to load the package `ggplot2` with:\n\n```{r}\nlibrary(ggplot2)\n```\nI get the error:\n\n&gt; Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :\nthere is no package called 'stringi'\n\nWhat am I doing wrong?"
  },
  {
    "objectID": "tools/wb_help_slides.html#still-not-good-enough",
    "href": "tools/wb_help_slides.html#still-not-good-enough",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Still not good enough",
    "text": "Still not good enough\nThis question is actually a duplicate of a question asked which is itself a duplicate of another question."
  },
  {
    "objectID": "tools/wb_help_slides.html#creating-a-minimal-reproducible-example",
    "href": "tools/wb_help_slides.html#creating-a-minimal-reproducible-example",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Creating a minimal reproducible example",
    "text": "Creating a minimal reproducible example\nThere are great posts on how to create a good minimal reproducible example. In particular:\nHow to create a Minimal, Reproducible Example\nFor R (but concepts apply to any language):\nHow to make a great R reproducible example\nWhat‚Äôs a reproducible example (reprex) and how do I do one?"
  },
  {
    "objectID": "tools/wb_help_slides.html#creating-a-minimal-reproducible-example-1",
    "href": "tools/wb_help_slides.html#creating-a-minimal-reproducible-example-1",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Creating a minimal reproducible example",
    "text": "Creating a minimal reproducible example\n\nLoad all necessary packages\nLoad or create necessary data\nSimplify the data & the code as much as possible while still reproducing the problem\nUse simple variable names"
  },
  {
    "objectID": "tools/wb_help_slides.html#data-for-your-example-your-own-data",
    "href": "tools/wb_help_slides.html#data-for-your-example-your-own-data",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Data for your example: your own data",
    "text": "Data for your example: your own data\nDo not upload data somewhere on the web to be downloaded.\nMake sure that the data is anonymised.\nDon‚Äôt keep more variables & more data points than are necessary to reproduce the problem.\nSimplify the variable names.\nIn R, you can use functions such as dput() to turn your reduced, anonymised data into text that is easy to copy/paste & can then be used to recreate the data."
  },
  {
    "objectID": "tools/wb_help_slides.html#data-for-your-example-create-a-toy-dataset",
    "href": "tools/wb_help_slides.html#data-for-your-example-create-a-toy-dataset",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Data for your example: create a toy dataset",
    "text": "Data for your example: create a toy dataset\nYou can also create a toy dataset.\nFunctions that create random data, series, or repetitions are very useful here."
  },
  {
    "objectID": "tools/wb_help_slides.html#data-for-your-example-pre-packaged-datasets",
    "href": "tools/wb_help_slides.html#data-for-your-example-pre-packaged-datasets",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Data for your example: pre-packaged datasets",
    "text": "Data for your example: pre-packaged datasets\nSome languages/packages come with pre-packaged datasets. If your code involves such languages/packages, you can make use of these datasets to create your reproducible example.\nFor example, R comes with many datasets directly available, including iris, mtcars, trees, airquality. In the R console, try:\n?iris\n?mtcars"
  },
  {
    "objectID": "tools/wb_help_slides.html#additional-considerations",
    "href": "tools/wb_help_slides.html#additional-considerations",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Additional considerations",
    "text": "Additional considerations\nEven if you always find answers to your questions without having to post yourself, consider signing up to these sites:\n\nIt allows you to upvote (SO/SE) or like (Discourse) the questions & answers that help you‚Äîand why not thank in this fashion those that are making your life easier?\nIt makes you a part of these communities.\nOnce you are signed up, maybe you will start being more involved & contribute with questions & answers of your own."
  },
  {
    "objectID": "tools/wb_help_slides.html#a-last-word",
    "href": "tools/wb_help_slides.html#a-last-word",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "A last word",
    "text": "A last word\nWhile it takes some work to ask a good question, do not let this discourage you from posting on Stack Overflow: if you ask a good question, you will get many great answers.\nYou will learn in the process of developing your question (you may actually find the answer in that process) & you will learn from the answers.\nIt is forth the effort.\nHere is the Stack Overflow documentation on how to ask a good question."
  },
  {
    "objectID": "tools/wb_help.html",
    "href": "tools/wb_help.html",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "",
    "text": "Stack Overflow, Stack Exchange, Discourse forums, and other online platforms ‚Ä¶ the internet is a treasure trove of online communities where you can find solutions to your coding problems. To have a positive experience and get the answers you need however, you have to know where to ask, how to ask, and when not to ask: if countless people are willing to give you their time for free, they usually expect that you do your part.\nIn this webinar, I will present key online sites, their functioning, and their culture; then I will go over the magic trick to get answers to your questions: knowing how to create minimum reproducible examples. I will not focus on any particular language as the principles (how to create a minimal dataset, how to deal with private data, how to create self-sufficient code, how to reproduce the problem, etc.) can apply to any language.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Getting help online"
    ]
  },
  {
    "objectID": "tools/wb_dvc_content.html",
    "href": "tools/wb_dvc_content.html",
    "title": "Version control for data science & machine learning with DVC",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Data version control with DVC",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_dvc_content.html#on-version-control",
    "href": "tools/wb_dvc_content.html#on-version-control",
    "title": "Version control for data science & machine learning with DVC",
    "section": "On version control",
    "text": "On version control\nI won‚Äôt introduce here the benefits of using a good version control system such as Git.\n\n\n\nOn the benefits of VCS\n\n\n\nExtending Git for data\nWhile Git is a wonderful tool for text files versioning (code, writings in markup formats), it isn‚Äôt a tool to manage changes to datasets.\nSeveral open source tools‚Äîeach with a different structure and functioning‚Äîextend Git capabilities to track data: Git LFS, git-annex, lakeFS, Dolt, DataLad.\n\n\nGit for models and experiments\nReproducible research and collaboration on data science and machine learning projects involve more than datasets management:\nExperiments and the models they produce also need to be tracked.\n\n\nMany moving parts\n\n*hp = hyperparameter\n\n\n\n\n\n\n\n\n\n\ndata1\n\ndata1\n\n\n\nmodel1\n\nmodel1\n\n\n\ndata1-&gt;model1\n\n\n\n\n\nmodel2\n\nmodel2\n\n\n\ndata1-&gt;model2\n\n\n\n\n\nmodel3\n\nmodel3\n\n\n\ndata1-&gt;model3\n\n\n\n\n\ndata2\n\ndata2\n\n\n\ndata2-&gt;model1\n\n\n\n\n\ndata2-&gt;model2\n\n\n\n\n\ndata2-&gt;model3\n\n\n\n\n\ndata3\n\ndata3\n\n\n\ndata3-&gt;model1\n\n\n\n\n\ndata3-&gt;model2\n\n\n\n\n\ndata3-&gt;model3\n\n\n\n\n\nhp1\n\nhp1\n\n\n\nhp1-&gt;model1\n\n\n\n\n\nhp1-&gt;model2\n\n\n\n\n\nhp1-&gt;model3\n\n\n\n\n\nhp2\n\nhp2\n\n\n\nhp2-&gt;model1\n\n\n\n\n\nhp2-&gt;model2\n\n\n\n\n\nhp2-&gt;model3\n\n\n\n\n\nhp3\n\nhp3\n\n\n\nhp3-&gt;model1\n\n\n\n\n\nhp3-&gt;model2\n\n\n\n\n\nhp3-&gt;model3\n\n\n\n\n\nperformance\n\nperformance1 ... performance27\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\n\n\n\n\n\nHow did we get performance17 again? ü§Ø",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Data version control with DVC",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_dvc_content.html#enters-dvc",
    "href": "tools/wb_dvc_content.html#enters-dvc",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Enters DVC",
    "text": "Enters DVC\n\nDVC principles\n\nLarge files (datasets, models‚Ä¶) are kept outside Git.\nEach large file or directory put under DVC tracking has an associated .dvc file.\nGit only tracks the .dvc files (metadata).\n\nWorkflows can be tracked for collaboration and reproducibility.\nDVC functions as a Makefile and allows to only rerun what is necessary.\n\n\nInstallation\nFor Linux (other OSes, refer to the doc):\n\npip:\npip install dvc\nconda\npipx (if you want dvc available everywhere without having to activate virtual envs):\npipx install dvc\n\n\nOptional dependencies [s3], [gdrive], etc. for remote storage.\n\n\n\nHow to run\nMultiple options:\n\nTerminal:\ndvc ...\nVS Code extension\nPython library if installed via pip or conda:\nimport dvc.api\n\n\nIn this webinar, I will use DVC through the command line.\n\n\n\nAcknowledgements\nCode and data for this webinar modified from:\n\nReal Python\nDataLad handbook\nDVC documentation\n\n\n\nThe project\ntree -L 3\n‚îú‚îÄ‚îÄ LICENSE\n‚îú‚îÄ‚îÄ data\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ prepared\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ raw\n‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ train\n‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ val\n‚îú‚îÄ‚îÄ metrics\n‚îú‚îÄ‚îÄ model\n‚îú‚îÄ‚îÄ requirements.txt\n‚îî‚îÄ‚îÄ src\n    ‚îú‚îÄ‚îÄ evaluate.py\n    ‚îú‚îÄ‚îÄ prepare.py\n    ‚îî‚îÄ‚îÄ train.py\n\n\nInitialize Git repo\ngit init\nInitialized empty Git repository in dvc/.git/\nThis creates the .git directory.\ngit status\nOn branch main\n\nNo commits yet\n\nUntracked files:\n    LICENSE\n    data/\n    requirements.txt\n    src/\n\n\nInitialize DVC project\ndvc init\nInitialized DVC repository.\n\nYou can now commit the changes to git.\n\nYou will also see a note about usage analytics collection and info on how to opt out.\n\nA .dvc directory and a .dvcignore file got created.\n\n\nCommit DVC system files\nDVC automatically staged its system file for us:\ngit status\nOn branch main\n\nNo commits yet\n\nChanges to be committed:\n    new file:   .dvc/.gitignore\n    new file:   .dvc/config\n    new file:   .dvcignore\n\nUntracked files:\n    LICENSE\n    data/\n    requirements.txt\n    src/\nSo we can directly commit:\ngit commit -m \"Initialize DVC\"\n\n\nPrepare repo\nLet‚Äôs work in a virtual environment:\n# Create venv and add to .gitignore\npython -m venv venv && echo venv &gt; .gitignore\n\n# Activate venv\nsource venv/bin/activate\n\n# Update pip\npython -m pip install --upgrade pip\n\n# Install packages needed\npython -m pip install -r requirements.txt\n\n\nClean working tree\ngit add .gitignore LICENSE requirements.txt\ngit commit -m \"Add general files\"\ngit add src\ngit commit -m \"Add scripts\"\ngit status\nOn branch main\nUntracked files:\n    data/\n\nNow, it is time to deal with the data.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Data version control with DVC",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_dvc_content.html#tracking-data-with-dvc",
    "href": "tools/wb_dvc_content.html#tracking-data-with-dvc",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Tracking data with DVC",
    "text": "Tracking data with DVC\n\nPut data under DVC tracking\nWe are still not tracking any data:\ndvc status\nThere are no data or pipelines tracked in this project yet.\nYou can choose what to track as a unit (i.e.¬†each picture individually, the whole data directory as a unit).\nLet‚Äôs break it down by set:\ndvc add data/raw/train\ndvc add data/raw/val\nThis adds data to .dvc/cache/files and created 3 files in data/raw:\n\n.gitignore\ntrain.dvc\nval.dvc\n\nThe .gitignore tells Git not to track the data:\ncat data/raw/.gitignore\n/train\n/val\nThe .dvc files contain the metadata for the cached directories.\n\n\nTracked data\nWe are all good:\ndvc status\nData and pipelines are up to date.\n\n\nData (de)duplication\nLink between checked-out version of a file/directory and the cache:\n\n\n\n\n\n\n\n\n\nDuplication\nEditable\n\n\n\n\nReflinks*\nOnly when needed\nYes\n\n\nHardlinks/Symlinks\nNo\nNo\n\n\nCopies\nYes\nYes\n\n\n\n\n*Reflinks only available for a few file systems (Btrfs, XFS, OCFS2, or APFS).\n\n\n\nCommit the metafiles\nThe metafiles should be put under Git version control.\n\nYou can configure DVC to automatically stage its newly created system files:\ndvc config [--system] [--global] core.autostage true\n\nYou can then commit directly:\ngit commit -m \"Initial version of data\"\ngit status\nOn branch main\nnothing to commit, working tree clean\n\n\nTrack changes to the data\nLet‚Äôs make some change to the data:\nrm data/raw/val/n03445777/ILSVRC2012_val*\nRemember that Git is not tracking the data:\ngit status\nOn branch main\nnothing to commit, working tree clean\nBut DVC is:\ndvc status\ndata/raw/val.dvc:\n    changed outs:\n            modified:           data/raw/val\n\n\nAdd changes to DVC\ndvc add data/raw/val\ndvc status\nData and pipelines are up to date.\nNow we need to commit the changes to the .dvc file to Git:\ngit status\nOn branch main\nChanges to be committed:\n    modified:   data/raw/val.dvc\n\nStaging happened automatically because I have set the autostage option to true on my system.\n\ngit commit -m \"Delete data/raw/val/n03445777/ILSVRC2012_val*\"\n\n\nCheck out older versions\nWhat if we want to go back to the 1st version of our data?\nFor this, we first use Git to checkout the proper commit, then run dvc checkout to have the data catch up to the .dvc file.\nTo avoid forgetting to run the commands that will make DVC catch up to Git, we can automate this process by installing Git hooks:\ndvc install\n\nNow, all we have to do is to checkout the commit we want:\ngit log --oneline\n94b520b (HEAD -&gt; main) Delete data/raw/val/n03445777/ILSVRC2012_val*\n92837a6 Initial version of data\ndd961c6 Add scripts\ndb9c14e Initialize repo\n7e08586 Initialize DVC\ngit checkout 92837a6\nThe version of the data in the working directory got automatically switched to match the .dvc file:\ndvc status\nData and pipelines are up to date.\nYou can look at your files to verify that the deleted files are back.\n\n\nGit workflows\ngit checkout is ok to have a look, but a detached HEAD is not a good place to create new commits.\nLet‚Äôs create a new branch and switch to it:\ngit switch -c alternative\nSwitched to a new branch 'alternative'\nGoing back and forth between both versions of our data is now as simple as switching branch:\ngit switch main\ngit switch alternative",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Data version control with DVC",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_dvc_content.html#collaboration",
    "href": "tools/wb_dvc_content.html#collaboration",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Collaboration",
    "text": "Collaboration\n\nClassic workflow\nThe Git project (including .dvc files) go to a Git remote (GitHub/GitLab/Bitbucket/server).\nThe data go to a DVC remote (AWS/Azure/Google Drive/server/etc.).\n\n\nDVC remotes\nDVC can use many cloud storage or remote machines/server via SSH, WebDAV, etc.\nLet‚Äôs create a local remote here:\n# Create a directory outside the project\nmkdir ../remote\n\n# Setup default (-d) remote\ndvc remote add -d local_remote ../remote\nSetting 'local_remote' as a default remote.\ncat .dvc/config\n[core]\n    remote = local_remote\n['remote \"local_remote\"']\n    url = ../../remote\n\n\nCommit remote config\nThe new remote configuration should be committed:\ngit status\nOn branch alternative\n\nChanges not staged for commit:\n    modified:   .dvc/config\ngit add .\ngit commit -m \"Config remote\"\n\n\nPush to remotes\nLet‚Äôs push the data from the cache (.dvc/cache) to the remote:\ndvc push\n2702 files pushed\n\nWith Git hooks installed, dvc push is automatically run after git push.\n(But the data is pushed to the DVC remote while the files tracked by Git get pushed to the Git remote).\n\nBy default, the entire data cache gets pushed to the remote, but there are many options.\n\nExample: only push data corresponding to a certain .dvc files.\ndvc push data/raw/val.dvc\n\n\n\nPull from remotes\ndvc fetch downloads data from the remote into the cache. To have it update the working directory, follow by dvc checkout.\nYou can do these 2 commands at the same time with dvc pull.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Data version control with DVC",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_dvc_content.html#tracking-experiments",
    "href": "tools/wb_dvc_content.html#tracking-experiments",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Tracking experiments",
    "text": "Tracking experiments\n\nDVC pipelines\nDVC pipelines create reproducible workflows and are functionally similar to Makefiles.\nEach step in a pipeline is created with dvc stage add and add an entry to a dvc.yaml file.\n\ndvc stage add options:\n-n: name of stage\n-d: dependency\n-o: output\n\nEach stage contains:\n\ncmd: the command executed\ndeps: the dependencies\nouts: the outputs\n\nThe file is then used to visualize the pipeline and run it.\n\n\nExample\nLet‚Äôs create a pipeline to run a classifier on our data.\nThe pipeline contains 3 steps:\n\nprepare\ntrain\nevaluate\n\n\n\nCreate a pipeline\n\n1st stage (data preparation)\ndvc stage add -n prepare -d src/prepare.py -d data/raw \\\n    -o data/prepared/train.csv -o data/prepared/test.csv \\\n    python src/prepare.py\nAdded stage 'prepare' in 'dvc.yaml'\n\n\n2nd stage (training)\ndvc stage add -n train -d src/train.py -d data/prepared/train.csv \\\n    -o model/model.joblib \\\n    python src/train.py\nAdded stage `train` in 'dvc.yaml'\n\n\n3rd stage (evaluation)\ndvc stage add -n evaluate -d src/evaluate.py -d model/model.joblib \\\n    -M metrics/accuracy.json \\\n    python src/evaluate.py\nAdded stage `evaluate` in 'dvc.yaml'\n\n\n\nCommit pipeline\ngit commit -m \"Define pipeline\"\nprepare:\n    changed deps:\n            modified:           data/raw\n            modified:           src/prepare.py\n    changed outs:\n            deleted:            data/prepared/test.csv\n            deleted:            data/prepared/train.csv\ntrain:\n    changed deps:\n            deleted:            data/prepared/train.csv\n            modified:           src/train.py\n    changed outs:\n            deleted:            model/model.joblib\nevaluate:\n    changed deps:\n            deleted:            model/model.joblib\n            modified:           src/evaluate.py\n    changed outs:\n            deleted:            metrics/accuracy.json\n[main 4aa331b] Define pipeline\n 3 files changed, 27 insertions(+)\n create mode 100644 data/prepared/.gitignore\n create mode 100644 dvc.yaml\n create mode 100644 model/.gitignore\n\n\nVisualize pipeline in a DAG\ndvc dag\n+--------------------+         +------------------+\n| data/raw/train.dvc |         | data/raw/val.dvc |\n+--------------------+         +------------------+\n                  ***           ***\n                     **       **\n                       **   **\n                    +---------+\n                    | prepare |\n                    +---------+\n                          *\n                          *\n                          *\n                      +-------+\n                      | train |\n                      +-------+\n                          *\n                          *\n                          *\n                    +----------+\n                    | evaluate |\n                    +----------+\n\n\nRun pipeline\ndvc repro\n'data/raw/train.dvc' didn't change, skipping\n'data/raw/val.dvc' didn't change, skipping\nRunning stage 'prepare':\n&gt; python src/prepare.py\nGenerating lock file 'dvc.lock'\nUpdating lock file 'dvc.lock'\n\nRunning stage 'train':\n&gt; python src/train.py\nUpdating lock file 'dvc.lock'\n\nRunning stage 'evaluate':\n&gt; python src/evaluate.py\nUpdating lock file 'dvc.lock'\nUse `dvc push` to send your updates to remote storage.\n\n\ndvc repro breakdown\n\ndvc repro runs the dvc.yaml file in a Makefile fashion.\nFirst, it looks at the dependencies: the data didn‚Äôt change.\nThen it ran the commands to produce the outputs (since it is our first run, we had no outputs).\nWhen the 1st stage is run, a dvc.lock is created with information on that part of the run.\nWhen the 2nd and 3rd stages are run, dvc.lock is updated. At the end of the run dvc.lock contains all the info about the run we just did (version of the data used, etc.).\nA new directory called runs is created in .dvc/cache with cached data for this run.\n\n\n\nResults of the run\n\nThe prepared data was created in data/prepared (with a .gitignore to exclude it from Git‚Äîyou don‚Äôt want to track results in Git, but the scripts that can reproduce them).\nA model was saved in model (with another .gitignore file).\nThe accuracy of this run was created in metrics.\n\n\n\nClean working tree\nNow, we definitely want to create a commit with the dvc.lock.\nWe could add the metrics resulting from this run in the same commit:\ngit add metrics\ngit commit -m \"First pipeline run and results\"\nOur working tree is now clean and our data/pipeline up to date:\ngit status\nOn branch alternative\nnothing to commit, working tree clean\ndvc status\nData and pipelines are up to date.\n\n\nModify pipeline\nFrom now on, if we edit one of the scripts, or one of the dependencies, dvc status will tell us what changed and dvc repro will only rerun the parts of the pipeline to update the result, pretty much as a Makefile would.\n\n\nGoing further ‚Ä¶ next time\nDVC is a sophisticated tool with many additional features:\n\nCreation of data registries\nDVCLive (Python library to log experiment metrics).\nVisualize the performance logs as plots.\nContinuous integration with CML (Continuous Machine Learning).",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Data version control with DVC",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/top_wb.html",
    "href": "tools/top_wb.html",
    "title": "Tools webinars",
    "section": "",
    "text": "Next gen Python  ¬†notebooks\n\n\n\n\nypst: a new typesetting system\n\n\n\n\n: the new R Markdown\n\n\n\n\nA great Git UI: Lazygit\n\n\n\n\n\n\nuv package manager\n\n\n\n\nData version control with\n\n\n\n\nFun tools for the command line\n\n\n\n\nMore command line tools\n\n\n\n\n\n\nModern shell utilities\n\n\n\n\nGetting online help & asking questions",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>"
    ]
  },
  {
    "objectID": "talks/index.html",
    "href": "talks/index.html",
    "title": "Talks",
    "section": "",
    "text": "Advanced research instruments\nDRI (Digital Research Infrastructure) Connect\n\n\n\n\nCreating training material with Quarto\nAlliance Staff To Staff Webinar Series\n\n\n\n\n\n\nBig data in the agrotech industry\nAgricultural Excellence Conference\n\n\n\n\nCommunication to researchers\nDRI (Digital Research Infrastructure) Connect\n\n\n\n\n\n\nPython for the humanities\nDigital Humanities Summer Institute (DHSI)\n\n\n\n\nCoding fundamentals for humanists\nDigital Humanities Summer Institute (DHSI)\n\n\n\n\n\n\nTeaching programming with LLMs\nHSS National Team Meeting",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>"
    ]
  },
  {
    "objectID": "talks/dhsi_content.html",
    "href": "talks/dhsi_content.html",
    "title": "Coding fundamentals for humanists",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Coding fundamentals",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/dhsi_content.html#the-course",
    "href": "talks/dhsi_content.html#the-course",
    "title": "Coding fundamentals for humanists",
    "section": "The course",
    "text": "The course\n\nGoal\n\n\n\n\nDemystify coding\n\n\n\n\nGive you confidence\n\n\n\n\n\nExplain foundational concepts\n\n\n\n\nGive you tools for your research\n\n\n\n\n\n\nWho should attend?\nAnyone without any coding experience who would like to use coding for their research or who is interested in understanding what coding is and how it works\nThis course is particularly useful as a prerequisite to other DHSI courses using Python\n\n\nOverview\n\n\n\n\nCore concepts of programming languages\n\n\n\n\nIntroduction to JupyterLab\n\n\n\n\nBasics of Python\n\n\n\n\nUsing LLMs to write code\n\n\n\n\n\n\n\nAPI querying in Python\n\n\n\n\nWeb scraping with Python\n\n\n\n\nYour turn: get data from a website\n\n\n\n\nPresentations: share what you learnt",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Coding fundamentals",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/dhsi_content.html#in-practice",
    "href": "talks/dhsi_content.html#in-practice",
    "title": "Coding fundamentals for humanists",
    "section": "In practice",
    "text": "In practice\n\nWebsite\n\n\n Each year we build a website\nEasier for attendees to follow along, copy code snippets, etc.\nThe sites never get taken down so attendees can rely on them to find information later on\n\n\n\n\n\n\n\n\n\nPresentation\nWe start the course with a presentation explaining the concepts\n\n\n\n\nHands-on\n\n\n Then move to hands-on\n\n\n\n\n\n\n\n\n\nJupyterLab\n\n\n We use the free and open-source JupyterLab as an interface to Python to make it easier to play with code\n\n\n\n\n\n\n\n\n\nWe write the Jupyter notebooks in advance\n\nExample of notebook you will download:\n\n\n\n\nAnd we let you fill-in the code\n\nExample of completed notebook:\n\n\n\n\nGuidance on using LLMs\nWhen used well, large language models can allow students:\n\nTo be much more independent\nNot to get frustrated over small road-blocks\nTo go much further faster\nTo keep learning on their own\nTo be able to apply Python to their research\n\nWe will show you what works and what doesn‚Äôt when using LLMs to write code",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Coding fundamentals",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/dhsi_content.html#what-you-will-be-able-to-do",
    "href": "talks/dhsi_content.html#what-you-will-be-able-to-do",
    "title": "Coding fundamentals for humanists",
    "section": "What you will be able to do",
    "text": "What you will be able to do\n\nEnd of course projects\nAt the end of the course, attendees work in pairs on a project of their choice (which can be their own research) with our help\nFollowing are samples of data our past students successfully scraped from various websites\n\n\nGuardian archives\n\n\n\nSpotify playlist\n\n\n\nNumbers of published books\n\n\n\n\n\n\n\n\n\n\n\nReddit data\n\n\n\nExported as a Python list:\n\n\n\n\n\n\nExported as a Python polars data frame:",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Coding fundamentals",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2025_teaching_with_llm_slides.html#one-week-is-too-little-to-teach-python-to-beginners",
    "href": "talks/2025_teaching_with_llm_slides.html#one-week-is-too-little-to-teach-python-to-beginners",
    "title": "Teaching programming to beginners with LLMs",
    "section": "One week is too little to teach Python to beginners",
    "text": "One week is too little to teach Python to beginners\nUsing LLMs is the only realistic way to bring them to a place where they can apply knowledge to their research"
  },
  {
    "objectID": "talks/2025_teaching_with_llm_slides.html#students-get-frustrated-by-failures",
    "href": "talks/2025_teaching_with_llm_slides.html#students-get-frustrated-by-failures",
    "title": "Teaching programming to beginners with LLMs",
    "section": "Students get frustrated by failures",
    "text": "Students get frustrated by failures\nThey want to make progress on something meaningful\nSpending hours debugging error messages about some obscure detail of their code makes them angry and discouraged"
  },
  {
    "objectID": "talks/2025_teaching_with_llm_slides.html#llms-seemed-like-the-perfect-answer-for-this-audience",
    "href": "talks/2025_teaching_with_llm_slides.html#llms-seemed-like-the-perfect-answer-for-this-audience",
    "title": "Teaching programming to beginners with LLMs",
    "section": "LLMs seemed like the perfect answer for this audience",
    "text": "LLMs seemed like the perfect answer for this audience\nThis is definitely the future\nLLMs can take care of the nitty gritty aspects of the code for them while they focus on the higher level they are interested in"
  },
  {
    "objectID": "talks/2025_teaching_with_llm_slides.html#course-intro",
    "href": "talks/2025_teaching_with_llm_slides.html#course-intro",
    "title": "Teaching programming to beginners with LLMs",
    "section": "Course intro",
    "text": "Course intro\nThe course started the same way as the traditional course:\n\nHigh-level intro to programming\nHow to choose a language (FOSS vs proprietary, compiled vs interpreted, etc.)\nHigh-level intro to Python\nTools needed for programming (text editor, IDE, etc.)\nIntro to Python shell, IPython, Jupyter, scripts\nIntro to general concepts (packages, syntax, data types, variables, functions, etc.)"
  },
  {
    "objectID": "talks/2025_teaching_with_llm_slides.html#intro-to-llms",
    "href": "talks/2025_teaching_with_llm_slides.html#intro-to-llms",
    "title": "Teaching programming to beginners with LLMs",
    "section": "Intro to LLMs",
    "text": "Intro to LLMs"
  },
  {
    "objectID": "talks/2025_teaching_with_llm_slides.html#first-play-with-text",
    "href": "talks/2025_teaching_with_llm_slides.html#first-play-with-text",
    "title": "Teaching programming to beginners with LLMs",
    "section": "First play with text",
    "text": "First play with text\n\n\nTraditional approach (e.g.¬†2024)\n\n\n\nLLM experiment (2025)"
  },
  {
    "objectID": "talks/2025_teaching_with_llm_slides.html#web-scraping",
    "href": "talks/2025_teaching_with_llm_slides.html#web-scraping",
    "title": "Teaching programming to beginners with LLMs",
    "section": "Web scraping",
    "text": "Web scraping\n\n\nTraditional approach (e.g.¬†2024)\n\n\n\nLLM experiment (2025)"
  },
  {
    "objectID": "talks/2025_teaching_with_llm_slides.html#society-is-changing-fast",
    "href": "talks/2025_teaching_with_llm_slides.html#society-is-changing-fast",
    "title": "Teaching programming to beginners with LLMs",
    "section": "Society is changing fast",
    "text": "Society is changing fast\n2024\nAll I could hear at DHSI was opposition to AI\n\nIssues with copyright (valid point!)\nArtists having their work stolen\nAI being bad and wrong and evil and to be avoided at all cost"
  },
  {
    "objectID": "talks/2025_teaching_with_llm_slides.html#society-is-changing-fast-1",
    "href": "talks/2025_teaching_with_llm_slides.html#society-is-changing-fast-1",
    "title": "Teaching programming to beginners with LLMs",
    "section": "Society is changing fast",
    "text": "Society is changing fast\n2025\nI came prepared to convince them that, despite the (absolutely real) downsides, they have to learn to use LLMs if they don‚Äôt want to fall behind and be at a disadvantage"
  },
  {
    "objectID": "talks/2025_teaching_with_llm_slides.html#society-is-changing-fast-2",
    "href": "talks/2025_teaching_with_llm_slides.html#society-is-changing-fast-2",
    "title": "Teaching programming to beginners with LLMs",
    "section": "Society is changing fast",
    "text": "Society is changing fast\n2025\nWhat I found‚Ä¶\nEverybody was way more comfortable than I was using LLMs\nEverybody had a subscription\n(and everybody was perplexed by my reassuring lecture on the usefulness of LLMs ‚Ä¶)"
  },
  {
    "objectID": "talks/2025_teaching_with_llm_slides.html#society-is-changing-fast-3",
    "href": "talks/2025_teaching_with_llm_slides.html#society-is-changing-fast-3",
    "title": "Teaching programming to beginners with LLMs",
    "section": "Society is changing fast",
    "text": "Society is changing fast\nOne year is a very long time at the moment\nI was aware that we need to keep up with\n\nthe technology (that‚Äôs feasible)\nthe regulations (easy for now!)\n\nBut I hadn‚Äôt anticipated that we also need to keep up with societal change"
  },
  {
    "objectID": "talks/2025_teaching_with_llm_slides.html#what-did-they-think",
    "href": "talks/2025_teaching_with_llm_slides.html#what-did-they-think",
    "title": "Teaching programming to beginners with LLMs",
    "section": "What did they think?",
    "text": "What did they think?\nExit surveys had several positive comments about the use of LLMs\nOne attendee pointed out however that they don‚Äôt need us to use an LLM and that there was no point going to a course if that is what we were doing (good point‚Ä¶)"
  },
  {
    "objectID": "talks/2025_teaching_with_llm_slides.html#will-i-do-it-again",
    "href": "talks/2025_teaching_with_llm_slides.html#will-i-do-it-again",
    "title": "Teaching programming to beginners with LLMs",
    "section": "Will I do it again?",
    "text": "Will I do it again?\n\nNo\n\n\nIt is too messy in the context of a classroom:\nEverybody goes down their own rabbit hole with their own LLM\n\n\nLLMs are amazing private tutors but their non-deterministic nature makes them impossible to use in the way I envisaged\n\n\nThe only way not to have it feel like I am herding squirrels is if I am the only one using an LLM while they passively watch"
  },
  {
    "objectID": "talks/2025_teaching_with_llm_slides.html#section-3",
    "href": "talks/2025_teaching_with_llm_slides.html#section-3",
    "title": "Teaching programming to beginners with LLMs",
    "section": "",
    "text": "Teaching them to use LLMs is silly: they know!\n\nBut now LLMs can teach them everything we can\n\n\nSo then the question becomes ‚Ä¶"
  },
  {
    "objectID": "talks/2025_teaching_with_llm_slides.html#have-we-become-irrelevant",
    "href": "talks/2025_teaching_with_llm_slides.html#have-we-become-irrelevant",
    "title": "Teaching programming to beginners with LLMs",
    "section": "Have we become irrelevant?",
    "text": "Have we become irrelevant?\n\n\nMaybe not yet\nOne attendee had fantastic suggestions in their feedback form\nWe could:\n\nCurate a dataset\nHave them do a more structured and simpler project in this artificially created world"
  },
  {
    "objectID": "talks/2025_teaching_with_llm_slides.html#we-need-to-start-teaching-differently",
    "href": "talks/2025_teaching_with_llm_slides.html#we-need-to-start-teaching-differently",
    "title": "Teaching programming to beginners with LLMs",
    "section": "We need to start teaching differently",
    "text": "We need to start teaching differently\n\n\nWe need to go beyond simple teaching if we want to remain relevant\nOrganizing a course experience that goes beyond knowledge delivery could be an answer\n(There is more than a hint of unconvinced wishful thinking in all this though ‚Ä¶)"
  },
  {
    "objectID": "talks/2025_teaching_with_llm_slides.html#llms-can-help-us-be-better-instructors",
    "href": "talks/2025_teaching_with_llm_slides.html#llms-can-help-us-be-better-instructors",
    "title": "Teaching programming to beginners with LLMs",
    "section": "LLMs can help us be better instructors",
    "text": "LLMs can help us be better instructors\n\nfrom https://www.nature.com/articles/s41539-025-00300-x"
  },
  {
    "objectID": "talks/2025_teaching_with_llm_slides.html#conclusions",
    "href": "talks/2025_teaching_with_llm_slides.html#conclusions",
    "title": "Teaching programming to beginners with LLMs",
    "section": "Conclusions",
    "text": "Conclusions\nIt is probably best to leave LLMs out of the classroom\nBut we need to realize that all students are using them (probably more than us)\nSo as not to become irrelevant, we need to adapt and offer fancy interactive curated courses, not just content delivery\nLLMs can help us with that since they can create synthetic datasets, come up with exercises, give us ideas, provide feedback, etc."
  },
  {
    "objectID": "talks/2025_teaching_with_llm_slides.html#epilogue",
    "href": "talks/2025_teaching_with_llm_slides.html#epilogue",
    "title": "Teaching programming to beginners with LLMs",
    "section": "Epilogue",
    "text": "Epilogue\nAnd then came Gemini 3 and Claude Opus 4.5 ‚Ä¶"
  },
  {
    "objectID": "talks/2025_teaching_with_llm.html",
    "href": "talks/2025_teaching_with_llm.html",
    "title": "Teaching programming with LLMs",
    "section": "",
    "text": "Presented at the HSS National Team Meeting in December 2025.\n\nOver the past five years, an instructor from ACENET and I have been teaching a week-long course called ‚ÄúCoding fundamentals for humanists‚Äù at the digital humanities summer institute (DHSI). The course is an introduction to coding concepts using Python as an example to humanities professors, deans, graduate students, and librarians with no programming experience. The goal is to demystify the topic and remove any apprehension at the idea of coding as well as to provide concrete applications useful in the field of social sciences.\nIn 2025, I decided to do things very differently and teach my section of the course using large language models (LLMs).\nIn this talk, I am presenting my motivation for doing so, how I went about it, what worked and what didn‚Äôt, and what I learnt in the process.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.)\nSlides content for easier browsing.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Teaching coding with LLMs"
    ]
  },
  {
    "objectID": "talks/2025_driconnect_content.html",
    "href": "talks/2025_driconnect_content.html",
    "title": "Communication to the research community",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "On communication",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2025_driconnect_content.html#topics",
    "href": "talks/2025_driconnect_content.html#topics",
    "title": "Communication to the research community",
    "section": "Topics",
    "text": "Topics\n\nAlliance website\nAlliance newsletter\nTraining emails",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "On communication",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2025_driconnect_content.html#alliance-website",
    "href": "talks/2025_driconnect_content.html#alliance-website",
    "title": "Communication to the research community",
    "section": "Alliance website",
    "text": "Alliance website\n\n2 buttons on the front page leading to 2 sub-websites\n\n\nStakeholders, click here\n\n\n\nResearchers, click here\n\n\n\n\n‚Ü™ Current site\n\n\n\n‚Ü™ Site with practical info for researchers:\n\nStatus of clusters\nLink to wiki\nHow to open tickets\nLink to training platform\nAnnouncements of upcoming training\n\n\n\nMy arguments:\nIt would make the information researchers need easy to find\n2 distinct audiences with different expectations vis-√†-vis the Alliance ¬†‚û° ¬†2 sub-websites\n\nDo you find this idea worthwhile?\nAre there reasons not to implement something along those lines?\nWho would be a good contact to pursue this idea?\nCould we make plans?",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "On communication",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2025_driconnect_content.html#alliance-newsletter",
    "href": "talks/2025_driconnect_content.html#alliance-newsletter",
    "title": "Communication to the research community",
    "section": "Alliance newsletter",
    "text": "Alliance newsletter\n\n2 different newsletters for 2 different audiences\n\n\n\nStakeholders‚Äô newsletter\nCurrent content\n(minus recent additions about training)\n\n\n\n\n\nResearchers‚Äô newsletter\n\nStatus of clusters\nLink to wiki\nHow to open tickets\nLink to training platform\nAnnouncements of upcoming training\n\n\n\n\n\n\n2 different newsletters for 2 different audiences\nMy argument: same thing!\nStake holders want to see that the Alliance is great, productive, and involved in transformative computing\nResearchers want practical information that can be useful to them\n\nDo you find this idea worthwhile?\nAre there reasons not to implement something along those lines?\nWho would be a good contact to pursue this idea?\nCould we make plans?",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "On communication",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2025_driconnect_content.html#training-emails",
    "href": "talks/2025_driconnect_content.html#training-emails",
    "title": "Communication to the research community",
    "section": "Training emails",
    "text": "Training emails\n\nThe problem\n\nMost researchers do not know about the services that we are offering\nWe do not have ways to reach out to them to inform them\n\nExplora is here and will help a lot! ü•≥\nBut it won‚Äôt solve everything:\n\nUsers will need to be informed and reminded that Explora exists\nSome users might prefer to get emails about upcoming training events\n\n\n\nMailing list access\nWe teach and help all Canadian academic researchers‚Äînot just Alliance clusters users\nThey are however our main target audience\nBeing allowed to email CCDB users to inform them of our services (with option to opt-out) would be a great solution\n\n\nEthics\nResponsible management is of course paramount and we would:\n\nstrictly respect opt-out requests\nstore data securely\nrespect privacy\nabide by anti-spamming laws\n\n\n\nAlternative solution\nAn alternative solution would be for an Alliance personnel to send emails on our behalf to advertise our events\nThis seems impractical and add to the work load of the Alliance but remains an option\n\n\nThoughts and discussion\nAre the concerns around allowing us to use CCDB emails about:\n\nprivacy?\ndata safety?\nspamming laws?\nother?\nIs there anything we could do to alleviate these concerns?\nWho would be a good contact to pursue this conversation?",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "On communication",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2025_driconnect_content.html#thank-you-for-joining-me-in-this-discussion",
    "href": "talks/2025_driconnect_content.html#thank-you-for-joining-me-in-this-discussion",
    "title": "Communication to the research community",
    "section": "Thank you for joining me in this discussion üòä",
    "text": "Thank you for joining me in this discussion üòä",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "On communication",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2025_dhsi_slides.html#website-httpsdhsi-2025.netlify.app",
    "href": "talks/2025_dhsi_slides.html#website-httpsdhsi-2025.netlify.app",
    "title": "Coding fundamentals for humanists",
    "section": "Website (https://dhsi-2025.netlify.app/)",
    "text": "Website (https://dhsi-2025.netlify.app/)"
  },
  {
    "objectID": "talks/2025_dhsi_slides.html#overview",
    "href": "talks/2025_dhsi_slides.html#overview",
    "title": "Coding fundamentals for humanists",
    "section": "Overview",
    "text": "Overview\n\nCore concepts of programming languages\nIntro to Python and JupyterLab\nBasics of Python\nUsing LLMs to write code\nAPI querying in Python\nWebscraping with Python and LLMs\nYour turn: get data from a website via an API or scraping\nPresentations: share your results, problems encountered, and what you learnt"
  },
  {
    "objectID": "talks/2025_dhsi_slides.html#pre-written-jupyter-notebooks-to-fill",
    "href": "talks/2025_dhsi_slides.html#pre-written-jupyter-notebooks-to-fill",
    "title": "Coding fundamentals for humanists",
    "section": "Pre-written Jupyter notebooks to fill",
    "text": "Pre-written Jupyter notebooks to fill\nExample of notebook given to students:"
  },
  {
    "objectID": "talks/2025_dhsi_slides.html#pre-written-jupyter-notebooks-to-fill-1",
    "href": "talks/2025_dhsi_slides.html#pre-written-jupyter-notebooks-to-fill-1",
    "title": "Coding fundamentals for humanists",
    "section": "Pre-written Jupyter notebooks to fill",
    "text": "Pre-written Jupyter notebooks to fill\nExample of completed notebook:"
  },
  {
    "objectID": "talks/2025_dhsi_slides.html#use-of-llms-to-teach-python",
    "href": "talks/2025_dhsi_slides.html#use-of-llms-to-teach-python",
    "title": "Coding fundamentals for humanists",
    "section": "Use of LLMs to teach Python",
    "text": "Use of LLMs to teach Python\nIt allowed students:\n\nto be much more independent,\nnot to get frustrated over small road-blocks,\nto go much further than in previous years,\nto keep learning on their own,\nto now be able to apply Python to their research\n\nOn our end, we learnt how to better use LLMs to teach"
  },
  {
    "objectID": "talks/2025_dhsi_slides.html#reddit-data",
    "href": "talks/2025_dhsi_slides.html#reddit-data",
    "title": "Coding fundamentals for humanists",
    "section": "Reddit data",
    "text": "Reddit data\n\n\nExported as a Python list:\n\n\n\n\nExported as a Python polars data frame:"
  },
  {
    "objectID": "talks/2025_dhsi_slides.html#numbers-of-published-books",
    "href": "talks/2025_dhsi_slides.html#numbers-of-published-books",
    "title": "Coding fundamentals for humanists",
    "section": "Numbers of published books",
    "text": "Numbers of published books"
  },
  {
    "objectID": "talks/2025_dhsi_slides.html#spotify-playlist",
    "href": "talks/2025_dhsi_slides.html#spotify-playlist",
    "title": "Coding fundamentals for humanists",
    "section": "Spotify playlist",
    "text": "Spotify playlist"
  },
  {
    "objectID": "talks/2025_dhsi_slides.html#the-guardian-archives",
    "href": "talks/2025_dhsi_slides.html#the-guardian-archives",
    "title": "Coding fundamentals for humanists",
    "section": "The Guardian archives",
    "text": "The Guardian archives"
  },
  {
    "objectID": "talks/2025_dhsi.html",
    "href": "talks/2025_dhsi.html",
    "title": "Coding fundamentals for humanists",
    "section": "",
    "text": "Presented at Digital Humanities Summer Institute (DHSI) in Montreal, QC, in June 2025.\n\nThis presentation gave a synopsis of the course Coding fundamentals for humanists offered at Digital Humanities Summer Institute (DHSI) from June 2nd to June 6th 2025.\nThe course covered core concepts of programming languages, an introduction to JupyterLab, the basics of Python, API querying, and web scraping. The format was a combination of lectures, hands-on exercises with and without large language models (LLMs), and projects relevant to the attendees academic research.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.)\nSlides content for easier browsing.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Python for the humanities"
    ]
  },
  {
    "objectID": "talks/2024_bccai_part2_content.html",
    "href": "talks/2024_bccai_part2_content.html",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Big data in agrotech industry",
      "<em>Slides content part 2</em>"
    ]
  },
  {
    "objectID": "talks/2024_bccai_part2_content.html#who-we-are",
    "href": "talks/2024_bccai_part2_content.html#who-we-are",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Who we are",
    "text": "Who we are\n\nSimon Fraser University\n\n\n\nSFU hosts the Cedar supercomputer‚Äîa cluster of 100,400 CPUs and 1,352 GPUs soon to be replaced by an even larger computer cluster.\n\n\n\n\n\n\n SFU also works with the Digital Research Alliance of Canada to offer researchers large amounts of computing power to solve challenging data and technology problems, as well as training to optimize their solutions.\n\n\n\nSFU‚Äôs Big Data Hub\n\n\n\nSince 2016, Simon Fraser University‚Äôs Big Data Hub has been offering workshops, events, and consulting services to researchers and industry partners helping them remain at the top of the fast evolving data landscape.\n\n\n\n\n\n\n\n\nBC Centre for Agritech Innovation\n\n\n\nSince 2022, SFU BCCAI has been helping small and medium enterprises in the farming industry to embrace technology driven solutions in:\n\nagritech projects\ntraining & upscaling\nagritech network",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Big data in agrotech industry",
      "<em>Slides content part 2</em>"
    ]
  },
  {
    "objectID": "talks/2024_bccai_part2_content.html#goals-for-this-workshop",
    "href": "talks/2024_bccai_part2_content.html#goals-for-this-workshop",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Goals for this workshop",
    "text": "Goals for this workshop\n\nSession 1\n\n\nA (hopefully) friendly lecture to:\n\nDemystify big data.\nDemonstrate the critical importance of big data in agriculture and farming.\n\n\n\n\n\n\n\n\n\nSession 1 recap\n\n\nBig data is defined by the 3 ‚ÄúV‚Äù:\n\nVolume (lots of data is generated)\nVariety (images, sounds, text‚Ä¶)\nVelocity (generated continuously)\n\n\n\n\n\n\n\n\nBig data has become crucial because it allows to train artificial intelligence models.\n\n\n\n\nOnce trained, those models are extremely powerful and capable of performing tasks impossible for traditional computer programs.\n(e.g.¬†creating art, generating human text, chat bots, excellent forecasting and optimization, computer vision, self-driving cars‚Ä¶).\n\n\n\n\n\n\n\n\n\nBig data and AI are transforming all sectors, including agriculture because they allow:\n\nReal time monitoring\nBetter decision making\nOptimizations\nAutomation of tasks\n\n\n\n\n\n\n\nHowever there are challenges to the implementation of such transformative methods.\n\nInfrastructure development\nSkill gaps among agricultural professionals\n\nWe are here to help.\nThis is the goal of today‚Äôs session.\n\n\n\n\n\n\n\n\n\n\n\nSession 2\n\n\n\nToday\n\nAn interactive workshop to:\n\nBrainstorm on how big data can benefit your operation\nHelp you make the transition to smart farming\n\n\n\n\n\n\n\n\n\nData management\n\n\nFirst, let‚Äôs focus on your data\nI will ask you to think about:\n\nThe data you use for your operation\nHow you are collecting it and storing it\nHow you could automate this\n\n\n\n\n\n\n\nAnalytics\n\n\nNow, let‚Äôs think about what this data is actually used for:\n\nWhat is purpose of this data?\nHow do you analyse it?\nWhat could be the benefits of using AI to process your data?\n\n\n\n\n\n\n\n\n\nChallenges\n\n\nWhat are the challenges of such an implementation\n\nat the financial level\nat the practical level\ndue to knowledge gaps\n\n\n\n\n\nFrom xkcd.com\n\n\n\n\n\n\nWho to turn to?\n\nConnecting with other operators can be extremely powerful in this transformation\nYou may also need to talk with researchers\nYou will need to find a technology provider\nHere my colleagues from the Big Data Hub and the BCCAI will jump in to orientate you\n\n\n\n\nSFU‚Äôs Big Data Hub\nWebsite\nContact us\nConsultation services\nPartnerships\n\n\nBCCAI\nWebsite\nContact us\nAgritech development program\nTraining\n\n\n\n\n\nCommunication with experts\n\n\nYou need basic concepts and vocabulary to communicate your needs to technology providers and researchers\n\nWhat concept do you feel that you are lacking and that we should cover?\nVocabulary clarification\n\n\n\n\n\n\n\nFrom xkcd.com",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Big data in agrotech industry",
      "<em>Slides content part 2</em>"
    ]
  },
  {
    "objectID": "talks/2024_bccai_part2_content.html#resources",
    "href": "talks/2024_bccai_part2_content.html#resources",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Resources",
    "text": "Resources\n\nUnderstanding neural networks\n3Blue1Brown by Grant Sanderson has a series of 4 videos on neural networks which is easy to watch, fun, and does an excellent job at introducing the functioning of a simple neural network\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLiterature\nOpen-access preprints:\nArxiv Sanity Preserver by Andrej Karpathy\nML papers in the computer science category on arXiv\nML papers in the stats category on arXiv\nDistill ML research online journal\n\n\nAcknowledgements\n\n\n\n\n\n\nCarson Li (BCCAI) suggested an outline for this talk.\n\n\n\n\n\n\n\n\n\nIan Chan (BCCAI) provided copious feedback.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Big data in agrotech industry",
      "<em>Slides content part 2</em>"
    ]
  },
  {
    "objectID": "talks/2024_bccai_part1_content.html",
    "href": "talks/2024_bccai_part1_content.html",
    "title": "Harnessing big data for agricultural excellence",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Big data in agrotech industry",
      "<em>Slides content part 1</em>"
    ]
  },
  {
    "objectID": "talks/2024_bccai_part1_content.html#who-we-are",
    "href": "talks/2024_bccai_part1_content.html#who-we-are",
    "title": "Harnessing big data for agricultural excellence",
    "section": "Who we are",
    "text": "Who we are\n\nSimon Fraser University\n\n\n\nSFU hosts the Cedar supercomputer‚Äîa cluster of 100,400 CPUs and 1,352 GPUs soon to be replaced by an even larger computer cluster.\n\n\n\n\n\n\n SFU also works with the Digital Research Alliance of Canada to offer researchers large amounts of computing power to solve challenging data and technology problems, as well as training to optimize their solutions.\n\n\n\nSFU‚Äôs Big Data Hub\n\n\n\nSince 2016, Simon Fraser University‚Äôs Big Data Hub has been offering workshops, events, and consulting services to researchers and industry partners helping them remain at the top of the fast evolving data landscape.\n\n\n\n\n\n\n\n\nBC Centre for Agritech Innovation\n\n\n\nSince 2022, SFU BCCAI has been helping small and medium enterprises in the farming industry to embrace technology driven solutions in:\n\nagritech projects\ntraining & upscaling\nagritech network",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Big data in agrotech industry",
      "<em>Slides content part 1</em>"
    ]
  },
  {
    "objectID": "talks/2024_bccai_part1_content.html#goals-for-this-workshop",
    "href": "talks/2024_bccai_part1_content.html#goals-for-this-workshop",
    "title": "Harnessing big data for agricultural excellence",
    "section": "Goals for this workshop",
    "text": "Goals for this workshop\n\nSession 1\n\n\n\nToday.\n\nA (hopefully) friendly lecture to:\n\nDemystify big data.\nDemonstrate the critical importance of big data in agriculture and farming.\n\n\n\n\n\n\n\n\n\nSession 2\n\n\n\nTomorrow at 11am in the Mount Baker Room.\n\nAn interactive workshop to:\n\nBrainstorm on how big data can benefit your operation.\nHelp you make the transition to smart farming.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Big data in agrotech industry",
      "<em>Slides content part 1</em>"
    ]
  },
  {
    "objectID": "talks/2024_bccai_part1_content.html#what-is-big-data",
    "href": "talks/2024_bccai_part1_content.html#what-is-big-data",
    "title": "Harnessing big data for agricultural excellence",
    "section": "What is big data?",
    "text": "What is big data?\n\n\nThe 3 ‚ÄúV‚Äù: Volume\n\n\n\nBefore\nFarmers were taking measurements (e.g.¬†on soil moisture) manually creating low volumes of data.\n\n\n\n\n\n\n\n\n\n\nNow\nInternet of Things (IoT) (e.g.¬†hundreds of soil moisture sensors) collects large volumes of data.\n\n\n\n\n\n\n\n\n\nThe 3 ‚ÄúV‚Äù: Variety\n\n\n\nBefore\nThere was a limited set of data a producer could collect.\n\n\n\n\n\n\n\n\n\n\nNow\nThere are so many different types of data (e.g.¬†satellite images, market data gathered from internet browsing‚Ä¶).\n\n\n\n\n\n\n\n\n\nThe 3 ‚ÄúV‚Äù: Velocity\n\n\n\nBefore\nA farmer could only gather so much data, even with a lot of employees.\n\n\n\n\n\n\n\n\n\n\nNow\nData is generated in real time and accumulates at high speed.\n\n\n\n\n\n\n\n\n\nWhy is it important?\n\n\n\nWhy has big data become so essential?\nAll this data is key to the development of artificial intelligence (AI).\nSo ‚Ä¶\nWhat is AI?\n\n\n\n\n\n\n\n\nAI\nVery loosely, you can think of neural networks (the most powerful form of AI) as an attempt to create a computer model that mimics the brain:\n\n\n\n\n\nBiological neurons\n\n\n\n\n\n\n\n\nNeural network\n\n\n\n\nIn traditional computing, a programmer writes code that gives a computer detailed instructions of what to do.\nThese instructions are called a program.\n\n\n\n\n\n\n\n\n\nSome action\n\n\n\n\n\n\nWith neural networks, instead of writing a program, a programmer writes a model, then feeds it lots of data and the model changes little by little over time.\nThe model ‚Äúlearns‚Äù thanks to this data.\n\n\n\nSimplilearn has a video explaining how neural networks work in 5 min:\n\n\n\n\n\n\nThis learning is nothing magical: some numbers in the model get tweaked a tiny bit, with each new piece of data, to make the model a little bit better.\n\n\n\n\n\n\nFrom xkcd.com\n\n\n\n\nBasically, we start with a model, train it with data, and we end up with a trained model that can be used as a traditional computer program.\n\nThat trained model can be used to get predictions, generate art or speech, identify objects in images or spams in emails‚Ä¶\nThe only difference from traditional computing is that we don‚Äôt write the program ourselves. Instead, we write a starting point (the untrained model), then train it with A LOT of data and let it get better by itself.\n\n\n\nTo get a very good model at the end‚Äîone that can write human language like ChatGPT or voice assistants for instance‚Äîyou really need A LOT OF DATA.\n\n\n\n\n\n\n\n\nAI: an example\nImagine that you want a program able to detect tomatoes in pictures.\nThis could be very useful to get real time data on your upcoming crop so that you can plan adequately (hiring staff, setting price, looking for markets).\nFor humans, this is straightforward.\nYet, this is impossible to achieve with traditional programming because there are too many factors (location of the tomatoes in the image, quality of the picture, colour of the tomatoes‚Ä¶).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHowever, by feeding a very large number of images with and without tomatoes along with labels that give the number of tomatoes for each image to a neural network, we can train it to recognize tomatoes in images that it has never seen.\nWith each pair of image/label (e.g.¬†‚ÄúPicture 34, label: 56 tomatoes‚Äù), the model gets better.\n\n\n\n\n\n\n\n\n\nWe don‚Äôt write the program to do this. We write the starting model, then let it adjust by itself based on the data.\nIt is a form of learning by experience, which is exactly what happens to us as we grow up. It is a form of programming that is much closer to how brains work than traditional programming.\n\n\n\n\n\n\nLawal, M. O. (2021). Tomato detection based on modified YOLOv3 framework. Scientific Reports, 11(1), 1-11.\n\n\n\n\n\n\nWhy now?\nThe idea is not new, but it is only recently that we have had enough computing power, internet connectivity, and storage capacity to implement it.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Big data in agrotech industry",
      "<em>Slides content part 1</em>"
    ]
  },
  {
    "objectID": "talks/2024_bccai_part1_content.html#big-data-and-ai-in-agriculture",
    "href": "talks/2024_bccai_part1_content.html#big-data-and-ai-in-agriculture",
    "title": "Harnessing big data for agricultural excellence",
    "section": "Big data and AI in agriculture",
    "text": "Big data and AI in agriculture\n\nSmart farming\n\n\nWe already talked about data collection thanks to the Internet of Things (e.g.¬†moisture sensors).\n\n\n\n\n\n\n\n\nBut this goes much further as AI algorithms can be used for ‚Äúprecision agriculture‚Äù.\n\n\n\n\nKarunathilake, E. M. B. M., Le, A. T., Heo, S., Chung, Y. S., & Mansoor, S. (2023). The path to smart farming: Innovations and opportunities in precision agriculture. Agriculture, 13(8), 1593.\n\n\n\n\n\n\nMany AI tools are involved in improving all domains of agriculture, from irrigation management to supply chain and demand forecasting.\nThe benefits are huge for both farmers (increased yields, reduced costs, better planning) and the environment (optimization of resources and pesticide use).\n\n\n\n\n\n\nKarunathilake, E. M. B. M., Le, A. T., Heo, S., Chung, Y. S., & Mansoor, S. (2023). The path to smart farming: Innovations and opportunities in precision agriculture. Agriculture, 13(8), 1593.\n\n\n\n\n\n\nDecision making\n\n\n\nBefore\nFarmers had to make decisions as best they could based on their experience and their limited data.\n\n\n\n\n\n\n\n\n\n\nNow\nFarmers can use powerful models to make informed decision in real time. This can be followed by the automation of some action (e.g.¬†watering).\n\n\n\n\n\n\n\n\n\nLivestock monitoring\n\n\n\nA case study\nLivestock successfully monitored remotely via sound sensors and algorithms for background noise filtering.\nAnimal welfare and efficiency improvements.\n\n\n\n\n\n\n\nJung, D. H., Kim, N. Y., Moon, S. H., Jhin, C., Kim, H. J., Yang, J. S., ‚Ä¶ & Park, S. H. (2021). Deep learning-based cattle vocal classification model and real-time livestock monitoring system with noise filtering. Animals, 11(2), 357.\n\n\n\n\n\n\nMarkets and supply chains\nThis next section looks at a review of market analysis and supply chain optimization.\n\nA review\n\n\nSystematic literature review of peer-reviewed articles and conference papers published between 2014 and 20241 showed large improvements of demand forecasting accuracy and supply chain optimization.\nReal time data analysis helped with predictive maintenance, market volatility, resource constraints, and climate variability.\n\n\n\n\n\n\n\n\n\nChallenges\nThere are challenges to the implementation of such transformative methods.\n\nInfrastructure development.\nSkill gaps among agricultural professionals.\n\nWe are here to help!\n\n\n\n\n\n\n\n\n\nCome to session 2 tomorrow!\n\n\nSession 2\nJoin us tomorrow at 11am in the Mount Baker Room for our 2nd session:\n\nDiagnosing and implementing big data solutions.\n\nWe will have an interactive workshop to:\n\nBrainstorm on how big data can benefit your operation.\nHelp you make the transition to smart farming.\n\n\nIf you are unable to attend, you can find the slides here, but it will be an interactive clinic with most of the material covered in the activity.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Big data in agrotech industry",
      "<em>Slides content part 1</em>"
    ]
  },
  {
    "objectID": "talks/2024_bccai_part1_content.html#resources",
    "href": "talks/2024_bccai_part1_content.html#resources",
    "title": "Harnessing big data for agricultural excellence",
    "section": "Resources",
    "text": "Resources\n\nGetting in touch\n\n\n\nSFU‚Äôs Big Data Hub\nWebsite\nContact us\nConsultation services\nPartnerships\n\n\nBCCAI\nWebsite\nContact us\nAgritech development program\nTraining\n\n\n\n\n\nUnderstanding neural networks\nTo go a bit further than the video mentioned earlier, 3Blue1Brown by Grant Sanderson has a series of 4 videos on neural networks which is easy to watch, fun, and does an excellent job at introducing the functioning of a simple neural network:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLiterature\nOpen-access preprints:\nArxiv Sanity Preserver by Andrej Karpathy\nML papers in the computer science category on arXiv\nML papers in the stats category on arXiv\nDistill ML research online journal\n\n\nAcknowledgements\n\n\n\n\n\n\nCarson Li (BCCAI) suggested an outline for this talk.\n\n\n\n\n\n\n\n\n\nIan Chan (BCCAI) provided copious feedback.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Big data in agrotech industry",
      "<em>Slides content part 1</em>"
    ]
  },
  {
    "objectID": "talks/2024_bccai_part1_content.html#footnotes",
    "href": "talks/2024_bccai_part1_content.html#footnotes",
    "title": "Harnessing big data for agricultural excellence",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nElufioye, O. A., Ike, C. U., Odeyemi, O., Usman, F. O., & Mhlongo, N. Z. (2024). Ai-Driven predictive analytics in agricultural supply chains: a review: assessing the benefits and challenges of ai in forecasting demand and optimizing supply in agriculture. Computer Science & IT Research Journal, 5(2), 473-497.‚Ü©Ô∏é",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Big data in agrotech industry",
      "<em>Slides content part 1</em>"
    ]
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_slides.html#markup-languages",
    "href": "talks/2023_stafftostaff_quarto_slides.html#markup-languages",
    "title": "Quarto as a great teaching tool",
    "section": "Markup languages",
    "text": "Markup languages\n\nControl the formatting of text documents\nPowerful but the unrendered text is visually cluttered and hard to read"
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_slides.html#markup-languages-1",
    "href": "talks/2023_stafftostaff_quarto_slides.html#markup-languages-1",
    "title": "Quarto as a great teaching tool",
    "section": "Markup languages",
    "text": "Markup languages\n\nControl the formatting of text documents\nPowerful but the unrendered text is visually cluttered and hard to read\n\n\nExample: Tex‚Äîoften with macro package LaTeX‚Äîto create pdfs\n\n\\documentclass{article}\n\\title{My title}\n\\author{My name}\n\\usepackage{datetime}\n\\newdate{date}{24}{11}{2022}\n\\date{\\displaydate{date}}\n\\begin{document}\n \\maketitle\n \\section{First section}\n Some text in the first section.\n\\end{document}"
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_slides.html#markup-languages-2",
    "href": "talks/2023_stafftostaff_quarto_slides.html#markup-languages-2",
    "title": "Quarto as a great teaching tool",
    "section": "Markup languages",
    "text": "Markup languages\n\nControl the formatting of text documents\nPowerful but the unrendered text is visually cluttered and hard to read\n\n\nExample: HTML‚Äîoften with css/scss files‚Äîto create webpages\n\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en-US\"&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"utf-8\" /&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width\" /&gt;\n    &lt;title&gt;My title&lt;/title&gt;\n    &lt;address class=\"author\"&gt;My name&lt;/address&gt;\n    &lt;input type=\"date\" value=\"2022-11-24\" /&gt;\n  &lt;/head&gt;\n  &lt;h1&gt;First section&lt;/h1&gt;\n  &lt;body&gt;\n    Some text in the first section.\n  &lt;/body&gt;\n&lt;/html&gt;"
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_slides.html#markdown",
    "href": "talks/2023_stafftostaff_quarto_slides.html#markdown",
    "title": "Quarto as a great teaching tool",
    "section": "Markdown",
    "text": "Markdown\n\nRemoves the visual clutter and makes texts readable prior to rendering\nCreated in 2004\nBy now quasi-ubiquitous\nInitially created for webpages\nRaw HTML can be inserted when easy syntax falls short\n\n\nPandoc‚Äôs extended Markdown\nPandoc (free and open-source markup formats converter) supports an extended Markdown syntax with functionality for figures, tables, callout blocks, LaTeX equations, citations‚Ä¶\nRemains as readable as basic Markdown, but can be rendered in any format (pdf, books, entire websites, Word documents‚Ä¶)"
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_slides.html#markdown-1",
    "href": "talks/2023_stafftostaff_quarto_slides.html#markdown-1",
    "title": "Quarto as a great teaching tool",
    "section": "Markdown",
    "text": "Markdown\n\nRemoves the visual clutter and makes texts readable prior to rendering\nCreated in 2004\nBy now quasi-ubiquitous\nInitially created for webpages\nRaw HTML can be inserted when easy syntax falls short\n\n\nPrevious example using Pandoc‚Äôs Markdown:\n\n---\ntitle: My title\nauthor: My name\ndate: 2022-11-24\n---\n# First section\nSome text in the first section."
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_slides.html#how-it-works",
    "href": "talks/2023_stafftostaff_quarto_slides.html#how-it-works",
    "title": "Quarto as a great teaching tool",
    "section": "How it works",
    "text": "How it works\nCode blocks are executed by Jupyter (Python or Julia) or knitr (R), then pandoc renders the document into any format\n\nJulia/Python:\n From Quarto documentation\nR:\n From Quarto documentation"
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_slides.html#how-it-works-1",
    "href": "talks/2023_stafftostaff_quarto_slides.html#how-it-works-1",
    "title": "Quarto as a great teaching tool",
    "section": "How it works",
    "text": "How it works\nCode blocks are executed by Jupyter (Python or Julia) or knitr (R), then pandoc renders the document into any format\nCan be used from .qmd text files or directly from RStudio or Jupyter notebooks."
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_slides.html#supported-languages",
    "href": "talks/2023_stafftostaff_quarto_slides.html#supported-languages",
    "title": "Quarto as a great teaching tool",
    "section": "Supported languages",
    "text": "Supported languages\nSyntax highlighting in pretty much any language\n\nExecutable code blocks in Python, R, Julia, Observable JS\n\n\nOutput formats\n- HTML\n- PDF\n- MS Word\n- OpenOffice\n- ePub\n- Revealjs\n- PowerPoint\n- Beamer\n- GitHub Markdown\n- CommonMark\n- Hugo\n- Docusaurus\n- Markua\n- MediaWiki\n- DokuWiki\n- ZimWiki\n- Jira Wiki\n- XWiki\n- JATS\n- Jupyter\n- ConTeXt\n- RTF\n- reST\n- AsciiDoc\n- Org-Mode\n- Muse\n- GNU\n- Groff"
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_slides.html#document-structure-syntax-front-matter",
    "href": "talks/2023_stafftostaff_quarto_slides.html#document-structure-syntax-front-matter",
    "title": "Quarto as a great teaching tool",
    "section": "Document structure & syntax: front matter",
    "text": "Document structure & syntax: front matter\nWritten in YAML\nSets the options for the document. Let‚Äôs see a few examples.\n\n\nCan be very basic:\n\n---\ntitle: \"My title\"\nauthor: \"My name\"\nformat: html\n---"
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_slides.html#document-structure-syntax-front-matter-1",
    "href": "talks/2023_stafftostaff_quarto_slides.html#document-structure-syntax-front-matter-1",
    "title": "Quarto as a great teaching tool",
    "section": "Document structure & syntax: front matter",
    "text": "Document structure & syntax: front matter\nWritten in YAML\nSets the options for the document. Let‚Äôs see a few examples.\n\nOr more sophisticated:\n\n---\ntitle: \"Some title\"\nsubtitle: \"Some subtitle\"\ninstitute: \"Simon Fraser University\"\ndate: \"2022-11-24\"\nexecute:\n  error: true\n  echo: true\nformat:\n  revealjs:\n    theme: [default, custom.scss]\n    highlight-style: monokai\n    code-line-numbers: false\n    embed-resources: true\n---"
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_slides.html#document-structure-syntax-text",
    "href": "talks/2023_stafftostaff_quarto_slides.html#document-structure-syntax-text",
    "title": "Quarto as a great teaching tool",
    "section": "Document structure & syntax: text",
    "text": "Document structure & syntax: text\nWritten in Pandoc‚Äôs extended Markdown"
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_slides.html#document-structure-syntax-code-blocks",
    "href": "talks/2023_stafftostaff_quarto_slides.html#document-structure-syntax-code-blocks",
    "title": "Quarto as a great teaching tool",
    "section": "Document structure & syntax: code blocks",
    "text": "Document structure & syntax: code blocks\nSyntax highlighting only:\n{.language} code\n\nSyntax highlighting and code execution:\n```{language}\ncode\n```\n\n\nOptions can be added to individual blocks:\n```{language}\n#| option: value\n\ncode\n```"
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_slides.html#rendering",
    "href": "talks/2023_stafftostaff_quarto_slides.html#rendering",
    "title": "Quarto as a great teaching tool",
    "section": "Rendering",
    "text": "Rendering\nTwo commands:\nquarto render file.qmd     # Renders the document\nquarto preview file.qmd  # Displays a live preview"
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_slides.html#general-considerations",
    "href": "talks/2023_stafftostaff_quarto_slides.html#general-considerations",
    "title": "Quarto as a great teaching tool",
    "section": "General considerations",
    "text": "General considerations\n\nExtremely well documented\nSolid team behind the work\nFree and open source\nUses only well established and well tested tools"
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_slides.html#webpageswebsites",
    "href": "talks/2023_stafftostaff_quarto_slides.html#webpageswebsites",
    "title": "Quarto as a great teaching tool",
    "section": "Webpages/websites",
    "text": "Webpages/websites\n\nFast, easy, and clean\nSites work on screens of any size out of the box (uses Bootstrap 5)\nCan be customized with CSS/SCSS, but good out of the box\nCode blocks can have a little copy button\nSite/pages can be hosted anywhere easily"
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_slides.html#advantages-of-code-execution",
    "href": "talks/2023_stafftostaff_quarto_slides.html#advantages-of-code-execution",
    "title": "Quarto as a great teaching tool",
    "section": "Advantages of code execution",
    "text": "Advantages of code execution\n\nPeople can see the output without running the code\nForces to test every bit of code\nIf the code broke when giving an old workshop, prevents the embarrassment of discovering it in the middle of a live demo\nNo need for a complex system linking code scripts with teaching documents"
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto.html",
    "href": "talks/2023_stafftostaff_quarto.html",
    "title": "Creating training material with Quarto",
    "section": "",
    "text": "Presented at the Digital Research Alliance of Canada Staff To Staff Webinar Series.\n\nQuarto (the successor to R Markdown) uses Jupyter (for Python and Julia) or knitr (for R) to execute code blocks and insert them into markdown documents that then get rendered by Pandoc into PDFs, websites, or other documents. This makes it a great tool to create training websites.\nIn this webinar, I will show how I use Quarto to create all of the training material that I develop for webinars, workshops, and courses.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Quarto as a teaching tool"
    ]
  },
  {
    "objectID": "talks/2023_driconnect_content.html",
    "href": "talks/2023_driconnect_content.html",
    "title": "The instruments for advanced research computing are here, but are researchers ready?",
    "section": "",
    "text": "Content from the talk slides for easier browsing.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "ARC instruments",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2023_driconnect_content.html#times-are-changing",
    "href": "talks/2023_driconnect_content.html#times-are-changing",
    "title": "The instruments for advanced research computing are here, but are researchers ready?",
    "section": "Times are changing",
    "text": "Times are changing\n\nSo many opportunities\nHuge amounts of computing power readily available\n\n\nOpen source on steroids\nExplosion of tools, libraries, software, new programming languages\nPowerful ML algorithms\nLiterate programming is finally mainstream\nBut‚Ä¶\n\nPIs often don‚Äôt have experience with new tools and are unable to help their students\n\nDepartments are slow to add courses needed by students\n\nSome fields don‚Äôt have a strong computing culture",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "ARC instruments",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2023_driconnect_content.html#our-training",
    "href": "talks/2023_driconnect_content.html#our-training",
    "title": "The instruments for advanced research computing are here, but are researchers ready?",
    "section": "Our training",
    "text": "Our training\n\nTopics\n\nUnix shell\nHPC\nVersion control with Git/DataLad\nScientific programming in R/Python/Julia\nParallel computing in R/Julia/Chapel\nDeep learning with PyTorch\nScientific visualization\nContainers/Alliance clouds/VMs\nWebscraping in R/Python\nGIS in R\nScientific publishing with Quarto\n\nA large team of 2 to develop the material, organize events, advertise, build magic castles, websites, and posters, handle registrations and emails, and teach1\n53 webinars/workshops/courses taught since the start of 2023\nTraining website linking to all material\nMint (Mint Is Not Training) website written in Quarto with my content",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "ARC instruments",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2023_driconnect_content.html#now-one-little-damper",
    "href": "talks/2023_driconnect_content.html#now-one-little-damper",
    "title": "The instruments for advanced research computing are here, but are researchers ready?",
    "section": "Now ‚Ä¶ one little damper ‚Ä¶",
    "text": "Now ‚Ä¶ one little damper ‚Ä¶\nTimes are changing.\nFast.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "ARC instruments",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2023_driconnect_content.html#footnotes",
    "href": "talks/2023_driconnect_content.html#footnotes",
    "title": "The instruments for advanced research computing are here, but are researchers ready?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMegan and James are very supportive‚Ü©Ô∏é",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "ARC instruments",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/ws_webscraping.html",
    "href": "r/ws_webscraping.html",
    "title": "Web scraping with R",
    "section": "",
    "text": "The internet is a trove of information. A lot of it is publicly available and thus suitable for use in research. Extracting that information and putting it in an organized format for analysis can, however, be extremely tedious. Web scraping tools allow to automate parts of that process and R is a popular language for the task.\nIn this workshop, we will guide you through a simple example using the package rvest.",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Web scraping with rvest"
    ]
  },
  {
    "objectID": "r/ws_webscraping.html#html-and-css",
    "href": "r/ws_webscraping.html#html-and-css",
    "title": "Web scraping with R",
    "section": "HTML and CSS",
    "text": "HTML and CSS\nHyperText Markup Language (HTML) is the standard markup language for websites: it encodes the information related to the formatting and structure of webpages. Additionally, some of the customization can be stored in Cascading Style Sheets (CSS) files.\nHTML uses tags of the form:\n&lt;some_tag&gt;Your content&lt;/some_tag&gt;\nSome tags have attributes:\n&lt;some_tag attribute_name=\"attribute value\"&gt;Your content&lt;/some_tag&gt;\n\nExamples:\n\nSite structure:\n\n&lt;h2&gt;This is a heading of level 2&lt;/h2&gt;\n&lt;p&gt;This is a paragraph&lt;/p&gt;\n\nFormatting:\n\n&lt;b&gt;This is bold&lt;/b&gt;\n&lt;a href=\"https://some.url\"&gt;This is the text for a link&lt;/a&gt;",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Web scraping with rvest"
    ]
  },
  {
    "objectID": "r/ws_webscraping.html#web-scrapping",
    "href": "r/ws_webscraping.html#web-scrapping",
    "title": "Web scraping with R",
    "section": "Web scrapping",
    "text": "Web scrapping\nWeb scraping is a general term for a set of tools which allow for the extraction of data from the web automatically.\nWhile most of the data on the internet is publicly available, it is illegal to scrape some sites and you should always look into the policy of a site before attempting to scrape it. Some sites will also block you if you submit too many requests in a short amount of time, so if you plan on scraping sites at a fairly large scale, you should look into the polite package which will help you scrape responsibly.",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Web scraping with rvest"
    ]
  },
  {
    "objectID": "r/ws_webscraping.html#example-for-this-workshop",
    "href": "r/ws_webscraping.html#example-for-this-workshop",
    "title": "Web scraping with R",
    "section": "Example for this workshop",
    "text": "Example for this workshop\nWe will use a website from the University of Tennessee containing a database of PhD theses from that university.\nOur goal is to scrape data from this site to produce a dataframe with the date, major, and advisor for each dissertation.\n\nWe will only do this for the first page which contains the links to the 100 most recent theses. If you really wanted to gather all the data, you would have to do this for all pages.",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Web scraping with rvest"
    ]
  },
  {
    "objectID": "r/ws_webscraping.html#lets-look-at-the-sites",
    "href": "r/ws_webscraping.html#lets-look-at-the-sites",
    "title": "Web scraping with R",
    "section": "Let‚Äôs look at the sites",
    "text": "Let‚Äôs look at the sites\nFirst of all, let‚Äôs have a close look at the websites we want to scrape to think carefully about what we want to do. Before starting to write code, it is always a good idea to think about what you are trying to achieve with your code.\nTo create a dataframe with the data for all the dissertations on that first page, we need to do two things:\n\nStep 1: from the dissertations database first page, we want to scrape the list of URLs for the dissertation pages.\nStep 2: once we have the URLs, we want to scrape those pages too to get the date, major, and advisor for each dissertation.",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Web scraping with rvest"
    ]
  },
  {
    "objectID": "r/ws_webscraping.html#package",
    "href": "r/ws_webscraping.html#package",
    "title": "Web scraping with R",
    "section": "Package",
    "text": "Package\nTo do all this, we will use the package rvest, part of the tidyverse (a modern set of R packages). It is a package influenced by the popular Python package Beautiful Soup and it makes scraping websites with R really easy.\nLet‚Äôs load it:\n\nlibrary(rvest)",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Web scraping with rvest"
    ]
  },
  {
    "objectID": "r/ws_webscraping.html#read-in-html-from-main-site",
    "href": "r/ws_webscraping.html#read-in-html-from-main-site",
    "title": "Web scraping with R",
    "section": "Read in HTML from main site",
    "text": "Read in HTML from main site\nAs mentioned above, our site is the database of PhD dissertations from the University of Tennessee.\nLet‚Äôs create a character vector with the URL:\n\nurl &lt;- \"https://trace.tennessee.edu/utk_graddiss/index.html\"\n\nFirst, we read in the html data from that page:\n\nhtml &lt;- read_html(url)\n\nLet‚Äôs have a look at the raw data:\n\nhtml\n\n{html_document}\n&lt;html lang=\"en\"&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] &lt;body&gt;\\n&lt;!-- FILE /srv/sequoia/main/data/trace.tennessee.edu/assets/heade ...",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Web scraping with rvest"
    ]
  },
  {
    "objectID": "r/ws_webscraping.html#test-run",
    "href": "r/ws_webscraping.html#test-run",
    "title": "Web scraping with R",
    "section": "Test run",
    "text": "Test run\n\nIdentify the relevant HTML markers\nThe html code for this webpage contains the data we are interested in, but it is mixed in with a lot of HTML formatting and data we don‚Äôt care about. We need to extract the data relevant to us and turn it into a workable format.\nThe first step is to find the HTML markers that contain our data. One option is to use a web inspector or‚Äîeven easier‚Äîthe SelectorGadget, a JavaScript bookmarklet built by Andrew Cantino.\nTo use this tool, go to the SelectorGadget website and drag the link of the bookmarklet to your bookmarks bar.\nNow, go to the dissertations database first page and click on the bookmarklet in your bookmarks bar. You will see a floating box at the bottom of your screen. As you move your mouse across the screen, an orange rectangle appears around each element over which you pass.\nClick on one of the dissertation links: now, there is an a appearing in the box at the bottom as well as the number of elements selected. The selected elements are highlighted in yellow. Those elements are links (in HTML, a tags define hyperlinks).\nAs you can see, all the links we want are selected. However, there are many other links we don‚Äôt want that are also highlighted. In fact, all links in the document are selected. We need to remove the categories of links that we don‚Äôt want. To do this, hover above any of the links we don‚Äôt want. You will see a red rectangle around it. Click on it: now all similar links are gone. You might have to do this a few times until only the relevant links (i.e.¬†those that lead to the dissertation information pages) remain highlighted.\nAs there are 100 such links per page, the count of selected elements in the bottom floating box should be down to 100.\nIn the main section of the floating box, you can now see: .article-listing a. This means that the data we want are under the HTML elements .article-listing a (the class .article-listing and the tag a).\n\n\nExtract test URL\nIt is a good idea to test things out on a single element before doing a massive batch scraping of a site, so let‚Äôs test our method for the first dissertation.\nTo start, we need to extract the first URL. The function html_element() from the package rvest extracts the first element matching some character. Let‚Äôs pass to this function our html object and the character \".article-listing a\" and assign the result to an object that we will call test:\n\ntest &lt;- html %&gt;% html_element(\".article-listing a\")\n\nError in dyn.load(file, DLLpath = DLLpath, ...): unable to load shared object '/home/marie/R/lib/stringi/libs/stringi.so':\n  libicui18n.so.75: cannot open shared object file: No such file or directory\n\n\n\n%&gt;% is a pipe from the magrittr tidyverse package. It passes the output from the left-hand side expression as the first argument of the right-hand side expression. We could have written this as:\ntest &lt;- html_element(html, \".article-listing a\")\n\nOur new object is a list:\n\ntypeof(test)\n\nError: object 'test' not found\n\n\nLet‚Äôs print it:\n\ntest\n\nError: object 'test' not found\n\n\nThe URL is in there, so we successfully extracted the correct element, but we need to do more cleaning.\na is one of the HTML tags that have an attribute (href) as you can see when you print test. It is actually the value of that attribute that we want. To extract an attribute value, we use the function html_attr():\n\nurl_test &lt;- test %&gt;% html_attr(\"href\")\n\nError: object 'test' not found\n\nurl_test\n\nError: object 'url_test' not found\n\n\nThis is our URL.\n\nstr(url_test)\n\nError: object 'url_test' not found\n\n\nIt is saved in a character vector, which is perfect.\n\nInstead of creating the intermediate objects html and test, we could have chained the functions:\n\nurl_test &lt;- read_html(url) %&gt;%\n  html_element(\".article-listing a\") %&gt;%\n  html_attr(\"href\")\n\nError in dyn.load(file, DLLpath = DLLpath, ...): unable to load shared object '/home/marie/R/lib/stringi/libs/stringi.so':\n  libicui18n.so.75: cannot open shared object file: No such file or directory\n\n\n\n\n\nRead in HTML data for test URL\nNow that we have the URL for the first dissertation information page, we want to extract the date, major, and advisor for that dissertation.\nWe just saw that url_test is a character vector representing a URL. We know how to deal with this.\nThe first thing to do‚Äîas we did earlier with the database site‚Äîis to read in the html data. Let‚Äôs assign it to a new object that we will call html_test:\n\nhtml_test &lt;- read_html(url_test)\n\nError: object 'url_test' not found\n\nhtml_test\n\nError: object 'html_test' not found\n\n\n\n\nGet data for test URL\nNow, we want to extract the publication date. Thanks to the SelectorGadget, following the method we saw earlier, we can see that we now need the element marked by #publication_date p.\nWe start by extracting the data as we did earlier by passing our object html_test and the character \"#publication_date p\" to html_element().\nWhile earlier we wanted the value of a tag attribute (i.e.¬†part of the metadata), here we want the actual text (i.e.¬†part of the actual content). To extract text from a snippet of HTML, we pass it to html_text2().\nLet‚Äôs run both operations at once to save the creation of an intermediate object:\n\ndate_test &lt;- html_test %&gt;%\n  html_element(\"#publication_date p\") %&gt;%\n  html_text2()\n\nError: object 'html_test' not found\n\n\n\nNote the difference with what we did earlier to extract the URL: if we had used html_text2() then we would have gotten the text part of the link (\"The Novel Chlorination of Zirconium Metal and Its Application to a Recycling Protocol for Zircaloy Cladding from Spent Nuclear Fuel Rods\") rather than the URL (\"https://trace.tennessee.edu/utk_graddiss/7600\").\n\nLet‚Äôs verify that our date object indeed contains the date:\n\ndate_test\n\nError: object 'date_test' not found\n\n\nWe also want the major for this thesis. The SelectorGadget allows us to find that this time, it is the #department p element that we need. Let‚Äôs extract it in the same fashion:\n\nmajor_test &lt;- html_test %&gt;%\n  html_element(\"#department p\") %&gt;%\n  html_text2()\n\nError: object 'html_test' not found\n\nmajor_test\n\nError: object 'major_test' not found\n\n\nAnd for the advisor, we need the #advisor1 p element:\n\nadvisor_test &lt;- html_test %&gt;%\n  html_element(\"#advisor1 p\") %&gt;%\n  html_text2()\n\nError: object 'html_test' not found\n\nadvisor_test\n\nError: object 'advisor_test' not found\n\n\n\n\nYour turn:\n\nTry using the SelectorGadget to identify the element necessary to extract the abstract of this dissertation.\nNow, write the code to extract it and make sure you actually get what you want.\n\nWe now have the date, major, and advisor for the first dissertation. We can create a matrix by passing them as arguments to cbind():\n\nresult_test &lt;- cbind(date_test, major_test, advisor_test)\n\nError: object 'date_test' not found\n\nresult_test\n\nError: object 'result_test' not found",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Web scraping with rvest"
    ]
  },
  {
    "objectID": "r/ws_webscraping.html#full-run",
    "href": "r/ws_webscraping.html#full-run",
    "title": "Web scraping with R",
    "section": "Full run",
    "text": "Full run\n\nExtract all URLs\nNow that we have tested our code on the first dissertation, we can apply it on all 100 dissertations of the first page of the database.\nInstead of using html_element(), this time we will use html_elements() which extracts all matching elements (instead of just the first one):\n\ndat &lt;- html %&gt;% html_elements(\".article-listing a\")\n\nError in dyn.load(file, DLLpath = DLLpath, ...): unable to load shared object '/home/marie/R/lib/stringi/libs/stringi.so':\n  libicui18n.so.75: cannot open shared object file: No such file or directory\n\ndat\n\nError: object 'dat' not found\n\n\n\ntypeof(dat)\n\nError: object 'dat' not found\n\nlength(dat)\n\nError: object 'dat' not found\n\ntypeof(dat[[1]])\n\nError: object 'dat' not found\n\n\nWe now have a list of lists.\nAs we did for a single URL in the test run, we now want to extract all the URLs. We will do this using a loop.\nBefore running for loops, it is important to initialize empty loops. It is much more efficient than growing the result at each iteration.\nSo let‚Äôs initialize an empty list that we call list_urls of the appropriate size:\n\nlist_urls &lt;- vector(\"list\", length(dat))\n\nError: object 'dat' not found\n\n\nNow we can run a loop to fill in our list:\n\nfor (i in seq_along(dat)) {\n  list_urls[[i]] &lt;- dat[[i]] %&gt;% html_attr(\"href\")\n}\n\nError: object 'dat' not found\n\n\nLet‚Äôs print again the first element of list_urls to make sure all looks good:\n\nlist_urls[[1]]\n\nError: object 'list_urls' not found\n\n\nWe now have a list of URLs (in the form of character vectors) as we wanted.\n\n\nExtract data from each page\nWe will now extract the data (date, major, and advisor) for all URLs in our list.\nAgain, before running a for loop, we need to allocate memory first by creating an empty container (here a list):\n\nlist_data &lt;- vector(\"list\", length(list_urls))\n\nError: object 'list_urls' not found\n\n\nWe move the code we tested for a single URL inside a loop and we add one result to the list_data list at each iteration until we have all 100 dissertation sites scraped. Because there are quite a few of us running the code at the same time, we don‚Äôt want the site to block our request. To play safe, we will add a little delay (0.1 second) at each iteration (many sites will block requests if they are too frequent):\n\nfor (i in seq_along(list_urls)) {\n  html &lt;- read_html(list_urls[[i]])\n  date &lt;- html %&gt;%\n    html_element(\"#publication_date p\") %&gt;%\n    html_text2()\n  major &lt;- html %&gt;%\n    html_element(\"#department p\") %&gt;%\n    html_text2()\n  advisor &lt;- html %&gt;%\n    html_element(\"#advisor1 p\") %&gt;%\n    html_text2()\n  Sys.sleep(0.1)  # Add a little delay\n  list_data[[i]] &lt;- cbind(date, major, advisor)\n}\n\nError: object 'list_urls' not found\n\n\nLet‚Äôs make sure all looks good by printing the first element of list_data:\n\nlist_data[[1]]\n\nError: object 'list_data' not found",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Web scraping with rvest"
    ]
  },
  {
    "objectID": "r/ws_webscraping.html#store-results-in-dataframe",
    "href": "r/ws_webscraping.html#store-results-in-dataframe",
    "title": "Web scraping with R",
    "section": "Store results in DataFrame",
    "text": "Store results in DataFrame\nWe can turn this big list into a dataframe:\n\nresult &lt;- do.call(rbind.data.frame, list_data)\n\nError: object 'list_data' not found\n\n\nresult is a long dataframe, so we will only print the first few elements:\n\nhead(result)\n\nError: object 'result' not found\n\n\nIf you like the tidyverse, you can turn it into a tibble:\n\nresult &lt;- result %&gt;% tibble::as_tibble()\n\nError: object 'result' not found\n\n\n\nThe notation tibble::as_tibble() means that we are using the function as_tibble() from the package tibble. A tibble is the tidyverse version of a dataframe. One advantage is that it will only print the first 10 rows by default instead of printing the whole dataframe, so you don‚Äôt have to use head() when printing long dataframes:\n\nresult\n\nError: object 'result' not found\n\n\n\nWe can capitalize the headers:\n\nnames(result) &lt;- c(\"Date\", \"Major\", \"Advisor\")\n\nError: object 'result' not found\n\n\nThis is what our final result looks like:\n\nresult\n\nError: object 'result' not found",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Web scraping with rvest"
    ]
  },
  {
    "objectID": "r/ws_webscraping.html#save-results-to-file",
    "href": "r/ws_webscraping.html#save-results-to-file",
    "title": "Web scraping with R",
    "section": "Save results to file",
    "text": "Save results to file\nAs a final step, we will save our data to a CSV file:\nwrite.csv(result, \"dissertations_data.csv\", row.names = FALSE)",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Web scraping with rvest"
    ]
  },
  {
    "objectID": "r/ws_webscraping.html#functions-recap",
    "href": "r/ws_webscraping.html#functions-recap",
    "title": "Web scraping with R",
    "section": "Functions recap",
    "text": "Functions recap\nBelow is a recapitulation of the rvest functions we have used today:\n\n\n\nFunctions\nUsage\n\n\n\n\nread_html()\nRead in HTML from URL\n\n\nhtml_element()\nExtract first matching element\n\n\nhtml_elements()\nExtract all matching elements\n\n\nhtml_attr()\nExtract the value of an attribute\n\n\nhtml_text2()\nExtract text",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Web scraping with rvest"
    ]
  },
  {
    "objectID": "r/ws_webscraping.html#recording",
    "href": "r/ws_webscraping.html#recording",
    "title": "Web scraping with R",
    "section": "Recording",
    "text": "Recording\n\nVideo of this workshop for the Digital Research Alliance of Canada HSS Winter Series 2023:",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Web scraping with rvest"
    ]
  },
  {
    "objectID": "r/ws_gis_intro.html",
    "href": "r/ws_gis_intro.html",
    "title": "Introduction to GIS with R",
    "section": "",
    "text": "This workshop is an introduction to GIS in R. We will learn how to import GIS data, explore it, and map it.\nIn particular, we will create maps (inset maps, faceted maps, animated maps, interactive maps, and raster maps), thanks to the packages sf, tmap, raster, leaflet, ggplot2, grid (part of Base R), and mapview.\nWe will also learn how to add basemaps from OpenStreetMap and Google Maps.",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro to GIS mapping with R"
    ]
  },
  {
    "objectID": "r/ws_gis_intro.html#getting-the-data",
    "href": "r/ws_gis_intro.html#getting-the-data",
    "title": "Introduction to GIS with R",
    "section": "Getting the data",
    "text": "Getting the data\n\nDatasets\nFor this webinar, we will use:\n\nthe Alaska as well as the Western Canada and USA subsets of the Randolph Glacier Inventory version 6.01\nthe USGS time series of the named glaciers of Glacier National Park2 The datasets can be downloaded as zip files from these websites.\n\n\n\nBasemaps\nFor our basemaps, we will use data from:\n\nNatural Earth: this dataset can be accessed direction from within R thanks to the packages rnaturalearth (which provides the functions) and rnaturalearthdata (which provides the data)",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro to GIS mapping with R"
    ]
  },
  {
    "objectID": "r/ws_gis_intro.html#loading-and-exploring-data",
    "href": "r/ws_gis_intro.html#loading-and-exploring-data",
    "title": "Introduction to GIS with R",
    "section": "Loading and exploring data",
    "text": "Loading and exploring data\nFirst, let‚Äôs load the necessary packages for this webinar:\nlibrary(sf)\nlibrary(tmap)\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(purrr)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\nlibrary(mapview)\nlibrary(grid) # part of base R (already installed), but needs to be explicitly loaded\nWe will start by mapping all the glaciers of Western North America thanks to:\n\nthe Alaska subset of the Randolph Glacier Inventory\nthe Western Canada and USA subset of the Randolph Glacier Inventory\n\nDownload and unzip 02_rgi60_WesternCanadaUS and 01_rgi60_Alaska from the Randolph Glacier Inventory version 6.0.\nData get imported and turned into sf objects by the function sf::st_read():\nak &lt;- st_read(\"01_rgi60_Alaska\")\nwes &lt;- st_read(\"02_rgi60_WesternCanadaUS\")\n\nMake sure to use the absolute paths or the proper paths relative to your working directory (which can be obtained with getwd() and modified with setwd()).\n\nYou can print and explore your new objects:\nak\nwes\n\nstr(ak)\nstr(wes)\nsf objects are data.frame-like objects with a geometry list-column as their last column. That column is itself an object of class sfc (simple feature geometry list column).",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro to GIS mapping with R"
    ]
  },
  {
    "objectID": "r/ws_gis_intro.html#mapping-with-tmap",
    "href": "r/ws_gis_intro.html#mapping-with-tmap",
    "title": "Introduction to GIS with R",
    "section": "Mapping with tmap",
    "text": "Mapping with tmap\ntmap follows a grammar of graphic similar to that of ggplot2: you first need to set a shape (a spatial data object) by passing an sf object to tm_shape(). Then you plot one or several layers with one of several tmap functions and you use the + sign between each element.\nTo see the available options, run:\n?tmap-element\nWe could thus plot the glaciers of Alaska with any of the options below:\ntm_shape(ak) +\n  tm_borders()\n\ntm_shape(ak) +\n  tm_fill()\n\ntm_shape(ak) +\n  tm_polygons()      # shows both borders and fill\nHere, we will use tm_polygons() which combines tm_borders() and tm_fill().",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro to GIS mapping with R"
    ]
  },
  {
    "objectID": "r/ws_gis_intro.html#layout-elements-and-attribute-layers",
    "href": "r/ws_gis_intro.html#layout-elements-and-attribute-layers",
    "title": "Introduction to GIS with R",
    "section": "Layout elements and attribute layers",
    "text": "Layout elements and attribute layers\nA map without title, compass, or scale bars is not very useful though. We need to add layout elements and attribute layers to the map.\nYou can loop up the many arguments of the tmap functions in the help pages to see how you can customize your maps:\n?tm_layout\n?tm_compass\n?tm_scale_bar\nLet‚Äôs now map the glaciers of Alaska:\ntm_shape(ak) +\n  tm_polygons() +\n  tm_layout(\n    title = \"Glaciers of Alaska\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 500, 1000),\n    position = c(\"right\", \"BOTTOM\")\n  )",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro to GIS mapping with R"
    ]
  },
  {
    "objectID": "r/ws_gis_intro.html#union-of-bounding-boxes",
    "href": "r/ws_gis_intro.html#union-of-bounding-boxes",
    "title": "Introduction to GIS with R",
    "section": "Union of bounding boxes",
    "text": "Union of bounding boxes\nNow, if we want to plot all the glaciers of Western North America, we want to combine both sf objects in the same map. A map can contain multiple shapes: you only need to ‚Äúadd‚Äù a tm_shape and its element(s). Before doing so however, it is very important to ensure that they have the same coordinate reference system (CRS):\nst_crs(ak)\nst_crs(wes)\n\nst_crs(ak) == st_crs(wes)\nThey do, so we are good to go.\n\nAs with ggplot2 or GIS graphical user interfaces, the order matters since the layers stack up on top of each other.\n\ntm_shape(ak) +\n  tm_polygons() +\n  tm_shape(wes) +\n  tm_polygons()\nIf you run the code above however, you may be surprised that you are still only plotting the map of Alaska.\nThis is because each map comes with a spatial bounding box (bbox).\nst_bbox(ak)\nst_bbox(wes)\nIn the code above, the bbox is set by the first shape, i.e.¬†our entire map uses the bbox of the Alaska sf object.\nWe first need to create a new bounding box encompassing both bounding boxes:\nnwa_bbox &lt;- st_bbox(\n  st_union(\n    st_as_sfc(st_bbox(wes)),\n    st_as_sfc(st_bbox(ak))\n  )\n)\nWe can now plot the glaciers of Western North America:\ntm_shape(ak, bbox = nwa_bbox) +\n  tm_polygons() +\n  tm_shape(wes) +\n  tm_polygons() +\n  tm_layout(\n    title = \"Glaciers of Western North America\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 1000, 2000),\n    position = c(\"right\", \"BOTTOM\")\n  )",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro to GIS mapping with R"
    ]
  },
  {
    "objectID": "r/ws_gis_intro.html#maps-based-on-an-attribute-variable",
    "href": "r/ws_gis_intro.html#maps-based-on-an-attribute-variable",
    "title": "Introduction to GIS with R",
    "section": "Maps based on an attribute variable",
    "text": "Maps based on an attribute variable\nWhat is interesting about glacier maps is to see their evolution through time as glaciers retreat due to climate change. While the Randolph Glacier Inventory (RGI) has an amazing map in terms of spacial coverage, it doesn‚Äôt yet have much temporal data.\nTo look at glacier retreat, we will look at the USGS time series of the named glaciers of Glacier National Park3. These 4 datasets have the contour lines of 39 glaciers for the years 1966, 1998, 2005, and 2015.\nWe could load and clean these datasets one by one. Copying and pasting code however is inefficient and error-prone. A better approach is to do this in a functional programming framework: create a function which does all the data loading and cleaning, then pass each element of a vector of the paths of all 4 datasets to it using purrr::map().\n‚ÄúCleaning‚Äù here consists of selecting the variables we are interested in, putting them in the same order in each dataset (they were not initially) and giving the exact same name across all datasets (there were case inconsistencies between datasets and R is case sensitive).\n# create a function that reads and cleans the data\nprep &lt;- function(dir) {\n  g &lt;- st_read(dir)\n  g %&lt;&gt;% rename_with(~ tolower(gsub(\"Area....\", \"area\", .x)))\n  g %&lt;&gt;% select(\n    year,\n    objectid,\n    glacname,\n    area,\n    shape_leng,\n    x_coord,\n    y_coord,\n    source_sca,\n    source\n  )\n}\n\n# create a vector of dataset names\ndirs &lt;- grep(\"GNPglaciers_.*\", list.dirs(), value = T)\n\n# pass each element of that vector through prep() thanks to map()\ngnp &lt;- map(dirs, prep)\nmap() returns a list, so we now have a list (gnp) of 4 elements: the 4 sf objects containing our cleaned datasets. A list is not really convenient and we will turn it into a single sf object.\nBefore doing so however, we want to make sure that they all have the same CRS:\nst_crs(gnp[[1]]) == st_crs(gnp[[2]])\nst_crs(gnp[[1]]) == st_crs(gnp[[3]])\nst_crs(gnp[[1]]) == st_crs(gnp[[4]])\nThey do, so we can turn gnp into a single sf object:\ngnp &lt;- do.call(\"rbind\", gnp)\n\ngnp\nstr(gnp)\nWe can now map the data:\ntm_shape(gnp) +\n  tm_polygons(\"year\", palette = \"Blues\") +\n  tm_layout(\n    title = \"Glaciers of Glacier National Park\",\n    title.position = c(\"center\", \"top\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 10, 20),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )\n\nI didn‚Äôt want to show the legend title and because there is no option to remove it, I set its color to that of the background.",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro to GIS mapping with R"
    ]
  },
  {
    "objectID": "r/ws_gis_intro.html#crs-transformation",
    "href": "r/ws_gis_intro.html#crs-transformation",
    "title": "Introduction to GIS with R",
    "section": "CRS transformation",
    "text": "CRS transformation\nWouldn‚Äôt it be nice to have this map as an inset of the previous map so that we can situate it within North America?\nBefore we can do this, we need to make sure that both maps use the same CRS:\nst_crs(ak)\nst_crs(gnp)\n\nWe could use wes instead of ak since we know that both sf objects have the same CRS.\n\nThey don‚Äôt have the same CRS, so we reproject gnp by transforming its data from its current CRS to that of ak.\ngnp &lt;- st_transform(gnp, st_crs(ak))\nst_crs(gnp)",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro to GIS mapping with R"
    ]
  },
  {
    "objectID": "r/ws_gis_intro.html#inset-map",
    "href": "r/ws_gis_intro.html#inset-map",
    "title": "Introduction to GIS with R",
    "section": "Inset map",
    "text": "Inset map\nNow we can create our map with an inset: the map of the Western North America glaciers (from the sf object nwa) will be our main map and the map of Glacier National Park (from the sf object gnp) will be the inset.\nIf the goal of this new map is to show the location of the gnp map within the nwa one, we need to add a rectangle showing the bounding box of gnp in the nwa map as a new layer.\nFor this, we create a new sfc_POLYGON from the bounding box of gnp:\ngnp_zone &lt;- st_bbox(gnp) %&gt;%\n  st_as_sfc()\nWe will use it as the following layer within the new map:\ntm_shape(gnp_zone) +\n  tm_borders(lwd = 1.5, col = \"#ff9900\")\nWe assign our new map (with an updated suitable title) to the object main_map:\nmain_map &lt;- tm_shape(ak, bbox = nwa_bbox) +\n  tm_polygons() +\n  tm_shape(wes) +\n  tm_polygons() +\n  tm_shape(gnp_zone) +\n  tm_borders(lwd = 1.5, col = \"#ff9900\") +\n  tm_layout(\n    title = \"Glaciers of Glacier National Park\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 500, 1000),\n    position = c(\"right\", \"BOTTOM\")\n  )\nNext, we will change the frame of the gnp inset to match the color of this new rectangle (to make it visually clear that this is a close-up view of that rectangle). We can also remove the title, compass and scale bar since this is an inset within a map which already have them. We assign this new map to the object inset_map:\ninset_map &lt;- tm_shape(gnp) +\n  tm_polygons(\"year\", palette = \"Blues\") +\n  tm_layout(\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 0.7,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.03, 0.03, 0.03, 0.03),\n    outer.margins = 0,\n    frame = \"#ff9900\",\n    frame.lwd = 3\n  )\nFinally, we combine the two maps with grid::viewport():\nmain_map\nprint(inset_map, vp = viewport(0.41, 0.26, width = 0.5, height = 0.5))",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro to GIS mapping with R"
    ]
  },
  {
    "objectID": "r/ws_gis_intro.html#tiled-web-maps-with-leaflet",
    "href": "r/ws_gis_intro.html#tiled-web-maps-with-leaflet",
    "title": "Introduction to GIS with R",
    "section": "Tiled web maps with Leaflet",
    "text": "Tiled web maps with Leaflet\nTiled web maps are interactive maps in a browser using web servers such as Google Maps or OpenStreetMap. Several packages allow to use Leaflet (an open-source JavaScript library for interactive maps) to create tile maps.\n\nWith mapview\nThe simplest option is to use mapview::mapview():\nmapview(gnp)\nThis will open a page in your browser in which you can pan, zoom, select/deselect data layers, and choose from a number of basemap layer options:\n\n\n\nCartoDB.Positron\n\n\n\n\n\nOpenTopoMap\n\n\n\n\n\nOpenStreetMap\n\n\n\n\n\nEsri.WorldImagery\n\n\n\n\nWith tmap\ntmap has similar capabilities.\nThe package has 2 modes:\n\nplot is the default mode for static maps that we used earlier.\nview is an interactive viewing mode using Leaflet in a browser. There, as with mapview, you can zoom in/out, select/deselect the different layers, and choose to display one of Esri.WorldGrayCanvas, OpenStreetMap, or Esri.WorldTopoMap basemaps.\n\nYou can toggle between the plot and view modes with ttm(), after which you can re-plot your last plot in the new mode with tmap_last(). You can also do both of these at once with ttmp().\nAlternatively, you can switch to either mode with tmap_mode(\"view\") and tmap_mode(\"plot\").\n\nExample:\n\nEarlier, we plotted all the glaciers of Western North America using tmap:\n\nAfter displaying this map, we could have run:\ntmap_mode(\"view\")\ntmap_last()\nAnd Leaflet would have open the following interactive map in our browser:\n\n\nAfterwards, if you want to create new static plots, don‚Äôt forget to get back to plot mode with tmap_mode(\"plot\").",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro to GIS mapping with R"
    ]
  },
  {
    "objectID": "r/ws_gis_intro.html#mapping-a-subset-of-the-data",
    "href": "r/ws_gis_intro.html#mapping-a-subset-of-the-data",
    "title": "Introduction to GIS with R",
    "section": "Mapping a subset of the data",
    "text": "Mapping a subset of the data\nEach glacier has 4 borders: one for each year of survey. They are however quite hard to see on such a large map.\nLet‚Äôs zoom on the Agassiz glacier:\n# select the data points corresponding to the Agassiz Glacier\nag &lt;- g %&gt;% filter(glacname == \"Agassiz Glacier\")\nAnd map it:\ntm_shape(ag) +\n  tm_polygons(\"year\", palette = \"Blues\") +\n  tm_layout(\n    title = \"Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )\n\nNow we can clearly see the retreat of the Agassiz Glacier between 1966 and 2015.",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro to GIS mapping with R"
    ]
  },
  {
    "objectID": "r/ws_gis_intro.html#faceted-map",
    "href": "r/ws_gis_intro.html#faceted-map",
    "title": "Introduction to GIS with R",
    "section": "Faceted map",
    "text": "Faceted map\nInstead of having all temporal data in a single map however, it can be split across facets:\ntm_shape(ag) +\n  tm_polygons(col = \"#86baff\") +\n  tm_layout(\n    main.title = \"Agassiz Glacier\",\n    main.title.position = c(\"center\", \"top\"),\n    main.title.size = 1.2,\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    # inner.margins = c(0, 0.03, 0, 0.03),\n    outer.margins = 0,\n    panel.label.bg.color = \"#fcfcfc\",\n    frame = F,\n    asp = 0.6\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 0.6\n  ) +\n  tm_facets(\n    by = \"year\",\n    free.coords = F,\n    ncol = 4\n  )",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro to GIS mapping with R"
    ]
  },
  {
    "objectID": "r/ws_gis_intro.html#animated-map",
    "href": "r/ws_gis_intro.html#animated-map",
    "title": "Introduction to GIS with R",
    "section": "Animated map",
    "text": "Animated map\nThe temporal data of the Agassiz Glacier retreat can also be conveyed through an animation:\nagassiz_anim &lt;- tm_shape(ag) +\n  tm_borders() +\n  tm_fill(col = \"#86baff\") +\n  tm_layout(\n    title = \"Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.08, 0, 0.08, 0),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  ) +\n  tm_facets(\n    along = \"year\",\n    free.coords = F\n  )\n\ntmap_animation(\n  agassiz_anim,\n  filename = \"ag.gif\",\n  dpi = 300,\n  inner.margins = c(0.08, 0, 0.08, 0),\n  delay = 100\n)",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro to GIS mapping with R"
    ]
  },
  {
    "objectID": "r/ws_gis_intro.html#additional-resources",
    "href": "r/ws_gis_intro.html#additional-resources",
    "title": "Introduction to GIS with R",
    "section": "Additional resources",
    "text": "Additional resources\nOpen GIS data:\nFree GIS Data: list of free GIS datasets\nBooks\nGeocomputation with R by Robin Lovelace, Jakub Nowosad, and Jannes Muenchow\nSpatial Data Science by Edzer Pebesma, Roger Bivand\nSpatial Data Science with R by Robert J. Hijmans\nUsing Spatial Data with R by Claudia A. Engel\nTutorial\nAn Introduction to Spatial Data Analysis and Visualisation in R by the CDRC\nWebsite\nr-spatial by Edzer Pebesma, Marius Appel, and Daniel N√ºst\nCRAN package list\nAnalysis of Spatial Data\nMailing list\nR Special Interest Group on using Geographical data and Mapping",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro to GIS mapping with R"
    ]
  },
  {
    "objectID": "r/ws_gis_intro.html#footnotes",
    "href": "r/ws_gis_intro.html#footnotes",
    "title": "Introduction to GIS with R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRGI Consortium (2017). Randolph Glacier Inventory ‚Äì A Dataset of Global Glacier Outlines: Version 6.0: Technical Report, Global Land Ice Measurements from Space, Colorado, USA. Digital Media. DOI: https://doi.org/10.7265/N5-RGI-60.‚Ü©Ô∏é\nFagre, D.B., McKeon, L.A., Dick, K.A., and Fountain, A.G., 2017, Glacier margin time series (1966, 1998, 2005, 2015) of the named glaciers of Glacier National Park, MT, USA: U.S. Geological Survey data release, https://doi.org/10.5066/F7P26WB1.‚Ü©Ô∏é\nFagre, D.B., McKeon, L.A., Dick, K.A., and Fountain, A.G., 2017, Glacier margin time series (1966, 1998, 2005, 2015) of the named glaciers of Glacier National Park, MT, USA: U.S. Geological Survey data release, https://doi.org/10.5066/F7P26WB1.‚Ü©Ô∏é",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro to GIS mapping with R"
    ]
  },
  {
    "objectID": "r/ws_demo_content.html",
    "href": "r/ws_demo_content.html",
    "title": "A little demo of programming in",
    "section": "",
    "text": "Content from the workshop slides for easier browsing."
  },
  {
    "objectID": "r/ws_demo_content.html#a-few-words-about-r",
    "href": "r/ws_demo_content.html#a-few-words-about-r",
    "title": "A little demo of programming in",
    "section": "A few words about R",
    "text": "A few words about R\n\nHistory\nCreated by academic statisticians Ross Ihaka and Robert Gentleman\nThe name comes from the language S which was a great influence as well as the first initial of the developers\nLaunched in 1993\nA GNU Project since 1997\n\n\nWhy R?\nFree and open source\nHigh-level and easy to learn\nLarge community\nVery well documented\nUnequalled number of statistics and modelling packages\nIntegrated package manager\nEasy connection with fast compiled languages such as C and C++\nPowerful IDEs (e.g.¬†RStudio, ESS, Jupyter)\n\n\nFor whom?\nFields with heavy statistics, modelling, or Bayesian inference such as biology, linguistics, economics, or statistics\nData science\n\n\nDownsides\nInconsistent syntax full of quirks\nSlow\nLarge memory usage"
  },
  {
    "objectID": "r/ws_demo_content.html#running-r",
    "href": "r/ws_demo_content.html#running-r",
    "title": "A little demo of programming in",
    "section": "Running R",
    "text": "Running R\n\nAn interpreted language\nR being an interpreted language, it can be run non-interactively or interactively\n\n\nRunning R non-interactively\nIf you write code in a text file (called a script), you can then execute it with:\nRscript my_script.R\n\nThe command to execute scripts is Rscript rather than R\nBy convention, R scripts take the extension .R\n\n\n\nRunning R interactively\nThere are several ways to run R interactively:\n\ndirectly in the console (the name for the R shell)\nin Jupyter with the R kernel (IRkernel package)\nin another IDE (e.g.¬†in Emacs with ESS)\nin the RStudio IDE\n\n\nThe R console\n\n\n\nRStudio\nPosit (formerly RStudio Inc.) developed a great and very popular IDE called RStudio\nHere is its cheatsheet (click on it to download it):\n\n\n\nfrom Posit Cheatsheets"
  },
  {
    "objectID": "r/ws_demo_content.html#a-few-basics",
    "href": "r/ws_demo_content.html#a-few-basics",
    "title": "A little demo of programming in",
    "section": "A few basics",
    "text": "A few basics\n\nDocumentation\nThe R documentation is excellent. Get info on any function with ? (e.g.¬†?sum)\n\n\nBasic operations\n\na &lt;- 5\nc &lt;- c(2, 4, 1)\nc * 5\n\n[1] 10 20  5\n\nsum(c)\n\n[1] 7\n\n\n\n\nStatistics, probabilities, and modelling\nR really shines when it comes to statistics and modelling\nWe will spend the rest of the hour diving into very complex and heavy Bayesian statistics\n\n\nJust kidding üôÇ\nIn this demo, I will stick to fun topics"
  },
  {
    "objectID": "r/ws_demo_content.html#data-visualization",
    "href": "r/ws_demo_content.html#data-visualization",
    "title": "A little demo of programming in",
    "section": "Data visualization",
    "text": "Data visualization\n\nDatasets\nR comes with a number of datasets. You can get a list by running data()\nThe ggplot2 package provides additional ones, such as the mpg dataset:\n\nlibrary(ggplot2)\nhead(mpg, 4)  # we are printing only the first 4 rows\n\n# A tibble: 4 √ó 11\n  manufacturer model displ  year   cyl trans      drv     cty   hwy fl   \n  &lt;chr&gt;        &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;\n1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p    \n2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p    \n3 audi         a4      2    2008     4 manual(m6) f        20    31 p    \n4 audi         a4      2    2008     4 auto(av)   f        21    30 p    \n  class  \n  &lt;chr&gt;  \n1 compact\n2 compact\n3 compact\n4 compact\n\n\n\n\nThe canvas\nThe first component is the data:\n\nggplot(data = mpg)\n\n\n\n\n\n\n\n\nThe second component sets the way variables are mapped on the axes. This is done with the aes() (aesthetics) function:\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy))\n\n\n\n\n\n\n\n\n\n\nGeometric representations of the data\nOnto this canvas, we can add ‚Äúgeoms‚Äù (geometrical objects) representing the data.\nTo represent the data as a scatterplot, we use the geom_point() function:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\nColour-coding based on variables\nWe can colour-code the points in the scatterplot based on the drv variable, showing the lower fuel efficiency of 4WD vehicles:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv))\n\n\n\n\n\n\n\n\nOr we can colour-code them based on the class variable:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class))\n\n\n\n\n\n\n\n\n\n\nMultiple geoms\nMultiple ‚Äúgeoms‚Äù can be added on top of each other. For instance, we can add a smoothed conditional means function that aids at seeing patterns in the data with geom_smooth():\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe default smoothing function uses the LOESS (locally estimated scatterplot smoothing) method. We can change the method by passing it as an argument to geom_smooth():\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nWe can apply the smoothing function to each class instead of the entire data. It creates a busy plot but shows that the downward trend remains true within each type of car:\n\nggplot(mpg, aes(x = displ, y = hwy, color = class)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nWe can remove the standard errors and customize the line for our linear model:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(\n    method = lm,\n    se = FALSE,\n    color = \"#999999\",\n    linewidth = 0.5\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nColour scales\n\nLet‚Äôs try the Dark2 palette:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  geom_smooth(\n    method = lm,\n    se = FALSE,\n    color = \"#999999\",\n    linewidth = 0.5\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nWe can add title, axes labels, captions‚Ä¶\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  geom_smooth(\n    method = lm,\n    se = FALSE,\n    color = \"#999999\",\n    linewidth = 0.5\n  ) +\n  labs(\n    title = \"Fuel consumption per engine size on highways\",\n    x = \"Engine size (L)\",\n    y = \"Fuel economy (mpg) on highways\",\n    color = \"Type of car\",\n    caption = \"EPA data from https://fueleconomy.gov/\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nLet‚Äôs change the theme to remove all this background noise:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\ngeom_point(aes(color = class)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  geom_smooth(\n    method = lm,\n    se = FALSE,\n    color = \"#999999\",\n    linewidth = 0.5\n  ) +\n  labs(\n    title = \"Fuel consumption per engine size on highways\",\n    x = \"Engine size (L)\",\n    y = \"Fuel economy (mpg) on highways\",\n    color = \"Type of car\",\n    caption = \"EPA data from https://fueleconomy.gov/\"\n  ) +\n  theme_classic()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe theme() function allows to tweak the theme in any number of ways. For instance, what if we don‚Äôt like the default position of the title and we‚Äôd rather have it centered?\n\nggplot(mpg, aes(x = displ, y = hwy)) +\ngeom_point(aes(color = class)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  geom_smooth(\n    method = lm,\n    se = FALSE,\n    color = \"#999999\",\n    linewidth = 0.5\n  ) +\n  labs(\n    title = \"Fuel consumption per engine size on highways\",\n    x = \"Engine size (L)\",\n    y = \"Fuel economy (mpg) on highways\",\n    color = \"Type of car\",\n    caption = \"EPA data from https://fueleconomy.gov/\"\n  ) +\n  theme_classic() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nMany things can be changed thanks to the theme() function. For instance, we can move the legend to give more space to the actual graph:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\ngeom_point(aes(color = class)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  geom_smooth(\n    method = lm,\n    se = FALSE,\n    color = \"#999999\",\n    linewidth = 0.5\n  ) +\n  labs(\n    title = \"Fuel consumption per engine size on highways\",\n    x = \"Engine size (L)\",\n    y = \"Fuel economy (mpg) on highways\",\n    color = \"Type of car\",\n    caption = \"EPA data from https://fueleconomy.gov/\"\n  ) +\n  theme_classic() +\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"bottom\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nggplot extensions\nMany packages build on ggplot2 and add functionality\n\n\nCombining plots\nOne ggplot extension is the patchwork package which allows to combine multiple plots on the same frame\nLet‚Äôs add a second plot next to our plot (we also make a few changes to the labels to improve the plots integration):\n\nlibrary(patchwork)\n\nggplot(mpg, aes(x = displ, y = hwy)) +        # First plot\n  geom_point(aes(color = class)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  geom_smooth(\n    method = lm,\n    se = FALSE,\n    color = \"#999999\",\n    linewidth = 0.5\n  ) +\n  labs(\n    x = \"Engine size (L)\",\n    y = \"Fuel economy (mpg) on highways\",\n    color = \"Type of car\"\n  ) +\n  theme_classic() +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    legend.position = c(0.7, 0.75),           # Better legend position\n    legend.background = element_rect(         # Add a frame to the legend\n      linewidth = 0.1,\n      linetype = \"solid\",\n      colour = \"black\"\n    )\n  ) +\n  ggplot(mpg, aes(x = displ, y = hwy)) +      # Second plot\n  geom_point(aes(color = drv)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(\n    x = \"Engine size (L)\",\n    y = element_blank(),                      # Remove redundant label\n    color = \"Type of drive train\",\n    caption = \"EPA data from https://fueleconomy.gov/\"\n  ) +\n  theme_classic() +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    legend.position = c(0.7, 0.87),\n    legend.background = element_rect(\n      linewidth = 0.1,\n      linetype = \"solid\",\n      colour = \"black\"\n    )\n  )\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\n‚Ñπ Please use the `legend.position.inside` argument of `theme()` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "r/ws_demo_content.html#web-scraping",
    "href": "r/ws_demo_content.html#web-scraping",
    "title": "A little demo of programming in",
    "section": "Web scraping",
    "text": "Web scraping\n\nHTML and CSS\nHyperText Markup Language (HTML) is the standard markup language for websites: it encodes the information related to the formatting and structure of webpages. Additionally, some of the customization can be stored in Cascading Style Sheets (CSS) files.\nHTML uses tags of the form:\n&lt;some_tag&gt;Your content&lt;/some_tag&gt;\nSome tags have attributes:\n&lt;some_tag attribute_name=\"attribute value\"&gt;Your content&lt;/some_tag&gt;\n\nExamples:\n\n\n&lt;h2&gt;This is a heading of level 2&lt;/h2&gt;\n&lt;b&gt;This is bold&lt;/b&gt;\n&lt;a href=\"https://some.url\"&gt;This is the text for a link&lt;/a&gt;\n\n\n\nExample for this workshop\nWe will use a website from the University of Tennessee containing a database of PhD theses from that university\nOur goal is to scrape data from this site to produce a dataframe with the date, major, and advisor for each dissertation\n\nWe will only do this for the first page which contains the links to the 100 most recent theses. If you really wanted to gather all the data, you would have to do this for all pages\n\n\n\nPackage\nTo do all this, we will use the package rvest, part of the tidyverse (a modern set of R packages). It is a package influenced by the popular Python package Beautiful Soup and it makes scraping websites with R really easy\nLet‚Äôs load it:\n\nlibrary(rvest)\n\n\n\nRead in HTML from main site\nAs mentioned above, our site is the database of PhD dissertations from the University of Tennessee\nLet‚Äôs create a character vector with the URL:\n\nurl &lt;- \"https://trace.tennessee.edu/utk_graddiss/index.html\"\n\nFirst, we read in the html data from that page:\n\nhtml &lt;- read_html(url)\n\nLet‚Äôs have a look at the raw data:\n\nhtml\n\n{html_document}\n&lt;html lang=\"en\"&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] &lt;body&gt;\\n&lt;!-- FILE /srv/sequoia/main/data/trace.tennessee.edu/assets/heade ...\n\n\n\n\nExtract all URLs\n\ndat &lt;- html %&gt;% html_elements(\".article-listing a\")\ndat[1:6]\n\n{xml_nodeset (6)}\n[1] &lt;a href=\"https://trace.tennessee.edu/utk_graddiss/12328\"&gt;Essays in Macroe ...\n[2] &lt;a href=\"https://trace.tennessee.edu/utk_graddiss/12671\"&gt;UNDERSTANDING AN ...\n[3] &lt;a href=\"https://trace.tennessee.edu/utk_graddiss/12672\"&gt;Soil Nitrous Oxi ...\n[4] &lt;a href=\"https://trace.tennessee.edu/utk_graddiss/12329\"&gt;CHARACTERIZATION ...\n[5] &lt;a href=\"https://trace.tennessee.edu/utk_graddiss/12330\"&gt;View from the To ...\n[6] &lt;a href=\"https://trace.tennessee.edu/utk_graddiss/12331\"&gt;Exploration of V ...\n\n\nWe now have a list of lists\nBefore running for loops, it is important to initialize empty loops. It is much more efficient than growing the result at each iteration\nSo let‚Äôs initialize an empty list that we call list_urls of the appropriate size:\n\nlist_urls &lt;- vector(\"list\", length(dat))\n\nNow we can run a loop to fill in our list:\n\nfor (i in seq_along(dat)) {\n  list_urls[[i]] &lt;- dat[[i]] %&gt;% html_attr(\"href\")\n}\n\nLet‚Äôs print again the first element of list_urls to make sure all looks good:\n\nlist_urls[[1]]\n\n[1] \"https://trace.tennessee.edu/utk_graddiss/12328\"\n\n\nWe now have a list of URLs (in the form of character vectors) as we wanted\n\n\nExtract data from each page\nWe will now extract the data (date, major, and advisor) for all URLs in our list.\nAgain, before running a for loop, we need to allocate memory first by creating an empty container (here a list):\n\nlist_data &lt;- vector(\"list\", length(list_urls))\n\nfor (i in seq_along(list_urls)) {\n  html &lt;- read_html(list_urls[[i]])\n  date &lt;- html %&gt;%\n    html_element(\"#publication_date p\") %&gt;%\n    html_text2()\n  major &lt;- html %&gt;%\n    html_element(\"#department p\") %&gt;%\n    html_text2()\n  advisor &lt;- html %&gt;%\n    html_element(\"#advisor1 p\") %&gt;%\n    html_text2()\n  Sys.sleep(0.1)  # Add a little delay\n  list_data[[i]] &lt;- cbind(date, major, advisor)\n}\n\n\n\nStore results in DataFrame\nWe can turn this big list into a dataframe:\n\nresult &lt;- do.call(rbind.data.frame, list_data)\n\nWe can capitalize the headers:\n\nnames(result) &lt;- c(\"Date\", \"Major\", \"Advisor\")\n\n\n\nOur final data\nresult is a long dataframe, so we will only print the first few elements:\n\nhead(result, 6)\n\n    Date                                           Major               Advisor\n1 5-2025                                       Economics     Andrew, S, Hanson\n2 8-2025                               Civil Engineering Nicholas E. Wierschem\n3 8-2025          Plant, Soil and Environmental Sciences         Debasish Saha\n4 5-2025 Biochemistry and Cellular and Molecular Biology              Jae Park\n5 5-2025                 Higher Education Administration       Pamella Angelle\n6 5-2025                                            &lt;NA&gt;        Andrea S. Lear\n\n\n\n\nSave results to file\nIf we wanted, we could save our data to a CSV file:\nwrite.csv(result, \"dissertations_data.csv\", row.names = FALSE)"
  },
  {
    "objectID": "r/ws_demo_content.html#gis-mapping",
    "href": "r/ws_demo_content.html#gis-mapping",
    "title": "A little demo of programming in",
    "section": "GIS mapping",
    "text": "GIS mapping\n\nImage credit: Sz≈±cs R√≥bert, Grasshopper Geography\n\n\nData reading and manipulation\n\nSpatial vectors: great modern packages are sf or terra\nRaster data: the package terra\n\nI will skip the data preparation due to lack of time, but you can look at the code in this webinar or this workshop\n\n\nMapping data\nGood options to create maps include ggplot2 (the package we already used for plotting) or tmap\n\n\nMap of glaciers in western North America\ntm_shape(states, bbox = nwa_bbox) +\n  tm_polygons(col = \"#f2f2f2\", lwd = 0.2) +\n  tm_shape(ak) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_shape(wes) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_layout(\n    title = \"Glaciers of Western North America\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 1000, 2000),\n    position = c(\"right\", \"BOTTOM\")\n  )\n\n\n\n\n\n\n\nMulti-layer map of the retreat of a glacier\ntm_shape(ag) +\n  tm_polygons(\"year\", palette = \"Blues\") +\n  tm_layout(\n    title = \"Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )\n\n\n\n\n\n\n\nAnimated map of the retreat of a glacier\n{.r} tmap_animation(tm_shape(ag) +                  tm_polygons(col = \"#86baff\") +                  tm_layout(                    title = \"Agassiz Glacier\",                    title.position = c(\"center\", \"top\"),                    legend.position = c(\"left\", \"bottom\"),                    legend.title.color = \"#fcfcfc\",                    legend.text.size = 1,                    bg.color = \"#fcfcfc\",                    inner.margins = c(0.08, 0, 0.08, 0),                    outer.margins = 0,                    panel.label.bg.color = \"#fcfcfc\"                  ) +                  tm_compass(                    type = \"arrow\",                    position = c(\"right\", \"top\"),                    text.size = 0.7                  ) +                  tm_scale_bar(                    breaks = c(0, 0.5, 1),                    position = c(\"right\", \"BOTTOM\"),                    text.size = 1                  ) +                  tm_facets(                    along = \"year\",                    free.coords = F                  )filename = \"ag.gif\",                dpi = 300,                inner.margins = c(0.08, 0, 0.08, 0),                delay = 100\n\n\n\n\n\n\n\nRegular R training\nEach region under the Alliance offers regular courses and workshops in R (and many other topics)\nIn the west, Alex Razoumov and myself offer regular free workshops, courses, and webinars for researchers in Canadian academic institutions\nYou can find our program here or join our mailing list here"
  },
  {
    "objectID": "r/wb_hpc_slides.html#intel-vs-gcc-compilers",
    "href": "r/wb_hpc_slides.html#intel-vs-gcc-compilers",
    "title": "High-performance research computing in ",
    "section": "Intel vs GCC compilers",
    "text": "Intel vs GCC compilers\nTo compile R packages, you need a C compiler.\nIn theory, you could use the proprietary Intel compiler which is loaded by default on the Alliance clusters, but it is recommended to replace it with the GCC compiler (R packages can even be compiled with Clang and LLVM, but the default GCC compiler is the best way to avoid headaches).\nIt is thus much simpler to always load a gcc module before loading an r module."
  },
  {
    "objectID": "r/wb_hpc_slides.html#r-module",
    "href": "r/wb_hpc_slides.html#r-module",
    "title": "High-performance research computing in ",
    "section": "R module",
    "text": "R module\nTo see what versions of R are available on a cluster, run:\nmodule spider r\nTo see the dependencies of a particular version (e.g.¬†r/4.2.1), run:\nmodule spider r/4.2.1\n\nStdEnv/2020 is a required module for this version.\nOn most Alliance clusters, it is automatically loaded, so you don‚Äôt need to include it. You can double-check with module list or you can include it (before r/4.2.1) just to be sure.\n\nFinally, load your modules:\nmodule load StdEnv/2020 gcc/11.3.0 r/4.2.1"
  },
  {
    "objectID": "r/wb_hpc_slides.html#scripts",
    "href": "r/wb_hpc_slides.html#scripts",
    "title": "High-performance research computing in ",
    "section": "Scripts",
    "text": "Scripts\nTo run an R script called &lt;your_script&gt;.R, you first need to write a job script:\n\nExample:\n\n\n&lt;your_job&gt;.sh\n\n#!/bin/bash\n#SBATCH --account=def-&lt;your_account&gt;\n#SBATCH --time=15\n#SBATCH --mem-per-cpu=3000M\n#SBATCH --cpus-per-task=4\n#SBATCH --job-name=\"&lt;your_job&gt;\"\nmodule load StdEnv/2020 gcc/11.3.0 r/4.2.1\nRscript &lt;your_script&gt;.R   # Note that R scripts are run with the command `Rscript`\n\n\nThen launch your job with:\nsbatch &lt;your_job&gt;.sh\nYou can monitor your job with sq (an alias for squeue -u $USER $@)."
  },
  {
    "objectID": "r/wb_hpc_slides.html#interactive-jobs",
    "href": "r/wb_hpc_slides.html#interactive-jobs",
    "title": "High-performance research computing in ",
    "section": "Interactive jobs",
    "text": "Interactive jobs\n\nWhile it is fine to run R on the login node when you install packages, you must start a SLURM job before any heavy computation.\n\nTo run R interactively, you should launch an salloc session.\nHere is what I will use for this webinar:\nsalloc --time=1:10:00 --mem-per-cpu=7000M --ntasks=8\nThis takes me to a compute node where I can launch R to run computations:\nR"
  },
  {
    "objectID": "r/wb_hpc_slides.html#profiling",
    "href": "r/wb_hpc_slides.html#profiling",
    "title": "High-performance research computing in ",
    "section": "Profiling",
    "text": "Profiling\nThe first thing to do if you want to improve your code efficiency is to identify bottlenecks in your code. Common tools are:\n\nthe base R function Rprof()\nthe package profvis\n\nprofvis is a newer tool, built by posit (formerly RStudio). Under the hood, it runs Rprof() to collect data, then produces an interactive html widget with a flame graph that allows for an easy visual identification of slow sections of code. While this tool integrates well within the RStudio IDE or the RPubs ecosystem, it is not very well suited for remote work on a cluster. One option is to profile your code with small data on your own machine. Another option is to use the base profiler with Rprof() directly as in this example."
  },
  {
    "objectID": "r/wb_hpc_slides.html#benchmarking",
    "href": "r/wb_hpc_slides.html#benchmarking",
    "title": "High-performance research computing in ",
    "section": "Benchmarking",
    "text": "Benchmarking\nOnce you have identified expressions that are particularly slow, you can use benchmarking tools to compare variations of the code.\nIn the most basic fashion, you can use system.time(), but this is limited and imprecise.\nThe microbenchmark package is a popular option.\nIt gives the minimum time, lower quartile, mean, median, upper quartile, and maximum time of R expressions.\nThe newer bench package has less overhead, is more accurate, and‚Äîfor sequential code‚Äîgives information on memory usage and garbage collections. This is the package I will use today."
  },
  {
    "objectID": "r/wb_hpc_slides.html#multi-threading",
    "href": "r/wb_hpc_slides.html#multi-threading",
    "title": "High-performance research computing in ",
    "section": "Multi-threading",
    "text": "Multi-threading\nWe talk about multi-threading when a single process (with its own memory) runs multiple threads.\nThe execution can happen in parallel‚Äîif each thread has access to a CPU core‚Äîor by alternating some of the threads on some CPU cores.\nBecause all threads in a process write to the same memory addresses, multi-threading can lead to race conditions.\nMulti-threading does not seem to be a common approach to parallelizing R code."
  },
  {
    "objectID": "r/wb_hpc_slides.html#multi-processing-in-shared-memory",
    "href": "r/wb_hpc_slides.html#multi-processing-in-shared-memory",
    "title": "High-performance research computing in ",
    "section": "Multi-processing in shared memory",
    "text": "Multi-processing in shared memory\nMulti-processing in shared memory happens when multiple processes execute code on multiple CPU cores of a single node (or a single machine).\nThe different processes need to communicate with each other, but because they are all running on the CPU cores of a single node, messages can pass via shared memory."
  },
  {
    "objectID": "r/wb_hpc_slides.html#multi-processing-in-distributed-memory",
    "href": "r/wb_hpc_slides.html#multi-processing-in-distributed-memory",
    "title": "High-performance research computing in ",
    "section": "Multi-processing in distributed memory",
    "text": "Multi-processing in distributed memory\nWhen processes involved in the execution of some code run on multiple nodes of a cluster, messages between them need to travel over the cluster interconnect. In that case, we talk about distributed memory."
  },
  {
    "objectID": "r/wb_hpc_slides.html#package-parallel-base-r",
    "href": "r/wb_hpc_slides.html#package-parallel-base-r",
    "title": "High-performance research computing in ",
    "section": "Package parallel (base R)",
    "text": "Package parallel (base R)\nThe parallel package has been part of the ‚Äúbase‚Äù package group since version 2.14.0.\nThis means that it is comes with R.\nMost parallel approaches in R build on this package.\nWe will make use of it to create and close an ad-hoc cluster.\n\nThe parallelly package adds functionality to the parallel package."
  },
  {
    "objectID": "r/wb_hpc_slides.html#package-foreach",
    "href": "r/wb_hpc_slides.html#package-foreach",
    "title": "High-performance research computing in ",
    "section": "Package foreach",
    "text": "Package foreach\nThe foreach package implements a looping construct without an explicit counter. It doesn‚Äôt require the preallocation of an output container, it brings to R an equivalent of the Python or Julia list comprehensions, and mostly, it allows for an easy execution of loops in parallel. Unlike loops, it creates variables (loops are used for their side-effect).\nLet‚Äôs look at an example to calculate the sum of 1e4 random vectors of length 3.\nWe will use foreach and iterators (which creates convenient iterators for foreach):\n\nlibrary(foreach)\nlibrary(iterators)"
  },
  {
    "objectID": "r/wb_hpc_slides.html#package-future",
    "href": "r/wb_hpc_slides.html#package-future",
    "title": "High-performance research computing in ",
    "section": "Package future",
    "text": "Package future\nA future is an object that acts as an abstract representation for a value in the future. A future can be resolved (if the value has been computed) or unresolved. If the value is queried while the future is unresolved, the process is blocked until the future is resolved.\nFutures allow for asynchronous and parallel evaluations. The future package provides a simple and unified API to evaluate futures."
  },
  {
    "objectID": "r/wb_hpc_slides.html#plans",
    "href": "r/wb_hpc_slides.html#plans",
    "title": "High-performance research computing in ",
    "section": "Plans",
    "text": "Plans\nThe future package does this thanks to the plan function:\n\nplan(sequential): futures are evaluated sequentially in the current R session\nplan(multisession): futures are evaluated by new R sessions spawned in the background (multi-processing in shared memory)\nplan(multicore): futures are evaluated in processes forked from the existing process (multi-processing in shared memory)\nplan(cluster): futures are evaluated on an ad-hoc cluster (allows for distributed parallelism across multiple nodes)"
  },
  {
    "objectID": "r/wb_hpc_slides.html#consistency",
    "href": "r/wb_hpc_slides.html#consistency",
    "title": "High-performance research computing in ",
    "section": "Consistency",
    "text": "Consistency\nTo ensure a consistent behaviour across plans, all evaluations are done in a local environment:\n\nlibrary(future)\n\na &lt;- 1\n\nb %&lt;-% {\n  a &lt;- 2\n}\n\na\n\n[1] 1"
  },
  {
    "objectID": "r/wb_hpc_slides.html#lets-return-to-our-example",
    "href": "r/wb_hpc_slides.html#lets-return-to-our-example",
    "title": "High-performance research computing in ",
    "section": "Let‚Äôs return to our example",
    "text": "Let‚Äôs return to our example\nWe had:\nset.seed(2)\nresult2 &lt;- foreach(icount(1e4), .combine = '+') %do% runif(3)\nWe can replace %do% with %dopar%:\nset.seed(2)\nresult3 &lt;- foreach(icount(1e4), .combine = '+') %dopar% runif(3)\nSince we haven‚Äôt registered any parallel backend, the expression will still be evaluated sequentially."
  },
  {
    "objectID": "r/wb_hpc_slides.html#load-packages",
    "href": "r/wb_hpc_slides.html#load-packages",
    "title": "High-performance research computing in ",
    "section": "Load packages",
    "text": "Load packages\nFor this toy example, I will use a modified version of one of the examples in the foreach vignette: I will b uild a classification model made of a forest of decision trees thanks to the randomForest package.\nBecause the code includes randomly generated numbers, I will use the doRNG package which replaces foreach::%dopar% wit h doRNG::%dorng%. This follows the recommendations of Pierre L‚ÄôEcuyer (1999)1 and ensures reproducibility.\nlibrary(doFuture)       # This will also load the `future` package\nlibrary(doRNG)          # This will also load the `foreach` package\nlibrary(randomForest)\nlibrary(bench)          # To do some benchmarking\nLoading required package: foreach\nLoading required package: future\nLoading required package: rngtools\nL‚ÄôEcuyer, P. (1999). Good parameters and implementations for combined multiple recursive random number generators. Operations Research, 47, 159‚Äì164."
  },
  {
    "objectID": "r/wb_hpc_slides.html#the-code-to-parallelize",
    "href": "r/wb_hpc_slides.html#the-code-to-parallelize",
    "title": "High-performance research computing in ",
    "section": "The code to parallelize",
    "text": "The code to parallelize\nThe goal is to create a classifier based on some data (here a matrix of random numbers for simplicity) and a response variable (as factor). This model could then be passed in the predict() function with novel data to generate predictions of classification. But here we are only interested in the creation of the model as this is the part that is computationally intensive. We aren‚Äôt interested in actually using it.\nset.seed(11)\ntraindata &lt;- matrix(runif(1e5), 100)\nfac &lt;- gl(2, 50)\n\nrf &lt;- foreach(ntree = rep(250, 8), .combine = combine) %do%\n  randomForest(x = traindata, y = fac, ntree = ntree)\n\nrf\nCall:\n randomForest(x = traindata, y = fac, ntree = ntree)\n               Type of random forest: classification\n                     Number of trees: 2000\nNo. of variables tried at each split: 31"
  },
  {
    "objectID": "r/wb_hpc_slides.html#reference-timing",
    "href": "r/wb_hpc_slides.html#reference-timing",
    "title": "High-performance research computing in ",
    "section": "Reference timing",
    "text": "Reference timing\nThis is the non parallelizable code with %do%:\ntref &lt;- mark(\n  rf1 &lt;- foreach(ntree = rep(250, 8), .combine = combine) %do%\n    randomForest(x = traindata, y = fac, ntree = ntree),\n  memory = FALSE\n)\n\ntref$median\n[1] 5.66s"
  },
  {
    "objectID": "r/wb_hpc_slides.html#plan-sequential",
    "href": "r/wb_hpc_slides.html#plan-sequential",
    "title": "High-performance research computing in ",
    "section": "Plan sequential",
    "text": "Plan sequential\nThis is the parallelizable foreach code, but run sequentially:\nregisterDoFuture()   # Set the parallel backend\nplan(sequential)     # Set the evaluation strategy\n\n# Using bench::mark()\ntseq &lt;- mark(\n  rf2 &lt;- foreach(ntree = rep(250, 8), .combine = combine) %dorng%\n    randomForest(x = traindata, y = fac, ntree = ntree),\n  memory = FALSE\n)\n\ntseq$median\n[1] 5.78s\n\nNo surprise: those are similar."
  },
  {
    "objectID": "r/wb_hpc_slides.html#multi-processing-in-shared-memory-1",
    "href": "r/wb_hpc_slides.html#multi-processing-in-shared-memory-1",
    "title": "High-performance research computing in ",
    "section": "Multi-processing in shared memory",
    "text": "Multi-processing in shared memory\nfuture provides availableCores() to detect the number of available cores:\navailableCores()\nsystem\n     4\n\nSimilar to parallel::detectCores().\n\nThis detects the number of CPU cores available to me on the current compute node, that is, what I can use for shared memory multi-processing."
  },
  {
    "objectID": "r/wb_hpc_slides.html#plan-multisession",
    "href": "r/wb_hpc_slides.html#plan-multisession",
    "title": "High-performance research computing in ",
    "section": "Plan multisession",
    "text": "Plan multisession\nShared memory multi-processing can be run with plan(multisession) that will spawn new R sessions in the background to evaluate futures:\nplan(multisession)\n\ntms &lt;- mark(\n  rf2 &lt;- foreach(ntree = rep(250, 8), .combine = combine) %dorng%\n    randomForest(x = traindata, y = fac, ntree = ntree),\n  memory = FALSE\n)\n\ntms$median\n[1] 2s\n\nWe got a speedup of 5.78 / 2 = 2.9."
  },
  {
    "objectID": "r/wb_hpc_slides.html#plan-multicore",
    "href": "r/wb_hpc_slides.html#plan-multicore",
    "title": "High-performance research computing in ",
    "section": "Plan multicore",
    "text": "Plan multicore\nShared memory multi-processing can also be run with plan(multicore) (except on Windows) that will fork the current R process to evaluate futures:\nplan(multicore)\n\ntmc &lt;- mark(\n  rf2 &lt;- foreach(ntree = rep(250, 8), .combine = combine) %dorng%\n    randomForest(x = traindata, y = fac, ntree = ntree),\n  memory = FALSE\n)\n\ntmc$median\n[1] 1.9s\n\nWe got a very similar speedup of 5.78 / 1.9 = 3.0."
  },
  {
    "objectID": "r/wb_hpc_slides.html#multi-processing-in-distributed-memory-1",
    "href": "r/wb_hpc_slides.html#multi-processing-in-distributed-memory-1",
    "title": "High-performance research computing in ",
    "section": "Multi-processing in distributed memory",
    "text": "Multi-processing in distributed memory\nI requested 8 tasks from Slurm on a training cluster made of nodes with 4 CPU cores each. Let‚Äôs verify that I got them by accessing the SLURM_NTASKS environment variable from within R:\nas.numeric(Sys.getenv(\"SLURM_NTASKS\"))\n[1] 8\nI can create a character vector with the name of the node each task is running on:\n(hosts &lt;- system(\"srun hostname | cut -f 1 -d '.'\", intern = TRUE))\nchr [1:8] \"node1\" \"node1\" \"node1\" \"node1\" \"node2\" \"node2\" \"node2\" \"node2\"\nThis allows me to create a cluster of workers:\n(cl &lt;- parallel::makeCluster(hosts))      # Defaults to type=\"PSOCK\"\nsocket cluster with 8 nodes on hosts ‚Äònode1‚Äô, ‚Äònode2‚Äô"
  },
  {
    "objectID": "r/wb_hpc_slides.html#plan-cluster",
    "href": "r/wb_hpc_slides.html#plan-cluster",
    "title": "High-performance research computing in ",
    "section": "Plan cluster",
    "text": "Plan cluster\nI can now try the code with distributed parallelism using all 8 CPU cores across both nodes:\nplan(cluster, workers = cl)\n\ntdis &lt;- mark(\n  rf2 &lt;- foreach(ntree = rep(250, 8), .combine = combine) %dorng%\n    randomForest(x = traindata, y = fac, ntree = ntree),\n  memory = FALSE\n)\n\ntdis$median\n[1] 1.14s\n\nSpeedup: 5.78 / 1.14 = 5.1.\n\nThe cluster of workers can be stopped with:\nparallel::stopCluster(cl)"
  },
  {
    "objectID": "r/wb_hpc_slides.html#alternative-approaches",
    "href": "r/wb_hpc_slides.html#alternative-approaches",
    "title": "High-performance research computing in ",
    "section": "Alternative approaches",
    "text": "Alternative approaches\nThe multidplyr package partitions data frames across worker processes, allows you to run the usual tidyverse functions on each partition, then collects the processed data.\nThe furrr package is a parallel equivalent to the purrr package from the tidyverse.\nIf you work with genomic data, you might want to have a look at the BiocParallel package from Bioconductor.\nYet another option to run distributed R code is to use the sparklyr package (an R interface to Spark).\nRmpi is a wrapper to MPI (Message-Passing Interface). It has proved slow and problematic on Cedar though.\nThe boot package provides functions and datasets specifically for bootstrapping in parallel."
  },
  {
    "objectID": "r/wb_hpc.html",
    "href": "r/wb_hpc.html",
    "title": "High-performance research computing in R",
    "section": "",
    "text": "R is not famous for its speed. With code optimization and parallelization, it can however be used for heavy computations.\nThis webinar will introduce you to working with R from the command line on the Alliance clusters with a focus on performance. We will discuss code benchmarking and various parallelization techniques.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "High-performance computing"
    ]
  },
  {
    "objectID": "r/wb_gis_mapping_content.html",
    "href": "r/wb_gis_mapping_content.html",
    "title": "GIS mapping with R",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "GIS mapping with R",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_gis_mapping_content.html#gis-concepts",
    "href": "r/wb_gis_mapping_content.html#gis-concepts",
    "title": "GIS mapping with R",
    "section": "GIS concepts",
    "text": "GIS concepts\n\nTypes of spatial data\n\nVector data\nVector data represent discrete objects.\nThey contain:\n\na geometry: the shape and location of the objects,\nattributes: additional variables (e.g.¬†name, year, type).\n\nCommon file formats include GeoJSON and shapefile.\n\nExamples: countries, roads, rivers, towns.\n\n\n\nRaster data\nRaster data represent continuous phenomena or spatial fields.\nCommon file formats include TIFF, GeoTIFF, NetCDF, and Esri grid.\n\nExamples: temperature, air quality, elevation, water depth.\n\n\n\n\nVector data\nVector data come in multiple types:\n\npoint: ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉsingle set of coordinates,\nmulti-point: ‚ÄÉ‚ÄÇmultiple sets of coordinates,\npolyline: ‚ÄÉ‚ÄÉ‚ÄÉmultiple sets for which the order matters,\nmulti-polyline: ‚ÄÇmultiple of the above,\npolygon: ‚ÄÉ‚ÄÉ‚ÄÉsame as polyline but first and last sets are the same,\nmulti-polygon: ‚ÄÇmultiple of the above.\n\n\n\nRaster data\nGrid of equally sized rectangular cells containing values for some variables.\nSize of cells = resolution.\nFor computing efficiency, rasters do not have coordinates of each cell, but the bounding box and the number of rows and columns.\n\n\nCoordinate Reference Systems\nA location on Earth‚Äôs surface can be identified by its coordinates and some reference system called CRS.\nThe coordinates (x, y) are called longitude and latitude.\nThere can be a 3rd coordinate (z) for elevation or other measurement‚Äîusually a vertical one.\nAnd a 4th (m) for some other data attribute‚Äîusually a horizontal measurement.\nIn 3D, longitude and latitude are expressed in angular units (e.g.¬†degrees) and the reference system needed is an angular CRS or geographic coordinate system (GCS).\nIn 2D, they are expressed in linear units (e.g.¬†meters) and the reference system needed is a planar CRS or projected coordinate system (PCS).\n\n\nDatums\nSince the Earth is not a perfect sphere, we use spheroidal models to represent its surface. Those are called geodetic datums.\nSome datums are global, others local (more accurate in a particular area of the globe, but only useful there).\n\nExamples of commonly used global datums:\n\nWGS84 (World Geodesic System 1984),\nNAD83 (North American Datum of 1983).\n\n\n\n\nAngular CRS\nAn angular CRS contains a datum, an angular unit and references such as a prime meridian (e.g.¬†the Royal Observatory, Greenwich, England).\nIn an angular CRS or GCS:\n\nLongitude (\\(\\lambda\\)) represents the angle between the prime meridian and the meridian that passes through that location.\nLatitude (\\(\\phi\\)) represents the angle between the line that passes through the center of the Earth and that location and its projection on the equatorial plane.\n\nLongitude and latitude are thus angular coordinates.\n\n\nProjections\nTo create a two-dimensional map, you need to project this 3D angular CRS into a 2D one.\nVarious projections offer different characteristics. For instance:\n\nsome respect areas (equal-area),\nsome respect the shape of geographic features (conformal),\nsome almost respect both for small areas.\n\nIt is important to choose one with sensible properties for your goals.\n\nExamples of projections:\n\nMercator,\nUTM,\nRobinson.\n\n\n\n\nPlanar CRS\nA planar CRS is defined by a datum, a projection and a set of parameters such as a linear unit and the origins.\nCommon planar CRS have been assigned a unique ID called EPSG code which is much more convenient to use.\nIn a planar CRS, coordinates will not be in degrees anymore but in meters (or other length unit).\n\n\nProjecting into a new CRS\nYou can change the projection of your data.\nVector data won‚Äôt suffer any loss of precision, but raster data will.\n‚Üí best to try to avoid reprojecting rasters: if you want to combine various datasets which have different projections, reproject vector data instead.",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "GIS mapping with R",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_gis_mapping_content.html#gis-in-r",
    "href": "r/wb_gis_mapping_content.html#gis-in-r",
    "title": "GIS mapping with R",
    "section": "GIS in R",
    "text": "GIS in R\n\nResources\n\nOpen GIS data\nFree GIS Data: list of free GIS datasets.\n\n\nBooks\nGeocomputation with R by Robin Lovelace, Jakub Nowosad and Jannes Muenchow.\nSpatial Data Science by Edzer Pebesma and Roger Bivand.\nSpatial Data Science with R by Robert J. Hijmans.\nUsing Spatial Data with R by Claudia A. Engel.\n\n\nTutorial\nAn Introduction to Spatial Data Analysis and Visualisation in R by the CDRC.\n\n\n\nResources\n\nWebsite\nr-spatial by Edzer Pebesma, Marius Appel and Daniel N√ºst.\n\n\nCRAN package list\nAnalysis of Spatial Data.\n\n\nMailing list\nR Special Interest Group on using Geographical data and Mapping.",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "GIS mapping with R",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_gis_mapping_content.html#packages",
    "href": "r/wb_gis_mapping_content.html#packages",
    "title": "GIS mapping with R",
    "section": "Packages",
    "text": "Packages\nThere is now a rich ecosystem of GIS packages in R1.\n\nData manipulation\n\nOlder packages\n\nsp\nraster\nrgdal\nrgeos\n\n\n\nNewer generation\n\nsf: ‚ÄÉ‚ÄÇ¬†vector data,\nterra: ‚ÄÇraster data (also has vector data capabilities).\n\n\n\n\nMapping\n\nStatic maps\n\nggplot2 + ggspatial\ntmap\n\n\n\nDynamic maps\n\nleaflet\nggplot2 + gganimate\nmapview\nggmap\ntmap\n\n\n\n\nsf: Simple Features in R\nGeospatial vectors: points, lines, polygons.\nSimple Features‚Äîdefined by the Open Geospatial Consortium (OGC) and formalized by ISO‚Äîis a set of standards now used by most GIS libraries.\nWell-known text (WKT) is a markup language for representing vector geometry objects according to those standards.\nA compact computer version also exists‚Äîwell-known binary (WKB)‚Äîused by spatial databases.\nThe package sp predates Simple Features.\nsf‚Äîlaunched in 2016‚Äîimplements these standards in R in the form of sf objects: data.frames (or tibbles) containing the attributes, extended by sfc objects or simple feature geometries list-columns.\n\n\nsf\nSome useful links:\n\nGitHub repo,\nPaper,\nResources,\nCheatsheet,\n6 vignettes: 1, 2, 3, 4, 5, 6.\n\nAnd the cheatsheet:\n\n\n\n\nsf objects\n\n\n\n\n\n\n\nsf functions\nMost functions start with st_ (which refers to ‚Äúspatial type‚Äù).\n\n\nterra: Geospatial rasters\nFaster and simpler replacement for the raster package by the same team.\nMostly implemented in C++.\nCan work with datasets too large to be loaded into memory.\n\n\nterra\nSome useful links:\n\nGitHub repo,\nResources,\nFull manual.\n\n\n\ntmap\ntmap is a layered grammar of graphics GIS map framework.\nSome useful links:\n\nGitHub repo,\nResources.\n\n\nHelp pages and vignettes\n?tmap-element\nvignette(\"tmap-getstarted\")\n# All the usual help pages, e.g.:\n?tm_layout\n\n\ntmap functions\nMain functions start with tmap_\nFunctions creating map elements start with tm_\n\n\ntmap functioning\nVery similar to ggplot2\nTypically, a map contains:\n\nOne or multiple layer(s) (the order matters as they stack on top of each other)\nSome layout (e.g.¬†customization of title, background, margins): tm_layout\nA compass: tm_compass\nA scale bar: tm_scale_bar\n\nEach layer contains:\n\nSome data: tm_shape\nHow that data will be represented: e.g.¬†tm_polygons, tm_lines, tm_raster\n\n\n\ntmap example\n\n\n\n\n\n\n\n\n\n\n\nggplot2 (the standard in R plots)\nSome useful links:\n\nGitHub repo,\nResources,\nCheatsheet.\n\n\n\ngeom_sf allows to plot sf objects (i.e.¬†make maps).",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "GIS mapping with R",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_gis_mapping_content.html#example-glaciers-melt-in-n-america",
    "href": "r/wb_gis_mapping_content.html#example-glaciers-melt-in-n-america",
    "title": "GIS mapping with R",
    "section": "Example: glaciers melt in N America",
    "text": "Example: glaciers melt in N America\n\nData\nFor this webinar, we will use:\n\nthe Alaska as well as the Western Canada and USA subsets of the Randolph Glacier Inventory version 6.02,\nthe USGS time series of the named glaciers of Glacier National Park3,\nthe Alaska as well as the Western Canada and USA subsets of the consensus estimate for the ice thickness distribution of all glaciers on Earth dataset4.\n\nThe datasets can be downloaded as zip files from these websites\n\n\nPackages\nPackages need to be installed before they can be loaded in a session.\nPackages on CRAN can be installed with:\ninstall.packages(\"&lt;package-name&gt;\")\nbasemaps is not on CRAN and needs to be installed from GitHub thanks to devtools:\ninstall.packages(\"devtools\")\ndevtools::install_github(\"16EAGLE/basemaps\")\nWe load all the packages that we will need at the top of the script:\nlibrary(sf)                 # spatial vector data manipulation\nlibrary(tmap)               # map production and tiled web map\nlibrary(dplyr)              # non GIS specific (tabular data manipulation)\nlibrary(magrittr)           # non GIS specific (pipes)\nlibrary(purrr)              # non GIS specific (functional programming)\nlibrary(rnaturalearth)      # basemap data access functions\nlibrary(rnaturalearthdata)  # basemap data\nlibrary(mapview)            # tiled web map\nlibrary(grid)               # (part of base R) used to create inset map\nlibrary(ggplot2)            # alternative to tmap for map production\nlibrary(ggspatial)          # spatial framework for ggplot2\nlibrary(terra)              # gridded spatial data manipulation\nlibrary(ggmap)              # download basemap data\nlibrary(basemaps)           # download basemap data\nlibrary(magick)             # wrapper around ImageMagick STL\nlibrary(leaflet)            # integrate Leaflet JS in R",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "GIS mapping with R",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_gis_mapping_content.html#reading-and-preparing-data",
    "href": "r/wb_gis_mapping_content.html#reading-and-preparing-data",
    "title": "GIS mapping with R",
    "section": "Reading and preparing data",
    "text": "Reading and preparing data\n\nRandolph Glacier Inventory\nThis dataset contains the contour of all glaciers on Earth.\nWe will focus on glaciers in Western North America.\nYou can download and unzip 02_rgi60_WesternCanadaUS and 01_rgi60_Alaska from the Randolph Glacier Inventory version 6.0.\n\n\nReading in data\nData get imported and turned into sf objects with the function sf::st_read:\nak &lt;- st_read(\"data/01_rgi60_Alaska\")\n\nMake sure to use the absolute paths or the paths relative to your working directory (which can be obtained with getwd).\n\nak &lt;- st_read(\"data/01_rgi60_Alaska\")\nReading layer `01_rgi60_Alaska' from data source `./data/01_rgi60_Alaska'\n               using driver `ESRI Shapefile'\nSimple feature collection with 27108 features and 22 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -176.1425 ymin: 52.05727 xmax: -126.8545 ymax: 69.35167\nGeodetic CRS:  WGS 84\n\n\nYour turn:\n\nRead in the data for the rest of north western America (from 02_rgi60_WesternCanadaUS) and create an sf object called wes.\n\n\n\nFirst look at the data\nak\nSimple feature collection with 27108 features and 22 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -176.1425 ymin: 52.05727 xmax: -126.8545 ymax: 69.35167\nGeodetic CRS:  WGS 84\nFirst 10 features:\n           RGIId        GLIMSId  BgnDate  EndDate    CenLon   CenLat O1Region\n1  RGI60-01.00001 G213177E63689N 20090703 -9999999 -146.8230 63.68900        1\n2  RGI60-01.00002 G213332E63404N 20090703 -9999999 -146.6680 63.40400        1\n3  RGI60-01.00003 G213920E63376N 20090703 -9999999 -146.0800 63.37600        1\n4  RGI60-01.00004 G213880E63381N 20090703 -9999999 -146.1200 63.38100        1\n5  RGI60-01.00005 G212943E63551N 20090703 -9999999 -147.0570 63.55100        1\n6  RGI60-01.00006 G213756E63571N 20090703 -9999999 -146.2440 63.57100        1\n7  RGI60-01.00007 G213771E63551N 20090703 -9999999 -146.2295 63.55085        1\n8  RGI60-01.00008 G213704E63543N 20090703 -9999999 -146.2960 63.54300        1\n9  RGI60-01.00009 G212400E63659N 20090703 -9999999 -147.6000 63.65900        1\n10 RGI60-01.00010 G212830E63513N 20090703 -9999999 -147.1700 63.51300        1\nO2Region   Area Zmin Zmax Zmed Slope Aspect  Lmax Status Connect Form\n1         2  0.360 1936 2725 2385    42    346   839      0       0    0\n2         2  0.558 1713 2144 2005    16    162  1197      0       0    0\n3         2  1.685 1609 2182 1868    18    175  2106      0       0    0\n4         2  3.681 1273 2317 1944    19    195  4175      0       0    0\n5         2  2.573 1494 2317 1914    16    181  2981      0       0    0\n6         2 10.470 1201 3547 1740    22     33 10518      0       0    0\n7         2  0.649 1918 2811 2194    23    151  1818      0       0    0\n8         2  0.200 2826 3555 3195    45     80   613      0       0    0\n9         2  1.517 1750 2514 1977    18    274  2255      0       0    0\n10        2  3.806 1280 1998 1666    17     35  3332      0       0    0\nTermType Surging Linkages Name                       geometry\n1         0       9        9 &lt;NA&gt; POLYGON ((-146.818 63.69081...\n2         0       9        9 &lt;NA&gt; POLYGON ((-146.6635 63.4076...\n3         0       9        9 &lt;NA&gt; POLYGON ((-146.0723 63.3834...\n4         0       9        9 &lt;NA&gt; POLYGON ((-146.149 63.37919...\n5         0       9        9 &lt;NA&gt; POLYGON ((-147.0431 63.5502...\n6         0       9        9 &lt;NA&gt; POLYGON ((-146.2436 63.5562...\n7         0       9        9 &lt;NA&gt; POLYGON ((-146.2495 63.5531...\n8         0       9        9 &lt;NA&gt; POLYGON ((-146.2992 63.5443...\n9         0       9        9 &lt;NA&gt; POLYGON ((-147.6147 63.6643...\n10        0       9        9 &lt;NA&gt; POLYGON ((-147.1494 63.5098...\n\n\nStructure of the data\nstr(ak)\nClasses ‚Äòsf‚Äô and 'data.frame':  27108 obs. of  23 variables:\n$ RGIId   : chr  \"RGI60-01.00001\" \"RGI60-01.00002\" \"RGI60-01.00003\" ...\n$ GLIMSId : chr  \"G213177E63689N\" \"G213332E63404N\" \"G213920E63376N\" ...\n$ BgnDate : chr  \"20090703\" \"20090703\" \"20090703\" \"20090703\" ...\n$ EndDate : chr  \"-9999999\" \"-9999999\" \"-9999999\" \"-9999999\" ...\n$ CenLon  : num  -147 -147 -146 -146 -147 ...\n$ CenLat  : num  63.7 63.4 63.4 63.4 63.6 ...\n$ O1Region: chr  \"1\" \"1\" \"1\" \"1\" ...\n$ O2Region: chr  \"2\" \"2\" \"2\" \"2\" ...\n$ Area    : num  0.36 0.558 1.685 3.681 2.573 ...\n$ Zmin    : int  1936 1713 1609 1273 1494 1201 1918 2826 1750 1280 ...\n$ Zmax    : int  2725 2144 2182 2317 2317 3547 2811 3555 2514 1998 ...\n$ Zmed    : int  2385 2005 1868 1944 1914 1740 2194 3195 1977 1666 ...\n$ Slope   : num  42 16 18 19 16 22 23 45 18 17 ...\n$ Aspect  : int  346 162 175 195 181 33 151 80 274 35 ...\n$ Lmax    : int  839 1197 2106 4175 2981 10518 1818 613 2255 3332 ...\n$ Status  : int  0 0 0 0 0 0 0 0 0 0 ...\n$ Connect : int  0 0 0 0 0 0 0 0 0 0 ...\n$ Form    : int  0 0 0 0 0 0 0 0 0 0 ...\n$ TermType: int  0 0 0 0 0 0 0 0 0 0 ...\n$ Surging : int  9 9 9 9 9 9 9 9 9 9 ...\n$ Linkages: int  9 9 9 9 9 9 9 9 9 9 ...\n$ Name    : chr  NA NA NA NA ...\n$ geometry:sfc_POLYGON of length 27108; first list element: List of 1\n..$ : num [1:65, 1:2] -147 -147 -147 -147 -147 ...\n..- attr(*, \"class\")= chr [1:3] \"XY\" \"POLYGON\" \"sfg\"\n- attr(*, \"sf_column\")= chr \"geometry\"\n- attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA ...\n..- attr(*, \"names\")= chr [1:22] \"RGIId\" \"GLIMSId\" \"BgnDate\" \"EndDate\" ...\n\n\nInspect your data\n\n\nYour turn:\n\nInspect the wes object you created.\n\n\n\nGlacier National Park dataset\nThis dataset contains a time series of the retreat of 39 glaciers of Glacier National Park, MT, USA for the years 1966, 1998, 2005 and 2015.\nYou can download and unzip the 4 sets of files from the USGS website.\n\n\nRead in and clean datasets\nCreate a function that reads and cleans the data:\nprep &lt;- function(dir) {\n  g &lt;- st_read(dir)\n  g %&lt;&gt;% rename_with(~ tolower(gsub(\"Area....\", \"area\", .x)))\n  g %&lt;&gt;% dplyr::select(\n    year,\n    objectid,\n    glacname,\n    area,\n    shape_leng,\n    x_coord,\n    y_coord,\n    source_sca,\n    source\n  )\n}\nCreate a vector of dataset names:\ndirs &lt;- grep(\"data/GNPglaciers_.*\", list.dirs(), value = T)\nPass each element of that vector through prep() thanks to map():\ngnp &lt;- map(dirs, prep)\n\nWe use dplyr::select because terra also has a select function.\n\n\n\nCombine datasets into one sf object\nCheck that the CRS are all the same:\nall(sapply(\n  list(st_crs(gnp[[1]]),\n       st_crs(gnp[[2]]),\n       st_crs(gnp[[3]]),\n       st_crs(gnp[[4]])),\n  function(x) x == st_crs(gnp[[1]])\n))\n[1] TRUE\nWe can rbind the elements of our list:\ngnp &lt;- do.call(\"rbind\", gnp)\nYou can inspect your new sf object by calling it or with str.\n\n\nEstimate for ice thickness\nThis dataset contains an estimate for the ice thickness of all glaciers on Earth.\nThe nomenclature follows the Randolph Glacier Inventory.\nIce thickness being a spatial field, this is raster data.\nWe will use data in RGI60-02.16664_thickness.tif from the ETH Z√ºrich Research Collection which corresponds to one of the glaciers (Agassiz) of Glacier National Park.\n\n\nLoad raster data\nRead in data and create a SpatRaster object:\nras &lt;- rast(\"data/RGI60-02/RGI60-02.16664_thickness.tif\")\n\n\nInspect our SpatRaster object\nras\nclass       : SpatRaster \ndimensions  : 93, 74, 1  (nrow, ncol, nlyr)\nresolution  : 25, 25  (x, y)\nextent      : 707362.5, 709212.5, 5422962, 5425288  (xmin, xmax, ymin, ymax)\ncoord. ref. : +proj=utm +zone=11 +datum=WGS84 +units=m +no_defs \nsource      : RGI60-02.16664_thickness.tif \nname        : RGI60-02.16664_thickness \nnlyr gives us the number of bands (a single one here). You can also run str(ras).\n\n\nOur data\nWe now have 3 sf objects and 1 SpatRaster object:\n\nak: contour of glaciers in AK,\nwes: contour of glaciers in the rest of Western North America,\ngnp: time series of 39 glaciers in Glacier National Park, MT, USA,\nras: ice thickness of the Agassiz Glacier from Glacier National Park.",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "GIS mapping with R",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_gis_mapping_content.html#making-maps",
    "href": "r/wb_gis_mapping_content.html#making-maps",
    "title": "GIS mapping with R",
    "section": "Making maps",
    "text": "Making maps\n\nLet‚Äôs map our sf object ak\nAt a bare minimum, we need tm_shape with the data and some info as to how to represent that data:\ntm_shape(ak) +\n  tm_polygons()\n\n\n\nWe need to label and customize it\ntm_shape(ak) +\n  tm_polygons() +\n  tm_layout(\n    title = \"Glaciers of Alaska\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 500, 1000),\n    position = c(\"right\", \"BOTTOM\")\n  )\n\n\n\nMake a map of the wes object\n\n\nYour turn:\n\nMake a map with the wes object you created with the data for Western North America excluding AK.\n\n\n\n\nNow, a map with ak and wes\nThe Coordinate Reference Systems (CRS) must be the same.\nsf has a function to retrieve the CRS of an sf object: st_crs.\nst_crs(ak) == st_crs(wes)\n[1] TRUE\nSo we‚Äôre good (we will see later what to do if this is not the case).\n\n\nOur combined map\nLet‚Äôs start again with a minimum map without any layout to test things out:\ntm_shape(ak) +\n  tm_polygons() +\n  tm_shape(wes) +\n  tm_polygons()\n\nUh ‚Ä¶ oh ‚Ä¶\n\n\nWhat went wrong?\nMaps are bound by ‚Äúbounding boxes‚Äù. In tmap, they are called bbox.\ntmap sets the bbox the first time tm_shape is called. In our case, the bbox was thus set to the bbox of the ak object.\nWe need to create a new bbox for our new map.\n\n\nRetrieving bounding boxes\nsf has a function to retrieve the bbox of an sf object: st_bbox\nThe bbox of ak is:\nst_bbox(ak)\nxmin         ymin       xmax         ymax\n-176.14247   52.05727   -126.85450   69.35167\n\n\nCombining bounding boxes\nbbox objects can‚Äôt be combined directly.\nHere is how we can create a new bbox encompassing both of our bboxes:\n\nfirst, we transform our bboxes to sfc objects with st_as_sfc,\nthen we combine those objects into a new sfc object with st_union,\nfinally, we retrieve the bbox of that object with st_bbox:\n\nnwa_bbox &lt;- st_bbox(\n  st_union(\n    st_as_sfc(st_bbox(wes)),\n    st_as_sfc(st_bbox(ak))\n  )\n)\n\n\nBack to our map\nWe can now use our new bounding box for the map of Western North America:\ntm_shape(ak, bbox = nwa_bbox) +\n  tm_polygons() +\n  tm_shape(wes) +\n  tm_polygons() +\n  tm_layout(\n    title = \"Glaciers of Western North America\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 1000, 2000),\n    position = c(\"right\", \"BOTTOM\")\n  )\n\n\n\nLet‚Äôs add a basemap\nWe will use data from Natural Earth, a public domain map dataset.\nThere are much more fancy options, but they usually involve creating accounts (e.g.¬†with Google) to access some API.\nIn addition, this dataset can be accessed direction from within R thanks to the rOpenSci packages:\n\nrnaturalearth: provides the functions,\nrnaturalearthdata: provides the data.\n\n\n\nCreate an sf object\nstates_all &lt;- ne_states(\n  country = c(\"canada\", \"united states of america\"),\n  returnclass = \"sf\"\n)\n\nne_ stands for ‚ÄúNatural Earth‚Äù.\n\n\n\nSelect relevant states/provinces\nstates &lt;- states_all %&gt;%\n  filter(name_en == \"Alaska\" |\n           name_en == \"British Columbia\" |\n           name_en == \"Yukon\" |\n           name_en == \"Northwest Territories\" |\n           name_en ==  \"Alberta\" |\n           name_en == \"California\" |\n           name_en == \"Washington\" |\n           name_en == \"Oregon\" |\n           name_en == \"Idaho\" |\n           name_en == \"Montana\" |\n           name_en == \"Wyoming\" |\n           name_en == \"Colorado\" |\n           name_en == \"Nevada\" |\n           name_en == \"Utah\"\n         )\n\n\nAdd the basemap to our map\n\nWhat do we need to make sure of first?\n\nst_crs(states) == st_crs(ak)\n[1] TRUE\nWe add the basemap as a 3rd layer.\nMind the order! If you put the basemap last, it will cover your data.\nOf course, we will use our nwa_bbox bounding box again.\nWe will also break tm_polygons into tm_borders and tm_fill for ak and wes in order to colourise them with slightly different colours:\ntm_shape(states, bbox = nwa_bbox) +\n  tm_polygons(col = \"#f2f2f2\", lwd = 0.2) +\n  tm_shape(ak) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_shape(wes) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_layout(\n    title = \"Glaciers of Western North America\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 1000, 2000),\n    position = c(\"right\", \"BOTTOM\")\n  )\n\n\n\ntmap styles\ntmap has a number of styles that you can try.\nFor instance, to set the style to ‚Äúclassic‚Äù, run the following before making your map:\ntmap_style(\"classic\")\n\nOther options are:\n‚Äúwhite‚Äù (default), ‚Äúgray‚Äù, ‚Äúnatural‚Äù, ‚Äúcobalt‚Äù, ‚Äúcol_blind‚Äù, ‚Äúalbatross‚Äù, ‚Äúbeaver‚Äù, ‚Äúbw‚Äù, and ‚Äúwatercolor‚Äù.\n\n\nTo return to the default, you need to run:\ntmap_style(\"white\")\nor:\ntmap_options_reset()\nwhich will reset every tmap option.",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "GIS mapping with R",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_gis_mapping_content.html#inset-maps",
    "href": "r/wb_gis_mapping_content.html#inset-maps",
    "title": "GIS mapping with R",
    "section": "Inset maps",
    "text": "Inset maps\nNow, how can we combine this with our gnp object?\nWe could add it as an inset of our Western North America map.\n\nFirst, let‚Äôs map it\nLet‚Äôs use the same tm_borders and tm_fill we just used:\ntm_shape(gnp) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_layout(\n    title = \"Glaciers of Glacier National Park\",\n    title.position = c(\"center\", \"top\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 10, 20),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )\n\n\n\nCreate an inset map\nAs always, first we check that the CRS are the same:\nst_crs(gnp) == st_crs(ak)\n[1] FALSE\nAH!\n\n\nCRS transformation\nWe need to reproject gnp into the CRS of our other sf objects (e.g.¬†ak):\ngnp &lt;- st_transform(gnp, st_crs(ak))\nWe can verify that the CRS are now the same:\nst_crs(gnp) == st_crs(ak)\n[1] TRUE\n\n\nInset maps: first step\nAdd a rectangle showing the location of the GNP map in the main North America map.\nWe need to create a new sfc object from the gnp bbox so that we can add it to our previous map as a new layer:\ngnp_zone &lt;- st_bbox(gnp) %&gt;%\n  st_as_sfc()\n\n\nInset maps: second step\nCreate a tmap object of the main map. Of course, we need to edit the title. Also, note the presence of our new layer:\nmain_map &lt;- tm_shape(states, bbox = nwa_bbox) +\n  tm_polygons(col = \"#f2f2f2\", lwd = 0.2) +\n  tm_shape(ak) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_shape(wes) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_shape(gnp_zone) +\n  tm_borders(lwd = 1.5, col = \"#ff9900\") +\n  tm_layout(\n    title = \"Glaciers of Glacier National Park\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 500, 1000),\n    position = c(\"right\", \"BOTTOM\")\n  )\n\n\nInset maps: third step\nCreate a tmap object of the inset map.\nWe make sure to matching colours and edit the layouts for better readability:\ninset_map &lt;- tm_shape(gnp) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_layout(\n    legend.show = F,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.03, 0.03, 0.03, 0.03),\n    outer.margins = 0,\n    frame = \"#ff9900\",\n    frame.lwd = 3\n  )\n\n\nInset maps: final step\nCombine the two tmap objects.\nWe print the main map and add the inset map with grid::viewport:\nmain_map\nprint(inset_map, vp = viewport(0.41, 0.26, width = 0.5, height = 0.5))",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "GIS mapping with R",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_gis_mapping_content.html#mapping-a-subset-of-the-data",
    "href": "r/wb_gis_mapping_content.html#mapping-a-subset-of-the-data",
    "title": "GIS mapping with R",
    "section": "Mapping a subset of the data",
    "text": "Mapping a subset of the data\nTo see the retreat of the ice, we need to zoom in.\nLet‚Äôs focus on a single glacier: Agassiz Glacier.\n\nMap of the Agassiz Glacier\nSelect the data points corresponding to the Agassiz Glacier:\nag &lt;- gnp %&gt;% filter(glacname == \"Agassiz Glacier\")\ntm_shape(ag) +\n  tm_polygons() +\n  tm_layout(\n    title = \"Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )\n\nNot great ‚Ä¶\n\n\nMap based on attribute variables\ntm_shape(ag) +\n  tm_polygons(\"year\", palette = \"Blues\") +\n  tm_layout(\n    title = \"Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )\n\n\n\nUsing ggplot2 instead of tmap\nAs an alternative to tmap, ggplot2 can plot maps with the geom_sf function:\nggplot(ag) +\n  geom_sf(aes(fill = year)) +\n  scale_fill_brewer(palette = \"Blues\") +\n  labs(title = \"Agassiz Glacier\") +\n  annotation_scale(location = \"bl\", width_hint = 0.4) +\n  annotation_north_arrow(location = \"tr\", which_north = \"true\",\n                         pad_x = unit(0.75, \"in\"), pad_y = unit(0.5, \"in\"),\n                         style = north_arrow_fancy_orienteering) +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5))\nThe package ggspatial adds a lot of functionality to ggplot2 for spatial data.",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "GIS mapping with R",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_gis_mapping_content.html#faceted-maps",
    "href": "r/wb_gis_mapping_content.html#faceted-maps",
    "title": "GIS mapping with R",
    "section": "Faceted maps",
    "text": "Faceted maps\n\nFaceted map of the retreat\ntm_shape(ag) +\n  tm_polygons(col = \"#86baff\") +\n  tm_layout(\n    main.title = \"Agassiz Glacier\",\n    main.title.position = c(\"center\", \"top\"),\n    main.title.size = 1.2,\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0, 0.03, 0, 0.03),\n    outer.margins = 0,\n    panel.label.bg.color = \"#fcfcfc\",\n    frame = F,\n    asp = 0.6\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 0.6\n  ) +\n  tm_facets(\n    by = \"year\",\n    free.coords = F,\n    ncol = 4\n  )",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "GIS mapping with R",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_gis_mapping_content.html#animated-maps",
    "href": "r/wb_gis_mapping_content.html#animated-maps",
    "title": "GIS mapping with R",
    "section": "Animated maps",
    "text": "Animated maps\n\nAnimated map of the retreat\nFirst, we need to create a tmap object with facets:\nagassiz_anim &lt;- tm_shape(ag) +\n  tm_polygons(col = \"#86baff\") +\n  tm_layout(\n    title = \"Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.08, 0, 0.08, 0),\n    outer.margins = 0,\n    panel.label.bg.color = \"#fcfcfc\"\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  ) +\n  tm_facets(\n    along = \"year\",\n    free.coords = F\n  )\nThen we can pass that object to tmap_animation:\ntmap_animation(\n  agassiz_anim,\n  filename = \"ag.gif\",\n  dpi = 300,\n  inner.margins = c(0.08, 0, 0.08, 0),\n  delay = 100\n)\n\n\n\nMap of ice thickness of Agassiz\nNow, let‚Äôs map the estimated ice thickness on Agassiz Glacier.\nThis time, we use tm_raster:\ntm_shape(ras) +\n  tm_raster(title = \"\") +\n  tm_layout(\n    title = \"Ice thickness (m) of Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.bg.color = \"#ffffff\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )\n\n\n\nCombining with Randolph data\nAs always, we check whether the CRS are the same:\nst_crs(ag) == st_crs(ras)\n[1] FALSE\nWe need to reproject ag (remember that it is best to avoid reprojecting raster data):\nag %&lt;&gt;% st_transform(st_crs(ras))\nThe retreat and ice thickness layers will hide each other (the order matters!). One option is to use tm_borders for one of them, but we can also use transparency (alpha). We also adjust the legend:\ntm_shape(ras) +\n  tm_raster(title = \"Ice (m)\") +\n  tm_shape(ag) +\n  tm_polygons(\"year\", palette = \"Blues\", alpha = 0.2, title = \"Contour\") +\n  tm_layout(\n    title = \"Ice thickness (m) and retreat of Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.bg.color = \"#ffffff\",\n    legend.text.size = 0.7,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )\n\n\n\nRefining raster maps\nLet‚Äôs go back to our ice thickness map:\n\nWe can change the palette to blue with tm_raster(palette = \"Blues\"):\n\n\nWe can create a more suitable interval scale\nFirst, let‚Äôs see what the maximum value is:\nglobal(ras, \"max\")\nmax\nRGI60-02.16664_thickness 70.10873\nThen we can set the breaks with tm_raster(breaks = seq(0, 80, 5))\nWe also need to tweak the layout, legend, etc.:\ntm_shape(ras) +\n  tm_raster(title = \"\", palette = \"Blues\", breaks = seq(0, 80, 5)) +\n  tm_layout(\n    title = \"Ice thickness (m) of Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.bg.color = \"#ffffff\",\n    legend.text.size = 0.7,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )\n\nOr we can use a continuous colour scheme with tm_raster(style = \"cont\"):",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "GIS mapping with R",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_gis_mapping_content.html#basemaps",
    "href": "r/wb_gis_mapping_content.html#basemaps",
    "title": "GIS mapping with R",
    "section": "Basemaps",
    "text": "Basemaps\n\nBasemap with ggmap\nbasemap &lt;- get_map(\n  bbox = c(\n    left = st_bbox(ag)[1],\n    bottom = st_bbox(ag)[2],\n    right = st_bbox(ag)[3],\n    top = st_bbox(ag)[4]\n  ),\n  source = \"osm\"\n)\n\nggmap is a powerful package, but Google now requires an API key obtained through registration\n\n\n\nBasemap with basemaps\nThe package basemaps allows to download open source basemap data from several sources, but those cannot easily be combined with sf objects\nThis plots a satellite image of the Agassiz Glacier:\nbasemap_plot(ag, map_service = \"esri\", map_type = \"world_imagery\")\n\n\nSatellite image",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "GIS mapping with R",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_gis_mapping_content.html#tiled-web-maps-with-leaflet-js",
    "href": "r/wb_gis_mapping_content.html#tiled-web-maps-with-leaflet-js",
    "title": "GIS mapping with R",
    "section": "Tiled web maps with Leaflet JS",
    "text": "Tiled web maps with Leaflet JS\n\nmapview\nmapview(gnp)\n\n\n\n\n\n\nCartoDB.Positron\n\n\n\n\n\n\n\nOpenStreetMap\n\n\n\n\n\n\n\n\n\nOpenTopoMap\n\n\n\n\n\n\n\nEsri.WorldImagery\n\n\n\n\n\n\n\ntmap\nSo far, we have used the plot mode of tmap. There is also a view mode which allows interactive viewing in a browser through Leaflet\nChange to view mode:\ntmap_mode(\"view\")\n\nYou can also toggle between modes with ttm\n\nRe-plot the last map we plotted with tmap:\ntmap_last()\n\n\nleaflet\nleaflet creates a map widget to which you add layers\nmap &lt;- leaflet()\naddTiles(map)",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "GIS mapping with R",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_gis_mapping_content.html#spatial-data-analysis",
    "href": "r/wb_gis_mapping_content.html#spatial-data-analysis",
    "title": "GIS mapping with R",
    "section": "Spatial data analysis",
    "text": "Spatial data analysis\n\nResources\nHere are some resources on the topic to get started.\n\nR companion to Geographic Information Analysis\nSpatial data analysis",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "GIS mapping with R",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_gis_mapping_content.html#image-credits",
    "href": "r/wb_gis_mapping_content.html#image-credits",
    "title": "GIS mapping with R",
    "section": "Image credits",
    "text": "Image credits\nSz≈±cs R√≥bert, Grasshopper Geography",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "GIS mapping with R",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_gis_mapping_content.html#footnotes",
    "href": "r/wb_gis_mapping_content.html#footnotes",
    "title": "GIS mapping with R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBivand, R.S. Progress in the R ecosystem for representing and handling spatial data. J Geogr Syst (2020). https://doi.org/10.1007/s10109-020-00336-0.‚Ü©Ô∏é\nRGI Consortium (2017). Randolph Glacier Inventory ‚Äì A Dataset of Global Glacier Outlines: Version 6.0: Technical Report, Global Land Ice Measurements from Space, Colorado, USA. Digital Media. DOI: https://doi.org/10.7265/N5-RGI-60.‚Ü©Ô∏é\nFagre, D.B., McKeon, L.A., Dick, K.A. and Fountain, A.G., 2017, Glacier margin time series (1966, 1998, 2005, 2015) of the named glaciers of Glacier National Park, MT, USA: U.S. Geological Survey data release. DOI: https://doi.org/10.5066/F7P26WB1.‚Ü©Ô∏é\nFarinotti, Daniel, 2019, A consensus estimate for the ice thickness distribution of all glaciers on Earth - dataset, Zurich. ETH Zurich. DOI: https://doi.org/10.3929/ethz-b-000315707.‚Ü©Ô∏é",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "GIS mapping with R",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/top_ws.html",
    "href": "r/top_ws.html",
    "title": "R workshops",
    "section": "",
    "text": "Web scraping with ¬†\n\n\n\n\nIntro to GIS mapping with R\n\n\n\n\nIntro R for the humanities\n\n\n\n\nA little demo of R programming",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>"
    ]
  },
  {
    "objectID": "r/top_intro.html",
    "href": "r/top_intro.html",
    "title": "Getting started with R",
    "section": "",
    "text": "R is a free and open-source programming language for statistical computing, modelling, and graphics, with an unbeatable collection of statistical packages. It is extremely popular in some academic fields such as statistics, biology, bioinformatics, data mining, data analysis, and linguistics.\nThis introductory course does not assume any prior knowledge.\n\n Start course ‚û§",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>"
    ]
  },
  {
    "objectID": "r/top_hpc.html",
    "href": "r/top_hpc.html",
    "title": "High-performance R",
    "section": "",
    "text": "R is a free and open-source statistical programming language that has become the norm in several data science fields thanks to its rich packages ecosystem. It is however a slow language with high memory usage.\nPeople interested in training deep learning models, running computations on massive datasets, or carrying out large numerical simulations would be better off turning to faster languages such as Python with Numba or JAX, Julia, or Chapel‚Äîall of which we also teach.\nFor those who are already R users though, with computations on tabular data that are not monstrous but take longer than seems reasonable, this course will cover benchmarking, various forms of optimizations, and several parallelization techniques. You will also learn how to run R on the Alliance supercomputers efficiently.\n\n Start course ‚û§",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>"
    ]
  },
  {
    "objectID": "r/intro_tidyverse.html",
    "href": "r/intro_tidyverse.html",
    "title": "The tidyverse",
    "section": "",
    "text": "The tidyverse is a set of packages which attempts to make R more consistent. R was written by statisticians and it is a bit quirky. The tidyverse makes it look more like other programming languages which were developed by computer scientists. It is a different style of writing R code and it is by no means necessary.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "The tidyverse"
    ]
  },
  {
    "objectID": "r/intro_tidyverse.html#a-glimpse-at-the-tidyverse",
    "href": "r/intro_tidyverse.html#a-glimpse-at-the-tidyverse",
    "title": "The tidyverse",
    "section": "A glimpse at the tidyverse",
    "text": "A glimpse at the tidyverse\nThe best introduction to the tidyverse is probably the book R for Data Science by Hadley Wickham and Garrett Grolemund.\nPosit (the company formerly known as RStudio Inc.¬†behind the tidyverse) developed a series of useful cheatsheets. Below are links to the ones you are the most likely to use as you get started with R.\n\nData import\nThe first thing you often need to do is to import your data into R. This is done with readr.\n\n\n\n\nfrom Posit Cheatsheets\n\n\n\n\nData transformation\nYou then often need to transformation your data into the right format. This is done with the packages dplyr and tidyr.\n\n\n\n\nfrom Posit Cheatsheets\n\n\n\n\n\n\nfrom Posit Cheatsheets\n\n\n\n\nVisualization\nVisualization in the tidyverse is done with the ggplot2 package.\n\n\n\n\nfrom Posit Cheatsheets\n\n\n\n\nWorking with factors\nThe package forcats offers the tidyverse approach to working with factors.\n\n\n\nfrom Posit Cheatsheets\n\n\n\n\nWorking with strings\nstringr is for strings.\n\n\n\n\nfrom Posit Cheatsheets\n\n\n\n\nWorking with dates\nlubridate will help you deal with dates.\n\n\n\n\nfrom Posit Cheatsheets\n\n\n\n\nFunctional programming\nFinally, purrr is the tidyverse equivalent to the apply functions in base R: a way to run functions on functions.\n\n\n\n\nfrom Posit Cheatsheets",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "The tidyverse"
    ]
  },
  {
    "objectID": "r/intro_tidyverse.html#base-r-or-tidyverse",
    "href": "r/intro_tidyverse.html#base-r-or-tidyverse",
    "title": "The tidyverse",
    "section": "Base R or tidyverse?",
    "text": "Base R or tidyverse?\n‚ÄúBase R‚Äù refers to the use of the standard R library. The expression is often used in contrast to the tidyverse.\nThere are a many things that you can do with either base R or the tidyverse. Because the syntaxes are quite different, it almost feels like using two different languages and people tend to favour one or the other.\nWhich one you should use is up to you.\n\n\n\n\n\n\n\nBase R\nTidyverse\n\n\n\n\nPreferred by old-schoolers\nIncreasingly becoming the norm with newer R users\n\n\nMore stable\nMore consistent syntax and behaviour\n\n\nDoesn‚Äôt require installing and loading packages\nMore and more resources and documentation available\n\n\n\nIn truth, even though the tidyverse has many detractors amongst old R users, it is increasingly becoming the norm.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "The tidyverse"
    ]
  },
  {
    "objectID": "r/intro_resources.html",
    "href": "r/intro_resources.html",
    "title": "Resources",
    "section": "",
    "text": "The R community is dynamic and offers a lot of online resources, from IDEs to Q&A, to workshops, books, or publications.\nThis section provides a selection of useful sites.\n\n\nMain sites\n\nR website\nComprehensive R Archive Network (CRAN): R versions and packages\n\n\n\nPosit and RStudio IDE\n\nPosit website (Posit was formerly called RStudio Inc.)\nPosit cheatsheets\n\n\n\nForums and Q&A\n\nStack Overflow [r] tag wiki\nStack Overflow [r] tag questions\nPosit Discourse\n\n\n\nDocumentation as pdf\n\nContributed documentation\nIntro books\n\n\n\nSoftware Carpentry online workshops\n\nProgramming with R\nR for Reproducible Scientific Analysis\nData analysis using R in the digital humanities\n\n\n\nOnline books\n\nR for Data Science (heavily based on the tidyverse)\nAdvanced R\nR Packages (how to create packages)\nR Programming for Data Science\nMastering Software Development in R\n\n\n\nR research\n\nThe R Journal",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Resources"
    ]
  },
  {
    "objectID": "r/intro_plotting.html",
    "href": "r/intro_plotting.html",
    "title": "Plotting",
    "section": "",
    "text": "This section focuses on plotting in R with the package ggplot2 from the tidyverse.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Plotting"
    ]
  },
  {
    "objectID": "r/intro_plotting.html#the-data",
    "href": "r/intro_plotting.html#the-data",
    "title": "Plotting",
    "section": "The data",
    "text": "The data\nR comes with a number of datasets. You can get a list by running data(). The ggplot2 package provides additional ones. We will use the mpg dataset from ggplot2.\nTo access the data, let‚Äôs load the package:\n\nlibrary(ggplot2)\n\nHere is what that dataset looks like:\n\nmpg\n\n# A tibble: 234 √ó 11\n   manufacturer model      displ  year   cyl trans      drv     cty   hwy fl   \n   &lt;chr&gt;        &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;\n 1 audi         a4           1.8  1999     4 auto(l5)   f        18    29 p    \n 2 audi         a4           1.8  1999     4 manual(m5) f        21    29 p    \n 3 audi         a4           2    2008     4 manual(m6) f        20    31 p    \n 4 audi         a4           2    2008     4 auto(av)   f        21    30 p    \n 5 audi         a4           2.8  1999     6 auto(l5)   f        16    26 p    \n 6 audi         a4           2.8  1999     6 manual(m5) f        18    26 p    \n 7 audi         a4           3.1  2008     6 auto(av)   f        18    27 p    \n 8 audi         a4 quattro   1.8  1999     4 manual(m5) 4        18    26 p    \n 9 audi         a4 quattro   1.8  1999     4 auto(l5)   4        16    25 p    \n10 audi         a4 quattro   2    2008     4 manual(m6) 4        20    28 p    \n   class  \n   &lt;chr&gt;  \n 1 compact\n 2 compact\n 3 compact\n 4 compact\n 5 compact\n 6 compact\n 7 compact\n 8 compact\n 9 compact\n10 compact\n# ‚Ñπ 224 more rows\n\n\n?mpg will give you information on the variables. In particular:\n\ndispl contains data on engine displacement (a measure of engine size and thus power) in litres (L).\nhwy contains data on fuel economy while driving on highways in miles per gallon (mpg).\ndrv represents the type of drive train (front-wheel drive, rear wheel drive, 4WD).\nclass represents the type of car.\n\nWe are interested in the relationship between engine size and fuel economy and see how the type of drive train and/or the type of car might affect this relationship.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Plotting"
    ]
  },
  {
    "objectID": "r/intro_plotting.html#base-r-plotting",
    "href": "r/intro_plotting.html#base-r-plotting",
    "title": "Plotting",
    "section": "Base R plotting",
    "text": "Base R plotting\nR contains built-in plotting capability thanks to the plot() function.\nA basic version of our plot would be:\n\nplot(\n  mpg$displ,\n  mpg$hwy,\n  main = \"Fuel consumption per engine size on highways\",\n  xlab = \"Engine size (L)\",\n  ylab = \"Fuel economy (mpg) on highways\"\n)",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Plotting"
    ]
  },
  {
    "objectID": "r/intro_plotting.html#grammar-of-graphics",
    "href": "r/intro_plotting.html#grammar-of-graphics",
    "title": "Plotting",
    "section": "Grammar of graphics",
    "text": "Grammar of graphics\nLeland Wilkinson developed the concept of grammar of graphics in his 2005 book The Grammar of Graphics. By breaking down statistical graphs into components following a set of rules, any plot can be described and constructed in a rigorous fashion.\nThis was further refined by Hadley Wickham in his 2010 article A Layered Grammar of Graphics and implemented in the package ggplot2 (that‚Äôs what the 2 ‚Äúg‚Äù stand for in ‚Äúggplot‚Äù).\nggplot2 has become the dominant graphing package in R. Let‚Äôs see how to construct a plot with this package.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Plotting"
    ]
  },
  {
    "objectID": "r/intro_plotting.html#plotting-with-ggplot2",
    "href": "r/intro_plotting.html#plotting-with-ggplot2",
    "title": "Plotting",
    "section": "Plotting with ggplot2",
    "text": "Plotting with ggplot2\n\nYou can find the ggplot2 cheatsheet here.\n\n\nThe Canvas\nThe first component is the data:\n\nggplot(data = mpg)\n\n\n\n\n\n\n\n\n\nThis can be simplified into ggplot(mpg).\n\nThe second component sets the way variables are mapped on the axes. This is done with the aes() (aesthetics) function:\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy))\n\n\n\n\n\n\n\n\n\nThis can be simplified into ggplot(mpg, aes(displ, hwy)).\n\n\n\nGeometric representations of the data\nOnto this canvas, we can add ‚Äúgeoms‚Äù (geometrical objects) representing the data. The type of ‚Äúgeom‚Äù defines the type of representation (e.g.¬†boxplot, histogram, bar chart).\nTo represent the data as a scatterplot, we use the geom_point() function:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point()\n\n\n\n\n\n\n\n\nWe can colour-code the points in the scatterplot based on the drv variable, showing the lower fuel efficiency of 4WD vehicles:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv))\n\n\n\n\n\n\n\n\nOr we can colour-code them based on the class variable:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class))\n\n\n\n\n\n\n\n\nMultiple ‚Äúgeoms‚Äù can be added on top of each other. For instance, we can add a smoothed conditional means function that aids at seeing patterns in the data with geom_smooth():\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThanks to the colour-coding of the types of car, we can see that the cluster of points in the top right corner all belong to the same type: 2 seaters. Those are outliers with high power, yet high few efficiency due to their smaller size.\nThe default smoothing function uses the LOESS (locally estimated scatterplot smoothing) method, which is a nonlinear regression. But maybe a linear model would actually show the general trend better. We can change the method by passing it as an argument to geom_smooth():\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nOf course, we could apply the smoothing function to each class instead of the entire data. It creates a busy plot but shows that the downward trend remains true within each type of car:\n\nggplot(mpg, aes(x = displ, y = hwy, color = class)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nOther arguments to geom_smooth() can set the line width, color, or whether or not the standard error (se) is shown:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(\n    method = lm,\n    se = FALSE,\n    color = \"#999999\",\n    linewidth = 0.5\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nColour scales\nIf we want to change the colour scale, we add another layer for this:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  geom_smooth(\n    method = lm,\n    se = FALSE,\n    color = \"#999999\",\n    linewidth = 0.5\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nscale_color_brewer(), based on color brewer 2.0, is one of many methods to change the color scale. Here is the list of available scales for this particular method:\n\n\n\nLabels\nWe can keep on adding layers. For instance, the labs() function allows to set title, subtitle, captions, tags, axes labels, etc.\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  geom_smooth(\n    method = lm,\n    se = FALSE,\n    color = \"#999999\",\n    linewidth = 0.5\n  ) +\n  labs(\n    title = \"Fuel consumption per engine size on highways\",\n    x = \"Engine size (L)\",\n    y = \"Fuel economy (mpg) on highways\",\n    color = \"Type of car\",\n    caption = \"EPA data from https://fueleconomy.gov/\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nThemes\nAnother optional layer sets one of several preset themes.\nEdward Tufte developed, amongst others, the principle of data-ink ratio which emphasizes that ink should be used primarily where it communicates meaningful messages. It is indeed common to see charts where more ink is used in labels or background than in the actual representation of the data.\nThe default ggplot2 theme could be criticized as not following this principle. Let‚Äôs change it:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  geom_smooth(\n    method = lm,\n    se = FALSE,\n    color = \"#999999\",\n    linewidth = 0.5\n  ) +\n  labs(\n    title = \"Fuel consumption per engine size on highways\",\n    x = \"Engine size (L)\",\n    y = \"Fuel economy (mpg) on highways\",\n    color = \"Type of car\",\n    caption = \"EPA data from https://fueleconomy.gov/\"\n  ) +\n  theme_classic()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe theme() function allows to tweak the theme in any number of ways. For instance, what if we don‚Äôt like the default position of the title and we would rather have it centered?\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  geom_smooth(\n    method = lm,\n    se = FALSE,\n    color = \"#999999\",\n    linewidth = 0.5\n  ) +\n  labs(\n    title = \"Fuel consumption per engine size on highways\",\n    x = \"Engine size (L)\",\n    y = \"Fuel economy (mpg) on highways\",\n    color = \"Type of car\",\n    caption = \"EPA data from https://fueleconomy.gov/\"\n  ) +\n  theme_classic() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nWe can also move the legend to give more space to the actual graph:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  geom_smooth(\n    method = lm,\n    se = FALSE,\n    color = \"#999999\",\n    linewidth = 0.5\n  ) +\n  labs(\n    title = \"Fuel consumption per engine size on highways\",\n    x = \"Engine size (L)\",\n    y = \"Fuel economy (mpg) on highways\",\n    color = \"Type of car\",\n    caption = \"EPA data from https://fueleconomy.gov/\"\n  ) +\n  theme_classic() +\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"bottom\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nAs you could see, ggplot2 works by adding a number of layers on top of each other, all following a standard set of rules, or ‚Äúgrammar‚Äù. This way, a vast array of graphs can be created by organizing simple components.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Plotting"
    ]
  },
  {
    "objectID": "r/intro_plotting.html#ggplot2-extensions",
    "href": "r/intro_plotting.html#ggplot2-extensions",
    "title": "Plotting",
    "section": "ggplot2 extensions",
    "text": "ggplot2 extensions\nThanks to its vast popularity, ggplot2 has seen a proliferation of packages extending its capabilities.\n\nCombining plots\nFor instance the patchwork package allows to easily combine multiple plots on the same frame.\nLet‚Äôs add a second plot next to our plot. To add plots side by side, we simply add them to each other. We also make a few changes to the labels to improve the plots integration:\n\nlibrary(patchwork)\n\nggplot(mpg, aes(x = displ, y = hwy)) +        # First plot\n  geom_point(aes(color = class)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  geom_smooth(\n    method = lm,\n    se = FALSE,\n    color = \"#999999\",\n    linewidth = 0.5\n  ) +\n  labs(\n    x = \"Engine size (L)\",\n    y = \"Fuel economy (mpg) on highways\",\n    color = \"Type of car\"\n  ) +\n  theme_classic() +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    legend.position = c(0.7, 0.75),           # Better legend position\n    legend.background = element_rect(         # Add a frame to the legend\n      linewidth = 0.1,\n      linetype = \"solid\",\n      colour = \"black\"\n    )\n  ) +\n  ggplot(mpg, aes(x = displ, y = hwy)) +      # Second plot\n  geom_point(aes(color = drv)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(\n    x = \"Engine size (L)\",\n    y = element_blank(),                      # Remove redundant label\n    color = \"Type of drive train\",\n    caption = \"EPA data from https://fueleconomy.gov/\"\n  ) +\n  theme_classic() +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    legend.position = c(0.7, 0.87),\n    legend.background = element_rect(\n      linewidth = 0.1,\n      linetype = \"solid\",\n      colour = \"black\"\n    )\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nExtensions list\nAnother popular extension is the gganimate package which allows to create data animations.\nA full list of extensions for ggplot2 is shown below (here is the website):",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Plotting"
    ]
  },
  {
    "objectID": "r/intro_manipulate.html",
    "href": "r/intro_manipulate.html",
    "title": "Data extraction",
    "section": "",
    "text": "It is often useful to focus on sections of the data to plot or analyse. In this section, we will see how to extract various elements of the us_contagious_diseases dataset from the dslabs package.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data extraction"
    ]
  },
  {
    "objectID": "r/intro_manipulate.html#load-packages",
    "href": "r/intro_manipulate.html#load-packages",
    "title": "Data extraction",
    "section": "Load packages",
    "text": "Load packages\nOne of the tidyverse packages is very useful for data manipulation: dplyr. Let‚Äôs load the dslabs package again as well as dplyr:\n\nlibrary(dslabs)\nlibrary(dplyr)",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data extraction"
    ]
  },
  {
    "objectID": "r/intro_manipulate.html#indexing",
    "href": "r/intro_manipulate.html#indexing",
    "title": "Data extraction",
    "section": "Indexing",
    "text": "Indexing\nYou can extract a subset of the data using their position by indexing. Indexing in R starts with 1 (in many languages, the first index is 0) and it is done with square brackets. Since a data frame has two dimensions, there are two possible indices in the square brackets:\n\nthe row index,\nthe column index.\n\nYou can index a single element:\n\nus_contagious_diseases[1, 1]\n\n[1] Hepatitis A\nLevels: Hepatitis A Measles Mumps Pertussis Polio Rubella Smallpox\n\nus_contagious_diseases[1, 2]\n\n[1] Alabama\n51 Levels: Alabama Alaska Arizona Arkansas California Colorado ... Wyoming\n\n\nOr a full row:\n\nus_contagious_diseases[1, ]\n\n      disease   state year weeks_reporting count population\n1 Hepatitis A Alabama 1966              50   321    3345787\n\nus_contagious_diseases[3000, ]\n\n     disease                state year weeks_reporting count population\n3000 Measles District Of Columbia 1981              27     2     631010\n\n\n\n\nYour turn:\n\nHow would you index the year column?",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data extraction"
    ]
  },
  {
    "objectID": "r/intro_manipulate.html#filtering-rows",
    "href": "r/intro_manipulate.html#filtering-rows",
    "title": "Data extraction",
    "section": "Filtering rows",
    "text": "Filtering rows\nYou can also filter data points based on their values:\n\nus_contagious_diseases |&gt;\n  filter(state == \"California\") |&gt;\n  count()\n\n    n\n1 315\n\n\n\n\nYour turn:\n\nHow many data points are there for the state of Arizona?\n\n\nus_contagious_diseases |&gt;\n  filter(state == \"California\" & year &gt; 2000)\n\n       disease      state year weeks_reporting count population\n1  Hepatitis A California 2001              40  1599   34199784\n2  Hepatitis A California 2002              49  1364   34529758\n3  Hepatitis A California 2003              46  1045   34861711\n4  Hepatitis A California 2004              48   788   35195792\n5  Hepatitis A California 2005              49   905   35532154\n6  Hepatitis A California 2006              52   688   35870957\n7  Hepatitis A California 2007              51   312   36212364\n8  Hepatitis A California 2008              52   337   36556548\n9  Hepatitis A California 2009              52   239   36903684\n10 Hepatitis A California 2010              49   201   37253956\n11 Hepatitis A California 2011              49   176   37607525\n12     Measles California 2001              40    34   34199784\n13     Measles California 2002              33     0   34529758\n14       Mumps California 2001              49    37   34199784\n15       Mumps California 2002              49    66   34529758\n16   Pertussis California 2001              40   440   34199784\n17   Pertussis California 2002              43   698   34529758\n18   Pertussis California 2003              41   635   34861711\n19   Pertussis California 2004              36   498   35195792\n20   Pertussis California 2005              45  1609   35532154\n21   Pertussis California 2006              42   831   35870957\n22   Pertussis California 2007              29    95   36212364\n23   Pertussis California 2008              39   276   36556548\n24   Pertussis California 2009              40   415   36903684\n25   Pertussis California 2010              48  1265   37253956\n26   Pertussis California 2011              49  1145   37607525\n27     Rubella California 2001               1     0   34199784\n28     Rubella California 2002              29     2   34529758\n\n\n\nus_contagious_diseases |&gt;\n  filter(state == \"California\" & year &gt; 2000) |&gt;\n  arrange(year)\n\n       disease      state year weeks_reporting count population\n1  Hepatitis A California 2001              40  1599   34199784\n2      Measles California 2001              40    34   34199784\n3        Mumps California 2001              49    37   34199784\n4    Pertussis California 2001              40   440   34199784\n5      Rubella California 2001               1     0   34199784\n6  Hepatitis A California 2002              49  1364   34529758\n7      Measles California 2002              33     0   34529758\n8        Mumps California 2002              49    66   34529758\n9    Pertussis California 2002              43   698   34529758\n10     Rubella California 2002              29     2   34529758\n11 Hepatitis A California 2003              46  1045   34861711\n12   Pertussis California 2003              41   635   34861711\n13 Hepatitis A California 2004              48   788   35195792\n14   Pertussis California 2004              36   498   35195792\n15 Hepatitis A California 2005              49   905   35532154\n16   Pertussis California 2005              45  1609   35532154\n17 Hepatitis A California 2006              52   688   35870957\n18   Pertussis California 2006              42   831   35870957\n19 Hepatitis A California 2007              51   312   36212364\n20   Pertussis California 2007              29    95   36212364\n21 Hepatitis A California 2008              52   337   36556548\n22   Pertussis California 2008              39   276   36556548\n23 Hepatitis A California 2009              52   239   36903684\n24   Pertussis California 2009              40   415   36903684\n25 Hepatitis A California 2010              49   201   37253956\n26   Pertussis California 2010              48  1265   37253956\n27 Hepatitis A California 2011              49   176   37607525\n28   Pertussis California 2011              49  1145   37607525\n\n\n\nus_contagious_diseases |&gt;\n  filter(state == \"California\" & year &gt; 2000) |&gt;\n  arrange(count)\n\n       disease      state year weeks_reporting count population\n1      Measles California 2002              33     0   34529758\n2      Rubella California 2001               1     0   34199784\n3      Rubella California 2002              29     2   34529758\n4      Measles California 2001              40    34   34199784\n5        Mumps California 2001              49    37   34199784\n6        Mumps California 2002              49    66   34529758\n7    Pertussis California 2007              29    95   36212364\n8  Hepatitis A California 2011              49   176   37607525\n9  Hepatitis A California 2010              49   201   37253956\n10 Hepatitis A California 2009              52   239   36903684\n11   Pertussis California 2008              39   276   36556548\n12 Hepatitis A California 2007              51   312   36212364\n13 Hepatitis A California 2008              52   337   36556548\n14   Pertussis California 2009              40   415   36903684\n15   Pertussis California 2001              40   440   34199784\n16   Pertussis California 2004              36   498   35195792\n17   Pertussis California 2003              41   635   34861711\n18 Hepatitis A California 2006              52   688   35870957\n19   Pertussis California 2002              43   698   34529758\n20 Hepatitis A California 2004              48   788   35195792\n21   Pertussis California 2006              42   831   35870957\n22 Hepatitis A California 2005              49   905   35532154\n23 Hepatitis A California 2003              46  1045   34861711\n24   Pertussis California 2011              49  1145   37607525\n25   Pertussis California 2010              48  1265   37253956\n26 Hepatitis A California 2002              49  1364   34529758\n27 Hepatitis A California 2001              40  1599   34199784\n28   Pertussis California 2005              45  1609   35532154\n\n\n\nus_contagious_diseases |&gt;\n  filter(state == \"California\" & year &gt; 2000) |&gt;\n  arrange(desc(count))\n\n       disease      state year weeks_reporting count population\n1    Pertussis California 2005              45  1609   35532154\n2  Hepatitis A California 2001              40  1599   34199784\n3  Hepatitis A California 2002              49  1364   34529758\n4    Pertussis California 2010              48  1265   37253956\n5    Pertussis California 2011              49  1145   37607525\n6  Hepatitis A California 2003              46  1045   34861711\n7  Hepatitis A California 2005              49   905   35532154\n8    Pertussis California 2006              42   831   35870957\n9  Hepatitis A California 2004              48   788   35195792\n10   Pertussis California 2002              43   698   34529758\n11 Hepatitis A California 2006              52   688   35870957\n12   Pertussis California 2003              41   635   34861711\n13   Pertussis California 2004              36   498   35195792\n14   Pertussis California 2001              40   440   34199784\n15   Pertussis California 2009              40   415   36903684\n16 Hepatitis A California 2008              52   337   36556548\n17 Hepatitis A California 2007              51   312   36212364\n18   Pertussis California 2008              39   276   36556548\n19 Hepatitis A California 2009              52   239   36903684\n20 Hepatitis A California 2010              49   201   37253956\n21 Hepatitis A California 2011              49   176   37607525\n22   Pertussis California 2007              29    95   36212364\n23       Mumps California 2002              49    66   34529758\n24       Mumps California 2001              49    37   34199784\n25     Measles California 2001              40    34   34199784\n26     Rubella California 2002              29     2   34529758\n27     Measles California 2002              33     0   34529758\n28     Rubella California 2001               1     0   34199784",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data extraction"
    ]
  },
  {
    "objectID": "r/intro_manipulate.html#selecting-columns",
    "href": "r/intro_manipulate.html#selecting-columns",
    "title": "Data extraction",
    "section": "Selecting columns",
    "text": "Selecting columns\nWe saw how to index columns from their position. It is also possible to select them based on their names:\n\nhead(us_contagious_diseases$year, 50)\n\n [1] 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980\n[16] 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995\n[31] 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010\n[46] 2011 1966 1967 1968 1969\n\n\nIf you want to select several columns, you can use the select() function from dplyr:\n\nus_contagious_diseases |&gt;\n  filter(state == \"California\" & year &gt; 2000 & disease == \"Hepatitis A\") |&gt;\n  select(year, count, population)\n\n   year count population\n1  2001  1599   34199784\n2  2002  1364   34529758\n3  2003  1045   34861711\n4  2004   788   35195792\n5  2005   905   35532154\n6  2006   688   35870957\n7  2007   312   36212364\n8  2008   337   36556548\n9  2009   239   36903684\n10 2010   201   37253956\n11 2011   176   37607525",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data extraction"
    ]
  },
  {
    "objectID": "r/intro_manipulate.html#grouping-data",
    "href": "r/intro_manipulate.html#grouping-data",
    "title": "Data extraction",
    "section": "Grouping data",
    "text": "Grouping data\nIt is often useful to group data by categories to compute some summary statistics.\nFor instance, we can group by year and calculate the total numbers of infections:\n\nus_contagious_diseases |&gt;\n  group_by(year) |&gt;\n  summarise(total = sum(count))\n\n# A tibble: 84 √ó 2\n    year  total\n   &lt;dbl&gt;  &lt;dbl&gt;\n 1  1928 524563\n 2  1929 380196\n 3  1930 439289\n 4  1931 482886\n 5  1932 404683\n 6  1933 391485\n 7  1934 739509\n 8  1935 739224\n 9  1936 292530\n10  1937 314425\n# ‚Ñπ 74 more rows\n\n\nAlternatively, we can group by state and get the totals:\n\nus_contagious_diseases |&gt;\n  group_by(state) |&gt; \n  summarise(total = sum(count))\n\n# A tibble: 51 √ó 2\n   state                  total\n   &lt;fct&gt;                  &lt;dbl&gt;\n 1 Alabama               257979\n 2 Alaska                 29136\n 3 Arizona               240233\n 4 Arkansas              177556\n 5 California           1906067\n 6 Colorado              322845\n 7 Connecticut           463148\n 8 Delaware               44427\n 9 District Of Columbia   77012\n10 Florida               268383\n# ‚Ñπ 41 more rows\n\n\nWe can also group by year and state and get the totals:\n\nus_contagious_diseases |&gt;\n  group_by(year, state) |&gt; \n  summarise(total = sum(count))\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 4,284 √ó 3\n# Groups:   year [84]\n    year state                total\n   &lt;dbl&gt; &lt;fct&gt;                &lt;dbl&gt;\n 1  1928 Alabama               9246\n 2  1928 Alaska                   0\n 3  1928 Arizona               1268\n 4  1928 Arkansas              9157\n 5  1928 California            4960\n 6  1928 Colorado              2510\n 7  1928 Connecticut          10247\n 8  1928 Delaware               607\n 9  1928 District Of Columbia  2609\n10  1928 Florida               1892\n# ‚Ñπ 4,274 more rows",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data extraction"
    ]
  },
  {
    "objectID": "r/intro_import.html",
    "href": "r/intro_import.html",
    "title": "Data import and export",
    "section": "",
    "text": "So far, we have used a well-formatted dataset. In the real world, things are often not this nice and tidy‚Ä¶\nIn this section, we will learn how to handle real data.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data import and export"
    ]
  },
  {
    "objectID": "r/intro_import.html#reading-in-data",
    "href": "r/intro_import.html#reading-in-data",
    "title": "Data import and export",
    "section": "Reading in data",
    "text": "Reading in data\nThe readr package from the tidyverse provides a number of functions to read in text files with tabular data (e.g.¬†comma-separated values (CSV) or tab-separated values (TSV) files).\nLet‚Äôs load it:\n\nlibrary(readr)\n\nThe read_csv() function allows to read in CSV files that are either stored locally or from a URL.\nLet‚Äôs use it to load a CSV file with mock archaeological data which is at the URL https://mint.westdri.ca/r/hss_data/arc1.csv:\n\narc1 &lt;- read_csv(\"https://mint.westdri.ca/r/hss_data/arc1.csv\")\n\nRows: 6 Columns: 5\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (5): Site, Date, Number of artifacts, Name of PI, Comments\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nIf the file was in your machine, you would provide its path instead of the URL.\n\nHere is our data:\n\narc1\n\n# A tibble: 6 √ó 5\n  Site  Date      `Number of artifacts` `Name of PI`\n  &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;                 &lt;chr&gt;       \n1 E1    13/2/2001 4                     John Doe    \n2 E1    14/2/2001 3                     John Doe    \n3 A2    26/3/2003 N/A                   Paul Smith  \n4 B18   4/5/2006  5                     Paul Smith  \n5 B7    4/5/2006  5                     n/a         \n6 B3    4/5/2006  5                     P. Smith    \n  Comments                          \n  &lt;chr&gt;                             \n1 &lt;NA&gt;                              \n2 &lt;NA&gt;                              \n3 Artifacts still need to be counted\n4 &lt;NA&gt;                              \n5 &lt;NA&gt;                              \n6 &lt;NA&gt;",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data import and export"
    ]
  },
  {
    "objectID": "r/intro_import.html#improper-na",
    "href": "r/intro_import.html#improper-na",
    "title": "Data import and export",
    "section": "Improper NA",
    "text": "Improper NA\nIn R, missing values are represented by NA (not available). It is a constant that R understands and can deal with, so it is important that all missing values are represented properly.\nWhen you enter data (say in an Excel file or CSV file), leave an empty cell for missing values: R will then transform them automatically into NA.\nBecause this data was not entered properly, we have to fix our missing values. One way to go about this is to replace the characters representing missing values in the file (\"N/A\" and \"n/a\") by NA:\n\nis.na(arc1) &lt;- arc1 == \"N/A\"\nis.na(arc1) &lt;- arc1 == \"n/a\"\narc1\n\n# A tibble: 6 √ó 5\n  Site  Date      `Number of artifacts` `Name of PI`\n  &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;                 &lt;chr&gt;       \n1 E1    13/2/2001 4                     John Doe    \n2 E1    14/2/2001 3                     John Doe    \n3 A2    26/3/2003 &lt;NA&gt;                  Paul Smith  \n4 B18   4/5/2006  5                     Paul Smith  \n5 B7    4/5/2006  5                     &lt;NA&gt;        \n6 B3    4/5/2006  5                     P. Smith    \n  Comments                          \n  &lt;chr&gt;                             \n1 &lt;NA&gt;                              \n2 &lt;NA&gt;                              \n3 Artifacts still need to be counted\n4 &lt;NA&gt;                              \n5 &lt;NA&gt;                              \n6 &lt;NA&gt;                              \n\n\nNow, we have another problem to fix: readr is very good at guessing the types of the various variables. Unfortunately, the character \"N/A\" in the Number of artifacts column prevented it to guess the type properly: it should be a double (a numerical value) and not a character. We can fix this too:\n\narc1$`Number of artifacts` &lt;- as.double(arc1$`Number of artifacts`)\narc1\n\n# A tibble: 6 √ó 5\n  Site  Date      `Number of artifacts` `Name of PI`\n  &lt;chr&gt; &lt;chr&gt;                     &lt;dbl&gt; &lt;chr&gt;       \n1 E1    13/2/2001                     4 John Doe    \n2 E1    14/2/2001                     3 John Doe    \n3 A2    26/3/2003                    NA Paul Smith  \n4 B18   4/5/2006                      5 Paul Smith  \n5 B7    4/5/2006                      5 &lt;NA&gt;        \n6 B3    4/5/2006                      5 P. Smith    \n  Comments                          \n  &lt;chr&gt;                             \n1 &lt;NA&gt;                              \n2 &lt;NA&gt;                              \n3 Artifacts still need to be counted\n4 &lt;NA&gt;                              \n5 &lt;NA&gt;                              \n6 &lt;NA&gt;                              \n\n\nAlternatively, it is simpler to have read_csv() properly recognize the missing values. This can be done thanks to the na argument:\n\narc1 &lt;- read_csv(\n  \"https://mint.westdri.ca/r/hss_data/arc1.csv\",\n  na = c(\"N/A\", \"n/a\")\n)\n\nRows: 6 Columns: 5\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (4): Site, Date, Name of PI, Comments\ndbl (1): Number of artifacts\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\narc1\n\n# A tibble: 6 √ó 5\n  Site  Date      `Number of artifacts` `Name of PI`\n  &lt;chr&gt; &lt;chr&gt;                     &lt;dbl&gt; &lt;chr&gt;       \n1 E1    13/2/2001                     4 John Doe    \n2 E1    14/2/2001                     3 John Doe    \n3 A2    26/3/2003                    NA Paul Smith  \n4 B18   4/5/2006                      5 Paul Smith  \n5 B7    4/5/2006                      5 &lt;NA&gt;        \n6 B3    4/5/2006                      5 P. Smith    \n  Comments                            \n  &lt;chr&gt;                               \n1 \"\"                                  \n2 \"\"                                  \n3 \"Artifacts still need to be counted\"\n4 \"\"                                  \n5 \"\"                                  \n6 \"\"                                  \n\n\nA benefit of this approach is that read_csv() now automatically detects the proper data type of Number of artifacts (since there is no more confusing character in what is otherwise a column of doubles).",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data import and export"
    ]
  },
  {
    "objectID": "r/intro_import.html#dealing-with-dates",
    "href": "r/intro_import.html#dealing-with-dates",
    "title": "Data import and export",
    "section": "Dealing with dates",
    "text": "Dealing with dates\nThere is another problem in our data frame: the Date variable should be of the date type, but read_csv() failed to recognize the values as dates and processed them as characters. This is because it is not entered in our data following the ISO 8601 format which is YYYY-MM-DD. When you enter data, make sure to follow this format as it will make things work automatically. In our case, we have to convert the date.\nThe tidyverse package dealing with date is lubridate. Let‚Äôs load it:\n\nlibrary(lubridate)\n\nlubridate comes with many functions that can convert dates and times from many format to the ISO format. Since our date have the day, then the month, then the year, the function we need is dmy():\n\narc1$Date &lt;- dmy(arc1$Date)\n\nAlternatively, read_csv() will understand dates in a non ISO format, provided you give it the right information. This can be done with the col_types argument and the col_date() function to which the parameters corresponding to your date format are passed.\nHere are the parameters to use:\n\n\n\n\nFormat\nExample\nParameter\n\n\n\n\nYear\n4 digits\n2024\n%Y\n\n\n\n2 digits\n24\n%y\n\n\nMonth\nDecimal\n2\n%m\n\n\n\nAbbreviated name\nFeb\n%b\n\n\n\nFull name\nFebruary\n%B\n\n\nDay\nDecimal\n8\n%d\n\n\n\nIn our case, the date looks like \"%d/%m/%Y\":\n\narc1 &lt;- read_csv(\n  \"https://mint.westdri.ca/r/hss_data/arc1.csv\",\n  na = c(\"N/A\", \"n/a\"),\n  col_types = cols(Date = col_date(\"%d/%m/%Y\"))\n)\narc1\n\n# A tibble: 6 √ó 5\n  Site  Date       `Number of artifacts` `Name of PI`\n  &lt;chr&gt; &lt;date&gt;                     &lt;dbl&gt; &lt;chr&gt;       \n1 E1    2001-02-13                     4 John Doe    \n2 E1    2001-02-14                     3 John Doe    \n3 A2    2003-03-26                    NA Paul Smith  \n4 B18   2006-05-04                     5 Paul Smith  \n5 B7    2006-05-04                     5 &lt;NA&gt;        \n6 B3    2006-05-04                     5 P. Smith    \n  Comments                            \n  &lt;chr&gt;                               \n1 \"\"                                  \n2 \"\"                                  \n3 \"Artifacts still need to be counted\"\n4 \"\"                                  \n5 \"\"                                  \n6 \"\"",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data import and export"
    ]
  },
  {
    "objectID": "r/intro_import.html#renaming-variables",
    "href": "r/intro_import.html#renaming-variables",
    "title": "Data import and export",
    "section": "Renaming variables",
    "text": "Renaming variables\nVariable names cannot contain spaces. Since our data did have spaces in some of the names and since those names were not quoted, R added backticks ``` to be able to make use of them. This makes for rather awkward variables. Let‚Äôs rename them.\nWe could use the camel or snake case, but we can also just simplify the names:\n\narc1 &lt;- arc1 |&gt;\n  rename(\n    Artifacts = `Number of artifacts`,\n    PI = `Name of PI`\n  )\n\nError in rename(arc1, Artifacts = `Number of artifacts`, PI = `Name of PI`): could not find function \"rename\"",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data import and export"
    ]
  },
  {
    "objectID": "r/intro_import.html#fixing-inconsistencies",
    "href": "r/intro_import.html#fixing-inconsistencies",
    "title": "Data import and export",
    "section": "Fixing inconsistencies",
    "text": "Fixing inconsistencies\nThere is still another problem in our data: Paul Smith and P. Smith are‚Äîas far as R is concerned‚Äî2 different values. The number of PIs in our data should be two, but R currently interprets it as being three:\n\ndplyr::n_distinct(arc1$PI, na.rm = TRUE)\n\nWarning: Unknown or uninitialised column: `PI`.\n\n\n[1] 0\n\n\n\nWe remove the missing values so that they don‚Äôt get counted as an additional PI (although, more PIs could have been involved in the data collection: dealing with missing values programmatically is easy once they are properly formatted, but what to do with them methodologically depends on the situation and is part of the research question).\n\nThis can be a problem for future analysis, so let‚Äôs fix it. There are many ways to go about this, but the simplest is to use regular expressions:\n\narc1$PI &lt;- gsub(\"P\\\\.\", \"Paul\", arc1$PI)\n\nWarning: Unknown or uninitialised column: `PI`.\n\n\nError in `$&lt;-`:\n! Assigned data `gsub(\"P\\\\\\\\.\", \"Paul\", arc1$PI)` must be compatible\n  with existing data.\n‚úñ Existing data has 6 rows.\n‚úñ Assigned data has 0 rows.\n‚Ñπ Only vectors of size 1 are recycled.\nCaused by error in `vectbl_recycle_rhs_rows()`:\n! Can't recycle input of size 0 to size 6.\n\n\nOur data is finally well formatted and can be used for plotting, analyses, etc.:\n\narc1\n\n# A tibble: 6 √ó 5\n  Site  Date       `Number of artifacts` `Name of PI`\n  &lt;chr&gt; &lt;date&gt;                     &lt;dbl&gt; &lt;chr&gt;       \n1 E1    2001-02-13                     4 John Doe    \n2 E1    2001-02-14                     3 John Doe    \n3 A2    2003-03-26                    NA Paul Smith  \n4 B18   2006-05-04                     5 Paul Smith  \n5 B7    2006-05-04                     5 &lt;NA&gt;        \n6 B3    2006-05-04                     5 P. Smith    \n  Comments                            \n  &lt;chr&gt;                               \n1 \"\"                                  \n2 \"\"                                  \n3 \"Artifacts still need to be counted\"\n4 \"\"                                  \n5 \"\"                                  \n6 \"\"",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data import and export"
    ]
  },
  {
    "objectID": "r/intro_import.html#writing-data-to-file",
    "href": "r/intro_import.html#writing-data-to-file",
    "title": "Data import and export",
    "section": "Writing data to file",
    "text": "Writing data to file\nNow that we have a properly formatted data frame, we could, if we needed to, export it to a new file. readr also has functions to write to text files.\nLet‚Äôs save our data frame as a new CSV file (make sure to give it a different name from the original file):\nwrite_csv(arc1, \"arc1_clean.csv\")",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data import and export"
    ]
  },
  {
    "objectID": "r/intro_explore.html",
    "href": "r/intro_explore.html",
    "title": "Data exploration",
    "section": "",
    "text": "An important first step of data analysis is to have a look at the data. In this section, we will explore the us_contagious_diseases dataset from the dslabs package.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data exploration"
    ]
  },
  {
    "objectID": "r/intro_explore.html#load-the-dslabs-package",
    "href": "r/intro_explore.html#load-the-dslabs-package",
    "title": "Data exploration",
    "section": "Load the dslabs package",
    "text": "Load the dslabs package\nThis package contains a number of datasets. To access any of them, we first need to load the package:\n\nlibrary(dslabs)\n\n\nlibrary() is a function:\n\nclass(library)\n\n[1] \"function\"\n\n\nFunctions are the ‚Äúverbs‚Äù of programming languages. They do things.\nlibrary() is a function that loads packages into the current session so that their content becomes available.\ndslabs is the argument that we pass to the function library(): it is this particular packages that we are loading in the session here.\nclass() is also a function: it tells what class an object belongs to. In class(library), library is the argument of the function class().",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data exploration"
    ]
  },
  {
    "objectID": "r/intro_explore.html#printing-data-to-screen",
    "href": "r/intro_explore.html#printing-data-to-screen",
    "title": "Data exploration",
    "section": "Printing data to screen",
    "text": "Printing data to screen\nTo print all the data, we would simply run us_contagious_diseases. There are a lot of rows however, so we only want to print a subset to the screen.\nTo print the first six rows, we use the function head(), using our data as the argument:\n\nhead(us_contagious_diseases)\n\n      disease   state year weeks_reporting count population\n1 Hepatitis A Alabama 1966              50   321    3345787\n2 Hepatitis A Alabama 1967              49   291    3364130\n3 Hepatitis A Alabama 1968              52   314    3386068\n4 Hepatitis A Alabama 1969              49   380    3412450\n5 Hepatitis A Alabama 1970              51   413    3444165\n6 Hepatitis A Alabama 1971              51   378    3481798\n\n\nIf you look at the documentation of the head() function (by running ?head), you can see that it accepts another argument that allows us to set the number of rows to print.\nLet‚Äôs print the first 15 rows:\n\nhead(us_contagious_diseases, n = 15)\n\n       disease   state year weeks_reporting count population\n1  Hepatitis A Alabama 1966              50   321    3345787\n2  Hepatitis A Alabama 1967              49   291    3364130\n3  Hepatitis A Alabama 1968              52   314    3386068\n4  Hepatitis A Alabama 1969              49   380    3412450\n5  Hepatitis A Alabama 1970              51   413    3444165\n6  Hepatitis A Alabama 1971              51   378    3481798\n7  Hepatitis A Alabama 1972              45   342    3524543\n8  Hepatitis A Alabama 1973              45   467    3571209\n9  Hepatitis A Alabama 1974              45   244    3620548\n10 Hepatitis A Alabama 1975              46   286    3671246\n11 Hepatitis A Alabama 1976              50   220    3721914\n12 Hepatitis A Alabama 1977              43   206    3771085\n13 Hepatitis A Alabama 1978              41   203    3817217\n14 Hepatitis A Alabama 1979              47   257    3858703\n15 Hepatitis A Alabama 1980              37   200    3893888\n\n\n\nBy default, n = 6 which is why head() prints six rows unless we specify otherwise. The L in the documentation of the print() function (n = 6L) means that 6 is an integer. You can ignore this for now.\nArguments can be passed to functions as positional arguments (then they have to respect the position of the function definition) or as named arguments (in that case, you need to use the arguments names).\nThat means that iff we keep the arguments in the right order, we can omit the name of the argument (n here) and only write its value (15). :\n\nhead(us_contagious_diseases, 15)\n\n       disease   state year weeks_reporting count population\n1  Hepatitis A Alabama 1966              50   321    3345787\n2  Hepatitis A Alabama 1967              49   291    3364130\n3  Hepatitis A Alabama 1968              52   314    3386068\n4  Hepatitis A Alabama 1969              49   380    3412450\n5  Hepatitis A Alabama 1970              51   413    3444165\n6  Hepatitis A Alabama 1971              51   378    3481798\n7  Hepatitis A Alabama 1972              45   342    3524543\n8  Hepatitis A Alabama 1973              45   467    3571209\n9  Hepatitis A Alabama 1974              45   244    3620548\n10 Hepatitis A Alabama 1975              46   286    3671246\n11 Hepatitis A Alabama 1976              50   220    3721914\n12 Hepatitis A Alabama 1977              43   206    3771085\n13 Hepatitis A Alabama 1978              41   203    3817217\n14 Hepatitis A Alabama 1979              47   257    3858703\n15 Hepatitis A Alabama 1980              37   200    3893888\n\n\nIf the arguments are given to the function out of order however, we do need to use their names.\nThis won‚Äôt work because R needs an integer for n or for the 2nd argument:\n\nhead(15, us_contagious_diseases)\n\nError in head.default(15, us_contagious_diseases): invalid 'n' - must be numeric, possibly NA.\n\n\nThis however works:\n\nhead(n = 15, us_contagious_diseases)\n\n       disease   state year weeks_reporting count population\n1  Hepatitis A Alabama 1966              50   321    3345787\n2  Hepatitis A Alabama 1967              49   291    3364130\n3  Hepatitis A Alabama 1968              52   314    3386068\n4  Hepatitis A Alabama 1969              49   380    3412450\n5  Hepatitis A Alabama 1970              51   413    3444165\n6  Hepatitis A Alabama 1971              51   378    3481798\n7  Hepatitis A Alabama 1972              45   342    3524543\n8  Hepatitis A Alabama 1973              45   467    3571209\n9  Hepatitis A Alabama 1974              45   244    3620548\n10 Hepatitis A Alabama 1975              46   286    3671246\n11 Hepatitis A Alabama 1976              50   220    3721914\n12 Hepatitis A Alabama 1977              43   206    3771085\n13 Hepatitis A Alabama 1978              41   203    3817217\n14 Hepatitis A Alabama 1979              47   257    3858703\n15 Hepatitis A Alabama 1980              37   200    3893888\n\n\n\nWe can also print the last 6 rows of the data:\n\ntail(us_contagious_diseases)\n\n       disease   state year weeks_reporting count population\n16060 Smallpox Wyoming 1947              49     1     276297\n16061 Smallpox Wyoming 1948              24     1     280803\n16062 Smallpox Wyoming 1949               0     0     285544\n16063 Smallpox Wyoming 1950               1     2     290529\n16064 Smallpox Wyoming 1951               1     1     295744\n16065 Smallpox Wyoming 1952               1     1     301083\n\n\n\n\nYour turn:\n\nHow would you print the last 10 rows of the data?",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data exploration"
    ]
  },
  {
    "objectID": "r/intro_explore.html#structure-of-the-data-object",
    "href": "r/intro_explore.html#structure-of-the-data-object",
    "title": "Data exploration",
    "section": "Structure of the data object",
    "text": "Structure of the data object\nus_contagious_diseases is an R object containing the dataset, but what kind of object is it?\n\nclass(us_contagious_diseases)\n\n[1] \"data.frame\"\n\n\nOur data is in a class of R object called a data frame.\nWe can get its full structure with:\n\nstr(us_contagious_diseases)\n\n'data.frame':   16065 obs. of  6 variables:\n $ disease        : Factor w/ 7 levels \"Hepatitis A\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ state          : Factor w/ 51 levels \"Alabama\",\"Alaska\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ year           : num  1966 1967 1968 1969 1970 ...\n $ weeks_reporting: num  50 49 52 49 51 51 45 45 45 46 ...\n $ count          : num  321 291 314 380 413 378 342 467 244 286 ...\n $ population     : num  3345787 3364130 3386068 3412450 3444165 ...\n\n\nThe names of the variables can be obtained with:\n\nnames(us_contagious_diseases)\n\n[1] \"disease\"         \"state\"           \"year\"            \"weeks_reporting\"\n[5] \"count\"           \"population\"     \n\n\nYou can display the data frame in a tabular fashion thanks to:\nView(us_contagious_diseases)",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data exploration"
    ]
  },
  {
    "objectID": "r/intro_explore.html#dimensions-of-our-data-frame",
    "href": "r/intro_explore.html#dimensions-of-our-data-frame",
    "title": "Data exploration",
    "section": "Dimensions of our data frame",
    "text": "Dimensions of our data frame\n\ndim(us_contagious_diseases)\n\n[1] 16065     6\n\nncol(us_contagious_diseases)\n\n[1] 6\n\nnrow(us_contagious_diseases)\n\n[1] 16065\n\n\n\nlength(us_contagious_diseases)\n\n[1] 6\n\nlength(us_contagious_diseases$disease)\n\n[1] 16065",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data exploration"
    ]
  },
  {
    "objectID": "r/intro_explore.html#summary-statistics",
    "href": "r/intro_explore.html#summary-statistics",
    "title": "Data exploration",
    "section": "Summary statistics",
    "text": "Summary statistics\n\nsummary(us_contagious_diseases)\n\n        disease            state            year      weeks_reporting\n Hepatitis A:2346   Alabama   :  315   Min.   :1928   Min.   : 0.00  \n Measles    :3825   Alaska    :  315   1st Qu.:1950   1st Qu.:31.00  \n Mumps      :1785   Arizona   :  315   Median :1975   Median :46.00  \n Pertussis  :2856   Arkansas  :  315   Mean   :1971   Mean   :37.38  \n Polio      :2091   California:  315   3rd Qu.:1990   3rd Qu.:50.00  \n Rubella    :1887   Colorado  :  315   Max.   :2011   Max.   :52.00  \n Smallpox   :1275   (Other)   :14175                                 \n     count          population      \n Min.   :     0   Min.   :   86853  \n 1st Qu.:     7   1st Qu.: 1018755  \n Median :    69   Median : 2749249  \n Mean   :  1492   Mean   : 4107584  \n 3rd Qu.:   525   3rd Qu.: 4996229  \n Max.   :132342   Max.   :37607525  \n                  NA's   :214",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data exploration"
    ]
  },
  {
    "objectID": "r/intro_control_flow.html",
    "href": "r/intro_control_flow.html",
    "title": "Control flow",
    "section": "",
    "text": "Control flow statements alter the linear execution of code, allowing for one or another section of code to be executed, or for one section of code to be executed multiple times.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Control flow"
    ]
  },
  {
    "objectID": "r/intro_control_flow.html#conditionals",
    "href": "r/intro_control_flow.html#conditionals",
    "title": "Control flow",
    "section": "Conditionals",
    "text": "Conditionals\nConditionals determine which section of code is to be ran based on predicates. A predicate is a test that returns either TRUE or FALSE.\nHere is an example:\n\ntest_sign &lt;- function(x) {\n  if (x &gt; 0) {\n    \"x is positif\"\n  } else if (x &lt; 0) {\n    \"x is negatif\"\n  } else {\n    \"x is equal to zero\"\n  }\n}\n\ntest_sign() is a function that accepts one argument. Depending on the value of that argument, one of three snippets of code is executed:\n\ntest_sign(3)\n\n[1] \"x is positif\"\n\ntest_sign(-2)\n\n[1] \"x is negatif\"\n\ntest_sign(0)\n\n[1] \"x is equal to zero\"",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Control flow"
    ]
  },
  {
    "objectID": "r/intro_control_flow.html#loops",
    "href": "r/intro_control_flow.html#loops",
    "title": "Control flow",
    "section": "Loops",
    "text": "Loops\nLoops allow to run the same instruction on various elements:\n\nfor (i in 1:10) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Control flow"
    ]
  },
  {
    "objectID": "r/intro_automation.html",
    "href": "r/intro_automation.html",
    "title": "Automation",
    "section": "",
    "text": "One of the strengths of programming is the ability to automate tasks.\nIn this section, we will see how a loop can automate the creation of file names.\n\nLet‚Äôs say that we now want to import data from 5 files arc1.csv, ‚Ä¶, arc5.csv and create 5 data frames with their data.\nWe need a character vector with the file names.\nWe could create it this way:\n\nfiles &lt;- c(\n  \"https://mint.westdri.ca/r/hss_data/arc1.csv\",\n  \"https://mint.westdri.ca/r/hss_data/arc2.csv\",\n  \"https://mint.westdri.ca/r/hss_data/arc3.csv\",\n  \"https://mint.westdri.ca/r/hss_data/arc4.csv\",\n  \"https://mint.westdri.ca/r/hss_data/arc5.csv\"\n)\n\nIt works of course:\n\nfiles\n\n[1] \"https://mint.westdri.ca/r/hss_data/arc1.csv\"\n[2] \"https://mint.westdri.ca/r/hss_data/arc2.csv\"\n[3] \"https://mint.westdri.ca/r/hss_data/arc3.csv\"\n[4] \"https://mint.westdri.ca/r/hss_data/arc4.csv\"\n[5] \"https://mint.westdri.ca/r/hss_data/arc5.csv\"\n\n\nBut if we had 50 files instead of 5, it would be quite a tedium! And if we had 500 files, it would be unrealistic. A better approach is to write a loop.\nIn order to store the results of a loop, we need to create an empty object and assign to it the result of the loop at each iteration. It is very important to pre-allocate memory: by creating an empty object of the final size, the necessary memory to hold this object is requested once (then the object gets filled in while the loop runs). Without this, more memory would have to be allocated at each iteration of the loop and this is highly inefficient.\nSo let‚Äôs create an empty vector of length 5 and of type character:\n\nfiles &lt;- character(5)\n\nNow we can fill in our vector with the proper values with the loop:\n\nfor (i in 1:5) {\n  files[i] &lt;- paste0(\"https://mint.westdri.ca/r/hss_data/arc\", i, \".csv\")\n}\n\nThis gives us the same result, but the big difference is that it is scalable:\n\nfiles\n\n[1] \"https://mint.westdri.ca/r/hss_data/arc1.csv\"\n[2] \"https://mint.westdri.ca/r/hss_data/arc2.csv\"\n[3] \"https://mint.westdri.ca/r/hss_data/arc3.csv\"\n[4] \"https://mint.westdri.ca/r/hss_data/arc4.csv\"\n[5] \"https://mint.westdri.ca/r/hss_data/arc5.csv\"\n\n\nNow, if our files were not named following such a nice sequence, we would have to modify our loop a little. Below are two examples:\n\nfiles &lt;- character(5)\n\nfor (i in seq_along(c(3, 6, 9, 10, 14))) {\n  files[i] &lt;- paste0(\n    \"https://mint.westdri.ca/r/hss_data/arc\",\n    c(3, 6, 9, 10, 14)[i],\n    \".csv\"\n  )\n}\n\nfiles\n\n[1] \"https://mint.westdri.ca/r/hss_data/arc3.csv\" \n[2] \"https://mint.westdri.ca/r/hss_data/arc6.csv\" \n[3] \"https://mint.westdri.ca/r/hss_data/arc9.csv\" \n[4] \"https://mint.westdri.ca/r/hss_data/arc10.csv\"\n[5] \"https://mint.westdri.ca/r/hss_data/arc14.csv\"\n\n\n\nfiles &lt;- character(5)\n\nfor (i in seq_along(c(\"_a\", \"_b\", \"_c\", \"_d\", \"_e\"))) {\n  files[i] &lt;- paste0(\n    \"https://mint.westdri.ca/r/hss_data/arc\",\n    c(\"_a\", \"_b\", \"_c\", \"_d\", \"_e\")[i],\n    \".csv\"\n  )\n}\n\nfiles\n\n[1] \"https://mint.westdri.ca/r/hss_data/arc_a.csv\"\n[2] \"https://mint.westdri.ca/r/hss_data/arc_b.csv\"\n[3] \"https://mint.westdri.ca/r/hss_data/arc_c.csv\"\n[4] \"https://mint.westdri.ca/r/hss_data/arc_d.csv\"\n[5] \"https://mint.westdri.ca/r/hss_data/arc_e.csv\"\n\n\n\nIf you had all the files in one directory, an alternative approach would be to create a list of all the names matching a regular expression.\nIn our case, we would use:\nfiles &lt;- list.files(pattern=\"^arc\\\\d+\\\\.csv$\")",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Automation"
    ]
  },
  {
    "objectID": "r/hss_why.html",
    "href": "r/hss_why.html",
    "title": "R: why and for whom?",
    "section": "",
    "text": "There are other high level programming languages such as Python or Julia, so when might it make sense for you to turn to R?",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "R: why and for whom?"
    ]
  },
  {
    "objectID": "r/hss_why.html#why-r",
    "href": "r/hss_why.html#why-r",
    "title": "R: why and for whom?",
    "section": "Why R?",
    "text": "Why R?\nHere are a number of reasons why you might want to consider using R:\n\nFree and open source\nHigh-level and easy to learn\nLarge community\nVery well documented\nUnequalled number of statistics and modelling packages\nIntegrated package manager\nEasy connection with fast compiled languages such as C and C++\nPowerful IDEs (e.g.¬†RStudio, ESS, Jupyter)",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "R: why and for whom?"
    ]
  },
  {
    "objectID": "r/hss_why.html#for-whom",
    "href": "r/hss_why.html#for-whom",
    "title": "R: why and for whom?",
    "section": "For whom?",
    "text": "For whom?\nFor whom is R particularly well suited?\n\nFields with heavy statistics, modelling, or Bayesian analysis such as biology, linguistics, economics, or statistics\nData science using a lot of tabular data",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "R: why and for whom?"
    ]
  },
  {
    "objectID": "r/hss_why.html#downsides-of-r",
    "href": "r/hss_why.html#downsides-of-r",
    "title": "R: why and for whom?",
    "section": "Downsides of R",
    "text": "Downsides of R\nOf course, R also has its downsides:\n\nInconsistent syntax full of quirks\nSlow\nLarge memory usage",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "R: why and for whom?"
    ]
  },
  {
    "objectID": "r/hss_tidyverse.html",
    "href": "r/hss_tidyverse.html",
    "title": "The tidyverse",
    "section": "",
    "text": "The tidyverse is a set of packages which attempts to make R more consistent. R was written by statisticians and it is a bit quirky. The tidyverse makes it look more like other programming languages which were developed by computer scientists. It is a different style of writing R code and it is by no means necessary.",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "The tidyverse"
    ]
  },
  {
    "objectID": "r/hss_tidyverse.html#a-glimpse-at-the-tidyverse",
    "href": "r/hss_tidyverse.html#a-glimpse-at-the-tidyverse",
    "title": "The tidyverse",
    "section": "A glimpse at the tidyverse",
    "text": "A glimpse at the tidyverse\nThe best introduction to the tidyverse is probably the book R for Data Science by Hadley Wickham and Garrett Grolemund.\nPosit (the company formerly known as RStudio Inc.¬†behind the tidyverse) developed a series of useful cheatsheets. Below are links to the ones you are the most likely to use as you get started with R.\n\nData import\nThe first thing you often need to do is to import your data into R. This is done with readr.\n\n\n\n\nfrom Posit Cheatsheets\n\n\n\n\nData transformation\nYou then often need to transformation your data into the right format. This is done with the packages dplyr and tidyr.\n\n\n\n\nfrom Posit Cheatsheets\n\n\n\n\n\n\nfrom Posit Cheatsheets\n\n\n\n\nVisualization\nVisualization in the tidyverse is done with the ggplot2 package.\n\n\n\n\nfrom Posit Cheatsheets\n\n\n\n\nWorking with factors\nThe package forcats offers the tidyverse approach to working with factors.\n\n\n\nfrom Posit Cheatsheets\n\n\n\n\nWorking with strings\nstringr is for strings.\n\n\n\n\nfrom Posit Cheatsheets\n\n\n\n\nWorking with dates\nlubridate will help you deal with dates.\n\n\n\n\nfrom Posit Cheatsheets\n\n\n\n\nFunctional programming\nFinally, purrr is the tidyverse equivalent to the apply functions in base R: a way to run functions on functions.\n\n\n\n\nfrom Posit Cheatsheets",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "The tidyverse"
    ]
  },
  {
    "objectID": "r/hss_tidyverse.html#base-r-or-tidyverse",
    "href": "r/hss_tidyverse.html#base-r-or-tidyverse",
    "title": "The tidyverse",
    "section": "Base R or tidyverse?",
    "text": "Base R or tidyverse?\n‚ÄúBase R‚Äù refers to the use of the standard R library. The expression is often used in contrast to the tidyverse.\nThere are a many things that you can do with either base R or the tidyverse. Because the syntaxes are quite different, it almost feels like using two different languages and people tend to favour one or the other.\nWhich one you should use is up to you.\n\n\n\n\n\n\n\nBase R\nTidyverse\n\n\n\n\nPreferred by old-schoolers\nIncreasingly becoming the norm with newer R users\n\n\nMore stable\nMore consistent syntax and behaviour\n\n\nDoesn‚Äôt require installing and loading packages\nMore and more resources and documentation available\n\n\n\nIn truth, even though the tidyverse has many detractors amongst old R users, it is increasingly becoming the norm.",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "The tidyverse"
    ]
  },
  {
    "objectID": "r/hss_resources.html",
    "href": "r/hss_resources.html",
    "title": "Resources",
    "section": "",
    "text": "The R community is dynamic and offers a lot of online resources, from IDEs to Q&A, to workshops, books, or publications.\nThis section provides a selection of useful sites.\n\n\nMain sites\n\nR website\nComprehensive R Archive Network (CRAN): R versions and packages\n\n\n\nPosit and RStudio IDE\n\nPosit website (Posit was formerly called RStudio Inc.)\nPosit cheatsheets\n\n\n\nForums and Q&A\n\nStack Overflow [r] tag wiki\nStack Overflow [r] tag questions\nPosit Discourse\n\n\n\nDocumentation as pdf\n\nContributed documentation\nIntro books\n\n\n\nSoftware Carpentry online workshops\n\nProgramming with R\nR for Reproducible Scientific Analysis\nData analysis using R in the digital humanities\n\n\n\nOnline books\n\nR for Data Science (heavily based on the tidyverse)\nAdvanced R\nR Packages (how to create packages)\nR Programming for Data Science\nMastering Software Development in R\n\n\n\nR research\n\nThe R Journal",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Resources"
    ]
  },
  {
    "objectID": "r/hss_packages.html",
    "href": "r/hss_packages.html",
    "title": "Packages",
    "section": "",
    "text": "Packages are a set of functions, constants, and/or data developed by the community that add functionality to R.\nIn this section, we look at where to find packages and how to install them.",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Packages"
    ]
  },
  {
    "objectID": "r/hss_packages.html#looking-for-packages",
    "href": "r/hss_packages.html#looking-for-packages",
    "title": "Packages",
    "section": "Looking for packages",
    "text": "Looking for packages\n\nPackage finder.\nYour peers and the literature.\nList of CRAN packages.\nList of CRAN task views (list of packages with information for a large number of wide topics).",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Packages"
    ]
  },
  {
    "objectID": "r/hss_packages.html#managing-r-packages",
    "href": "r/hss_packages.html#managing-r-packages",
    "title": "Packages",
    "section": "Managing R packages",
    "text": "Managing R packages\n\nFor this course, you won‚Äôt have to install any package as they have already been installed in our RStudio server.\n\nR packages can be installed, updated, and removed from within R:\ninstall.packages(\"&lt;package_name&gt;\", repos=\"&lt;url-cran-mirror&gt;\")\nremove.packages(\"&lt;package-name&gt;\")\nupdate_packages()\n\nExample:\n\ninstall.packages(\"rvest\", repos=\"https://mirror.rcg.sfu.ca/mirror/CRAN/\")\n\nrepos argument: chose a CRAN mirror close to the location of your cluster or use https://cloud.r-project.org/.\n\n\nThe first time you install a package, R will ask you whether you want to create a personal library in your home directory. Answer yes to both questions. Your packages will now install under ~/.\n\n\nSome packages require additional modules to be loaded before they can be installed. Other packages need additional R packages as dependencies. In either case, you will get explicit error messages. Adding the argument dependencies = T helps in the second case, but you will still have to add packages manually from time to time.",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Packages"
    ]
  },
  {
    "objectID": "r/hss_packages.html#loading-packages",
    "href": "r/hss_packages.html#loading-packages",
    "title": "Packages",
    "section": "Loading packages",
    "text": "Loading packages\nTo make a package available in an R session, you load it with the library() function.\n\nExample:\n\nlibrary(readxl)\nAlternatively, you can access a function from a package without loading it with the syntax: package::function().\n\nExample:\n\nreadxl::read_excel(\"file.xlsx\")",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Packages"
    ]
  },
  {
    "objectID": "r/hss_packages.html#package-documentation",
    "href": "r/hss_packages.html#package-documentation",
    "title": "Packages",
    "section": "Package documentation",
    "text": "Package documentation\n\nSelect a package from the list of CRAN packages.\nGoogle ‚Äúcran‚Äù and the name of your package (e.g.¬†‚Äúcran dplyr‚Äù).\nLook up a package in the package documentation.\nGet a list of functions within a package with the help() function (installed, but not loaded in session):\n\n\nExample to get a list of functions in the dplyr package:\n\nhelp(package = \"dplyr\")\n\nGet help on a function within a package:\n\nIf you are using RStudio or the HTML format for your R help and you already ran the command to get the list of functions within a package (e.g.¬†help(package = \"dplyr\")), you can get help on any function by clicking on its name.\nIf you are using the text format for help (for instance, if you are running R remotely on the command line), you can get help for any function by adding its name at as the first argument of the previous command.\n\nExample to get help on the function bind() of the package dplyr:\n\nhelp(bind, package = \"dplyr\")\nOf course, if the dplyr package is already loaded in your session, you can simply run help(bind).\n\nGet a list of all help files with alias or concept or title matching a regular expression in all installed packages:\n\n\nExample to get a list of all help files with alias or concept or title matching bind:\n\n??bind\nYou can then open those help files as seen previously.\n\nGet a list of all vignettes for all installed packages:\n\nIf you are using RStudio or the HTML help format:\nbrowseVignettes()\nIf you are using the text help format:\nvignette()\n\nGet a list of vignettes available for a package (not all packages have vignettes):\n\n\nExample to get a list of vignettes for the package dplyr:\n\nIf you are using RStudio or the HTML help format:\nvignette(package = \"dplyr\")\nIf you are using the text help format:\nbrowseVignettes(package = \"dplyr\")\nYou can then open those help vignettes as seen previously.",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Packages"
    ]
  },
  {
    "objectID": "r/hss_import.html",
    "href": "r/hss_import.html",
    "title": "Data import and export",
    "section": "",
    "text": "So far, we have used a well-formatted dataset. In the real world, things are often not this nice and tidy‚Ä¶\nIn this section, we will learn how to handle real data.",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data import and export"
    ]
  },
  {
    "objectID": "r/hss_import.html#reading-in-data",
    "href": "r/hss_import.html#reading-in-data",
    "title": "Data import and export",
    "section": "Reading in data",
    "text": "Reading in data\nThe readr package from the tidyverse provides a number of functions to read in text files with tabular data (e.g.¬†comma-separated values (CSV) or tab-separated values (TSV) files).\nLet‚Äôs load it:\n\nlibrary(readr)\n\nThe read_csv() function allows to read in CSV files that are either stored locally or from a URL.\nLet‚Äôs use it to load a CSV file with mock archaeological data which is at the URL https://mint.westdri.ca/r/hss_data/arc1.csv:\n\narc1 &lt;- read_csv(\"https://mint.westdri.ca/r/hss_data/arc1.csv\")\n\nRows: 6 Columns: 5\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (5): Site, Date, Number of artifacts, Name of PI, Comments\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nIf the file was in your machine, you would provide its path instead of the URL.\n\nHere is our data:\n\narc1\n\n# A tibble: 6 √ó 5\n  Site  Date      `Number of artifacts` `Name of PI`\n  &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;                 &lt;chr&gt;       \n1 E1    13/2/2001 4                     John Doe    \n2 E1    14/2/2001 3                     John Doe    \n3 A2    26/3/2003 N/A                   Paul Smith  \n4 B18   4/5/2006  5                     Paul Smith  \n5 B7    4/5/2006  5                     n/a         \n6 B3    4/5/2006  5                     P. Smith    \n  Comments                          \n  &lt;chr&gt;                             \n1 &lt;NA&gt;                              \n2 &lt;NA&gt;                              \n3 Artifacts still need to be counted\n4 &lt;NA&gt;                              \n5 &lt;NA&gt;                              \n6 &lt;NA&gt;",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data import and export"
    ]
  },
  {
    "objectID": "r/hss_import.html#improper-na",
    "href": "r/hss_import.html#improper-na",
    "title": "Data import and export",
    "section": "Improper NA",
    "text": "Improper NA\nIn R, missing values are represented by NA (not available). It is a constant that R understands and can deal with, so it is important that all missing values are represented properly.\nWhen you enter data (say in an Excel file or CSV file), leave an empty cell for missing values: R will then transform them automatically into NA.\nBecause this data was not entered properly, we have to fix our missing values. One way to go about this is to replace the characters representing missing values in the file (\"N/A\" and \"n/a\") by NA:\n\nis.na(arc1) &lt;- arc1 == \"N/A\"\nis.na(arc1) &lt;- arc1 == \"n/a\"\narc1\n\n# A tibble: 6 √ó 5\n  Site  Date      `Number of artifacts` `Name of PI`\n  &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;                 &lt;chr&gt;       \n1 E1    13/2/2001 4                     John Doe    \n2 E1    14/2/2001 3                     John Doe    \n3 A2    26/3/2003 &lt;NA&gt;                  Paul Smith  \n4 B18   4/5/2006  5                     Paul Smith  \n5 B7    4/5/2006  5                     &lt;NA&gt;        \n6 B3    4/5/2006  5                     P. Smith    \n  Comments                          \n  &lt;chr&gt;                             \n1 &lt;NA&gt;                              \n2 &lt;NA&gt;                              \n3 Artifacts still need to be counted\n4 &lt;NA&gt;                              \n5 &lt;NA&gt;                              \n6 &lt;NA&gt;                              \n\n\nNow, we have another problem to fix: readr is very good at guessing the types of the various variables. Unfortunately, the character \"N/A\" in the Number of artifacts column prevented it to guess the type properly: it should be a double (a numerical value) and not a character. We can fix this too:\n\narc1$`Number of artifacts` &lt;- as.double(arc1$`Number of artifacts`)\narc1\n\n# A tibble: 6 √ó 5\n  Site  Date      `Number of artifacts` `Name of PI`\n  &lt;chr&gt; &lt;chr&gt;                     &lt;dbl&gt; &lt;chr&gt;       \n1 E1    13/2/2001                     4 John Doe    \n2 E1    14/2/2001                     3 John Doe    \n3 A2    26/3/2003                    NA Paul Smith  \n4 B18   4/5/2006                      5 Paul Smith  \n5 B7    4/5/2006                      5 &lt;NA&gt;        \n6 B3    4/5/2006                      5 P. Smith    \n  Comments                          \n  &lt;chr&gt;                             \n1 &lt;NA&gt;                              \n2 &lt;NA&gt;                              \n3 Artifacts still need to be counted\n4 &lt;NA&gt;                              \n5 &lt;NA&gt;                              \n6 &lt;NA&gt;                              \n\n\nAlternatively, it is simpler to have read_csv() properly recognize the missing values. This can be done thanks to the na argument:\n\narc1 &lt;- read_csv(\n  \"https://mint.westdri.ca/r/hss_data/arc1.csv\",\n  na = c(\"N/A\", \"n/a\")\n)\n\nRows: 6 Columns: 5\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (4): Site, Date, Name of PI, Comments\ndbl (1): Number of artifacts\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\narc1\n\n# A tibble: 6 √ó 5\n  Site  Date      `Number of artifacts` `Name of PI`\n  &lt;chr&gt; &lt;chr&gt;                     &lt;dbl&gt; &lt;chr&gt;       \n1 E1    13/2/2001                     4 John Doe    \n2 E1    14/2/2001                     3 John Doe    \n3 A2    26/3/2003                    NA Paul Smith  \n4 B18   4/5/2006                      5 Paul Smith  \n5 B7    4/5/2006                      5 &lt;NA&gt;        \n6 B3    4/5/2006                      5 P. Smith    \n  Comments                            \n  &lt;chr&gt;                               \n1 \"\"                                  \n2 \"\"                                  \n3 \"Artifacts still need to be counted\"\n4 \"\"                                  \n5 \"\"                                  \n6 \"\"                                  \n\n\nA benefit of this approach is that read_csv() now automatically detects the proper data type of Number of artifacts (since there is no more confusing character in what is otherwise a column of doubles).",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data import and export"
    ]
  },
  {
    "objectID": "r/hss_import.html#dealing-with-dates",
    "href": "r/hss_import.html#dealing-with-dates",
    "title": "Data import and export",
    "section": "Dealing with dates",
    "text": "Dealing with dates\nThere is another problem in our data frame: the Date variable should be of the date type, but read_csv() failed to recognize the values as dates and processed them as characters. This is because it is not entered in our data following the ISO 8601 format which is YYYY-MM-DD. When you enter data, make sure to follow this format as it will make things work automatically. In our case, we have to convert the date.\nThe tidyverse package dealing with date is lubridate. Let‚Äôs load it:\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\nlubridate comes with many functions that can convert dates and times from many format to the ISO format. Since our date have the day, then the month, then the year, the function we need is dmy():\n\narc1$Date &lt;- dmy(arc1$Date)\n\nAlternatively, read_csv() will understand dates in a non ISO format, provided you give it the right information. This can be done with the col_types argument and the col_date() function to which the parameters corresponding to your date format are passed.\nHere are the parameters to use:\n\n\n\n\nFormat\nExample\nParameter\n\n\n\n\nYear\n4 digits\n2024\n%Y\n\n\n\n2 digits\n24\n%y\n\n\nMonth\nDecimal\n2\n%m\n\n\n\nAbbreviated name\nFeb\n%b\n\n\n\nFull name\nFebruary\n%B\n\n\nDay\nDecimal\n8\n%d\n\n\n\nIn our case, the date looks like \"%d/%m/%Y\":\n\narc1 &lt;- read_csv(\n  \"https://mint.westdri.ca/r/hss_data/arc1.csv\",\n  na = c(\"N/A\", \"n/a\"),\n  col_types = cols(Date = col_date(\"%d/%m/%Y\"))\n)\narc1\n\n# A tibble: 6 √ó 5\n  Site  Date       `Number of artifacts` `Name of PI`\n  &lt;chr&gt; &lt;date&gt;                     &lt;dbl&gt; &lt;chr&gt;       \n1 E1    2001-02-13                     4 John Doe    \n2 E1    2001-02-14                     3 John Doe    \n3 A2    2003-03-26                    NA Paul Smith  \n4 B18   2006-05-04                     5 Paul Smith  \n5 B7    2006-05-04                     5 &lt;NA&gt;        \n6 B3    2006-05-04                     5 P. Smith    \n  Comments                            \n  &lt;chr&gt;                               \n1 \"\"                                  \n2 \"\"                                  \n3 \"Artifacts still need to be counted\"\n4 \"\"                                  \n5 \"\"                                  \n6 \"\"",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data import and export"
    ]
  },
  {
    "objectID": "r/hss_import.html#renaming-variables",
    "href": "r/hss_import.html#renaming-variables",
    "title": "Data import and export",
    "section": "Renaming variables",
    "text": "Renaming variables\nVariable names cannot contain spaces. Since our data did have spaces in some of the names and since those names were not quoted, R added backticks ``` to be able to make use of them. This makes for rather awkward variables. Let‚Äôs rename them.\nWe could use the camel or snake case, but we can also just simplify the names:\n\narc1 &lt;- arc1 |&gt;\n  rename(\n    Artifacts = `Number of artifacts`,\n    PI = `Name of PI`\n  )\n\nError in rename(arc1, Artifacts = `Number of artifacts`, PI = `Name of PI`): could not find function \"rename\"",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data import and export"
    ]
  },
  {
    "objectID": "r/hss_import.html#fixing-inconsistencies",
    "href": "r/hss_import.html#fixing-inconsistencies",
    "title": "Data import and export",
    "section": "Fixing inconsistencies",
    "text": "Fixing inconsistencies\nThere is still another problem in our data: Paul Smith and P. Smith are‚Äîas far as R is concerned‚Äî2 different values. The number of PIs in our data should be two, but R currently interprets it as being three:\n\ndplyr::n_distinct(arc1$PI, na.rm = TRUE)\n\nWarning: Unknown or uninitialised column: `PI`.\n\n\n[1] 0\n\n\n\nWe remove the missing values so that they don‚Äôt get counted as an additional PI (although, more PIs could have been involved in the data collection: dealing with missing values programmatically is easy once they are properly formatted, but what to do with them methodologically depends on the situation and is part of the research question).\n\nThis can be a problem for future analysis, so let‚Äôs fix it. There are many ways to go about this, but the simplest is to use regular expressions:\n\narc1$PI &lt;- gsub(\"P\\\\.\", \"Paul\", arc1$PI)\n\nWarning: Unknown or uninitialised column: `PI`.\n\n\nError in `$&lt;-`:\n! Assigned data `gsub(\"P\\\\\\\\.\", \"Paul\", arc1$PI)` must be compatible\n  with existing data.\n‚úñ Existing data has 6 rows.\n‚úñ Assigned data has 0 rows.\n‚Ñπ Only vectors of size 1 are recycled.\nCaused by error in `vectbl_recycle_rhs_rows()`:\n! Can't recycle input of size 0 to size 6.\n\n\nOur data is finally well formatted and can be used for plotting, analyses, etc.:\n\narc1\n\n# A tibble: 6 √ó 5\n  Site  Date       `Number of artifacts` `Name of PI`\n  &lt;chr&gt; &lt;date&gt;                     &lt;dbl&gt; &lt;chr&gt;       \n1 E1    2001-02-13                     4 John Doe    \n2 E1    2001-02-14                     3 John Doe    \n3 A2    2003-03-26                    NA Paul Smith  \n4 B18   2006-05-04                     5 Paul Smith  \n5 B7    2006-05-04                     5 &lt;NA&gt;        \n6 B3    2006-05-04                     5 P. Smith    \n  Comments                            \n  &lt;chr&gt;                               \n1 \"\"                                  \n2 \"\"                                  \n3 \"Artifacts still need to be counted\"\n4 \"\"                                  \n5 \"\"                                  \n6 \"\"",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data import and export"
    ]
  },
  {
    "objectID": "r/hss_import.html#writing-data-to-file",
    "href": "r/hss_import.html#writing-data-to-file",
    "title": "Data import and export",
    "section": "Writing data to file",
    "text": "Writing data to file\nNow that we have a properly formatted data frame, we could, if we needed to, export it to a new file. readr also has functions to write to text files.\nLet‚Äôs save our data frame as a new CSV file (make sure to give it a different name from the original file):\nwrite_csv(arc1, \"arc1_clean.csv\")",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data import and export"
    ]
  },
  {
    "objectID": "r/hss_functions.html",
    "href": "r/hss_functions.html",
    "title": "Function definition",
    "section": "",
    "text": "R comes with a number of built-in functions. Packages can provide additional ones. In many cases however, you will want to create your own functions to perform exactly the computations that you need.\nIn this section, we will see how to define new functions.",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Function definition"
    ]
  },
  {
    "objectID": "r/hss_functions.html#syntax",
    "href": "r/hss_functions.html#syntax",
    "title": "Function definition",
    "section": "Syntax",
    "text": "Syntax\nHere is the syntax to define a new function:\nname &lt;- function(arguments) {\n  body\n}",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Function definition"
    ]
  },
  {
    "objectID": "r/hss_functions.html#example",
    "href": "r/hss_functions.html#example",
    "title": "Function definition",
    "section": "Example",
    "text": "Example\nLet‚Äôs define a function that we call compare which will compare the value between 2 numbers:\n\ncompare &lt;- function(x, y) {\n  x == y\n}\n\n\ncompare is the name of our function.\nx and y are the placeholders for the arguments that our function will accept (our function will need 2 arguments to run successfully).\nx == y is the body of the function, that is, the computation performed by our function.\n\nWe can now use our function:\n\ncompare(2, 3)\n\n[1] FALSE",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Function definition"
    ]
  },
  {
    "objectID": "r/hss_functions.html#what-is-returned-by-a-function",
    "href": "r/hss_functions.html#what-is-returned-by-a-function",
    "title": "Function definition",
    "section": "What is returned by a function?",
    "text": "What is returned by a function?\nIn R, the result of the last statement is printed automatically:\n\ntest &lt;- function(x, y) {\n  x\n  y\n}\ntest(2, 3)\n\n[1] 3\n\n\nIf you want to also print other results, you need to explicitly use the print() function:\n\ntest &lt;- function(x, y) {\n  print(x)\n  y\n}\ntest(2, 3)\n\n[1] 2\n\n\n[1] 3\n\n\nNote that, unlike print(), the function return() exits the function:\n\ntest &lt;- function(x, y) {\n  return(x)\n  y\n}\ntest(2, 3)\n\n[1] 2\n\n\n\ntest &lt;- function(x, y) {\n  return(x)\n  return(y)\n}\ntest(2, 3)\n\n[1] 2",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Function definition"
    ]
  },
  {
    "objectID": "r/hss_data_types.html",
    "href": "r/hss_data_types.html",
    "title": "Data types and structures",
    "section": "",
    "text": "It might be time to talk a bit more formally about the various data types and structures available in R. The goal of this course is not to get bogged down in the nitty-gritty of R syntax, so this section is kept very short.",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data types and structures"
    ]
  },
  {
    "objectID": "r/hss_data_types.html#data-types",
    "href": "r/hss_data_types.html#data-types",
    "title": "Data types and structures",
    "section": "Data types",
    "text": "Data types\n\ntypeof(\"Some words\")\n\n[1] \"character\"\n\ntypeof(2)\n\n[1] \"double\"\n\ntypeof(2.0)\n\n[1] \"double\"\n\ntypeof(2L)\n\n[1] \"integer\"\n\ntypeof(TRUE)\n\n[1] \"logical\"",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data types and structures"
    ]
  },
  {
    "objectID": "r/hss_data_types.html#data-structures",
    "href": "r/hss_data_types.html#data-structures",
    "title": "Data types and structures",
    "section": "Data structures",
    "text": "Data structures\n\n\n\nDimension\nHomogeneous\nHeterogeneous\n\n\n\n\n1 d\nAtomic vector\nList\n\n\n2 d\nMatrix\nData frame\n\n\n3 d\nArray\n\n\n\n\n\nAtomic vectors\n\nc(2, 4, 1)\n\n[1] 2 4 1\n\nstr(c(2, 4, 1))\n\n num [1:3] 2 4 1\n\nc(2.2, 4.4, 1.0)\n\n[1] 2.2 4.4 1.0\n\nstr(c(2.2, 4.4, 1.0))\n\n num [1:3] 2.2 4.4 1\n\n1:3\n\n[1] 1 2 3\n\nstr(1:3)\n\n int [1:3] 1 2 3\n\nc(\"some\", \"random\", \"words\")\n\n[1] \"some\"   \"random\" \"words\" \n\nstr(c(\"some\", \"random\", \"words\"))\n\n chr [1:3] \"some\" \"random\" \"words\"\n\n\n\n\nMatrices\n\nm &lt;- matrix(1:12, nrow = 3, ncol = 4)\nm\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12\n\nstr(m)\n\n int [1:3, 1:4] 1 2 3 4 5 6 7 8 9 10 ...\n\n\n\n\nArrays\n\na &lt;- array(as.double(1:24), c(3, 2, 4))\na\n\n, , 1\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\n, , 2\n\n     [,1] [,2]\n[1,]    7   10\n[2,]    8   11\n[3,]    9   12\n\n, , 3\n\n     [,1] [,2]\n[1,]   13   16\n[2,]   14   17\n[3,]   15   18\n\n, , 4\n\n     [,1] [,2]\n[1,]   19   22\n[2,]   20   23\n[3,]   21   24\n\nstr(a)\n\n num [1:3, 1:2, 1:4] 1 2 3 4 5 6 7 8 9 10 ...\n\n\n\n\nLists\n\nl &lt;- list(2L, 3, c(2, 1), FALSE, \"string\")\nl\n\n[[1]]\n[1] 2\n\n[[2]]\n[1] 3\n\n[[3]]\n[1] 2 1\n\n[[4]]\n[1] FALSE\n\n[[5]]\n[1] \"string\"\n\nstr(l)\n\nList of 5\n $ : int 2\n $ : num 3\n $ : num [1:2] 2 1\n $ : logi FALSE\n $ : chr \"string\"\n\n\n\n\nData frames\n\nd &lt;- data.frame(\n  country = c(\"Canada\", \"USA\", \"Mexico\"),\n  var = c(2.9, 3.1, 4.5)\n)\nd\n\n  country var\n1  Canada 2.9\n2     USA 3.1\n3  Mexico 4.5\n\nstr(d)\n\n'data.frame':   3 obs. of  2 variables:\n $ country: chr  \"Canada\" \"USA\" \"Mexico\"\n $ var    : num  2.9 3.1 4.5",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data types and structures"
    ]
  },
  {
    "objectID": "r/hss_analyze.html",
    "href": "r/hss_analyze.html",
    "title": "Data visualization",
    "section": "",
    "text": "To understand the data, it is useful to visualize it."
  },
  {
    "objectID": "r/hpc_resources.html",
    "href": "r/hpc_resources.html",
    "title": "Resources for HPC in R",
    "section": "",
    "text": "This section contains resources specific to high-performance R. For introductory/general R resources, see this page instead.\n\n\nCRAN Task Views\n\nCRAN Task Views give information on packages relevant to certain topics.\n\n\nThe High-Performance and Parallel Computing with R task view lists a lot of packages useful for HPC in R.\n\n\n\nRunning R on the Alliance clusters\n\nThe Alliance wiki contains a lot of documentation on how to run code on the Alliance clusters. Here are pages particularly relevant for HPC in R:\n\n\nGetting started: how to get started using the Alliance supercomputers.\nRunning jobs: how to launch Slurm jobs.\nRunning R: how to use R on the Alliance supercomputers.\nTechnical support: what to do if you are stuck running code on one of the Alliance clusters.\n\nIf you are still having issues after reading the documentation, you can open a ticket by emailing support@tech.alliancecan.ca.\n\n\nOnline books\n\nAdvanced R\nEfficient R programming\n\n\n\nRcpp\n\nDocumentation and examples",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Resources for HPC in R"
    ]
  },
  {
    "objectID": "r/hpc_performance.html",
    "href": "r/hpc_performance.html",
    "title": "Measuring performance:",
    "section": "",
    "text": "Before we talk about ways to improve performance, let‚Äôs see how to measure it.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Measuring performance"
    ]
  },
  {
    "objectID": "r/hpc_performance.html#when-should-you-care",
    "href": "r/hpc_performance.html#when-should-you-care",
    "title": "Measuring performance:",
    "section": "When should you care?",
    "text": "When should you care?\n\n‚ÄúThere is no doubt that the grail of efficiency leads to abuse. Programmers waste enormous amounts of time thinking about, or worrying about, the speed of noncritical parts of their programs, and these attempts at efficiency actually have a strong negative impact when debugging and maintenance are considered. We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil. Yet we should not pass up our opportunities in that critical 3%.‚Äù\n‚Äî Donald Knuth\n\nOptimizing code takes time, can lead to mistakes, and may make code harder to read. Consequently, not all code is worth optimizing and before jumping into optimizations, you need a strategy.\nYou should consider optimizations when:\n\nyou have debugged your code (optimization comes last, don‚Äôt optimize a code that doesn‚Äôt run),\nyou will run a section of code (e.g.¬†a function) many times (your optimization efforts will really pay off),\na section of code is particularly slow.\n\nHow do you know which sections of your code are slow? Don‚Äôt rely on intuition. You need to profile your code to identify bottlenecks.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Measuring performance"
    ]
  },
  {
    "objectID": "r/hpc_performance.html#profiling",
    "href": "r/hpc_performance.html#profiling",
    "title": "Measuring performance:",
    "section": "Profiling",
    "text": "Profiling\n\n‚ÄúIt is often a mistake to make a priori judgments about what parts of a program are really critical, since the universal experience of programmers who have been using measurement tools has been that their intuitive guesses fail.‚Äù\n‚Äî Donald Knuth\n\n\nBase R profiler\nR comes with a profiler: Rprof.\nThe data gets collected with:\n## Start profiler\nRprof()\n\n&lt;Your code to profile&gt;\n\n## Stop profiler\nRprof(NULL)\nThis creates a Rprof.out file in your working directory (you can give it another name by passing a name into the initial call to Rprof (e.g.¬†Rprof(\"test.out\")).\nThe raw data is dense and is better read by running summaryRprof() (or summaryRprof(\"test.out\") if you have created the file test.out rather than the default).\nAlternatively, you can run R CMD Rprof (or R CMD Rprof test.out if you named your file) from the command line.\nYou can find an example here.\n\n\nPackages\nA number of packages run Rprof under the hood and create flame graphs or provide other utilities to visualize the profiling data:\n\nprofr,\nproftools,\nprofvis built by posit (formerly RStudio Inc) is the newest tool. See here for an example.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Measuring performance"
    ]
  },
  {
    "objectID": "r/hpc_performance.html#benchmarking",
    "href": "r/hpc_performance.html#benchmarking",
    "title": "Measuring performance:",
    "section": "Benchmarking",
    "text": "Benchmarking\nOnce you have identified expressions that are particularly slow, you can use benchmarking tools to compare variations of the code.\nIn the most basic fashion, you can use system.time(), but this is limited and imprecise.\nThe microbenchmark package is a much better option. It gives the minimum time, lower quartile, mean, median, upper quartile, and maximum time of R expressions.\nThe newer bench package is very similar, but it has less overhead, is more accurate, and‚Äîfor sequential code‚Äîgives information on memory usage and garbage collections. This is the package that we will use for this course.\nThe main function from this package is mark(). You can pass as argument(s) one or multiple expressions that you want to benchmark. By default, it ensures that all expressions output the same result. If you want to remove this test, add the argument check = FALSE.\nWhile mark() gives memory usage and garbage collection information for sequential code, this functionality is not yet implemented for parallel code. When benchmarking parallel expressions, we will have to use the argument memory = FALSE.\nYou will see many examples of this throughout this course.\n\nWhen benchmarking code, it‚Äôs generally best to use the median rather than the minimum or mean, especially if your data might contain outliers, as the median is less affected by extreme values and provides a better representation of the ‚Äútypical‚Äù performance.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Measuring performance"
    ]
  },
  {
    "objectID": "r/hpc_parallelism.html",
    "href": "r/hpc_parallelism.html",
    "title": "Parallelism: concepts",
    "section": "",
    "text": "Once all sequential optimizations on the bottlenecks have been exhausted, it is time to consider whether parallelization makes sense.\nThis section covers important concepts that are necessary to understand before moving on to writing parallel code.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Parallelism: concepts"
    ]
  },
  {
    "objectID": "r/hpc_parallelism.html#hidden-parallelism",
    "href": "r/hpc_parallelism.html#hidden-parallelism",
    "title": "Parallelism: concepts",
    "section": "Hidden parallelism",
    "text": "Hidden parallelism\nAn increasing number of packages run code in parallel under the hood. It is very important to be aware of this before attempting any explicit parallelization or you may end up with recursive multicore parallelization and an explosion of running cores. This can be both inefficient with demultiplied overhead and extremely resource intensive.\nOne way to assess this is to test the package on your machine and look at the number of cores running with tools such as htop.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Parallelism: concepts"
    ]
  },
  {
    "objectID": "r/hpc_parallelism.html#embarrassingly-parallel-problems",
    "href": "r/hpc_parallelism.html#embarrassingly-parallel-problems",
    "title": "Parallelism: concepts",
    "section": "Embarrassingly parallel problems",
    "text": "Embarrassingly parallel problems\nIdeal cases for parallelization are embarrassingly parallel problems: problems which can be broken down into independent tasks without any work.\nExamples:\n\nLoops for which all iterations are independent of each others.\nResampling (e.g.¬†bootstrapping or cross-validation).\nEnsemble learning (e.g.¬†random forests).\n\nExamples of problems which are not embarrassingly parallel:\n\nLoops for which the result of one iteration is needed for the next iteration.\nRecursive function calls.\nProblems that are inherently sequential.\n\nFor non-embarrassingly parallel problems, one solution is to use C++ to improve speed, as we will see at the end of this course.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Parallelism: concepts"
    ]
  },
  {
    "objectID": "r/hpc_parallelism.html#types-of-parallelism",
    "href": "r/hpc_parallelism.html#types-of-parallelism",
    "title": "Parallelism: concepts",
    "section": "Types of parallelism",
    "text": "Types of parallelism\nThere are various ways to run code in parallel and it is important to have a clear understanding of what each method entails.\n\nMulti-threading\nWe talk about multi-threading when a single process (with its own memory) runs multiple threads.\nThe execution can happen in parallel‚Äîif each thread has access to a CPU core‚Äîor by alternating some of the threads on some CPU cores.\nBecause all threads in a process write to the same memory addresses, multi-threading can lead to race conditions.\nR was not built with multi-threading. Many sites will use the term ‚Äúmulti-threading‚Äù improperly and actually mean ‚Äúmulti-processing‚Äù. Proper multi-threading cannot be achieved in R. A handful of packages (either very specialized or not under development anymore) bring multi-threading to R by using another language under the hood.\n\n\nMulti-processing in shared memory\nMulti-processing in shared memory happens when multiple processes execute code on multiple CPU cores of a single node (or a single machine).\nThe different processes need to communicate with each other, but because they are all running on the CPU cores of a single node, messages can pass via shared memory.\n\n\nMulti-processing in distributed memory\nWhen processes involved in the execution of some code run on multiple nodes of a cluster, messages between them need to travel over the cluster interconnect. In that case, we talk about distributed memory.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Parallelism: concepts"
    ]
  },
  {
    "objectID": "r/hpc_optimizations.html",
    "href": "r/hpc_optimizations.html",
    "title": "Optimizations",
    "section": "",
    "text": "R is not a fast language. Poorly written R is really slow!\nFaced with slow code, people tend to think ‚Äúparallel‚Äù or ‚ÄúGPU‚Äù (which is an adjacent topic since GPUs allow to run many simple calculations in parallel). Parallel programming can indeed greatly help speed up some types of code. A lot of hardware however is not the answer to poorly written code.\nBefore considering parallelization, you should think of ways to optimize your code sequentially because not all programs can be parallelized, parallel programming has costs and overheads, and an optimized serial code will also benefit your parallel code.\nIn many cases, writing better code will save you more computing time than parallelization.\nIn this section, we will cover several optimization principles by playing with the programmatic implementation of the fizz buzz game.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Optimizations"
    ]
  },
  {
    "objectID": "r/hpc_optimizations.html#toy-example",
    "href": "r/hpc_optimizations.html#toy-example",
    "title": "Optimizations",
    "section": "Toy example",
    "text": "Toy example\nFizz buzz is a children game to practice divisions. Players take turn counting out loud from ‚Äú1‚Äù while replacing:\n\nany number divisible by 3 with the word ‚ÄúFizz‚Äù,\nany number divisible by 5 with the word ‚ÄúBuzz‚Äù,\nany number divisible by both 3 and 5 with the word ‚ÄúFizzBuzz‚Äù.\n\nThis creates a series that starts with: \"1, 2, Fizz, 4, Buzz, Fizz, 7, 8, Fizz, Buzz, 11, Fizz, 13, 14, FizzBuzz, 16\", etc.\nLet‚Äôs write functions that output series from 1 to n following these rules and time them to draw general principles about code efficiency.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Optimizations"
    ]
  },
  {
    "objectID": "r/hpc_optimizations.html#setup",
    "href": "r/hpc_optimizations.html#setup",
    "title": "Optimizations",
    "section": "Setup",
    "text": "Setup\nFirst of all, we need to load the necessary modules:\nmodule load StdEnv/2023 gcc/13.3 r/4.4.0\nThen we need to launch a job. There are 2 options:\n\nInteractive job\nIf there are few of us, we will use an interactive session with one CPU each. To launch it, run the following (in the Bash terminal, not in R):\nsalloc --time=2:00:00 --mem-per-cpu=3500M\nWe can then launch R:\nR\nNow, we load the benchmarking package that we will use throughout this section:\n\nlibrary(bench)\n\n\n\nBatch jobs\nIf there are more of us than there are CPUs in the cluster, we will run batch jobs. In this Case:\n\nCreate an R script called optim.R with the code to run (you can reuse the same script for all sections on this page by editing it). Don‚Äôt forget to load the package bench in your script.\nCreate a bash script called optim.sh with the following:\n\n\n\noptim.sh\n\n#!/bin/bash\n#SBATCH --time=15\n#SBATCH --mem-per-cpu=3500M\n\nmodule load StdEnv/2023 gcc/13.3 r/4.4.0\nRscript optim.R\n\n\nRun the jobs with:\n\nsbatch optim.sh",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Optimizations"
    ]
  },
  {
    "objectID": "r/hpc_optimizations.html#optimizations",
    "href": "r/hpc_optimizations.html#optimizations",
    "title": "Optimizations",
    "section": "Optimizations",
    "text": "Optimizations\n\nProper memory pre-allocation\nIn order to store the results of a loop, we need to create an object and assign to it the result of the loop at each iteration. In this first function, we create an empty object z of class integer and of length 0 for that purpose:\n\nf1 &lt;- function(n) {\n  z &lt;- integer()\n  for(i in 1:n) {\n    if(i %% 3 == 0 && i %% 5 == 0) {\n      z[i] &lt;- \"FizzBuzz\"\n    } else if(i %% 3 == 0) {\n      z[i] &lt;- \"Fizz\"\n    } else if(i %% 5 == 0) {\n      z[i] &lt;- \"Buzz\"\n    } else {\n      z[i] &lt;- i\n    }\n  }\n  z\n}\n\nThe second function is similar, but this time, we initialize z with its final length. This means that we are pre-allocating memory for the full vector before we run the loop instead of growing the vector at each iteration:\n\nf2 &lt;- function(n) {\n  z &lt;- integer(n)\n  for(i in 1:n) {\n    if(i %% 3 == 0 && i %% 5 == 0) {\n      z[i] &lt;- \"FizzBuzz\"\n    } else if(i %% 3 == 0) {\n      z[i] &lt;- \"Fizz\"\n    } else if(i %% 5 == 0) {\n      z[i] &lt;- \"Buzz\"\n    } else {\n      z[i] &lt;- i\n    }\n  }\n  z\n}\n\nLet‚Äôs make sure that our functions work by testing it on a short series:\n\nf1(20)\n\n [1] \"1\"        \"2\"        \"Fizz\"     \"4\"        \"Buzz\"     \"Fizz\"    \n [7] \"7\"        \"8\"        \"Fizz\"     \"Buzz\"     \"11\"       \"Fizz\"    \n[13] \"13\"       \"14\"       \"FizzBuzz\" \"16\"       \"17\"       \"Fizz\"    \n[19] \"19\"       \"Buzz\"    \n\nf2(20)\n\n [1] \"1\"        \"2\"        \"Fizz\"     \"4\"        \"Buzz\"     \"Fizz\"    \n [7] \"7\"        \"8\"        \"Fizz\"     \"Buzz\"     \"11\"       \"Fizz\"    \n[13] \"13\"       \"14\"       \"FizzBuzz\" \"16\"       \"17\"       \"Fizz\"    \n[19] \"19\"       \"Buzz\"    \n\n\nShort series are good to get a feel for what our functions return, but they would be inadequate for benchmarking because the functions would run too fast and the timing differences would be too small. Always make sure that your function runs are long enough when you benchmark.\nLet‚Äôs pick a bigger value for n:\n\nn &lt;- 1e5\n\nNow, we can benchmark our functions:\n\nmark(f1(n), f2(n))\n\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n\n\n# A tibble: 2 √ó 6\n  expression      min   median `itr/sec` mem_alloc `gc/sec`\n  &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n1 f1(n)         306ms    311ms      3.22   16.55MB     11.3\n2 f2(n)         214ms    219ms      4.58    1.15MB     16.8\n\n\nf2() is consistently faster, although not by much (speedup of 1.4). In many cases, the difference you will find will be a lot greater.\nIn the cluster, because memory is allocated outside of R (by Slurm), it is not tracked by mark() (see documentation).\nThe output you can see on this site was obtained on my laptop. It shows that a properly written function with pre-allocated memory uses 14 times less memory.\nNow, notice how our function actually returns a character and not an integer:\n\ntypeof(f2(n))\n\n[1] \"character\"\n\n\nSo let‚Äôs create the object z, which will hold the results of our loop, directly of the proper type:\n\nf3 &lt;- function(n) {\n  z &lt;- character(n)\n  for(i in 1:n) {\n    if(i %% 3 == 0 && i %% 5 == 0) {\n      z[i] &lt;- \"FizzBuzz\"\n    } else if(i %% 3 == 0) {\n      z[i] &lt;- \"Fizz\"\n    } else if(i %% 5 == 0) {\n      z[i] &lt;- \"Buzz\"\n    } else {\n      z[i] &lt;- i\n    }\n  }\n  z\n}\n\nAnd now for the benchmark against f2():\n\nmark(f2(n), f3(n))\n\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n\n\n# A tibble: 2 √ó 6\n  expression      min   median `itr/sec` mem_alloc `gc/sec`\n  &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n1 f2(n)         214ms    219ms      4.56    1.23MB     15.2\n2 f3(n)         217ms    219ms      4.51   863.8KB     16.5\n\n\nYou can see that there is no difference in timing, but that f3() is still slightly better because it uses a little less memory. This shows that type matters, but the most important thing you want to worry about in memory pre-allocation is the final length of your objects.\n\n\nNo, loops are not a big ‚Äòno no‚Äô\nBy now, you might be thinking: ‚ÄúWait‚Ä¶ aren‚Äôt loops a big ‚Äòno no‚Äô in R? I‚Äôve always been told that they are slow and that one should always use functional programming! We are talking about optimization in this course and we are using loops?!?‚Äù\nThere are a lot of misconceptions around R loops. They can be very slow if you don‚Äôt pre-allocate memory. Otherwise they are almost always faster than functions (the apply() family or the tidyverse equivalent of the purrr::map() family). You can choose to use a functional programming approach for style and readability, but not for speed.\nLet‚Äôs test it.\nFirst we create a function:\n\nf4 &lt;- function(n) {\n  if(n %% 3 == 0 && n %% 5 == 0) {\n    \"FizzBuzz\"\n  } else if(n %% 3 == 0) {\n    \"Fizz\"\n  } else if(n %% 5 == 0) {\n    \"Buzz\"\n  } else {\n    n\n  }\n}\n\nThen we have to pass our function through sapply().\nLet‚Äôs make sure that the code works:\n\nsapply(1:20, f4)\n\n [1] \"1\"        \"2\"        \"Fizz\"     \"4\"        \"Buzz\"     \"Fizz\"    \n [7] \"7\"        \"8\"        \"Fizz\"     \"Buzz\"     \"11\"       \"Fizz\"    \n[13] \"13\"       \"14\"       \"FizzBuzz\" \"16\"       \"17\"       \"Fizz\"    \n[19] \"19\"       \"Buzz\"    \n\n\nNow, we compare the timing with that of f3() (our fastest function so far):\n\nmark(f3(n), sapply(1:n, f4))\n\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n\n\n# A tibble: 2 √ó 6\n  expression           min   median `itr/sec` mem_alloc `gc/sec`\n  &lt;bch:expr&gt;      &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n1 f3(n)              262ms    267ms      3.75   781.3KB     16.9\n2 sapply(1:n, f4)    355ms    372ms      2.68    3.29MB     12.1\n\n\nAs you can see, the loop is faster (speed up of 1.4). On my laptop, it also used 4 times less memory.\n\n\nAvoid unnecessary operations\n\nExample 1\nCalling z as the last command in our function is the same as calling return(z).\nFrom the R documentation:\n\nIf the end of a function is reached without calling return, the value of the last evaluated expression is returned.\n\nNow, what about using print() instead?\n\nf5 &lt;- function(n) {\n  z &lt;- character(n)\n  for(i in 1:n) {\n    if(i %% 3 == 0 && i %% 5 == 0) {\n      z[i] &lt;- \"FizzBuzz\"\n    } else if(i %% 3 == 0) {\n      z[i] &lt;- \"Fizz\"\n    } else if(i %% 5 == 0) {\n      z[i] &lt;- \"Buzz\"\n    } else {\n      z[i] &lt;- i\n    }\n  }\n  print(z)\n}\n\nLet‚Äôs test that it works:\n\nf5(20)\n\n [1] \"1\"        \"2\"        \"Fizz\"     \"4\"        \"Buzz\"     \"Fizz\"    \n [7] \"7\"        \"8\"        \"Fizz\"     \"Buzz\"     \"11\"       \"Fizz\"    \n[13] \"13\"       \"14\"       \"FizzBuzz\" \"16\"       \"17\"       \"Fizz\"    \n[19] \"19\"       \"Buzz\"    \n\n\nNow, let‚Äôs benchmark it against f3() (still our fastest function so far):\nmark(f3(n), f5(n))\n [1] \"1\"        \"2\"        \"Fizz\"     \"4\"        \"Buzz\"     \"Fizz\"    \n [7] \"7\"        \"8\"        \"Fizz\"     \"Buzz\"     \"11\"       \"Fizz\"    \n[13] \"13\"       \"14\"       \"FizzBuzz\" \"16\"       \"17\"       \"Fizz\"    \n[19] \"19\"       \"Buzz\"     \"Fizz\"     \"22\"       \"23\"       \"Fizz\"    \n[25] \"Buzz\"     \"26\"       \"Fizz\"     \"28\"       \"29\"       \"FizzBuzz\"\n[31] \"31\"       \"32\"       \"Fizz\"     \"34\"       \"Buzz\"     \"Fizz\"    \n[37] \"37\"       \"38\"       \"Fizz\"     \"Buzz\"     \"41\"       \"Fizz\"\n...\n\n# A tibble: 2 √ó 13\n  expression      min median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc total_time\n  &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;   &lt;bch:tm&gt;\n1 f3(n)         116ms  120ms      7.45        NA    26.1      4    14      537ms\n2 f5(n)         925ms  925ms      1.08        NA     3.24     1     3      925ms\n# ‚Ñπ 4 more variables: result &lt;list&gt;, memory &lt;list&gt;, time &lt;list&gt;, gc &lt;list&gt;\nWarning message:\nSome expressions had a GC in every iteration; so filtering is disabled.\nf5() is 7.7 times slower.\nWhat happened?\nprint() returns its argument, but it additionally prints it to the standard output. This is why the mark() function printed the output of f5() before printing the timings.\nAs you can see, printing takes a long time.\nIf you are evaluating f3() on its own (e.g.¬†f3(20)), the returned result will also be printed to standard output and both functions will be equivalent. However, if you are using the function in another context, printing becomes an unnecessary and timely operation and f5() would be a very bad option. f5() is thus not a good function.\nHere is an example in which f5() would perform a totally unnecessary operation that f3() avoids:\n\na &lt;- f3(20)\n\n\nNo unnecessary printing.\n\n\na &lt;- f5(20)\n\n [1] \"1\"        \"2\"        \"Fizz\"     \"4\"        \"Buzz\"     \"Fizz\"    \n [7] \"7\"        \"8\"        \"Fizz\"     \"Buzz\"     \"11\"       \"Fizz\"    \n[13] \"13\"       \"14\"       \"FizzBuzz\" \"16\"       \"17\"       \"Fizz\"    \n[19] \"19\"       \"Buzz\"    \n\n\n\nUnnecessary printing.\n\nEven worse would be to use:\n\nf6 &lt;- function(n) {\n  for(i in 1:n) {\n    if(i %% 3 == 0 && i %% 5 == 0) {\n      print(\"FizzBuzz\")\n    } else if(i %% 3 == 0) {\n      print(\"Fizz\")\n    } else if(i %% 5 == 0) {\n      print(\"Buzz\")\n    } else {\n      print(i)\n    }\n  }\n}\n\nLet‚Äôs test it:\n\nf6(20)\n\n[1] 1\n[1] 2\n[1] \"Fizz\"\n[1] 4\n[1] \"Buzz\"\n[1] \"Fizz\"\n[1] 7\n[1] 8\n[1] \"Fizz\"\n[1] \"Buzz\"\n[1] 11\n[1] \"Fizz\"\n[1] 13\n[1] 14\n[1] \"FizzBuzz\"\n[1] 16\n[1] 17\n[1] \"Fizz\"\n[1] 19\n[1] \"Buzz\"\n\n\nThe values are correct, although the output is of a different type (NULL instead of a character since our function didn‚Äôt return anything and the values got printed as a side effect of the for loop).\nBenchmark against f3():\nmark(f3(n), f6(n), check = F)\n# A tibble: 2 √ó 13\n  expression      min median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc total_time\n  &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;   &lt;bch:tm&gt;\n1 f3(n)         105ms  108ms     9.10         NA    30.9      5    17      549ms\n2 f6(n)            6s     6s     0.167        NA     3.34     1    20         6s\n# ‚Ñπ 4 more variables: result &lt;list&gt;, memory &lt;list&gt;, time &lt;list&gt;, gc &lt;list&gt;\nWarning message:\nSome expressions had a GC in every iteration; so filtering is disabled.\n\nWe need to disable the check here because the results of the two functions are not the same.\n\nHere the difference in timing is a factor of 55.5 due to all those printing calls.\n\n\nExample 2\nOne modulo operation and equality test can be removed by replacing i %% 3 == 0 && i %% 5 == 0 by i %% 15 == 0. We now have three modulo operations and equality tests per iteration instead of four. This gives us a little speedup:\n\nf7 &lt;- function(n) {\n  z &lt;- character(n)\n  for(i in 1:n) {\n    if(i %% 15 == 0) {\n      z[i] &lt;- \"FizzBuzz\"\n    } else if(i %% 3 == 0) {\n      z[i] &lt;- \"Fizz\"\n    } else if(i %% 5 == 0) {\n      z[i] &lt;- \"Buzz\"\n    } else {\n      z[i] &lt;- i\n    }\n  }\n  z\n}\n\nThe benchmark with our fastest function f3() gives:\n\nmark(f3(n), f7(n))\n\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n\n\n# A tibble: 2 √ó 6\n  expression      min   median `itr/sec` mem_alloc `gc/sec`\n  &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n1 f3(n)         326ms    330ms      3.03     781KB     12.1\n2 f7(n)         311ms    311ms      3.22     852KB     11.3\n\n\nBut we can remove an additional modulo operation and equality test at each iteration by assigning i %% 3 == 0 and i %% 5 == 0 to variables:\n\nf8 &lt;- function(n) {\n  z &lt;- character(n)\n  for(i in 1:n) {\n    div3 &lt;- (i %% 3 == 0)\n    div5 &lt;- (i %% 5 == 0)\n    if(div3 && div5) {\n      z[i] &lt;- \"FizzBuzz\"\n    } else if(div3) {\n      z[i] &lt;- \"Fizz\"\n    } else if(div5) {\n      z[i] &lt;- \"Buzz\"\n    } else {\n      z[i] &lt;- i\n    }\n  }\n  z\n}\n\nNow we only have two modulo operations and equality tests per iteration and we get another little speedup when we benchmark it against f7(), our new best function:\n\nmark(f7(n), f8(n))\n\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n\n\n# A tibble: 2 √ó 6\n  expression      min   median `itr/sec` mem_alloc `gc/sec`\n  &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n1 f7(n)         183ms    186ms      5.36     781KB     19.7\n2 f8(n)         173ms    175ms      5.72     856KB     17.2\n\n\n\n\nExample 3\nWe can assign 1:n to z instead of initializing it as an empty vector, thus rendering the assignment of i to z[i] in the last else statement unnecessary:\n\nf9 &lt;- function(n) {\n  z &lt;- 1:n\n  for(i in z) {\n    div3 &lt;- (i %% 3 == 0)\n    div5 &lt;- (i %% 5 == 0)\n    if(div3 && div5) {\n      z[i] &lt;- \"FizzBuzz\"\n    } else if(div3) {\n      z[i] &lt;- \"Fizz\"\n    } else if(div5) {\n      z[i] &lt;- \"Buzz\"\n    } \n  }\n  z\n}\n\nThis function works:\n\nf9(20)\n\n [1] \"1\"        \"2\"        \"Fizz\"     \"4\"        \"Buzz\"     \"Fizz\"    \n [7] \"7\"        \"8\"        \"Fizz\"     \"Buzz\"     \"11\"       \"Fizz\"    \n[13] \"13\"       \"14\"       \"FizzBuzz\" \"16\"       \"17\"       \"Fizz\"    \n[19] \"19\"       \"Buzz\"    \n\n\nand we get a little more speedup when compared to f8()‚Äîour current best function:\n\nmark(f8(n), f9(n))\n\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n\n\n# A tibble: 2 √ó 6\n  expression      min   median `itr/sec` mem_alloc `gc/sec`\n  &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n1 f8(n)         180ms    182ms      5.37   781.3KB     17.9\n2 f9(n)         130ms    134ms      7.47    1.15MB     18.7\n\n\n\n\n\nVectorize whenever possible\nWe can actually get rid of the loop and use a vectorized approach instead, utilizing what really constitutes the strength of the R language. The following is pure R style at its best:\n\nf10 &lt;- function(n) {\n  z &lt;- 1:n\n  div3 &lt;- (z %% 3 == 0)\n  div5 &lt;- (z %% 5 == 0)\n  z[div3] &lt;- \"Fizz\"\n  z[div5] &lt;- \"Buzz\"\n  z[(div3 & div5)] &lt;- \"FizzBuzz\"\n  z\n}\n\nThis still give us the same result:\n\nf10(20)\n\n [1] \"1\"        \"2\"        \"Fizz\"     \"4\"        \"Buzz\"     \"Fizz\"    \n [7] \"7\"        \"8\"        \"Fizz\"     \"Buzz\"     \"11\"       \"Fizz\"    \n[13] \"13\"       \"14\"       \"FizzBuzz\" \"16\"       \"17\"       \"Fizz\"    \n[19] \"19\"       \"Buzz\"    \n\n\nNow for the benchmark with f9() (our best function up to this point):\n\nmark(f9(n), f10(n))\n\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n\n\n# A tibble: 2 √ó 6\n  expression      min   median `itr/sec` mem_alloc `gc/sec`\n  &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n1 f9(n)       114.6ms  117.8ms      8.11    1.21MB    17.8 \n2 f10(n)       30.2ms   33.9ms     29.2     5.62MB     1.94\n\n\nThe speedup of 3.5 shows the importance of using vectorization whenever possible.\n\n\nTry alternate methods\nSometimes, it isn‚Äôt obvious that one method will be faster than another. Benchmarking alternative expressions can teach you which ones are faster.\nFor instance, it is much faster to index a column from a dataframe by its name (e.g.¬†dataframe$column1) than by using list indexing (e.g.¬†dataframe[[1]]). Until you test it, there is nothing obvious about this because it has to do with how R processes the data under the hood.\n\n\nUse faster packages\nTo achieve the best performance, you should look for efficient packages and learn them.\nPackages exist which bring much more efficiency than can be achieved with base R or the tidyverse. In the case of data frames for example, there is data.table.\n\n\nConclusion\nStarting from our first function f1(), we have gained a speedup of 6, simply by writing better code and without using parallelization and additional hardware:\n\nmark(f1(n), f10(n))\n\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n\n\n# A tibble: 2 √ó 6\n  expression      min   median `itr/sec` mem_alloc `gc/sec`\n  &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n1 f1(n)         279ms  289.6ms      3.45   16.63MB    13.8 \n2 f10(n)       34.7ms   36.6ms     26.9     5.57MB     1.92\n\n\nIf we used a silly function such as f6() as our starting function, the speedup would be 333.\n\nBefore thinking about running R in parallel or throwing GPUs at your problem, hoping that these would solve the slowness of your code, identify the bottlenecks and rewrite the slow sections more efficiently.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Optimizations"
    ]
  },
  {
    "objectID": "r/hpc_optimizations.html#exercises",
    "href": "r/hpc_optimizations.html#exercises",
    "title": "Optimizations",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nConsider the following code:\nf1 &lt;- function(n) {\n  squares_sum &lt;- 0\n  for(i in 1:length(n)) {\n    squares_sum &lt;- squares_sum + n[i]^2\n  }\n  squares_sum\n}\n\nn &lt;- 1:10000\n\nf1(n)\nWrite a function f2() that is more efficient than f1() (make sure that both functions give you the same result and that f2() is indeed faster).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 2\nConsider the following code:\nf1 &lt;- function(n) {\n  cum_sum &lt;- numeric(0)\n  for (i in 1:length(n)) {\n    cum_sum &lt;- c(cum_sum, sum(n[1:i]))\n  }\n  cum_sum\n}\n\nn &lt;- 1:10000\n\nf1(n)\nWrite a more efficient code that gives the same result.\n\n\n\n\n\n\n\n\n\n\n\nExercise 3\nConsider the code:\nf1 &lt;- function(n, threshold) {\n  count &lt;- 0\n  for (i in 1:length(n)) {\n    if (n[i] &gt; threshold) {\n      count &lt;- count + 1\n    }\n  }\n  count\n}\n\nset.seed(42)\nn &lt;- runif(100000, min = 0, max = 1000)\nthreshold &lt;- 500\n\nf1(n, threshold)\nWrite a function f2() that is more efficient than f1() (make sure that both functions give you the same result and that f2() is indeed faster).",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Optimizations"
    ]
  },
  {
    "objectID": "r/hpc_future.html",
    "href": "r/hpc_future.html",
    "title": "The future package",
    "section": "",
    "text": "The future package is a modern package that brings a consistent and simple API for all evaluation strategies of futures in R.\nExcellent backends have been built on top of it.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "The future package"
    ]
  },
  {
    "objectID": "r/hpc_future.html#classic-parallel-packages-in-r",
    "href": "r/hpc_future.html#classic-parallel-packages-in-r",
    "title": "The future package",
    "section": "Classic parallel packages in R",
    "text": "Classic parallel packages in R\nWe talked in the previous section about various types of parallelism. Several options exist in R to run code in shared-memory or distributed parallelism.\nExamples of options for shared-memory parallelism:\n\nThe foreach package with backends such as doMC, now also part of the doParallel package.\nmclapply() and mcmapply() from the parallel package (part of the core distribution of R).\n\nExamples of options for distributed parallelism:\n\nThe foreach package with backends such as doSNOW, now also part of the doParallel package.\nThe suite of clusterApply() and par*apply() functions from the parallel package.\n\n\nThe parallel package is a merger of the former multicore package for shared-memory and of the snow package for distributed parallelism.\nSimilarly, the doParallel package is merger of the doMC package for use with foreach in shared-memory and the doSNOW package for use with foreach for distributed parallelism.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "The future package"
    ]
  },
  {
    "objectID": "r/hpc_future.html#the-future-package",
    "href": "r/hpc_future.html#the-future-package",
    "title": "The future package",
    "section": "The future package",
    "text": "The future package\nThe future package opened up a new landscape in the world of parallel R by providing a simple and consistent API for the evaluation of futures sequentially, through shared-memory parallelism, or through distributed parallelism.\n\nA future is an object that acts as an abstract representation for a value in the future. A future can be resolved (if the value has been computed) or unresolved. If the value is queried while the future is unresolved, the process is blocked until the future is resolved. Futures thus allow for asynchronous and parallel evaluations.\n\nThe evaluation strategy is set with the plan() function:\n\nplan(sequential):\nFutures are evaluated sequentially in the current R session.\nplan(multisession):\nFutures are evaluated by new R sessions spawned in the background (multi-processing in shared memory).\nplan(multicore):\nFutures are evaluated in processes forked from the existing process (multi-processing in shared memory).\nplan(cluster):\nFutures are evaluated on an ad-hoc cluster (distributed parallelism across multiple nodes).\n\n\nConsistency\nTo ensure a consistent behaviour across plans, all evaluations are done in a local environment:\n\nlibrary(future)\n\na &lt;- 1\n\nb %&lt;-% {      # %&lt;-% creates futures\n  a &lt;- 2\n}\n\na\n\n[1] 1",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "The future package"
    ]
  },
  {
    "objectID": "r/hpc_future.html#the-future-ecosystem",
    "href": "r/hpc_future.html#the-future-ecosystem",
    "title": "The future package",
    "section": "the future ecosystem",
    "text": "the future ecosystem\nSeveral great packages have been built on top of the future API.\n\nThe doFuture package allows to parallelize foreach expressions on the future evaluation strategies.\nSimilarly, the future.apply package parallelizes the *apply() functions on these strategies.\nThe furrr package provides a parallel version of purrr for those who prefer this approach to functional programming.\nThe future.callr package implements a future evaluation based on callr that resolves every future in a new R session. This removes any limitation on the number of background R parallel processes that can be active at the same time.\nThe future.batchtools package implements a future evaluation based on the batchtools package‚Äîa package that provides functions to interact with HPC systems schedulers such as Slurm.\n\nIn this course, we will cover foreach with doFuture in great details to explain all the important concepts. After that, you will be able to use any of these backends easily.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "The future package"
    ]
  },
  {
    "objectID": "r/hpc_data.html",
    "href": "r/hpc_data.html",
    "title": "Data on HPC clusters",
    "section": "",
    "text": "So far, we have played with randomly created data. In your work, you will often need to work with real world data.\nHow do you move it to the cluster? Where should you store it?\nIt‚Äôs time to talk about data on HPC clusters."
  },
  {
    "objectID": "r/hpc_data.html#transferring-data-tofrom-the-cluster",
    "href": "r/hpc_data.html#transferring-data-tofrom-the-cluster",
    "title": "Data on HPC clusters",
    "section": "Transferring data to/from the cluster",
    "text": "Transferring data to/from the cluster\n\nSecure Copy Protocol\nSecure Copy Protocol (SCP) allows to copy files over the Secure Shell Protocol (SSH) with the scp utility. scp follows a syntax similar to that of the cp command.\nNote that you need to run it from your local machines (not from the cluster).\n\nCopy from your machine to the cluster\n# Copy a local file to your home directory on the cluster\nscp /local/path/file username@hostname:\n# Copy a local file to some path on the cluster\nscp /local/path/file username@hostname:/remote/path\n\n\nCopy from the cluster to your machine\n# Copy a file from the cluster to some path on your machine\nscp username@hostname:/remote/path/file /local/path\n# Copy a file from the cluster to your current location on your machine\nscp username@hostname:/remote/path/file .\nYou can also use wildcards to transfer multiple files:\n# Copy all the Bash scripts from your cluster home dir to some local path\nscp username@hostname:*.sh /local/path\n\n\nCopying directories\nTo copy a directory, you need to add the -r (recursive) flag:\nscp -r /local/path/folder username@hostname:/remote/path\n\n\nCopying for Windows users\nMobaXterm users (on Windows) can copy files by dragging them between the local and remote machines in the GUI. Alternatively, they can use the download and upload buttons.\n\n\n\nSecure File Transfer Protocol\nThe Secure File Transfer Protocol (SFTP) is more sophisticated and allows additional operations in an interactive shell. The sftp command provided by OpenSSH and other packages launches an SFTP client:\nsftp username@hostname\n\nLook at your prompt: your usual Bash/Zsh prompt has been replaced with sftp&gt;.\n\nFrom this prompt, you can access a number of SFTP commands. Type help for a list:\nsftp&gt; help\nAvailable commands:\nbye                                Quit sftp\ncd path                            Change remote directory to 'path'\nchgrp [-h] grp path                Change group of file 'path' to 'grp'\nchmod [-h] mode path               Change permissions of file 'path' to 'mode'\nchown [-h] own path                Change owner of file 'path' to 'own'\ncopy oldpath newpath               Copy remote file\ncp oldpath newpath                 Copy remote file\ndf [-hi] [path]                    Display statistics for current directory or\n                                   filesystem containing 'path'\nexit                               Quit sftp\nget [-afpR] remote [local]         Download file\nhelp                               Display this help text\nlcd path                           Change local directory to 'path'\nlls [ls-options [path]]            Display local directory listing\nlmkdir path                        Create local directory\nln [-s] oldpath newpath            Link remote file (-s for symlink)\nlpwd                               Print local working directory\nls [-1afhlnrSt] [path]             Display remote directory listing\nlumask umask                       Set local umask to 'umask'\nmkdir path                         Create remote directory\nprogress                           Toggle display of progress meter\nput [-afpR] local [remote]         Upload file\npwd                                Display remote working directory\nquit                               Quit sftp\nreget [-fpR] remote [local]        Resume download file\nrename oldpath newpath             Rename remote file\nreput [-fpR] local [remote]        Resume upload file\nrm path                            Delete remote file\nrmdir path                         Remove remote directory\nsymlink oldpath newpath            Symlink remote file\nversion                            Show SFTP version\n!command                           Execute 'command' in local shell\n!                                  Escape to local shell\n?                                  Synonym for help\nAs this list shows, you have access to a number of classic Unix command such as cd, pwd, ls, etc. These commands will be executed on the remote machine.\nIn addition, there are a number of commands of the form l&lt;command&gt;. ‚Äúl‚Äù stands for ‚Äúlocal‚Äù.\nThese commands will be executed on your local machine.\nFor instance, ls will list the files in your current directory in the remote machine while lls (‚Äúlocal ls‚Äù) will list the files in your current directory on your computer.\nThis means that you are now able to navigate two file systems at once: your local machine and the remote machine.\n\nHere are a few examples:\n\nsftp&gt; pwd              # print remote working directory\nsftp&gt; lpwd             # print local working directory\nsftp&gt; ls               # list files in remote working directory\nsftp&gt; lls              # list files in local working directory\nsftp&gt; cd               # change the remote directory\nsftp&gt; lcd              # change the local directory\nsftp&gt; put local_file   # upload a file\nsftp&gt; get remote_file  # download a file\n\nCopying directories\nTo upload/download directories, you first need to create them in the destination, then copy the content with the -r (recursive) flag.\n\nIf you have a local directory called dir and you want to copy it to the cluster you need to run:\n\nsftp&gt; mkdir dir    # First create the directory\nsftp&gt; put -r dir   # Then copy the content\nTo terminate the session, press &lt;Ctrl+D&gt;.\n\n\n\nSyncing\nIf, instead of an occasional copying of files between your machine and the cluster, you want to keep a directory in sync between both machines, you might want to use rsync instead. You can look at the Alliance wiki page on rsync for complete instructions.\n\n\nHeavy transfers\nWhile the methods covered above work very well for limited amounts of data, if you need to make large transfers, you should use globus instead, following the instructions in the Alliance wiki page on this service.\n\n\nWindows line endings\nOn modern Mac operating systems and on Linux, lines in files are terminated with a newline (\\n). On Windows, they are terminated with a carriage return + newline (\\r\\n).\nWhen you transfer files between Windows and Linux (the cluster uses Linux), this creates a mismatch. Most modern software handle this correctly, but you may occasionally run into problems.\nThe solution is to convert a file from Windows encoding to Unix encoding with:\ndos2unix file\nTo convert a file back to Windows encoding, run:\nunix2dos file"
  },
  {
    "objectID": "r/hpc_data.html#files-management",
    "href": "r/hpc_data.html#files-management",
    "title": "Data on HPC clusters",
    "section": "Files management",
    "text": "Files management\nThe Alliance clusters are designed to handle large files very well. They are however slowed by the presence of many small files. It is thus important to know how to handle large collections of files by archiving them with tools such as tar and dar."
  },
  {
    "objectID": "r/hpc_data.html#where-to-store-data",
    "href": "r/hpc_data.html#where-to-store-data",
    "title": "Data on HPC clusters",
    "section": "Where to store data",
    "text": "Where to store data\nSupercomputers have several filesystems and you should familiarize yourself with the quotas and policies of the clusters you use.\nAll filesystems are mounted on all nodes so that you can access the data on any network storage from any node (e.g.¬†something in /home, /project, or /scratch will be accessible from any login node or compute node).\nA temporary folder gets created directly on the compute nodes while a job is running. In situations with heavy I/O or involving many files, it is worth considering copying data to it as part of the job. In that case, make sure to copy the results back to network storage before the end of the job."
  },
  {
    "objectID": "python/ws_webscraping.html",
    "href": "python/ws_webscraping.html",
    "title": "Web scraping with Beautiful Soup",
    "section": "",
    "text": "The internet is a trove of information. A lot of it is publicly available and thus suitable for use in research. Extracting that information and putting it in an organized format for analysis can however be extremely tedious.\nWeb scraping tools allow to automate parts of that process and Python is a popular language for the task.\nIn this workshop, I will guide you through a simple example using the package Beautiful Soup.",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Web scraping with bs4"
    ]
  },
  {
    "objectID": "python/ws_webscraping.html#html-and-css",
    "href": "python/ws_webscraping.html#html-and-css",
    "title": "Web scraping with Beautiful Soup",
    "section": "HTML and CSS",
    "text": "HTML and CSS\nHyperText Markup Language (HTML) is the standard markup language for websites: it encodes the information related to the formatting and structure of webpages. Additionally, some of the customization can be stored in Cascading Style Sheets (CSS) files.\nHTML uses tags of the form:\n&lt;some_tag&gt;Your content&lt;/some_tag&gt;\nSome tags have attributes:\n&lt;some_tag attribute_name=\"attribute value\"&gt;Your content&lt;/some_tag&gt;\n\nExamples:\n\nSite structure:\n\n&lt;h2&gt;This is a heading of level 2&lt;/h2&gt;\n&lt;p&gt;This is a paragraph&lt;/p&gt;\n\nFormatting:\n\n&lt;b&gt;This is bold&lt;/b&gt;\n&lt;a href=\"https://some.url\"&gt;This is the text for a link&lt;/a&gt;",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Web scraping with bs4"
    ]
  },
  {
    "objectID": "python/ws_webscraping.html#web-scrapping",
    "href": "python/ws_webscraping.html#web-scrapping",
    "title": "Web scraping with Beautiful Soup",
    "section": "Web scrapping",
    "text": "Web scrapping\nWeb scraping is a general term for a set of tools which allow for the extraction of data from the web automatically.\nWhile most of the data on the internet is publicly available, it is illegal to scrape some sites and you should always look into the policy of a site before attempting to scrape it. Some sites will also block you if you submit too many requests in a short amount of time, so remember to scrape responsibly.",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Web scraping with bs4"
    ]
  },
  {
    "objectID": "python/ws_webscraping.html#example-for-this-workshop",
    "href": "python/ws_webscraping.html#example-for-this-workshop",
    "title": "Web scraping with Beautiful Soup",
    "section": "Example for this workshop",
    "text": "Example for this workshop\nWe will use a website from the University of Tennessee containing a database of PhD theses from that university.\nOur goal is to scrape data from this site to produce a dataframe with the date, major, and advisor for each dissertation.\n\nWe will only do this for the first page which contains the links to the 100 most recent theses. If you really wanted to gather all the data, you would have to do this for all pages.",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Web scraping with bs4"
    ]
  },
  {
    "objectID": "python/ws_webscraping.html#lets-look-at-the-site",
    "href": "python/ws_webscraping.html#lets-look-at-the-site",
    "title": "Web scraping with Beautiful Soup",
    "section": "Let‚Äôs look at the site",
    "text": "Let‚Äôs look at the site\nFirst of all, let‚Äôs have a close look at the website we want to scrape to think carefully about what we want to do. Before starting to write code, it is always a good idea to think about what you are trying to achieve with your code.\nTo create a dataframe with the data for all the dissertations on that first page, we need to do two things:\n\nStep 1: from the dissertations database first page, we want to scrape the list of URLs for the dissertation pages.\nStep 2: once we have the URLs, we want to scrape those pages too to get the date, major, and advisor for each dissertation.",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Web scraping with bs4"
    ]
  },
  {
    "objectID": "python/ws_webscraping.html#load-packages",
    "href": "python/ws_webscraping.html#load-packages",
    "title": "Web scraping with Beautiful Soup",
    "section": "Load packages",
    "text": "Load packages\nLet‚Äôs load the packages that will make scraping websites with Python easier:\n\nimport requests                 # To download the html data from a site\nfrom bs4 import BeautifulSoup   # To parse the html data\nimport time                     # To add a delay between each requests\nimport pandas as pd             # To store our data in a DataFrame",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Web scraping with bs4"
    ]
  },
  {
    "objectID": "python/ws_webscraping.html#send-request-to-the-main-site",
    "href": "python/ws_webscraping.html#send-request-to-the-main-site",
    "title": "Web scraping with Beautiful Soup",
    "section": "Send request to the main site",
    "text": "Send request to the main site\nAs mentioned above, our site is the database of PhD dissertations from the University of Tennessee.\nLet‚Äôs create a string with the URL:\n\nurl = \"https://trace.tennessee.edu/utk_graddiss/index.html\"\n\nFirst, we send a request to that URL and save the response in a variable called r:\n\nr = requests.get(url)\n\nLet‚Äôs see what our response looks like:\n\nr\n\n&lt;Response [200]&gt;\n\n\nIf you look in the list of HTTP status codes, you can see that a response with a code of 200 means that the request was successful.",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Web scraping with bs4"
    ]
  },
  {
    "objectID": "python/ws_webscraping.html#explore-the-raw-data",
    "href": "python/ws_webscraping.html#explore-the-raw-data",
    "title": "Web scraping with Beautiful Soup",
    "section": "Explore the raw data",
    "text": "Explore the raw data\nTo get the actual content of the response as unicode (text), we can use the text property of the response. This will give us the raw HTML markup from the webpage.\nLet‚Äôs print the first 200 characters:\n\nprint(r.text[:200])\n\n\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;&lt;!-- inj yui3-seed: --&gt;&lt;script type='text/javascript' src='//cdnjs.cloudflare.com/ajax/libs/yui/3.6.0/yui/yui-min.js'&gt;&lt;/script&gt;&lt;script type='text/javascript' sr",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Web scraping with bs4"
    ]
  },
  {
    "objectID": "python/ws_webscraping.html#parse-the-data",
    "href": "python/ws_webscraping.html#parse-the-data",
    "title": "Web scraping with Beautiful Soup",
    "section": "Parse the data",
    "text": "Parse the data\nThe package Beautiful Soup transforms (parses) such HTML data into a parse tree, which will make extracting information easier.\nLet‚Äôs create an object called mainpage with the parse tree:\n\nmainpage = BeautifulSoup(r.text, \"html.parser\")\n\n\nhtml.parser is the name of the parser that we are using here. It is better to use a specific parser to get consistent results across environments.\n\nWe can print the beginning of the parsed result:\n\nprint(mainpage.prettify()[:200])\n\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n &lt;head&gt;\n  &lt;!-- inj yui3-seed: --&gt;\n  &lt;script src=\"//cdnjs.cloudflare.com/ajax/libs/yui/3.6.0/yui/yui-min.js\" type=\"text/javascript\"&gt;\n  &lt;/script&gt;\n  &lt;script src=\"//ajax.g\n\n\n\nThe prettify method turns the BeautifulSoup object we created into a string (which is needed for slicing).\n\nIt doesn‚Äôt look any more clear to us, but it is now in a format the Beautiful Soup package can work with.\nFor instance, we can get the HTML segment containing the title with three methods:\n\nusing the title tag name:\n\n\nmainpage.title\n\n&lt;title&gt;\nDoctoral Dissertations | Graduate School | University of Tennessee, Knoxville\n&lt;/title&gt;\n\n\n\nusing find to look for HTML markers (tags, attributes, etc.):\n\n\nmainpage.find(\"title\")\n\n&lt;title&gt;\nDoctoral Dissertations | Graduate School | University of Tennessee, Knoxville\n&lt;/title&gt;\n\n\n\nusing select which accepts CSS selectors:\n\n\nmainpage.select(\"title\")\n\n[&lt;title&gt;\n Doctoral Dissertations | Graduate School | University of Tennessee, Knoxville\n &lt;/title&gt;]\n\n\nfind will only return the first element. find_all will return all elements. select will also return all elements. Which one you chose depends on what you need to extract. There often several ways to get you there.\nHere are other examples of data extraction:\n\nmainpage.head\n\n&lt;head&gt;&lt;!-- inj yui3-seed: --&gt;&lt;script src=\"//cdnjs.cloudflare.com/ajax/libs/yui/3.6.0/yui/yui-min.js\" type=\"text/javascript\"&gt;&lt;/script&gt;&lt;script src=\"//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js\" type=\"text/javascript\"&gt;&lt;/script&gt;&lt;!-- Adobe Analytics --&gt;&lt;script src=\"https://assets.adobedtm.com/4a848ae9611a/d0e96722185b/launch-d525bb0064d8.min.js\" type=\"text/javascript\"&gt;&lt;/script&gt;&lt;script src=\"/assets/nr_browser_production.js\" type=\"text/javascript\"&gt;&lt;/script&gt;\n&lt;!-- def.1 --&gt;\n&lt;meta charset=\"utf-8\"/&gt;\n&lt;meta content=\"width=device-width\" name=\"viewport\"/&gt;\n&lt;title&gt;\nDoctoral Dissertations | Graduate School | University of Tennessee, Knoxville\n&lt;/title&gt;\n&lt;!-- FILE meta-tags.inc --&gt;&lt;!-- FILE: /srv/sequoia/main/data/assets/site/meta-tags.inc --&gt;\n&lt;!-- FILE: meta-tags.inc (cont) --&gt;\n&lt;!-- sh.1 --&gt;\n&lt;link href=\"/ir-style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/&gt;\n&lt;link href=\"/ir-custom.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/&gt;\n&lt;link href=\"ir-custom.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/&gt;\n&lt;link href=\"/ir-local.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/&gt;\n&lt;link href=\"ir-local.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/&gt;\n&lt;link href=\"/ir-print.css\" media=\"print\" rel=\"stylesheet\" type=\"text/css\"/&gt;\n&lt;link href=\"/assets/floatbox/floatbox.css\" rel=\"stylesheet\" type=\"text/css\"/&gt;\n&lt;link href=\"/recent.rss\" rel=\"alternate\" title=\"Site Feed\" type=\"application/rss+xml\"/&gt;\n&lt;link href=\"/favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\"/&gt;\n&lt;!--[if IE]&gt;\n&lt;link rel=\"stylesheet\" href=\"/ir-ie.css\" type=\"text/css\" media=\"screen\"&gt;\n&lt;![endif]--&gt;\n&lt;!-- JS --&gt;\n&lt;script src=\"/assets/jsUtilities.js\" type=\"text/javascript\"&gt;&lt;/script&gt;\n&lt;script src=\"/assets/footnoteLinks.js\" type=\"text/javascript\"&gt;&lt;/script&gt;\n&lt;script src=\"/assets/scripts/yui-init.pack.js\" type=\"text/javascript\"&gt;&lt;/script&gt;\n&lt;script src=\"/assets/scripts/bepress-init.pack.js\" type=\"text/javascript\"&gt;&lt;/script&gt;\n&lt;script src=\"/assets/scripts/JumpListYUI.pack.js\" type=\"text/javascript\"&gt;&lt;/script&gt;\n&lt;!-- end sh.1 --&gt;\n&lt;script type=\"text/javascript\"&gt;var pageData = {\"page\":{\"environment\":\"prod\",\"productName\":\"bpdg\",\"language\":\"en\",\"name\":\"ir_etd\",\"businessUnit\":\"els:rp:st\"},\"visitor\":{}};&lt;/script&gt;\n&lt;/head&gt;\n\n\n\nmainpage.a\n\n&lt;a data-scroll=\"\" href=\"https://trace.tennessee.edu\" title=\"Home\"&gt;Home&lt;/a&gt;\n\n\n\nmainpage.find_all(\"a\")[:5]\n\n[&lt;a data-scroll=\"\" href=\"https://trace.tennessee.edu\" title=\"Home\"&gt;Home&lt;/a&gt;,\n &lt;a data-scroll=\"\" href=\"https://trace.tennessee.edu/do/search/advanced/\" title=\"Search\"&gt;&lt;i class=\"icon-search\"&gt;&lt;/i&gt; Search&lt;/a&gt;,\n &lt;a data-scroll=\"\" href=\"https://trace.tennessee.edu/communities.html\" title=\"Browse\"&gt;Browse Collections&lt;/a&gt;,\n &lt;a data-scroll=\"\" href=\"/cgi/myaccount.cgi?context=utk_graddiss\" title=\"My Account\"&gt;My Account&lt;/a&gt;,\n &lt;a data-scroll=\"\" href=\"https://trace.tennessee.edu/about.html\" title=\"About\"&gt;About&lt;/a&gt;]\n\n\n\nmainpage.select(\"a\")[:5]\n\n[&lt;a data-scroll=\"\" href=\"https://trace.tennessee.edu\" title=\"Home\"&gt;Home&lt;/a&gt;,\n &lt;a data-scroll=\"\" href=\"https://trace.tennessee.edu/do/search/advanced/\" title=\"Search\"&gt;&lt;i class=\"icon-search\"&gt;&lt;/i&gt; Search&lt;/a&gt;,\n &lt;a data-scroll=\"\" href=\"https://trace.tennessee.edu/communities.html\" title=\"Browse\"&gt;Browse Collections&lt;/a&gt;,\n &lt;a data-scroll=\"\" href=\"/cgi/myaccount.cgi?context=utk_graddiss\" title=\"My Account\"&gt;My Account&lt;/a&gt;,\n &lt;a data-scroll=\"\" href=\"https://trace.tennessee.edu/about.html\" title=\"About\"&gt;About&lt;/a&gt;]",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Web scraping with bs4"
    ]
  },
  {
    "objectID": "python/ws_webscraping.html#test-run",
    "href": "python/ws_webscraping.html#test-run",
    "title": "Web scraping with Beautiful Soup",
    "section": "Test run",
    "text": "Test run\n\nIdentify relevant markers\nThe html code for this webpage contains the data we are interested in, but it is mixed in with a lot of HTML formatting and data we don‚Äôt care about. We need to extract the data relevant to us and turn it into a workable format.\nThe first step is to find the HTML markers that contain our data. One option is to use a web inspector or‚Äîeven easier‚Äîthe SelectorGadget, a JavaScript bookmarklet built by Andrew Cantino.\nTo use this tool, go to the SelectorGadget website and drag the link of the bookmarklet to your bookmarks bar.\nNow, go to the dissertations database first page and click on the bookmarklet in your bookmarks bar. You will see a floating box at the bottom of your screen. As you move your mouse across the screen, an orange rectangle appears around each element over which you pass.\nClick on one of the dissertation links: now, there is an a appearing in the box at the bottom as well as the number of elements selected. The selected elements are highlighted in yellow. Those elements are links (in HTML, a tags define hyperlinks).\nAs you can see, all the links we want are selected. However, there are many other links we don‚Äôt want that are also highlighted. In fact, all links in the document are selected. We need to remove the categories of links that we don‚Äôt want. To do this, hover above any of the links we don‚Äôt want. You will see a red rectangle around it. Click on it: now all similar links are gone. You might have to do this a few times until only the relevant links (i.e.¬†those that lead to the dissertation information pages) remain highlighted.\nAs there are 100 such links per page, the count of selected elements in the bottom floating box should be down to 100.\nIn the main section of the floating box, you can now see: .article-listing a. This means that the data we want are under the HTML elements .article-listing a (the class .article-listing and the tag a).\n\n\nExtract test URL\nIt is a good idea to test things out on a single element before doing a massive batch scraping of a site, so let‚Äôs test our method for the first dissertation.\nTo start, we need to extract the first URL. Here, we will use the CSS selectors (we can get there using find too). mainpage.select(\".article-listing a\") would give us all the results (100 links):\n\nlen(mainpage.select(\".article-listing a\"))\n\n100\n\n\nTo get the first one, we index it:\n\nmainpage.select(\".article-listing a\")[0]\n\n&lt;a href=\"https://trace.tennessee.edu/utk_graddiss/10400\"&gt;The Sons of Melisende: Baldwin III, Amalric, and Kingship in the Kingdom of Jerusalem, 1143-1174 CE&lt;/a&gt;\n\n\nThe actual URL is contained in the href attribute. Attributes can be extracted with the get method:\n\nmainpage.select(\".article-listing a\")[0].get(\"href\")\n\n'https://trace.tennessee.edu/utk_graddiss/10400'\n\n\nWe now have our URL as a string. We can double-check that it is indeed a string:\n\ntype(mainpage.select(\".article-listing a\")[0].get(\"href\"))\n\nstr\n\n\nThis is exactly what we need to send a request to that site, so let‚Äôs create an object url_test with it:\n\nurl_test = mainpage.select(\".article-listing a\")[0].get(\"href\")\n\nWe have our first thesis URL:\n\nprint(url_test)\n\nhttps://trace.tennessee.edu/utk_graddiss/10400\n\n\n\n\nSend request to test URL\nNow that we have the URL for the first dissertation information page, we want to extract the date, major, and advisor for that dissertation.\nThe first thing to do‚Äîas we did earlier with the database site‚Äîis to send a request to that page. Let‚Äôs assign it to a new object that we will call r_test:\n\nr_test = requests.get(url_test)\n\nThen we can parse it with Beautiful Soup (as we did before). Let‚Äôs create a dissertpage_test object:\n\ndissertpage_test = BeautifulSoup(r_test.text, \"html.parser\")\n\n\n\nGet data for test URL\nIt is time to extract the publication date, major, and advisor for our test URL.\nLet‚Äôs start with the date. Thanks to the SelectorGadget, following the method we saw earlier, we can see that we now need elements marked by #publication_date p.\nWe can use select as we did earlier:\n\ndissertpage_test.select(\"#publication_date p\")\n\n[&lt;p&gt;8-2024&lt;/p&gt;]\n\n\nNotice the square brackets around our result: this is import. It shows us that we have a ResultSet (a list of results specific to Beautiful Soup). This is because select returns all the results. Here, we have a single result, but the format is still list-like. Before we can go further, we need to index the value out of it:\n\ndissertpage_test.select(\"#publication_date p\")[0]\n\n&lt;p&gt;8-2024&lt;/p&gt;\n\n\nWe can now get the text out of this paragraph with the text attribute:\n\ndissertpage_test.select(\"#publication_date p\")[0].text\n\n'8-2024'\n\n\nWe could save it in a variable date_test:\n\ndate_test = dissertpage_test.select(\"#publication_date p\")[0].text\n\n\n\nYour turn:\n\nGet the major and advisor for our test URL.",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Web scraping with bs4"
    ]
  },
  {
    "objectID": "python/ws_webscraping.html#full-run",
    "href": "python/ws_webscraping.html#full-run",
    "title": "Web scraping with Beautiful Soup",
    "section": "Full run",
    "text": "Full run\nOnce everything is working for a test site, we can do some bulk scraping.\n\nExtract all URLs\nWe already know how to get the 100 dissertations links from the main page: mainpage.select(\".article-listing a\"). Let‚Äôs assign it to a variable:\n\ndissertlinks = mainpage.select(\".article-listing a\")\n\nThis ResultSet is an iterable, meaning that it can be used in a loop.\nLet‚Äôs write a loop to extract all the URLs from this ResultSet of links:\n\n# Create an empty list before filling it during the loop\nurls = []\n\nfor link in dissertlinks:\n    urls.append(link.get(\"href\"))\n\nLet‚Äôs see our first 5 URLs:\n\nurls[:5]\n\n['https://trace.tennessee.edu/utk_graddiss/10400',\n 'https://trace.tennessee.edu/utk_graddiss/11307',\n 'https://trace.tennessee.edu/utk_graddiss/10081',\n 'https://trace.tennessee.edu/utk_graddiss/10401',\n 'https://trace.tennessee.edu/utk_graddiss/11330']\n\n\n\n\nExtract data from each page\nFor each element of urls (i.e.¬†for each dissertation URL), we can now get our information.\n\n# Create an empty list\nls = []\n\n# For each element of our list of sites\nfor url in urls:\n    # Send a request to the site\n    r = requests.get(url)\n    # Parse the result\n    dissertpage = BeautifulSoup(r.text, \"html.parser\")\n    # Get the date\n    date = dissertpage.select(\"#publication_date p\")[0].text\n    # Get the major\n    major = dissertpage.select(\"#department p\")[0].text\n    # Get the advisor\n    advisor = dissertpage.select(\"#advisor1 p\")[0].text\n    # Store the results in the list\n    ls.append((date, major, advisor))\n    # Add a delay at each iteration\n    time.sleep(0.1)\n\n\nSome sites will block requests if they are too frequent. Adding a little delay between requests is often a good idea.",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Web scraping with bs4"
    ]
  },
  {
    "objectID": "python/ws_webscraping.html#store-results-in-dataframe",
    "href": "python/ws_webscraping.html#store-results-in-dataframe",
    "title": "Web scraping with Beautiful Soup",
    "section": "Store results in DataFrame",
    "text": "Store results in DataFrame\nA DataFrame would be a lot more convenient than a list to hold our results.\nFirst, we create a list with the column names for our future DataFrame:\n\ncols = [\"Date\", \"Major\", \"Advisor\"]\n\nThen we create our DataFrame:\n\ndf = pd.DataFrame(ls, columns=cols)\n\n\ndf\n\n\n\n\n\n\n\n\nDate\nMajor\nAdvisor\n\n\n\n\n0\n8-2024\nHistory\nJay Rubenstein\n\n\n1\n12-2024\nBiochemistry and Cellular and Molecular Biology\nDr. Rebecca A. Prosser\n\n\n2\n5-2024\nBusiness Administration\nLarry A. Fauver\n\n\n3\n8-2024\nElectrical Engineering\nDan Wilson\n\n\n4\n12-2024\nMechanical Engineering\nPrashant Singh\n\n\n...\n...\n...\n...\n\n\n95\n5-2024\nMechanical Engineering\nFeng-Yuan Zhang\n\n\n96\n8-2024\nComputer Science\nScott Ruoti\n\n\n97\n8-2024\nMechanical Engineering\nTony L. Schmitz\n\n\n98\n8-2024\nMicrobiology\nShigetoshi Eda\n\n\n99\n8-2024\nEnergy Science and Engineering\nDavid C. Donovan\n\n\n\n\n100 rows √ó 3 columns",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Web scraping with bs4"
    ]
  },
  {
    "objectID": "python/ws_webscraping.html#save-results-to-file",
    "href": "python/ws_webscraping.html#save-results-to-file",
    "title": "Web scraping with Beautiful Soup",
    "section": "Save results to file",
    "text": "Save results to file\nAs a final step, we will save our data to a CSV file:\ndf.to_csv('dissertations_data.csv', index=False)\n\nThe default index=True writes the row numbers. We are not writing these indices in our file by changing the value of this argument to False.\n\nIf you are using a Jupyter notebook or the IPython shell, you can type !ls to see that the file is there and !cat dissertations_data.csv to print its content.\n\n! is a magic command that allows to run Unix shell commands in a notebook or IPython shell.",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Web scraping with bs4"
    ]
  },
  {
    "objectID": "python/ws_pandas.html",
    "href": "python/ws_pandas.html",
    "title": "Data frames with pandas",
    "section": "",
    "text": "pandas is a Python library built to manipulate data frames and time series.\nFor this section, we will use the Covid-19 data from the Johns Hopkins University CSSE repository.\nYou can visualize this data in a dashboard created by the Johns Hopkins University Center for Systems Science and Engineering.",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Data frames with pandas"
    ]
  },
  {
    "objectID": "python/ws_pandas.html#setup",
    "href": "python/ws_pandas.html#setup",
    "title": "Data frames with pandas",
    "section": "Setup",
    "text": "Setup\nFirst, we need to load the pandas library and read in the data from the web:\n\n# Load the pandas library and create a shorter name for it\nimport pandas as pd\n\n# The global confirmed cases are available in CSV format at the url:\nurl = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\"\n\n# pandas allows to read in data from the web directly\ncases = pd.read_csv(url)",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Data frames with pandas"
    ]
  },
  {
    "objectID": "python/ws_pandas.html#first-look-at-the-data",
    "href": "python/ws_pandas.html#first-look-at-the-data",
    "title": "Data frames with pandas",
    "section": "First look at the data",
    "text": "First look at the data\nWhat does our data look like?\n\ncases\n\n\n\n\n\n\n\n\nProvince/State\nCountry/Region\nLat\nLong\n1/22/20\n1/23/20\n1/24/20\n1/25/20\n1/26/20\n1/27/20\n...\n2/28/23\n3/1/23\n3/2/23\n3/3/23\n3/4/23\n3/5/23\n3/6/23\n3/7/23\n3/8/23\n3/9/23\n\n\n\n\n0\nNaN\nAfghanistan\n33.939110\n67.709953\n0\n0\n0\n0\n0\n0\n...\n209322\n209340\n209358\n209362\n209369\n209390\n209406\n209436\n209451\n209451\n\n\n1\nNaN\nAlbania\n41.153300\n20.168300\n0\n0\n0\n0\n0\n0\n...\n334391\n334408\n334408\n334427\n334427\n334427\n334427\n334427\n334443\n334457\n\n\n2\nNaN\nAlgeria\n28.033900\n1.659600\n0\n0\n0\n0\n0\n0\n...\n271441\n271448\n271463\n271469\n271469\n271477\n271477\n271490\n271494\n271496\n\n\n3\nNaN\nAndorra\n42.506300\n1.521800\n0\n0\n0\n0\n0\n0\n...\n47866\n47875\n47875\n47875\n47875\n47875\n47875\n47875\n47890\n47890\n\n\n4\nNaN\nAngola\n-11.202700\n17.873900\n0\n0\n0\n0\n0\n0\n...\n105255\n105277\n105277\n105277\n105277\n105277\n105277\n105277\n105288\n105288\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n284\nNaN\nWest Bank and Gaza\n31.952200\n35.233200\n0\n0\n0\n0\n0\n0\n...\n703228\n703228\n703228\n703228\n703228\n703228\n703228\n703228\n703228\n703228\n\n\n285\nNaN\nWinter Olympics 2022\n39.904200\n116.407400\n0\n0\n0\n0\n0\n0\n...\n535\n535\n535\n535\n535\n535\n535\n535\n535\n535\n\n\n286\nNaN\nYemen\n15.552727\n48.516388\n0\n0\n0\n0\n0\n0\n...\n11945\n11945\n11945\n11945\n11945\n11945\n11945\n11945\n11945\n11945\n\n\n287\nNaN\nZambia\n-13.133897\n27.849332\n0\n0\n0\n0\n0\n0\n...\n343012\n343012\n343079\n343079\n343079\n343135\n343135\n343135\n343135\n343135\n\n\n288\nNaN\nZimbabwe\n-19.015438\n29.154857\n0\n0\n0\n0\n0\n0\n...\n263921\n264127\n264127\n264127\n264127\n264127\n264127\n264127\n264276\n264276\n\n\n\n\n289 rows √ó 1147 columns\n\n\n\n\n# Quick summary of the data\ncases.describe()\n\n\n\n\n\n\n\n\nLat\nLong\n1/22/20\n1/23/20\n1/24/20\n1/25/20\n1/26/20\n1/27/20\n1/28/20\n1/29/20\n...\n2/28/23\n3/1/23\n3/2/23\n3/3/23\n3/4/23\n3/5/23\n3/6/23\n3/7/23\n3/8/23\n3/9/23\n\n\n\n\ncount\n287.000000\n287.000000\n289.000000\n289.000000\n289.000000\n289.000000\n289.000000\n289.000000\n289.000000\n289.000000\n...\n2.890000e+02\n2.890000e+02\n2.890000e+02\n2.890000e+02\n2.890000e+02\n2.890000e+02\n2.890000e+02\n2.890000e+02\n2.890000e+02\n2.890000e+02\n\n\nmean\n19.718719\n22.182084\n1.927336\n2.273356\n3.266436\n4.972318\n7.335640\n10.134948\n19.307958\n21.346021\n...\n2.336755e+06\n2.337519e+06\n2.338173e+06\n2.338805e+06\n2.338992e+06\n2.339187e+06\n2.339387e+06\n2.339839e+06\n2.340460e+06\n2.341073e+06\n\n\nstd\n25.956609\n77.870931\n26.173664\n26.270191\n32.707271\n45.523871\n63.623197\n85.724481\n210.329649\n211.628535\n...\n8.506608e+06\n8.511285e+06\n8.514488e+06\n8.518031e+06\n8.518408e+06\n8.518645e+06\n8.519346e+06\n8.521641e+06\n8.524968e+06\n8.527765e+06\n\n\nmin\n-71.949900\n-178.116500\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000e+00\n0.000000e+00\n0.000000e+00\n0.000000e+00\n0.000000e+00\n0.000000e+00\n0.000000e+00\n0.000000e+00\n0.000000e+00\n0.000000e+00\n\n\n25%\n4.072192\n-32.823050\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.456700e+04\n1.456700e+04\n1.456700e+04\n1.456700e+04\n1.456700e+04\n1.456700e+04\n1.456700e+04\n1.456700e+04\n1.456700e+04\n1.456700e+04\n\n\n50%\n21.512583\n20.939400\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.032480e+05\n1.032480e+05\n1.032480e+05\n1.032480e+05\n1.032480e+05\n1.032480e+05\n1.032480e+05\n1.032480e+05\n1.032480e+05\n1.032480e+05\n\n\n75%\n40.401784\n89.224350\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.051998e+06\n1.052122e+06\n1.052247e+06\n1.052382e+06\n1.052519e+06\n1.052664e+06\n1.052664e+06\n1.052926e+06\n1.053068e+06\n1.053213e+06\n\n\nmax\n71.706900\n178.065000\n444.000000\n444.000000\n549.000000\n761.000000\n1058.000000\n1423.000000\n3554.000000\n3554.000000\n...\n1.034435e+08\n1.035339e+08\n1.035898e+08\n1.036487e+08\n1.036508e+08\n1.036470e+08\n1.036555e+08\n1.036909e+08\n1.037558e+08\n1.038027e+08\n\n\n\n\n8 rows √ó 1145 columns\n\n\n\n\nOf course, this value is meaningless for Lat and Long!\n\n\n# Data types of the various columns\ncases.dtypes\n\nProvince/State     object\nCountry/Region     object\nLat               float64\nLong              float64\n1/22/20             int64\n                   ...   \n3/5/23              int64\n3/6/23              int64\n3/7/23              int64\n3/8/23              int64\n3/9/23              int64\nLength: 1147, dtype: object\n\n\n\ncases.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 289 entries, 0 to 288\nColumns: 1147 entries, Province/State to 3/9/23\ndtypes: float64(2), int64(1143), object(2)\nmemory usage: 2.5+ MB\n\n\n\ncases.shape\n\n(289, 1147)",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Data frames with pandas"
    ]
  },
  {
    "objectID": "python/ws_pandas.html#cases-per-country-by-date",
    "href": "python/ws_pandas.html#cases-per-country-by-date",
    "title": "Data frames with pandas",
    "section": "Cases per country by date",
    "text": "Cases per country by date\nThe dataset is a time series: this means that we have the cumulative numbers up to each date.\n\n# Let's get rid of the latitude and longitude to simplify our data\nsimple = cases.drop(columns=['Lat', 'Long'])\nsimple\n\n\n\n\n\n\n\n\nProvince/State\nCountry/Region\n1/22/20\n1/23/20\n1/24/20\n1/25/20\n1/26/20\n1/27/20\n1/28/20\n1/29/20\n...\n2/28/23\n3/1/23\n3/2/23\n3/3/23\n3/4/23\n3/5/23\n3/6/23\n3/7/23\n3/8/23\n3/9/23\n\n\n\n\n0\nNaN\nAfghanistan\n0\n0\n0\n0\n0\n0\n0\n0\n...\n209322\n209340\n209358\n209362\n209369\n209390\n209406\n209436\n209451\n209451\n\n\n1\nNaN\nAlbania\n0\n0\n0\n0\n0\n0\n0\n0\n...\n334391\n334408\n334408\n334427\n334427\n334427\n334427\n334427\n334443\n334457\n\n\n2\nNaN\nAlgeria\n0\n0\n0\n0\n0\n0\n0\n0\n...\n271441\n271448\n271463\n271469\n271469\n271477\n271477\n271490\n271494\n271496\n\n\n3\nNaN\nAndorra\n0\n0\n0\n0\n0\n0\n0\n0\n...\n47866\n47875\n47875\n47875\n47875\n47875\n47875\n47875\n47890\n47890\n\n\n4\nNaN\nAngola\n0\n0\n0\n0\n0\n0\n0\n0\n...\n105255\n105277\n105277\n105277\n105277\n105277\n105277\n105277\n105288\n105288\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n284\nNaN\nWest Bank and Gaza\n0\n0\n0\n0\n0\n0\n0\n0\n...\n703228\n703228\n703228\n703228\n703228\n703228\n703228\n703228\n703228\n703228\n\n\n285\nNaN\nWinter Olympics 2022\n0\n0\n0\n0\n0\n0\n0\n0\n...\n535\n535\n535\n535\n535\n535\n535\n535\n535\n535\n\n\n286\nNaN\nYemen\n0\n0\n0\n0\n0\n0\n0\n0\n...\n11945\n11945\n11945\n11945\n11945\n11945\n11945\n11945\n11945\n11945\n\n\n287\nNaN\nZambia\n0\n0\n0\n0\n0\n0\n0\n0\n...\n343012\n343012\n343079\n343079\n343079\n343135\n343135\n343135\n343135\n343135\n\n\n288\nNaN\nZimbabwe\n0\n0\n0\n0\n0\n0\n0\n0\n...\n263921\n264127\n264127\n264127\n264127\n264127\n264127\n264127\n264276\n264276\n\n\n\n\n289 rows √ó 1145 columns\n\n\n\n Some countries (e.g.¬†Australia) are split between several provinces or states so we will have to add the values of all their provinces/states to get their totals.\nHere is how to make the sum for all Australian states:\nLet‚Äôs first select all the data for Australia: we want all the rows for which the Country/Region column is equal to Australia.\nFirst, we want to select the Country/Region column. There are several ways to index in pandas.\nWhen indexing columns, one can use square brackets directly after the DataFrame to index:\n\nsimple['Country/Region']\n\n0               Afghanistan\n1                   Albania\n2                   Algeria\n3                   Andorra\n4                    Angola\n               ...         \n284      West Bank and Gaza\n285    Winter Olympics 2022\n286                   Yemen\n287                  Zambia\n288                Zimbabwe\nName: Country/Region, Length: 289, dtype: object\n\n\nHowever, it is more efficient to use the .loc or .iloc methods.\n\nUse .loc when using labels or booleans:\n\n\nsimple.loc[:, 'Country/Region']\n\n0               Afghanistan\n1                   Albania\n2                   Algeria\n3                   Andorra\n4                    Angola\n               ...         \n284      West Bank and Gaza\n285    Winter Olympics 2022\n286                   Yemen\n287                  Zambia\n288                Zimbabwe\nName: Country/Region, Length: 289, dtype: object\n\n\n\nUse .iloc when using indices:\n\n\nsimple.iloc[:, 1]\n\n0               Afghanistan\n1                   Albania\n2                   Algeria\n3                   Andorra\n4                    Angola\n               ...         \n284      West Bank and Gaza\n285    Winter Olympics 2022\n286                   Yemen\n287                  Zambia\n288                Zimbabwe\nName: Country/Region, Length: 289, dtype: object\n\n\n\nCountry/Region is the 2nd column, but indexing starts at 0 in Python.\n\nThen we need a conditional to filter the rows for which the value is equal to Australia:\n\nsimple.loc[:, 'Country/Region'] == 'Australia'\n\n0      False\n1      False\n2      False\n3      False\n4      False\n       ...  \n284    False\n285    False\n286    False\n287    False\n288    False\nName: Country/Region, Length: 289, dtype: bool\n\n\nFinally, we index, out of our entire data frame, the rows for which that condition returns True:\n\nsimple.loc[simple.loc[:, 'Country/Region'] == 'Australia']\n\n\n\n\n\n\n\n\nProvince/State\nCountry/Region\n1/22/20\n1/23/20\n1/24/20\n1/25/20\n1/26/20\n1/27/20\n1/28/20\n1/29/20\n...\n2/28/23\n3/1/23\n3/2/23\n3/3/23\n3/4/23\n3/5/23\n3/6/23\n3/7/23\n3/8/23\n3/9/23\n\n\n\n\n9\nAustralian Capital Territory\nAustralia\n0\n0\n0\n0\n0\n0\n0\n0\n...\n232018\n232018\n232619\n232619\n232619\n232619\n232619\n232619\n232619\n232974\n\n\n10\nNew South Wales\nAustralia\n0\n0\n0\n0\n3\n4\n4\n4\n...\n3900969\n3900969\n3908129\n3908129\n3908129\n3908129\n3908129\n3908129\n3908129\n3915992\n\n\n11\nNorthern Territory\nAustralia\n0\n0\n0\n0\n0\n0\n0\n0\n...\n104931\n104931\n105021\n105021\n105021\n105021\n105021\n105021\n105021\n105111\n\n\n12\nQueensland\nAustralia\n0\n0\n0\n0\n0\n0\n0\n1\n...\n1796633\n1796633\n1800236\n1800236\n1800236\n1800236\n1800236\n1800236\n1800236\n1800236\n\n\n13\nSouth Australia\nAustralia\n0\n0\n0\n0\n0\n0\n0\n0\n...\n880207\n880207\n881911\n881911\n881911\n881911\n881911\n881911\n881911\n883620\n\n\n14\nTasmania\nAustralia\n0\n0\n0\n0\n0\n0\n0\n0\n...\n286264\n286264\n286264\n286897\n286897\n286897\n286897\n286897\n286897\n287507\n\n\n15\nVictoria\nAustralia\n0\n0\n0\n0\n1\n1\n1\n1\n...\n2874262\n2874262\n2877260\n2877260\n2877260\n2877260\n2877260\n2877260\n2877260\n2880559\n\n\n16\nWestern Australia\nAustralia\n0\n0\n0\n0\n0\n0\n0\n0\n...\n1291077\n1291077\n1293461\n1293461\n1293461\n1293461\n1293461\n1293461\n1293461\n1293461\n\n\n\n\n8 rows √ó 1145 columns\n\n\n\n\nHere we use .loc to index based on a boolean array.\n\nWe can now make the sum for all of Australia for each day:\n\ntotal_australia = simple.loc[simple.loc[:, 'Country/Region'] == 'Australia'].sum(numeric_only=True)\ntotal_australia\n\n1/22/20           0\n1/23/20           0\n1/24/20           0\n1/25/20           0\n1/26/20           4\n             ...   \n3/5/23     11385534\n3/6/23     11385534\n3/7/23     11385534\n3/8/23     11385534\n3/9/23     11399460\nLength: 1143, dtype: int64\n\n\nWe can do this for all countries by grouping them:\n\ntotals = simple.groupby('Country/Region').sum(numeric_only=True)\ntotals\n\n\n\n\n\n\n\n\n1/22/20\n1/23/20\n1/24/20\n1/25/20\n1/26/20\n1/27/20\n1/28/20\n1/29/20\n1/30/20\n1/31/20\n...\n2/28/23\n3/1/23\n3/2/23\n3/3/23\n3/4/23\n3/5/23\n3/6/23\n3/7/23\n3/8/23\n3/9/23\n\n\nCountry/Region\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfghanistan\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n209322\n209340\n209358\n209362\n209369\n209390\n209406\n209436\n209451\n209451\n\n\nAlbania\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n334391\n334408\n334408\n334427\n334427\n334427\n334427\n334427\n334443\n334457\n\n\nAlgeria\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n271441\n271448\n271463\n271469\n271469\n271477\n271477\n271490\n271494\n271496\n\n\nAndorra\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n47866\n47875\n47875\n47875\n47875\n47875\n47875\n47875\n47890\n47890\n\n\nAngola\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n105255\n105277\n105277\n105277\n105277\n105277\n105277\n105277\n105288\n105288\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nWest Bank and Gaza\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n703228\n703228\n703228\n703228\n703228\n703228\n703228\n703228\n703228\n703228\n\n\nWinter Olympics 2022\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n535\n535\n535\n535\n535\n535\n535\n535\n535\n535\n\n\nYemen\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n11945\n11945\n11945\n11945\n11945\n11945\n11945\n11945\n11945\n11945\n\n\nZambia\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n343012\n343012\n343079\n343079\n343079\n343135\n343135\n343135\n343135\n343135\n\n\nZimbabwe\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n263921\n264127\n264127\n264127\n264127\n264127\n264127\n264127\n264276\n264276\n\n\n\n\n201 rows √ó 1143 columns\n\n\n\n Now, we can look at the totals for any date:\n\ntotals.loc[:, '6/12/21']\n\nCountry/Region\nAfghanistan              88740\nAlbania                 132449\nAlgeria                 133070\nAndorra                  13813\nAngola                   36600\n                         ...  \nWest Bank and Gaza      311018\nWinter Olympics 2022         0\nYemen                     6857\nZambia                  110332\nZimbabwe                 39852\nName: 6/12/21, Length: 201, dtype: int64\n\n\nTo make it easier to read, let‚Äôs order those numbers by decreasing order:\n\ntotals.loc[:, '6/12/21'].sort_values(ascending=False)\n\nCountry/Region\nUS                      33573694\nIndia                   29439989\nBrazil                  17385952\nFrance                   5799565\nTurkey                   5325435\n                          ...   \nPalau                          0\nTonga                          0\nSummer Olympics 2020           0\nTuvalu                         0\nWinter Olympics 2022           0\nName: 6/12/21, Length: 201, dtype: int64\n\n\nWe can also index the data for a particular country by indexing a row instead of a column:\n\ntotals.loc['Albania', :]\n\n1/22/20         0\n1/23/20         0\n1/24/20         0\n1/25/20         0\n1/26/20         0\n            ...  \n3/5/23     334427\n3/6/23     334427\n3/7/23     334427\n3/8/23     334443\n3/9/23     334457\nName: Albania, Length: 1143, dtype: int64\n\n\nWhen indexing rows, this syntax can be simplified to:\n\ntotals.loc['Albania']\n\n1/22/20         0\n1/23/20         0\n1/24/20         0\n1/25/20         0\n1/26/20         0\n            ...  \n3/5/23     334427\n3/6/23     334427\n3/7/23     334427\n3/8/23     334443\n3/9/23     334457\nName: Albania, Length: 1143, dtype: int64",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Data frames with pandas"
    ]
  },
  {
    "objectID": "python/ws_pandas.html#global-totals",
    "href": "python/ws_pandas.html#global-totals",
    "title": "Data frames with pandas",
    "section": "Global totals",
    "text": "Global totals\nNow, what if we want to have the world totals for each day? We calculate the columns totals (i.e.¬†the sum across countries):\n\ntotals.sum()\n\n1/22/20          557\n1/23/20          657\n1/24/20          944\n1/25/20         1437\n1/26/20         2120\n             ...    \n3/5/23     676024901\n3/6/23     676082941\n3/7/23     676213378\n3/8/23     676392824\n3/9/23     676570149\nLength: 1143, dtype: int64\n\n\n\n\nYour turn:\n\nHow many confirmed cases were there in Venezuela by March 10, 2021?\n\n\n\n\n\n\n\nWarningSolution\n\n\n\n\n\nFirst, we need to select the data for Venezuela:\n\nvenez = totals.loc['Venezuela']\nvenez\n\n1/22/20         0\n1/23/20         0\n1/24/20         0\n1/25/20         0\n1/26/20         0\n            ...  \n3/5/23     552051\n3/6/23     552125\n3/7/23     552157\n3/8/23     552157\n3/9/23     552162\nName: Venezuela, Length: 1143, dtype: int64\n\n\nThen, we need to select for the proper date:\n\nanswer = venez.loc['3/10/21']\nanswer\n\nnp.int64(143321)\n\n\nWe could have done it at once by indexing the row and column:\n\ntotals.loc['Venezuela', '3/10/21']\n\nnp.int64(143321)",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Data frames with pandas"
    ]
  },
  {
    "objectID": "python/ws_pandas.html#pandas-documentation",
    "href": "python/ws_pandas.html#pandas-documentation",
    "title": "Data frames with pandas",
    "section": "pandas documentation",
    "text": "pandas documentation\n\nA user Guide to pandas\nFull documentation",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Data frames with pandas"
    ]
  },
  {
    "objectID": "python/wb_uv_content.html",
    "href": "python/wb_uv_content.html",
    "title": "A tool to rule them all",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_uv_content.html#context",
    "href": "python/wb_uv_content.html#context",
    "title": "A tool to rule them all",
    "section": "Context",
    "text": "Context\n\nA cluttered toolkit\n\n\n\n\nAge of Rust\n\n\n\n\nuv\n\nUniversal tool.\nReally fast.\nExcellent dependency resolution with PubGrub (you guessed it, also written in Rust).\nDependency deduplication.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_uv_content.html#warning",
    "href": "python/wb_uv_content.html#warning",
    "title": "A tool to rule them all",
    "section": "Warning",
    "text": "Warning\n\nDo not use uv on the Alliance clusters. This is for your local computer only.\nFollowing is a recap of a good workflow on the Alliance clusters.\n\n\nPython versions on Alliance clusters\nUse module (uv).\nList available Python versions:\nmodule spider python\nCheck how to load a particular version:\nmodule spider python/3.12.4\nLoad a particular version:\nmodule load python/3.12.4\nCreate a Python virtual environment:\npython -m venv ~/env\nActivate it:\nsource ~/env/bin/activate\nUpdate pip from wheel:\npython -m pip install --upgrade pip --no-index\nUse pip with --no-index to use wheels whenever possible:\npython -m pip install --no-index jax[cuda12] jax-ai-stack[grain]",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_uv_content.html#getting-started-with-uv",
    "href": "python/wb_uv_content.html#getting-started-with-uv",
    "title": "A tool to rule them all",
    "section": "Getting started with uv",
    "text": "Getting started with uv\n\nInstall uv\n\n\n\n\nHelp\nList of commands and options:\nuv\nList of options:\nuv &lt;command&gt; -h    # e.g. uv init -h\nMan page:\nuv help &lt;command&gt;  # e.g. uv help init",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_uv_content.html#stuck-in-a-rut",
    "href": "python/wb_uv_content.html#stuck-in-a-rut",
    "title": "A tool to rule them all",
    "section": "Stuck in a rut",
    "text": "Stuck in a rut\n(When you can‚Äôt change your workflow.)\n\nDrop-in replacement\nYou can add uv in front of your usual venv and pip commands.\nThis actually runs uv (and neither pip nor venv) so you get the speedup, but it keeps everything compatible.\n\n\nCreate a virtual env\nuv venv\n\nWith specific Python version:\n\nuv venv --python 3.12\nBy default, the virtual env is called .venv. If you don‚Äôt change its name, uv will use it automatically so you don‚Äôt need to source it.\n\n\nInstall packages in virtual env\nuv pip install jax flax\n\nFrom GitHub repo:\n\nuv pip install \"git+https://github.com/jax-ml/jax\"\nuv pip install \"git+https://github.com/jax-ml/jax@main\"\nuv pip install \"git+https://github.com/jax-ml/jax@766e68c4813a30e29b4fcefaa3253a42d0e197be\"\n\nFrom requirements.txt or pyproject.toml files:\n\nuv pip install -r requirements.txt\nuv pip install -r pyproject.toml\n\n\nAll your usual commands work\nuv pip uninstall jax\nuv pip list\nuv pip freeze\n‚Ä¶",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_uv_content.html#python-versions",
    "href": "python/wb_uv_content.html#python-versions",
    "title": "A tool to rule them all",
    "section": "Python versions",
    "text": "Python versions\n\nAutomatic installation\nMissing Python versions are automatically installed when required.\n\nExample:\n\nuv venv --python 3.12\n\nIf Python 3.12 is missing, uv will install it during the creation of this virtual env.\n\n\n\nInstall Python\nPython versions can also be installed explicitly:\nuv python install 3.12.3\nuv python install '&gt;=3.8,&lt;3.10'\n\nSpecific implementations (default is cpython):\n\nuv python install pypy\nuv python install 'pypy&gt;=3.8,&lt;3.10'\n\n\nManage versions\nView installed and available versions:\nuv python list\nUninstall Python version:\nuv python uninstall 3.10\n\nNoe that this is a lot more convenient than pyenv which requires the exact Python version number to uninstall (e.g.¬†pyenv uninstall 3.10.6).",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_uv_content.html#python-projects",
    "href": "python/wb_uv_content.html#python-projects",
    "title": "A tool to rule them all",
    "section": "Python projects",
    "text": "Python projects\n\nInitialize projects\nuv init my_project\nInitialized project `my-project` at `/home/marie/my_project`\n\nWith specific Python version:\n\nuv init --python 3.12 my_project\n\nCustomize which files get created:\n\nuv init --no-readme --no-description\n\n\nProject structure\n\neza -aT my_project\n\n\"my_project\": No such file or directory (os error 2)\n\n\n\nbat -p my_project/pyproject.toml\n\n\u001b[31m[bat error]\u001b[0m: 'my_project/pyproject.toml': No such file or directory (os error 2)\n\n\n\n\nAdd dependencies\nYou need to cd into the project, then you can add dependencies:\ncd my_project\nuv add polars matplotlib\nThis creates a virtual env called .venv and a uv.lock:\neza -aTL 1\n\n\n\"my_project\": No such file or directory (os error 2)\n\n\nHere again, no need to source the virtual env as long as you use uv.\n\n\nProject file\nGets populated automatically with dependencies:\nbat -p pyproject.toml\n\n\n\u001b[31m[bat error]\u001b[0m: 'my_project/pyproject.toml': No such file or directory (os error 2)\n\n\n\n\nList installed dependencies\nTo list explicitly installed dependencies:\nuv tree -d 1\n\n\nbash: line 1: cd: my_project: No such file or directory\nerror: No `pyproject.toml` found in current directory or any parent directory\n\n\n\n\nList all dependencies\nuv pip list\n\n\nbash: line 1: cd: my_project: No such file or directory\nUsing Python 3.12.10 environment at: /home/marie/.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu\nPackage Version\n------- -------\npip     24.3.1\n\n\n\n\nManage dependencies\nUpdate all dependencies in lock file and virtual env:\nuv sync -U\nRemove dependencies:\nuv remove matplotlib",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_uv_content.html#did-you-say-fast",
    "href": "python/wb_uv_content.html#did-you-say-fast",
    "title": "A tool to rule them all",
    "section": "Did you say fast?",
    "text": "Did you say fast?\n\nPython versions pyenv vs uv\n\npyenv\npyenv install 3.10\n\n\n\n\n\n\nThis is really taking forever ü•±\n\n\n\n\n\nuv\nuv python install 3.10\nInstalled Python 3.10.17 in 1.49s\n\nYes, uv brags about how fast it installs things‚Ä¶ but it can!\n\n\n\n\nPackages: pip vs uv pip\n\npip\nCreate virtual env:\npython -m venv .venv\nActivate it:\nsource .venv/bin/activate\nUpdate pip:\npython -m pip install --upgrade pip\nInstall package:\npython -m pip install jax-ai-stack\n\n\nuv pip\nCreate virtual env:\nuv venv\n\nI am deleting my entire uv cache to make sure that I am not cheating in the comparison. You normally never do that since the cache prevents deduplication (saves space) and makes installations much faster.\nrm -rf ~/.cache/uv\n\nInstall package:\nuv pip install jax-ai-stack\nTo use the virtual env, I can activate it but I can also access it directly by running commands preceded by uv run.\n\nFor instance, I can launch a JupyterLab with access to the project virtual env with:\n\nuv run --with jupyter jupyter lab\n\nor run a script with:\n\nuv run script.py",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_uv_content.html#convenience",
    "href": "python/wb_uv_content.html#convenience",
    "title": "A tool to rule them all",
    "section": "Convenience",
    "text": "Convenience\nHere is a real world use case: I needed to install a number of packages for a deep learning course with JAX, including Grain which still requires Python 3.12. So I needed a virtual environment with a specific Python version.\nFollowing are the workflows with classic tools vs uv.\n\npyenv, venv, and pip\nInstall Python 3.12:\npyenv install 3.12\nCreate virtual env with Python 3.12 (requires identifying the path):\n~/.pyenv/versions/3.12.10/bin/python -m venv .venv\nActivate it:\nsource .venv/bin/activate\nUpdate pip:\npython -m pip install --upgrade pip\nInstall packages:\npython -m pip install datasets jax-ai-stack[grain] matplotlib tqdm transformers\n\n\nuv\nuv init --python 3.12 demo\n\nAutomatically installs Python 3.12 if missing.\n\ncd demo\nuv add datasets jax-ai-stack[grain] matplotlib tqdm transformers\n\n\nuv advantages\nMuch simpler.\nMuch (much!) faster.\nLeaves me with a nice pyproject.toml file:\n[project]\nname = \"fl\"\nversion = \"0.1.0\"\nrequires-python = \"&gt;=3.12\"\ndependencies = [\n    \"datasets&gt;=3.5.0\",\n    \"jax-ai-stack[grain]&gt;=2025.2.5\",\n    \"matplotlib&gt;=3.10.1\",\n    \"tqdm&gt;=4.67.1\",\n    \"transformers&gt;=4.50.3\",\n]\nand a uv.lock file that I can put under version control and share for reproducibility.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_uv_content.html#tools",
    "href": "python/wb_uv_content.html#tools",
    "title": "A tool to rule them all",
    "section": "Tools",
    "text": "Tools\n\npipx replacement\nPython tools are packages used for convenience (e.g.¬†linters, formatters) across projects, but not necessary for running your code.\nThey are commonly installed via your Linux distribution package manager, Homebrew, or pipx.\nThey can also be installed by uv:\nuv tool install ruff\n\n\nUse tools without installation\nTools can even be used without installation (from a temporary install).\nuvx ruff\n\nuvx is an alias for uv tool run.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_uv_content.html#resources",
    "href": "python/wb_uv_content.html#resources",
    "title": "A tool to rule them all",
    "section": "Resources",
    "text": "Resources\n\nGitHub repo\nWebsite",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "uv package manager",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_polars_slides.html#tabular-data",
    "href": "python/wb_polars_slides.html#tabular-data",
    "title": "DataFrames on steroids with Polars",
    "section": "Tabular data",
    "text": "Tabular data\nMany fields of machine learning and data science rely on tabular data where\n\ncolumns hold variables and are homogeneous (same data type)\nrows contain observations and can be heterogeneous\n\nEarly computer options to manipulate such data were limited to spreadsheets\nDataframes (data frames or DataFrames) are two dimensional objects that brought tabular data to programming"
  },
  {
    "objectID": "python/wb_polars_slides.html#early-history-of-dataframes",
    "href": "python/wb_polars_slides.html#early-history-of-dataframes",
    "title": "DataFrames on steroids with Polars",
    "section": "Early history of dataframes",
    "text": "Early history of dataframes\n\n\n\n\n\n\n\n\n\ny1\n1990\n\n\n\ny2\n2000\n\n\n\ny1--y2\n\n\n\n\ny3\n2008\n\n\n\ny2--y3\n\n\n\n\nl1\n\nS programming language\n\n\n\n\n\nl2\n\nR\n\n\n\n\n\n\nl3\n\nPandas (Python)\n\n\n\n\n\n\n\n\n\n\n\nThe world was simple ‚Ä¶ but slow. Another problem: high memory usage"
  },
  {
    "objectID": "python/wb_polars_slides.html#issues-with-pandas",
    "href": "python/wb_polars_slides.html#issues-with-pandas",
    "title": "DataFrames on steroids with Polars",
    "section": "Issues with Pandas",
    "text": "Issues with Pandas\nWes McKinney (pandas creator) himself has complaints about it:\n\n‚Ä¢ Internals too far from ‚Äúthe metal‚Äù\n‚Ä¢ No support for memory-mapped datasets\n‚Ä¢ Poor performance in database and file ingest / export\n‚Ä¢ Warty missing data support\n‚Ä¢ Lack of transparency into memory use, RAM management\n‚Ä¢ Weak support for categorical data\n‚Ä¢ Complex groupby operations awkward and slow\n‚Ä¢ Appending data to a DataFrame tedious and very costly\n‚Ä¢ Limited, non-extensible type metadata\n‚Ä¢ Eager evaluation model, no query planning\n‚Ä¢ ‚ÄúSlow‚Äù, limited multicore algorithms for large datasets"
  },
  {
    "objectID": "python/wb_polars_slides.html#parallel-computing",
    "href": "python/wb_polars_slides.html#parallel-computing",
    "title": "DataFrames on steroids with Polars",
    "section": "Parallel computing",
    "text": "Parallel computing\nPython global interpreter lock (GIL) gets in the way of multi-threading\nLibraries such as Ray, Dask, and Apache Spark allow use of multiple cores and bring dataframes on clusters\nDask and Spark have APIs for Pandas and Modin makes this even more trivial by providing a drop-in replacement for Pandas on Dask, Spark, and Ray\nfugue provides a unified interface for distributed computing that works on Spark, Dask, and Ray"
  },
  {
    "objectID": "python/wb_polars_slides.html#accelerators",
    "href": "python/wb_polars_slides.html#accelerators",
    "title": "DataFrames on steroids with Polars",
    "section": "Accelerators",
    "text": "Accelerators\nRAPIDS brings dataframes on the GPUs with the cuDF library\nIntegration with pandas is easy"
  },
  {
    "objectID": "python/wb_polars_slides.html#lazy-out-of-core",
    "href": "python/wb_polars_slides.html#lazy-out-of-core",
    "title": "DataFrames on steroids with Polars",
    "section": "Lazy out-of-core",
    "text": "Lazy out-of-core\nVaex exists as an alternative to pandas (no integration)"
  },
  {
    "objectID": "python/wb_polars_slides.html#sql",
    "href": "python/wb_polars_slides.html#sql",
    "title": "DataFrames on steroids with Polars",
    "section": "SQL",
    "text": "SQL\nStructured query language (SQL) handles relational databases, but the distinction between SQL and dataframe software is getting increasingly blurry with most libraries now able to handle both\nDuckDB is a very fast and popular option with good integration with pandas\nMany additional options such as dbt and the snowflake snowpark Python API exist, although integration with pandas is not always as good"
  },
  {
    "objectID": "python/wb_polars_slides.html#comparison-with-pandas",
    "href": "python/wb_polars_slides.html#comparison-with-pandas",
    "title": "DataFrames on steroids with Polars",
    "section": "Comparison with Pandas",
    "text": "Comparison with Pandas\n\n\n\n\nPandas\nPolars\n\n\n\n\nAvailable for\nPython\nRust, Python, R, NodeJS\n\n\nWritten in\nCython\nRust\n\n\nMultithreading\nSome operations\nYes (GIL released)\n\n\nIndex\nRows are indexed\nInteger positions are used\n\n\nEvaluation\nEager only\nLazy and eager\n\n\nQuery optimizer\nNo\nYes\n\n\nOut-of-core\nNo\nYes\n\n\nSIMD vectorization\nYes\nYes\n\n\nData in memory\nWith NumPy arrays\nWith Apache Arrow arrays\n\n\nMemory efficiency\nPoor\nExcellent\n\n\nHandling of missing data\nInconsistent\nConsistent, promotes type stability"
  },
  {
    "objectID": "python/wb_polars_slides.html#polars-integration-with-other-tools",
    "href": "python/wb_polars_slides.html#polars-integration-with-other-tools",
    "title": "DataFrames on steroids with Polars",
    "section": "Polars integration with other tools",
    "text": "Polars integration with other tools\nAs good as Pandas‚Äô (except for cuDF, still in development)\n\nWith NumPy: see the documentation, the from_numpy and to_numpy functions, the development progress of this integration, and performance advice\nParallel computing: with Ray thanks to this setting; with Spark, Dask, and Ray thanks to fugue\nGPUs: with the cuDF library from RAPIDS (in development)\nSQL: with DuckDB\n\nThe list is growing fast"
  },
  {
    "objectID": "python/wb_polars_slides.html#benchmarks",
    "href": "python/wb_polars_slides.html#benchmarks",
    "title": "DataFrames on steroids with Polars",
    "section": "Benchmarks",
    "text": "Benchmarks\nComparisons between Polars and distributed (Dask, Ray, Spark) or GPU (RAPIDS) libraries aren‚Äôt the most pertinent since they can be used in combination with Polars and the benefits can be combined\nIt makes most sense to compare Polars with another library occupying the same ‚Äúniche‚Äù such as Pandas or Vaex"
  },
  {
    "objectID": "python/wb_polars_slides.html#benchmarks-1",
    "href": "python/wb_polars_slides.html#benchmarks-1",
    "title": "DataFrames on steroids with Polars",
    "section": "Benchmarks",
    "text": "Benchmarks\nThe net is full of benchmarks with consistent results: Polars is 3 to 150 times faster than Pandas\nPandas is trying to fight back: v 2.0 came with optional Arrow support instead of NumPy, then it became the default engine, but performance remains way below that of Polars (e.g.¬†in DataCamp benchmarks, official benchmarks, many blog posts for whole scripts or individual tasks)\nAs for Vaex, it seems twice slower and development has stalled over the past 10 months\nThe only framework performing better than Polars in some benchmarks is datatable (derived from the R package data.table), but it hasn‚Äôt been developed for 6 months‚Äîa sharp contrast with the fast development of Polars"
  },
  {
    "objectID": "python/wb_polars_slides.html#installation",
    "href": "python/wb_polars_slides.html#installation",
    "title": "DataFrames on steroids with Polars",
    "section": "Installation",
    "text": "Installation\nPersonal computer:\npython -m venv ~/env                  # Create virtual env\nsource ~/env/bin/activate             # Activate virtual env\npip install --upgrade pip             # Update pip\npip install polars                    # Install Polars\n Alliance clusters (polars wheels are available, always prefer wheels when possible):\npython -m venv ~/env                  # Create virtual env\nsource ~/env/bin/activate             # Activate virtual env\npip install --upgrade pip --no-index  # Update pip from wheel\npip install polars --no-index         # Install Polars from wheel"
  },
  {
    "objectID": "python/wb_polars_slides.html#syntax",
    "href": "python/wb_polars_slides.html#syntax",
    "title": "DataFrames on steroids with Polars",
    "section": "Syntax",
    "text": "Syntax\nThe package is well documented\nKevin Heavey wrote Modern Polars following the model of the Modern Pandas book. This is a great resource, although getting a little outdated for the scaling chapter since Polars is evolving so fast\nOverall, the syntax feels somewhat similar to R‚Äôs dplyr from the tidyverse"
  },
  {
    "objectID": "python/wb_polars_slides.html#table-visualization",
    "href": "python/wb_polars_slides.html#table-visualization",
    "title": "DataFrames on steroids with Polars",
    "section": "Table visualization",
    "text": "Table visualization\nWhile Pandas comes with internal capabilities to make publication ready tables, Polars integrates very well with great-tables"
  },
  {
    "objectID": "python/wb_polars_slides.html#a-rich-new-field",
    "href": "python/wb_polars_slides.html#a-rich-new-field",
    "title": "DataFrames on steroids with Polars",
    "section": "A rich new field",
    "text": "A rich new field\nAfter years with the one Python option (Pandas), there is currently this exuberant explosion of faster alternatives for dataframes\nIt might seem confusing and overwhelming, but in fact, the picture seems quite simple\nFor now, the new memory standard seems to be Apache Arrow and the most efficient library making use of it is Polars"
  },
  {
    "objectID": "python/wb_polars_slides.html#best-performance-strategy-for-software",
    "href": "python/wb_polars_slides.html#best-performance-strategy-for-software",
    "title": "DataFrames on steroids with Polars",
    "section": "Best performance strategy for software",
    "text": "Best performance strategy for software\nThe best strategy thus seems to be at the moment:\n\nSingle machine: Polars\nCluster: Polars + fugue (example benchmark, documentation of integration)\nGPUs available: Polars + RAPIDS library cuDF (integration coming soon)\nSQL: Polars + DuckDB (documentation of integration)\nOr combination of the above (if cluster with GPUs, etc.)\n\nAs so many libraries are developing an integration with Polars, it is becoming hard to still find reasons to use Pandas"
  },
  {
    "objectID": "python/wb_polars_slides.html#performance-tips",
    "href": "python/wb_polars_slides.html#performance-tips",
    "title": "DataFrames on steroids with Polars",
    "section": "Performance tips",
    "text": "Performance tips\n\nRead the migration guide: it will help you write Polars code rather than ‚Äúliterally translated‚Äù Pandas code that runs, but doesn‚Äôt make use of Polars‚Äô strengths. The differences in style mostly come from the fact that Polars runs in parallel\nExecution: lazy where possible\nFile format: Apache Parquet"
  },
  {
    "objectID": "python/wb_polars.html",
    "href": "python/wb_polars.html",
    "title": "DataFrames on steroids with Polars",
    "section": "",
    "text": "Polars is a modern open source and very fast DataFrame framework for Python, Rust, JS, R, and Ruby.\nIn this webinar, I will demo Polars for Python and show how much faster it is compared to pandas while remaining just as convenient.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Faster data frames"
    ]
  },
  {
    "objectID": "python/wb_marimo_content.html",
    "href": "python/wb_marimo_content.html",
    "title": "The next generation of Python notebooks",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Next gen Python notebooks",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_marimo_content.html#notes",
    "href": "python/wb_marimo_content.html#notes",
    "title": "The next generation of Python notebooks",
    "section": "Notes",
    "text": "Notes\n\nI am making an opinionated decision to use uv for installation.\nNotebooks are great for prototyping but not at scale.\nmarimo is not available on the Alliance clusters at this point.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Next gen Python notebooks",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_marimo_content.html#a-new-notebook",
    "href": "python/wb_marimo_content.html#a-new-notebook",
    "title": "The next generation of Python notebooks",
    "section": "A new notebook",
    "text": "A new notebook\n\nWhat‚Äôs wrong with Jupyter?\nJupyter notebooks are very popular but they come with downsides:\n\nVersion control nightmare.\nAwkward JSON file format.\nReproducibility issues.\n\n\n\nDAG dataflow\nmarimo notebooks automatically generate an intermediate representation (IR) in the form of a directed acyclic graph (DAG) of:\n\ndefinitions (defs) of global variables,\nreferences (refs) of global variables.\n\nEach cell is parsed into an abstract syntax tree (AST).\nStatically inferred (no runtime tracing).\n\n\nPython files\n\n\n\nNotebooks are saved as .py files.\nEach cell is stored as a function.\nPure functions can be reused as modules.\n\n\n‚ûî\n\n\nEasy version control.\nDirectly executable as scripts or web apps.\nReadable in text editors.\n\n\n\n\n\nInteractive elements\nmarimo.ui creates interactive user interface (UI) elements with first-class support.\nNotebooks are automatically updated when values are changed via interactions.\n\n\nCool features\n\nTurn notebooks into apps.\nIntegrated AI.\nDocstrings on hover.\n\n\n\nThe constraints\nAll this comes at the cost of some constraints:\n\nGlobal variables must be unique.\nIn-place transformations are not allowed.\nMutations and attributes are not tracked.\n\n\nAll this is good practice for strict functional programming (and JAX)!\n\n\n\nComputation cost\nThere is a cost to updating the DAG at each change.\nRuntime configurations and cell settings allow to control when re-runs happen.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Next gen Python notebooks",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_marimo_content.html#getting-started",
    "href": "python/wb_marimo_content.html#getting-started",
    "title": "The next generation of Python notebooks",
    "section": "Getting started",
    "text": "Getting started\n\nInstallation\nCreate a uv project:\nuv init --bare\nInstall marimo in it as a development dependency:\nuv add --dev marimo\n(Optional) add tools marimo can make use of:\nuv add --dev ruff basedpyright mcp\n\n\nLaunch a notebook\nmarimo edit notebook.py\n\nIf you installed with uv, first activate the virtual env or run instead:\nuv run marimo edit notebook.py\n\n\n\nConfiguration\nVia GUI\n top right corner (Notebook settings) ‚ûî User settings\n\nPackage manager\n ‚ûî User settings ‚ûî Packages & Data ‚ûî Package Management ‚ûî Manager: uv\n\n\nAI pair programming\n\nCode completion\nUse GitHub Copilot without account.\n\n\nAI assistant\nUse any of the classic LLMs with API key.\n\n\nMCP servers\n\nmarimo docs\nContext7\n\nUser settings are saved in ~/.config/marimo/marimo.toml (or similar in different OS).\n[mcp]\npresets = [\"marimo\", \"context7\"]\n\n[mcp.mcpServers]\n\n[runtime]\nwatcher_on_save = \"lazy\"\nauto_reload = \"off\"\ndefault_sql_output = \"auto\"\nauto_instantiate = true\nstd_stream_max_bytes = 1000000\ndefault_auto_download = []\non_cell_change = \"autorun\"\noutput_max_bytes = 8000000\nreactive_tests = true\n\n[formatting]\nline_length = 79\n\n[completion]\ncopilot = \"github\"\nactivate_on_typing = true\n\n[snippets]\ncustom_paths = []\ninclude_default_snippets = true\n\n[keymap]\npreset = \"default\"\ndestructive_delete = true\n\nLogs are found at ~/.cache/marimo/logs (or similar).\n\n\n\n\n\nOfficial website\nExcellent documentation:\nUser guides.\nAPI reference.\n\n\nTutorials\nmarimo tutorial intro\nFor more tutorials, replace intro with any of:\ndataflow\nui\nmarkdown\nplots\nsql\nlayout\nfileformat\nmarkdown-format\nfor-jupyter-users\n\nIf you installed with uv, first activate the virtual env or run instead:\nuv run marimo tutorial intro\n\n\n\nKey bindings\nVim kbd available.\n\nCommand mode\nEsc\nWith vim keybindings are enabled or other issues, use Ctrl+Esc or Shift+Esc instead.\nNavigation between cells, copy/cut/paste cells.\n\n\nEdit mode\nEnter or click on a cell.\nEdit content.\nCustomizable. List displayed by Ctrl-Shift-h.\n\n\n\n\n\n\n\n\nipynb notebooks conversion\nmarimo convert notebook.ipynb -o notebook.py\n\nIPython magics are replaced by Python functions.\n\n\nAfter a uv install, run (or activate the virtual env):\nuv run marimo convert notebook.ipynb -o notebook.py",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Next gen Python notebooks",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_marimo_content.html#general-usage",
    "href": "python/wb_marimo_content.html#general-usage",
    "title": "The next generation of Python notebooks",
    "section": "General Usage",
    "text": "General Usage\n\nInstalling Python packages\nDirectly in the notebook following a pop-up when trying to use uninstalled package.\n\nOf course this can also be done via the command line:\nuv add &lt;package&gt;\n\nExample:\n\nuv add numpy\n\n\n\nOutputs displays\n\n\n\nConsole outputs\nText written to stdout/stderr\n‚ûî displayed below cells by default,\n‚ûî hidden in app mode.\n\nExample:\n\n\n\ncell\n\nprint(\"This is a console output.\")\n\n\n\n\n\n\nCell outputs\n\n‚ûî displayed above cells by default,\n‚ûî shown in app mode.\n\nExample:\n\n\n\ncell\n\n\"This is a cell output.\"\n\n\n\n\n\n\nForbidden re-assignments\nVariables re-assignments are OK within cells, but not across cells.\nThe cells with re-assignments will not run.\n\nReusing i in loops across cells won‚Äôt work.\n+=, -=, etc. won‚Äôt run.\n\n\nSolutions\n\n\n\nUse cell local variables\nVariables prefixed with _ are cell local.\n(names can thus be reused between cells).\n\n\ncell 0\n\n_a = 3\nprint(_a)\n\n\n\ncell 1\n\nprint(_a)\n\nname '_a' is not defined\n\n_i can be reused between cells:\n\n\ncell\n\nfor _i in range(10):\n    print(_i)\n\n\n\n\n\n‚ÄÇor\n\n\nWrap in functions\nFunctions create local environments.\nVariables created in functions don‚Äôt enter the global environment.\n‚ûî their names can be reused in functions in different cells.\n\n\ncell\n\ndef _():\n     for i in range(10):\n         print(i)\n\n_()\n\n\n\n\n\n\n\nMutations do not call re-runs\nLet‚Äôs consider:\n\n\ncell 0\n\nl = [1, 2, 3]\n\n\n\ncell 1\n\nlen(l)\n\n\n\ncell 2\n\nl.append(4)\n\nrunning the cell 2 will not update cell 1.\n\nSolutions\n\n\nMutate variables in the cells in which they are defined:\n\n\ncell 0\n\nl = [1, 2, 3]\nl.append(4)\n\n\n\ncell 1\n\nlen(l)\n\n\n\n‚ÄÇor\n\nCreate new variables:\n\n\ncell 0\n\nl = [1, 2, 3]\n\n\n\ncell 1\n\nlen(l)\n\n\n\ncell 2\n\nl2 = l + [4]\n\n\n\ncell 3\n\nlen(l2)\n\n\n\n\n\n\nDeleting cells\nAutomatically deletes variables defined in them (and cells with refs to them are re-run).\n\n\nNo cycles permitted\nThis would make the DAG impossible:\n\n\ncell 0\n\nvar1 = 4\nprint(var2)\n\n\n\ncell 1\n\nvar2 = 7\nprint(var1)\n\n\n\nAttributes are not tracked\nAssignments to attributes aren‚Äôt tracked:\n\n\ncell 0\n\nclass Object(object):\n    pass\n\nobj = Object()\nobj.somefield = \"somevalue\"\n\n\n\ncell 1\n\nprint(obj.somefield)\n\n\n\ncell 2\n\nobj.somefield = \"newvalue\"\n\ncell 1 is not re-run and updated automatically.\n\n\nDataflow programming\nExecution order \\(\\neq\\) cell order.\nThe execution order is determined by the DAG.\nThis is a totally valid notebook:\n\n\ncell 0\n\nprint(new_var)\n\n\n\ncell 1\n\nnew_var = 8\n\nThese are perfectly equivalent notebooks (they have the same DAG):\n\n\n\n\ncell 0\n\na = 3\n\n\n\ncell 1\n\na1 = 8.9\na2 = 8.3\n\n\n\ncell 2\n\na3 = 3.0\n\n\n\ncell 3\n\na4 = 1.2\n\n\n\ncell 4\n\nmy_list = [a1, a2, a3, a4]\n\n\n\n\n\n\ncell 0\n\nmy_list = [a1, a2, a3, a4]\n\n\n\ncell 1\n\na = 3\n\n\n\ncell 2\n\na3 = 3.0\n\n\n\ncell 3\n\na1 = 8.9\na2 = 8.3\n\n\n\ncell 4\n\na4 = 1.2\n\n\n\n\n\nDataflow navigation\n\n\nHere is our notebook:\n\n\ncell 0\n\na = 3\n\n\n\ncell 1\n\na1 = 8.9\na2 = 8.3\n\n\n\ncell 2\n\na3 = 3.0\n\n\n\ncell 3\n\na4 = 1.2\n\n\n\ncell 4\n\nmy_list = [a1, a2, a3, a4]\n\n\n\n\n‚ÄÉ‚ÄÉThis is the corresponding DAG:\n\n\n\n\n\n\n\n\n\n0\n\ncell 0\n\n\n\n1\n\ncell 1\n\n\n\n\n2\n\ncell 2\n\n\n\n\n4\n\ncell 4\n\n\n\n1-&gt;4\n\n\n\n\n\n3\n\ncell 3\n\n\n\n\n2-&gt;4\n\n\n\n\n\n3-&gt;4\n\n\n\n\n\n\n\n\n\n\n\n\nNavigating and understanding the dataflow is made easy by a number of tools:\n\nMinimap (Ctrl-Shift-i).\nDependency explorer (left menu).\nReference highlighting and jumping (hover on underlined refs, Ctrl+click to jump to defs).\n\n\n\nManaging runs\nRe-running heavy computations to update the notebooks can be costly.\nThis can be controlled by disabling/enabling:\n\nautorun on startup,\nautorun on cell change (lazy execution),\nspecific cells.\n\n\n\nMarkdown\nYou can turn cells into markdown and select raw strings and/or f-string.\n\n\n\n\n\n\nat the bottom right corner of every cell.\n\n\n\nMarkdown extensions\n\n\ncell\n\n/// details | Click for details.\n\nYou can create accordion blocks.\n///\n\n\n\ncell\n\n/// admonition | Tips\n\nYou can create info blocks.\n///\n\n\n\ncell\n\n/// attention | Be careful!\n\nYou can create warning blocks.\n///\n\n\n\nPlots\nPlotting works as you would expect.\nJavaScript interactivity also works.\n\n\ncell\n\nimport plotly.express as px\ndf = px.data.tips()\n\nfig = px.density_contour(df, x=\"total_bill\", y=\"tip\")\nfig.update_traces(contours_coloring=\"fill\", contours_showlabels = True)\nfig.show()\n\n\n\nScript\nYou can run a notebook as a script, without having to do any conversion, with:\npython notebook.py\n\n\nApps\nYou can run a notebook as an app with:\nmarimo run notebook.py\n\n\nAI\n\nCompletion\nProvided out of the box with GitHub Copilot. Tab to complete.\n\n\nGenerate cells with AI\nBox at the bottom of notebook.\n\n\nCells refactoring\nIn the menu of each cell.\n\n\nChat\nButton on the left menu opens a chat panel.\n\n\nGoing crazy\nmarimo new asks an LLM to generate a full notebook from scratch:\n\nExample:\n\nmarimo new \"Create a cool-looking 3D plot with matplotlib.\"",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Next gen Python notebooks",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_marimo_content.html#interactive-ui",
    "href": "python/wb_marimo_content.html#interactive-ui",
    "title": "The next generation of Python notebooks",
    "section": "Interactive UI",
    "text": "Interactive UI\n\nThe marimo module\nEvery notebook loads the marimo module automatically.\nInteractive elements make use of the module, so it is convenient to create an alias:\n\n\ncell 0\n\nimport marimo as mo\n\n\n\nCreate an interactive element\nYou create an element with one of the mo.ui methods.\nCall it at the end of the cell to display it:\n\n\ncell 1\n\nslider = mo.ui.slider(start=1, stop=10, step=1)\nslider\n\n\nUI elements are defs.\n\nYou can embed it in a markdown output and format it with an f-string:\n\n\ncell 1\n\nslider = mo.ui.slider(start=1, stop=10, step=1)\nmo.md(f\"Pick a value: {slider}\")\n\n\n\nAccess the value\nYou then need to access its value in another cell:\n\n\ncell 2\n\nslider.value\n\nWhich you can also embed in some markdown:\n\n\ncell 2\n\nmo.md(f\"You picked the value: {slider.value}\")\n\n\n\nExample\nCreate a date selector element:\n\n\ncell 0\n\ndate = mo.ui.date()\nmo.md(f\"Select a date: {date}\")\n\nPrint the selected date:\n\n\ncell 1\n\nmo.md(f\"Your selected date is: {date.value}\")\n\n\n\nProgress bars\nSimilar to tqdm:\n\n\ncell\n\nimport time\n\nfor i in mo.status.progress_bar(range(50)):\n    print(i)\n    time.sleep(0.1)",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Next gen Python notebooks",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_marimo_content.html#under-the-hood",
    "href": "python/wb_marimo_content.html#under-the-hood",
    "title": "The next generation of Python notebooks",
    "section": "Under the hood",
    "text": "Under the hood\n\nPython files for notebooks\nNotebooks get written in Python as:\n\n\nnotebook.py\n\nimport marimo\n\n__generated_with = \"&lt;some version&gt;\"\napp = marimo.App()\n\n\"&lt;your cells go here&gt;\"\n\nif __name__ == \"__main__\":\n    app.run()\n\n\n\nNotebook settings\nAdded as:\n\n\nnotebook.py\n\nimport marimo\n\n__generated_with = \"&lt;some version&gt;\"\napp = marimo.App(width=\"medium\", css_file=\"custom.css\", auto_download=[\"html\"])\n\n\"&lt;your cells go here&gt;\"\n\nif __name__ == \"__main__\":\n    app.run()\n\n\n\nWhat are cells really?\nCells are functions wrapped by an @app.cell decorator.\nThis makes them easy to turn into apps.\nWhen you create an empty cell, your .py file (let‚Äôs call it notebook.py) sees the following added:\n\n\nnotebook.py\n\n@app.cell\ndef _():\n    return\n\nNow, add in the cell:\n\n\ncell 0\n\nx = 8\ny = 9\n\nand you get in your .py file:\n\n\nnotebook.py\n\n@app.cell\ndef _():\n    x = 8\n    y = 9\n    return\n\nHide the code and the script turns into:\n\n\nnotebook.py\n\n@app.cell(hide_code=True)\ndef _():\n    x = 8\n    y = 9\n    return\n\n\n\nReferences\nCell dependencies are passed as arguments to the function:\n\n\nNotebook cells:\n\n\ncell 1\n\nprint(x)\n\n\n\n\ncell 2\n\nprint(x, y)\n\n\n\n\nCorresponding Python file:\n\n\nnotebook.py\n\n@app.cell\ndef _(x):\n    print(x)\n    return\n\n\n\nnotebook.py\n\n@app.cell\ndef _(x, y):\n    print(x, y)\n    return\n\n\n\n\n\nPrint refs and defs\nmo.defs and mo.refs output the defs and refs of a cell:\n\n\ncell 0\n\nvar = 8\nprint(f\"The defs are: {mo.defs()} and the refs are: {mo.refs()}\")\n\n\n\ncell 1\n\nvar + 7\nprint(f\"The defs are: {mo.defs()} and the refs are: {mo.refs()}\")\n\n\n\nHow is md turned into Python?\nMarkdown text is wrapped in mo.md functions:\n\n\nnotebook.py\n\n@app.cell\ndef _(mo):\n    mo.md(\n        r\"\"\"\n    ## Heading\n\n    Some markdown with some *italic* formatting.\n    \"\"\"\n    )\n    return",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Next gen Python notebooks",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_jax_slides.html#what-is-jax",
    "href": "python/wb_jax_slides.html#what-is-jax",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "What is JAX?",
    "text": "What is JAX?\n\nLibrary for Python developed by Google\n\n\nKey data structure: Array\n\n\nComposition, transformation, and differentiation of numerical programs\n\n\nCompilation for CPUs, GPUs, and TPUs\n\n\nNumPy-like and lower-level APIs\n\n\nRequires strict functional programming"
  },
  {
    "objectID": "python/wb_jax_slides.html#why-jax",
    "href": "python/wb_jax_slides.html#why-jax",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Why JAX?",
    "text": "Why JAX?\n\n\n\n\n\n\n\n\n\n01\n\n\nAutodiff method\n\n\n\n1\nStatic graph\nand XLA\n\n\n\n\n02\n\n\nFramework\n\n\n\n\n2\nDynamic graph\n\n\n\n1-&gt;2\n\n\n\n\n\na\n\nTensorFlow\n\n\n\n\n4\nDynamic graph\nand XLA\n\n\n\n2-&gt;4\n\n\n\n\n\nb\n\nPyTorch\n\n\n\n\n5\nPseudo-dynamic\nand XLA\n\n\n\n4-&gt;5\n\n\n\n\n\nd\n\nTensorFlow2\n\n\n\n\ne\n\nJAX\n\n\n\n\n\n03\n\n\nAdvantage\n\n\n\n\n\n7\nMostly\noptimized AD\n\n\n\n\n\n8\nConvenient\n\n\n\n\n\n9\nConvenient\n\n\n\n\n10\nConvenient and\nmostly optimized AD\n\n\n\n\n\n04\n\n\nDisadvantage\n\n\n\n\n\nA\nManual writing of IR\n\n\n\n\n\nB\nLimited AD optimization\n\n\n\n\n\nD\nDisappointing speed\n\n\n\n\nE\nPure functions\n\n\n\n\n\n\n\n\n\n\n\n\n\n‚ÄÉ‚ÄÉSummarized from a blog post by Chris Rackauckas"
  },
  {
    "objectID": "python/wb_jax_slides.html#installation",
    "href": "python/wb_jax_slides.html#installation",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Installation",
    "text": "Installation\n Install from pip wheels:\n\nPersonal computer: use wheels installation commands from official site\nAlliance clusters: python -m pip install jax --no-index \n\n\nWindows: GPU support only via WSL"
  },
  {
    "objectID": "python/wb_jax_slides.html#the-numpy-api",
    "href": "python/wb_jax_slides.html#the-numpy-api",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "The NumPy API",
    "text": "The NumPy API\n\nNumPyJAX NumPy\n\n\n\nimport numpy as np\n\nprint(np.array([(1, 2, 3), (4, 5, 6)]))\n\n[[1 2 3]\n [4 5 6]]\n\n\n\nprint(np.arange(5))\n\n[0 1 2 3 4]\n\n\n\nprint(np.zeros(2))\n\n[0. 0.]\n\n\n\nprint(np.linspace(0, 2, 9))\n\n[0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ]\n\n\n\n\nimport jax.numpy as jnp\n\nprint(jnp.array([(1, 2, 3), (4, 5, 6)]))\n[[1 2 3]\n [4 5 6]]\nprint(jnp.arange(5))\n[0 1 2 3 4]\nprint(jnp.zeros(2))\n[0. 0.]\nprint(jnp.linspace(0, 2, 9))\n[0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ]"
  },
  {
    "objectID": "python/wb_jax_slides.html#different-types",
    "href": "python/wb_jax_slides.html#different-types",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Different types",
    "text": "Different types\n\nNumpyJAX NumPy\n\n\n\ntype(np.zeros((2, 3)))\n\nnumpy.ndarray\n\n\n\n\ntype(jnp.zeros((2, 3)))\njaxlib.xla_extension.ArrayImpl"
  },
  {
    "objectID": "python/wb_jax_slides.html#different-default-data-types",
    "href": "python/wb_jax_slides.html#different-default-data-types",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Different default data types",
    "text": "Different default data types\n\nNumpyJAX NumPy\n\n\n\nnp.zeros((2, 3)).dtype\n\ndtype('float64')\n\n\n\n\njnp.zeros((2, 3)).dtype\ndtype('float32')\n\nStandard for DL and libraries built for accelerators\nFloat64 are very slow on GPUs and not supported on TPUs"
  },
  {
    "objectID": "python/wb_jax_slides.html#immutable-arrays",
    "href": "python/wb_jax_slides.html#immutable-arrays",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Immutable arrays",
    "text": "Immutable arrays\n\nNumpyJAX NumPy\n\n\n\na = np.arange(5)\na[0] = 9\nprint(a)\n\n[9 1 2 3 4]\n\n\n\n\na = jnp.arange(5)\na[0] = 9\nTypeError: '&lt;class 'jaxlib.xla_extension.ArrayImpl'&gt;' object does not support item assignment. JAX arrays are immutable.\nb = a.at[0].set(9)\nprint(b)\n[9 1 2 3 4]"
  },
  {
    "objectID": "python/wb_jax_slides.html#strict-input-control",
    "href": "python/wb_jax_slides.html#strict-input-control",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Strict input control",
    "text": "Strict input control\n\nNumpyJAX NumPy\n\n\nNumPy is easy-going:\n\nnp.sum([1.0, 2.0])  # argument is a list\n\nnp.float64(3.0)\n\n\n\nnp.sum((1.0, 2.0))  # argument is a tuple\n\nnp.float64(3.0)\n\n\n\n\nTo avoid inefficiencies, JAX will only accept arrays:\njnp.sum([1.0, 2.0])\nTypeError: sum requires ndarray or scalar arguments, got &lt;class 'list'&gt;\njnp.sum((1.0, 2.0))\nTypeError: sum requires ndarray or scalar arguments, got &lt;class 'tuple'&gt;"
  },
  {
    "objectID": "python/wb_jax_slides.html#out-of-bounds-indexing",
    "href": "python/wb_jax_slides.html#out-of-bounds-indexing",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Out of bounds indexing",
    "text": "Out of bounds indexing\n\nNumpyJAX NumPy\n\n\nNumPy will error if you index out of bounds:\n\nprint(np.arange(5)[10])\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[10], line 1\n----&gt; 1 print(np.arange(5)[10])\n\nIndexError: index 10 is out of bounds for axis 0 with size 5\n\n\n\n\n\nJAX will silently return the closest boundary:\nprint(jnp.arange(5)[10])\n4"
  },
  {
    "objectID": "python/wb_jax_slides.html#prng",
    "href": "python/wb_jax_slides.html#prng",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "PRNG",
    "text": "PRNG\nTraditional pseudorandom number generators are based on nondeterministic state of OS\nSlow and problematic for parallel executions\nJAX relies on explicitly-set random state called a key:\nfrom jax import random\n\ninitial_key = random.PRNGKey(18)\nprint(initial_key)\n[ 0 18]"
  },
  {
    "objectID": "python/wb_jax_slides.html#prng-1",
    "href": "python/wb_jax_slides.html#prng-1",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "PRNG",
    "text": "PRNG\nEach key can only be used for one random function, but it can be split into new keys:\nnew_key1, new_key2 = random.split(initial_key)\n\ninitial_key can‚Äôt be used anymore now\n\nprint(new_key1)\n[4197003906 1654466292]\nprint(new_key2)\n[1685972163 1654824463]\nWe need to keep one key to split whenever we need and we can use the other one"
  },
  {
    "objectID": "python/wb_jax_slides.html#prng-2",
    "href": "python/wb_jax_slides.html#prng-2",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "PRNG",
    "text": "PRNG\nTo make sure we don‚Äôt reuse a key by accident, it is best to overwrite the initial key with one of the new ones\nHere are easier names:\nkey = random.PRNGKey(18)\nkey, subkey = random.split(key)\nWe can now use subkey to generate a random array:\nx = random.normal(subkey, (3, 2))"
  },
  {
    "objectID": "python/wb_jax_slides.html#benchmarking",
    "href": "python/wb_jax_slides.html#benchmarking",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Benchmarking",
    "text": "Benchmarking\nJAX uses asynchronous dispatch\nInstead of waiting for a computation to complete before control returns to Python, the computation is dispatched to an accelerator and a future is created\nTo get proper timings, we need to make sure the future is resolved by using the block_until_ready() method"
  },
  {
    "objectID": "python/wb_jax_slides.html#jit-syntax",
    "href": "python/wb_jax_slides.html#jit-syntax",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "JIT syntax",
    "text": "JIT syntax\nfrom jax import jit\n\nkey = random.PRNGKey(8)\nkey, subkey1, subkey2 = random.split(key, 3)\n\na = random.normal(subkey1, (500, 500))\nb = random.normal(subkey2, (500, 500))\n\ndef sum_squared_error(a, b):\n    return jnp.sum((a-b)**2)\nOur function could simply be used as:\nsse = sum_squared_error(a, b)"
  },
  {
    "objectID": "python/wb_jax_slides.html#jit-syntax-1",
    "href": "python/wb_jax_slides.html#jit-syntax-1",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "JIT syntax",
    "text": "JIT syntax\nOur code will run faster if we create a JIT compiled version and use that instead:\nsum_squared_error_jit = jit(sum_squared_error)\n\nsse = sum_squared_error_jit(a, b)\nAlternatively, this can be written as:\nsse = jit(sum_squared_error)(a, b)\nOr with the @jit decorator:\n@jit\ndef sum_squared_error(a, b):\n    return jnp.sum((a - b) ** 2)\n\nsse = sum_squared_error(a, b)"
  },
  {
    "objectID": "python/wb_jax_slides.html#static-vs-traced-variables",
    "href": "python/wb_jax_slides.html#static-vs-traced-variables",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Static vs traced variables",
    "text": "Static vs traced variables\n@jit\ndef cond_func(x):\n    if x &lt; 0.0:\n        return x ** 2.0\n    else:\n        return x ** 3.0\n\nprint(cond_func(1.0))\njax.errors.TracerBoolConversionError: Attempted boolean conversion of traced array with shape bool[]\nJIT compilation uses tracing of the code based on shape and dtype so that the same compiled code can be reused for new values with the same characteristics\nTracer objects are not real values but abstract representation that are more general\nHere, an abstract general value does not work as it wouldn‚Äôt know which branch to take"
  },
  {
    "objectID": "python/wb_jax_slides.html#static-vs-traced-variables-1",
    "href": "python/wb_jax_slides.html#static-vs-traced-variables-1",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Static vs traced variables",
    "text": "Static vs traced variables\nOne solution is to tell jit() to exclude the problematic arguments from tracing\nwith arguments positions:\ndef cond_func(x):\n    if x &lt; 0.0:\n        return x ** 2.0\n    else:\n        return x ** 3.0\n\ncond_func_jit = jit(cond_func, static_argnums=(0,))\n\nprint(cond_func_jit(2.0))\nprint(cond_func_jit(-2.0))\n8.0\n4.0"
  },
  {
    "objectID": "python/wb_jax_slides.html#static-vs-traced-variables-2",
    "href": "python/wb_jax_slides.html#static-vs-traced-variables-2",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Static vs traced variables",
    "text": "Static vs traced variables\nOne solution is to tell jit() to exclude the problematic arguments from tracing\nwith arguments names:\ndef cond_func(x):\n    if x &lt; 0.0:\n        return x ** 2.0\n    else:\n        return x ** 3.0\n\ncond_func_jit_alt = jit(cond_func, static_argnames=\"x\")\n\nprint(cond_func_jit_alt(2.0))\nprint(cond_func_jit_alt(-2.0))\n8.0\n4.0"
  },
  {
    "objectID": "python/wb_jax_slides.html#control-flow-primitives",
    "href": "python/wb_jax_slides.html#control-flow-primitives",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Control flow primitives",
    "text": "Control flow primitives\nAnother solution, is to use one of the structured control flow primitives:\nfrom jax import lax\n\nlax.cond(False, lambda x: x ** 2.0, lambda x: x ** 3.0, jnp.array([2.]))\nArray([8.], dtype=float32)\nlax.cond(True, lambda x: x ** 2.0, lambda x: x ** 3.0, jnp.array([-2.]))\nArray([4.], dtype=float32)"
  },
  {
    "objectID": "python/wb_jax_slides.html#control-flow-primitives-1",
    "href": "python/wb_jax_slides.html#control-flow-primitives-1",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Control flow primitives",
    "text": "Control flow primitives\nOther control flow primitives:\n\nlax.while_loop\nlax.fori_loop\nlax.scan\n\nOther pseudo dynamic control flow functions:\n\nlax.select (NumPy API jnp.where and jnp.select)\nlax.switch (NumPy API jnp.piecewise)"
  },
  {
    "objectID": "python/wb_jax_slides.html#static-vs-traced-operations",
    "href": "python/wb_jax_slides.html#static-vs-traced-operations",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Static vs traced operations",
    "text": "Static vs traced operations\nSimilarly, you can mark problematic operations as static so that they don‚Äôt get traced during JIT compilation:\n@jit\ndef f(x):\n    return x.reshape(jnp.array(x.shape).prod())\n\nx = jnp.ones((2, 3))\nprint(f(x))\nTypeError: Shapes must be 1D sequences of concrete values of integer type, got [Traced&lt;ShapedArray(int32[])&gt;with&lt;DynamicJaxprTrace(level=1/0)&gt;]"
  },
  {
    "objectID": "python/wb_jax_slides.html#static-vs-traced-operations-1",
    "href": "python/wb_jax_slides.html#static-vs-traced-operations-1",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Static vs traced operations",
    "text": "Static vs traced operations\nThe problem here is that the shape of the argument to prod() depends on the value of x which is unknown at compilation time\nOne solution is to use the NumPy version of prod():\nimport numpy as np\n\n@jit\ndef f(x):\n    return x.reshape((np.prod(x.shape)))\n\nprint(f(x))\n[1. 1. 1. 1. 1. 1.]"
  },
  {
    "objectID": "python/wb_jax_slides.html#jaxprs",
    "href": "python/wb_jax_slides.html#jaxprs",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Jaxprs",
    "text": "Jaxprs\nimport jax\n\nx = jnp.array([1., 4., 3.])\ny = jnp.array([8., 1., 2.])\n\ndef f(x, y):\n    return 2 * x**2 + y\n\njax.make_jaxpr(f)(x, y) \n{ lambda ; a:f32[3] b:f32[3]. let\n    c:f32[3] = integer_pow[y=2] a\n    d:f32[3] = mul 2.0 c\n    e:f32[3] = add d b\n  in (e,) }"
  },
  {
    "objectID": "python/wb_jax_slides.html#outputs-only-based-on-inputs",
    "href": "python/wb_jax_slides.html#outputs-only-based-on-inputs",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Outputs only based on inputs",
    "text": "Outputs only based on inputs\ndef f(x):\n    return a + x\nf uses the variable a from the global environment\nThe output does not solely depend on the inputs: not a pure function"
  },
  {
    "objectID": "python/wb_jax_slides.html#outputs-only-based-on-inputs-1",
    "href": "python/wb_jax_slides.html#outputs-only-based-on-inputs-1",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Outputs only based on inputs",
    "text": "Outputs only based on inputs\na = jnp.ones(3)\nprint(a)\n[1. 1. 1.]\ndef f(x):\n    return a + x\n\nprint(jit(f)(jnp.ones(3)))\n[2. 2. 2.]\n\nThings seem ok here because this is the first run (tracing)"
  },
  {
    "objectID": "python/wb_jax_slides.html#outputs-only-based-on-inputs-2",
    "href": "python/wb_jax_slides.html#outputs-only-based-on-inputs-2",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Outputs only based on inputs",
    "text": "Outputs only based on inputs\nNow, let‚Äôs change the value of a to an array of zeros:\na = jnp.zeros(3)\nprint(a)\n[0. 0. 0.]\nAnd rerun the same code:\nprint(jit(f)(jnp.ones(3)))\n[2. 2. 2.]\n\nOur cached compiled program is run and we get a wrong result"
  },
  {
    "objectID": "python/wb_jax_slides.html#outputs-only-based-on-inputs-3",
    "href": "python/wb_jax_slides.html#outputs-only-based-on-inputs-3",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Outputs only based on inputs",
    "text": "Outputs only based on inputs\nThe new value for a will only take effect if we re-trigger tracing by changing the shape and/or dtype of x:\na = jnp.zeros(4)\nprint(a)\n[0. 0. 0. 0.]\nprint(jit(f)(jnp.ones(4)))\n[1. 1. 1. 1.]\nPassing to f() an argument of a different shape forced retracing"
  },
  {
    "objectID": "python/wb_jax_slides.html#no-side-effects",
    "href": "python/wb_jax_slides.html#no-side-effects",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "No side effects",
    "text": "No side effects\nSide effects: anything beside returned output\nExamples:\n\nPrinting to standard output\nReading from file/writing to file\nModifying a global variable"
  },
  {
    "objectID": "python/wb_jax_slides.html#no-side-effects-1",
    "href": "python/wb_jax_slides.html#no-side-effects-1",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "No side effects",
    "text": "No side effects\nThe side effects will happen during tracing, but not on subsequent runs. You cannot rely on side effects in your code\ndef f(a, b):\n    print(\"Calculating sum\")\n    return a + b\n\nprint(jit(f)(jnp.arange(3), jnp.arange(3)))\nCalculating sum\n[0 2 4]\n\nPrinting happened here because this is the first run"
  },
  {
    "objectID": "python/wb_jax_slides.html#no-side-effects-2",
    "href": "python/wb_jax_slides.html#no-side-effects-2",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "No side effects",
    "text": "No side effects\nLet‚Äôs rerun the function:\nprint(jit(f)(jnp.arange(3), jnp.arange(3)))\n[0 2 4]\nThis time, no printing"
  },
  {
    "objectID": "python/wb_jax_slides.html#automatic-differentiation",
    "href": "python/wb_jax_slides.html#automatic-differentiation",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Automatic differentiation",
    "text": "Automatic differentiation\nConsidering the function f:\nf = lambda x: x**3 + 2*x**2 - 3*x + 8\nWe can create a new function dfdx that computes the gradient of f w.r.t. x:\nfrom jax import grad\n\ndfdx = grad(f)\ndfdx returns the derivatives\nprint(dfdx(1.))\n4.0"
  },
  {
    "objectID": "python/wb_jax_slides.html#composing-transformations",
    "href": "python/wb_jax_slides.html#composing-transformations",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Composing transformations",
    "text": "Composing transformations\nTransformations can be composed:\nprint(jit(grad(f))(1.))\n4.0\nprint(grad(jit(f))(1.))\n4.0"
  },
  {
    "objectID": "python/wb_jax_slides.html#forward-and-reverse-modes",
    "href": "python/wb_jax_slides.html#forward-and-reverse-modes",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Forward and reverse modes",
    "text": "Forward and reverse modes\nOther autodiff methods:\n\nReverse-mode vector-Jacobian products: jax.vjp\nForward-mode Jacobian-vector products: jax.jvp"
  },
  {
    "objectID": "python/wb_jax_slides.html#higher-order-differentiation",
    "href": "python/wb_jax_slides.html#higher-order-differentiation",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Higher-order differentiation",
    "text": "Higher-order differentiation\n With a single variable, the grad function calls can be nested:\nd2fdx = grad(dfdx)   # function to compute 2nd order derivatives\nd3fdx = grad(d2fdx)  # function to compute 3rd order derivatives\n...\n With several variables:\n\njax.jacfwd for forward-mode\njax.jacrev for reverse-mode"
  },
  {
    "objectID": "python/wb_jax_slides.html#pytrees",
    "href": "python/wb_jax_slides.html#pytrees",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Pytrees",
    "text": "Pytrees\nJAX has a nested container structure: pytree extremely useful for DNN"
  },
  {
    "objectID": "python/wb_jax_slides.html#vectorization-and-parallelization",
    "href": "python/wb_jax_slides.html#vectorization-and-parallelization",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Vectorization and parallelization",
    "text": "Vectorization and parallelization\nOther transformations for parallel run of computations across batches of arrays:\n\nAutomatic vectorization with jax.vmap\nParallelization across devices with jax.pmap"
  },
  {
    "objectID": "python/wb_jax_slides.html#lax-api",
    "href": "python/wb_jax_slides.html#lax-api",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Lax API",
    "text": "Lax API\njax.numpy is a high-level NumPy-like API wrapped around jax.lax\njax.lax is a more efficient lower-level API itself wrapped around XLA"
  },
  {
    "objectID": "python/wb_jax_slides.html#pallas-extension-to-write-gpu-and-tpu-kernels",
    "href": "python/wb_jax_slides.html#pallas-extension-to-write-gpu-and-tpu-kernels",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Pallas: extension to write GPU and TPU kernels",
    "text": "Pallas: extension to write GPU and TPU kernels\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\n Just-in-time \n(JIT)\ncompilation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\ntriton\n\nTriton\n\n\n\nGPU\n\nGPU\n\n\n\ntriton-&gt;GPU\n\n\n\n\n\nmosaic\n\nMosaic\n\n\n\nTPU\n\nTPU\n\n\n\nmosaic-&gt;TPU\n\n\n\n\n\ntransform\n\nVectorization\nParallelization\n ¬†¬†Differentiation ¬†\n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;triton\n\n\n\n\nhlo-&gt;mosaic"
  },
  {
    "objectID": "python/wb_jax.html",
    "href": "python/wb_jax.html",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "",
    "text": "JAX is an open source Python library for high-performance array computing and flexible automatic differentiation.\nHigh-performance computing is achieved by asynchronous dispatch, just-in-time compilation, the XLA compiler for linear algebra, and full compatibility with accelerators (GPUs and TPUs).\nAutomatic differentiation uses Autograd and works with complex control flows (conditions, recursions), second and third-order derivatives, forward and reverse modes. This makes JAX ideal for machine learning and neural network libraries such as Flax are built on it.\nThis webinar will give an overview of JAX‚Äôs principles and functioning.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Accelerated arrays & AD"
    ]
  },
  {
    "objectID": "python/wb_hss_prog_content.html",
    "href": "python/wb_hss_prog_content.html",
    "title": "Intro programming for the humanities",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Intro programming for HSS",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_hss_prog_content.html#computer-programming",
    "href": "python/wb_hss_prog_content.html#computer-programming",
    "title": "Intro programming for the humanities",
    "section": "Computer programming",
    "text": "Computer programming\nProgramming (or coding) consists of writing a set of instructions (a program) for computers so that they perform a task.\nThere are many programming languages‚Äîeach with its own syntax‚Äîbut the core concepts apply to all languages. For this course, we will use Python.\nPrograms accept inputs (data) and produce outputs (transformed data).",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Intro programming for HSS",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_hss_prog_content.html#how-to-choose-a-language",
    "href": "python/wb_hss_prog_content.html#how-to-choose-a-language",
    "title": "Intro programming for the humanities",
    "section": "How to choose a language?",
    "text": "How to choose a language?\n\nImportant considerations\n\nFree and open source software (FOSS) vs proprietary.\nCompiled vs interpreted language (speed vs convenience).\nLanguage adapted to particular usage.\nLanguage used in your field (colleagues, collaborators, literature).\n\n\n\nDownsides of proprietary software\n\nResearchers who do not have access to the tool cannot reproduce your methods.\nOnce you leave academia, you may not have access to the tool anymore.\nYour university may stop paying for a license.\nYou may get locked-in.\nProprietary tools are black boxes.\nLong-term access is uncertain.\nProprietary tools fall behind popular open-source tools.\nProprietary tools often fail to address specialized edge cases needed in research.\n\n\n\nThe argument for FOSS\n\nEqual access to everyone, including poorer countries or organizations (it‚Äôs free!).\nOpen science.\nTransparency.\nThe whole community can contribute to and have a say about development.\nYou an build specific capabilities for your edge cases.\nGuarantied long term access.\nNo risk of getting locked-in.\n\n\n\nCompiled languages\nYou write code, compile it into machine code, then use this to process your data:\n\nCompiled languages are fast. The two step process however makes prototyping less practical and these languages are hard to learn and debug.\n\nExamples of compiled languages include C, C++, Fortran, Go, Haskell.\n\n\n\nInterpreted languages\nInterpreted languages are executed directly:\n\nYou get direct feed-back, making it easier to prototype. Interpreted languages are easy to learn and debug, but they are much slower.\n\nExamples of interpreted languages include R, Python, Perl, and JavaScript.\n\n\n\nPython\nPython is free and open-source, interpreted, and general-purpose.\nIt was created by Dutch programmer Guido van Rossum in the 80s, with a launch in 1989.\nThe PYPL PopularitY of Programming Language index is based on the number of tutorial searches in Google. Python has been going up steadily, reaching the first position in 2018. It is also ahead in other indices and is the language used by most of the deep learning community.\nThis doesn‚Äôt mean that Python is better than other languages, but it means that there are a lot of resources and a large collection of external packages.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Intro programming for HSS",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_hss_prog_content.html#tools-you-need-for-programming",
    "href": "python/wb_hss_prog_content.html#tools-you-need-for-programming",
    "title": "Intro programming for the humanities",
    "section": "Tools you need for programming",
    "text": "Tools you need for programming\n\nText editor to write scripts\nA text editor is not the same as a word processor such as Microsoft Office Word. Word documents are not plain text documents: they contain a lot of hidden formatting and are actually a collection of files. This is not what you want to write scripts.\nExamples of good text editors (free and open source):\n\nEmacs\nVisual Studio Code\nVim\n\n\n\nOptional: an IDE\nIntegrated development environments (IDEs) are software that make running a language more friendly by adding functionality and convenience tools, usually within a graphical user interface (GUI).\nA popular IDE for Python is JupyterLab.\n\n\nDebugging and profiling tools\nSome languages come with debugging tools that make it easier to find problems in the code.\nProfilers allow you to spot bottlenecks in the execution of your code.\nBenchmarking tools allow you to compare several versions of code to find which is faster.\n\n\nHardware\nPython is great in many respects, but it is not a fast language.\nMany libraries for Python are written in faster compiled languages (e.g.¬†C, C++, Fortran).\nTo speed things up more, some code or sections of code can be run in parallel (instead of serially). To do this though, you need more hardware.\nYou can run code using multiple CPUs (central processing unit). Some code can be accelerated using GPUs (graphical processing unit).\nFor very large scale projects such as very large simulations, deep learning, or big data projects, you can use supercomputers.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Intro programming for HSS",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_hss_prog_content.html#how-to-run-python",
    "href": "python/wb_hss_prog_content.html#how-to-run-python",
    "title": "Intro programming for the humanities",
    "section": "How to run Python",
    "text": "How to run Python\n\nPython shell\nThe simplest way to use Python is to type commands directly in the Python shell. This sends commands directly to the interpreter.\nThe Python shell has a prompt that looks like this:\n&gt;&gt;&gt;\n\n\nIPython\nIPython is an improved shell with better performance and more functionality (e.g.¬†colour-coding, magic commands).\nThe prompt looks like:\nIn [x]:\n\nx is the command number (e.g.¬†for your first command, it will show In [1]:.\n\n\n\nJupyter\nThe IPython shell was integrated into a fancy interface, the Jupyter notebook. This later lead to a fully fledged IDE (integrated development environment) called JupyterLab which contains notebooks, a command line, a file explorer, and other functionality.\n\nEven though JupyterLab runs in your browser, it does not use the internet: it is all run locally on your machine (browsers are software that are great at displaying HTML files, so we use them to access the web, but they can also display files from your computer).\n\n\n\nOther IDEs\nJupyter has probably become the most popular IDE, but it is possible to run Python in other IDE such as Emacs.\n\n\nPython script\nYou can write your Python code in a text file with a .py extension and run the script in your terminal with:\npython script.py\nThis will execute the code non-interactively.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Intro programming for HSS",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_hss_prog_content.html#programming-concepts",
    "href": "python/wb_hss_prog_content.html#programming-concepts",
    "title": "Intro programming for the humanities",
    "section": "Programming concepts",
    "text": "Programming concepts\n\nPackages\nMany languages can have their functionality expanded by the installation of packages developed by the open source community. The potential is unlimited.\nMany languages come with their own package manager.\nIn Python, popular package managers include pip, Conda, and the newer much faster uv.\n\n\nSyntax\nEach language uses its own syntax.\n\nExample:\nIn Python, the tab (equal to four spaces by default) has meaning, while in R, it doesn‚Äôt (it only makes it easier for people to read code).\n\n\n\nData types\nEach language contains various data types such as integers, floating-point numbers (decimals), strings (series of characters), Booleans (true/false), etc.\n\nPython examples:\n\n\ntype(5)\n\nint\n\n\n\ntype(5.0)\n\nfloat\n\n\n\ntype(\"This is a string\")\n\nstr\n\n\n\ntype(True)\n\nbool\n\n\n\n\nVariables\nValues can be assigned to names to create variables.\n\nPython example:\n\n\na = 3\n\na is now a variable containing the value 3:\n\nprint(a)\n\n3\n\n\n\na * 2\n\n6\n\n\n\n\nData structures\nA data structure is a collection of values.\n\nPython examples:\n\n\ntype([0, 5, \"something\"])\n\nlist\n\n\n\ntype((3, 5, \"something\"))\n\ntuple\n\n\n\ntype({0, 2, 6})\n\nset\n\n\nEach type of structure has its own characteristics (necessarily homogeneous or not, mutable or not, ordered or not, etc.). This gives several data storage options, each best in different situations.\n\n\nFunctions\nFunctions are snippets of code that accomplish a specific task.\nBuilt-in functions come with the language and are readily available. Other functions become available once a particular module or package is loaded. Finally, the user can definite their own functions.\nSome functions take arguments.\n\nPython examples:\n\n\nmax([3, 5, 2])\n\n5\n\n\n\ndef hello():\n    print(\"Hello everyone!\")\n\nhello()\n\nHello everyone!\n\n\n\n\nControl flow\nCommands are normally run sequentially, from top to bottom, but it is possible to alter the flow of execution by creating repeats (loops) or conditional executions.\n\nPython examples:\n\n\nfor i in range(3):\n    print(i)\n\n0\n1\n2\n\n\n\nx = -3\n\nif x &gt; 0:\n    print(x + 2)\nelse:\n    print(x * 3)\n\n-9",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Intro programming for HSS",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_hss_prog_content.html#getting-help",
    "href": "python/wb_hss_prog_content.html#getting-help",
    "title": "Intro programming for the humanities",
    "section": "Getting help",
    "text": "Getting help\n\nInternal documentation\nMost languages come with their internal documentation.\n\nExample with Python:\n\nhelp(sum)\nHelp on built-in function sum in module builtins:\n\nsum(iterable, /, start=0)\n    Return the sum of a 'start' value (default: 0) plus an iterable of numbers\n\n    When the iterable is empty, return the start value.\n    This function is intended specifically for use with numeric values and may\n    reject non-numeric types.\n\n\nThe internet\nGoogle is often your best bet, but you need to know the vocabulary in order to ask questions.\nStack Overflow is a fantastic community question & answer website.\n\n\nLarge language models (LLMs)\nOver the past few years, LLMs have become increasingly performant at coding.\nPeople use them in different ways:\n\nAsk questions (explain code, documentation).\nAuto-completion.\nFirst code draft.\nDebugging.\nVibe coding.\n\nIn this course, I will show you how they can help you write code.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Intro programming for HSS",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/top_ws.html",
    "href": "python/top_ws.html",
    "title": "Python workshops",
    "section": "",
    "text": "Web scraping with ¬†\n\n\n\n\nDataFrames with ¬†\n\n\n\n\nPlaying with text",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>"
    ]
  },
  {
    "objectID": "python/top_nlp.html",
    "href": "python/top_nlp.html",
    "title": "Text analysis",
    "section": "",
    "text": "This course is a gentle introduction to rule-based text analysis for the humanities and social sciences using the Python library TextBlob.\nIt only requires a very basic knowledge of Python.\n\n Start course ‚û§",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>"
    ]
  },
  {
    "objectID": "python/top_intro.html",
    "href": "python/top_intro.html",
    "title": "Getting started in Python",
    "section": "",
    "text": "For better or for worse, Python has been one of the most popular programming languages for the past 20 years. During that period, it has increasingly become a key language for data science. Its¬†prevalence was further consolidated by the advent of deep learning since the most popular frameworks were released as Python libraries.\nThis introductory course will walk you through the basics of programming in Python. We will cover the main language features: variables and data types, conditionals, lists, for/while loops, list comprehensions, dictionaries, and writing functions.\n\n Start course ‚û§",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>"
    ]
  },
  {
    "objectID": "python/polars_types.html",
    "href": "python/polars_types.html",
    "title": "Data types",
    "section": "",
    "text": "Data types supported by Polars are, for the most part, quite classic.",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Data types"
    ]
  },
  {
    "objectID": "python/polars_types.html#list-of-data-types",
    "href": "python/polars_types.html#list-of-data-types",
    "title": "Data types",
    "section": "List of data types",
    "text": "List of data types\n\n\n\n\n\n\n\n\n\nnumeric\nnumeric\n\n\n\ntemporal\ntemporal\n\n\n\n\nsint\nsigned integer\n\n\n\nnumeric--sint\n\n\n\n\nuint\nunsigned integer\n\n\n\nnumeric--uint\n\n\n\n\nfloat\nfloat\n\n\n\nnumeric--float\n\n\n\n\nDecimal\n\nDecimal\n\n\n\nnumeric--Decimal\n\n\n\n\nnested\nnested\n\n\n\n\nDate\n\nDate\n\n\n\ntemporal--Date\n\n\n\n\nTime\n\nTime\n\n\n\ntemporal--Time\n\n\n\n\nDatetime\n\nDatetime\n\n\n\ntemporal--Datetime\n\n\n\n\nDuration\n\nDuration\n\n\n\ntemporal--Duration\n\n\n\n\nList\n\nList\n\n\n\nnested--List\n\n\n\n\nStruct\n\nStruct\n\n\n\nnested--Struct\n\n\n\n\nArray\n\nArray\n\n\n\nnested--Array\n\n\n\n\nInt8\n\nInt8\n\n\n\nsint--Int8\n\n\n\n\nInt16\n\nInt16\n\n\n\nsint--Int16\n\n\n\n\nInt32\n\nInt32\n\n\n\nsint--Int32\n\n\n\n\nInt64\n\nInt64\n\n\n\nsint--Int64\n\n\n\n\nUInt8\n\nUInt8\n\n\n\nuint--UInt8\n\n\n\n\nUInt16\n\nUInt16\n\n\n\nuint--UInt16\n\n\n\n\nUInt32\n\nUInt32\n\n\n\nuint--UInt32\n\n\n\n\nUInt64\n\nUInt64\n\n\n\nuint--UInt64\n\n\n\n\nFloat32\n\nFloat32\n\n\n\nfloat--Float32\n\n\n\n\nFloat64\n\nFloat64\n\n\n\nfloat--Float64\n\n\n\n\nBoolean\n\nBoolean\n\n\n\nBoolean--Int8\n\n\n\n\nDecimal--Date\n\n\n\n\nDate--Time\n\n\n\n\nTime--Datetime\n\n\n\n\nDatetime--Duration\n\n\n\n\nString\n\nString\n\n\n\nDuration--String\n\n\n\n\nList--Struct\n\n\n\n\nStruct--Array\n\n\n\n\nBinary\n\nBinary\n\n\n\nString--Binary\n\n\n\n\nObject\n\nObject\n\n\n\nBinary--Object\n\n\n\n\nCategorical\n\nCategorical\n\n\n\nObject--Categorical\n\n\n\n\nEnum\n\nEnum\n\n\n\nCategorical--Enum\n\n\n\n\nEnum--List\n\n\n\n\nNull\n\nNull\n\n\n\nNull--Boolean\n\n\n\n\nInt8--Int16\n\n\n\n\nInt16--Int32\n\n\n\n\nInt32--Int64\n\n\n\n\nInt64--UInt8\n\n\n\n\nUInt8--UInt16\n\n\n\n\nUInt16--UInt32\n\n\n\n\nUInt32--UInt64\n\n\n\n\nUInt64--Float32\n\n\n\n\nFloat32--Float64\n\n\n\n\nFloat64--Decimal",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Data types"
    ]
  },
  {
    "objectID": "python/polars_types.html#exotic-polars-types",
    "href": "python/polars_types.html#exotic-polars-types",
    "title": "Data types",
    "section": "Exotic Polars types",
    "text": "Exotic Polars types\nStructs are series combining multiple columns.\nEnum is used for categorical variables. It is stricter, but also more efficient than the more flexible and slower Categorical type. When categories are all known before runtime, use Enum. If you need to infer the categories at runtime, use Categorical.\nObject allows to wrap any Python object.",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Data types"
    ]
  },
  {
    "objectID": "python/polars_structures.html",
    "href": "python/polars_structures.html",
    "title": "Data structures",
    "section": "",
    "text": "Polars provides two fundamental data structures: series and data frames.",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Data structures"
    ]
  },
  {
    "objectID": "python/polars_structures.html#series",
    "href": "python/polars_structures.html#series",
    "title": "Data structures",
    "section": "Series",
    "text": "Series\nIn Polars, series are one-dimensional and homogeneous (all elements have the same data type).\n\nIn other frameworks or languages (e.g.¬†pandas, R), such data structure would be called a vector.\n\n\nimport polars as pl\n\ns1 = pl.Series(range(5))\nprint(s1)\n\nshape: (5,)\nSeries: '' [i64]\n[\n    0\n    1\n    2\n    3\n    4\n]\n\n\n\nData types\nPolars infers data types from the data. Defaults are Int64 and Float64. For other options, you can create typed series by specifying the type:\n\ns2 = pl.Series(range(5), dtype=pl.Int32)\nprint(s2)\n\nshape: (5,)\nSeries: '' [i32]\n[\n    0\n    1\n    2\n    3\n    4\n]\n\n\n\n\nNamed series\nSeries can be named:\n\ns3 = pl.Series(\"Name\", [\"Bob\", \"Luc\", \"Lucy\"])\nprint(s3)\n\nshape: (3,)\nSeries: 'Name' [str]\n[\n    \"Bob\"\n    \"Luc\"\n    \"Lucy\"\n]",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Data structures"
    ]
  },
  {
    "objectID": "python/polars_structures.html#data-frames",
    "href": "python/polars_structures.html#data-frames",
    "title": "Data structures",
    "section": "Data frames",
    "text": "Data frames\nData frames are two-dimensional and composed of named series of equal lengths. This means that data frames are heterogeneous, but that columns contain homogeneous data.\nThey can be created from:\n\nlists of series:\n\n\ndf1 = pl.DataFrame([s3, pl.Series(\"Colour\", [\"Red\", \"Green\", \"Blue\"])])\nprint(df1)\n\nshape: (3, 2)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Name ‚îÜ Colour ‚îÇ\n‚îÇ ---  ‚îÜ ---    ‚îÇ\n‚îÇ str  ‚îÜ str    ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ Bob  ‚îÜ Red    ‚îÇ\n‚îÇ Luc  ‚îÜ Green  ‚îÇ\n‚îÇ Lucy ‚îÜ Blue   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\ndictionaries:\n\n\nfrom datetime import date\n\ndf2 = pl.DataFrame(\n    {\n        \"Date\": [\n            date(2024, 10, 1),\n            date(2024, 10, 2),\n            date(2024, 10, 3),\n            date(2024, 10, 6)\n        ],\n        \"Rain\": [2.1, 0.5, 0.0, 1.8],\n        \"Cloud cover\": [1, 1, 0, 2]\n        }\n    )\nprint(df2)\n\nshape: (4, 3)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Date       ‚îÜ Rain ‚îÜ Cloud cover ‚îÇ\n‚îÇ ---        ‚îÜ ---  ‚îÜ ---         ‚îÇ\n‚îÇ date       ‚îÜ f64  ‚îÜ i64         ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 2024-10-01 ‚îÜ 2.1  ‚îÜ 1           ‚îÇ\n‚îÇ 2024-10-02 ‚îÜ 0.5  ‚îÜ 1           ‚îÇ\n‚îÇ 2024-10-03 ‚îÜ 0.0  ‚îÜ 0           ‚îÇ\n‚îÇ 2024-10-06 ‚îÜ 1.8  ‚îÜ 2           ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\nNumPy ndarrays:\n\n\nimport numpy as np\n\ndf3 = pl.DataFrame(np.array([(1, 2), (3, 4)]))\nprint(df3)\n\nshape: (2, 2)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ column_0 ‚îÜ column_1 ‚îÇ\n‚îÇ ---      ‚îÜ ---      ‚îÇ\n‚îÇ i64      ‚îÜ i64      ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 1        ‚îÜ 2        ‚îÇ\n‚îÇ 3        ‚îÜ 4        ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\nBecause NumPy ndarrays are stored in memory by rows, the values in the first dimension of the array fill in the first row. If you want to fill in the data frame by column, you use the orient parameter:\n\ndf4 = pl.DataFrame(np.array([(1, 2), (3, 4)]), orient=\"col\")\nprint(df4)\n\nshape: (2, 2)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ column_0 ‚îÜ column_1 ‚îÇ\n‚îÇ ---      ‚îÜ ---      ‚îÇ\n‚îÇ i64      ‚îÜ i64      ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 1        ‚îÜ 3        ‚îÇ\n‚îÇ 2        ‚îÜ 4        ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\nTo specify column names, you can use the schema parameter:\n\ndf5 = pl.DataFrame(np.array([(1, 2), (3, 4)]), schema=[\"Var1\", \"Var2\"])\nprint(df5)\n\nshape: (2, 2)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Var1 ‚îÜ Var2 ‚îÇ\n‚îÇ ---  ‚îÜ ---  ‚îÇ\n‚îÇ i64  ‚îÜ i64  ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 1    ‚îÜ 2    ‚îÇ\n‚îÇ 3    ‚îÜ 4    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Data structures"
    ]
  },
  {
    "objectID": "python/polars_structures.html#data-types-1",
    "href": "python/polars_structures.html#data-types-1",
    "title": "Data structures",
    "section": "Data types",
    "text": "Data types\nTo specify data types different from the default, you also use the schema parameter:\n\ndf6 = pl.DataFrame(\n    {\n        \"Rain\": [2.1, 0.5, 0.0, 1.8],\n        \"Cloud cover\": [1, 1, 0, 2],\n    },\n    schema={\"Rain\": pl.Float32, \"Cloud cover\": pl.Int32}\n)\nprint(df6)\n\nshape: (4, 2)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Rain ‚îÜ Cloud cover ‚îÇ\n‚îÇ ---  ‚îÜ ---         ‚îÇ\n‚îÇ f32  ‚îÜ i32         ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 2.1  ‚îÜ 1           ‚îÇ\n‚îÇ 0.5  ‚îÜ 1           ‚îÇ\n‚îÇ 0.0  ‚îÜ 0           ‚îÇ\n‚îÇ 1.8  ‚îÜ 2           ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Data structures"
    ]
  },
  {
    "objectID": "python/polars_pandas.html",
    "href": "python/polars_pandas.html",
    "title": "Comparison with pandas",
    "section": "",
    "text": "As pandas was the only data frame library for Python for a long time, many Python users are familiar with it and a comparison with Polars might be useful.",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Comparison with pandas"
    ]
  },
  {
    "objectID": "python/polars_pandas.html#overview",
    "href": "python/polars_pandas.html#overview",
    "title": "Comparison with pandas",
    "section": "Overview",
    "text": "Overview\n\n\n\n\npandas\nPolars\n\n\n\n\nAvailable for\nPython\nRust, Python, R, NodeJS\n\n\nWritten in\nCython\nRust\n\n\nMultithreading\nSome operations\nYes (GIL released)\n\n\nIndex\nRows are indexed\nInteger positions are used\n\n\nEvaluation\nEager\nEager and lazy\n\n\nQuery optimizer\nNo\nYes\n\n\nOut-of-core\nNo\nYes\n\n\nSIMD vectorization\nYes\nYes\n\n\nData in memory\nWith NumPy arrays\nWith Apache Arrow arrays\n\n\nMemory efficiency\nPoor\nExcellent\n\n\nHandling of missing data\nInconsistent\nConsistent, promotes type stability",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Comparison with pandas"
    ]
  },
  {
    "objectID": "python/polars_pandas.html#performance",
    "href": "python/polars_pandas.html#performance",
    "title": "Comparison with pandas",
    "section": "Performance",
    "text": "Performance\n\nExample 1\nLet‚Äôs use the FizzBuzz problem.\nIn his pandas course, Alex compares multiple methods and shows that the best method uses masks. Let‚Äôs see how Polars fares in comparison to pandas‚Äô best method.\nFirst, let‚Äôs load the packages we will need:\n\nimport pandas as pd\nimport numpy as np\nimport polars as pl\n\nAnd let‚Äôs make sure that the code works.\nWith pandas:\n\ndf_pd = pd.DataFrame()\nsize = 10_000\ndf_pd[\"number\"] = np.arange(1, size+1)\ndf_pd[\"response\"] = df_pd[\"number\"].astype(str)\ndf_pd.loc[df_pd[\"number\"] % 3 == 0, \"response\"] = \"Fizz\"\ndf_pd.loc[df_pd[\"number\"] % 5 == 0, \"response\"] = \"Buzz\"\ndf_pd.loc[df_pd[\"number\"] % 15 == 0, \"response\"] = \"FizzBuzz\"\n\nprint(df_pd)\n\n      number response\n0          1        1\n1          2        2\n2          3     Fizz\n3          4        4\n4          5     Buzz\n...      ...      ...\n9995    9996     Fizz\n9996    9997     9997\n9997    9998     9998\n9998    9999     Fizz\n9999   10000     Buzz\n\n[10000 rows x 2 columns]\n\n\nWith Polars:\n\nsize = 10_000\ndf_pl = pl.DataFrame({\"number\": np.arange(1, size+1)})\ndf_pl.with_columns(pl.col(\"number\").cast(pl.String).alias(\"response\"))\ndf_pl = df_pl.with_columns(\n    pl.when(pl.col(\"number\") % 3 == 0)\n    .then(pl.lit(\"Fizz\"))\n    .when(pl.col(\"number\") % 5 == 0)\n    .then(pl.lit(\"Buzz\"))\n    .when(pl.col(\"number\") % 15 == 0)\n    .then(pl.lit(\"FizzBuzz\"))\n    .otherwise(pl.col(\"number\"))\n    .alias(\"response\")\n)\n\nprint(df_pl)\n\nshape: (10_000, 2)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ number ‚îÜ response ‚îÇ\n‚îÇ ---    ‚îÜ ---      ‚îÇ\n‚îÇ i64    ‚îÜ str      ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 1      ‚îÜ 1        ‚îÇ\n‚îÇ 2      ‚îÜ 2        ‚îÇ\n‚îÇ 3      ‚îÜ Fizz     ‚îÇ\n‚îÇ 4      ‚îÜ 4        ‚îÇ\n‚îÇ 5      ‚îÜ Buzz     ‚îÇ\n‚îÇ ‚Ä¶      ‚îÜ ‚Ä¶        ‚îÇ\n‚îÇ 9996   ‚îÜ Fizz     ‚îÇ\n‚îÇ 9997   ‚îÜ 9997     ‚îÇ\n‚îÇ 9998   ‚îÜ 9998     ‚îÇ\n‚îÇ 9999   ‚îÜ Fizz     ‚îÇ\n‚îÇ 10000  ‚îÜ Buzz     ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\nNow, let‚Äôs time them.\npandas:\n\n%%timeit\n\ndf_pd = pd.DataFrame()\nsize = 10_000\ndf_pd[\"number\"] = np.arange(1, size+1)\ndf_pd[\"response\"] = df_pd[\"number\"].astype(str)\ndf_pd.loc[df_pd[\"number\"] % 3 == 0, \"response\"] = \"Fizz\"\ndf_pd.loc[df_pd[\"number\"] % 5 == 0, \"response\"] = \"Buzz\"\ndf_pd.loc[df_pd[\"number\"] % 15 == 0, \"response\"] = \"FizzBuzz\"\n\n3.7 ms ¬± 26.4 Œºs per loop (mean ¬± std. dev. of 7 runs, 100 loops each)\n\n\nPolars:\n\n%%timeit\n\nsize = 10_000\ndf_pl = pl.DataFrame({\"number\": np.arange(1, size+1)})\ndf_pl.with_columns(pl.col(\"number\").cast(pl.String).alias(\"response\"))\ndf_pl.with_columns(\n    pl.when(pl.col(\"number\") % 3 == 0)\n    .then(pl.lit(\"Fizz\"))\n    .when(pl.col(\"number\") % 5 == 0)\n    .then(pl.lit(\"Buzz\"))\n    .when(pl.col(\"number\") % 15 == 0)\n    .then(pl.lit(\"FizzBuzz\"))\n    .otherwise(pl.col(\"number\"))\n    .alias(\"response\")\n)\n\n583 Œºs ¬± 2.78 Œºs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)\n\n\nThat‚Äôs a speedup of 9 (the longer the series, the larger this speedup will be).\n\n\nExample 2\nFor a second example, let‚Äôs go back to the jeopardy example with a large file and compare the timing of pandas and Polar.\nFirst, let‚Äôs make sure that the code works.\npandas:\n\ndf_pd = pd.read_csv(\"https://raw.githubusercontent.com/razoumov/publish/master/jeopardy.csv\")\ndf_pd.loc[df_pd[\"Category\"] == \"HISTORY\"].shape\n\n(349, 7)\n\n\nPolars:\n\ndf_pl = pl.read_csv(\"https://raw.githubusercontent.com/razoumov/publish/master/jeopardy.csv\")\ndf_pl.filter(pl.col(\"Category\") == \"HISTORY\").shape\n\n(349, 7)\n\n\nAnd now for timings.\npandas:\n\n%%timeit\n\ndf_pd = pd.read_csv(\"https://raw.githubusercontent.com/razoumov/publish/master/jeopardy.csv\")\ndf_pd.loc[df_pd[\"Category\"] == \"HISTORY\"].shape\n\n1.15 s ¬± 14.8 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n\n\nPolars:\n\n%%timeit\n\ndf_pl = pl.read_csv(\"https://raw.githubusercontent.com/razoumov/publish/master/jeopardy.csv\")\ndf_pl.filter(pl.col(\"Category\") == \"HISTORY\").shape\n\n825 ms ¬± 26.9 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n\n\nThat‚Äôs a speedup of 2.\nBut it gets much better with lazy evaluation. First, we create a LazyFrame instead of a DataFrame by using scan_csv instead of read_csv. The query is not evaluated but a graph is created. This allows the query optimizer to combine operations and perform optimizations where possible, very much the way compilers work. To evaluate the query and get a result, we use the collect method.\nLet‚Äôs make sure that the lazy Polars code gives us the same result:\n\ndf_pl = pl.scan_csv(\"https://raw.githubusercontent.com/razoumov/publish/master/jeopardy.csv\")\ndf_pl.filter(pl.col(\"Category\") == \"HISTORY\").collect().shape\n\n(349, 7)\n\n\nLazy timing:\n\n%%timeit\n\ndf_pl = pl.scan_csv(\"https://raw.githubusercontent.com/razoumov/publish/master/jeopardy.csv\")\ndf_pl.filter(pl.col(\"Category\") == \"HISTORY\").collect().shape\n\n72.9 ms ¬± 12.2 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)\n\n\nThat‚Äôs a speedup of 20 (the larger the file, the larger this speedup will be).\n\nPandas is trying to fight back: v 2.0 came with optional Arrow support instead of NumPy, then it became the default engine, but performance remains way below that of Polars (e.g.¬†in DataCamp benchmarks, official benchmarks, many blog posts for whole scripts or individual tasks).\n\n\nComparison with other frameworks\nComparisons between Polars and distributed (Dask, Ray, Spark) or GPU (RAPIDS) libraries aren‚Äôt the most pertinent since they can be used in combination with Polars and the benefits can thus be combined.\nIt only makes sense to compare Polars with other libraries occupying the same ‚Äúniche‚Äù such as pandas or Vaex.\nFor Vaex, some benchmark found it twice slower, but this could have changed with recent developments.\nOne framework performing better than Polars in some benchmarks is datatable (derived from the R package data.table), but it hasn‚Äôt been developed for a year‚Äîa sharp contrast with the fast development of Polars.",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Comparison with pandas"
    ]
  },
  {
    "objectID": "python/polars_pandas.html#migrating-from-pandas",
    "href": "python/polars_pandas.html#migrating-from-pandas",
    "title": "Comparison with pandas",
    "section": "Migrating from Pandas",
    "text": "Migrating from Pandas\nRead the migration guide: it will help you write Polars code rather than ‚Äúliterally translated‚Äù Pandas code that runs, but doesn‚Äôt make use of Polars‚Äô strengths. The differences in style mostly come from the fact that Polars runs in parallel.",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Comparison with pandas"
    ]
  },
  {
    "objectID": "python/polars_install.html",
    "href": "python/polars_install.html",
    "title": "Installation",
    "section": "",
    "text": "The best way to install Polars is to do so inside a Python virtual environment.\nFor this course, we will use a JupyterHub running on a training cluster.",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Installation"
    ]
  },
  {
    "objectID": "python/polars_install.html#installing-polars",
    "href": "python/polars_install.html#installing-polars",
    "title": "Installation",
    "section": "Installing Polars",
    "text": "Installing Polars\n\nPersonal computer\npython -m venv ~/env                  # Create virtual env\nsource ~/env/bin/activate             # Activate virtual env\npip install --upgrade pip             # Update pip\npip install polars                    # Install Polars\n\nA newer and much faster approach to install Python packages now is to use uv.\n\n\n\nAlliance clusters\nPolars wheels are available for Polars (always prefer wheels when possible):\npython -m venv ~/env                  # Create virtual env\nsource ~/env/bin/activate             # Activate virtual env\npip install --upgrade pip --no-index  # Update pip from wheel\npip install polars --no-index         # Install Polars from wheel",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Installation"
    ]
  },
  {
    "objectID": "python/polars_install.html#running-polars-for-this-course",
    "href": "python/polars_install.html#running-polars-for-this-course",
    "title": "Installation",
    "section": "Running Polars for this course",
    "text": "Running Polars for this course\nFor this course, we will use JupyterLab on a training cluster via JupyterHub‚Äîa set of tools that spawn and manage multiple instances of JupyterLab servers.\n\nLog in to JupyterHub\n\ngo to the URL we will give you in class,\nsign in with the username and password we will give you,\nleave OTP blank,\nyou don‚Äôt need to edit anything in the server options,\npress start.\n\n\nNote that, unlike other JupyterHubs you might have used (e.g.¬†Syzygy), this JupyterHub is not permanent and will be destroyed at the end of this course.\n\nIf you don‚Äôt need all the time you asked for after all, it is a great thing to log out (the resources you are using on this cluster are shared amongst many people and when resources are allocated to you, they aren‚Äôt available to other people. So it is a good thing not to ask for unnecessary resources and have them sit idle when others could be using them).\nTo log out, click on File in the top menu and select Log out at the very bottom.\nIf you would like to make a change to the information you entered on the server option page after you have pressed start, log out in the same way, log back in, edit the server options, and press start again.\n\n\nStart a Python notebook\nTo start a Jupyter notebook with the Python kernel, click on the button Python 3 in the Notebook section (top row of buttons).",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Installation"
    ]
  },
  {
    "objectID": "python/polars_dataframes.html",
    "href": "python/polars_dataframes.html",
    "title": "The world of data frames",
    "section": "",
    "text": "Let‚Äôs talk about data frames, how they came to the world of programming, how pandas had the monopoly for many years in Python, and how things are changing very quickly at the moment.",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "The world of data frames"
    ]
  },
  {
    "objectID": "python/polars_dataframes.html#tabular-data",
    "href": "python/polars_dataframes.html#tabular-data",
    "title": "The world of data frames",
    "section": "Tabular data",
    "text": "Tabular data\nMany fields of machine learning, data science, and humanities rely on tabular data where:\n\ncolumns hold variables and are homogeneous (same data type)‚Äîyou can think of them as vectors,\nrows contain observations and can be heterogeneous.\n\nEarly computer options to manipulate such data were limited to spreadsheets (e.g.¬†Microsoft Excel).\nDataframes (data frames or DataFrames) are two dimensional objects that brought tabular data to programming.",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "The world of data frames"
    ]
  },
  {
    "objectID": "python/polars_dataframes.html#early-history-of-data-frames",
    "href": "python/polars_dataframes.html#early-history-of-data-frames",
    "title": "The world of data frames",
    "section": "Early history of data frames",
    "text": "Early history of data frames\nAfter data frames emerged in S, then R, they were added to Python with the library pandas in 2008:\n\n\n\n\n\n\n\n\n\ny1\n1990\n\n\n\ny2\n2000\n\n\n\ny1--y2\n\n\n\n\ny3\n2008\n\n\n\ny2--y3\n\n\n\n\nl1\n\nS programming language\n\n\n\n\n\nl2\n\nR\n\n\n\n\n\n\nl3\n\npandas (Python)\n\n\n\n\n\n\n\n\n\n\n\nAfter which, pandas remained the Python data frame library for a long time.",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "The world of data frames"
    ]
  },
  {
    "objectID": "python/polars_dataframes.html#issues-with-pandas",
    "href": "python/polars_dataframes.html#issues-with-pandas",
    "title": "The world of data frames",
    "section": "Issues with pandas",
    "text": "Issues with pandas\nWes McKinney‚Äîthe author of pandas‚Äîhimself has complaints about pandas:\n\ninternals too far from the hardware,\nno support for memory-mapped datasets,\npoor performance in database and file ingest / export,\nlack of proper support for missing data,\nlack of memory use and RAM management transparency,\nweak support for categorical data,\ncomplex groupby operations awkward and slow,\nappending data to a DataFrame tedious and costly,\nlimited and non-extensible type metadata,\neager evaluation model with no query planning,\nslow and limited multicore algorithms for large datasets.",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "The world of data frames"
    ]
  },
  {
    "objectID": "python/polars_dataframes.html#a-rich-new-field",
    "href": "python/polars_dataframes.html#a-rich-new-field",
    "title": "The world of data frames",
    "section": "A rich new field",
    "text": "A rich new field\nOver the past few years, there has been an explosion of faster alternatives.\n\nParallel computing\nThe Python global interpreter lock (GIL) gets in the way of multi-threading, but several libraries allow the use of Python on multiple cores:\n\nRay\nDask\nApache Spark\n\nFugue provides a unified interface for distributed computing that works with all three libraries.\nTo use data frames on multiple cores, Dask and Spark have APIs for pandas and Modin provides a drop-in replacement for pandas in all three libraries.\n\n\nAccelerators\nRAPIDS brings data frames on the GPUs with the cuDF library and integration with pandas is easy.\n\n\nLazy out-of-core\nVaex exists as an alternative to pandas.\n\n\nSQL\nStructured query language (SQL) handles relational databases, but the distinction between SQL and data frame software is getting increasingly blurry with most libraries now able to handle both.\nDuckDB is a very fast and popular option with good integration with pandas.\nMany additional options such as dbt and the snowflake snowpark Python API exist, although integration with pandas is not always as good.\n\n\nPolars\nPolars uses Apache Arrow columnar memory format‚Äîthe new standard for efficiency.\nMost libraries are developing an integration with Polars, lodging it nicely in the Python ecosystem.",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "The world of data frames"
    ]
  },
  {
    "objectID": "python/polars_dataframes.html#best-data-frame-strategy",
    "href": "python/polars_dataframes.html#best-data-frame-strategy",
    "title": "The world of data frames",
    "section": "Best data frame strategy",
    "text": "Best data frame strategy\nFor maximum efficiency, the best strategy currently seems to be:\n\nSingle machine ‚ÄÉ ‚ûî ¬†use Polars.\nCluster ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇ ‚ûî ¬†use Polars + fugue (example benchmark, documentation of Polars integration).\nGPUs available ‚ÄÉ¬† ‚ûî ¬†use Polars + RAPIDS library cuDF (Polars integration coming soon).\nCluster with GPUs¬† ‚ûî ¬†use Polars + fugue + RAPIDS.\n\nNo matter the scenario, Polars is better than pandas and you should use it instead.",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "The world of data frames"
    ]
  },
  {
    "objectID": "python/nlp_normalization.html",
    "href": "python/nlp_normalization.html",
    "title": "Text normalization",
    "section": "",
    "text": "TextBlob allows to transform text‚Äîsomething very useful in preparation for text analysis.",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Text normalization"
    ]
  },
  {
    "objectID": "python/nlp_normalization.html#case",
    "href": "python/nlp_normalization.html#case",
    "title": "Text normalization",
    "section": "Case",
    "text": "Case\nThere are methods to change the case of TextBlob objects.\nFor example, capitalization (let‚Äôs only print the first 1000 characters)\n\nprint(text.title()[:1000])\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[2], line 1\n----&gt; 1 print(text.title()[:1000])\n\nNameError: name 'text' is not defined\n\n\n\nOr transformation to upper case:\n\nprint(text.upper()[:1000])\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 print(text.upper()[:1000])\n\nNameError: name 'text' is not defined",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Text normalization"
    ]
  },
  {
    "objectID": "python/nlp_normalization.html#number",
    "href": "python/nlp_normalization.html#number",
    "title": "Text normalization",
    "section": "Number",
    "text": "Number\nThe number (singular/plural) of particular words can also be changed:\n\nprint(text.words[6])\nprint(text.words[6].singularize())\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[4], line 1\n----&gt; 1 print(text.words[6])\n      2 print(text.words[6].singularize())\n\nNameError: name 'text' is not defined\n\n\n\n\nprint(text.words[42])\nprint(text.words[42].pluralize())\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[5], line 1\n----&gt; 1 print(text.words[42])\n      2 print(text.words[42].pluralize())\n\nNameError: name 'text' is not defined",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Text normalization"
    ]
  },
  {
    "objectID": "python/nlp_normalization.html#lemmatization",
    "href": "python/nlp_normalization.html#lemmatization",
    "title": "Text normalization",
    "section": "Lemmatization",
    "text": "Lemmatization\nLemmatization reduces all words to their lemma (dictionary or canonical form) so that inflected words such as ‚Äúdog‚Äù and ‚Äúdogs‚Äù aren‚Äôt counted in separate categories in analyses.\n\nNouns\nThe lemmatize method uses as its default argument \"n\" (for noun):\n\nprint(TextBlob(\"heirs\").words[0].lemmatize())\nprint(TextBlob(\"daggers\").words[0].lemmatize())\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[6], line 1\n----&gt; 1 print(TextBlob(\"heirs\").words[0].lemmatize())\n      2 print(TextBlob(\"daggers\").words[0].lemmatize())\n\nNameError: name 'TextBlob' is not defined\n\n\n\n\nBe careful: you can‚Äôt always trust that TextBlob will work properly. It is a library very easy to use, but it has its limitations.\nFor instance, I am not sure why this one doesn‚Äôt work:\n\nprint(TextBlob(\"men\").words[0].lemmatize())\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[7], line 1\n----&gt; 1 print(TextBlob(\"men\").words[0].lemmatize())\n\nNameError: name 'TextBlob' is not defined\n\n\n\nWhile this totally works:\n\nprint(TextBlob(\"policemen\").words[0].lemmatize())\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[8], line 1\n----&gt; 1 print(TextBlob(\"policemen\").words[0].lemmatize())\n\nNameError: name 'TextBlob' is not defined\n\n\n\nUsing the more complex and more powerful NLTK Python library, you can implement the solution suggested here.\n\n\n\nVerbs\nTo lemmatize verbs, you need to pass \"v\" (for verbs) to the lemmatize method:\n\nprint(TextBlob(\"seen\").words[0].lemmatize(\"v\"))\nprint(TextBlob(\"seeing\").words[0].lemmatize(\"v\"))\nprint(TextBlob(\"sees\").words[0].lemmatize(\"v\"))\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[9], line 1\n----&gt; 1 print(TextBlob(\"seen\").words[0].lemmatize(\"v\"))\n      2 print(TextBlob(\"seeing\").words[0].lemmatize(\"v\"))\n      3 print(TextBlob(\"sees\").words[0].lemmatize(\"v\"))\n\nNameError: name 'TextBlob' is not defined\n\n\n\n\n\nYour turn:\n\nWhy is this one not working?\n\nprint(TextBlob(\"saw\").words[0].lemmatize(\"v\"))\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[10], line 1\n----&gt; 1 print(TextBlob(\"saw\").words[0].lemmatize(\"v\"))\n\nNameError: name 'TextBlob' is not defined\n\n\n\n\nExamples from the text:\n\nprint(TextBlob(\"starring\").words[0].lemmatize(\"v\"))\nprint(TextBlob(\"stabbed\").words[0].lemmatize(\"v\"))\nprint(TextBlob(\"howled\").words[0].lemmatize(\"v\"))\nprint(TextBlob(\"rejoicing\").words[0].lemmatize(\"v\"))\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[11], line 1\n----&gt; 1 print(TextBlob(\"starring\").words[0].lemmatize(\"v\"))\n      2 print(TextBlob(\"stabbed\").words[0].lemmatize(\"v\"))\n      3 print(TextBlob(\"howled\").words[0].lemmatize(\"v\"))\n\nNameError: name 'TextBlob' is not defined\n\n\n\n\n\nAdjectives\nTo lemmatize adjectives, you need to pass \"a\" (for adjectives) to the lemmatize method:\n\nprint(TextBlob(\"youngest\").words[0].lemmatize(\"a\"))\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[12], line 1\n----&gt; 1 print(TextBlob(\"youngest\").words[0].lemmatize(\"a\"))\n\nNameError: name 'TextBlob' is not defined",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Text normalization"
    ]
  },
  {
    "objectID": "python/nlp_normalization.html#correction",
    "href": "python/nlp_normalization.html#correction",
    "title": "Text normalization",
    "section": "Correction",
    "text": "Correction\nThe correct method attempts to correct spelling mistakes:\n\nprint(TextBlob(\"Somethingg with speling mystakes\").correct())\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[13], line 1\n----&gt; 1 print(TextBlob(\"Somethingg with speling mystakes\").correct())\n\nNameError: name 'TextBlob' is not defined\n\n\n\n\nThere are however limitations since the method is based on a lexicon and isn‚Äôt aware of the relationship between words (and thus cannot correct grammatical errors):\n\nprint(TextBlob(\"Some thingg with speling mystake\").correct())\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[14], line 1\n----&gt; 1 print(TextBlob(\"Some thingg with speling mystake\").correct())\n\nNameError: name 'TextBlob' is not defined\n\n\n\nAn example even more obvious:\n\nprint(TextBlob(\"He drink\").correct())\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[15], line 1\n----&gt; 1 print(TextBlob(\"He drink\").correct())\n\nNameError: name 'TextBlob' is not defined",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Text normalization"
    ]
  },
  {
    "objectID": "python/nlp_data.html",
    "href": "python/nlp_data.html",
    "title": "Getting the data",
    "section": "",
    "text": "In this section, we will import the pdf of a book from an online URL into Python.",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Getting the data"
    ]
  },
  {
    "objectID": "python/nlp_data.html#the-text",
    "href": "python/nlp_data.html#the-text",
    "title": "Getting the data",
    "section": "The text",
    "text": "The text\n\n\n\nWyrd Sisters, the sixth Discworld novel by Terry Pratchett published in 1988, has countless references to Macbeth (including, obviously, the title), other Shakespeare‚Äôs plays, the Marx Brothers, Charlie Chaplin, and Laurel and Hardy.  The book is available as a pdf at this URL and this is the text we will use for this course.\n\n\n¬†\n\n\n\n\n\nArt by Josh Kirby used for the cover of Wyrd Sisters",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Getting the data"
    ]
  },
  {
    "objectID": "python/nlp_data.html#packages-needed",
    "href": "python/nlp_data.html#packages-needed",
    "title": "Getting the data",
    "section": "Packages needed",
    "text": "Packages needed\nFirst off, we need to load two of the packages that you installed in the previous section:\n\nRequests: this package sends requests to websites to download information. We will use it to download the pdf.\nPyMuPDF: this package will allow us to extract the content from the pdf.\n\nLet‚Äôs load the packages into our session to make them available:\n\nimport requests\nimport pymupdf\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[1], line 2\n      1 import requests\n----&gt; 2 import pymupdf\n\nModuleNotFoundError: No module named 'pymupdf'",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Getting the data"
    ]
  },
  {
    "objectID": "python/nlp_data.html#download-the-data",
    "href": "python/nlp_data.html#download-the-data",
    "title": "Getting the data",
    "section": "Download the data",
    "text": "Download the data\nFirst, let‚Äôs create a string with the URL of the online pdf:\n\nurl = \"https://funnyengwish.wordpress.com/wp-content/uploads/2017/05/pratchett_terry_wyrd_sisters_-_royallib_ru.pdf\"\n\nNow we can send a request to that URL to download the data and create a response object:\n\nresponse = requests.get(url)\n\nLet‚Äôs print the value of our response to ensure that it was successful:\n\nprint(response)\n\n&lt;Response [200]&gt;\n\n\n\nOn the list of HTTP status codes, you can see that 200 means OK. So our request was successful.\n\nThen we extract the text from the pdf:\n\ndata = response.content\ndoc = pymupdf.Document(stream=data)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[5], line 2\n      1 data = response.content\n----&gt; 2 doc = pymupdf.Document(stream=data)\n\nNameError: name 'pymupdf' is not defined\n\n\n\nLet‚Äôs explore this doc object that we created.\nIt is a Document object from the pymupdf package:\n\ntype(doc)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[6], line 1\n----&gt; 1 type(doc)\n\nNameError: name 'doc' is not defined\n\n\n\nThe first element corresponds to the first page of the pdf:\n\ndoc[0]\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[7], line 1\n----&gt; 1 doc[0]\n\nNameError: name 'doc' is not defined\n\n\n\n\nRemember that indexing in Python starts at 0.\n\n\ntype(doc[0])\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[8], line 1\n----&gt; 1 type(doc[0])\n\nNameError: name 'doc' is not defined\n\n\n\nThe pdf had 139 pages:\n\nlen(doc)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[9], line 1\n----&gt; 1 len(doc)\n\nNameError: name 'doc' is not defined\n\n\n\nWe can get the text of the first page with the get_text method. Let‚Äôs create an string that we call page1 with this text:\n\npage1 = doc[0].get_text()\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[10], line 1\n----&gt; 1 page1 = doc[0].get_text()\n\nNameError: name 'doc' is not defined\n\n\n\nWe can now print the text of the first page of the pdf:\n\nprint(page1)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[11], line 1\n----&gt; 1 print(page1)\n\nNameError: name 'page1' is not defined",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Getting the data"
    ]
  },
  {
    "objectID": "python/llm_why.html",
    "href": "python/llm_why.html",
    "title": "LLMs and coding",
    "section": "",
    "text": "For the past few years, large language models have been everywhere, but not everyone has the same level of knowledge and experience with them. So let‚Äôs start from the basics. If you have stayed clear of the topic, whether due to ethical concerns, personal reasons, or lack of interest, this section aims to catch you up.",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "LLMs and coding"
    ]
  },
  {
    "objectID": "python/llm_why.html#what-are-llms",
    "href": "python/llm_why.html#what-are-llms",
    "title": "LLMs and coding",
    "section": "What are LLMs?",
    "text": "What are LLMs?\nLarge language models (LLMs) are a type of generative deep learning models based on natural language processing (NLP) and capable of generating human and programming languages.\nThey do so by predicting the most likely token (word or code element) in the sequence. They are, at heart, probabilistic. This means that the same question asked several times to the same model will lead to slightly different answers. This is in contrast to classic computer programs which are deterministic (the same code run several times under the same conditions leads to the same results).\nModified versions of LLMs are capable of generating images, videos, and sounds.",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "LLMs and coding"
    ]
  },
  {
    "objectID": "python/llm_why.html#llms-and-ethics",
    "href": "python/llm_why.html#llms-and-ethics",
    "title": "LLMs and coding",
    "section": "LLMs and ethics",
    "text": "LLMs and ethics\nThere are numerous ethical concerns around the topic of AI:\n\nA lot of the data used to train large language models was obtained via copyright infringement.\nTraining and using models requires a lot of electricity and the construction of large data centres which produce a lot of heat, so AI comes with a high environmental cost.\nData centres are sometimes built in developing countries, putting a burden on their infrastructures and thus the local populations.\nThere are many justified concerns that AI will put a lot of people out of work and disrupt societies.\nTraining some types of models requires huge amounts of processed data (e.g.¬†labelled data: pictures associated with labels describing what is in them). The labelling is done by people in developing countries that are underpaid.\nAI is so transformative that a new arms race has started between the US and China.\nSome AI can be used to automate drones and killing devices.\nSome people worry that at some point in the future extremely intelligent AI might put humanity at risk through lack of alignment.\nAI is already used for spamming, scams, disinformation, and deepfakes abuse. There are concerns that they could be used in the future for terrorism.\nModels (when not open-source) are owned by private companies and this raises questions about concentration of power.\nLLMs hallucinate, make mistakes, and can be biased.\nLLM-based ‚Äúfriends‚Äù or ‚Äúromantic partners‚Äù can have all sorts of psychological impacts on people, particularly young ones.\n\nThat said, these models are extremely useful for research and refusal by some people to use them could cause them to fall behind in an unfair competition.\nWhatever one thinks about AI and its problems, I personally think that it is important to be as educated as possible about the problems and solutions they offer and to know how to use them.",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "LLMs and coding"
    ]
  },
  {
    "objectID": "python/llm_why.html#llms-and-code",
    "href": "python/llm_why.html#llms-and-code",
    "title": "LLMs and coding",
    "section": "LLMs and code",
    "text": "LLMs and code\nWhile LLMs are capable of producing human language, they are particularly good at writing code.\nFor people with no coding background and who could greatly benefit from coding for their research, LLMs are particularly useful which is why I decided to bring them to this course for the first time this year.\nIn previous years, people attending the introduction to Python course at DHSI encountered several types of problems and frustrations:\n\nIt is impossible to learn enough Python in a week to be able to use it for research: reaching a level of competency that can be useful takes months.\nProgramming is unforgiving in that any slight typo or syntax error in the code will break it. People in previous years would get frustrated by code that was not working due to a suite of small mistakes. The nitty-gritty of fixing syntax would take away the joy of writing code.\n\nLLMs solve all this. Once you know a little bit of Python and once you know how to use these models, you become able to actually produce code that can be useful for your research.",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "LLMs and coding"
    ]
  },
  {
    "objectID": "python/llm_why.html#which-llm-to-chose",
    "href": "python/llm_why.html#which-llm-to-chose",
    "title": "LLMs and coding",
    "section": "Which LLM to chose?",
    "text": "Which LLM to chose?\nThis is a purely personal decision. Moreover, the field is fast evolving.\nWith most companies, you will have to create an account or doing so will give you access to more features. Some services are free, others require a subscription. Some universities might have subscriptions with some companies so you might want to check whether your institution does. Some services (e.g.¬†GitHub Copilot) are free for instructors.\nUsually, what you get for free involves some of the following (but it is company dependent and can change over time):\n\nolder and less powerful models,\nlimited number of queries per month, week, or day,\nlimited functionality (e.g.¬†you might only be able to upload a few documents for the model to process),\nyour queries might be used by the companies to train their next models.\n\nWhile subscriptions tend to provide some of the following:\n\nlatest models which perform better since things are evolving fast,\nunlimited usage,\nfull functionality (e.g.¬†being able to upload unlimited numbers of documents that the model can use to better help you),\nno usage of your queries.\n\nDifferent models have different styles and some perform better than others in some contexts, but the competition is tight. Some models have open-source weights (e.g.¬†LLaMA and DeepSeek) while most are for the moment closed-source. Open-source weights mean that anybody can take those trained weights and use them to build their own model.\nAs of 2025, popular options include various versions of the following models (in random order and non-exhaustively):\n\nle Chat by Mistral AI,\nGemini by Google DeepMind,\nChatGPT by OpenAI,\nClaude by Anthropic,\nDeepSeek by DeepSeek,\nLLaMA by Meta.\n\nCompanies such as Perplexity AI also provide search engines that can use a multitude of the above models under the hood to answer your queries.",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "LLMs and coding"
    ]
  },
  {
    "objectID": "python/llm_why.html#how-to-use-an-llm-for-coding",
    "href": "python/llm_why.html#how-to-use-an-llm-for-coding",
    "title": "LLMs and coding",
    "section": "How to use an LLM for coding?",
    "text": "How to use an LLM for coding?\nLLMs can be used for a variety of tasks. In particular, they can:\n\nauto-complete code,\nexplain programming concepts,\nexplain code,\nwrite code,\ndebug code,\nwrite software tests,\nwrite entire programs, websites, and applications (vibe coding).\n\nIn this course, we will use LLMs to write and understand Python code.",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "LLMs and coding"
    ]
  },
  {
    "objectID": "python/llm_webscraping.html",
    "href": "python/llm_webscraping.html",
    "title": "Webscraping with an LLM",
    "section": "",
    "text": "The internet is a trove of information. A lot of it is publicly available and thus suitable for use in research. Extracting that information and putting it in an organized format for analysis can however be extremely tedious.\nSome websites have an API that makes it easy to extract information. These are websites that were built with the intention of being scraped (e.g.¬†sites that contain databases, museums, art collections, etc.). When this is the case, this is definitely the way to go. Most websites however do not contain an API that can be queried.\nWeb scraping tools allow to automate parts of that process and Python is a popular language for the task.\nOf note, an increasing number of websites use JavaScript to add cookies, interactivity, etc. to websites. This makes them a lot harder to scrape and require more sophisticated tools.\nIn this section, we will scrape a simple site that does not contain any JavaScript using the package Beautiful Soup.\nWe will use an LLM to help us in this process.",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "Webscraping with an LLM"
    ]
  },
  {
    "objectID": "python/llm_webscraping.html#background-information",
    "href": "python/llm_webscraping.html#background-information",
    "title": "Webscraping with an LLM",
    "section": "Background information",
    "text": "Background information\n\nHTML and CSS\nHyperText Markup Language (HTML) is the standard markup language for websites: it encodes the information related to the formatting and structure of webpages. Additionally, some of the customization can be stored in Cascading Style Sheets (CSS) files.\nHTML uses tags of the form:\n&lt;some_tag&gt;Your content&lt;/some_tag&gt;\nSome tags have attributes:\n&lt;some_tag attribute_name=\"attribute value\"&gt;Your content&lt;/some_tag&gt;\n\nExamples:\n\nSite structure:\n\n&lt;h2&gt;This is a heading of level 2&lt;/h2&gt;\n&lt;p&gt;This is a paragraph&lt;/p&gt;\n\nFormatting:\n\n&lt;b&gt;This is bold&lt;/b&gt;\n&lt;a href=\"https://some.url\"&gt;This is the text for a link&lt;/a&gt;\n\n\n\nWeb scrapping\nWeb scraping is a general term for a set of tools which allow for the extraction of data from the web automatically.\nWhile most of the data on the internet is publicly available, it is illegal to scrape some sites and you should always look into the policy of a site before attempting to scrape it. Some sites will also block you if you submit too many requests in a short amount of time, so remember to scrape responsibly.",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "Webscraping with an LLM"
    ]
  },
  {
    "objectID": "python/llm_webscraping.html#webscraping-example",
    "href": "python/llm_webscraping.html#webscraping-example",
    "title": "Webscraping with an LLM",
    "section": "Webscraping example",
    "text": "Webscraping example\nWe will use a website from the University of Tennessee containing a database of PhD theses from that university which uses the Digital Commons Network.\nOur goal is to scrape data from this site to produce a dataframe with the date, major, and advisor for each dissertation. Scraping any other site which uses the Digital Commons Network can be done following a similar workflow.\n\nSite exploration\nFirst of all, let‚Äôs have a close look at the website we want to scrape to think carefully about what we want to do. Before starting to write code, it is always a good idea to think about what you are trying to achieve with your code.\nTo see how the website is built, you can open the web inspector. Most browsers allow to right-click on an element and select ‚Äúinspect‚Äù in the menu. Alternatively, Chrome opens the web inspector with F12 and Firefox and Edge with Ctrl+Shift+I (Windows, Linux) or Command+Option+I (macOS).\nTo create a dataframe with the data for all the dissertations on the first page, we need to do two things:\n\nStep 1: from the dissertations database first page, we want to scrape the list of URLs for the dissertation pages.\nStep 2: once we have the URLs, we want to scrape those pages too to get the date, major, and advisor for each dissertation.\n\n\nNote that we are only scraping the first page (with the 100 most recent theses) to keep things simple. If you wanted to get all the data from the site, you would have to create a loop and repeat this over all 117 pages of the site.\n\n\n\nLLM code\nLet‚Äôs use an LLM to get us started.\nHere is the prompt I used:\n\nWrite Python code to scrape the following website: https://trace.tennessee.edu/utk_graddiss/index.html.\nAs the end result, I want to have a polars dataframe with the following columns:\n\nDate\nMajor of the thesis\nAdvisor (PI)\n\n\n\nimport requests\nfrom bs4 import BeautifulSoup\nimport polars as pl\nfrom urllib.parse import urljoin\n\nbase_url = \"https://trace.tennessee.edu/utk_graddiss/index.html\"\n\ndef get_dissertation_data():\n    # Get main page and extract dissertation URLs\n    main_page = requests.get(base_url)\n    soup = BeautifulSoup(main_page.content, \"html.parser\")\n\n    # Extract individual dissertation links\n    links = [urljoin(base_url, a[\"href\"])\n             for a in soup.select(\".article-listing a\")]\n\n    data = []\n\n    for link in links[:10]:  # Reduced to 10 for testing; remove slice for full 100\n        try:\n            # Get individual dissertation page\n            page = requests.get(link)\n            page_soup = BeautifulSoup(page.content, \"html.parser\")\n\n            # Extract required fields\n            date = page_soup.select_one(\"#publication_date p\").text.strip()\n            major = page_soup.select_one(\"#department p\").text.strip()\n            advisor = page_soup.select_one(\"#advisor1 p\").text.strip()\n\n            data.append({\n                \"Date\": date,\n                \"Major\": major,\n                \"Advisor\": advisor\n            })\n\n        except Exception as e:\n            print(f\"Error processing {link}: {str(e)}\")\n\n    return pl.DataFrame(data)\n\n# Usage\ndf = get_dissertation_data()\nprint(df)\n\nshape: (10, 3)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Date    ‚îÜ Major                           ‚îÜ Advisor                ‚îÇ\n‚îÇ ---     ‚îÜ ---                             ‚îÜ ---                    ‚îÇ\n‚îÇ str     ‚îÜ str                             ‚îÜ str                    ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 8-2024  ‚îÜ History                         ‚îÜ Jay Rubenstein         ‚îÇ\n‚îÇ 12-2024 ‚îÜ Biochemistry and Cellular and ‚Ä¶ ‚îÜ Dr. Rebecca A. Prosser ‚îÇ\n‚îÇ 5-2024  ‚îÜ Business Administration         ‚îÜ Larry A. Fauver        ‚îÇ\n‚îÇ 8-2024  ‚îÜ Electrical Engineering          ‚îÜ Dan Wilson             ‚îÇ\n‚îÇ 12-2024 ‚îÜ Mechanical Engineering          ‚îÜ Prashant Singh         ‚îÇ\n‚îÇ 5-2024  ‚îÜ Chemical Engineering            ‚îÜ Steven M. Abel         ‚îÇ\n‚îÇ 12-2024 ‚îÜ Industrial Engineering          ‚îÜ Anahita Khojandi       ‚îÇ\n‚îÇ 12-2024 ‚îÜ Education                       ‚îÜ Clara Lee Brown        ‚îÇ\n‚îÇ 8-2024  ‚îÜ Geography                       ‚îÜ Sally P Horn           ‚îÇ\n‚îÇ 12-2024 ‚îÜ Education                       ‚îÜ Enlida J Romero-Hall   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\nThe package Beautiful Soup‚Äîloaded in Python as bs4‚Äîtransforms (parses) HTML data into a parse tree, which makes extracting information easier.\n\n\n\nYour turn:\n\n\nDid it work? Go to the site and verify the data.\nWhat is the problem? Can you fix it?\n\n\n\n\nCode improvements\nLLMs can be very helpful in getting you started, but you will often have to tweak the code to improve it‚Äîeven when it works.\nWe now have code that works, but its downside is that we created a function that can only work on one webpage‚Ä¶ so it is of limited use. If, for instance, we wanted to apply that function to the second page of the site (https://trace.tennessee.edu/utk_graddiss/index.2.html), we can‚Äôt because it doesn‚Äôt accept any argument. The URL of the site is inside the function. This is called hard coding and it isn‚Äôt a good coding practice.\nA better approach would be to create a function accepting the URL of the page we want to scrape as argument. It is actually really easy to modify the code to get this:\n\ndef get_dissertation_data(base_url):\n    # Get main page and extract dissertation URLs\n    main_page = requests.get(base_url)\n    soup = BeautifulSoup(main_page.content, \"html.parser\")\n\n    # Extract individual dissertation links\n    links = [urljoin(base_url, a[\"href\"])\n             for a in soup.select(\".article-listing a\")]\n\n    data = []\n\n    for link in links:\n        try:\n            # Get individual dissertation page\n            page = requests.get(link)\n            page_soup = BeautifulSoup(page.content, \"html.parser\")\n\n            # Extract required fields\n            date = page_soup.select_one(\"#publication_date p\").text.strip()\n            major = page_soup.select_one(\"#department p\").text.strip()\n            advisor = page_soup.select_one(\"#advisor1 p\").text.strip()\n\n            data.append({\n                \"Date\": date,\n                \"Major\": major,\n                \"Advisor\": advisor\n            })\n\n        except Exception as e:\n            print(f\"Error processing {link}: {str(e)}\")\n\n    return pl.DataFrame(data)\n\nNow, if we want to use the function on that first page, we need to pass the URL as an argument:\n\ndf = get_dissertation_data(base_url)\n\nYou can verify that the code still works:\n\nprint(df)\n\nshape: (100, 3)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Date    ‚îÜ Major                           ‚îÜ Advisor                ‚îÇ\n‚îÇ ---     ‚îÜ ---                             ‚îÜ ---                    ‚îÇ\n‚îÇ str     ‚îÜ str                             ‚îÜ str                    ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 8-2024  ‚îÜ History                         ‚îÜ Jay Rubenstein         ‚îÇ\n‚îÇ 12-2024 ‚îÜ Biochemistry and Cellular and ‚Ä¶ ‚îÜ Dr. Rebecca A. Prosser ‚îÇ\n‚îÇ 5-2024  ‚îÜ Business Administration         ‚îÜ Larry A. Fauver        ‚îÇ\n‚îÇ 8-2024  ‚îÜ Electrical Engineering          ‚îÜ Dan Wilson             ‚îÇ\n‚îÇ 12-2024 ‚îÜ Mechanical Engineering          ‚îÜ Prashant Singh         ‚îÇ\n‚îÇ ‚Ä¶       ‚îÜ ‚Ä¶                               ‚îÜ ‚Ä¶                      ‚îÇ\n‚îÇ 5-2024  ‚îÜ Mechanical Engineering          ‚îÜ Feng-Yuan Zhang        ‚îÇ\n‚îÇ 8-2024  ‚îÜ Computer Science                ‚îÜ Scott Ruoti            ‚îÇ\n‚îÇ 8-2024  ‚îÜ Mechanical Engineering          ‚îÜ Tony L. Schmitz        ‚îÇ\n‚îÇ 8-2024  ‚îÜ Microbiology                    ‚îÜ Shigetoshi Eda         ‚îÇ\n‚îÇ 8-2024  ‚îÜ Energy Science and Engineering  ‚îÜ David C. Donovan       ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\nThe code looks very similar, but it now allows us to scrape the data from any page of the website.\n\n\nYour turn:\n\nScrape the data from the sixth page (https://trace.tennessee.edu/utk_graddiss/index.6.html).\n\nAnother improvement that we can make to the code is to add a little delay between requests because some sites will block requests if they are too frequent.\nFor this we need to load the time module:\n\nimport time\n\nThen add time.sleep(0.1) in the loop:\ndef get_dissertation_data(base_url):\n    # Get main page and extract dissertation URLs\n    main_page = requests.get(base_url)\n    soup = BeautifulSoup(main_page.content, \"html.parser\")\n\n    # Extract individual dissertation links\n    links = [urljoin(base_url, a[\"href\"])\n             for a in soup.select(\".article-listing a\")]\n\n    data = []\n\n    for link in links:\n        try:\n            # Get individual dissertation page\n            page = requests.get(link)\n            page_soup = BeautifulSoup(page.content, \"html.parser\")\n\n            # Extract required fields\n            date = page_soup.select_one(\"#publication_date p\").text.strip()\n            major = page_soup.select_one(\"#department p\").text.strip()\n            advisor = page_soup.select_one(\"#advisor1 p\").text.strip()\n\n            data.append({\n                \"Date\": date,\n                \"Major\": major,\n                \"Advisor\": advisor\n\n            # Add 0.1 s between each request to the site\n            time.sleep(0.1)\n            })\n\n        except Exception as e:\n            print(f\"Error processing {link}: {str(e)}\")\n\n    return pl.DataFrame(data)\n\n\nSave data to file\nIf you want to export the data and save it to a CSV file, you can do this:\ndf.write_csv(\"dissertations_data.csv\")",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "Webscraping with an LLM"
    ]
  },
  {
    "objectID": "python/llm_first_dab.html",
    "href": "python/llm_first_dab.html",
    "title": "First dab at playing with an LLM",
    "section": "",
    "text": "In this section, we will download a text from a URL and get some info on it.",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "First dab at playing with an LLM"
    ]
  },
  {
    "objectID": "python/llm_first_dab.html#open-a-chat",
    "href": "python/llm_first_dab.html#open-a-chat",
    "title": "First dab at playing with an LLM",
    "section": "Open a chat",
    "text": "Open a chat\nOpen an LLM chat interface. If you are familiar with a particular LLM, feel free to use that one. If you have never used an LLM before, you can pick one in the non-exhaustive list I gave in the previous section.\nSome interfaces have options worth looking into. Le Chat from Mistral for instance will not search the web automatically. This means that it will give answers based only on the data used to train the model. This works well in many situations, but it does not work when searching for events that happened after the data to train the model was harvested from the internet. To ask Python questions, not using the web search option is usually fine, but if you are looking for information on a new library or on a library that recently got updated, the answers you will get will be out of date.\nIt would be great if you could sit next to someone using a different model so that you could compare the outputs given by both models to similar prompts. Compare the results and talk with each other. Experiment and play with these tools to see how they work and how you can make them as useful to you as possible.",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "First dab at playing with an LLM"
    ]
  },
  {
    "objectID": "python/llm_first_dab.html#open-a-notebook",
    "href": "python/llm_first_dab.html#open-a-notebook",
    "title": "First dab at playing with an LLM",
    "section": "Open a notebook",
    "text": "Open a notebook\nOpen a new notebook in JupyterLab.\nWhen the LLM gives us some code, we will copy paste it in the notebook to run it.",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "First dab at playing with an LLM"
    ]
  },
  {
    "objectID": "python/llm_first_dab.html#llm-as-instructor",
    "href": "python/llm_first_dab.html#llm-as-instructor",
    "title": "First dab at playing with an LLM",
    "section": "LLM as instructor",
    "text": "LLM as instructor\nLLMs are great at teaching programming concepts. For instance, you learnt about loops this morning. Let‚Äôs ask our LLM to explain Python loops.\nHere is the question I asked the LLM:\n\nExplain to me how to write Python loops.\n\n\n\nYour turn:\n\nAsk questions about variables, data types, dictionaries, and other things you learnt this morning. In particular, ask questions about things you didn‚Äôt fully understand.\n\nNow, let‚Äôs learn something that wasn‚Äôt covered this morning: writing Python functions.\n\n\nYour turn:\n\n\nAsk the LLM what Python functions are.\nAsk how to write them.\nAsk the model to write a Python function that would give you the time.",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "First dab at playing with an LLM"
    ]
  },
  {
    "objectID": "python/llm_first_dab.html#llm-as-coder",
    "href": "python/llm_first_dab.html#llm-as-coder",
    "title": "First dab at playing with an LLM",
    "section": "LLM as coder",
    "text": "LLM as coder\n\nDownload a text file from a URL\nThe snippet of text we will play with is in a text file I created containing the very beginning of the novel Going Postal by Terry Pratchett. I made it available at the URL https://mint.westdri.ca/python/data/pratchett.txt.\nLet‚Äôs ask our LLM how to do this. Here is the prompt I use (feel free to write your own prompt):\n\nHow can I download the text from this url: https://mint.westdri.ca/python/data/pratchett.txt in Python?\n\nOn my end, I got some nice explanations and the following code:\n\nimport requests\n\nurl = \"https://mint.westdri.ca/python/data/pratchett.txt\"\nresponse = requests.get(url)\ntext = response.text  # This contains the text content as a string\n\nprint(text)  # Prints the downloaded text\n\nThey say that the prospect of being hanged in the morning concentrates a man's mind wonderfully; unfortunately, what the mind inevitably concentrates on is that, in the morning, it will be in a body that is going to be hanged.\nThe man going to be hanged had been named Moist von Lipwig by doting if unwise parents, but he was not going to embarrass the name, insofar as that was still possible, by being hung under it. To the world in general, and particularly on that bit of it known as the death warrant, he was Alfred Spangler.\nAnd he took a more positive approach to the situation and had concentrated his mind on the prospect of not being hanged in the morning, and, most particularly, on the prospect of removing all the crumbling mortar from around a stone in his cell wall with a spoon. So far the work had taken him five weeks and reduced the spoon to something like a nail file. Fortunately, no one ever came to change the bedding here, or else they would have discovered the world's heaviest mattress.\nIt was a large and heavy stone that was currently the object of his attentions, and, at some point, a huge staple had been hammered into it as an anchor for manacles.\nMoist sat down facing the wall, gripped the iron ring in both hands, braced his legs against the stones on either side, and heaved.\nHis shoulders caught fire, and a red mist filled his vision, but the block slid out with a faint and inappropriate tinkling noise. Moist managed to ease it away from the hole and peered inside.\nAt the far end was another block, and the mortar around it looked suspiciously strong and fresh.\nJust in front of it was a new spoon. It was shiny.\nAs he studied it, he heard the clapping behind him. He turned his head, tendons twanging a little riff of agony, and saw several of the wardens watching him through the bars.\n\"Well done, Mr. Spangler!\" said one of them. \"Ron here owes me five dollars! I told him you were a sticker!! 'He's a sticker,' I said!\"\n\"You set this up, did you, Mr. Wilkinson?\" said Moist weakly, watching the glint of light on the spoon.\n\"Oh, not us, sir. Lord Vetinari's orders. He insists that all condemned prisoners should be offered the prospect of freedom.\"\n\"Freedom? But there's a damn great stone through there!\"\n\"Yes, there is that, sir, yes, there is that,\" said the warden. \"It's only the prospect, you see. Not actual free freedom as such. Hah, that'd be a bit daft, eh?\"\n\"I suppose so, yes,\" said Moist. He didn't say \"you bastards.\" The wardens had treated him quite civilly these past six weeks, and he made a point of getting on with people. He was very, very good at it. People skills were part of his stock-in-trade; they were nearly the whole of it.\nBesides, these people had big sticks. So, speaking carefully, he added: \"Some people might consider this cruel, Mr. Wilkinson.\"\n\"Yes, sir, we asked him about that, sir, but he said no, it wasn't. He said it provided\"--his forehead wrinkled \"--occ-you-pay-shun-all ther-rap-py, healthy exercise, prevented moping, and offered that greatest of all treasures, which is Hope, sir.\"\n\"Hope,\" muttered Moist glumly.\n\"Not upset, are you, sir?\"\n\"Upset? Why should I be upset, Mr. Wilkinson?\"\n\"Only the last bloke we had in this cell, he managed to get down that drain, sir. Very small man. Very agile.\"\n\n\n\n\nNote that the comments in the code are not mine but from the LLM, which is nice.\n\nIt looks like the code works.\n\n\nCount a few things\nNow, let‚Äôs count the number of words in the text.\nI asked the follow-up question (here again, you can phrase the question however you want. It is good to experiment):\n\nWrite Python code to count the number of words in this text.\n\nHere again, I got some explanations and the following code:\n\n# Split the text into words using whitespace\nwords = text.split()\nword_count = len(words)\n\nprint(f\"Number of words in the text: {word_count}\")\n\nNumber of words in the text: 590\n\n\n\nWrite Python code to find the number of times the word ‚Äúthe‚Äù occurs in the text.\n\nHere, the LLM warned me that the following answer counts all instances of ‚Äúthe‚Äù (ignoring case) and that if this was not what I wanted, I just had to say so in a follow-up chat entry. This is what I wanted, so I am keeping the code as is:\n\nimport re\n\n# Use regular expressions to find all whole-word, case-insensitive matches of \"the\"\nthe_count = len(re.findall(r'\\bthe\\b', text, flags=re.IGNORECASE))\n\nprint(f'The word \"the\" occurs {the_count} times in the text.')\n\nThe word \"the\" occurs 36 times in the text.\n\n\n\n\nYour turn:\n\n\nAsk your LLM to explain the regular expression in the code.\nWe all know that LLMs hallucinate and make plenty of mistakes. You should never trust the code (or any LLM answer for that matter) uncritically. How could you double-check that this code is correct?\n\n\n\n\n\n\nExtracting quotes\nNow, let‚Äôs extract all quotes from the text.\nMy prompt:\n\nWrite Python code that would extract all the quotes from the text\n\nHere is the code I got in the answer:\n\n# Extract all quotes enclosed in double quotes\nquotes = re.findall(r'\"(.*?)\"', text)\n\n# Example: print the first 10 quotes\nfor quote in quotes[:10]:\n    print(quote)\n\nWell done, Mr. Spangler!\nRon here owes me five dollars! I told him you were a sticker!! 'He's a sticker,' I said!\nYou set this up, did you, Mr. Wilkinson?\nOh, not us, sir. Lord Vetinari's orders. He insists that all condemned prisoners should be offered the prospect of freedom.\nFreedom? But there's a damn great stone through there!\nYes, there is that, sir, yes, there is that,\nIt's only the prospect, you see. Not actual free freedom as such. Hah, that'd be a bit daft, eh?\nI suppose so, yes,\nyou bastards.\nSome people might consider this cruel, Mr. Wilkinson.\n\n\n\n\nYour turn:\n\n\nThis looks good, but what if we want all the quotes from the text?\nWhat does quotes[:10] mean?\nWhat kind of structure is this:\n\nfor quote in quotes[:10]:\n    print(quote)\n\nHow do such structures work?",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "First dab at playing with an LLM"
    ]
  },
  {
    "objectID": "python/llm_first_dab.html#llm-as-debugger",
    "href": "python/llm_first_dab.html#llm-as-debugger",
    "title": "First dab at playing with an LLM",
    "section": "LLM as debugger",
    "text": "LLM as debugger\nHere is a Python code snippet:\n\nimport string\n\nclean_text = text.translate(str.maketrans(string.punctuation))\nprint(clean_text)\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[5], line 3\n      1 import string\n----&gt; 3 clean_text = text.translate(str.maketrans(string.punctuation))\n      4 print(clean_text)\n\nTypeError: if you give only one argument to maketrans it must be a dict\n\n\n\nIt doesn‚Äôt work üôÅ\n\n\nYour turn:\n\n\nWhat is wrong with it?\nWhat would be the proper syntax?\nWhat does that code do?",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "First dab at playing with an LLM"
    ]
  },
  {
    "objectID": "python/intro_run.html",
    "href": "python/intro_run.html",
    "title": "Running Python",
    "section": "",
    "text": "This section covers some of the many ways to run Python either on your machine or on the Alliance clusters.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Running Python"
    ]
  },
  {
    "objectID": "python/intro_run.html#on-your-machine",
    "href": "python/intro_run.html#on-your-machine",
    "title": "Running Python",
    "section": "On your machine",
    "text": "On your machine\n\nNon-interactive Python\nYou can write your Python code in a text file with a .py extension and run the script in your terminal with:\npython &lt;script-name&gt;.py\n\n\nInteractive Python\nOne key reason why Python is so popular is that it is an interpreted language: you can use it in an interactive session that makes prototyping code very friendly.\nOne way to do this is to use a shell.\n\nShells\n\nPython shell\nThe simplest (and driest) way to run Python interactively is to use the Python shell. If you launch Python by double-clicking on the Python executable or running the command python in a terminal, you end up in the Python shell with its typical &gt;&gt;&gt; prompt.\nAlthough the Python shell finally saw minor improvements with the release of Python 3.13, this shell is still extremely primitive:\n\nno syntax highlighting,\nno multiline editing,\naustere autocompletion.\n\nFor this reason, a number of shells have been developed by external parties to improve the experience of using Python in the terminal.\n\n\nIPython\nIPython is a greatly improved shell with more functionality (e.g.¬†syntax highlighting, nicer completion interface, magic commands).\nYou can install IPython and launch it instead of launching Python by running ipython in your terminal.\n\nNow that everybody is using Jupyter (see below), using the IPython shell directly has fallen out of fashion, but it is actually one of my favourite methods to run Python.\n\n\n\nptpython\nptpython is an even more fancy Python shell that is highly customizable and offers amazing autocompletion, multiline editing, mouse support, beautiful colour schemes, and more.\nYou can also combine ptpython with IPython by running ptipython.\n\n\nbpython\nbpython is another interface for the Python shell with a different style and feel.\n\n\nXonsh\nXonsh allows to mix Python and Bash in the same commands.\n\n\n\nIDEs\nA more sophisticated way to run Python interactively is to use an integrated development environment (IDE). In addition to providing an improved shell, IDEs make writing scripts or other documents convenient, they provide ways to send sections of scripts to the Python shell, and they might come with their own file system interface.\n\nJupyter\nThe IPython shell was integrated into a fancy interface, the Jupyter notebook. This later lead to a fully fledged IDE (integrated development environment) called JupyterLab which contains notebooks, a command line, a file explorer, and other functionality.\nYou can install JupyterLab, launch it by running jupyter lab in a terminal and the IDE will open in your browser.\n\nEven though JupyterLab runs in your browser, it does not use internet: it is all run locally.\n\n\n\nmarimo\nmarimo is a new type of Python notebooks that solves some of the downsides of Jupyter notebooks (e.g.¬†no hidden states, saved as .py files, built-in interactive widgets, support for interactive plots, easy deployment as web apps, powerful query system).\nI gave a webinar on marimo in November 2025.\n\n\nText editors\nJupyter has probably become the most popular IDE, but it is possible to run Python in other IDE such as Emacs.\n\n\n\nQuarto\nThe very popular RMarkdown developed by Posit (formerly RStudio Inc) lead to a new and more powerful tool called Quarto. Quarto runs code blocks of R, Julia, and Python in markdown documents which can be rendered into websites, pdfs, presentations, and more (this website is built with Quarto).\nUnder the hood, Quarto runs Jupyter notebooks, so it is in fact IPython running in Jupyter that executes the Python code in Quarto.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Running Python"
    ]
  },
  {
    "objectID": "python/intro_run.html#on-alliance-clusters",
    "href": "python/intro_run.html#on-alliance-clusters",
    "title": "Running Python",
    "section": "On Alliance clusters",
    "text": "On Alliance clusters\n\nNon-interactive Python\nYou can SSH into an Alliance cluster, load the Python module with the Python version of your choice (use module spider python to find the module, then module load to load it), write a Python script, an sbatch script and run your code with a batch job as you saw in our HPC course. This is covered in detail in a later section.\n\n\nInteractive Python\n\nPython shell\nSimilarly, if you SSH to a cluster, load the Python module of your choice, then launch an interactive job with salloc, you can run the Python shell.\n\n\nIPython\nTo use IPython, load the IPython module of your choice (module spider ipython to find it, module load to load it), launch an interactive job with salloc, and finally launch the IPython shell by running ipython in the terminal.\n\n\nJupyter\nTo use JupyterLab on a cluster, you use what is called a JupyterHub: a set of tools that spawn and manage multiple instances of JupyterLab servers. Under the hood, they manage an interactive job used by your JupyterLab server.\nLet‚Äôs try it on our training cluster.\n\nLaunch JupyterLab\n\nClaim a username\nGo to the etherpad that we will share during the course and claim a username by adding your first name or a pseudo next to a free username on the list.\nYour username is the name that was already on the list, NOT what you wrote next to it (which doesn‚Äôt matter at all and only serves at signalling that this username is now taken).\nYour username will look like userxx‚Äîxx being 2 digits‚Äîwith no space and no capital letter.\n\n\nLog in\n\ngo to the URL we will give you during the course,\nsign in with your new username and a password that we will give you during the course,\nleave OTP blank,\nlog in.\n\n\n\nLaunch a job\nThis will take you to server options page:\n\n\nChange the time to 2.0 hours,\npress start.\n\n\nNote that, unlike other JupyterHubs you might have used (e.g.¬†Syzygy), this JupyterHub is not permanent and will be destroyed at the end of the course.\n\n\n\n\nEnd a session\nIf you don‚Äôt need all the time you asked for after all, it is a great thing to log out (the resources you are using on this cluster are shared amongst many people and when resources are allocated to you, they aren‚Äôt available to other people. So it is a good thing not to ask for unnecessary resources and have them sit idle when others could be using them).\nTo log out, click on File in the top menu and select Log out at the very bottom.\nIf you would like to make a change to the information you entered on the server option page after you have pressed start, log out, log back in, edit the server options, and press start again.\n\n\nStart a Python notebook\nTo start a Jupyter notebook with the Python kernel, click on the button Python 3 in the Notebook section (top row of buttons).\n\n\nThe Jupyter interface\nIn a fashion Vi users will be familiar with, Jupyter notebooks come with two modes: edit mode in which you can type text as usual and command mode in which many keys are shortcuts to specific actions.\nHere are some useful key bindings to navigate a Jupyter notebook:\n\nEnter            enter edit mode\nEsc              enter command mode\n\n# in edit mode\nTab              code completion\n\n# in command mode\nup               navigate up\ndown             navigate up\nShift+up         select multiple cells up\nShift+down       select multiple cells down\na                insert a new blank cell above\nb                insert a new blank cell below\nc                copy the current or selected cells\nx                cut the current or selected cells\nv                paste the copied or cut cells\nm                turn the cell into a markdown cell\ny                turn the cell into a code cell\nShift+m          merge selected cells\n\n# in either mode\nCtl+Enter        run the current cell\nShift+Enter      run the current cell and move to a new cell below",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Running Python"
    ]
  },
  {
    "objectID": "python/intro_python.html",
    "href": "python/intro_python.html",
    "title": "A few words about Python",
    "section": "",
    "text": "Before we start our course, let‚Äôs talk briefly about Python, its history, its strengths, and its limitations.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "A few words about Python"
    ]
  },
  {
    "objectID": "python/intro_python.html#a-very-popular-language",
    "href": "python/intro_python.html#a-very-popular-language",
    "title": "A few words about Python",
    "section": "A very popular language",
    "text": "A very popular language\n\nFrom a slowish start ‚Ä¶\nPython was released in 1991 by Dutch programmer Guido van Rossum to the ‚Äúalt.sources‚Äù Usenet group.\nIts initial adoption was very gradual in niche communities.\nIn the 2000s, the release of Python 2.0, the birth of Python-based web frameworks, and the development of the first scientific libraries turned Python into a mainstream language.\nThe introduction of version 3.0 in 2008 fixed core design flaws in the language, but because many changes were backwards-incompatible, it also created rifts in the community and a slow and fragmented transition from the old mature version to the new one.\n\n\n‚Ä¶ to the most popular language\nSince the mid-2010s, the language has seen an explosive growth thanks to the uptake by the data science community and the deep learning revolution (when Google released TensorFlow in 2015 and Facebook released PyTorch in 2016, they chose Python as their primary interface, making it, for better or for worse the lingua franca of AI and Machine Learning).\nYou can track its ever increasing advantage over other programming languages in indexes such as the PYPL PopularitY of Programming Language index (based on the number of tutorial searches in Google) or the TIOBE (calculated from the number of search engine results for queries containing the name of the language).",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "A few words about Python"
    ]
  },
  {
    "objectID": "python/intro_python.html#an-interpreted-language",
    "href": "python/intro_python.html#an-interpreted-language",
    "title": "A few words about Python",
    "section": "An interpreted language",
    "text": "An interpreted language\n\nCompiled languages\nCompiled languages require two steps:\n\nIn a first step the code you write in a human-readable format (the source code, usually in plain text) gets compiled into machine code.\nIt is then this machine code that is used to process your data.\n\nSo you write a script, compile it, then use it.\n\nBecause machine code is a lot easier to process by computers, compiled languages are fast. The two step process however makes prototyping new code less practical, these languages are hard to learn, and debugging compilation errors can be challenging.\n\nExamples of compiled languages include C, C++, Fortran, Go, and Haskell.\n\n\n\nInterpreted languages\nInterpreted languages on the other hand are executed directly. This has many advantages such as dynamic typing and direct feed-back. They are easy to learn and prototyping and debugging are a lot simpler. This however comes at the cost of efficiency.\n\n\nThe source code can facultatively be bytecompiled into non human-readable, more compact, lower level bytecode which is read by the interpreter a bit more efficiently.\n\n\nExamples of interpreted languages include R, Perl, JavaScript, and for our purpose here, Python.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "A few words about Python"
    ]
  },
  {
    "objectID": "python/intro_python.html#pythons-pros-and-cons",
    "href": "python/intro_python.html#pythons-pros-and-cons",
    "title": "A few words about Python",
    "section": "Python‚Äôs pros and cons",
    "text": "Python‚Äôs pros and cons\nTo sum up, here are the main strong points and drawbacks of Python:\n\n\n\n\n\n\nStrengths\n\n\n\n\nVery popular\n\n\nLarge number of libraries\n\n\nFriendly syntax\n\n\nInterpreted (easy prototyping)\n\n\nDominant language in deep learning frameworks\n\n\nNumerous resources\n\n\n\n\n\n\n\n\n\n\n\nWeaknesses\n\n\n\n\nSlow\n\n\nMemory intensive\n\n\nThreading limitations\n\n\nOOP added after the fact and clunky\n\n\nRuntime errors (dynamic typing)",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "A few words about Python"
    ]
  },
  {
    "objectID": "python/intro_pkg.html",
    "href": "python/intro_pkg.html",
    "title": "Modules, packages, and libraries",
    "section": "",
    "text": "So far, we have talked about functionality that is available whenever you launch Python. Python however comes with a lot more capabilities, some of it out of the box, some of it after you have installed third-party components.\nThis session covers the types of additional code that can be loaded in a Python session.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Modules, pkgs, and libraries"
    ]
  },
  {
    "objectID": "python/intro_pkg.html#definitions",
    "href": "python/intro_pkg.html#definitions",
    "title": "Modules, packages, and libraries",
    "section": "Definitions",
    "text": "Definitions\nModules are Python files containing reusable code (e.g.¬†functions, constants, utilities).\nPackages are collections of modules.\nLibraries, technically, are collections of packages, although packages and libraries are often used loosely and interchangeably in Python.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Modules, pkgs, and libraries"
    ]
  },
  {
    "objectID": "python/intro_pkg.html#the-standard-library",
    "href": "python/intro_pkg.html#the-standard-library",
    "title": "Modules, packages, and libraries",
    "section": "The standard library",
    "text": "The standard library\nPython comes with an extensive standard library. As soon as you launch the program, you can access part of it such as the built-in functions and built-in constants:\n\nExample:\n\n\ntype(3)    # type is a built-in function\n\nint\n\n\nMost of the standard library however is held in several thematic modules. Each module contains additional functions, constants, and facilities. Before you can use them, you need to load them into your session.\n\nExample: the math module\nThe math module contains many mathematical functions and constants, including the sqrt function.\nThis function cannot be accessed directly:\n\nsqrt(9)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[2], line 1\n----&gt; 1 sqrt(9)\n\nNameError: name 'sqrt' is not defined\n\n\n\nIn order to use it, you have two options:\n\nLoad the module, then access the function as a method of the module:\n\n\nimport math\nmath.sqrt(9)\n\n3.0\n\n\n\nYou can create an alias for the module:\n\nimport math as m\nm.sqrt(9)\n\n3.0\n\n\nThis is particularly convenient with modules of longer names.\n\n\nImport the function directly:\n\n\nfrom math import sqrt\nsqrt(9)\n\n3.0",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Modules, pkgs, and libraries"
    ]
  },
  {
    "objectID": "python/intro_pkg.html#installing-packages-on-your-machine",
    "href": "python/intro_pkg.html#installing-packages-on-your-machine",
    "title": "Modules, packages, and libraries",
    "section": "Installing packages on your machine",
    "text": "Installing packages on your machine\nYou can install external packages containing additional functions, constants, datasets, and utilities to extend the capabilities of Python.\nThe Python Package Index is a public repository of open source packages contributed by users.\nInstallation of packages can be done via pip or (better and much faster) with the new Python package and project manager uv.\nInstead of installing packages system wide or for your user, you can create a semi-isolated Python environment in which you install the packages needed for a particular project. This makes reproducibility and collaboration easier. It also helps handle dependency conflicts. It is a great practice to always use virtual environments.\n\nSome Linux distributions will not let you use pip outside a virtual environment anymore.\nuv will automatically install packages in virtual environments.\n\n\nTraditional workflow with pip\n\nNote that the method with uv in the next section is a better (and much faster) option.\n\nCreate a Python virtual environment called env:\npython -m venv ~/env\nActivate it:\nsource ~/env/bin/activate\nUpdate pip:\npython -m pip install --upgrade pip\nInstall packages:\npython -m pip install &lt;package&gt;\nTo deactivate a virtual environment, run:\ndeactivate\n\n\nModern workflow with uv\nuv is an amazing new package and project manager for Python written in Rust that replaces all the old tools (pip, pyenv, virtualenv, poetry, pipx, etc.). It does everything very well and very fast.\nThe best approach while using uv is to create projects. In addition to a virtual environment, a project contains a TOML file with a list of dependencies (Python packages), a file setting the Python version for the project, and a lock. This is extremely convenient.\nCreate a new project:\nuv init &lt;project-name&gt;\nInstall packages in the virtual environment of the project:\nuv add &lt;package&gt;\n\nYou don‚Äôt need to activate the virtual environment as long as you are using uv commands.\n\nIf you want to launch Jupyter from a uv project, run:\nuv run --with jupyter jupyter lab\nIf you already have a workflow involving pip that you cannot change and you still would like to use uv, you can use the pip interface. It is not as convenient as the project approach, but it allows you to benefit from uv speed.\n\nFor more information on uv, you can have a look at the webinar I gave on this tool in May 2025.\n\n\n\nNon-Python dependencies\nWhile uv is fantastic to handle all things Python-related (Python versions, packages, environments, projects, etc.), if you need to install a software stack involving non-Python dependencies on your local machine, you will need to use Mamba, conda, or another package manager that can handle non-Python packages.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Modules, pkgs, and libraries"
    ]
  },
  {
    "objectID": "python/intro_pkg.html#installing-packages-on-the-clusters",
    "href": "python/intro_pkg.html#installing-packages-on-the-clusters",
    "title": "Modules, packages, and libraries",
    "section": "Installing packages on the clusters",
    "text": "Installing packages on the clusters\nDon‚Äôt use conda or Anaconda on the Alliance clusters. If you really must, do it in a container with Apptainer.\nOn the Alliance clusters, install packages inside a virtual environment and use Python wheels whenever possible.\nYou can see whether a wheel is available with avail_wheels &lt;package&gt; or look at the list of available wheels. To install from wheels instead of downloading from PyPI, add the --no-index flag to the install command.\nAdvantages of wheels:\n\ncompiled for the clusters hardware,\nensures no missing or conflicting dependencies,\nmuch faster installation.\n\nThe workflow thus looks like:\npython -m venv ~/env\nsource ~/env/bin/activate\npython -m pip install --upgrade --no-index pip\npython -m pip install --no-index &lt;package&gt;\n\nAt this point, uv is not technically supported on Alliance clusters. Some people have had success using it, others have had issues while interacting with the clusters module system.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Modules, pkgs, and libraries"
    ]
  },
  {
    "objectID": "python/intro_pkg.html#installing-packages-from-jupyter",
    "href": "python/intro_pkg.html#installing-packages-from-jupyter",
    "title": "Modules, packages, and libraries",
    "section": "Installing packages from Jupyter",
    "text": "Installing packages from Jupyter\nYou can run either of the pip or uv commands from within a Jupyter notebook cell by preceding them with the IPython magic command ! which lets it know that it is a Bash (rather than a Python) command.\n\nExample:\n\n!uv init project",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Modules, pkgs, and libraries"
    ]
  },
  {
    "objectID": "python/intro_numpy.html",
    "href": "python/intro_numpy.html",
    "title": "Array computing with NumPy",
    "section": "",
    "text": "NumPy is a Python library written in C, Python, and C++ that adds support for the mathematical manipulation of large multidimensional arrays. It is the library that brought Python to the scientific community and many scientific packages rely on it.\nThis introductory course does not leave us enough time to cover NumPy, but the official NumPy website contains an excellent and extensive documentation.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Array computing with NumPy"
    ]
  },
  {
    "objectID": "python/intro_functions.html",
    "href": "python/intro_functions.html",
    "title": "Writing functions",
    "section": "",
    "text": "Python comes with a number of built-in functions. Packages can provide additional ones. In many cases however, you will want to create your own functions to perform exactly the computations that you need.\nIn this section, we will see how to define new functions.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Writing functions"
    ]
  },
  {
    "objectID": "python/intro_functions.html#syntax",
    "href": "python/intro_functions.html#syntax",
    "title": "Writing functions",
    "section": "Syntax",
    "text": "Syntax\nThe function definition syntax follows:\ndef &lt;name&gt;(&lt;arguments&gt;):\n    &lt;body&gt;\nOnce defined, new functions can be used as any other function.\nLet‚Äôs give this a try by creating some greeting functions.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Writing functions"
    ]
  },
  {
    "objectID": "python/intro_functions.html#function-without-argument",
    "href": "python/intro_functions.html#function-without-argument",
    "title": "Writing functions",
    "section": "Function without argument",
    "text": "Function without argument\nLet‚Äôs start with the simple case in which our function does not accept any argument:\n\ndef hello():\n    print('Hello!')\n\nThen we call it:\n\nhello()\n\nHello!\n\n\nThis was great, but ‚Ä¶\n\nhello('Marie')\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[88], line 1\n----&gt; 1 hello('Marie')\n\nTypeError: hello() takes 0 positional arguments but 1 was given\n\n\n\n‚Ä¶ it does not accept arguments.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Writing functions"
    ]
  },
  {
    "objectID": "python/intro_functions.html#function-with-one-argument",
    "href": "python/intro_functions.html#function-with-one-argument",
    "title": "Writing functions",
    "section": "Function with one argument",
    "text": "Function with one argument\nLet‚Äôs step this up with a function which can accept an argument:\n\ndef greetings(name):\n    print('Hello ' + name + '!')\n\nThis time, this works:\n\ngreetings('Marie')\n\nHello Marie!\n\n\nHowever, this does not work anymore:\n\ngreetings()\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[91], line 1\n----&gt; 1 greetings()\n\nTypeError: greetings() missing 1 required positional argument: 'name'\n\n\n\nüôÅ",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Writing functions"
    ]
  },
  {
    "objectID": "python/intro_functions.html#f-strings",
    "href": "python/intro_functions.html#f-strings",
    "title": "Writing functions",
    "section": "F-strings",
    "text": "F-strings\nTo be more fancy, you can use a formatted string literal or f-string instead of a simple string. F-strings allow to include the expressions that are replaced by arguments to be included inside the string and to format them.\nTo use them, you use f or F just before the string expression (without space) as in f'This is a formatted string literal'. Then you include the expressions that will be replaced by arguments inside the string, but in curly braces as in f'This is a formatted string literal with an {expression}'.\n\nExample:\n\n\ndef greetings(name):\n    print(f'Hello {name}!')\n\ngreetings('Marie')\n\nHello Marie!\n\n\n\nNote the difference in syntax. Here, we aren‚Äôt using + anymore as we aren‚Äôt concatenating a series of strings. Instead, we create a single string which includes the expression name that will be replaced by the argument.\n\nWith f-strings, you can now add formatting to the output.\n\nExample:\n\n\n# Add quotes around the expression\ndef greetings(name):\n    print(f'Hello {name!r}!')\n\ngreetings('Marie')\n\nHello 'Marie'!\n\n\nYou can explore more tricks that can be done with f-strings in the official Python tutorials.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Writing functions"
    ]
  },
  {
    "objectID": "python/intro_functions.html#function-with-a-facultative-argument",
    "href": "python/intro_functions.html#function-with-a-facultative-argument",
    "title": "Writing functions",
    "section": "Function with a facultative argument",
    "text": "Function with a facultative argument\nLet‚Äôs make this even more fancy: a function with a facultative argument. That is, a function which accepts an argument, but also has a default value for when we do not provide any argument:\n\ndef howdy(name='everyone'):\n    print(f'Hello {name}!')\n\nWe can call it without argument (making use of the default value):\n\nhowdy()\n\nHello everyone!\n\n\nAnd we can call it with an argument:\n\nhowdy('Marie')\n\nHello Marie!\n\n\nThis was better, but ‚Ä¶\n\nhowdy('Marie', 'Alex')\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[97], line 1\n----&gt; 1 howdy('Marie', 'Alex')\n\nTypeError: howdy() takes from 0 to 1 positional arguments but 2 were given\n\n\n\n‚Ä¶ this does not work.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Writing functions"
    ]
  },
  {
    "objectID": "python/intro_functions.html#function-with-two-arguments",
    "href": "python/intro_functions.html#function-with-two-arguments",
    "title": "Writing functions",
    "section": "Function with two arguments",
    "text": "Function with two arguments\nWe could create a function which takes two arguments:\n\ndef hey(name1, name2):\n    print(f'Hello {name1} and {name2}!')\n\nWhich solves our problem:\n\nhey('Marie', 'Alex')\n\nHello Marie and Alex!\n\n\nBut it is terribly limiting:\n\n# This doesn't work\nhey()\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[100], line 2\n      1 # This doesn't work\n----&gt; 2 hey()\n\nTypeError: hey() missing 2 required positional arguments: 'name1' and 'name2'\n\n\n\n\n# And neither does this\nhey('Marie')\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[101], line 2\n      1 # And neither does this\n----&gt; 2 hey('Marie')\n\nTypeError: hey() missing 1 required positional argument: 'name2'\n\n\n\n\n# Nor to mention this...\nhey('Marie', 'Alex', 'Luc')\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[102], line 2\n      1 # Nor to mention this...\n----&gt; 2 hey('Marie', 'Alex', 'Luc')\n\nTypeError: hey() takes 2 positional arguments but 3 were given",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Writing functions"
    ]
  },
  {
    "objectID": "python/intro_functions.html#function-with-any-number-of-args",
    "href": "python/intro_functions.html#function-with-any-number-of-args",
    "title": "Writing functions",
    "section": "Function with any number of args",
    "text": "Function with any number of args\nLet‚Äôs create a function which handles all cases.\nWe will have to break it down into the various scenarios, but we already saw how to do this in the previous lesson with if statements.\nThe scenarios are:\n\nno name given (we need to set some default somehow),\none name given (no grammar syntax needs adding),\ntwo names given (we need to add ‚Äúand‚Äù),\nmore than two names (we need to add commas after all but the last name and we need to add ‚Äúand‚Äù before the last name).\n\nWe saw above how to create a default value. Here, we will use a different approach that will make our life easier. We will use the argument as the list of names. That allows us to get its length (to see which scenario we are in) and to index it (to add the grammar syntax at the right place).\nFinally, we need a way to make the function work with any number of arguments. To do this, we use an arbitrary argument list with * followed by a name. When the function already accepts some arguments, by convention, people use *args to signify that any number of additional arguments can be passed to the function. But you can use any name preceded by the asterisk.\nHere, because we will only use the starred argument, let‚Äôs call it *names.\nThis and that Stack Overflow questions attracted a lot of very useful answers to explain the concepts of * and **.\nHere is our function:\n\ndef hi(*names):\n    # Case 1: No names were provided.\n    if not names:\n        print(\"Hello everyone!\")\n        return\n\n    # Case 2: Only one name was provided.\n    if len(names) == 1:\n        # names is a tuple, so we access the first element with names[0]\n        print(f\"Hello {names[0]}!\")\n        return\n\n    # Case 3: Two names were provided.\n    if len(names) == 2:\n        print(f\"Hello {names[0]} and {names[1]}!\")\n        return\n\n    # Case 4: Three or more names were provided (the general case).\n    # We take all names except the last one for the main list.\n    all_but_last = names[:-1]\n    last_person = names[-1]\n\n    # We join the main list with commas.\n    greeting_list = \", \".join(all_but_last)\n\n    # Then we construct the final sentence.\n    print(f\"Hello {greeting_list}, and {last_person}!\")\n\nLet‚Äôs test it:\n\nhi()\nhi('Marie')\nhi('Marie', 'Alex')\nhi('Marie', 'Alex', 'Luc')\nhi('Marie', 'Alex', 'Luc', 'Grace')\n\nHello everyone!\nHello Marie!\nHello Marie and Alex!\nHello Marie, Alex, and Luc!\nHello Marie, Alex, Luc, and Grace!\n\n\nEverything works! üôÇ\nNote the presence of the keyword return in this function. When the return statement is encountered during a function execution, the function terminates immediately and any code after that statement is not executed. This is why we could write this function with a series of if statements.\nInstead, we could have written our function using if elif else statements as we saw in the previous lesson.\n\n\nYour turn:\n\nWrite a version of this function that does not use return to exit the function, but uses if elif else statements instead.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Writing functions"
    ]
  },
  {
    "objectID": "python/intro_functions.html#documenting-functions",
    "href": "python/intro_functions.html#documenting-functions",
    "title": "Writing functions",
    "section": "Documenting functions",
    "text": "Documenting functions\nIt is a good habit to document what your functions do. As with comments, those ‚Äúdocumentation strings‚Äù or ‚Äúdocstrings‚Äù will help future you or other users of your code.\nPEP 257‚Äîdocstring conventions‚Äîsuggests to use single-line docstrings surrounded by triple quotes.\nRemember the function definition syntax we saw at the start of this chapter? To be more exhaustive, we should have written it this way:\ndef &lt;name&gt;(&lt;arguments&gt;):\n    \"\"\"&lt;docstrings&gt;\"\"\"\n    &lt;body&gt;\n\nExample:\n\n\ndef hi(*names):\n    \"\"\"Greets a variable number of people with proper grammar.\"\"\"\n    # Case 1: No names were provided.\n    if not names:\n        print(\"Hello everyone!\")\n        return\n\n    # Case 2: Only one name was provided.\n    if len(names) == 1:\n        # names is a tuple, so we access the first element with names[0]\n        print(f\"Hello {names[0]}!\")\n        return\n\n    # Case 3: Two names were provided.\n    if len(names) == 2:\n        print(f\"Hello {names[0]} and {names[1]}!\")\n        return\n\n    # Case 4: Three or more names were provided (the general case).\n    # We take all names except the last one for the main list.\n    all_but_last = names[:-1]\n    last_person = names[-1]\n\n    # We join the main list with commas.\n    greeting_list = \", \".join(all_but_last)\n\n    # Then we construct the final sentence.\n    print(f\"Hello {greeting_list}, and {last_person}!\")\n\nPEP 8‚Äîthe style guide for Python code‚Äîsuggests a maximum of 72 characters per line for docstrings.\nIf your docstring is longer, you should create a multi-line one. In that case, PEP 257 suggests to have a summary line at the top (right after the opening set of triple quotes), then leave a blank line, then have your long docstrings (which can occupy multiple lines), and finally have the closing set of triple quotes on a line of its own:\ndef &lt;name&gt;(&lt;arguments&gt;):\n    \"\"\"&lt;summary docstrings line&gt;\"\"\"\n\n    &lt;more detailed description&gt;\n    \"\"\"\n    &lt;body&gt;\n\nExample:\n\n\ndef hi(*names):\n    \"\"\"\n    Greets a variable number of people with proper grammar.\n\n    This function uses *args to accept any number of string arguments.\n    \"\"\"\n    # Case 1: No names were provided.\n    if not names:\n        print(\"Hello everyone!\")\n        return\n\n    # Case 2: Only one name was provided.\n    if len(names) == 1:\n        # names is a tuple, so we access the first element with names[0]\n        print(f\"Hello {names[0]}!\")\n        return\n\n    # Case 3: Two names were provided.\n    if len(names) == 2:\n        print(f\"Hello {names[0]} and {names[1]}!\")\n        return\n\n    # Case 4: Three or more names were provided (the general case).\n    # We take all names except the last one for the main list.\n    all_but_last = names[:-1]\n    last_person = names[-1]\n\n    # We join the main list with commas.\n    greeting_list = \", \".join(all_but_last)\n\n    # Then we construct the final sentence.\n    print(f\"Hello {greeting_list}, and {last_person}!\")\n\nYou can now access the documentation of your function as you would any Python function:\n\nhelp(hi)\n\nHelp on function hi in module __main__:\n\nhi(*names)\n    Greets a variable number of people with proper grammar.\n\n    This function uses *args to accept any number of string arguments.\n\n\n\nOr:\n\nprint(hi.__doc__)\n\n\nGreets a variable number of people with proper grammar.\n\nThis function uses *args to accept any number of string arguments.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Writing functions"
    ]
  },
  {
    "objectID": "python/intro_functions.html#returning-values",
    "href": "python/intro_functions.html#returning-values",
    "title": "Writing functions",
    "section": "Returning values",
    "text": "Returning values\nSo far, all the functions we looked at printed something. Often, you will want your functions to calculate some result. This result needs to be ‚Äúreturned‚Äù. This is also done with the keyword return that we saw above, this time followed by the value(s) to be returned.\nLet‚Äôs create a dummy function:\n\ndef add_one(value):\n    value + 1\n\nand test it:\n\nadd_one(4)\n\nWe don‚Äôt get any result. ü§î\nThat‚Äôs because our function is not returning anything. To fix it, we need to return the result:\n\ndef add_one(value):\n    return value + 1\n\nNow it works:\n\nadd_one(4)\n\n5",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Writing functions"
    ]
  },
  {
    "objectID": "python/intro_functions.html#printing-vs-returning",
    "href": "python/intro_functions.html#printing-vs-returning",
    "title": "Writing functions",
    "section": "Printing vs returning",
    "text": "Printing vs returning\nSo what‚Äôs the difference between printing and returning?\nPrinting is called a side-effect: it modifies the state of the terminal by displaying some text on it, but it doesn‚Äôt return any value to the program (in fact it returns None):\n\ndef test_print():\n    print('Printing function')\n\na = test_print()\n\nPrinting function\n\n\n\ntype(a)\n\nNoneType\n\n\n\nprint(a)\n\nNone\n\n\nOn the contrary, returning a value makes it available to the program:\n\ndef test_return():\n    return 3\n\na = test_return()\n\n\ntype(a)\n\nint\n\n\n\nprint(a)\n\n3\n\n\n\n\nYour turn:\n\nWrite a function that calculates an area. It should:\n\nbe documented,\naccept 2 arguments: length and width,\nprint an error message if length and/or width is negative.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Writing functions"
    ]
  },
  {
    "objectID": "python/intro_control_flow.html",
    "href": "python/intro_control_flow.html",
    "title": "Control flow",
    "section": "",
    "text": "Control flow statements alter the linear execution of code, allowing for one or another section of code to be executed, or for one section of code to be executed multiple times.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Control flow"
    ]
  },
  {
    "objectID": "python/intro_control_flow.html#conditionals",
    "href": "python/intro_control_flow.html#conditionals",
    "title": "Control flow",
    "section": "Conditionals",
    "text": "Conditionals\nConditionals dictate the flow of information based on predicates (statements that return True or False).\n\nExample predicates:\n\n4 &lt; 3\n2 == 4\n2 != 4\n2 in range(5)\n2 not in range(5)\n3 &lt;= 4 and 4 &gt; 5\n3 &lt;= 4 and 4 &gt; 5 and 3 != 2\n3 &lt;= 4 or 4 &gt; 5\n\nIf statements\nIn the simplest case, we have:\nif &lt;predicate&gt;:\n    &lt;some action&gt;\nThis translates to:\n\nIf &lt;predicate&gt; evaluates to True, the body of the if statement gets evaluated (&lt;some action&gt; is run),\nIf &lt;predicate&gt; evaluates to False, nothing happens.\n\n\nExamples:\n\n\nx = 3\nif x &gt;= 0:\n    print(x, 'is positive')\n\n3 is positive\n\n\n\nx = -3\nif x &gt;= 0:\n    print(x, 'is positive')\n\n\nNothing gets returned since the predicate returned False.\n\n\n\nIf else statements\nLet‚Äôs add an else statement so that our code also returns something when the predicate evaluates to False:\nif &lt;predicate&gt;:\n    &lt;some action&gt;\nelse:\n    &lt;some other action&gt;\n\nExample:\n\n\nx = -3\nif x &gt;= 0:\n    print(x, 'is positive')\nelse:\n    print(x, 'is negative')\n\n-3 is negative\n\n\n\n\nIf elif else\nWe can make this even more complex with:\nif &lt;predicate1&gt;:\n    &lt;some action&gt;\nelif &lt;predicate2&gt;:\n    &lt;some other action&gt;    \nelse:\n    &lt;yet some other action&gt;\n\nExample:\n\n\nx = -3\nif x &gt; 0:\n    print(x, 'is positive')\nelif x &lt; 0:\n    print(x, 'is negative')\nelse:\n    print(x, 'is zero')\n\n-3 is negative",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Control flow"
    ]
  },
  {
    "objectID": "python/intro_control_flow.html#loops",
    "href": "python/intro_control_flow.html#loops",
    "title": "Control flow",
    "section": "Loops",
    "text": "Loops\n\nFor loops\nFor loops run a set of instructions for each element of an iterable.\nAn iterable is any Python object cable of returning the items it contains one at a time.\n\nExamples of iterables:\n\nrange(5)\n'a string is an iterable'\n[2, 'word', 4.0]\nFor loops follow the syntax:\nfor &lt;iterable&gt;:\n    &lt;some action&gt;\n\nExample:\n\n\nfor i in range(5):\n    print(i)\n\n0\n1\n2\n3\n4\n\n\n\n\nYour turn:\n\nRemember that the indentation matters in Python.\nWhat do you think that this will print?\nfor i in range(5):\n    print(i)\nprint(i)\n\nStrings are iterables too, so this works:\n\nfor i in 'a string is an iterable':\n    print(i)\n\na\n \ns\nt\nr\ni\nn\ng\n \ni\ns\n \na\nn\n \ni\nt\ne\nr\na\nb\nl\ne\n\n\nTo iterate over multiple iterables at the same time, a convenient option is to use the function zip which creates an iterator of tuples:\n\nfor i, j in zip([1, 2, 3, 4], [3, 4, 5, 6]):\n    print(i + j)\n\n4\n6\n8\n10\n\n\n\n\nWhile loops\nWhile loops run as long as a predicate remains true. They follow the syntax:\nwhile &lt;predicate&gt;:\n    &lt;some action&gt;\n\nExample:\n\n\ni = 0\nwhile i &lt;= 10:\n    print(i)\n    i += 1\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Control flow"
    ]
  },
  {
    "objectID": "python/index.html",
    "href": "python/index.html",
    "title": "Python",
    "section": "",
    "text": "Getting started in ¬†\nAn intro course to Python\n\n\n\n\nLearning ¬† with an LLM\nAn intro course to programming using an LLM\n\n\n\n\n\n\nFaster ¬†\nSpeeding up Python computations\n\n\n\n\nText analysis\nAn introduction to NLP using TextBlob\n\n\n\n\n\n\nWorkshops\nVarious Python topics\n\n\n\n\n60 min webinars\nVarious Python topics",
    "crumbs": [
      "Python",
      "<br>&nbsp;<img src=\"img/logo_python.svg\" class=\"img-fluid\" style=\"width:1.55em\" alt=\"noshadow\"><br><br>"
    ]
  },
  {
    "objectID": "python/hpc_jax.html",
    "href": "python/hpc_jax.html",
    "title": "An introduction to JAX",
    "section": "",
    "text": "JAX can be used for any high-performance scientific computing with arrays, but because it is a good starting point to build deep learning libraries, please find this course in the AI section.",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "JAX: accelerated arrays & AD"
    ]
  },
  {
    "objectID": "newsletter.html",
    "href": "newsletter.html",
    "title": "Training events mailing list",
    "section": "",
    "text": "If you want to get informed about upcoming training events, please subscribe to our mailing list:  \n(We will only email you about training events.)"
  },
  {
    "objectID": "julia/wb_makie_slides.html#plotting-in-julia",
    "href": "julia/wb_makie_slides.html#plotting-in-julia",
    "title": "Makie",
    "section": "Plotting in Julia",
    "text": "Plotting in Julia\n\nMany options:\n\nPlots.jl: high-level API for working with different back-ends (GR, Pyplot, Plotly‚Ä¶)\nPyPlot.jl: Julia interface to Matplotlib‚Äôs matplotlib.pyplot\nPlotlyJS.jl: Julia interface to plotly.js\nPlotlyLight.jl: the fastest plotting option in Julia by far, but limited features\nGadfly.jl: following the grammar of graphics popularized by Hadley Wickham in R\nVegaLite.jl: grammar of interactive graphics\nPGFPlotsX.jl: Julia interface to the PGFPlots LaTeX package\nUnicodePlots.jl: plots in the terminal üôÇ\n\n\n\n\nMakie.jl: powerful plotting ecosystem: animation, 3D, GPU optimization"
  },
  {
    "objectID": "julia/wb_makie_slides.html#makie-ecosystem",
    "href": "julia/wb_makie_slides.html#makie-ecosystem",
    "title": "Makie",
    "section": "Makie ecosystem",
    "text": "Makie ecosystem\n\n\nMain package:\n\nMakie: plots functionalities. Backend needed to render plots into images or vector graphics\n\n\n\n\n\nBackends:\n\nCairoMakie: vector graphics or high-quality 2D plots. Creates, but does not display plots (you need an IDE that does or you can use ElectronDisplay.jl)\nGLMakie: based on OpenGL; 3D rendering and interactivity in GLFW window (no vector graphics)\nWGLMakie: web version of GLMakie (plots rendered in a browser instead of a window)"
  },
  {
    "objectID": "julia/wb_makie_slides.html#extensions",
    "href": "julia/wb_makie_slides.html#extensions",
    "title": "Makie",
    "section": "Extensions",
    "text": "Extensions\n\nGeoMakie.jl add geographical plotting utilities to Makie\nAlgebraOfGraphics.jl turns plotting into a simple algebra of building blocks\nGraphMakie.jl to create network graphs"
  },
  {
    "objectID": "julia/wb_makie_slides.html#cheatsheet-2d",
    "href": "julia/wb_makie_slides.html#cheatsheet-2d",
    "title": "Makie",
    "section": "Cheatsheet 2D",
    "text": "Cheatsheet 2D\n\nFrom: Storopoli, Huijzer and Alonso (2021). Julia Data Science. https://juliadatascience.io. ISBN: 97984898"
  },
  {
    "objectID": "julia/wb_makie_slides.html#cheatsheet-3d",
    "href": "julia/wb_makie_slides.html#cheatsheet-3d",
    "title": "Makie",
    "section": "Cheatsheet 3D",
    "text": "Cheatsheet 3D\n\nFrom: Storopoli, Huijzer and Alonso (2021). Julia Data Science. https://juliadatascience.io. ISBN: 97984898"
  },
  {
    "objectID": "julia/wb_makie_slides.html#resources",
    "href": "julia/wb_makie_slides.html#resources",
    "title": "Makie",
    "section": "Resources",
    "text": "Resources\n\nOfficial documentation\nJulia Data Science book, chapter 5\nMany examples in the project Beautiful Makie"
  },
  {
    "objectID": "julia/wb_makie_slides.html#troubleshooting",
    "href": "julia/wb_makie_slides.html#troubleshooting",
    "title": "Makie",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nInstalling GLMakie can be challenging. This page may lead you towards solutions\nCairoMakie and WGLMakie should install without issues"
  },
  {
    "objectID": "julia/wb_makie_slides.html#figure",
    "href": "julia/wb_makie_slides.html#figure",
    "title": "Makie",
    "section": "Figure",
    "text": "Figure\nLoad the package (here, we are using CairoMakie):\n\nusing CairoMakie                        # no need to import Makie itself\n\n\n\nCreate a Figure (container object):\n\nfig = Figure()\n\n\n\n\n\n\n\n\n\ntypeof(fig)\n\nFigure"
  },
  {
    "objectID": "julia/wb_makie_slides.html#axis",
    "href": "julia/wb_makie_slides.html#axis",
    "title": "Makie",
    "section": "Axis",
    "text": "Axis\n\n\nThen, you can create an Axis:\n\nax = Axis(Figure()[1, 1]);\n\n\n\n\n\n\ntypeof(ax)\n\nAxis"
  },
  {
    "objectID": "julia/wb_makie_slides.html#add-a-plot",
    "href": "julia/wb_makie_slides.html#add-a-plot",
    "title": "Makie",
    "section": "Add a plot",
    "text": "Add a plot\n\nfig = Figure(size=(1000, 400))\nax = Axis(fig[1, 1])\nx = LinRange(-10, 10, 20)\ny = x\nscatter!(ax, x, y)  # Functions with ! transform their arguments\nfig"
  },
  {
    "objectID": "julia/wb_makie_slides.html#d",
    "href": "julia/wb_makie_slides.html#d",
    "title": "Makie",
    "section": "2D",
    "text": "2D\n\nusing CairoMakie\nusing StatsBase, LinearAlgebra\nusing Interpolations, OnlineStats\nusing Distributions\nCairoMakie.activate!(type=\"png\")\n\nfunction eq_hist(matrix; nbins=256 * 256)\n    h_eq = fit(Histogram, vec(matrix), nbins=nbins)\n    h_eq = normalize(h_eq, mode=:density)\n    cdf = cumsum(h_eq.weights)\n    cdf = cdf / cdf[end]\n    edg = h_eq.edges[1]\n    interp_linear = LinearInterpolation(edg, [cdf..., cdf[end]])\n    out = reshape(interp_linear(vec(matrix)), size(matrix))\n    return out\nend\n\nfunction getcounts!(h, fn; n=100)\n    for _ in 1:n\n        vals = eigvals(fn())\n        x0 = real.(vals)\n        y0 = imag.(vals)\n        fit!(h, zip(x0,y0))\n    end\nend\n\nm(;a=10rand()-5, b=10rand()-5) = [0 0 0 a; -1 -1 1 0; b 0 0 0; -1 -1 -1 -1]\n\nh = HeatMap(range(-3.5,3.5, length=1200), range(-3.5,3.5, length=1200))\ngetcounts!(h, m; n=2_000_000)\n\nwith_theme(theme_black()) do\n    fig = Figure(figure_padding=0,size=(600,600))\n    ax = Axis(fig[1,1]; aspect=DataAspect())\n    heatmap!(ax,-3.5..3.5, -3.5..3.5, eq_hist(h.counts); colormap=:bone_1)\n    hidedecorations!(ax)\n    hidespines!(ax)\n    fig\nend"
  },
  {
    "objectID": "julia/wb_makie_slides.html#d-output",
    "href": "julia/wb_makie_slides.html#d-output",
    "title": "Makie",
    "section": "2D",
    "text": "2D"
  },
  {
    "objectID": "julia/wb_makie_slides.html#d-1",
    "href": "julia/wb_makie_slides.html#d-1",
    "title": "Makie",
    "section": "3D",
    "text": "3D\nusing GLMakie, Random\nGLMakie.activate!()\n\nRandom.seed!(13)\nx = -6:0.5:6\ny = -6:0.5:6\nz = 6exp.( -(x.^2 .+ y' .^ 2)./4)\n\nbox = Rect3(Point3f(-0.5), Vec3f(1))\nn = 100\ng(x) = x^(1/10)\nalphas = [g(x) for x in range(0,1,length=n)]\ncmap_alpha = resample_cmap(:linear_worb_100_25_c53_n256, n, alpha=alphas)\n\nwith_theme(theme_dark()) do\n    fig, ax, = meshscatter(x, y, z;\n                           marker=box,\n                           markersize=0.5,\n                           color=vec(z),\n                           colormap=cmap_alpha,\n                           colorrange=(0,6),\n                           axis=(;\n                                   type=Axis3,\n                                   aspect=:data,\n                                   azimuth=7.3,\n                                   elevation=0.189,\n            perspectiveness=0.5),\n        figure=(;\n            resolution=(1200,800)))\n    meshscatter!(ax, x .+ 7, y, z./2;\n        markersize=0.25,\n        color=vec(z./2),\n        colormap=cmap_alpha,\n        colorrange=(0, 6),\n        ambient=Vec3f(0.85, 0.85, 0.85),\n        backlight=1.5f0)\n    xlims!(-5.5,10)\n    ylims!(-5.5,5.5)\n    hidedecorations!(ax; grid=false)\n    hidespines!(ax)\n    fig\nend"
  },
  {
    "objectID": "julia/wb_makie_slides.html#d-2",
    "href": "julia/wb_makie_slides.html#d-2",
    "title": "Makie",
    "section": "3D",
    "text": "3D"
  },
  {
    "objectID": "julia/wb_makie_slides.html#compiling-sysimages",
    "href": "julia/wb_makie_slides.html#compiling-sysimages",
    "title": "Makie",
    "section": "Compiling sysimages",
    "text": "Compiling sysimages\nWhile Makie is extremely powerful, its compilation time and its time to first plot are extremely long\nFor this reason, it might save you a lot of time to create a sysimage (a file containing information from a Julia session such as loaded packages, global variables, compiled code, etc.) with PackageCompiler.jl\n\nThe upcoming Julia 1.9 will do this automatically"
  },
  {
    "objectID": "julia/wb_makie_slides.html#cairomakie",
    "href": "julia/wb_makie_slides.html#cairomakie",
    "title": "Makie",
    "section": "CairoMakie",
    "text": "CairoMakie\nCairoMakie will run without problem on the Alliance clusters\nIt is not designed for interactivity, so saving to file is what makes the most sense\n\nExample:\n\nsave(\"graph.png\", fig)\n Remember however that CairoMakie is 2D only (for now)"
  },
  {
    "objectID": "julia/wb_makie_slides.html#glmakie",
    "href": "julia/wb_makie_slides.html#glmakie",
    "title": "Makie",
    "section": "GLMakie",
    "text": "GLMakie\nGLMakie relies on GLFW to create windows with OpenGL\nGLFW doesn‚Äôt support creating contexts without an associated window\nThe dependency GLFW.jl will thus not install in the clusters‚Äîeven with X11 forwarding‚Äîunless you use VDI nodes, VNC, or Virtual GL"
  },
  {
    "objectID": "julia/wb_makie_slides.html#wglmakie",
    "href": "julia/wb_makie_slides.html#wglmakie",
    "title": "Makie",
    "section": "WGLMakie",
    "text": "WGLMakie\nYou can setup a server with JSServe.jl as per the documentation\nHowever, this method is intended for the creation of interactive widgets, e.g.¬†for a website\nWhile this is really cool, it isn‚Äôt optimized for performance\nThere might also be a way to create an SSH tunnel to your local browser, although there is no documentation on this\nBest probably is to save to file"
  },
  {
    "objectID": "julia/wb_makie_slides.html#conclusion-makie-on-production-clusters",
    "href": "julia/wb_makie_slides.html#conclusion-makie-on-production-clusters",
    "title": "Makie",
    "section": "Conclusion: Makie on production clusters",
    "text": "Conclusion: Makie on production clusters\n\n2D plots: use CairoMakie and save to file\n3D plots: use WGLMakie and save to file"
  },
  {
    "objectID": "julia/wb_makie.html",
    "href": "julia/wb_makie.html",
    "title": "Makie",
    "section": "",
    "text": "There are several popular data visualization libraries for the Julia programming language (e.g.¬†Plots, Gadfly, VegaLite, Makie). They vary in their precompilation time, time to first plot, layout capabilities, ability to handle 3D data, ease of use, and syntax style. In this landscape, Makie focuses on high performance, fancy layouts, and extensibility.\nMakie comes with multiple backends. In this webinar, we will cover:\n\nGLMakie (ideal for interactive 2D and 3D plotting)\nWGLMakie (an equivalent that runs within browsers)\nCairoMakie (best for high-quality vector graphics)\n\nWe will also see how to run Makie in the Alliance clusters.\n\nSlides (Click and wait: this reveal.js presentation is heavy and takes some time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "Julia",
      "<b><em>Webinars</em></b>",
      "Data visualization with Makie"
    ]
  },
  {
    "objectID": "julia/wb_firstdab.html",
    "href": "julia/wb_firstdab.html",
    "title": "First dab at Julia",
    "section": "",
    "text": "Julia is fast: just-in-time (JIT) compilation and multiple dispatch bring efficiency to interactivity. People often say that using Julia feels like running R or python with a speed almost comparable to that of C.\nBut Julia also comes with parallel computing and multi-threading capabilities.\nIn this webinar, after a quickly presentation of some of the key features of Julia‚Äôs beautifully concise syntax, I will dive into using Julia for HPC.",
    "crumbs": [
      "Julia",
      "<b><em>Webinars</em></b>",
      "First gentle dab at Julia"
    ]
  },
  {
    "objectID": "julia/intro_types.html",
    "href": "julia/intro_types.html",
    "title": "Types",
    "section": "",
    "text": "Type safety (catching errors of inadequate type) performed at compilation time.\n\nExamples: C, C++, Java, Fortran, Haskell.\n\n\n\n\nType safety performed at runtime.\n\nExamples: Python, JavaScript, PHP, Ruby, Lisp.\n\n\n\n\n\nJulia type system is dynamic (types are unknown until runtime), but types can be declared, optionally bringing the advantages of static type systems.\nThis gives users the freedom to choose between an easy and convenient language, or a clearer, faster, and more robust one (or a combination of the two).",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Types"
    ]
  },
  {
    "objectID": "julia/intro_types.html#types-systems",
    "href": "julia/intro_types.html#types-systems",
    "title": "Types",
    "section": "",
    "text": "Type safety (catching errors of inadequate type) performed at compilation time.\n\nExamples: C, C++, Java, Fortran, Haskell.\n\n\n\n\nType safety performed at runtime.\n\nExamples: Python, JavaScript, PHP, Ruby, Lisp.\n\n\n\n\n\nJulia type system is dynamic (types are unknown until runtime), but types can be declared, optionally bringing the advantages of static type systems.\nThis gives users the freedom to choose between an easy and convenient language, or a clearer, faster, and more robust one (or a combination of the two).",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Types"
    ]
  },
  {
    "objectID": "julia/intro_types.html#julia-types-a-hierarchical-tree",
    "href": "julia/intro_types.html#julia-types-a-hierarchical-tree",
    "title": "Types",
    "section": "Julia types: a hierarchical tree",
    "text": "Julia types: a hierarchical tree\nAt the bottom: ‚ÄÉconcrete types.\nAbove: ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉabstract types (concepts for collections of concrete types).\nAt the top: ‚ÄÉ‚ÄÉ‚ÄÇ¬†the Any type, encompassing all types.\n\n\n\nfrom O‚ÄôReilly\n\n\nOne common type missing in this diagram is the boolean type.\nIt is a subtype of the integer type, as can be tested with the subtype operator &lt;:\n\nBool &lt;: Integer\n\ntrue\n\n\nIt can also be made obvious by the following:\n\nfalse == 0\n\ntrue\n\n\n\ntrue == 1\n\ntrue\n\n\n\na = true;\nb = false;\n3a + 2b\n\n3",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Types"
    ]
  },
  {
    "objectID": "julia/intro_types.html#optional-type-declaration",
    "href": "julia/intro_types.html#optional-type-declaration",
    "title": "Types",
    "section": "Optional type declaration",
    "text": "Optional type declaration\nDone with ::\n&lt;value&gt;::&lt;type&gt;\n\nExample:\n\n\n2::Int\n\n2",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Types"
    ]
  },
  {
    "objectID": "julia/intro_types.html#illustration-of-type-safety",
    "href": "julia/intro_types.html#illustration-of-type-safety",
    "title": "Types",
    "section": "Illustration of type safety",
    "text": "Illustration of type safety\nThis works:\n\n2::Int\n\n2\n\n\nThis doesn‚Äôt work:\n\n2.0::Int\n\n\nTypeError: in typeassert, expected Int64, got a value of type Float64\nStacktrace:\n [1] top-level scope\n   @ ~/parvus/prog/mint/julia/intro_types.qmd:99\n\n\n\nType declaration is not yet supported on global variables; this is used in local contexts such as inside a function.\n\nExample:\n\n\nfunction floatsum(a, b)\n    (a + b)::Float64\nend\n\nfloatsum (generic function with 1 method)\n\n\nThis works:\n\nfloatsum(2.3, 1.0)\n\n3.3\n\n\nThis doesn‚Äôt work:\n\nfloatsum(2, 4)\n\n\nTypeError: in typeassert, expected Float64, got a value of type Int64\nStacktrace:\n [1] floatsum(a::Int64, b::Int64)\n   @ Main.Notebook ~/parvus/prog/mint/julia/intro_types.qmd:112\n [2] top-level scope\n   @ ~/parvus/prog/mint/julia/intro_types.qmd:125",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Types"
    ]
  },
  {
    "objectID": "julia/intro_types.html#information-and-conversion",
    "href": "julia/intro_types.html#information-and-conversion",
    "title": "Types",
    "section": "Information and conversion",
    "text": "Information and conversion\nThe typeof function gives the type of an object:\n\ntypeof(2)\n\nInt64\n\n\n\ntypeof(2.0)\n\nFloat64\n\n\n\ntypeof(\"Hello, World!\")\n\nString\n\n\n\ntypeof(true)\n\nBool\n\n\n\ntypeof((2, 4, 1.0, \"test\"))\n\nTuple{Int64, Int64, Float64, String}\n\n\nConversion between types is possible in some cases:\n\nInt(2.0)\n\n2\n\n\n\ntypeof(Int(2.0))\n\nInt64\n\n\n\nChar(2.0)\n\n'\\x02': ASCII/Unicode U+0002 (category Cc: Other, control)\n\n\n\ntypeof(Char(2.0))\n\nChar",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Types"
    ]
  },
  {
    "objectID": "julia/intro_types.html#stylistic-convention",
    "href": "julia/intro_types.html#stylistic-convention",
    "title": "Types",
    "section": "Stylistic convention",
    "text": "Stylistic convention\nThe names of types start with a capital letter and camel case is used in multiple-word names.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Types"
    ]
  },
  {
    "objectID": "julia/intro_resources.html",
    "href": "julia/intro_resources.html",
    "title": "Resources",
    "section": "",
    "text": "Here are a couple of Julia resources.\n\n\nDocumentation\n\nOfficial Julia website\nOfficial Julia manual\nAlliance wiki Julia page\nOnline training material\nThe Julia YouTube channel\nThe Julia Wikibook\nA blog aggregator for Julia\n\n\n\nGetting help\n\nDiscourse forum\n[julia] tag on Stack Overflow\nSlack team (you need to agree to the community code of conduct at slackinvite.julialang.org to receive an invitation)\n#julialang hashtag on Twitter\nSubreddit\nGitter channel\n#julia IRC channel on Freenode",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "julia/intro_packages.html",
    "href": "julia/intro_packages.html",
    "title": "Packages",
    "section": "",
    "text": "Julia comes with a collection of packages. In Linux, they are in /usr/share/julia/stdlib/vx.x.\nHere is the list:\nBase64\nCRC32c\nDates\nDelimitedFiles\nDistributed\nFileWatching\nFuture\nInteractiveUtils\nLibdl\nLibGit2\nLinearAlgebra\nLogging\nMarkdown\nMmap\nPkg\nPrintf\nProfile\nRandom\nREPL\nSerialization\nSHA\nSharedArrays\nSockets\nSparseArrays\nStatistics\nSuiteSparse\nTest\nUnicode\nUUIDs",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Packages"
    ]
  },
  {
    "objectID": "julia/intro_packages.html#standard-library",
    "href": "julia/intro_packages.html#standard-library",
    "title": "Packages",
    "section": "",
    "text": "Julia comes with a collection of packages. In Linux, they are in /usr/share/julia/stdlib/vx.x.\nHere is the list:\nBase64\nCRC32c\nDates\nDelimitedFiles\nDistributed\nFileWatching\nFuture\nInteractiveUtils\nLibdl\nLibGit2\nLinearAlgebra\nLogging\nMarkdown\nMmap\nPkg\nPrintf\nProfile\nRandom\nREPL\nSerialization\nSHA\nSharedArrays\nSockets\nSparseArrays\nStatistics\nSuiteSparse\nTest\nUnicode\nUUIDs",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Packages"
    ]
  },
  {
    "objectID": "julia/intro_packages.html#installing-additional-packages",
    "href": "julia/intro_packages.html#installing-additional-packages",
    "title": "Packages",
    "section": "Installing additional packages",
    "text": "Installing additional packages\nYou can install additional packages.\nThese go to your personal library in ~/.julia (this is also where your REPL history is saved).\nAll registered packages are on GitHub and can easily be searched here.\nThe GitHub star system allows you to easily judge the popularity of a package and to see whether it is under current development.\nIn addition to these, there are unregistered packages and you can build your own.\n\n\nYour turn:\n\nTry to find a list of popular plotting packages.\n\nYou can manage your personal library easily in package mode with the commands:\n(env) pkg&gt; add &lt;package&gt;   # install &lt;package&gt;\n(env) pkg&gt; rm &lt;package&gt;    # uninstall &lt;package&gt;\n(env) pkg&gt; up &lt;package&gt;    # upgrade &lt;package&gt;\n(env) pkg&gt; st              # st or status: list installed packages\n(env) pkg&gt; up              # up or upgrade: upgrade all packages\n\nReplace &lt;package&gt; by the name of the package (e.g.¬†Plots ).\n\nYou can install, uninstall, or update several packages at once by listing them with a space:\n(env) pkg&gt; add &lt;package1&gt; &lt;package2&gt; &lt;package3&gt;\nAn alternative to this convenience mode is to load the package manager (package Pkg, part of stdlib) and use it as you would any other package:\nusing Pkg\n\nPkg.add(\"&lt;package&gt;\")        # install &lt;package&gt;\nPkg.rm(\"&lt;package&gt;\")         # uninstall &lt;package&gt;\nPkg.status(\"&lt;package&gt;\")     # status of &lt;package&gt;\nPkg.update(\"&lt;package&gt;\")     # update &lt;package&gt;\nPkg.update()                # status of all installed packages\nPkg.status()                # update all packages\n\nThe short forms up and st do not work in this context.\n\nTo install, uninstall, or update several packages at once in this context, you need to create an array:\nPkg.add([\"&lt;package1&gt;\", \"&lt;package2&gt;\", \"&lt;package3&gt;\"])\n\n\nYour turn:\n\nCheck your list of packages; install the packages Plots, GR, Distributions, StatsPlots, and UnicodePlot; then check that list again.\n\n\n\nYour turn:\n\nNow go explore your ~/.julia. If you don‚Äôt find it, make sure that your file explorer allows you to see hidden files.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Packages"
    ]
  },
  {
    "objectID": "julia/intro_packages.html#loading-packages",
    "href": "julia/intro_packages.html#loading-packages",
    "title": "Packages",
    "section": "Loading packages",
    "text": "Loading packages\nWhether a package from the standard library or one you installed, before you can use a package you need to load it. This has to be done at each new Julia session so the code to load packages should be part of your scripts.\nThis is done with the using command (e.g.¬†using Plots).",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Packages"
    ]
  },
  {
    "objectID": "julia/intro_macros.html",
    "href": "julia/intro_macros.html",
    "title": "Macros",
    "section": "",
    "text": "Julia code is itself data and can be manipulated by the language while it is running.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Macros"
    ]
  },
  {
    "objectID": "julia/intro_macros.html#metaprogramming",
    "href": "julia/intro_macros.html#metaprogramming",
    "title": "Macros",
    "section": "Metaprogramming",
    "text": "Metaprogramming\n\nLarge influence from Lisp.\nSince Julia is entirely written in Julia, it is particularly well suited for metaprogramming.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Macros"
    ]
  },
  {
    "objectID": "julia/intro_macros.html#parsing-and-evaluating",
    "href": "julia/intro_macros.html#parsing-and-evaluating",
    "title": "Macros",
    "section": "Parsing and evaluating",
    "text": "Parsing and evaluating\nLet‚Äôs start with something simple:\n\n2 + 3\n\n5\n\n\nHow is this run internally?\nThe string \"2 + 3\" gets parsed into an expression:\n\nMeta.parse(\"2 + 3\")\n\n:(2 + 3)\n\n\nThen that expression gets evaluated:\n\neval(Meta.parse(\"2 + 3\"))\n\n5",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Macros"
    ]
  },
  {
    "objectID": "julia/intro_macros.html#macros",
    "href": "julia/intro_macros.html#macros",
    "title": "Macros",
    "section": "Macros",
    "text": "Macros\nThey resemble functions and just like functions, they accept as input a tuple of arguments.\nBUT macros return an expression which is compiled directly rather than requiring a runtime eval call.\nSo they execute before the rest of the code is run.\nMacro‚Äôs names are preceded by @ (e.g.¬†@time).\nJulia comes with many macros and you can create your own with:\nmacro &lt;name&gt;()\n    &lt;body&gt;\nend",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Macros"
    ]
  },
  {
    "objectID": "julia/intro_macros.html#stylistic-conventions",
    "href": "julia/intro_macros.html#stylistic-conventions",
    "title": "Macros",
    "section": "Stylistic conventions",
    "text": "Stylistic conventions\nAs with functions, Julia suggests to use lower case, without underscores, as macro names.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Macros"
    ]
  },
  {
    "objectID": "julia/intro_functions.html",
    "href": "julia/intro_functions.html",
    "title": "Functions",
    "section": "",
    "text": "Functions are objects containing a set of instructions.\nWhen you pass a tuple of argument(s) (possibly an empty tuple) to them, you get one or more values as output.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Functions"
    ]
  },
  {
    "objectID": "julia/intro_functions.html#operators",
    "href": "julia/intro_functions.html#operators",
    "title": "Functions",
    "section": "Operators",
    "text": "Operators\nOperators are functions and can be written in a way that shows the tuple of arguments more explicitly.\n\nFor instance, you can use the addition operator (+) in 2 ways:\n\n\n3 + 2\n+(3, 2)\n\n5\n\n\nThe multiplication operator can be omitted when this does not create any ambiguity:\n\na = 3;\n2a\n\n6\n\n\nJulia has ‚Äúassignment by operation‚Äù operators:\n\na = 2;\na += 7    # this is the same as a = a + 7\n\n9\n\n\nThere is a left division operator:\n\n2\\8 == 8/2\n\ntrue\n\n\nJulia supports fraction operations:\n\n4//8\n\n1//2\n\n\n\n1//2 + 3//4\n\n5//4",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Functions"
    ]
  },
  {
    "objectID": "julia/intro_functions.html#function-definition",
    "href": "julia/intro_functions.html#function-definition",
    "title": "Functions",
    "section": "Function definition",
    "text": "Function definition\nThere are 2 ways to define a new function:\n\nLong form\nfunction &lt;name&gt;(&lt;arguments&gt;)\n    &lt;body&gt;\nend\n\nExample:\n\n\nfunction hello1()\n    println(\"Hello\")\nend\n\nhello1 (generic function with 1 method)\n\n\n\n\nAssignment form\n&lt;name&gt;(&lt;arguments&gt;) = &lt;body&gt;\n\nExample:\n\n\nhello1() = println(\"Hello\")\n\nhello1 (generic function with 1 method)\n\n\nThe function hello1 defined with this terse syntax is exactly the same as the one we defined above.\n\n\nStylistic convention\nJulia suggests to use lower case without underscores as function names when the name is readable enough.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Functions"
    ]
  },
  {
    "objectID": "julia/intro_functions.html#calling-functions",
    "href": "julia/intro_functions.html#calling-functions",
    "title": "Functions",
    "section": "Calling functions",
    "text": "Calling functions\nSince you pass a tuple to a function when you run it, you call a function by appending parentheses to its name:\n\nhello1()\n\nHello\n\n\n\nHere, our function does not take any argument, so the tuple is empty.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Functions"
    ]
  },
  {
    "objectID": "julia/intro_functions.html#arguments",
    "href": "julia/intro_functions.html#arguments",
    "title": "Functions",
    "section": "Arguments",
    "text": "Arguments\n\nNo argument\nOur function hello1 does not accept any argument. If we pass an argument, we get an error message:\nhello1(\"Bob\")\nLoadError: MethodError: no method matching hello1(::String)\n\n\nOne argument\nTo define a function which accepts an argument, we need to add a placeholder for it in the function definition.\n\nSo let‚Äôs try this:\n\n\nfunction hello2(name)\n    println(\"Hello name\")\nend\n\nhello2 (generic function with 1 method)\n\n\n\nhello2(\"Bob\")\n\nHello name\n\n\nMmm ‚Ä¶ not quite ‚Ä¶ this function works but does not give the result we wanted.\nHere, we need to use string interpolation:\n\nfunction hello3(name)\n    println(\"Hello $name\")\nend\n\nhello3 (generic function with 1 method)\n\n\n$name in the body of the function points to name in the tuple of argument.\nWhen we run the function, $name is replaced by the value we used in lieu of name in the function definition:\n\nhello3(\"Bob\")\n\nHello Bob\n\n\nHere is the corresponding assignment form for hello3:\n\nhello3(name) = println(\"Hello $name\")\n\nhello3 (generic function with 1 method)\n\n\n\nNote that this dollar sign is only required with strings. Here is an example with integers:\n\n\nfunction addTwo(a)\n    a + 2\nend\n\naddTwo (generic function with 1 method)\n\n\nAnd the corresponding assignment form:\n\naddTwo(a) = a + 2\n\naddTwo (generic function with 1 method)\n\n\n\naddTwo(4)\n\n6\n\n\n\n\nMultiple arguments\nNow, let‚Äôs write a function which accepts 2 arguments. For this, we put 2 placeholders in the tuple passed to the function in the function definition:\n\nfunction hello4(name1, name2)\n    println(\"Hello $name1 and $name2\")\nend\n\nhello4 (generic function with 1 method)\n\n\nThis means that this function expects a tuple of 2 values:\n\nhello4(\"Bob\", \"Pete\")\n\nHello Bob and Pete\n\n\n\n\nYour turn:\n\nSee what happens when you pass no argument, a single argument, or three arguments to this function.\n\n\n\nDefault arguments\nYou can set a default value for some or all arguments. In this case, the function will run with or without a value passed for those arguments. If no value is given, the default is used. If a value is given, it will replace the default.\n\nExample:\n\n\nfunction hello5(name=\"\")\n    println(\"Hello $name\")\nend\n\nhello5 (generic function with 2 methods)\n\n\n\nhello5()\n\nHello \n\n\n\nhello5(\"Bob\")\n\nHello Bob\n\n\n\nAnother example:\n\n\nfunction addSomethingOrTwo(a, b=2)\n    a + b\nend\n\naddSomethingOrTwo (generic function with 2 methods)\n\n\n\naddSomethingOrTwo(3)\n\n5\n\n\n\naddSomethingOrTwo(3, 4)\n\n7",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Functions"
    ]
  },
  {
    "objectID": "julia/intro_functions.html#returning-the-result",
    "href": "julia/intro_functions.html#returning-the-result",
    "title": "Functions",
    "section": "Returning the result",
    "text": "Returning the result\nIn Julia, functions return the value(s) of the last expression automatically. If you want to return something else instead, you need to use the return statement. This causes the function to exit early.\n\nLook at these 5 functions:\n\nfunction test1(x, y)\n    x + y\nend\n\nfunction test2(x, y)\n    return x + y\nend\n\nfunction test3(x, y)\n    x * y\n    x + y\nend\n\nfunction test4(x, y)\n    return x * y\n    x + y\nend\n\nfunction test5(x, y)\n    return x * y\n    return x + y\nend\n\nfunction test6(x, y)\n    x * y, x + y\nend\n\n\nYour turn:\n\nWithout running the code, try to guess the outputs of:\n\ntest1(1, 2)\ntest2(1, 2)\ntest3(1, 2)\ntest4(1, 2)\ntest5(1, 2)\ntest6(1, 2)\n\n\nYour turn:\n\nNow, run the code and draw some conclusions on the behaviour of the return statement.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Functions"
    ]
  },
  {
    "objectID": "julia/intro_functions.html#anonymous-functions",
    "href": "julia/intro_functions.html#anonymous-functions",
    "title": "Functions",
    "section": "Anonymous functions",
    "text": "Anonymous functions\nAnonymous functions are functions which aren‚Äôt given a name:\nfunction (&lt;arguments&gt;)\n    &lt;body&gt;\nend\nIn compact form:\n&lt;arguments&gt; -&gt; &lt;body&gt;\n\nExample:\n\n\nfunction (name)\n    println(\"Hello $name\")\nend\n\n#13 (generic function with 1 method)\n\n\nCompact form:\n\nname -&gt; println(\"Hello $name\")\n\n#15 (generic function with 1 method)\n\n\n\nWhen would you want to use anonymous functions?\nThis is very useful for functional programming (when you apply a function‚Äîfor instance map‚Äîto other functions to apply them in a vectorized manner which avoids repetitions).\n\nExample:\n\n\nmap(name -&gt; println(\"Hello $name\"), [\"Bob\", \"Lucie\", \"Sophie\"]);\n\nHello Bob\nHello Lucie\nHello Sophie",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Functions"
    ]
  },
  {
    "objectID": "julia/intro_functions.html#pipes",
    "href": "julia/intro_functions.html#pipes",
    "title": "Functions",
    "section": "Pipes",
    "text": "Pipes\n|&gt; is the pipe in Julia. It redirects the output of the expression on the left as the input of the expression on the right.\n\nThe following 2 expressions are equivalent:\n\nprintln(\"Hello\")\n\"Hello\" |&gt; println\n\nHere is another example:\n\n\nsqrt(2) == 2 |&gt; sqrt\n\ntrue",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Functions"
    ]
  },
  {
    "objectID": "julia/intro_functions.html#function-composition",
    "href": "julia/intro_functions.html#function-composition",
    "title": "Functions",
    "section": "Function composition",
    "text": "Function composition\nYou can pass a function inside another function:\n&lt;function2&gt;(&lt;function1&gt;(&lt;arguments&gt;))\n&lt;arguments&gt; will be passed to &lt;function1&gt; and the result will then be passed to &lt;function2&gt;.\nAn equivalent syntax is to use the composition operator ‚àò (in the REPL, type \\circ then press tab):\n(&lt;function2&gt; ‚àò &lt;function1&gt;)(&lt;arguments&gt;)\n\nExample:\n\n\n# sum is our first function\nsum(1:3)\n\n6\n\n\n\n# sqrt is the second function\nsqrt(sum(1:3))\n\n2.449489742783178\n\n\n\n# This is equivalent\n(sqrt ‚àò sum)(1:3)\n\n2.449489742783178\n\n\n\n\nYour turn:\n\nWrite three other equivalent expressions using the pipe.\n\n\nAnother example:\n\n\nexp(+(-3, 1))\n\n(exp ‚àò +)(-3, 1)\n\n0.1353352832366127\n\n\n\n\nYour turn:\n\nTry to write the same expression in another 2 different ways.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Functions"
    ]
  },
  {
    "objectID": "julia/intro_functions.html#mutating-functions",
    "href": "julia/intro_functions.html#mutating-functions",
    "title": "Functions",
    "section": "Mutating functions",
    "text": "Mutating functions\nFunctions usually do not modify their argument(s):\n\na = [-2, 3, -5]\n\n3-element Vector{Int64}:\n -2\n  3\n -5\n\n\n\nsort(a)\n\n3-element Vector{Int64}:\n -5\n -2\n  3\n\n\n\na\n\n3-element Vector{Int64}:\n -2\n  3\n -5\n\n\nJulia has a set of functions which modify their argument(s). By convention, their names end with !\n\nThe function sort has a mutating equivalent sort!:\n\n\nsort!(a);\na\n\n3-element Vector{Int64}:\n -5\n -2\n  3\n\n\n\nIf you write functions which modify their arguments, make sure to follow this convention too.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Functions"
    ]
  },
  {
    "objectID": "julia/intro_functions.html#broadcasting",
    "href": "julia/intro_functions.html#broadcasting",
    "title": "Functions",
    "section": "Broadcasting",
    "text": "Broadcasting\nTo apply a function to each element of a collection rather than to the collection as a whole, Julia uses broadcasting.\n\nLet‚Äôs create a collection (here a tuple):\n\n\na = (2, 3)\n\n(2, 3)\n\n\n\nIf we pass a to the string function, that function applies to the whole collection:\n\n\nstring(a)\n\n\"(2, 3)\"\n\n\n\nIn contrast, we can broadcast the function string to all elements of a:\n\n\nbroadcast(string, a)\n\n(\"2\", \"3\")\n\n\n\nAn alternative syntax is to add a period after the function name:\n\n\nstring.(a)\n\n(\"2\", \"3\")\n\n\n\nHere is another example:\n\na = [-3, 2, -5]\nabs(a)\nERROR: MethodError: no method matching abs(::Array{Int64,1})\nThis doesn‚Äôt work because the function abs only applies to single elements.\nBy broadcasting abs, you apply it to each element of a:\n\nbroadcast(abs, a)\n\n(2, 3)\n\n\nThe dot notation is equivalent:\n\nabs.(a)\n\n(2, 3)\n\n\nIt can also be applied to the pipe, to unary and binary operators, etc.\n\nExample:\n\n\na .|&gt; abs\n\n(2, 3)\n\n\n\n\nYour turn:\n\nTry to understand the difference between the following 2 expressions:\n\n\nabs.(a) == a .|&gt; abs\nabs.(a) .== a .|&gt; abs\n\n(true, true)",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Functions"
    ]
  },
  {
    "objectID": "julia/intro_functions.html#multiple-dispatch",
    "href": "julia/intro_functions.html#multiple-dispatch",
    "title": "Functions",
    "section": "Multiple dispatch",
    "text": "Multiple dispatch\nIn some programming languages, functions can be polymorphic (multiple versions exist under the same function name). The process of selecting which version to use is called dispatch.\nThere are multiple types of dispatch depending on the language:\n\nDynamic dispatch: the process of selecting one version of a function at run time.\nSingle dispatch: the choice of version is based on a single object.\n\n\nThis is typical of object-oriented languages such as Python, C++, Java, Smalltalk, etc.\n\n\nMultiple dispatch: the choice of version is based on the combination of all operands and their types.\n\n\nThis the case of Lisp and Julia. In Julia, these versions are called methods.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Functions"
    ]
  },
  {
    "objectID": "julia/intro_functions.html#methods",
    "href": "julia/intro_functions.html#methods",
    "title": "Functions",
    "section": "Methods",
    "text": "Methods\nRunning methods(+) let‚Äôs you see that the function + has 206 methods!\nMethods can be added to existing functions.\n\n\nYour turn:\n\nRun the following and try to understand the outputs:\nabssum(x::Int64, y::Int64) = abs(x + y)\nabssum(x::Float64, y::Float64) = abs(x + y)\n\nabssum(2, 4)\nabssum(2.0, 4.0)\nabssum(2, 4.0)\nWhat could you do if you wanted the last expression to work?",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Functions"
    ]
  },
  {
    "objectID": "julia/intro_collections.html",
    "href": "julia/intro_collections.html",
    "title": "Collections",
    "section": "",
    "text": "Values can be stored in collections. This workshop introduces tuples, dictionaries, sets, and arrays in Julia.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Collections"
    ]
  },
  {
    "objectID": "julia/intro_collections.html#tuples",
    "href": "julia/intro_collections.html#tuples",
    "title": "Collections",
    "section": "Tuples",
    "text": "Tuples\nTuples are immutable, indexable, and possibly heterogeneous collections of elements. The order of elements matters.\n\n# Possibly heterogeneous (values can be of different types)\ntypeof((2, 'a', 1.0, \"test\"))\n\nTuple{Int64, Char, Float64, String}\n\n\n\n# Indexable (note that indexing in Julia starts with 1)\nx = (2, 'a', 1.0, \"test\");\nx[3]\n\n1.0\n\n\n\n# Immutable (they cannot be modified)\n# So this returns an error\nx[3] = 8\n\nLoadError: MethodError: no method matching setindex!(::Tuple{Int64, Char, Float64, String}, ::Int64, ::Int64)\nMethodError: no method matching setindex!(::Tuple{Int64, Char, Float64, String}, ::Int64, ::Int64)\n\nStacktrace:\n [1] top-level scope\n   @ In[4]:3\n\n\n\nNamed tuples\nTuples can have named components:\n\ntypeof((a=2, b='a', c=1.0, d=\"test\"))\n\n@NamedTuple{a::Int64, b::Char, c::Float64, d::String}\n\n\n\nx = (a=2, b='a', c=1.0, d=\"test\");\nx.c\n\n1.0",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Collections"
    ]
  },
  {
    "objectID": "julia/intro_collections.html#dictionaries",
    "href": "julia/intro_collections.html#dictionaries",
    "title": "Collections",
    "section": "Dictionaries",
    "text": "Dictionaries\nJulia also has dictionaries: associative collections of key/value pairs:\n\nx = Dict(\"Name\"=&gt;\"Roger\", \"Age\"=&gt;52, \"Index\"=&gt;0.3)\n\nDict{String, Any} with 3 entries:\n  \"Index\" =&gt; 0.3\n  \"Age\"   =&gt; 52\n  \"Name\"  =&gt; \"Roger\"\n\n\n\"Name\", \"Age\", and \"Index\" are the keys; \"Roger\", 52, and 0.3 are the values.\nThe =&gt; operator is the same as the Pair function:\n\np = \"foo\" =&gt; 7\n\n\"foo\" =&gt; 7\n\n\n\nq = Pair(\"bar\", 8)\n\n\"bar\" =&gt; 8\n\n\nDictionaries can be heterogeneous (as in this example) and the order doesn‚Äôt matter. They are also indexable:\n\nx[\"Name\"]\n\n\"Roger\"\n\n\nAnd mutable (they can be modified):\n\nx[\"Name\"] = \"Alex\";\nx\n\nDict{String, Any} with 3 entries:\n  \"Index\" =&gt; 0.3\n  \"Age\"   =&gt; 52\n  \"Name\"  =&gt; \"Alex\"",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Collections"
    ]
  },
  {
    "objectID": "julia/intro_collections.html#sets",
    "href": "julia/intro_collections.html#sets",
    "title": "Collections",
    "section": "Sets",
    "text": "Sets\nSets are collections without duplicates. The order of elements doesn‚Äôt matter.\n\nset1 = Set([9, 4, 8, 2, 7, 8])\n\nSet{Int64} with 5 elements:\n  4\n  7\n  2\n  9\n  8\n\n\n\nNotice how this is a set of 5 (and not 6) elements: the duplicated 8 didn‚Äôt matter.\n\n\nset2 = Set([10, 2, 3])\n\nSet{Int64} with 3 elements:\n  2\n  10\n  3\n\n\nYou can compare sets:\n\n# The union is the set of elements that are in one OR the other set\nunion(set1, set2)\n\nSet{Int64} with 7 elements:\n  4\n  7\n  2\n  10\n  9\n  8\n  3\n\n\n\n# The intersect is the set of elements that are in one AND the other set\nintersect(set1, set2)\n\nSet{Int64} with 1 element:\n  2\n\n\n\n# The setdiff is the set of elements that are in the first set but not in the second\n# Note that the order matters here\nsetdiff(set1, set2)\n\nSet{Int64} with 4 elements:\n  4\n  7\n  9\n  8\n\n\nSets can be heterogeneous:\n\nSet([\"test\", 9, :a])\n\nSet{Any} with 3 elements:\n  :a\n  \"test\"\n  9",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Collections"
    ]
  },
  {
    "objectID": "julia/intro_collections.html#arrays",
    "href": "julia/intro_collections.html#arrays",
    "title": "Collections",
    "section": "Arrays",
    "text": "Arrays\n\nVectors\nUnidimensional arrays in Julia are called vectors.\n\nVectors of one element\n\n[3]\n\n1-element Vector{Int64}:\n 3\n\n\n\n[3.4]\n\n1-element Vector{Float64}:\n 3.4\n\n\n\n[\"Hello, World!\"]\n\n1-element Vector{String}:\n \"Hello, World!\"\n\n\n\n\nVectors of multiple elements\n\n[3, 4]\n\n2-element Vector{Int64}:\n 3\n 4\n\n\n\n\n\nTwo dimensional arrays\n\n[3 4]\n\n1√ó2 Matrix{Int64}:\n 3  4\n\n\n\n[[1, 3] [1, 2]]\n\n2√ó2 Matrix{Int64}:\n 1  1\n 3  2\n\n\n\n\nSyntax subtleties\nThese 3 syntaxes are equivalent:\n\n[2 4 8]\n\n1√ó3 Matrix{Int64}:\n 2  4  8\n\n\n\nhcat(2, 4, 8)\n\n1√ó3 Matrix{Int64}:\n 2  4  8\n\n\n\ncat(2, 4, 8, dims=2)\n\n1√ó3 Matrix{Int64}:\n 2  4  8\n\n\nThese 4 syntaxes are equivalent:\n\n[2\n 4\n 8]\n\n3-element Vector{Int64}:\n 2\n 4\n 8\n\n\n\n[2; 4; 8]\n\n3-element Vector{Int64}:\n 2\n 4\n 8\n\n\n\nvcat(2, 4, 8)\n\n3-element Vector{Int64}:\n 2\n 4\n 8\n\n\n\ncat(2, 4, 8, dims=1)\n\n3-element Vector{Int64}:\n 2\n 4\n 8\n\n\nElements separated by semi-colons or end of lines get expanded vertically.\nThose separated by commas do not get expanded.\nElements separated by spaces or tabs get expanded horizontally.\n\n\nYour turn:\n\nCompare the outputs of the following:\n\n\n[1:2; 3:4]\n\n4-element Vector{Int64}:\n 1\n 2\n 3\n 4\n\n\n\n[1:2\n 3:4]\n\n4-element Vector{Int64}:\n 1\n 2\n 3\n 4\n\n\n\n[1:2, 3:4]\n\n2-element Vector{UnitRange{Int64}}:\n 1:2\n 3:4\n\n\n\n[1:2 3:4]\n\n2√ó2 Matrix{Int64}:\n 1  3\n 2  4\n\n\n\n\nArrays and types\nIn Julia, arrays can be heterogeneous:\n\n[3, \"hello\"]\n\n2-element Vector{Any}:\n 3\n  \"hello\"\n\n\nThis is possible because all elements of an array, no matter of what types, will always sit below the Any type in the type hierarchy.\n\n\nInitializing arrays\nBelow are examples of some of the functions initializing arrays:\n\nrand(2, 3, 4)\n\n2√ó3√ó4 Array{Float64, 3}:\n[:, :, 1] =\n 0.70497   0.452224  0.210217\n 0.152121  0.808499  0.748643\n\n[:, :, 2] =\n 0.964218  0.533504  0.295138\n 0.530122  0.705078  0.448783\n\n[:, :, 3] =\n 0.101024  0.702216  0.351094\n 0.451474  0.643441  0.193529\n\n[:, :, 4] =\n 0.365804  0.593161  0.213761\n 0.908817  0.669264  0.160509\n\n\n\nrand(Int64, 2, 3, 4)\n\n2√ó3√ó4 Array{Int64, 3}:\n[:, :, 1] =\n  -808940715765468093  -1584927078315600374  -5301199987516324173\n -6596392331988765638  -6192885842242193678   1889096344742778536\n\n[:, :, 2] =\n -1263311441971715837   -398863679696473412    425946792632171343\n -8887634749817674030  -6532441838130849674  -5790650878322099032\n\n[:, :, 3] =\n -3504949663976209361  -7056126120819890696   9014204101180695865\n  5444915959299197671   7453311557699154449  -7332672815187269775\n\n[:, :, 4] =\n -1027239353605623832  8546329529560148599  5006263260814316361\n  3614836023227257818  -380255779183739001  9031894209972587885\n\n\n\nzeros(Int64, 2, 5)\n\n2√ó5 Matrix{Int64}:\n 0  0  0  0  0\n 0  0  0  0  0\n\n\n\nones(2, 5)\n\n2√ó5 Matrix{Float64}:\n 1.0  1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0  1.0\n\n\n\nreshape([1, 2, 4, 2], (2, 2))\n\n2√ó2 Matrix{Int64}:\n 1  4\n 2  2\n\n\n\nfill(\"test\", (2, 2))\n\n2√ó2 Matrix{String}:\n \"test\"  \"test\"\n \"test\"  \"test\"\n\n\n\n\nBroadcasting\nTo apply a function to each element of a collection rather than to the collection as a whole, Julia uses broadcasting.\n\na = [-3, 2, -5]\n\n3-element Vector{Int64}:\n -3\n  2\n -5\n\n\nabs(a)\nLoadError: MethodError: no method matching abs(::Vector{Int64})\nThis doesn‚Äôt work because the function abs only applies to single elements.\nBy broadcasting abs, you apply it to each element of a:\n\nbroadcast(abs, a)\n\n3-element Vector{Int64}:\n 3\n 2\n 5\n\n\nThe dot notation is equivalent:\n\nabs.(a)\n\n3-element Vector{Int64}:\n 3\n 2\n 5\n\n\nIt can also be applied to the pipe, to unary and binary operators, etc.\n\na .|&gt; abs\n\n3-element Vector{Int64}:\n 3\n 2\n 5\n\n\n\n\nYour turn:\n\nTry to understand the difference between the following 2 expressions:\n\n\nabs.(a) == a .|&gt; abs\n\ntrue\n\n\n\nabs.(a) .== a .|&gt; abs\n\n3-element BitVector:\n 1\n 1\n 1\n\n\n\nHint: 0/1 are a short-form notations for false/true in arrays of Booleans.\n\n\n\nComprehensions\nJulia has an array comprehension syntax similar to Python‚Äôs:\n\n[ 3i + j for i=1:10, j=3 ]\n\n10-element Vector{Int64}:\n  6\n  9\n 12\n 15\n 18\n 21\n 24\n 27\n 30\n 33",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Collections"
    ]
  },
  {
    "objectID": "julia/intro_collections.html#indexing",
    "href": "julia/intro_collections.html#indexing",
    "title": "Collections",
    "section": "Indexing",
    "text": "Indexing\nAs in other mathematically oriented languages such as R, Julia starts indexing at 1.\nIndexing is done with square brackets:\n\na = [1 2; 3 4]\n\n2√ó2 Matrix{Int64}:\n 1  2\n 3  4\n\n\n\na[1, 1]\n\n1\n\n\n\na[1, :]\n\n2-element Vector{Int64}:\n 1\n 2\n\n\n\na[:, 1]\n\n2-element Vector{Int64}:\n 1\n 3\n\n\n\n# Here, we are indexing a tuple\n(2, 4, 1.0, \"test\")[2]\n\n4\n\n\n\n\nYour turn:\n\nIndex the element on the 3rd row and 2nd column of b:\n\nb = [\"wrong\" \"wrong\" \"wrong\"; \"wrong\" \"wrong\" \"wrong\"; \"wrong\" \"you got it\" \"wrong\"]\n\n3√ó3 Matrix{String}:\n \"wrong\"  \"wrong\"       \"wrong\"\n \"wrong\"  \"wrong\"       \"wrong\"\n \"wrong\"  \"you got it\"  \"wrong\"\n\n\n\n\n\nYour turn:\n\na = [1 2; 3 4]\na[1, 1]\na[1, :]\nHow can I get the second column?\nHow can I get the tuple (2, 4)? (a tuple is a list of elements)\n\nAs in Python, by default, arrays are passed by sharing:\n\na = [1, 2, 3];\na[1] = 0;\na\n\n3-element Vector{Int64}:\n 0\n 2\n 3\n\n\nThis prevents the unwanted copying of arrays.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Collections"
    ]
  },
  {
    "objectID": "julia/index.html",
    "href": "julia/index.html",
    "title": "Julia",
    "section": "",
    "text": "Getting started with ¬†\nAn intro course to Julia\n\n\n\n\nHigh-performance ¬†\nAn HPC course on Julia\n\n\n\n\n\n\n60 min webinars\nVarious Julia topics",
    "crumbs": [
      "Julia",
      "<br>&nbsp;<img src=\"img/logo_julia.png\" class=\"img-fluid\" style=\"width:1.65em\" alt=\"noshadow\"><br><br>"
    ]
  },
  {
    "objectID": "julia/hpc_multithreading.html",
    "href": "julia/hpc_multithreading.html",
    "title": "Multi-threading",
    "section": "",
    "text": "Julia, which was built with efficiency in mind, aimed from the start to have parallel programming abilities. These however came gradually: first, there were coroutines, which is not parallel programming, but allows independent executions of elements of code; then there was a macro allowing for loops to run on several cores, but this would not work on nested loops and it did not integrate with the coroutines or I/O. With version 1.3 however multi-threading capabilities were born.\nWhat is great about Julia‚Äôs new task parallelism is that it is incredibly easy to use: no need to write low-level code as with MPI to set where tasks are run. Everything is automatic.",
    "crumbs": [
      "Julia",
      "<b><em>High-performance Julia</em></b>",
      "Multi-threading"
    ]
  },
  {
    "objectID": "julia/hpc_multithreading.html#launching-julia-on-multiple-threads",
    "href": "julia/hpc_multithreading.html#launching-julia-on-multiple-threads",
    "title": "Multi-threading",
    "section": "Launching Julia on multiple threads",
    "text": "Launching Julia on multiple threads\nTo use Julia with multiple threads, we need to launch julia with the JULIA_NUM_THREADS environment variable or with the flag --threads/-t:\n$ JULIA_NUM_THREADS=n julia\nor\n$ julia -t n\nFirst, we need to know how many threads we actually have on our machine.\nThere are many Linux tools for this, but here are two particularly convenient options:\n# To get the total number of available processes\n$ nproc\n\n# For more information (# of sockets, cores per socket, threads per core)\n$ lscpu | grep -E '(S|s)ocket|Thread|^CPU\\(s\\)'\nSince I have 4 available processes (2 cores with 2 threads each), I can launch Julia on 4 threads:\n$ JULIA_NUM_THREADS=4 julia\nThis can also be done from within the Juno IDE.\nTo see how many threads we are using, as well as the ID of the current thread, you can run:\nThreads.nthreads()\nThreads.threadid()",
    "crumbs": [
      "Julia",
      "<b><em>High-performance Julia</em></b>",
      "Multi-threading"
    ]
  },
  {
    "objectID": "julia/hpc_multithreading.html#for-loops-on-multiple-threads",
    "href": "julia/hpc_multithreading.html#for-loops-on-multiple-threads",
    "title": "Multi-threading",
    "section": "For loops on multiple threads",
    "text": "For loops on multiple threads\n\n\nYour turn:\n\nLaunch Julia on 1 thread and run the function below. Then run Julia on the maximum number of threads you have on your machine and run the same function.\n\nThreads.@threads for i = 1:10\n    println(\"i = $i on thread $(Threads.threadid())\")\nend\nUtilities such as htop allow you to visualize the working threads.",
    "crumbs": [
      "Julia",
      "<b><em>High-performance Julia</em></b>",
      "Multi-threading"
    ]
  },
  {
    "objectID": "julia/hpc_multithreading.html#generalization-of-multi-threading",
    "href": "julia/hpc_multithreading.html#generalization-of-multi-threading",
    "title": "Multi-threading",
    "section": "Generalization of multi-threading",
    "text": "Generalization of multi-threading\nLet‚Äôs consider the example presented in a Julia blog post in July 2019.\nBoth scripts sort a one dimensional array of 20,000,000 floats between 0 and 1, one with parallelism and one without.\nScript 1, without parallelism: sort.jl.\n# Create one dimensional array of 20,000,000 floats between 0 and 1\na = rand(20000000);\n\n# Use the MergeSort algorithm of the sort function\n# (in the standard Julia Base library)\nb = copy(a); @time sort!(b, alg = MergeSort);\n\n# Let's run the function a second time to remove the effect\n# of the initial compilation\nb = copy(a); @time sort!(b, alg = MergeSort);\nScript 2, with parallelism: psort.jl.\nimport Base.Threads.@spawn\n\n# The psort function is the same as the MergeSort algorithm\n# of the Base sort function with the addition of\n# the @spawn macro on one of the recursive calls\n\n# Sort the elements of `v` in place, from indices `lo` to `hi` inclusive\n\nfunction psort!(v, lo::Int=1, hi::Int = length(v))\n    \n    # 1 or 0 elements: nothing to do\n    if lo &gt;= hi\n        return v\n    end\n    \n    # Below some cutoff: run in serial\n    if hi - lo &lt; 100000\n        sort!(view(v, lo:hi), alg = MergeSort)\n        return v\n    end\n    \n    # Find the midpoint\n    mid = (lo + hi) &gt;&gt;&gt; 1\n    \n    # Task to sort the lower half\n    # will run in parallel with the current call sorting the upper half\n    half = @spawn psort!(v, lo, mid)\n    psort!(v, mid + 1, hi)\n    # Wait for the lower half to finish\n    wait(half)\n\n    # Workspace for merging\n    temp = v[lo:mid]\n    \n    # Merge the two sorted sub-arrays\n    i, k, j = 1, lo, mid + 1\n    @inbounds while k &lt; j &lt;= hi\n        if v[j] &lt; temp[i]\n            v[k] = v[j]\n            j += 1\n        else\n            v[k] = temp[i]\n            i += 1\n        end\n        k += 1\n    end\n    @inbounds while k &lt; j\n        v[k] = temp[i]\n        k += 1\n        i += 1\n    end\n    \n    return v\nend\n\na = rand(20000000);\n\n# Now, let's use our function\nb = copy(a); @time psort!(b);\n\n# And running it a second time to remove\n# the effect of the initial compilation\nb = copy(a); @time psort!(b);\nNow, we can test both scripts with one or multiple threads.\n\nSingle thread, non-parallel script:\n\n$ julia /path/to/sort.jl\n2.234024 seconds (111.88 k allocations: 82.489 MiB, 0.21% gc time)\n2.158333 seconds (11 allocations: 76.294 MiB, 0.51% gc time)\n\nNote the lower time for the 2nd run due to pre-compilation.\n\n\nSingle thread, parallel script:\n\n$ julia /path/to/psort.jl\n2.748138 seconds (336.77 k allocations: 703.200 MiB, 2.24% gc time)\n2.438032 seconds (3.58 k allocations: 686.932 MiB, 0.27% gc time)\n\nEven longer time: normal, there was more to run (import package, read function).\n\n\n2 threads, non-parallel script:\n\n$ JULIA_NUM_THREADS=2 julia /path/to/sort.jl\n2.233720 seconds (111.87 k allocations: 82.145 MiB, 0.21% gc time)\n2.155232 seconds (11 allocations: 76.294 MiB, 0.54% gc time)\n\nRemarkably similar to the single thread: the addition of a thread did not change anything.\n\n\n2 threads, parallel script:\n\n$ JULIA_NUM_THREADS=2 julia /path/to/psort.jl\n1.773643 seconds (336.99 k allocations: 703.171 MiB, 4.08% gc time)\n1.460539 seconds (3.79 k allocations: 686.935 MiB, 0.47% gc time)\n\n33% faster.\nNot twice as fast as one could have hoped since processes have to wait for each other. But that‚Äôs a good improvement.\n\n\n4 threads, non-parallel script:\n\n$ JULIA_NUM_THREADS=4 julia /path/to/sort.jl\n2.231717 seconds (111.87 k allocations: 82.145 MiB, 0.21% gc time)\n2.153509 seconds (11 allocations: 76.294 MiB, 0.53% gc time)\n\nAgain: same result as the single thread.\n\n\n4 threads, parallel script:\n\n$ JULIA_NUM_THREADS=4 julia /path/to/psort.jl\n1.291714 seconds (336.98 k allocations: 703.171 MiB, 3.48% gc time)\n1.194282 seconds (3.78 k allocations: 686.935 MiB, 5.19% gc time)\n\nEven though we only split our code in 2 tasks, there is still an improvement over the 2 thread run.",
    "crumbs": [
      "Julia",
      "<b><em>High-performance Julia</em></b>",
      "Multi-threading"
    ]
  },
  {
    "objectID": "julia/hpc_distributed.html",
    "href": "julia/hpc_distributed.html",
    "title": "Distributed computing",
    "section": "",
    "text": "Julia supports distributed computing thanks to the module Distributed from its standard library.\nThere are two ways to launch several Julia processes (called ‚Äúworkers‚Äù):\n\n\nJulia can be started with the -p flag followed by the number of workers by running (in a terminal):\njulia -p n\nThis launches n workers, available for parallel computations, in addition to the process running the interactive prompt (so there are n + 1 Julia processes in total).\nThe module Distributed is needed whenever you want to use several workers, but the -p flag loads it automatically.\n\nExample:\n\njulia -p 4\nWithin Julia, you can see how many workers are running with:\nnworkers()\nThe total number of processes can be seen with:\nnprocs()\n\n\n\nAlternatively, workers can be started from within a Julia session. In this case, you need to load the module Distributed explicitly:\nusing Distributed\nTo launch n workers:\naddprocs(n)\n\nExample:\n\naddprocs(4)",
    "crumbs": [
      "Julia",
      "<b><em>High-performance Julia</em></b>",
      "Distributed computing"
    ]
  },
  {
    "objectID": "julia/hpc_distributed.html#launching-several-julia-processes",
    "href": "julia/hpc_distributed.html#launching-several-julia-processes",
    "title": "Distributed computing",
    "section": "",
    "text": "Julia supports distributed computing thanks to the module Distributed from its standard library.\nThere are two ways to launch several Julia processes (called ‚Äúworkers‚Äù):\n\n\nJulia can be started with the -p flag followed by the number of workers by running (in a terminal):\njulia -p n\nThis launches n workers, available for parallel computations, in addition to the process running the interactive prompt (so there are n + 1 Julia processes in total).\nThe module Distributed is needed whenever you want to use several workers, but the -p flag loads it automatically.\n\nExample:\n\njulia -p 4\nWithin Julia, you can see how many workers are running with:\nnworkers()\nThe total number of processes can be seen with:\nnprocs()\n\n\n\nAlternatively, workers can be started from within a Julia session. In this case, you need to load the module Distributed explicitly:\nusing Distributed\nTo launch n workers:\naddprocs(n)\n\nExample:\n\naddprocs(4)",
    "crumbs": [
      "Julia",
      "<b><em>High-performance Julia</em></b>",
      "Distributed computing"
    ]
  },
  {
    "objectID": "julia/hpc_distributed.html#managing-workers",
    "href": "julia/hpc_distributed.html#managing-workers",
    "title": "Distributed computing",
    "section": "Managing workers",
    "text": "Managing workers\nTo list all the worker process identifiers:\nworkers()\n\nThe process running the Julia prompt has id 1.\n\nTo kill a worker:\nrmprocs(&lt;pid&gt;)\nwhere &lt;pid&gt; is the process identifier of the worker you want to kill (you can kill several workers by providing a list of pids).",
    "crumbs": [
      "Julia",
      "<b><em>High-performance Julia</em></b>",
      "Distributed computing"
    ]
  },
  {
    "objectID": "julia/hpc_distributed.html#using-workers",
    "href": "julia/hpc_distributed.html#using-workers",
    "title": "Distributed computing",
    "section": "Using workers",
    "text": "Using workers\nThere are a number of macros that are very convenient here:\n\nTo execute an expression on all processes, there is @everywhere\n\nFor instance, if your parallel code requires a module or an external package to run, you need to load that module or package with @everywhere:\n@everywhere using DataFrames\nIf the parallel code requires a script to run:\n@everywhere include(\"script.jl\")\nIf it requires a function that you are defining, you need to define it on all the workers:\n@everywhere function &lt;name&gt;(&lt;arguments&gt;)\n    &lt;body&gt;\nend\n\nTo assign a task to a particular worker, you use @spawnat\n\nThe first argument indicates the process id, the second argument is the expression that should be evaluated:\n@spawnat &lt;pid&gt; &lt;expression&gt;\n@spawnat returns of Future: the placeholder for a computation of unknown status and time. The function fetch waits for a Future to complete and returns the result of the computation.\n\nExample:\n\nThe function myid gives the id of the current process. As I mentioned earlier, the process running the interactive Julia prompt has the pid 1. So myid() normally returns 1.\nBut we can ‚Äúspawn‚Äù myid on one of the worker, for instance the first worker (so pid 2):\n@spawnat 2 myid()\nAs you can see, we get a Future as a result. But if we pass it through fetch, we get the result of myid ran on the worker with pid 2:\nfetch(@spawnat 2 myid())\nIf you want tasks to be assigned to any worker automatically, you can pass the symbol :any to @spawnat instead of the worker id:\n@spawnat :any myid()\nTo get the result:\nfetch(@spawnat :any myid())\nIf you run this multiple times, you will see that myid is run on any of your available workers. This will however never return 1, except when you only have one running Julia process (in that case, the process running the prompt is considered a worker).",
    "crumbs": [
      "Julia",
      "<b><em>High-performance Julia</em></b>",
      "Distributed computing"
    ]
  },
  {
    "objectID": "git/ws_search.html",
    "href": "git/ws_search.html",
    "title": "Searching a version-controlled project",
    "section": "",
    "text": "What is the point of creating all these commits if you are unable to make use of them because you can‚Äôt find the information you need in them?\nIn this workshop, we will learn how to search:\n\nyour files (at any of their versions) and\nyour commit logs.\n\nBy the end of the workshop, you should be able to retrieve anything you need from your versioned project."
  },
  {
    "objectID": "git/ws_search.html#installation",
    "href": "git/ws_search.html#installation",
    "title": "Searching a version-controlled project",
    "section": "Installation",
    "text": "Installation\nmacOS & Linux users:\nInstall Git from the official website.\nWindows users:\nInstall Git for Windows. This will also install ‚ÄúGit Bash‚Äù, a Bash emulator."
  },
  {
    "objectID": "git/ws_search.html#using-git",
    "href": "git/ws_search.html#using-git",
    "title": "Searching a version-controlled project",
    "section": "Using Git",
    "text": "Using Git\nWe will use Git from the command line throughout this workshop.\nmacOS users: ‚ÄÉ‚ÄÉ‚ÄÇopen ‚ÄúTerminal‚Äù.\nWindows users: ‚ÄÉ‚ÄÇopen ‚ÄúGit Bash‚Äù.\nLinux users: ‚ÄÉ‚ÄÉ‚ÄÉopen the terminal emulator of your choice."
  },
  {
    "objectID": "git/ws_search.html#practice-repo",
    "href": "git/ws_search.html#practice-repo",
    "title": "Searching a version-controlled project",
    "section": "Practice repo",
    "text": "Practice repo\n\nGet a repo\nYou are welcome to use a repository of yours to follow this workshop. Alternatively, you can clone a practice repo I have on GitHub:\n\nNavigate to an appropriate location:\n\ncd /path/to/appropriate/location\n\nClone the repo:\n\n# If you have set SSH for your GitHub account\ngit clone git@github.com:prosoitos/practice_repo.git\n# If you haven't set SSH\ngit clone https://github.com/prosoitos/practice_repo.git\n\nEnter the repo:\n\ncd practice_repo"
  },
  {
    "objectID": "git/ws_search.html#searching-files",
    "href": "git/ws_search.html#searching-files",
    "title": "Searching a version-controlled project",
    "section": "Searching files",
    "text": "Searching files\nThe first thing that can happen is that you are looking for a certain pattern somewhere in your project (for instance a certain function or a certain word).\n\ngit grep\nThe main command to look through versioned files is git grep.\nYou might be familiar with the command-line utility grep which allows to search for lines matching a certain pattern in files. git grep does a similar job with these differences:\n\nit is much faster since all files under version control are already indexed by Git,\nyou can easily search any commit without having to check it out,\nit has features lacking in grep such as, for instance, pattern arithmetic or tree search using globs.\n\n\n\nLet‚Äôs try it\nBy default, git grep searches recursively through the tracked files in the working directory (that is, the current version of the tracked files).\nFirst, let‚Äôs look for the word test in the current version of the tracked files in the test repo:\n\ngit grep test\n\nintro_aliases.qmd:Now, let's build an alias for a more complex command: `git grep \"test\" $(git rev-list --all)`. This example\nintro_aliases.qmd:from the *\"Searching a Git project\"* section below will search for the string \"test\" in all previous\nintro_aliases.qmd:commits. There are two problems with this command: (1) it takes an argument (the string \"test\"), and (2) it\nintro_aliases.qmd:git search test\nintro_aliases.qmd:should search the entire current Git project history for \"test\".\nintro_branches.qmd:git branch test\nintro_branches.qmd:git switch test\nintro_branches.qmd:* test\nintro_branches.qmd:The `*` shows the branch you are currently on (i.e. the branch to which `HEAD` points to). In our example, the project has two branches and we are on the branch `test`.\nintro_branches.qmd:git diff main test\nintro_branches.qmd:When you are happy with the changes you made on your test branch, you can merge it into `main`.\nintro_branches.qmd:If you have only created new commits on the branch `test`, the merge is called a \"fast-forward merge\" because `main` and `test` have not diverged: it is simply a question of having `main` catch up to `test`.\nintro_branches.qmd:git merge test\nintro_branches.qmd:Then, usually, you delete the branch `test` as it has served its purpose:\nintro_branches.qmd:git branch -d test\nintro_branches.qmd:Alternatively, you can switch back to `test` and do the next bit of experimental work on it. This allows to keep `main` free of mishaps and bad developments.\nintro_branches.qmd:Let's go back to our situation before we created the branch `test`:\nintro_branches.qmd:This time, you create a branch called `test2`:\nintro_branches.qmd:To merge your branch `test2` into `main`, a new commit is now required. Git will create this new commit automatically. As long as there is no conflict, it is just as easy as a fast-forward merge:\nintro_branches.qmd:git merge test2\nintro_branches.qmd:After which, you can delete the (now useless) test branch (with `git branch -d test2`):\nintro_branches.qmd:&gt;&gt;&gt;&gt;&gt;&gt;&gt; test2\nintro_intro_old.qmd:The pointer `HEAD`, which normally points to the branch `main` which itself points to latest commit, can be moved around. By moving `HEAD` to any commit, you can revisit the state of your project at that particular version.\nintro_intro_old.qmd:Instead of working on your branch `main`, you create a test branch and work on it (so `HEAD` is on the branch `test` and both move along as you create commits):\nintro_intro_old.qmd:When you are happy with the changes you made on your test branch, you decide to merge `main` onto it.\nintro_intro_old.qmd:Then you do the fast-forward merge from `main` onto `test` (so `main` catches up to `test`):\nintro_intro_old.qmd:Then, usually, you delete the branch `test` as it has served its purpose (with `git branch -d test`). Alternatively, you can switch back to it and do the next bit of experimental work in it.\nintro_intro_old.qmd:This allows to keep `main` free of possible mishaps and bad developments (if you aren't happy with the work you did on your test branch, you can simply delete it and Git will clean the commits that are on it but not on `main` during the next garbage collection.\nintro_intro_old.qmd:You create a test branch and switch to it:\nintro_intro_old.qmd:To merge your main branch and your test branch, a new commit is now required (note that the command is the same as in the case of a fast-forward merge: `git merge`. Git will create the new commit automatically. As long as there is no conflict, it is just as easy as a fast-forward merge. We will talk later about resolving conflicts).\nintro_intro_old.qmd:After which, you can delete the (now useless) test branch (with `git branch -d test2`):\nintro_remotes.qmd:Click on the `Code` green drop-down button, select SSH [if you have set SSH for your GitHub account](https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/connecting-to-github-with-ssh) or HTTPS and copy the address.\nintro_revisiting_old_commits_alternate.qmd:The pointer `HEAD`, which normally points to the branch `main` which itself points to latest commit, can be moved around. By moving `HEAD` to any commit, you can revisit the state of your project at that particular version.\nintro_undo.qmd:Here is a common scenario: you make a commit, then realize that you forgot to include some changes in that commit; or you aren't happy with the commit message; or both. You can edit your latest commit with the `--amend` flag:\nws_collab.qmd:Click on the `Code` green drop-down button, select SSH [if you have set SSH for your GitHub account](https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/connecting-to-github-with-ssh) or HTTPS and copy the address.\n\n\nLet‚Äôs add blank lines between the results of each file for better readability:\n\ngit grep --break test\n\nintro_aliases.qmd:Now, let's build an alias for a more complex command: `git grep \"test\" $(git rev-list --all)`. This example\nintro_aliases.qmd:from the *\"Searching a Git project\"* section below will search for the string \"test\" in all previous\nintro_aliases.qmd:commits. There are two problems with this command: (1) it takes an argument (the string \"test\"), and (2) it\nintro_aliases.qmd:git search test\nintro_aliases.qmd:should search the entire current Git project history for \"test\".\n\nintro_branches.qmd:git branch test\nintro_branches.qmd:git switch test\nintro_branches.qmd:* test\nintro_branches.qmd:The `*` shows the branch you are currently on (i.e. the branch to which `HEAD` points to). In our example, the project has two branches and we are on the branch `test`.\nintro_branches.qmd:git diff main test\nintro_branches.qmd:When you are happy with the changes you made on your test branch, you can merge it into `main`.\nintro_branches.qmd:If you have only created new commits on the branch `test`, the merge is called a \"fast-forward merge\" because `main` and `test` have not diverged: it is simply a question of having `main` catch up to `test`.\nintro_branches.qmd:git merge test\nintro_branches.qmd:Then, usually, you delete the branch `test` as it has served its purpose:\nintro_branches.qmd:git branch -d test\nintro_branches.qmd:Alternatively, you can switch back to `test` and do the next bit of experimental work on it. This allows to keep `main` free of mishaps and bad developments.\nintro_branches.qmd:Let's go back to our situation before we created the branch `test`:\nintro_branches.qmd:This time, you create a branch called `test2`:\nintro_branches.qmd:To merge your branch `test2` into `main`, a new commit is now required. Git will create this new commit automatically. As long as there is no conflict, it is just as easy as a fast-forward merge:\nintro_branches.qmd:git merge test2\nintro_branches.qmd:After which, you can delete the (now useless) test branch (with `git branch -d test2`):\nintro_branches.qmd:&gt;&gt;&gt;&gt;&gt;&gt;&gt; test2\n\nintro_intro_old.qmd:The pointer `HEAD`, which normally points to the branch `main` which itself points to latest commit, can be moved around. By moving `HEAD` to any commit, you can revisit the state of your project at that particular version.\nintro_intro_old.qmd:Instead of working on your branch `main`, you create a test branch and work on it (so `HEAD` is on the branch `test` and both move along as you create commits):\nintro_intro_old.qmd:When you are happy with the changes you made on your test branch, you decide to merge `main` onto it.\nintro_intro_old.qmd:Then you do the fast-forward merge from `main` onto `test` (so `main` catches up to `test`):\nintro_intro_old.qmd:Then, usually, you delete the branch `test` as it has served its purpose (with `git branch -d test`). Alternatively, you can switch back to it and do the next bit of experimental work in it.\nintro_intro_old.qmd:This allows to keep `main` free of possible mishaps and bad developments (if you aren't happy with the work you did on your test branch, you can simply delete it and Git will clean the commits that are on it but not on `main` during the next garbage collection.\nintro_intro_old.qmd:You create a test branch and switch to it:\nintro_intro_old.qmd:To merge your main branch and your test branch, a new commit is now required (note that the command is the same as in the case of a fast-forward merge: `git merge`. Git will create the new commit automatically. As long as there is no conflict, it is just as easy as a fast-forward merge. We will talk later about resolving conflicts).\nintro_intro_old.qmd:After which, you can delete the (now useless) test branch (with `git branch -d test2`):\n\nintro_remotes.qmd:Click on the `Code` green drop-down button, select SSH [if you have set SSH for your GitHub account](https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/connecting-to-github-with-ssh) or HTTPS and copy the address.\n\nintro_revisiting_old_commits_alternate.qmd:The pointer `HEAD`, which normally points to the branch `main` which itself points to latest commit, can be moved around. By moving `HEAD` to any commit, you can revisit the state of your project at that particular version.\n\nintro_undo.qmd:Here is a common scenario: you make a commit, then realize that you forgot to include some changes in that commit; or you aren't happy with the commit message; or both. You can edit your latest commit with the `--amend` flag:\n\nws_collab.qmd:Click on the `Code` green drop-down button, select SSH [if you have set SSH for your GitHub account](https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/connecting-to-github-with-ssh) or HTTPS and copy the address.\n\n\nLet‚Äôs also put the file names on separate lines:\n\ngit grep --break --heading test\n\nintro_aliases.qmd\nNow, let's build an alias for a more complex command: `git grep \"test\" $(git rev-list --all)`. This example\nfrom the *\"Searching a Git project\"* section below will search for the string \"test\" in all previous\ncommits. There are two problems with this command: (1) it takes an argument (the string \"test\"), and (2) it\ngit search test\nshould search the entire current Git project history for \"test\".\n\nintro_branches.qmd\ngit branch test\ngit switch test\n* test\nThe `*` shows the branch you are currently on (i.e. the branch to which `HEAD` points to). In our example, the project has two branches and we are on the branch `test`.\ngit diff main test\nWhen you are happy with the changes you made on your test branch, you can merge it into `main`.\nIf you have only created new commits on the branch `test`, the merge is called a \"fast-forward merge\" because `main` and `test` have not diverged: it is simply a question of having `main` catch up to `test`.\ngit merge test\nThen, usually, you delete the branch `test` as it has served its purpose:\ngit branch -d test\nAlternatively, you can switch back to `test` and do the next bit of experimental work on it. This allows to keep `main` free of mishaps and bad developments.\nLet's go back to our situation before we created the branch `test`:\nThis time, you create a branch called `test2`:\nTo merge your branch `test2` into `main`, a new commit is now required. Git will create this new commit automatically. As long as there is no conflict, it is just as easy as a fast-forward merge:\ngit merge test2\nAfter which, you can delete the (now useless) test branch (with `git branch -d test2`):\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; test2\n\nintro_intro_old.qmd\nThe pointer `HEAD`, which normally points to the branch `main` which itself points to latest commit, can be moved around. By moving `HEAD` to any commit, you can revisit the state of your project at that particular version.\nInstead of working on your branch `main`, you create a test branch and work on it (so `HEAD` is on the branch `test` and both move along as you create commits):\nWhen you are happy with the changes you made on your test branch, you decide to merge `main` onto it.\nThen you do the fast-forward merge from `main` onto `test` (so `main` catches up to `test`):\nThen, usually, you delete the branch `test` as it has served its purpose (with `git branch -d test`). Alternatively, you can switch back to it and do the next bit of experimental work in it.\nThis allows to keep `main` free of possible mishaps and bad developments (if you aren't happy with the work you did on your test branch, you can simply delete it and Git will clean the commits that are on it but not on `main` during the next garbage collection.\nYou create a test branch and switch to it:\nTo merge your main branch and your test branch, a new commit is now required (note that the command is the same as in the case of a fast-forward merge: `git merge`. Git will create the new commit automatically. As long as there is no conflict, it is just as easy as a fast-forward merge. We will talk later about resolving conflicts).\nAfter which, you can delete the (now useless) test branch (with `git branch -d test2`):\n\nintro_remotes.qmd\nClick on the `Code` green drop-down button, select SSH [if you have set SSH for your GitHub account](https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/connecting-to-github-with-ssh) or HTTPS and copy the address.\n\nintro_revisiting_old_commits_alternate.qmd\nThe pointer `HEAD`, which normally points to the branch `main` which itself points to latest commit, can be moved around. By moving `HEAD` to any commit, you can revisit the state of your project at that particular version.\n\nintro_undo.qmd\nHere is a common scenario: you make a commit, then realize that you forgot to include some changes in that commit; or you aren't happy with the commit message; or both. You can edit your latest commit with the `--amend` flag:\n\nws_collab.qmd\nClick on the `Code` green drop-down button, select SSH [if you have set SSH for your GitHub account](https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/connecting-to-github-with-ssh) or HTTPS and copy the address.\n\n\nWe can display the line numbers for the results with the -n flag:\n\ngit grep --break --heading -n test\n\nintro_aliases.qmd\n48:Now, let's build an alias for a more complex command: `git grep \"test\" $(git rev-list --all)`. This example\n49:from the *\"Searching a Git project\"* section below will search for the string \"test\" in all previous\n50:commits. There are two problems with this command: (1) it takes an argument (the string \"test\"), and (2) it\n68:git search test\n71:should search the entire current Git project history for \"test\".\n\nintro_branches.qmd\n54:git branch test\n72:git switch test\n99:* test\n102:The `*` shows the branch you are currently on (i.e. the branch to which `HEAD` points to). In our example, the project has two branches and we are on the branch `test`.\n109:git diff main test\n116:When you are happy with the changes you made on your test branch, you can merge it into `main`.\n120:If you have only created new commits on the branch `test`, the merge is called a \"fast-forward merge\" because `main` and `test` have not diverged: it is simply a question of having `main` catch up to `test`.\n135:git merge test\n140:Then, usually, you delete the branch `test` as it has served its purpose:\n143:git branch -d test\n148:Alternatively, you can switch back to `test` and do the next bit of experimental work on it. This allows to keep `main` free of mishaps and bad developments.\n154:Let's go back to our situation before we created the branch `test`:\n158:This time, you create a branch called `test2`:\n182:To merge your branch `test2` into `main`, a new commit is now required. Git will create this new commit automatically. As long as there is no conflict, it is just as easy as a fast-forward merge:\n185:git merge test2\n190:After which, you can delete the (now useless) test branch (with `git branch -d test2`):\n215:&gt;&gt;&gt;&gt;&gt;&gt;&gt; test2\n\nintro_intro_old.qmd\n904:The pointer `HEAD`, which normally points to the branch `main` which itself points to latest commit, can be moved around. By moving `HEAD` to any commit, you can revisit the state of your project at that particular version.\n1219:Instead of working on your branch `main`, you create a test branch and work on it (so `HEAD` is on the branch `test` and both move along as you create commits):\n1227:When you are happy with the changes you made on your test branch, you decide to merge `main` onto it.\n1233:Then you do the fast-forward merge from `main` onto `test` (so `main` catches up to `test`):\n1237:Then, usually, you delete the branch `test` as it has served its purpose (with `git branch -d test`). Alternatively, you can switch back to it and do the next bit of experimental work in it.\n1238:This allows to keep `main` free of possible mishaps and bad developments (if you aren't happy with the work you did on your test branch, you can simply delete it and Git will clean the commits that are on it but not on `main` during the next garbage collection.\n1250:You create a test branch and switch to it:\n1270:To merge your main branch and your test branch, a new commit is now required (note that the command is the same as in the case of a fast-forward merge: `git merge`. Git will create the new commit automatically. As long as there is no conflict, it is just as easy as a fast-forward merge. We will talk later about resolving conflicts).\n1274:After which, you can delete the (now useless) test branch (with `git branch -d test2`):\n\nintro_remotes.qmd\n45:Click on the `Code` green drop-down button, select SSH [if you have set SSH for your GitHub account](https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/connecting-to-github-with-ssh) or HTTPS and copy the address.\n\nintro_revisiting_old_commits_alternate.qmd\n3:The pointer `HEAD`, which normally points to the branch `main` which itself points to latest commit, can be moved around. By moving `HEAD` to any commit, you can revisit the state of your project at that particular version.\n\nintro_undo.qmd\n16:Here is a common scenario: you make a commit, then realize that you forgot to include some changes in that commit; or you aren't happy with the commit message; or both. You can edit your latest commit with the `--amend` flag:\n\nws_collab.qmd\n52:Click on the `Code` green drop-down button, select SSH [if you have set SSH for your GitHub account](https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/connecting-to-github-with-ssh) or HTTPS and copy the address.\n\n\nNotice how the results for the file src/test_manuel.py involve functions. It would be very convenient to have the names of the functions in which test appears.\nWe can do this with the -p flag:\n\ngit grep --break --heading -p test src/test_manuel.py\n\nfatal: ambiguous argument 'src/test_manuel.py': unknown revision or path not in the working tree.\nUse '--' to separate paths from revisions, like this:\n'git &lt;command&gt; [&lt;revision&gt;...] -- [&lt;file&gt;...]'\n\n\n\nWe added the argument src/test_manuel.py to limit the search to that file.\n\nWe can now see that the word test appears in the functions test and main.\nNow, instead of printing all the matching lines, let‚Äôs print the number of matches per file:\n\ngit grep -c test\n\nintro_aliases.qmd:5\nintro_branches.qmd:17\nintro_intro_old.qmd:9\nintro_remotes.qmd:1\nintro_revisiting_old_commits_alternate.qmd:1\nintro_undo.qmd:1\nws_collab.qmd:1\n\n\n\n\nMore complex patterns\ngit grep in fact searches for regular expressions. test is a regular expression matching test, but we can look for more complex patterns.\nLet‚Äôs look for image:\n\ngit grep image\n\nintro_ignore.qmd:- Non-text files (e.g. images, office documents)\n\n\n\nNo output means that the search is not returning any result.\n\nLet‚Äôs make this search case insensitive:\n\ngit grep -i image\n\nintro_ignore.qmd:- Non-text files (e.g. images, office documents)\n\n\nWe are now getting some results as Image was present in three lines of the file src/new_file.py.\nLet‚Äôs now search for data:\n\ngit grep data\n\nintro_changes.qmd:Remember that HEAD is a pointer pointing at a branch, that a branch is itself a pointer pointing at a commit, and finally that a commit is a Git object pointing at compressed blobs containing data about your project at a certain commit. When the HEAD pointer moves around, whatever commit it points to populates the [HEAD]{.emph} tree with the corresponding data.\nintro_first_steps.qmd:Alternatively, you can download the file with this button: \nintro_first_steps.qmd:data/\nintro_first_steps.qmd:data\nintro_first_steps.qmd:data\nintro_first_steps.qmd:./data:\nintro_first_steps.qmd:dataset.csv\nintro_first_steps.qmd:‚îú‚îÄ‚îÄ data\nintro_first_steps.qmd:‚îÇ¬†¬† ‚îî‚îÄ‚îÄ dataset.csv\nintro_first_steps.qmd:This is our very exciting data set:\nintro_first_steps.qmd:cat data/dataset.csv\nintro_first_steps.qmd:df = pd.read_csv('../data/dataset.csv')\nintro_first_steps.qmd:data\nintro_first_steps.qmd:        data/\nintro_first_steps.qmd:        data/\nintro_first_steps.qmd:Remember that each commit contains the following metadata:\nintro_first_steps.qmd:        data/\nintro_ignore.qmd:- Your initial data\nintro_ignore.qmd:Notice how `data/` is not listed in the untracked files anymore.\nintro_ignore.qmd:git commit -m \"Add .gitignore file with data and results\"\nintro_ignore.qmd:[main a1df8e5] Add .gitignore file with data and results\nintro_intro_old.qmd:mkdir chapter3/src chapter3/ms chapter3/data chapter3/results\nintro_intro_old.qmd:df &lt;- data.frame(\nintro_intro_old.qmd:data\nintro_intro_old.qmd:Each commit is identified by a unique *hash* and contains these metadata:\nintro_intro_old.qmd:@@ -7,3 +7,5 @@ df &lt;- data.frame(\nintro_intro_old.qmd:@@ -7,3 +7,5 @@ df &lt;- data.frame(\nintro_intro_old.qmd:Not everything should be under version control. For instance, you don't want to put under version control non-text files or your initial data. You also shouldn't put under version control documents that can be easily recreated such as graphs and script outputs.\nintro_intro_old.qmd:echo \"/data/\nintro_intro_old.qmd:This creates a `.gitignore` file with two entries (`/data/` and `/results/`) and from now on, any file in either of these directories will be ignored by Git.\nintro_intro_old.qmd:git commit -m \"Add .gitignore file with data and results\"\nintro_intro_old.qmd:[main a1df8e5] Add .gitignore file with data and results\nintro_intro_old.qmd:    Add .gitignore file with data and results\nintro_intro_old.qmd:a1df8e5 (HEAD -&gt; main) Add .gitignore file with data and results\nintro_intro_old.qmd:|     Add .gitignore file with data and results\nintro_intro_old.qmd:* a1df8e5 88 seconds ago  (HEAD -&gt; main)Add .gitignore file with data and results xxx@xxx\nintro_intro_old.qmd:In addition to displaying the commit metadata, this also displays the difference with the previous commit.\nintro_intro_old.qmd:    Add .gitignore file with data and results\nintro_intro_old.qmd:+/data/\nintro_intro_old.qmd:@@ -7,3 +7,5 @@ df &lt;- data.frame(\nintro_intro_old.qmd:    Add .gitignore file with data and results\nintro_intro_slides.qmd:The data is stored as blobs, doesn't create unnecessary copies (unchanged files are referenced from old blobs), and uses excellent compression\nintro_intro_slides.qmd:Each commit has a unique *hash* and contains the following metadata:\nintro_logs.qmd:    Add .gitignore file with data and results\nintro_logs.qmd:c4ab5e7 Add .gitignore file with data and results\nintro_logs.qmd:|     Add .gitignore file with data and results\nintro_logs.qmd:* c4ab5e7 34 minutes ago Add .gitignore file with data and results xxx@xxx\nintro_logs.qmd:+df = pd.read_csv('../data/dataset.csv')\nintro_logs.qmd:    Add .gitignore file with data and results\nintro_logs.qmd:+/data/\nintro_logs.qmd:In addition to displaying the commit metadata, `git show` also displays the diff of that commit with its parent commit.\nintro_remotes.qmd:## Getting data from a remote\nintro_remotes.qmd:If you collaborate on a project, you have to get the data added by your teammates to keep your local project up to date.\nintro_remotes.qmd:To download new data from a remote, you have 2 options:\nintro_remotes.qmd:*Fetching* downloads the data from a remote that you don't already have in your local version of the project:\nintro_remotes.qmd:Uploading data to the remote is called *pushing*:\nintro_undo.qmd:As you just experienced, this command leads to data loss. \\\nBinary file project.zip matches\nwb_dvc.qmd:title: Version control for data science and machine learning with DVC\n\n\nWe are getting results for the word data, but also for the pattern data in longer expressions such as train_data or dataset. If we only want results for the word data, we can use the -w flag:\n\ngit grep -w data\n\nintro_changes.qmd:Remember that HEAD is a pointer pointing at a branch, that a branch is itself a pointer pointing at a commit, and finally that a commit is a Git object pointing at compressed blobs containing data about your project at a certain commit. When the HEAD pointer moves around, whatever commit it points to populates the [HEAD]{.emph} tree with the corresponding data.\nintro_first_steps.qmd:Alternatively, you can download the file with this button: \nintro_first_steps.qmd:data/\nintro_first_steps.qmd:data\nintro_first_steps.qmd:data\nintro_first_steps.qmd:./data:\nintro_first_steps.qmd:‚îú‚îÄ‚îÄ data\nintro_first_steps.qmd:This is our very exciting data set:\nintro_first_steps.qmd:cat data/dataset.csv\nintro_first_steps.qmd:df = pd.read_csv('../data/dataset.csv')\nintro_first_steps.qmd:data\nintro_first_steps.qmd:        data/\nintro_first_steps.qmd:        data/\nintro_first_steps.qmd:        data/\nintro_ignore.qmd:- Your initial data\nintro_ignore.qmd:Notice how `data/` is not listed in the untracked files anymore.\nintro_ignore.qmd:git commit -m \"Add .gitignore file with data and results\"\nintro_ignore.qmd:[main a1df8e5] Add .gitignore file with data and results\nintro_intro_old.qmd:mkdir chapter3/src chapter3/ms chapter3/data chapter3/results\nintro_intro_old.qmd:df &lt;- data.frame(\nintro_intro_old.qmd:data\nintro_intro_old.qmd:@@ -7,3 +7,5 @@ df &lt;- data.frame(\nintro_intro_old.qmd:@@ -7,3 +7,5 @@ df &lt;- data.frame(\nintro_intro_old.qmd:Not everything should be under version control. For instance, you don't want to put under version control non-text files or your initial data. You also shouldn't put under version control documents that can be easily recreated such as graphs and script outputs.\nintro_intro_old.qmd:echo \"/data/\nintro_intro_old.qmd:This creates a `.gitignore` file with two entries (`/data/` and `/results/`) and from now on, any file in either of these directories will be ignored by Git.\nintro_intro_old.qmd:git commit -m \"Add .gitignore file with data and results\"\nintro_intro_old.qmd:[main a1df8e5] Add .gitignore file with data and results\nintro_intro_old.qmd:    Add .gitignore file with data and results\nintro_intro_old.qmd:a1df8e5 (HEAD -&gt; main) Add .gitignore file with data and results\nintro_intro_old.qmd:|     Add .gitignore file with data and results\nintro_intro_old.qmd:* a1df8e5 88 seconds ago  (HEAD -&gt; main)Add .gitignore file with data and results xxx@xxx\nintro_intro_old.qmd:    Add .gitignore file with data and results\nintro_intro_old.qmd:+/data/\nintro_intro_old.qmd:@@ -7,3 +7,5 @@ df &lt;- data.frame(\nintro_intro_old.qmd:    Add .gitignore file with data and results\nintro_intro_slides.qmd:The data is stored as blobs, doesn't create unnecessary copies (unchanged files are referenced from old blobs), and uses excellent compression\nintro_logs.qmd:    Add .gitignore file with data and results\nintro_logs.qmd:c4ab5e7 Add .gitignore file with data and results\nintro_logs.qmd:|     Add .gitignore file with data and results\nintro_logs.qmd:* c4ab5e7 34 minutes ago Add .gitignore file with data and results xxx@xxx\nintro_logs.qmd:+df = pd.read_csv('../data/dataset.csv')\nintro_logs.qmd:    Add .gitignore file with data and results\nintro_logs.qmd:+/data/\nintro_remotes.qmd:## Getting data from a remote\nintro_remotes.qmd:If you collaborate on a project, you have to get the data added by your teammates to keep your local project up to date.\nintro_remotes.qmd:To download new data from a remote, you have 2 options:\nintro_remotes.qmd:*Fetching* downloads the data from a remote that you don't already have in your local version of the project:\nintro_remotes.qmd:Uploading data to the remote is called *pushing*:\nintro_undo.qmd:As you just experienced, this command leads to data loss. \\\nBinary file project.zip matches\nwb_dvc.qmd:title: Version control for data science and machine learning with DVC\n\n\nNow, let‚Äôs use a more complex regular expression. We want the counts for the pattern \".*_.*\" (i.e.¬†any name with a snail case such as train_loader):\n\ngit grep -c \".*_.*\"\n\nimg/01.png:16\nimg/02.png:32\nimg/03.png:31\nimg/04.png:26\nimg/05.png:31\nimg/06.png:32\nimg/07.png:30\nimg/08.png:34\nimg/09.png:35\nimg/10.png:41\nimg/11.png:47\nimg/12.png:40\nimg/13.png:39\nimg/14.png:32\nimg/15.png:38\nimg/16.png:43\nimg/17.png:34\nimg/18.png:35\nimg/19.png:30\nimg/20.png:33\nimg/21.png:40\nimg/22.png:41\nimg/23.png:47\nimg/24.png:64\nimg/25.png:66\nimg/26.png:50\nimg/27.png:60\nimg/28.png:57\nimg/29.png:33\nimg/30.png:39\nimg/31.png:14\nimg/32.png:16\nimg/33.png:18\nimg/34.png:16\nimg/35.png:20\nimg/36.png:18\nimg/37.png:18\nimg/51.png:55\nimg/52.png:46\nimg/53.png:55\nimg/collab.jpg:178\nimg/git_graph.png:121\nimg/gitout.png:42\nimg/logo_git.png:4\nimg/vc.jpg:259\nindex.qmd:4\nintro_documentation.qmd:1\nintro_first_steps.qmd:4\nintro_install.qmd:2\nintro_intro.qmd:1\nintro_intro_old.qmd:8\nintro_intro_slides.qmd:5\nintro_logs.qmd:1\nintro_tags.qmd:5\nintro_time_travel.qmd:1\ntop_intro.qmd:2\ntop_ws.qmd:3\nwb_dvc.qmd:1\n\n\nLet‚Äôs print the first 3 results per file:\n\ngit grep -m 3 \".*_.*\"\n\nBinary file img/01.png matches\nBinary file img/02.png matches\nBinary file img/03.png matches\nBinary file img/04.png matches\nBinary file img/05.png matches\nBinary file img/06.png matches\nBinary file img/07.png matches\nBinary file img/08.png matches\nBinary file img/09.png matches\nBinary file img/10.png matches\nBinary file img/11.png matches\nBinary file img/12.png matches\nBinary file img/13.png matches\nBinary file img/14.png matches\nBinary file img/15.png matches\nBinary file img/16.png matches\nBinary file img/17.png matches\nBinary file img/18.png matches\nBinary file img/19.png matches\nBinary file img/20.png matches\nBinary file img/21.png matches\nBinary file img/22.png matches\nBinary file img/23.png matches\nBinary file img/24.png matches\nBinary file img/25.png matches\nBinary file img/26.png matches\nBinary file img/27.png matches\nBinary file img/28.png matches\nBinary file img/29.png matches\nBinary file img/30.png matches\nBinary file img/31.png matches\nBinary file img/32.png matches\nBinary file img/33.png matches\nBinary file img/34.png matches\nBinary file img/35.png matches\nBinary file img/36.png matches\nBinary file img/37.png matches\nBinary file img/51.png matches\nBinary file img/52.png matches\nBinary file img/53.png matches\nBinary file img/collab.jpg matches\nBinary file img/git_graph.png matches\nBinary file img/gitout.png matches\nBinary file img/logo_git.png matches\nBinary file img/vc.jpg matches\nindex.qmd:  Version control & collaboration with &nbsp;[![](img/logo_git.png){width=\"1.3em\" fig-alt=\"noshadow\"}](https://git-scm.com/)\nindex.qmd:[Getting started with &nbsp;![](img/logo_git.png){width=\"1.2em\" fig-alt=\"noshadow\"}](top_intro.qmd){.card-title2 .stretched-link}\nindex.qmd:[Workshops](top_ws.qmd){.card-title2 .stretched-link}\nintro_documentation.qmd:All these methods lead to the same thing: the manual page corresponding to the command will open in a pager (usually [less](https://en.wikipedia.org/wiki/Less_(Unix))). A pager is a program which makes it easier to read documents in the command line.\nintro_first_steps.qmd:  - first_steps.html\nintro_first_steps.qmd:wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1SJV5mRGexf91lNyFwdS_JmuAXX0xS4pE' -O project.zip\nintro_first_steps.qmd:df = pd.read_csv('../data/dataset.csv')\nintro_install.qmd:Git is built for Unix-like systems (Linux and MacOS). In order to use Git from the command line on Windows, you need a Unix shell such as [Bash](https://en.wikipedia.org/wiki/Bash_(Unix_shell)). To make this very easy, Git for Windows comes with its Bash emulator.\nintro_install.qmd:git config user.email \"your_other@email\"\nintro_intro.qmd:[Slides](intro_intro_slides.html){.btn .btn-outline-primary} [(Click and wait: the presentation might take a few instants to load)]{.inlinenote}\nintro_intro_old.qmd:  - intro_old.html\nintro_intro_old.qmd:&lt;script type=\"text/javascript\" src=\"https://ssl.gstatic.com/trends_nrtr/3045_RC01/embed_loader.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\"&gt; trends.embed.renderExploreWidget(\"TIMESERIES\", {\"comparisonItem\":[{\"keyword\":\"/m/05vqwg\",\"geo\":\"\",\"time\":\"2004-01-01 2022-10-03\"},{\"keyword\":\"/m/08441_\",\"geo\":\"\",\"time\":\"2004-01-01 2022-10-03\"},{\"keyword\":\"/m/012ct9\",\"geo\":\"\",\"time\":\"2004-01-01 2022-10-03\"},{\"keyword\":\"/m/09d6g\",\"geo\":\"\",\"time\":\"2004-01-01 2022-10-03\"}],\"category\":0,\"property\":\"\"}, {\"exploreQuery\":\"date=all&q=%2Fm%2F05vqwg,%2Fm%2F08441_,%2Fm%2F012ct9,%2Fm%2F09d6g\",\"guestPath\":\"https://trends.google.com:443/trends/embed/\"}); &lt;/script&gt;\nintro_intro_old.qmd:git config user.email \"your_other@email\"\nintro_intro_slides.qmd:  - intro_slides.html\nintro_intro_slides.qmd:frontpic: \"img/git_graph.png\"\nintro_intro_slides.qmd:    logo: /img/logo_sfudrac.png\nintro_logs.qmd:+df = pd.read_csv('../data/dataset.csv')\nintro_tags.qmd:git tag J_Climate_2009\nintro_tags.qmd:git show J_Climate_2009\nintro_tags.qmd:git checkout J_Climate_2009\nintro_time_travel.qmd:  - time_travel.html\ntop_intro.qmd:description: An introductory course to version control with &nbsp;[![](img/logo_git.png){width=\"1.3em\" fig-alt=\"noshadow\"}](https://git-scm.com/)\ntop_intro.qmd:[[Start course ‚û§](intro_intro.qmd)]{.topinline}\ntop_ws.qmd:[Searching a Git project](practice_repo/ws_search.qmd){.card-title-ws .stretched-link}\ntop_ws.qmd:[Collaborating through Git](ws_collab.qmd){.card-title-ws .stretched-link}\ntop_ws.qmd:[Contributing to projects](ws_contrib.qmd){.card-title-ws .stretched-link}\nwb_dvc.qmd:[As DVC is a popular tool in machine learning, **please find this webinar [in the AI section](/ai/wb_dvc.html){.stretched-link}**.]{.btn-redirect}\n\n\nAs you can see, our results also include __init__ which is not what we were looking for. So let‚Äôs exclude __:\n\ngit grep -m 3 -e \".*_.*\" --and --not -e \"__\"\n\nBinary file img/01.png matches\nBinary file img/02.png matches\nBinary file img/03.png matches\nBinary file img/04.png matches\nBinary file img/05.png matches\nBinary file img/06.png matches\nBinary file img/07.png matches\nBinary file img/08.png matches\nBinary file img/09.png matches\nBinary file img/10.png matches\nBinary file img/11.png matches\nBinary file img/12.png matches\nBinary file img/13.png matches\nBinary file img/14.png matches\nBinary file img/15.png matches\nBinary file img/16.png matches\nBinary file img/17.png matches\nBinary file img/18.png matches\nBinary file img/19.png matches\nBinary file img/20.png matches\nBinary file img/21.png matches\nBinary file img/22.png matches\nBinary file img/23.png matches\nBinary file img/24.png matches\nBinary file img/25.png matches\nBinary file img/26.png matches\nBinary file img/27.png matches\nBinary file img/28.png matches\nBinary file img/29.png matches\nBinary file img/30.png matches\nBinary file img/31.png matches\nBinary file img/32.png matches\nBinary file img/33.png matches\nBinary file img/34.png matches\nBinary file img/35.png matches\nBinary file img/36.png matches\nBinary file img/37.png matches\nBinary file img/51.png matches\nBinary file img/52.png matches\nBinary file img/53.png matches\nBinary file img/collab.jpg matches\nBinary file img/git_graph.png matches\nBinary file img/gitout.png matches\nBinary file img/logo_git.png matches\nBinary file img/vc.jpg matches\nindex.qmd:  Version control & collaboration with &nbsp;[![](img/logo_git.png){width=\"1.3em\" fig-alt=\"noshadow\"}](https://git-scm.com/)\nindex.qmd:[Getting started with &nbsp;![](img/logo_git.png){width=\"1.2em\" fig-alt=\"noshadow\"}](top_intro.qmd){.card-title2 .stretched-link}\nindex.qmd:[Workshops](top_ws.qmd){.card-title2 .stretched-link}\nintro_documentation.qmd:All these methods lead to the same thing: the manual page corresponding to the command will open in a pager (usually [less](https://en.wikipedia.org/wiki/Less_(Unix))). A pager is a program which makes it easier to read documents in the command line.\nintro_first_steps.qmd:  - first_steps.html\nintro_first_steps.qmd:wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1SJV5mRGexf91lNyFwdS_JmuAXX0xS4pE' -O project.zip\nintro_first_steps.qmd:df = pd.read_csv('../data/dataset.csv')\nintro_install.qmd:Git is built for Unix-like systems (Linux and MacOS). In order to use Git from the command line on Windows, you need a Unix shell such as [Bash](https://en.wikipedia.org/wiki/Bash_(Unix_shell)). To make this very easy, Git for Windows comes with its Bash emulator.\nintro_install.qmd:git config user.email \"your_other@email\"\nintro_intro.qmd:[Slides](intro_intro_slides.html){.btn .btn-outline-primary} [(Click and wait: the presentation might take a few instants to load)]{.inlinenote}\nintro_intro_old.qmd:  - intro_old.html\nintro_intro_old.qmd:&lt;script type=\"text/javascript\" src=\"https://ssl.gstatic.com/trends_nrtr/3045_RC01/embed_loader.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\"&gt; trends.embed.renderExploreWidget(\"TIMESERIES\", {\"comparisonItem\":[{\"keyword\":\"/m/05vqwg\",\"geo\":\"\",\"time\":\"2004-01-01 2022-10-03\"},{\"keyword\":\"/m/08441_\",\"geo\":\"\",\"time\":\"2004-01-01 2022-10-03\"},{\"keyword\":\"/m/012ct9\",\"geo\":\"\",\"time\":\"2004-01-01 2022-10-03\"},{\"keyword\":\"/m/09d6g\",\"geo\":\"\",\"time\":\"2004-01-01 2022-10-03\"}],\"category\":0,\"property\":\"\"}, {\"exploreQuery\":\"date=all&q=%2Fm%2F05vqwg,%2Fm%2F08441_,%2Fm%2F012ct9,%2Fm%2F09d6g\",\"guestPath\":\"https://trends.google.com:443/trends/embed/\"}); &lt;/script&gt;\nintro_intro_old.qmd:git config user.email \"your_other@email\"\nintro_intro_slides.qmd:  - intro_slides.html\nintro_intro_slides.qmd:frontpic: \"img/git_graph.png\"\nintro_intro_slides.qmd:    logo: /img/logo_sfudrac.png\nintro_logs.qmd:+df = pd.read_csv('../data/dataset.csv')\nintro_tags.qmd:git tag J_Climate_2009\nintro_tags.qmd:git show J_Climate_2009\nintro_tags.qmd:git checkout J_Climate_2009\nintro_time_travel.qmd:  - time_travel.html\ntop_intro.qmd:description: An introductory course to version control with &nbsp;[![](img/logo_git.png){width=\"1.3em\" fig-alt=\"noshadow\"}](https://git-scm.com/)\ntop_intro.qmd:[[Start course ‚û§](intro_intro.qmd)]{.topinline}\ntop_ws.qmd:[Searching a Git project](practice_repo/ws_search.qmd){.card-title-ws .stretched-link}\ntop_ws.qmd:[Collaborating through Git](ws_collab.qmd){.card-title-ws .stretched-link}\ntop_ws.qmd:[Contributing to projects](ws_contrib.qmd){.card-title-ws .stretched-link}\nwb_dvc.qmd:[As DVC is a popular tool in machine learning, **please find this webinar [in the AI section](/ai/wb_dvc.html){.stretched-link}**.]{.btn-redirect}\n\n\n\nFor simple searches, you don‚Äôt have to use the -e flag before the pattern you are searching for. Here however, our command has gotten complex enough that we have to use it before each pattern.\n\nLet‚Äôs make sure this worked as expected:\n\ngit grep -c \".*_.*\"\necho \"---\"\ngit grep -c \"__\"\necho \"---\"\ngit grep -ce \".*_.*\" --and --not -e \"__\"\n\nimg/01.png:16\nimg/02.png:32\nimg/03.png:31\nimg/04.png:26\nimg/05.png:31\nimg/06.png:32\nimg/07.png:30\nimg/08.png:34\nimg/09.png:35\nimg/10.png:41\nimg/11.png:47\nimg/12.png:40\nimg/13.png:39\nimg/14.png:32\nimg/15.png:38\nimg/16.png:43\nimg/17.png:34\nimg/18.png:35\nimg/19.png:30\nimg/20.png:33\nimg/21.png:40\nimg/22.png:41\nimg/23.png:47\nimg/24.png:64\nimg/25.png:66\nimg/26.png:50\nimg/27.png:60\nimg/28.png:57\nimg/29.png:33\nimg/30.png:39\nimg/31.png:14\nimg/32.png:16\nimg/33.png:18\nimg/34.png:16\nimg/35.png:20\nimg/36.png:18\nimg/37.png:18\nimg/51.png:55\nimg/52.png:46\nimg/53.png:55\nimg/collab.jpg:178\nimg/git_graph.png:121\nimg/gitout.png:42\nimg/logo_git.png:4\nimg/vc.jpg:259\nindex.qmd:4\nintro_documentation.qmd:1\nintro_first_steps.qmd:4\nintro_install.qmd:2\nintro_intro.qmd:1\nintro_intro_old.qmd:8\nintro_intro_slides.qmd:5\nintro_logs.qmd:1\nintro_tags.qmd:5\nintro_time_travel.qmd:1\ntop_intro.qmd:2\ntop_ws.qmd:3\nwb_dvc.qmd:1\n---\nimg/01.png:1\nimg/02.png:2\nimg/03.png:2\nimg/04.png:1\nimg/05.png:3\nimg/06.png:3\nimg/07.png:1\nimg/08.png:1\nimg/09.png:1\nimg/10.png:1\nimg/11.png:1\nimg/12.png:1\nimg/13.png:2\nimg/14.png:2\nimg/15.png:3\nimg/16.png:1\nimg/17.png:1\nimg/18.png:2\nimg/19.png:1\nimg/20.png:1\nimg/21.png:1\nimg/22.png:2\nimg/23.png:4\nimg/24.png:2\nimg/25.png:1\nimg/26.png:1\nimg/27.png:2\nimg/28.png:3\nimg/29.png:2\nimg/30.png:1\nimg/31.png:1\nimg/51.png:1\nimg/52.png:2\nimg/53.png:1\nimg/collab.jpg:1\nimg/git_graph.png:2\nimg/gitout.png:1\n---\nimg/01.png:15\nimg/02.png:30\nimg/03.png:29\nimg/04.png:25\nimg/05.png:28\nimg/06.png:29\nimg/07.png:29\nimg/08.png:33\nimg/09.png:34\nimg/10.png:40\nimg/11.png:46\nimg/12.png:39\nimg/13.png:37\nimg/14.png:30\nimg/15.png:35\nimg/16.png:42\nimg/17.png:33\nimg/18.png:33\nimg/19.png:29\nimg/20.png:32\nimg/21.png:39\nimg/22.png:39\nimg/23.png:43\nimg/24.png:62\nimg/25.png:65\nimg/26.png:49\nimg/27.png:58\nimg/28.png:54\nimg/29.png:31\nimg/30.png:38\nimg/31.png:13\nimg/32.png:16\nimg/33.png:18\nimg/34.png:16\nimg/35.png:20\nimg/36.png:18\nimg/37.png:18\nimg/51.png:54\nimg/52.png:44\nimg/53.png:54\nimg/collab.jpg:177\nimg/git_graph.png:119\nimg/gitout.png:41\nimg/logo_git.png:4\nimg/vc.jpg:259\nindex.qmd:4\nintro_documentation.qmd:1\nintro_first_steps.qmd:4\nintro_install.qmd:2\nintro_intro.qmd:1\nintro_intro_old.qmd:8\nintro_intro_slides.qmd:5\nintro_logs.qmd:1\nintro_tags.qmd:5\nintro_time_travel.qmd:1\ntop_intro.qmd:2\ntop_ws.qmd:3\nwb_dvc.qmd:1\n\n\nThere were 2 lines matching __ in src/test_manuel.py and we have indeed excluded them from our search.\nExtended regular expressions are also covered with the flag -E.\n\n\nSearching other trees\nSo far, we have searched the current version of tracked files, but we can just as easily search files at any commit.\nLet‚Äôs search for test in the tracked files 20 commits ago:\n\ngit grep test HEAD~20\n\nHEAD~20:intro_aliases.qmd:Now, let's build an alias for a more complex command: `git grep \"test\" $(git rev-list --all)`. This example\nHEAD~20:intro_aliases.qmd:from the *\"Searching a Git project\"* section below will search for the string \"test\" in all previous\nHEAD~20:intro_aliases.qmd:commits. There are two problems with this command: (1) it takes an argument (the string \"test\"), and (2) it\nHEAD~20:intro_aliases.qmd:git search test\nHEAD~20:intro_aliases.qmd:should search the entire current Git project history for \"test\".\nHEAD~20:intro_branches.qmd:git branch test\nHEAD~20:intro_branches.qmd:git switch test\nHEAD~20:intro_branches.qmd:* test\nHEAD~20:intro_branches.qmd:The `*` shows the branch you are currently on (i.e. the branch to which `HEAD` points to). In our example, the project has two branches and we are on the branch `test`.\nHEAD~20:intro_branches.qmd:git diff main test\nHEAD~20:intro_branches.qmd:When you are happy with the changes you made on your test branch, you can merge it into `main`.\nHEAD~20:intro_branches.qmd:If you have only created new commits on the branch `test`, the merge is called a \"fast-forward merge\" because `main` and `test` have not diverged: it is simply a question of having `main` catch up to `test`.\nHEAD~20:intro_branches.qmd:git merge test\nHEAD~20:intro_branches.qmd:Then, usually, you delete the branch `test` as it has served its purpose:\nHEAD~20:intro_branches.qmd:git branch -d test\nHEAD~20:intro_branches.qmd:Alternatively, you can switch back to `test` and do the next bit of experimental work on it. This allows to keep `main` free of mishaps and bad developments.\nHEAD~20:intro_branches.qmd:Let's go back to our situation before we created the branch `test`:\nHEAD~20:intro_branches.qmd:This time, you create a branch called `test2`:\nHEAD~20:intro_branches.qmd:To merge your branch `test2` into `main`, a new commit is now required. Git will create this new commit automatically. As long as there is no conflict, it is just as easy as a fast-forward merge:\nHEAD~20:intro_branches.qmd:git merge test2\nHEAD~20:intro_branches.qmd:After which, you can delete the (now useless) test branch (with `git branch -d test2`):\nHEAD~20:intro_branches.qmd:&gt;&gt;&gt;&gt;&gt;&gt;&gt; test2\nHEAD~20:intro_intro_old.qmd:The pointer `HEAD`, which normally points to the branch `main` which itself points to latest commit, can be moved around. By moving `HEAD` to any commit, you can revisit the state of your project at that particular version.\nHEAD~20:intro_intro_old.qmd:Instead of working on your branch `main`, you create a test branch and work on it (so `HEAD` is on the branch `test` and both move along as you create commits):\nHEAD~20:intro_intro_old.qmd:When you are happy with the changes you made on your test branch, you decide to merge `main` onto it.\nHEAD~20:intro_intro_old.qmd:Then you do the fast-forward merge from `main` onto `test` (so `main` catches up to `test`):\nHEAD~20:intro_intro_old.qmd:Then, usually, you delete the branch `test` as it has served its purpose (with `git branch -d test`). Alternatively, you can switch back to it and do the next bit of experimental work in it.\nHEAD~20:intro_intro_old.qmd:This allows to keep `main` free of possible mishaps and bad developments (if you aren't happy with the work you did on your test branch, you can simply delete it and Git will clean the commits that are on it but not on `main` during the next garbage collection.\nHEAD~20:intro_intro_old.qmd:You create a test branch and switch to it:\nHEAD~20:intro_intro_old.qmd:To merge your main branch and your test branch, a new commit is now required (note that the command is the same as in the case of a fast-forward merge: `git merge`. Git will create the new commit automatically. As long as there is no conflict, it is just as easy as a fast-forward merge. We will talk later about resolving conflicts).\nHEAD~20:intro_intro_old.qmd:After which, you can delete the (now useless) test branch (with `git branch -d test2`):\nHEAD~20:intro_remotes.qmd:Click on the `Code` green drop-down button, select SSH [if you have set SSH for your GitHub account](https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/connecting-to-github-with-ssh) or HTTPS and copy the address.\nHEAD~20:intro_revisiting_old_commits_alternate.qmd:The pointer `HEAD`, which normally points to the branch `main` which itself points to latest commit, can be moved around. By moving `HEAD` to any commit, you can revisit the state of your project at that particular version.\nHEAD~20:intro_undo.qmd:Here is a common scenario: you make a commit, then realize that you forgot to include some changes in that commit; or you aren't happy with the commit message; or both. You can edit your latest commit with the `--amend` flag:\nHEAD~20:ws_collab.qmd:Click on the `Code` green drop-down button, select SSH [if you have set SSH for your GitHub account](https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/connecting-to-github-with-ssh) or HTTPS and copy the address.\n\n\n\nAs you can see, the file src/test_manuel.py is not in the results. Either it didn‚Äôt exist or it didn‚Äôt have the word test at that commit.\n\nIf you want to search tracked files AND untracked files, you need to use the --untracked flag.\nLet‚Äôs create a new (thus untracked) file with some content including the word test:\n\necho \"This is a test\" &gt; newfile\n\nNow compare the following:\n\ngit grep -c test\n\nintro_aliases.qmd:5\nintro_branches.qmd:17\nintro_intro_old.qmd:9\nintro_remotes.qmd:1\nintro_revisiting_old_commits_alternate.qmd:1\nintro_undo.qmd:1\nws_collab.qmd:1\n\n\nwith:\n\ngit grep -c --untracked test\n\nindex.html:1\nintro_aliases.html:4\nintro_aliases.qmd:5\nintro_branches.html:18\nintro_branches.qmd:17\nintro_changes.html:1\nintro_documentation.html:1\nintro_first_steps.html:1\nintro_ignore.html:1\nintro_install.html:1\nintro_intro.html:1\nintro_intro_old.qmd:9\nintro_intro_slides.html:18\nintro_logs.html:1\nintro_remotes.html:2\nintro_remotes.qmd:1\nintro_reset.html:1\nintro_resources.html:1\nintro_revisiting_old_commits_alternate.html:2\nintro_revisiting_old_commits_alternate.qmd:1\nintro_stash.html:1\nintro_tags.html:1\nintro_three_trees.html:1\nintro_time_travel.html:1\nintro_tools.html:1\nintro_undo.html:2\nintro_undo.qmd:1\nnewfile:1\ntop_intro.html:1\ntop_ws.html:1\nwb_dvc.html:1\nws_collab.html:2\nws_collab.qmd:1\nws_contrib.html:1\nws_search.rmarkdown:41\n\n\n\nThis last result also returned our untracked file newfile.\n\nIf you want to search untracked and ignored files (meaning all your files), use the flags --untracked --no-exclude-standard.\nLet‚Äôs see what the .gitignore file contains:\n\ncat .gitignore\n\ncat: .gitignore: No such file or directory\n\n\nThe directory data is in .gitignore. This means that it is not under version control and it thus doesn‚Äôt exist in our repo (since we cloned our repo, we only have the version-controlled files). Let‚Äôs create it:\nmkdir data\nNow, let‚Äôs create a file in it that contains test:\n\necho \"And another test\" &gt; data/file\n\nbash: line 1: data/file: No such file or directory\n\n\nWe can rerun our previous two searches to verify that files excluded from version control are not searched:\n\ngit grep -c test\n\nintro_aliases.qmd:5\nintro_branches.qmd:17\nintro_intro_old.qmd:9\nintro_remotes.qmd:1\nintro_revisiting_old_commits_alternate.qmd:1\nintro_undo.qmd:1\nws_collab.qmd:1\n\n\n\ngit grep -c --untracked test\n\nindex.html:1\nintro_aliases.html:4\nintro_aliases.qmd:5\nintro_branches.html:18\nintro_branches.qmd:17\nintro_changes.html:1\nintro_documentation.html:1\nintro_first_steps.html:1\nintro_ignore.html:1\nintro_install.html:1\nintro_intro.html:1\nintro_intro_old.qmd:9\nintro_intro_slides.html:18\nintro_logs.html:1\nintro_remotes.html:2\nintro_remotes.qmd:1\nintro_reset.html:1\nintro_resources.html:1\nintro_revisiting_old_commits_alternate.html:2\nintro_revisiting_old_commits_alternate.qmd:1\nintro_stash.html:1\nintro_tags.html:1\nintro_three_trees.html:1\nintro_time_travel.html:1\nintro_tools.html:1\nintro_undo.html:2\nintro_undo.qmd:1\nnewfile:1\ntop_intro.html:1\ntop_ws.html:1\nwb_dvc.html:1\nws_collab.html:2\nws_collab.qmd:1\nws_contrib.html:1\nws_search.rmarkdown:41\n\n\nAnd now, let‚Äôs try:\n\ngit grep -c --untracked --no-exclude-standard test\n\nindex.html:1\nintro_aliases.html:4\nintro_aliases.qmd:5\nintro_branches.html:18\nintro_branches.qmd:17\nintro_changes.html:1\nintro_documentation.html:1\nintro_first_steps.html:1\nintro_ignore.html:1\nintro_install.html:1\nintro_intro.html:1\nintro_intro_old.qmd:9\nintro_intro_slides.html:18\nintro_logs.html:1\nintro_remotes.html:2\nintro_remotes.qmd:1\nintro_reset.html:1\nintro_resources.html:1\nintro_revisiting_old_commits_alternate.html:2\nintro_revisiting_old_commits_alternate.qmd:1\nintro_stash.html:1\nintro_tags.html:1\nintro_three_trees.html:1\nintro_time_travel.html:1\nintro_tools.html:1\nintro_undo.html:2\nintro_undo.qmd:1\nnewfile:1\ntop_intro.html:1\ntop_ws.html:1\nwb_dvc.html:1\nws_collab.html:2\nws_collab.qmd:1\nws_contrib.html:1\nws_search.rmarkdown:41\n\n\n\ndata/file, despite being excluded from version control, is also searched.\n\n\n\nSearching all commits\nWe saw that git grep &lt;pattern&gt; &lt;commit&gt; can search a pattern in any commit. Now, what if we all to search all commits for a pattern?\nFor this, we pass the expression $(git rev-list --all) in lieu of &lt;commit&gt;.\ngit rev-list --all creates a list of all the commits in a way that can be used as an argument to other functions. The $() allows to run the expression inside it and pass the result as and argument.\nTo search for test in all the commits, we thus run:\ngit grep \"test\" $(git rev-list --all)\nI am not running this command has it has a huge output. Instead, I will limit the search to the last two commits:\n\ngit grep \"test\" $(git rev-list --all -2)\n\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_aliases.qmd:Now, let's build an alias for a more complex command: `git grep \"test\" $(git rev-list --all)`. This example\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_aliases.qmd:from the *\"Searching a Git project\"* section below will search for the string \"test\" in all previous\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_aliases.qmd:commits. There are two problems with this command: (1) it takes an argument (the string \"test\"), and (2) it\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_aliases.qmd:git search test\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_aliases.qmd:should search the entire current Git project history for \"test\".\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_branches.qmd:git branch test\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_branches.qmd:git switch test\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_branches.qmd:* test\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_branches.qmd:The `*` shows the branch you are currently on (i.e. the branch to which `HEAD` points to). In our example, the project has two branches and we are on the branch `test`.\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_branches.qmd:git diff main test\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_branches.qmd:When you are happy with the changes you made on your test branch, you can merge it into `main`.\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_branches.qmd:If you have only created new commits on the branch `test`, the merge is called a \"fast-forward merge\" because `main` and `test` have not diverged: it is simply a question of having `main` catch up to `test`.\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_branches.qmd:git merge test\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_branches.qmd:Then, usually, you delete the branch `test` as it has served its purpose:\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_branches.qmd:git branch -d test\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_branches.qmd:Alternatively, you can switch back to `test` and do the next bit of experimental work on it. This allows to keep `main` free of mishaps and bad developments.\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_branches.qmd:Let's go back to our situation before we created the branch `test`:\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_branches.qmd:This time, you create a branch called `test2`:\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_branches.qmd:To merge your branch `test2` into `main`, a new commit is now required. Git will create this new commit automatically. As long as there is no conflict, it is just as easy as a fast-forward merge:\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_branches.qmd:git merge test2\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_branches.qmd:After which, you can delete the (now useless) test branch (with `git branch -d test2`):\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_branches.qmd:&gt;&gt;&gt;&gt;&gt;&gt;&gt; test2\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_intro_old.qmd:The pointer `HEAD`, which normally points to the branch `main` which itself points to latest commit, can be moved around. By moving `HEAD` to any commit, you can revisit the state of your project at that particular version.\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_intro_old.qmd:Instead of working on your branch `main`, you create a test branch and work on it (so `HEAD` is on the branch `test` and both move along as you create commits):\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_intro_old.qmd:When you are happy with the changes you made on your test branch, you decide to merge `main` onto it.\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_intro_old.qmd:Then you do the fast-forward merge from `main` onto `test` (so `main` catches up to `test`):\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_intro_old.qmd:Then, usually, you delete the branch `test` as it has served its purpose (with `git branch -d test`). Alternatively, you can switch back to it and do the next bit of experimental work in it.\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_intro_old.qmd:This allows to keep `main` free of possible mishaps and bad developments (if you aren't happy with the work you did on your test branch, you can simply delete it and Git will clean the commits that are on it but not on `main` during the next garbage collection.\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_intro_old.qmd:You create a test branch and switch to it:\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_intro_old.qmd:To merge your main branch and your test branch, a new commit is now required (note that the command is the same as in the case of a fast-forward merge: `git merge`. Git will create the new commit automatically. As long as there is no conflict, it is just as easy as a fast-forward merge. We will talk later about resolving conflicts).\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_intro_old.qmd:After which, you can delete the (now useless) test branch (with `git branch -d test2`):\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_remotes.qmd:Click on the `Code` green drop-down button, select SSH [if you have set SSH for your GitHub account](https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/connecting-to-github-with-ssh) or HTTPS and copy the address.\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_revisiting_old_commits_alternate.qmd:The pointer `HEAD`, which normally points to the branch `main` which itself points to latest commit, can be moved around. By moving `HEAD` to any commit, you can revisit the state of your project at that particular version.\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:intro_undo.qmd:Here is a common scenario: you make a commit, then realize that you forgot to include some changes in that commit; or you aren't happy with the commit message; or both. You can edit your latest commit with the `--amend` flag:\nf1802fb9273fdbaad5fa0f1381ff8b18a84a15ce:ws_collab.qmd:Click on the `Code` green drop-down button, select SSH [if you have set SSH for your GitHub account](https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/connecting-to-github-with-ssh) or HTTPS and copy the address.\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_aliases.qmd:Now, let's build an alias for a more complex command: `git grep \"test\" $(git rev-list --all)`. This example\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_aliases.qmd:from the *\"Searching a Git project\"* section below will search for the string \"test\" in all previous\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_aliases.qmd:commits. There are two problems with this command: (1) it takes an argument (the string \"test\"), and (2) it\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_aliases.qmd:git search test\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_aliases.qmd:should search the entire current Git project history for \"test\".\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_branches.qmd:git branch test\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_branches.qmd:git switch test\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_branches.qmd:* test\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_branches.qmd:The `*` shows the branch you are currently on (i.e. the branch to which `HEAD` points to). In our example, the project has two branches and we are on the branch `test`.\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_branches.qmd:git diff main test\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_branches.qmd:When you are happy with the changes you made on your test branch, you can merge it into `main`.\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_branches.qmd:If you have only created new commits on the branch `test`, the merge is called a \"fast-forward merge\" because `main` and `test` have not diverged: it is simply a question of having `main` catch up to `test`.\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_branches.qmd:git merge test\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_branches.qmd:Then, usually, you delete the branch `test` as it has served its purpose:\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_branches.qmd:git branch -d test\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_branches.qmd:Alternatively, you can switch back to `test` and do the next bit of experimental work on it. This allows to keep `main` free of mishaps and bad developments.\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_branches.qmd:Let's go back to our situation before we created the branch `test`:\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_branches.qmd:This time, you create a branch called `test2`:\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_branches.qmd:To merge your branch `test2` into `main`, a new commit is now required. Git will create this new commit automatically. As long as there is no conflict, it is just as easy as a fast-forward merge:\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_branches.qmd:git merge test2\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_branches.qmd:After which, you can delete the (now useless) test branch (with `git branch -d test2`):\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_branches.qmd:&gt;&gt;&gt;&gt;&gt;&gt;&gt; test2\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_intro_old.qmd:The pointer `HEAD`, which normally points to the branch `main` which itself points to latest commit, can be moved around. By moving `HEAD` to any commit, you can revisit the state of your project at that particular version.\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_intro_old.qmd:Instead of working on your branch `main`, you create a test branch and work on it (so `HEAD` is on the branch `test` and both move along as you create commits):\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_intro_old.qmd:When you are happy with the changes you made on your test branch, you decide to merge `main` onto it.\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_intro_old.qmd:Then you do the fast-forward merge from `main` onto `test` (so `main` catches up to `test`):\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_intro_old.qmd:Then, usually, you delete the branch `test` as it has served its purpose (with `git branch -d test`). Alternatively, you can switch back to it and do the next bit of experimental work in it.\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_intro_old.qmd:This allows to keep `main` free of possible mishaps and bad developments (if you aren't happy with the work you did on your test branch, you can simply delete it and Git will clean the commits that are on it but not on `main` during the next garbage collection.\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_intro_old.qmd:You create a test branch and switch to it:\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_intro_old.qmd:To merge your main branch and your test branch, a new commit is now required (note that the command is the same as in the case of a fast-forward merge: `git merge`. Git will create the new commit automatically. As long as there is no conflict, it is just as easy as a fast-forward merge. We will talk later about resolving conflicts).\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_intro_old.qmd:After which, you can delete the (now useless) test branch (with `git branch -d test2`):\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_remotes.qmd:Click on the `Code` green drop-down button, select SSH [if you have set SSH for your GitHub account](https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/connecting-to-github-with-ssh) or HTTPS and copy the address.\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_revisiting_old_commits_alternate.qmd:The pointer `HEAD`, which normally points to the branch `main` which itself points to latest commit, can be moved around. By moving `HEAD` to any commit, you can revisit the state of your project at that particular version.\n397ef976e18724c06713ffbf7ebe205b7016a35f:intro_undo.qmd:Here is a common scenario: you make a commit, then realize that you forgot to include some changes in that commit; or you aren't happy with the commit message; or both. You can edit your latest commit with the `--amend` flag:\n397ef976e18724c06713ffbf7ebe205b7016a35f:ws_collab.qmd:Click on the `Code` green drop-down button, select SSH [if you have set SSH for your GitHub account](https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/connecting-to-github-with-ssh) or HTTPS and copy the address.\n\n\n\nIn combination with the fuzzy finder tool fzf, this can make finding a particular commit extremely easy.\nFor instance, the code below allows you to dynamically search in the result through incremental completion:\ngit grep \"test\" $(git rev-list --all) | fzf --cycle -i -e\nOr even better, you can automatically copy the short form of the hash of the selected commit to clipboard so that you can use it with git show, git checkout, etc.:\ngit grep \"test\" $(git rev-list --all) |\n    fzf --cycle -i -e |\n    cut -c 1-7 |\n    xclip -r -selection clipboard\n\nHere, I am using xclip to copy to the clipboard as I am on Linux. Depending on your OS you might need to use a different tool.\n\nOf course, you can create a function in your .bashrc file with such code so that you wouldn‚Äôt have to type it each time:\ngrep_all_commits () {\n    git grep \"$1\" $(git rev-list --all) |\n        fzf --cycle -i -e |\n        cut -c 1-7 |\n        xclip -r -selection clipboard\n}\nAlternatively, you can pass the result directly into whatever git command you want to use that commit for.\nHere is an example with git show:\ngit grep \"test\" $(git rev-list --all) |\n    fzf --cycle -i -e |\n    cut -c 1-7 |\n    git show\nAnd if you wanted to get really fancy, you could go with:\ngit grep \"test\" $(git rev-list --all) |\n    fzf --cycle -i -e --no-multi \\\n        --ansi --preview=\"$_viewGitLogLine\" \\\n        --header \"enter: view, C-c: copy hash\" \\\n        --bind \"enter:execute:$_viewGitLogLine | less -R\" \\\n        --bind \"ctrl-c:execute:$_gitLogLineToHash |\n        xclip -r -selection clipboard\"\nWrapped in a function:\ngrep_all_commits_preview () {\n    git grep \"$1\" $(git rev-list --all) |\n        fzf --cycle -i -e --no-multi \\\n            --ansi --preview=\"$_viewGitLogLine\" \\\n            --header \"enter: view, C-c: copy hash\" \\\n            --bind \"enter:execute:$_viewGitLogLine |\n              less -R\" \\\n            --bind \"ctrl-c:execute:$_gitLogLineToHash |\n        xclip -r -selection clipboard\"\n}\nThis last function allows you to search through all the results in an incremental fashion while displaying a preview of the selected diff (the changes made at that particular commit). If you want to see more of the diff than the preview displays, press &lt;enter&gt; (then q to quit the pager), if you want to copy the hash of a commit, press C-c (Control + c).\nWith this function, you can now instantly get a preview of the changes made to any line containing an expression for any file, at any commit, and copy the hash of the selected commit. This is really powerful.\n\n\n\nAliases\nIf you don‚Äôt want to type a series of flags all the time, you can configure aliases for Git. For instance, Alex Razoumov uses the alias git search for git grep --break --heading -n -i.\nLet‚Äôs add to it the -p flag. Here is how you would set this alias:\ngit config --global alias.search 'grep --break --heading -n -i -p'\n\nThis setting gets added to your main Git configuration file (on Linux, by default, at ~/.gitconfig).\n\nFrom there on, you can use your alias with:\n\ngit search test\n\ngit: 'search' is not a git command. See 'git --help'."
  },
  {
    "objectID": "git/ws_search.html#searching-logs",
    "href": "git/ws_search.html#searching-logs",
    "title": "Searching a version-controlled project",
    "section": "Searching logs",
    "text": "Searching logs\nThe second thing that can happen is that you are looking for some pattern in your version control logs.\n\ngit log\ngit log allows to get information on commit logs.\nBy default, it outputs all the commits of the current branch.\nLet‚Äôs show the logs of the last 3 commits:\n\ngit log -3\n\ncommit f1802fb9273fdbaad5fa0f1381ff8b18a84a15ce\nAuthor: Marie-Helene Burle &lt;marie.burle@westdri.ca&gt;\nDate:   Wed Apr 24 12:26:52 2024 -0700\n\n    update site\n\ncommit 397ef976e18724c06713ffbf7ebe205b7016a35f\nAuthor: Marie-Helene Burle &lt;marie.burle@westdri.ca&gt;\nDate:   Wed Apr 24 12:26:43 2024 -0700\n\n    styles: improve callouts\n\ncommit e24aebab9ca82555effde05942503ba677df36e3\nAuthor: Marie-Helene Burle &lt;marie.burle@westdri.ca&gt;\nDate:   Wed Apr 24 12:25:09 2024 -0700\n\n    minor edits numpy\n\n\nThe output can be customized thanks to a plethora of options.\nFor instance, here are the logs of the last 15 commits, in a graph, with one line per commit:\n\ngit log --graph --oneline -n 15\n\n* f1802fb9 update site\n* 397ef976 styles: improve callouts\n* e24aebab minor edits numpy\n* 212577bc minor edit benchmark\n* 84337761 update site\n* b44b9816 big improvements benchmark\n* 45cd8e29 update site\n* 4d9e0e27 correct static function explanation + make graph bigger\n* 949277e2 jx numpy: change order headers\n* e0ccfb29 update site\n* e79d100d edit jax parallel\n* 5e7e0a0b update site\n* 7b202e6f small edits to jax parallel\n* 66f50cb4 add jax parallel to navbar\n* c9d7da6e update site\n\n\nBut git log has also flags that allow to search for patterns.\n\n\nSearching commit messages\nOne of the reasons it is so important to write informative commit messages is that they are key to finding commits later on.\nTo look for a pattern in all your commit messages, use git log --grep=&lt;pattern&gt;.\nLet‚Äôs look for test in the commit messages and limit the output to 3 commits:\n\ngit log --grep=test -3\n\ncommit 6f07fd90be8045378b482d5ca0175446b42797c8\nAuthor: Marie-Helene Burle &lt;marie.burle@westdri.ca&gt;\nDate:   Tue Feb 27 20:32:43 2024 -0800\n\n    add test csv data file into the site\n\ncommit 7167606e3188e9497768761963af0c4bdc7aad90\nAuthor: Marie-Helene Burle &lt;marie.burle@westdri.ca&gt;\nDate:   Tue Feb 27 20:16:20 2024 -0800\n\n    add test csv data file\n\ncommit 87f11c6715a5da31888dc6b92645156e6738d207\nAuthor: Marie-Helene Burle &lt;marie.burle@westdri.ca&gt;\nDate:   Mon Dec 18 14:06:51 2023 -0800\n\n    test blockquote media for phones\n\n\nFor a more compact output:\n\ngit log --grep=\"test\" -3 --oneline\n\n6f07fd90 add test csv data file into the site\n7167606e add test csv data file\n87f11c67 test blockquote media for phones\n\n\n\nHere too you can use this in combination to fzf with for instance:\ngit log --grep=\"test\" | fzf --cycle -i -e\nOr:\ngit log --grep=\"test\" --oneline |\n    fzf --cycle -i -e --no-multi \\\n        --ansi --preview=\"$_viewGitLogLine\" \\\n        --header \"enter: view, C-c: copy hash\" \\\n        --bind \"enter:execute:$_viewGitLogLine | less -R\" \\\n        --bind \"ctrl-c:execute:$_gitLogLineToHash |\n        xclip -r -selection clipboard\"\n\n\n\nChanges made to a pattern\nRemember that test was present in the file src/test_manuel.py. If we want to see when the pattern was first created and then each time it was modified, we use the -L flag in this fashion:\ngit log -L :&lt;pattern&gt;:file\nIn our case:\n\ngit log -L :test:src/test_manuel.py\n\nfatal: There is no path git/src/test_manuel.py in the commit\n\n\nThis is very useful if you want to see, for instance, changes made to a function in a script.\n\n\nChanges in number of occurrences of a pattern\nNow, if we want to list all commits that created a change in the number of occurrences of test in our project, we run:\n\ngit log -S test --oneline\n\n84337761 update site\n45cd8e29 update site\n93bb9017 add jax benchmark section\n112a5403 update site\n1c85d9fe edits to install\n5a3afe3a jax parallel: remove asynchronous dispatch moved to benchmarking section\n7da77a9a update site\nf0f936cc finish jax webinar slides presentation and embed resources\na847af69 update site\ncd5ac347 update site after embedding resources JAX webinar slides\n1639488f update site\ne5b6373a update site\nfc1e5925 improve jax jit\nc8da0b3d update site\nd395fe8b add intro to ipython + better formatting with tabset (rather than columns)\nb1e330ba add JAX section on jobs\n67a51585 add JAX section on installation\n361c27bf update title and abstract jax webinar\neba13650 update title and abstract jax course\nf84c38bc update site\n8877228e update site\ncd4d8869 update site\n4a6b96cb update site\nb3e68d9b update site\nf9abd0f1 update site\nf162c6a9 update site\nb0f28e7b update site\ncc696002 update site\n7f4d8801 update site\n373d2f49 add content in intro ml nlp slides\n93503a04 update site after full render\n0fa44f29 update site\ned3df92b update site\n8976cb6a update site\n7b1d418e update site\nc813fca7 update site\n4c2cca59 update site\n4ec83107 update\n289d7eee update\n2e9865d5 update\ndb5eebf7 update\nc59f0926 update\n84016b9c update\n62af7b93 update\n88bcbaba update\n428ee1db update\n97cf5731 update\n27bb78e3 add qmd files from molecules\n8e70f8b6 update site\ne395a204 update\nc0a93fbd add prefix (intro_, ws_, wb_) to bash, git, and tools sections\n63ba55fc update\ndbded239 update\n1ca5c158 update\n79ebb58b minor fixes dvc slides\nac8afe70 update\n525ca03c dvc slides before another big change\nd287f33c update\na6dc00eb update\na4e14d34 update\n91d6403f update\na38386a2 update\n413a323d update\ne126a321 update after render\nfee353f5 update\ne934a832 update site\n7e6fe93b update site after render\n10277778 update\ne2640dc6 update\n69ab00ba update site\n0cd6525f update site\n484054e8 update site\n7d4a19bb finish draft stateless\nf4bae193 update site\nc2aadc75 minor edits\ne9f983a8 update site\n8aa9f4e5 finish quick draft of parallel section\n719274ed update site\nb648de49 combine datasets loading from 3 options in one section\nba698653 update site\n169845ab version with: loading datasets with Hugging Face\n5376cca0 update site\n7aaf321f add state draft\n4d98a5b0 update site after full render\n4fbc9736 update site\nfbad50d0 update site\n7c19d98d update site\n92dad162 update site\n4a5ef1ea update site\nf763bc1a update site\n3b955ea5 update site\n27e1a097 update site\n3158ff17 update site\n7c132d5e update site\n141204ed add flax abstract\n52152ef3 update JAX abstract after removing dl part with flax\n8f250d57 update site\n255b3205 update freeze\nb61b6df9 update site\n99a77db3 finish jit draft\n57d56299 update site\nd7e0bcb9 finish jx numpy section\nd344ad8a update site\n858e5422 JAX: big revamp course structure\n62c400b2 update site\n1b2e846f jx principles: add async dispatch\n8c8116e0 update site\n09080851 update site\n8f32ea61 update site\ncd78f159 udpate site\n4a003c52 update site\n4b3bec75 update site\ne8e73865 update site\nc545c684 update site\n0b628db2 finish hpc data partition chapter\n1a5c59f7 save a version of hpc_partition before modifying it\n08552b77 update site\nc7fccd5b update site\nd85a0541 edit running htop on local machine\nb5fa9d35 update site\nacb1a4ff rename and heavily modify the foreach chapter\n4536fc63 add pics\n7c318e74 f4 and f5: do testing on the cluster and remove quarto comment\n2aa72b9b update site\n22192dbf add example releasing memory\n08d8f896 add jx profiling page\na841844f improve hpc optimization\nbde35ec8 improve intro indexing\nf1780432 jx why: replace gtrend embedded by img (keeps breaking), improve graph color, add abstract, add a bit of content\n78c3b7b9 add colors to jax intro diagrams\nfb5662b6 add a number of jx early drafts\nc54f6ed7 add new jx sections and update site using a virtual env for Python\ndbcfca2a add prefix for various sections in julia and r, prevent old and bk files from being executed/rendered, prevent webscraping files from being created\n43b79abd update site\n64ddfd7d small edits to hpc r before course\n9204ff32 add jax top intro\n09f64aee add info on profiling\n0cce7374 move jax below PyTorch as it is a more advanced course\nf33135e1 update gcc and r module versions\n96c23b77 update site\n279f6937 update site after full render\n084d5221 embed resources\nae9b67be update site\n4e9c611e more improvements and little tweaks frameworks slides. Add more info\nd58ae469 update site\n445bb296 improvements frameworks slides\n21882057 update site\nfd17244c update formatting framework slides\n185e051a update site\nbead0b06 many tweaks of formatting\nc68c4611 first very rough draft of frameworks slides\n09f1fe51 replace mermaid diagram in file system exercise with a graphviz one\nc6d4a350 filesystem: add exercise with a diagram\n2798c6a1 minor fix\n7a08552d update skl workflow\nac76eea3 update site\n8a504230 add sklearn workflow\nea800fde add an sklearn serie\nc7ac7301 update site\nccf1a85c added content to aliases.qmd\nf17c8c95 added aliases.qmd\ndc7aae4e update site\n74a4e08b finish logs\n0ffe3e1a add logs draft\n23827256 add project.zip\nc8afe95a add downloadthis extension\nfe3f956d add abstract to documentation section\nbb145734 edits intro slides\n40571641 embed resources intro slides\nffa2c749 total revamp of git intro with simply link to slides\n28032012 update ml course\n043c6cf4 minor edits r course\n4888db47 edit sections on how to run r\ne16c9467 update site\n44ceba8e update site\n0ece9c2e update site\n51b8534e replace old webscraping (Python) workshop to new version from DHSI\nfecc161b add webscraping old to gitignore\n4bb8faf0 little improvements web scraping R\nb784f17d update site\n91fa0247 update site\n3bbe8ac5 add (bad) intro blurb to Python course\n3a3361af update site\nf589a660 rename the ext section into talks\n73dfeda0 improvements collections section\n6617a5bc update site\n622631fc fix and improve pandas section\n3eaacd19 update site\nf8c47d0a add index for new big section (talks)\ne29ae75f update site\n9e6a1b8a edit scripts\n0f60d0db finish redirections\n583f27c1 add filesystem section\na7c08558 gis slides: fix typo\nfec32a19 makie: add content in html below video\n954eb10d makie slides: minor improvements\n90adee86 more info in workflow section\n2250d59a minor edits workflow\n39f737d4 add workflow section\n2cd8c6f3 update navbar by moving data, model, and training in a single section\n5f33a182 make backup of autograd in autograd_old and start to make new version of autograd (not complete)\nfc853e13 some edits to training, but still not complete\n01f0f732 finish tensor section\n24b059f9 finalize parallel loops\ne5401892 again many changes to parallel loops before changing yet again\n1428b5fa many changes to parallel loops before making yet many new alternative changes\n6abe68e0 move copy on modify from basics to indexing and make it better\nfd1d1408 update site\n0649af93 move concepts to reading and create a new intro section with slides\nba7938d1 update site\n2525e9e8 finish function section\nb71c7614 finish control flow section\n7f226584 finalize plotting section\n302627a3 add plotting section\na477bd4d add publishing page with links to quarto workshop and webinar\na30a0759 add data structures section\nc5a92ed6 add blurb basics\n68489a39 basics: change title + move a lot of content into section specific pages\n58e586ec packages: add blurb\n848f4362 update navbar\nb7284048 minor edits bash intro\n075dd527 update site\na519d857 create wildcards section\n42f51d4a rename file from search to find\n7df872bf add videos: 4 workshops for HSS series + staff to staff webinar + regular webinar\nb2e565c7 update site\n590bb505 quarto: add installation links\neca80cdb make slides less wordy based on the s2s webinar given on quarto\n43d1ea7f update site\nf424bba7 add slides for quarto staff to staff webinar\n1f33a777 update site\n99c7e56f add new minor optimization\ndd71a56a turn the parallel loop lesson from the webinar version to the workshop version using batch jobs\n07871c1f add 2nd optimization by louis\n55e7c61a update site\nabb1ced7 update site\nf758b8c1 update site\n61f3b8ec add function suggested by workshop participant\n649f8258 update site\nbafb7696 remove profiler from performance section\n176e5ba4 finish optimization section\n3d42df1c add section on memory\n1ba9cc4a important commit: remove \"avoid type conversions\" in R hpc optimizations section as this doesn't change the timing consistently\nb64856dd first draft optimizations\na563fa97 re-render site\n95086e88 update site\n473d722b many edits r resource page\ne0ab5c78 tweak all heading levels\n934f9a86 update site\n37cef298 remove front page for workshops and webinars + add logo image for front page for intro and hpc courses + re-shuffle a few sections + move most ml topics into a course + minor edits (abstract, etc.)\nfc82cf5d update site\n3bcf2df8 rename first git section of git course to match structure of other topics\n628525d5 fix how to download bash data\n952d027c create front pages for Bash and cards on main topic page\nc6ea3e02 add buttons to r main page\nf3e70692 several improvements to web scraping\nc5258d5f split parallel r section into 3 section and add improvements and edits\n046b607d minor fixes hss slides\ncda4fc9d add missing image and very minor edits ml hss slides\nb9f8b5f5 embed resources intro hss ml slides\n898cdd93 update site\n4c07296e add intro ml for hss slides\n38a825da many formatting edits all reveal.js presentations\n8688a717 replace workshop by webinar in all webinars\n20224c1e update site\n50fcdc72 finish script section (shortened. Need to add more content)\n5ef06d8d finish function section\nbf2653fa move control flow, script, and search to molecules folder\nbad3da30 transfer: add globus and abstract\ne7412c33 finish redirections and move it to the molecules repo to run code\n23bed49d add html_children\n9ff42fbe add html section\n9c2f06ef add delay at each iteration to reduce risk of being blocked\n246c64d1 web scraping: minor edits and improvements\n0d08979d add explanations and comments web scraping\n4599ed35 disable cache for webscraping as it conflicts with rvest\n2703353f minor edit nav titles\n5cd69306 change rstudio server time to 1.5h and remove jh option image as it is not the right one\n8159f9b2 minor edits: add some explanations, improve code a bit\nb78b4b6d add first decent draft webscraping with more or less all code and some explanations\n1c251034 add alliance wiki page for r in intro hss resources\ncf851391 first draft bash redirections and pipes\n03b9e332 first draft bash script\n20a392b6 add a little content to intro r\n5c3cfb03 add 2 new sections (not covered by alex)\nfb69b01d add draft content to intro hss r\n6c6d0cf3 add bash empty chapters for online course\nb900e688 intro hpc slides by re-embeding resources\n66bca7e2 fix typo git search\nd72b1706 finish hpc r slides\n1f14f6be open link to hpc slides\n95f20745 finish control flow chapter\n12d248d8 add many little things in list and make a correction for strings\nc9d2e1dd update site\na65bd054 remove out of the package section everything that can live elsewhere\n173d128f move content jh instructions to a new chapter on running Python\nb259e525 remove alex acknowledgement\nb4b87e69 minor edit git front page\nbb2c6fe2 add acknowledgement of alex content\ndd132ab7 supress redundancy between basic and functions\n6f2f0ae4 finish list section (Python)\ndb33cd1f finish basic chapter (Python)\n7ac57447 first draft collections\n04db2fcc edit basics\nfd677ff1 add first draft Python intro hpc copied from Julia. Still needs lots of work\n7464d141 add first draft Python functions (not far from ready)\n1ccb1569 add first draft web scraping in Python\n663e401f yml: uncomment Python tab and add first two Python workshops\n4450be7c add alias\n479f1aa6 many small edits search + add fzf example for searching the logs\n2556ab4e update site\nc53e0f51 add a big info block with more fancy searches using fzf\n1752db62 first final version of search workshop\nfab10006 minor updates hpc r slides\n534a0da6 first draft hpc in r slides\n2f647bd8 remove unnecessary jupyter: python3 in 2 ml revealjs\n919d2061 git lessons: adjust img new names + fixes, corrections, improvements\n7a3d5b13 rename all git diagram img in some sensible order\n16ca4f6a finish branches and add it to the nav\n2725f415 improve front page image\n115aa01f edits many julia files: remove unnecessary jupyter: julia-1.8, small additions, small fixes, small improvements\n9db0e744 add preliminary draft of branches (git) and commented out nav entry\n4ca06a6a add distributed (julia)\na181d66f add symlink for search.qmd which is in the nested git repo\nbdb30cb3 edit control flow\nda7332f8 add remotes\n774a9d45 rename git main workshop\n8f8eb031 add tags and its img\nc1d8385f add multithreading\na31c5aad edits, additions, fixes\n2ba97085 remove from basics elements moved to other files\n8472020c remove from intro hpc everything that is intro julia (move it in various other sections)\na8f09800 turn arrays to collections and add content\n0cc0c59a add julia functions\n1d65319d add julia control flow\n5ec2bccf add julia basics\n22494671 add julia types\n4b09f00e add julia performance\n55813908 add non interactive julia\nf9dd47ca add julia arrays\nea059d51 edit paths and remove shadow img three trees\n38e370fe add undo\n29eb1ac1 add tools\n81fa8648 add stashing\n73ee1b14 add ignore\nd8970df8 add three trees of git\n8148a866 move all top levels to h2 instead of h1 following chat with quarto developpers\n4637b686 julia intro: change header levels + reformat all code blocks\nc072c6c9 add packages\n1601205a add r resources\n3e81b34a add contrib workshop\n5cc2efa0 move section about collaboration through git to new workshop\n96108ed4 uncomment grid section with wider body width\ncddb972c add ml hpc.qmd\n6fa885a4 add quarto link to about\n08e488af make all page start with h1 instead of h2 + add author where missing + move intro to def block\nf09e60bf update site\n9f97ec82 add 5 new ml workshops\n50a465a0 add note about revealjs presentations slow to load in all links\n2a6a3faf improvement to mnist: small additions + run code\ne2056339 add choosing frameworks\n2e281131 add concept workshop in ml\n68183ee7 add autograd to workshops\n8e6c61c4 add mnist to workshops\ne8b21668 add intro scripting workshop\n6e5faa1f add julia intro hpc workshop\n2ab3deb6 add julia covid plotting\n7e19653b add torchtensor slides\n515a4ddb fix R logo (not good on light bg) and add logos for all other sections\n6a781ea0 rename ml intro hss\n06496189 finish formatting upscaling slides\n44bc8530 reduce high res pics upscaling because GitHub's limit is reach with revealjs with self embedded option\n7989e1a5 add gis mapping slides\n0454b612 add upscaling slides\nd9e4e106 turn link to slides into buttons\n82356532 add _site to vc to solve publish issue on GitHub\neb7f3b17 delete publish.yml for GitHub actions\n82781458 update freeze\nf7f08ca0 update freeze\n74174941 update freeze\nccc30a73 update freeze\n9ef79da4 update freeze\nf23a4123 remove in code lengthy comment and add note instead\nb75bf0d5 add custom title-slide.html with partial template for revealjs title slide\n16ebe722 re-add makie slides *after* having rebuilt the site with freeze true\n348b7acb remove makie slides\nf131770c makie webinar: re-add slides\n36539180 remove makie slides for now for gh actions to build\necda9e1d update freeze with julia makie slides\nff2ec56b add makie slides\n6d406585 front page: switch buttons to cards and readjust content accordingly\nfc203393 update freeze\n4ceac573 add outputs of quarto demos so as not to have to run them all the time (annoying with latex). works with blocking rendering of that dir in yml\n0bbc3117 update freeze with computations from r the basics\n71c4ab68 add r the basics from autumn school 22 to r workshops\nb2e73700 add all quarto example files\n358bfb88 add quarto webinar\n818cb8c7 first commit with _freeze (for the quarto examples)\n8b21abf0 add all ml webinars\nfeafdc57 front page: finalize title and add aside about main site\n13dad000 big changes to about page\n3dd050c0 add publish.yml file for GitHub actions\nb6fc959e add 2022_git_sfu.qmd\n\n\nThis can be useful to identify the commit you need."
  },
  {
    "objectID": "git/ws_search.html#tldr",
    "href": "git/ws_search.html#tldr",
    "title": "Searching a version-controlled project",
    "section": "TL;DR",
    "text": "TL;DR\nHere are the search functions you are the most likely to use:\n\nSearch for a pattern in the current version of your tracked files:\n\ngit grep &lt;pattern&gt;\n\nSearch for a pattern in your files at a certain commit:\n\ngit grep &lt;pattern&gt; &lt;commit&gt;\n\nSearch for a pattern in your files in all the commits:\n\ngit grep &lt;pattern&gt; $(git rev-list --all)\n\nSearch for a pattern in your commit messages:\n\ngit log --grep=&lt;pattern&gt;\nNow you should be able to find pretty much anything in your projects and their histories."
  },
  {
    "objectID": "git/ws_collab.html",
    "href": "git/ws_collab.html",
    "title": "Collaborating through Git & GitHub",
    "section": "",
    "text": "Using Internet hosting services such as GitHub, Git is a powerful collaboration tool.\nIn this workshop, we will cover the three classic collaboration situations and see how a collaborative workflow works.",
    "crumbs": [
      "Git",
      "<b><em>Workshops</em></b>",
      "Collaborating through Git"
    ]
  },
  {
    "objectID": "git/ws_collab.html#three-situations",
    "href": "git/ws_collab.html#three-situations",
    "title": "Collaborating through Git & GitHub",
    "section": "Three situations",
    "text": "Three situations\nWhen you collaborate on a project through Git and a remote such as GitHub, there are three situations:\n\nyou create a project on your machine and want others to contribute to it (1),\nyou want to contribute to a project started by others and\n\nyou have write access to it (2),\nyou do not have write access to it (3).\n\n\n\n(1) You start the project\nIn this first situation, you are the author of a project (you have a project under version control on your own machine) and you want to initiate a collaboration with others on it using GitHub as a remote.\n\nCreate a remote on GitHub\nYou need to create a remote on GitHub.\n\nCreate a free GitHub account\nIf you don‚Äôt already have one, sign up for a free GitHub account.\n\nTo avoid having to type your password all the time, you should set up SSH for your account.\n\n\n\nCreate a repository on GitHub\n\nGo to the GitHub website, login, and go to your home page.\nLook for the Repositories tab & click the green New button.\nEnter the name you want for your repo, without spaces.\nMake the repository public or private.\n\n\n\nLink GitHub repo to local repo\nClick on the Code green drop-down button, select SSH if you have set SSH for your GitHub account or HTTPS and copy the address.\nIn the command line, cd inside your project, and add the remote:\ngit remote add &lt;remote-name&gt; &lt;remote-address&gt;\nremote-name is a convenience name to identify that remote. You can choose any name, but since Git automatically call the remote origin when you clone a repo, it is common practice to use origin as the name for the first remote.\n\nExample (using an SSH address):\n\ngit remote add origin git@github.com:&lt;user&gt;/&lt;repo&gt;.git\n\nExample (using an HTTPS address):\n\ngit remote add origin https://github.com/&lt;user&gt;/&lt;repo&gt;.git\nIf you don‚Äôt want to grant others write access to the project, and you only accept contributions through pull requests, you are set.\nIf you want to grant your collaborators write access to the project however, you need to add them to it.\n\n\n\nInvite collaborators\n\nGo to your GitHub project page.\nClick on the Settings tab.\nClick on the Manage access section on the left-hand side (you will be prompted for your GitHub password).\nClick on the Invite a collaborator green button.\nInvite your collaborators with one of their GitHub user name, their email address, or their full name.\n\n\n\n\n(2) Write access to project\nIn this second situation, someone else started a project and they are inviting you to collaborate to it, giving you write access to the project.\nIn this case, you need to clone the project: cd to the location where you want your local copy, then:\ngit clone &lt;remote-address&gt; &lt;local-name&gt;\nThis sets the project as a remote to your new local copy and that remote is automatically called origin.\nWithout &lt;local-name&gt;, the repo will have the name of the last part of the remote address.\n\n\n(3) No write access to project\nIn this third situation, someone else started a project and you want to collaborate to it, but you do not have write access to it.\nIn this case, you will have to submit pull requests.\nHere is the workflow for a pull request (PR):\n\nFork the project on GitHub.\nClone your fork on your machine.\nAdd the initial project as a second remote & call it upstream.\nPull from upstream to update your local project.\nCreate & checkout a new branch.\nMake & commit your changes on that branch.\nPush that branch to your fork (i.e.¬†origin ‚Äî remember that you do not have write access to upstream).\nGo to the original project GitHub‚Äôs page & open a pull request.",
    "crumbs": [
      "Git",
      "<b><em>Workshops</em></b>",
      "Collaborating through Git"
    ]
  },
  {
    "objectID": "git/ws_collab.html#collaborative-workflow",
    "href": "git/ws_collab.html#collaborative-workflow",
    "title": "Collaborating through Git & GitHub",
    "section": "Collaborative workflow",
    "text": "Collaborative workflow\n\nPulling and pushing\nWhen you collaborate with others using GitHub (or other remote), you and others will work simultaneously on some project. How does this work?\nTo upload your changes to the remote on GitHub you push to it with git push.\nIf one of your collaborators has made changes to the remote (pushing from their own local version of the project), you won‚Äôt be able to push. Instead, you will get the following message:\nTo xxx.git\n ! [rejected]        main -&gt; main (fetch first)\nerror: failed to push some refs to 'xxx.git'\nhint: Updates were rejected because the remote contains work that you do\nhint: not have locally. This is usually caused by another repository pushing\nhint: to the same ref. You may want to first integrate the remote changes\nhint: (e.g., 'git pull ...') before pushing again.\nhint: See the 'Note about fast-forwards' in 'git push --help' for details.\nThe solution?\nYou first have to download (git pull) their work onto your machine, merge it with yours (which will happen automatically if there are no conflicts), before you can push your work to GitHub.\nNow‚Ä¶ what if there are conflicts?\n\n\nResolving conflicts\n\n\n\nFrom crystallize.com\n\n\nGit works line by line. As long as your collaborators and you aren‚Äôt working on the same line(s) of the same file(s) at the same time, there will not be any problem. If however you modified one or more of the same line(s) of the same file(s), Git will not be able to decide which version should be kept.\nWhen you git pull their work on your machine, the automatic merging will get interrupted and Git will ask you to resolve the conflict(s) before the merge can resume. It will conveniently tell you which file(s) contain the conflict(s).\nThere are fancy tools to resolve conflicts, but you can do it in any text editor: simply open the file(s) listed by Git as having conflicts and look for the following markers:\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nThis is your version.\n=======\nThis is the alternative version of the same section of the file.\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; alternative version\nThese markers are added by Git to signal the areas of conflict. It is up to you to choose between the two versions (or create a third one) and remove the conflict markers. After that, you can stage the file(s) which contained the conflicts to finish the merge (and then you can commit).",
    "crumbs": [
      "Git",
      "<b><em>Workshops</em></b>",
      "Collaborating through Git"
    ]
  },
  {
    "objectID": "git/wb_lazygit_content.html",
    "href": "git/wb_lazygit_content.html",
    "title": "A great Git TUI: lazygit",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "Git",
      "<b><em>Webinars</em></b>",
      "A great Git TUI: lazygit",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "git/wb_lazygit_content.html#git-interfaces",
    "href": "git/wb_lazygit_content.html#git-interfaces",
    "title": "A great Git TUI: lazygit",
    "section": "Git interfaces",
    "text": "Git interfaces\nThere are 3 main ways to use Git:\n\nThrough a Git GUI.\nFrom the command line.\nIntegrated within IDE.\n\nThey all have downsides:\n\n\n\n\nThrough a Git GUI\nFrom the command line\nIntegrated within IDE\n\n\n\n‚ûî\n‚ûî\n‚ûî\n\n\nSlow and buggy\nAustere and unintuitive\nLimited",
    "crumbs": [
      "Git",
      "<b><em>Webinars</em></b>",
      "A great Git TUI: lazygit",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "git/wb_lazygit_content.html#on-the-beauty-of-tuis",
    "href": "git/wb_lazygit_content.html#on-the-beauty-of-tuis",
    "title": "A great Git TUI: lazygit",
    "section": "On the beauty of TUIs",
    "text": "On the beauty of TUIs\nTerminal user interfaces (TUIs) were precursors to graphical user interfaces (GUIs), but they did not disappear. People continue to build TUIs because they uniquely provide the speed of the command line and the easy of use of GUIs.\nGitHub is full of sleek, modern, open source TUIs for all sorts of applications.\nSeveral of them provide an interface to Git. lazygit is my favourite one.",
    "crumbs": [
      "Git",
      "<b><em>Webinars</em></b>",
      "A great Git TUI: lazygit",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "git/wb_lazygit_content.html#lazygit",
    "href": "git/wb_lazygit_content.html#lazygit",
    "title": "A great Git TUI: lazygit",
    "section": "lazygit",
    "text": "lazygit\nWith over 52k stars on GitHub, lazygit, created and maintained by Jesse Duffield is probably the most polished Git TUI.\nI followed it as it grew and developed over the past 5 years. It was great from the start, but by now, it is a truly beautiful mature tool.\nIt is cross-platform. You can find installation instructions in the README.\nGet command options:\nlazygit -h\nPrint default configurations with:\nlazygit -c\n\nlazygit is fully customizable.",
    "crumbs": [
      "Git",
      "<b><em>Webinars</em></b>",
      "A great Git TUI: lazygit",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "git/wb_lazygit_content.html#resources",
    "href": "git/wb_lazygit_content.html#resources",
    "title": "A great Git TUI: lazygit",
    "section": "Resources",
    "text": "Resources\n\nRepo\nDefault kbds\nConfiguration options",
    "crumbs": [
      "Git",
      "<b><em>Webinars</em></b>",
      "A great Git TUI: lazygit",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "git/wb_lazygit_content.html#time-for-a-demo",
    "href": "git/wb_lazygit_content.html#time-for-a-demo",
    "title": "A great Git TUI: lazygit",
    "section": "Time for a demo!",
    "text": "Time for a demo!\nI will spend the rest of this webinar showing you how to use Git through lazygit.",
    "crumbs": [
      "Git",
      "<b><em>Webinars</em></b>",
      "A great Git TUI: lazygit",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "git/wb_dvc_slides.html#on-version-control",
    "href": "git/wb_dvc_slides.html#on-version-control",
    "title": "Version control for data science & machine learning with DVC",
    "section": "On version control",
    "text": "On version control\nI won‚Äôt introduce here the benefits of using a good version control system such as Git\n\n\n\nOn the benefits of VCS"
  },
  {
    "objectID": "git/wb_dvc_slides.html#extending-git-for-data",
    "href": "git/wb_dvc_slides.html#extending-git-for-data",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Extending Git for data",
    "text": "Extending Git for data\nWhile Git is a wonderful tool for text files versioning (code, writings in markup formats), it isn‚Äôt a tool to manage changes to datasets\nSeveral open source tools‚Äîeach with a different structure and functioning‚Äîextend Git capabilities to track data: Git LFS, git-annex, lakeFS, Dolt, DataLad"
  },
  {
    "objectID": "git/wb_dvc_slides.html#extending-git-for-models-and-experiments",
    "href": "git/wb_dvc_slides.html#extending-git-for-models-and-experiments",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Extending Git for models and experiments",
    "text": "Extending Git for models and experiments\nReproducible research and collaboration on data science and machine learning projects involve more than datasets management:\nExperiments and the models they produce also need to be tracked"
  },
  {
    "objectID": "git/wb_dvc_slides.html#many-moving-parts",
    "href": "git/wb_dvc_slides.html#many-moving-parts",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Many moving parts",
    "text": "Many moving parts\n\n*hp = hyperparameter\n\n\n\n\n\n\n\n\n\n\ndata1\n\ndata1\n\n\n\nmodel1\n\nmodel1\n\n\n\ndata1-&gt;model1\n\n\n\n\n\nmodel2\n\nmodel2\n\n\n\ndata1-&gt;model2\n\n\n\n\n\nmodel3\n\nmodel3\n\n\n\ndata1-&gt;model3\n\n\n\n\n\ndata2\n\ndata2\n\n\n\ndata2-&gt;model1\n\n\n\n\n\ndata2-&gt;model2\n\n\n\n\n\ndata2-&gt;model3\n\n\n\n\n\ndata3\n\ndata3\n\n\n\ndata3-&gt;model1\n\n\n\n\n\ndata3-&gt;model2\n\n\n\n\n\ndata3-&gt;model3\n\n\n\n\n\nhp1\n\nhp1\n\n\n\nhp1-&gt;model1\n\n\n\n\n\nhp1-&gt;model2\n\n\n\n\n\nhp1-&gt;model3\n\n\n\n\n\nhp2\n\nhp2\n\n\n\nhp2-&gt;model1\n\n\n\n\n\nhp2-&gt;model2\n\n\n\n\n\nhp2-&gt;model3\n\n\n\n\n\nhp3\n\nhp3\n\n\n\nhp3-&gt;model1\n\n\n\n\n\nhp3-&gt;model2\n\n\n\n\n\nhp3-&gt;model3\n\n\n\n\n\nperformance\n\nperformance1 ... performance27\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\n\n\n\n\n\n\nHow did we get performance17 again? ü§Ø"
  },
  {
    "objectID": "git/wb_dvc_slides.html#dvc-principles",
    "href": "git/wb_dvc_slides.html#dvc-principles",
    "title": "Version control for data science & machine learning with DVC",
    "section": "DVC principles",
    "text": "DVC principles\nLarge files (datasets, models‚Ä¶) are kept outside Git\nEach large file or directory put under DVC tracking has an associated .dvc file\nGit only tracks the .dvc files (metadata)\n\nWorkflows can be tracked for collaboration and reproducibility\n\n\nDVC functions as a Makefile and allows to only rerun what is necessary"
  },
  {
    "objectID": "git/wb_dvc_slides.html#installation",
    "href": "git/wb_dvc_slides.html#installation",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Installation",
    "text": "Installation\nFor Linux (other OSes, refer to the doc):\n\npip:\npip install dvc\nconda\npipx (if you want dvc available everywhere without having to activate virtual envs):\npipx install dvc\n\n\nOptional dependencies [s3], [gdrive], etc. for remote storage"
  },
  {
    "objectID": "git/wb_dvc_slides.html#how-to-run",
    "href": "git/wb_dvc_slides.html#how-to-run",
    "title": "Version control for data science & machine learning with DVC",
    "section": "How to run",
    "text": "How to run\nMultiple options:\n\nTerminal:\ndvc ...\nVS Code extension\nPython library if installed via pip or conda:\nimport dvc.api\n\n\nIn this webinar, I will use DVC through the command line"
  },
  {
    "objectID": "git/wb_dvc_slides.html#acknowledgements",
    "href": "git/wb_dvc_slides.html#acknowledgements",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nCode and data for this webinar modified from:\n\nReal Python\nDataLad handbook\nDVC documentation"
  },
  {
    "objectID": "git/wb_dvc_slides.html#the-project",
    "href": "git/wb_dvc_slides.html#the-project",
    "title": "Version control for data science & machine learning with DVC",
    "section": "The project",
    "text": "The project\ntree -L 3\n‚îú‚îÄ‚îÄ LICENSE\n‚îú‚îÄ‚îÄ data\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ prepared\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ raw\n‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ train\n‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ val\n‚îú‚îÄ‚îÄ metrics\n‚îú‚îÄ‚îÄ model\n‚îú‚îÄ‚îÄ requirements.txt\n‚îî‚îÄ‚îÄ src\n    ‚îú‚îÄ‚îÄ evaluate.py\n    ‚îú‚îÄ‚îÄ prepare.py\n    ‚îî‚îÄ‚îÄ train.py"
  },
  {
    "objectID": "git/wb_dvc_slides.html#initialize-git-repo",
    "href": "git/wb_dvc_slides.html#initialize-git-repo",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Initialize Git repo",
    "text": "Initialize Git repo\ngit init\nInitialized empty Git repository in dvc/.git/\n\nThis creates the .git directory\n\n\ngit status\nOn branch main\n\nNo commits yet\n\nUntracked files:\n    LICENSE\n    data/\n    requirements.txt\n    src/"
  },
  {
    "objectID": "git/wb_dvc_slides.html#initialize-dvc-project",
    "href": "git/wb_dvc_slides.html#initialize-dvc-project",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Initialize DVC project",
    "text": "Initialize DVC project\ndvc init\nInitialized DVC repository.\n\nYou can now commit the changes to git.\n\nYou will also see a note about usage analytics collection and info on how to opt out\n\n\nA .dvc directory and a .dvcignore file got created"
  },
  {
    "objectID": "git/wb_dvc_slides.html#commit-dvc-system-files",
    "href": "git/wb_dvc_slides.html#commit-dvc-system-files",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Commit DVC system files",
    "text": "Commit DVC system files\nDVC automatically staged its system file for us:\ngit status\nOn branch main\n\nNo commits yet\n\nChanges to be committed:\n    new file:   .dvc/.gitignore\n    new file:   .dvc/config\n    new file:   .dvcignore\n\nUntracked files:\n    LICENSE\n    data/\n    requirements.txt\n    src/"
  },
  {
    "objectID": "git/wb_dvc_slides.html#commit-dvc-system-files-1",
    "href": "git/wb_dvc_slides.html#commit-dvc-system-files-1",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Commit DVC system files",
    "text": "Commit DVC system files\nSo we can directly commit:\ngit commit -m \"Initialize DVC\""
  },
  {
    "objectID": "git/wb_dvc_slides.html#prepare-repo",
    "href": "git/wb_dvc_slides.html#prepare-repo",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Prepare repo",
    "text": "Prepare repo\nLet‚Äôs work in a virtual environment:\n# Create venv and add to .gitignore\npython -m venv venv && echo venv &gt; .gitignore\n\n# Activate venv\nsource venv/bin/activate\n\n# Update pip\npython -m pip install --upgrade pip\n\n# Install packages needed\npython -m pip install -r requirements.txt"
  },
  {
    "objectID": "git/wb_dvc_slides.html#clean-working-tree",
    "href": "git/wb_dvc_slides.html#clean-working-tree",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Clean working tree",
    "text": "Clean working tree\ngit add .gitignore LICENSE requirements.txt\ngit commit -m \"Add general files\"\ngit add src\ngit commit -m \"Add scripts\"\ngit status\nOn branch main\nUntracked files:\n    data/\n\n\nNow, it is time to deal with the data"
  },
  {
    "objectID": "git/wb_dvc_slides.html#put-data-under-dvc-tracking",
    "href": "git/wb_dvc_slides.html#put-data-under-dvc-tracking",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Put data under DVC tracking",
    "text": "Put data under DVC tracking\nWe are still not tracking any data:\ndvc status\nThere are no data or pipelines tracked in this project yet.\nYou can choose what to track as a unit (i.e.¬†each picture individually, the whole data directory as a unit)\nLet‚Äôs break it down by set:\ndvc add data/raw/train\ndvc add data/raw/val"
  },
  {
    "objectID": "git/wb_dvc_slides.html#section",
    "href": "git/wb_dvc_slides.html#section",
    "title": "Version control for data science & machine learning with DVC",
    "section": "",
    "text": "This adds data to .dvc/cache/files and created 3 files in data/raw:\n\n.gitignore\ntrain.dvc\nval.dvc\n\nThe .gitignore tells Git not to track the data:\ncat data/raw/.gitignore\n/train\n/val\nThe .dvc files contain the metadata for the cached directories"
  },
  {
    "objectID": "git/wb_dvc_slides.html#tracked-data",
    "href": "git/wb_dvc_slides.html#tracked-data",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Tracked data",
    "text": "Tracked data\nWe are all good:\ndvc status\nData and pipelines are up to date."
  },
  {
    "objectID": "git/wb_dvc_slides.html#data-deduplication",
    "href": "git/wb_dvc_slides.html#data-deduplication",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Data (de)duplication",
    "text": "Data (de)duplication\nLink between checked-out version of a file/directory and the cache:\n\nCache ‚ü∑ working directory\n\n\n\n\n\n\n\n\nDuplication\nEditable\n\n\n\n\nReflinks*\nOnly when needed\nYes\n\n\nHardlinks/Symlinks\nNo\nNo\n\n\nCopies\nYes\nYes\n\n\n\n\n*Reflinks only available for a few file systems (Btrfs, XFS, OCFS2, or APFS)"
  },
  {
    "objectID": "git/wb_dvc_slides.html#commit-the-metafiles",
    "href": "git/wb_dvc_slides.html#commit-the-metafiles",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Commit the metafiles",
    "text": "Commit the metafiles\nThe metafiles should be put under Git version control\n\nYou can configure DVC to automatically stage its newly created system files:\ndvc config [--system] [--global] core.autostage true\n\nYou can then commit directly:\ngit commit -m \"Initial version of data\"\ngit status\nOn branch main\nnothing to commit, working tree clean"
  },
  {
    "objectID": "git/wb_dvc_slides.html#track-changes-to-the-data",
    "href": "git/wb_dvc_slides.html#track-changes-to-the-data",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Track changes to the data",
    "text": "Track changes to the data\nLet‚Äôs make some change to the data:\nrm data/raw/val/n03445777/ILSVRC2012_val*\n\nRemember that Git is not tracking the data:\ngit status\nOn branch main\nnothing to commit, working tree clean\n\n\nBut DVC is:\ndvc status\ndata/raw/val.dvc:\n    changed outs:\n            modified:           data/raw/val"
  },
  {
    "objectID": "git/wb_dvc_slides.html#add-changes-to-dvc",
    "href": "git/wb_dvc_slides.html#add-changes-to-dvc",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Add changes to DVC",
    "text": "Add changes to DVC\ndvc add data/raw/val\ndvc status\nData and pipelines are up to date.\n\nNow we need to commit the changes to the .dvc file to Git:\ngit status\nOn branch main\nChanges to be committed:\n    modified:   data/raw/val.dvc\n\nStaging happened automatically because I have set the autostage option to true on my system\n\ngit commit -m \"Delete data/raw/val/n03445777/ILSVRC2012_val*\""
  },
  {
    "objectID": "git/wb_dvc_slides.html#check-out-older-versions",
    "href": "git/wb_dvc_slides.html#check-out-older-versions",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Check out older versions",
    "text": "Check out older versions\nWhat if we want to go back to the 1st version of our data?\nFor this, we first use Git to checkout the proper commit, then run dvc checkout to have the data catch up to the .dvc file\nTo avoid forgetting to run the commands that will make DVC catch up to Git, we can automate this process by installing Git hooks:\ndvc install"
  },
  {
    "objectID": "git/wb_dvc_slides.html#git-workflows",
    "href": "git/wb_dvc_slides.html#git-workflows",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Git workflows",
    "text": "Git workflows\ngit checkout is ok to have a look, but a detached HEAD is not a good place to create new commits\nLet‚Äôs create a new branch and switch to it:\ngit switch -c alternative\nSwitched to a new branch 'alternative'\nGoing back and forth between both versions of our data is now as simple as switching branch:\ngit switch main\ngit switch alternative"
  },
  {
    "objectID": "git/wb_dvc_slides.html#classic-workflow",
    "href": "git/wb_dvc_slides.html#classic-workflow",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Classic workflow",
    "text": "Classic workflow\nThe Git project (including .dvc files) go to a Git remote (GitHub/GitLab/Bitbucket/server)\nThe data go to a DVC remote (AWS/Azure/Google Drive/server/etc.)"
  },
  {
    "objectID": "git/wb_dvc_slides.html#dvc-remotes",
    "href": "git/wb_dvc_slides.html#dvc-remotes",
    "title": "Version control for data science & machine learning with DVC",
    "section": "DVC remotes",
    "text": "DVC remotes\nDVC can use many cloud storage or remote machines/server via SSH, WebDAV, etc.\nLet‚Äôs create a local remote here:\n# Create a directory outside the project\nmkdir ../remote\n\n# Setup default (-d) remote\ndvc remote add -d local_remote ../remote\nSetting 'local_remote' as a default remote.\ncat .dvc/config\n[core]\n    remote = local_remote\n['remote \"local_remote\"']\n    url = ../../remote"
  },
  {
    "objectID": "git/wb_dvc_slides.html#commit-remote-config",
    "href": "git/wb_dvc_slides.html#commit-remote-config",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Commit remote config",
    "text": "Commit remote config\nThe new remote configuration should be committed:\ngit status\nOn branch alternative\n\nChanges not staged for commit:\n    modified:   .dvc/config\ngit add .\ngit commit -m \"Config remote\""
  },
  {
    "objectID": "git/wb_dvc_slides.html#push-to-remotes",
    "href": "git/wb_dvc_slides.html#push-to-remotes",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Push to remotes",
    "text": "Push to remotes\nLet‚Äôs push the data from the cache (.dvc/cache) to the remote:\ndvc push\n2702 files pushed\n\nWith Git hooks installed, dvc push is automatically run after git push\n(But the data is pushed to the DVC remote while the files tracked by Git get pushed to the Git remote)\n\nBy default, the entire data cache gets pushed to the remote, but there are many options\n\nExample: only push data corresponding to a certain .dvc files\ndvc push data/raw/val.dvc"
  },
  {
    "objectID": "git/wb_dvc_slides.html#pull-from-remotes",
    "href": "git/wb_dvc_slides.html#pull-from-remotes",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Pull from remotes",
    "text": "Pull from remotes\ndvc fetch downloads data from the remote into the cache. To have it update the working directory, follow by dvc checkout\nYou can do these 2 commands at the same time with dvc pull"
  },
  {
    "objectID": "git/wb_dvc_slides.html#dvc-pipelines",
    "href": "git/wb_dvc_slides.html#dvc-pipelines",
    "title": "Version control for data science & machine learning with DVC",
    "section": "DVC pipelines",
    "text": "DVC pipelines\nDVC pipelines create reproducible workflows and are functionally similar to Makefiles\nEach step in a pipeline is created with dvc stage add and add an entry to a dvc.yaml file\n\ndvc stage add options:\n-n: name of stage\n-d: dependency\n-o: output\n\n\nEach stage contains:\n\ncmd: the command executed\ndeps: the dependencies\nouts: the outputs\n\nThe file is then used to visualize the pipeline and run it"
  },
  {
    "objectID": "git/wb_dvc_slides.html#example",
    "href": "git/wb_dvc_slides.html#example",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Example",
    "text": "Example\nLet‚Äôs create a pipeline to run a classifier on our data\nThe pipeline contains 3 steps:\n\nprepare\ntrain\nevaluate"
  },
  {
    "objectID": "git/wb_dvc_slides.html#create-a-pipeline",
    "href": "git/wb_dvc_slides.html#create-a-pipeline",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Create a pipeline",
    "text": "Create a pipeline\n1st stage (data preparation):\ndvc stage add -n prepare -d src/prepare.py -d data/raw \\\n    -o data/prepared/train.csv -o data/prepared/test.csv \\\n    python src/prepare.py\nAdded stage 'prepare' in 'dvc.yaml'"
  },
  {
    "objectID": "git/wb_dvc_slides.html#create-a-pipeline-1",
    "href": "git/wb_dvc_slides.html#create-a-pipeline-1",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Create a pipeline",
    "text": "Create a pipeline\n2nd stage (training)\ndvc stage add -n train -d src/train.py -d data/prepared/train.csv \\\n    -o model/model.joblib \\\n    python src/train.py\nAdded stage `train` in 'dvc.yaml'"
  },
  {
    "objectID": "git/wb_dvc_slides.html#create-a-pipeline-2",
    "href": "git/wb_dvc_slides.html#create-a-pipeline-2",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Create a pipeline",
    "text": "Create a pipeline\n3rd stage (evaluation)\ndvc stage add -n evaluate -d src/evaluate.py -d model/model.joblib \\\n    -M metrics/accuracy.json \\\n    python src/evaluate.py\nAdded stage `evaluate` in 'dvc.yaml'"
  },
  {
    "objectID": "git/wb_dvc_slides.html#commit-pipeline",
    "href": "git/wb_dvc_slides.html#commit-pipeline",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Commit pipeline",
    "text": "Commit pipeline\ngit commit -m \"Define pipeline\"\nprepare:\n    changed deps:\n            modified:           data/raw\n            modified:           src/prepare.py\n    changed outs:\n            deleted:            data/prepared/test.csv\n            deleted:            data/prepared/train.csv\ntrain:\n    changed deps:\n            deleted:            data/prepared/train.csv\n            modified:           src/train.py\n    changed outs:\n            deleted:            model/model.joblib\nevaluate:\n    changed deps:\n            deleted:            model/model.joblib\n            modified:           src/evaluate.py\n    changed outs:\n            deleted:            metrics/accuracy.json\n[main 4aa331b] Define pipeline\n 3 files changed, 27 insertions(+)\n create mode 100644 data/prepared/.gitignore\n create mode 100644 dvc.yaml\n create mode 100644 model/.gitignore"
  },
  {
    "objectID": "git/wb_dvc_slides.html#visualize-pipeline-in-a-dag",
    "href": "git/wb_dvc_slides.html#visualize-pipeline-in-a-dag",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Visualize pipeline in a DAG",
    "text": "Visualize pipeline in a DAG\ndvc dag\n+--------------------+         +------------------+\n| data/raw/train.dvc |         | data/raw/val.dvc |\n+--------------------+         +------------------+\n                  ***           ***\n                     **       **\n                       **   **\n                    +---------+\n                    | prepare |\n                    +---------+\n                          *\n                          *\n                          *\n                      +-------+\n                      | train |\n                      +-------+\n                          *\n                          *\n                          *\n                    +----------+\n                    | evaluate |\n                    +----------+"
  },
  {
    "objectID": "git/wb_dvc_slides.html#run-pipeline",
    "href": "git/wb_dvc_slides.html#run-pipeline",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Run pipeline",
    "text": "Run pipeline\ndvc repro\n'data/raw/train.dvc' didn't change, skipping\n'data/raw/val.dvc' didn't change, skipping\nRunning stage 'prepare':\n&gt; python src/prepare.py\nGenerating lock file 'dvc.lock'\nUpdating lock file 'dvc.lock'\n\nRunning stage 'train':\n&gt; python src/train.py\nUpdating lock file 'dvc.lock'\n\nRunning stage 'evaluate':\n&gt; python src/evaluate.py\nUpdating lock file 'dvc.lock'\nUse `dvc push` to send your updates to remote storage."
  },
  {
    "objectID": "git/wb_dvc_slides.html#dvc-repro-breakdown",
    "href": "git/wb_dvc_slides.html#dvc-repro-breakdown",
    "title": "Version control for data science & machine learning with DVC",
    "section": "dvc repro breakdown",
    "text": "dvc repro breakdown\n\ndvc repro runs the dvc.yaml file in a Makefile fashion\nFirst, it looks at the dependencies: the data didn‚Äôt change\nThen it ran the commands to produce the outputs (since it is our first run, we had no outputs)\nWhen the 1st stage is run, a dvc.lock is created with information on that part of the run\nWhen the 2nd and 3rd stages are run, dvc.lock is updated\nAt the end of the run dvc.lock contains all the info about the run we just did (version of the data used, etc.)\nA new directory called runs is created in .dvc/cache with cached data for this run"
  },
  {
    "objectID": "git/wb_dvc_slides.html#results-of-the-run",
    "href": "git/wb_dvc_slides.html#results-of-the-run",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Results of the run",
    "text": "Results of the run\n\nThe prepared data was created in data/prepared (with a .gitignore to exclude it from Git‚Äîyou don‚Äôt want to track results in Git, but the scripts that can reproduce them)\nA model was saved in model (with another .gitignore file)\nThe accuracy of this run was created in metrics"
  },
  {
    "objectID": "git/wb_dvc_slides.html#clean-working-tree-1",
    "href": "git/wb_dvc_slides.html#clean-working-tree-1",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Clean working tree",
    "text": "Clean working tree\nNow, we definitely want to create a commit with the dvc.lock\nWe could add the metrics resulting from this run in the same commit:\ngit add metrics\ngit commit -m \"First pipeline run and results\"\n\nOur working tree is now clean and our data/pipeline up to date:\ngit status\nOn branch alternative\nnothing to commit, working tree clean\ndvc status\nData and pipelines are up to date."
  },
  {
    "objectID": "git/wb_dvc_slides.html#modify-pipeline",
    "href": "git/wb_dvc_slides.html#modify-pipeline",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Modify pipeline",
    "text": "Modify pipeline\nFrom now on, if we edit one of the scripts, or one of the dependencies, dvc status will tell us what changed and dvc repro will only rerun the parts of the pipeline to update the result, pretty much as a Makefile would"
  },
  {
    "objectID": "git/wb_dvc_slides.html#going-further-next-time",
    "href": "git/wb_dvc_slides.html#going-further-next-time",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Going further ‚Ä¶ next time",
    "text": "Going further ‚Ä¶ next time\n DVC is a sophisticated tool with many additional features:\n\nCreation of data registries\nDVCLive\nA Python library to log experiment metrics\nVisualize the performance logs as plots\nContinuous integration\nWith the sister project CML (Continuous Machine Learning)"
  },
  {
    "objectID": "git/wb_dvc.html",
    "href": "git/wb_dvc.html",
    "title": "Version control for data science and machine learning with DVC",
    "section": "",
    "text": "Data version control (DVC) is an open source tool that brings all the versioning and collaboration capabilities you use on your code with Git to your data and machine learning workflow.\nIf you use datasets in your work, it makes it easy to track their evolution.\nIf you are in the field of machine learning, it additionally allows you to track your models, manage your pipelines from parameters to metrics, collaborate on your experiments, and integrate with the continuous integration tool for machine learning projects CML.\nThis webinar will show you how to get started with DVC, first in the simple case where you just want to put your data under version control, then in the more complex situation where you want to manage your machine learning workflow in a more organized and reproducible fashion.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "Git",
      "<b><em>Webinars</em></b>",
      "Data version control with DVC"
    ]
  },
  {
    "objectID": "git/top_wb.html",
    "href": "git/top_wb.html",
    "title": "Git webinars",
    "section": "",
    "text": "Data version control with\n\n\n\n\nA great Git UI: Lazygit",
    "crumbs": [
      "Git",
      "<b><em>Webinars</em></b>"
    ]
  },
  {
    "objectID": "git/top_col.html",
    "href": "git/top_col.html",
    "title": "Collaborating on GitHub",
    "section": "",
    "text": "Git is excellent at merging different versions of projects. Furthermore, it is a distributed version control system, meaning that everybody has a full copy of the project locally and local copies exchange information via a shared remote (examples of remotes that allow for easy shared access include servers and Internet hosting services such as GitHub, GitLab, and Bitbucket).\nThese characteristics make Git a powerful collaboration tool: everybody can work simultaneously on their local copies‚Äîa huge benefit over having to work asynchronously on a unique copy sent back and forth!\nThere are various ways to collaborate on a project using Git and a shared remote:\n\nYou initiate a project and want others to contribute to it (situation 1), or\nYou want to contribute to a project started by someone else and\n\nYou have write access to it (situation 2), or\nYou do not have write access to it (situation 3).\n\n\nThis course will cover all three cases using GitHub as an example.\nThis course assumes working knowledge of Git. If you are new to it, you should first look at our introductory course.\n\n Start course ‚û§",
    "crumbs": [
      "Git",
      "<b><em>Collaborating on GitHub</em></b>"
    ]
  },
  {
    "objectID": "git/intro_undo.html",
    "href": "git/intro_undo.html",
    "title": "Undoing",
    "section": "",
    "text": "This section covers a few of the ways actions can be undone in Git.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Undoing"
    ]
  },
  {
    "objectID": "git/intro_undo.html#amending-the-last-commit",
    "href": "git/intro_undo.html#amending-the-last-commit",
    "title": "Undoing",
    "section": "Amending the last commit",
    "text": "Amending the last commit\nHere is a common scenario: you make a commit, then realize that you forgot to include some changes in that commit; or you aren‚Äôt happy with the commit message; or both. You can edit your latest commit with the --amend flag:\ngit commit --amend\nThis will hide your last commit (as if it had never happened), add the changes in the staging area (if any) to the changes in that last commit, open a text editor showing the message of the last commit (you can keep or edit that message), and create a new commit which replaces your last commit.\nSo if you only want to change the commit message, run that command with an empty staging area. If you want to add changes to the last commit, stage them, then run the command.\nIn short, what this does is to replace your last commit with a new commit with the added changes and/or edited message. This prevents having a messy history with commits of the type ‚Äúadd missing file to last commit‚Äù or ‚Äúbetter message for last commit: bla bla bla‚Äù. If you made a typo in your last commit message (and if you care about having a nice, clean history), you can fix it easily this way.\n\n\nYour turn:\n\n\nRun git log --oneline (notice the hash of the last commit)\nEdit your last commit message\nRun git log --oneline again to see that your last commit now has a new hash (so it is a different commit) and a new message\nNow, make some change in your project (add a file, or edit a file‚Ä¶ any change you want)\nThen add that new change to your last commit without changing the message",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Undoing"
    ]
  },
  {
    "objectID": "git/intro_undo.html#unstaging",
    "href": "git/intro_undo.html#unstaging",
    "title": "Undoing",
    "section": "Unstaging",
    "text": "Unstaging\nYou know how to add changes to the staging area. But what if you want to unstage changes? You don‚Äôt want to loose those changes. But you staged them and then realized that you don‚Äôt want to include them in your next commit after all.\nHere is the command for this:\ngit restore --staged &lt;file&gt;\n\nNote that Git will remind you about the existence of this command when you run git status and have staged files ready to be committed.\n\n\n\nYour turn:\n\n\nMake changes to one of your existing files\nStage that file\nRun git status and notice Git‚Äôs reminder about this command\nUnstage the changes on that file",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Undoing"
    ]
  },
  {
    "objectID": "git/intro_undo.html#erasing-modifications",
    "href": "git/intro_undo.html#erasing-modifications",
    "title": "Undoing",
    "section": "Erasing modifications",
    "text": "Erasing modifications\nNow, what if you made changes to a file, then decide that they were no good? You can easily get rid of these edits and restore the file to its last committed version:\ngit restore &lt;file&gt;\n\nNote that Git will tell you about this command when you run git status and have unstaged changes in tracked files.\n\n\n\nYour turn:\n\n\nRun git status again and notice Git‚Äôs reminder about the existence of this command\nErase that last change of yours\nOpen your file and notice that your edits are gone\n\n\n\nAs you just experienced, this command leads to data loss.\nThose last edits are gone and unrecoverable. Be very careful when using this!",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Undoing"
    ]
  },
  {
    "objectID": "git/intro_undo.html#reverting",
    "href": "git/intro_undo.html#reverting",
    "title": "Undoing",
    "section": "Reverting",
    "text": "Reverting\n\nThe working directory must be clean before you can use git revert.\n\ngit revert creates a new commit which reverses the effect of past commit(s).\n\nTo revert the last commit (current location of HEAD):\n\ngit revert HEAD\n\nYou can use the hash of the last commit instead of HEAD.\n\n\nTo revert the last two commits:\n\ngit revert HEAD~\n\nHEAD~ is equivalent to HEAD~1 and means the commit before the one HEAD is on.\nHere too of course, you can use the hash of the commit before last instead of HEAD~.\n\n\nTo revert the last three commits:\n\ngit revert HEAD~2",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Undoing"
    ]
  },
  {
    "objectID": "git/intro_time_travel.html",
    "href": "git/intro_time_travel.html",
    "title": "Revisiting old commits",
    "section": "",
    "text": "It‚Äôs great to record history, but if we don‚Äôt know how to make use of it, it isn‚Äôt exactly useful.\nIn this workshop, you will travel through the history of a project.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Revisiting old commits"
    ]
  },
  {
    "objectID": "git/intro_time_travel.html#looking-at-the-past-without-travelling",
    "href": "git/intro_time_travel.html#looking-at-the-past-without-travelling",
    "title": "Revisiting old commits",
    "section": "Looking at the past without travelling",
    "text": "Looking at the past without travelling\nHEAD is a little file in the .git directory which points to our current location in the Git history.\nYou already saw multiple ways to have a glimpse at your project history without moving HEAD:\n\ngit log and its many variations shows a list or a tree of your commits\ngit show displays information about a Git object such as a past commit\n\nThose are useful options, but Git allows you to really travel in your project history: HEAD can be moved around with the command git checkout to point to any branch, tag, or commit.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Revisiting old commits"
    ]
  },
  {
    "objectID": "git/intro_time_travel.html#travelling-through-history",
    "href": "git/intro_time_travel.html#travelling-through-history",
    "title": "Revisiting old commits",
    "section": "Travelling through history",
    "text": "Travelling through history\nAs soon as you move HEAD to a new Git object with git checkout, the working directory and the index get updated to match the snapshot that Git object is pointing to. That means that your project will suddenly be back to the state in which it was when you committed that snapshot.\n\nMoving HEAD\nLet‚Äôs give this a try and move HEAD to a past commit.\n\nIdentifying the commit we want to move HEAD to\nYou can use the ~ notation:\n\nHEAD~ or HEAD~1 means the commit which precedes the one HEAD is pointing to.\nHEAD~2 means the commit before that.\nHEAD~3 refers to the 3rd commit before the current commit.\netc.\n\nYou can also run git log to find the hash of your commit of interest.\n\n\n\nDetached HEAD\nLet‚Äôs look at a hypothetical scenario to see what happens when you checkout a commit.\nThis is our starting point:\n\nNow, we move HEAD to the commit 31fukv1:\ngit checkout 31fukv1\n\nNotice that HEAD is not pointing at a branch anymore: it is pointing directly at a commit. This is called a detached HEAD state and Git will give you plenty of warnings about it.\nIf you look at your files, you will see that they match their state when you committed 31fukv1: your working directory got updated to match the current position of HEAD.\nYou can look at your project at that point in its history, then go back to your main branch (here main) with:\ngit checkout main\n\nAnd that‚Äôs that. You took a little trip into the past just to have a look, then came back to ‚Äúthe present‚Äù and all went well.\n\n\nCreating commits from a detached HEAD\nNow, when you are at commit 31fukv1, maybe you wanted to try something.\n\nYou can safely try anything you want: when you checkout main to come back to ‚Äúthe present‚Äù, those experimental changes will get lost.\nBut what if you want to keep those changes you made at 31fukv1?\nIn that case, as you always do, you create a commit to archive those changes into the project history:\n\nYou can make more commits:\n\nThe thing is that you are still in this detached HEAD state. HEAD is not pointing to a branch as it normally is. Is this a problem?\n\nBad workflow\nWell, it becomes a problem if you checkout main from there:\n\nIf you decide that you don‚Äôt care about those commits after all, then all is good. But if you care about them, this is a bad situation because those commits you created when you were in a detached HEAD state are now left behind: they are not in the history of any branch or tag.\nThis is bad for three reasons:\n\nThose commits will not show when you run git log, so it is easy to forget about them.\nIt is not easy to go back to them because there aren‚Äôt any tag or branch that you can checkout.\nThe garbage collection (which runs every 30 days by default) will delete those commits which are not on any branch or tag. So you will ultimately loose them.\n\n\n\nGood workflow\nA good workflow would have been to create a new branch on 31fukv1 (let‚Äôs call it alternative) and switch to it. That way, the commits created from 31fukv1 are on a branch and they will not be deleted by the next garbage collection:\n\nIn this good workflow, it is totally safe to switch back to main:\n\n\nIf you want to list the commits 23f481q and rthy7wg when you are back on main, you need to run git log with the --all flag.\n\n\n\nRecovering commits left behind\nWhat if you left commits behind (not on a branch)?\nYou can retrieve their hash by running:\ngit reflog\nThis tracks the position of HEAD over time.\nYou can then checkout the commit you care about (so you are going back to a detached HEAD state):\ngit checkout &lt;hash-abandonned-commit&gt;\nThis puts you back into a situation where you can rescue the commit(s) by creating a branch:\nDo this as soon as you can since those commits will be deleted at the next garbage collection (and finding their hash with git reflog will become increasingly complicated as you wait).",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Revisiting old commits"
    ]
  },
  {
    "objectID": "git/intro_tags.html",
    "href": "git/intro_tags.html",
    "title": "Tags",
    "section": "",
    "text": "When you reach an important point in the development of a project, it is convenient to be able to identify the next commit easily. Rather than having to look for it through date, commit message, or hash, you can create a tag: a pointer to that commit.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Tags"
    ]
  },
  {
    "objectID": "git/intro_tags.html#leightweight-tag",
    "href": "git/intro_tags.html#leightweight-tag",
    "title": "Tags",
    "section": "Leightweight tag",
    "text": "Leightweight tag\nYou create a tag with:\ngit tag &lt;tag-name&gt;\n\nExample:\n\ngit tag J_Climate_2009\n\nAs you keep developing the project and create new commits, the branch and HEAD pointers will move along, but the tag remains on your important commit.\n\nAt any time, you can get info on the commit thus tagged with:\ngit show J_Climate_2009\nOr you can check it out with:\ngit checkout J_Climate_2009",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Tags"
    ]
  },
  {
    "objectID": "git/intro_tags.html#annotated-tag",
    "href": "git/intro_tags.html#annotated-tag",
    "title": "Tags",
    "section": "Annotated tag",
    "text": "Annotated tag\nA more sophisticated form of tag comes with a message:\ngit tag -a &lt;tag-name&gt; -m \"&lt;message&gt;\"\ngit tag -a J_Climate_2009 -m \"State of project at the publication of paper\"",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Tags"
    ]
  },
  {
    "objectID": "git/intro_tags.html#list-tags",
    "href": "git/intro_tags.html#list-tags",
    "title": "Tags",
    "section": "List tags",
    "text": "List tags\ngit tag",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Tags"
    ]
  },
  {
    "objectID": "git/intro_tags.html#deleting-tags",
    "href": "git/intro_tags.html#deleting-tags",
    "title": "Tags",
    "section": "Deleting tags",
    "text": "Deleting tags\ngit tag -d &lt;tag-name&gt;\ngit tag -d J_Climate_2009",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Tags"
    ]
  },
  {
    "objectID": "git/intro_resources.html",
    "href": "git/intro_resources.html",
    "title": "Resources",
    "section": "",
    "text": "This section contains useful resources on Git as well as some advice.\n\n\nOnline documentation\n\nOfficial Git manual\nOpen source Pro Git book\n\n\n\nCourses & workshops\n\nWestern Canada Research Computing Git workshops\nWestGrid Summer School 2020 Git course\nWestGrid Autumn School 2020 Git course\nSoftware Carpentry Git lesson\n\n\n\nQ & A\n\nStack Overflow [git] tag\n\n\n\nTroubleshooting\n\n‚ÄúListen‚Äù to Git!\nGit is extremely verbose: by default, it will return lots of information. Read it!\nThese messages may feel overwhelming at first, but:\n\nthey will make more and more sense as you gain expertise,\nthey often give you clues as to what the problem is,\neven if you don‚Äôt understand them, you can use them as Google search terms.\n\n\n\n(Re-read) the doc\nAs I have no memory, I need to check the man pages all the time. That‚Äôs ok! It is quick and easy.\nFor more detailed information and examples, I really like the Official Git manual.\n\n\nSearch online\n\nGoogle\nStack Overflow [git] tag\n\n\n\nDon‚Äôt panic\nBe analytical. It is easy to panic and feel lost if something doesn‚Äôt work as expected. Take a breath and start with the basis:\n\nmake sure you are in the repo (pwd) and the files are where you think they are (ls -a),\ninspect the repository (git status, git diff, git log). Make sure not to overlook what Git is ‚Äútelling‚Äù you there.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "git/intro_logs.html",
    "href": "git/intro_logs.html",
    "title": "Getting information on commits",
    "section": "",
    "text": "Before we can make use of old commits, we need to be able to get information about them. This is critical to know how to navigate the history of a project.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Getting information on commits"
    ]
  },
  {
    "objectID": "git/intro_logs.html#displaying-the-commit-history",
    "href": "git/intro_logs.html#displaying-the-commit-history",
    "title": "Getting information on commits",
    "section": "Displaying the commit history",
    "text": "Displaying the commit history\nDo you remember this diagram from the first section of this course?\n\nThis is very useful to get a map of the history of our project. But how can we get a visual for it? The command here is git log and its many options.\nIn its basic form, it outputs the logs of our past commits:\ngit log\ncommit ca3c0360bd8ab961117671dd1f8fb2d2c3d5d7a1 (HEAD -&gt; main)\nAuthor: Marie-Helene Burle &lt;xxx@xxx&gt;\nDate:   Tue Jul 11 23:08:59 2023 -0700\n\n    Add first draft of script\n\ncommit c4ab5e755179a7b28a09c0ca587551bdac504d35\nAuthor: Marie-Helene Burle &lt;xxx@xxx&gt;\nDate:   Tue Jul 11 23:06:40 2023 -0700\n\n    Add .gitignore file with data and results\n\ncommit 61abf96298b54baf6d48cdea2ab1477db1075b5e\nAuthor: Marie-Helene Burle &lt;xxx@xxx&gt;\nDate:   Mon Jul 10 23:23:25 2023 -0700\n\n    Initial commit\nAs you can see, commits are listed from the bottom up.\nCommits can be displayed as one-liners:\ngit log --oneline\nca3c036 (HEAD -&gt; main) Add first draft of script\nc4ab5e7 Add .gitignore file with data and results\n61abf96 Initial commit\nOr as a graph:\ngit log --graph\n* commit ca3c0360bd8ab961117671dd1f8fb2d2c3d5d7a1 (HEAD -&gt; main)\n| Author: Marie-Helene Burle &lt;xxx@xxx&gt;\n| Date:   Tue Jul 11 23:08:59 2023 -0700\n|\n|     Add first draft of script\n|\n* commit c4ab5e755179a7b28a09c0ca587551bdac504d35\n| Author: Marie-Helene Burle &lt;xxx@xxx&gt;\n| Date:   Tue Jul 11 23:06:40 2023 -0700\n|\n|     Add .gitignore file with data and results\n|\n* commit 61abf96298b54baf6d48cdea2ab1477db1075b5e\n  Author: Marie-Helene Burle &lt;xxx@xxx&gt;\n  Date:   Mon Jul 10 23:23:25 2023 -0700\n\n      Initial commit\nOr in any fancy way you like:\ngit log \\\n    --graph \\\n    --date=short \\\n    --pretty=format:'%C(cyan)%h %C(blue)%ar %C(auto)%d'`\n                   `'%C(yellow)%s%+b %C(magenta)%ae'\n* ca3c036 31 minutes ago  (HEAD -&gt; main)Add first draft of script xxx@xxx\n* c4ab5e7 34 minutes ago Add .gitignore file with data and results xxx@xxx\n* 61abf96 24 hours ago Initial commit xxx@xxx\nRun man git-log for a full list of options.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Getting information on commits"
    ]
  },
  {
    "objectID": "git/intro_logs.html#information-about-a-commit",
    "href": "git/intro_logs.html#information-about-a-commit",
    "title": "Getting information on commits",
    "section": "Information about a commit",
    "text": "Information about a commit\ngit log is useful to get an overview of our project history, but the information we get about each commit is limited. To get additional information about a particular commit, you can use git show followed by the hash of the commit you are interested in.\nFor instance, let‚Äôs explore our last commit\ngit show\ncommit ca3c0360bd8ab961117671dd1f8fb2d2c3d5d7a1 (HEAD -&gt; main)\nAuthor: Marie-Helene Burle &lt;xxx@xxx&gt;\nDate:   Tue Jul 11 23:08:59 2023 -0700\n\n    Add first draft of script\n\ndiff --git a/src/script.py b/src/script.py\nnew file mode 100644\nindex 0000000..263ef67\n--- /dev/null\n+++ b/src/script.py\n@@ -0,0 +1,7 @@\n+import pandas as pd\n+from matplotlib import pyplot as plt\n+\n+df = pd.read_csv('../data/dataset.csv')\n+\n+df.plot()\n+plt.savefig('../results/plot.png', dpi=300)\nOr our second commit:\ngit show c4ab5e7  # Replace the hash by the hash of your second commit\ncommit c4ab5e755179a7b28a09c0ca587551bdac504d35\nAuthor: Marie-Helene Burle &lt;xxx@xxx&gt;\nDate:   Tue Jul 11 23:06:40 2023 -0700\n\n    Add .gitignore file with data and results\n\ndiff --git a/.gitignore b/.gitignore\nnew file mode 100644\nindex 0000000..e85f44a\n--- /dev/null\n+++ b/.gitignore\n@@ -0,0 +1,2 @@\n+/data/\n+/results/\nIn addition to displaying the commit metadata, git show also displays the diff of that commit with its parent commit.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Getting information on commits"
    ]
  },
  {
    "objectID": "git/intro_ignore.html",
    "href": "git/intro_ignore.html",
    "title": "Excluding from version control",
    "section": "",
    "text": "Not everything should be under version control, yet we don‚Äôt want a cluttered working directory. The solution: a list of files or patterns that Git disregards.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Excluding from version control"
    ]
  },
  {
    "objectID": "git/intro_ignore.html#what-to-exclude",
    "href": "git/intro_ignore.html#what-to-exclude",
    "title": "Excluding from version control",
    "section": "What to exclude",
    "text": "What to exclude\nThere are files you really want to put under version control, but there are files you shouldn‚Äôt.\nPut under version control:\n\nScripts\nManuscripts and notes\nMakefile & similar\n\nDo NOT put under version control:\n\nNon-text files (e.g.¬†images, office documents)\nYour initial data\nOutputs that can be recreated by running code (e.g.¬†graphs, results)\n\nHowever, you don‚Äôt want to have such documents constantly showing up when you run git status. In order to have a clean working directory while keeping them out of version control, you can create a file called .gitignore and add to it a list of files or patterns that you want Git to disregard.\n\n\nYour turn:\n\nIn the case of our mock project,\n\nwhat should we put under version control?\nwhat should we ignore?",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Excluding from version control"
    ]
  },
  {
    "objectID": "git/intro_ignore.html#how-to-exclude",
    "href": "git/intro_ignore.html#how-to-exclude",
    "title": "Excluding from version control",
    "section": "How to exclude",
    "text": "How to exclude\n\nThe .gitignore file\nTo exclude files from version control, create a file called .gitignore in the root of your project and add those files to it, one per line.\n\nExample:\n\n# Create .gitignore and add 'graph.png' to it\necho graph.png &gt; .gitignore\n\n# `&gt;` would overwrite the content. `&gt;&gt;` appends\necho output.txt &gt;&gt; .gitignore\nYou can also ignore entire directories.\n\nExample:\n\necho /results/ &gt;&gt; .gitignore\nFinally, you can use globbing patterns to ignore all files matching a certain pattern.\n\nExample:\n\n# Exclude all .png files\necho *.png &gt;&gt; .gitignore\n\n.gitignore syntax\nEach line in a .gitignore file specifies a pattern.\nBlank lines are ignored and can serve as separators for readability.\nLines starting with # are comments.\nTo add patterns starting with a special character (e.g.¬†#, !), that character needs to be escaped with \\.\nTrailing spaces are ignored unless they are escaped with \\.\n! negates patterns.\nPatterns ending with / match directories. Otherwise patterns match both files and directories.\n/ at the beginning or within a search pattern indicates that the pattern is relative to the directory level of the .gitignore file (usually the root of the project). Otherwise the pattern matches anywhere below the .gitignore level.\n\nExamples:\n/foo/bar/ matches the directory foo/bar, but not the directory a/foo/bar\nfoo/bar/ matches both the directories foo/bar and a/foo/bar\n\n* matches anything except /.\n? matches any one character except /.\nThe range notation (e.g.¬†[a-zA-Z]) can be used to match one of the characters in a range.\nA leading **/ matches all directories.\n\nExample:\n**/foo matches file or directory foo anywhere. This is the same as foo.\n\nA trailing /** matches everything inside what it precedes.\n\nExample:\nabc/** matches all files (recursively) inside directory abc\n\n/**/ matches zero or more directories.\n\nExample:\na/**/b matches a/b, a/x/b, and a/x/y/b\n\n\n\n\nYour turn:\n\nCreate a .gitignore file suitable for our mock project.\n\nThe .gitignore is a file like any other file, so you‚Äôll want to stage and commit it:\ngit status\nOn branch main\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n    .gitignore\n    src/\n\nnothing added to commit but untracked files present (use \"git add\" to track)\n\nNotice how data/ is not listed in the untracked files anymore.\n\nWe stage our .gitignore file:\ngit add .gitignore\ngit status\nOn branch main\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n    new file:   .gitignore\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n    src/\nAnd we create a new commit:\ngit commit -m \"Add .gitignore file with data and results\"\ngit status\n[main a1df8e5] Add .gitignore file with data and results\n 1 file changed, 2 insertions(+)\n create mode 100644 .gitignore\ngit status\nOn branch main\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n    src/\n\nnothing added to commit but untracked files present (use \"git add\" to track)\nLet‚Äôs create a third commit with the Python script:\ngit add src/script.py\ngit commit -m \"Add first draft of script\"\n[main ca3c036] Add first draft of script\n 1 file changed, 7 insertions(+)\n create mode 100644 src/script.py\ngit status\nOn branch main\nnothing to commit, working tree clean\nWhat does ‚Äúworking tree clean‚Äù mean? In the next section, we will talk about the three file trees of Git.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Excluding from version control"
    ]
  },
  {
    "objectID": "git/intro_git_content.html",
    "href": "git/intro_git_content.html",
    "title": "What is Git?",
    "section": "",
    "text": "Content from the intro slides for easier browsing.\nFirst, we need to answer the question:",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "What is Git?",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "git/intro_git_content.html#what-is-version-control",
    "href": "git/intro_git_content.html#what-is-version-control",
    "title": "What is Git?",
    "section": "What is version control?",
    "text": "What is version control?\nWhenever we work on important documents, we know that we should keep key versions.\n\nExample:\n\nThe version of a manuscript that we sent to our supervisor.\nThe revised version after we addressed their comments.\nThe revised version after we addressed reviewer comments.\nEtc.\n\n\n\n\n\nHome-made versioning:\nIt is quite messy‚Ä¶\n\n\n\n\n\nFrom PhD\n\n\n\n\n\n\n\nAnd inevitably, it leads to this:\n\n\n\n\n\nFrom Geek&Poke\n\n\n\n\nVersion control systems (VCS) are software that handle versioning effectively.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "What is Git?",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "git/intro_git_content.html#which-vcs-should-i-use",
    "href": "git/intro_git_content.html#which-vcs-should-i-use",
    "title": "What is Git?",
    "section": "Which VCS should I use?",
    "text": "Which VCS should I use?\nSeveral systems have been developed over the years with various functioning.\nThen came Git‚Ä¶\n\n\n\nGit\nGit is an open source distributed VCS created in 2005 by Linus Torvalds for the versioning of the Linux kernel during its development.\nIn distributed VCS, the full history of projects lives on everybody‚Äôs machine‚Äîas opposed to being only stored on a central server as was the case with centralized VCS. This allows for offline work and multiple backups.\nGit also introduced an extremely powerful and light-weight branching system.\nIt is extremely powerful and almost universally adopted.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "What is Git?",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "git/intro_git_content.html#how-does-git-work",
    "href": "git/intro_git_content.html#how-does-git-work",
    "title": "What is Git?",
    "section": "How does Git work?",
    "text": "How does Git work?\nGit saves the history of a project as a series of snapshots:\n\nThe data is stored as blobs, doesn‚Äôt create unnecessary copies (unchanged files are referenced from old blobs), and uses excellent compression.\nThese snapshots are identified by commits:\n\nEach commit has a unique hash and contains the following metadata:\n\nAuthor.\nDate and time.\nThe hash of parent commit(s).\nA descriptive message.\n\nWhen you create the 1st commit, a pointer called a branch is created and points to it:\n\nBy default, that first branch is called main.\nAnother pointer (HEAD) points to the branch main. HEAD indicates where you are in the project history.\nAs you create more commits the pointers HEAD and main move automatically:\n\nAs you create more commits the pointers HEAD and main move automatically:\n\nFor simplicity, the diagrams can be simplified this way:",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "What is Git?",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "git/intro_git_content.html#how-can-these-commits-be-used",
    "href": "git/intro_git_content.html#how-can-these-commits-be-used",
    "title": "What is Git?",
    "section": "How can these commits be used?",
    "text": "How can these commits be used?\nYou can revisit old commits by moving HEAD to them:\n\nThis will uncompress the corresponding snapshot and you can look at the state of your files at that commit before going back to your branch.\nYou can also print the differences between various commits.\nYou can create multiple branches to explore freely and safely:\n\nHEAD can be moved back and forth between branches.\nYou can merge branches to bring your experiments into your main branch:\n\n\n\n\n\nTime to get started!\n\n\n\n\n\nFrom xkcd.com",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "What is Git?",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "git/intro_first_steps.html",
    "href": "git/intro_first_steps.html",
    "title": "First steps",
    "section": "",
    "text": "In this section, we will initialize our first Git repository, learn to explore it, and create a few commits.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "First steps"
    ]
  },
  {
    "objectID": "git/intro_first_steps.html#get-a-mock-project",
    "href": "git/intro_first_steps.html#get-a-mock-project",
    "title": "First steps",
    "section": "Get a mock project",
    "text": "Get a mock project\nLet‚Äôs download a mock project with a couple of files to practice with.\n\n1. Download the zip file\nNavigate to a suitable location (e.g.¬†cd ~), then download the file with:\ncurl --output project.zip https://mint.westdri.ca/git/project.zip\n\nIf you are working on your own machine (and not on our training cluster), you can alternatively download the file with this button:  Download the data \nNote that if you do this, you will have to know how to navigate to your Downloads directory from the command line so running the code above is a lot simpler.\n\n\n\n2. Unzip the file\nUnzip the file with:\nunzip project.zip\nYou should now have a project directory with a number of subdirectories and files. This is the project we will use today.\n\n\n3. Enter in the project root\ncd in the root of the project:\ncd project",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "First steps"
    ]
  },
  {
    "objectID": "git/intro_first_steps.html#inspect-the-project",
    "href": "git/intro_first_steps.html#inspect-the-project",
    "title": "First steps",
    "section": "Inspect the project",
    "text": "Inspect the project\nFirst, let‚Äôs have a look at our (very small) mock project.\nLet‚Äôs list the content of project:\nls -F\ndata/\nms/\nresults/\nsrc/\nThere are 4 subdirectories.\nls -a     # Show hidden files\n.\n..\ndata\nms\nresults\nsrc\nAs you can see, there are no hidden files.\nls -R\n.:\ndata\nms\nresults\nsrc\n\n./data:\ndataset.csv\n\n./ms:\nproposal.md\n\n./results:\n\n./src:\nscript.py\nNow we can see the content of each subdirectory.\nYou probably don‚Äôt have the tree command on your machine, so this won‚Äôt work for you, but don‚Äôt worry about it: this is only to show you the same result in a more readable format:\ntree\n.\n‚îú‚îÄ‚îÄ data\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ dataset.csv\n‚îú‚îÄ‚îÄ ms\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ proposal.md\n‚îú‚îÄ‚îÄ results\n‚îî‚îÄ‚îÄ src\n    ‚îî‚îÄ‚îÄ script.py\n\n5 directories, 3 files\nLet‚Äôs look at the content of the files.\nThis is our very exciting data set:\ncat data/dataset.csv\nvar1,var2,var3,\n1,2,1,\n0,1,0,\n3,3,3\nAnd a no less exciting manuscript (the proposal for our project):\ncat ms/proposal.md\n# Summary\n\nThis is the summary for our proposal.\n\n# Funding\n\nInformation on funding for the project.\n\n# Methods\n\nHere we have some methods using our Python scripts.\n\n# Expected results\n\nWe hope to achieve a lot.\n\n# Conclusion\n\nThis is truly a great proposal.\nAnd finally, a Python script:\ncat src/script.py\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\ndf = pd.read_csv('../data/dataset.csv')\n\ndf.plot()\nplt.savefig('../results/plot.png', dpi=300)",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "First steps"
    ]
  },
  {
    "objectID": "git/intro_first_steps.html#initializing-a-git-repository",
    "href": "git/intro_first_steps.html#initializing-a-git-repository",
    "title": "First steps",
    "section": "Initializing a Git repository",
    "text": "Initializing a Git repository\nOur project is just a bunch of files and subdirectories. To turn it into a Git repository, we run:\ngit init\nInitialized empty Git repository in project/.git/\n\nMake sure to be at the root of the project (here, inside the project directory) before initializing the repository.\n\n\nGit is verbose: you will often get useful feed-back after running commands. Read them!\n\nWhen you run this command, Git creates a .git repository. This is where it will store all its files (all those blob objects, pointers, and other files).\nYou can see that this repository was created by running:\nls -a\n.\n..\n.git\ndata\nms\nresults\nsrc\n\nIf you run git init in the wrong location, you can easily fix this by deleting the .git directory that you created (e.g.¬†rm -r .git).\n\n\nGit commands\nAs you might have already noticed, Git commands start with git.\nA typical command is of the form:\ngit &lt;command&gt; [flags] [arguments]\n\nExample of a command we used to configure Git:\n\ngit config --global \"Your Name\"\n\nExample of a much simpler command with no flag nor argument:\n\ngit init",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "First steps"
    ]
  },
  {
    "objectID": "git/intro_first_steps.html#status-of-the-repository",
    "href": "git/intro_first_steps.html#status-of-the-repository",
    "title": "First steps",
    "section": "Status of the repository",
    "text": "Status of the repository\nOne command you will run often when working with Git is git status. It gives you information on new changes to your project:\ngit status\nOn branch main\n\nNo commits yet\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n        data/\n        ms/\n        src/\n\nnothing added to commit but untracked files present (use \"git add\" to track)\nThere is a lot of information here:\n\nWe are on branch main. That is the default name for the branch that gets created automatically as soon as we initialize a Git repository.\nThere are no commits yet (normal: we just initialized a new repository).\nThere are untracked files in our repo.\n\nIt is time to create a first commit‚Ä¶",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "First steps"
    ]
  },
  {
    "objectID": "git/intro_first_steps.html#creating-commits",
    "href": "git/intro_first_steps.html#creating-commits",
    "title": "First steps",
    "section": "Creating commits",
    "text": "Creating commits\nRemember that commits are those ‚Äúsnapshots‚Äù of your project at certain moments in time. You should create a new commit whenever you think that your project is at a point to which you might want to go back to later. There is no rule about when or how often to create commits: it is really up to you.\nBefore we create our first commit, we need to decide what file(s) we want to add to this commit.\nWe could add everything.\nWe can also be more selective and add files one by one.\nWe can even add only sections of files.\nHow do we tell Git what to add to the next commit?\n\nThe staging area\nGit has a staging area: a way to select what to add to the next commit. Files (or sections of files) get added to the staging area with git add.\nTo add all the files at once, we run, from the root of the project:\ngit add .\nThe . represents the current directory. Because Git adds files recursively, this will add all new files.\nTo add a particular file, we add its path as an argument to git add.\n\nExample:\n\ngit add ms/proposal.md\nTo add all the files in a directory, we add the path of that directory as an argument to git add.\n\nExample:\n\ngit add ms\n\nSince there is a single file in the ms directory, both commands will in our case lead to the same result.\n\nLet‚Äôs run that last command:\ngit add ms\nIt looks like nothing happened. Did it work? How can I know?\nAnswer: by running git status again. That‚Äôs the command to go to whenever you need to get some update on the status of the repo:\ngit status\nOn branch main\n\nNo commits yet\n\nChanges to be committed:\n  (use \"git rm --cached &lt;file&gt;...\" to unstage)\n        new file:   ms/proposal.md\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n        data/\n        src/\nIt worked! We can see that the content of the ms subdirectory is ready to be committed. It is in the staging area.\n\n\nYour turn:\n\nWhat if we change our mind as to the composition of our first commit and we want to create our first commit with the Python script instead? To do that, we need to unstage proposal.md first.\nHow can we do that? Give it a try.\nThen, how can we stage the Python script?\n\n\n\nCommitting\nOnce we are happy with the content of the future commit, it is time to create it. The command for this is git commit.\nRemember that each commit contains the following metadata:\n\nauthor,\ndate and time,\nthe hash of parent commit(s),\na message.\n\nThe first three can be set by Git automatically (you have configured Git so it knows who the author is).\nGit has no way to come up with the forth one however. You need to create it yourself.\nIf you run git commit, Git will open your text editor so that you can type the message. If you want to enter the message directly from the command line, you use the -m flag followed by the quoted message:\ngit commit -m \"Initial commit\"\n[main (root-commit) 61abf96] Initial commit\n 1 file changed, 19 insertions(+)\n create mode 100644 ms/proposal.md\nWe now have a first commit. Its hash starts (in my case‚Äîyours will be different of course) with 61abf96.\n\nGood commit messages\n\n\n\nFrom xkcd.com\n\n\nIt is suggested to:\n\nuse the present tense,\nthe first line is a summary of the commit and is less than 50 characters long,\nleave a blank line below,\nthen add the body of your commit message with more details.\n\n\nExample of a good commit message:\n\ngit commit -m \"Reduce boundary conditions by a factor of 0.3\n\nUpdate boundaries\nRerun model and update table\nRephrase method section in ms\"\nFuture you will thank you! (And so will your collaborators).\n\nIf we run git status once more, we now get:\nOn branch main\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n        data/\n        src/\n\nnothing added to commit but untracked files present (use \"git add\" to track)\nThe directory ms has disappeared from the list of untracked files: its content has now been committed to history.\n\n\nUnderstanding the staging area\nNew Git users are often confused about the two-step commit process (first, you stage with git add, then you commit with git commit). This intermediate step seems, at first, totally unnecessary. In fact, it is very useful: without it, commits would always include all new changes made to a project and they would thus be very messy. The staging area allows to prepare (‚Äústage‚Äù) the next commit. This way, you only commit what you want when you want.\n\nLet‚Äôs go over a simple example:\n\nWe don‚Äôt always work linearly. Maybe you are working on a section of your manuscript when you realize by chance that there is a mistake in your script. You fix that mistake. On your next commit, it might make little sense to commit together that fix and your manuscript changes since they are not related. If your commits are random bag of changes, it will be very hard for future you to navigate your project history.\nIt is a lot better to only stage your script fix, commit it, then only stage your manuscript update, and commit this in a different commit.\nThe staging area allows you to pick and chose the changes from one or various files that constitute some coherent change to the project and that make sense to commit together.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "First steps"
    ]
  },
  {
    "objectID": "git/intro_changes.html",
    "href": "git/intro_changes.html",
    "title": "Inspecting changes",
    "section": "",
    "text": "While git status gives you information on the files that were changed since the last commit, it doesn‚Äôt provide any information on what those changes are.\nIn this section, we will see how we can get information on the changes to the files contents.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Inspecting changes"
    ]
  },
  {
    "objectID": "git/intro_changes.html#the-three-trees-of-git",
    "href": "git/intro_changes.html#the-three-trees-of-git",
    "title": "Inspecting changes",
    "section": "The three trees of Git",
    "text": "The three trees of Git\nBefore we can jump into this section, we need to understand a bit more how Git works.\nOne useful mental representation is to imagine three file trees:\n\n\nThe working tree\nLet‚Äôs imagine that you are starting to work on a project.\nFirst, you create a directory.\nIn it, you create several sub-directories.\nIn those, you create a number of files.\nYou can open these files, read them, edit them, etc. This is something you are very familiar with.\nIn the Git world, this is the working directory or working tree of the project.\nThat is: an uncompressed version of your files that you can access and edit.\nYou can think of it as a sandbox because this is where you can experiment with the project. This is where the project gets developed.\nNow, Git has two other important pieces in its architecture.\n\n\nThe index\nIf you want the project history to be useful to future you, it has to be nice and tidy. You don‚Äôt want to record snapshots haphazardly or you will never be able to find anything back.\nBefore you record a snapshot, you carefully select the elements of the project as it is now that would be useful to write to the project history together. The index or staging area is what allows to do that: it contains the suggested future commit.\n\n\nHEAD\nFinally, the last tree in Git architecture is one snapshot in the project history that serves as a reference version of the project: if you want to see what you have been experimenting on in your ‚Äúsandbox‚Äù, you need to compare the state of the working directory with some snapshot.\nRemember that HEAD is a pointer pointing at a branch, that a branch is itself a pointer pointing at a commit, and finally that a commit is a Git object pointing at compressed blobs containing data about your project at a certain commit. When the HEAD pointer moves around, whatever commit it points to populates the HEAD tree with the corresponding data.\nAs we saw earlier, when you create a commit, HEAD automatically points to the new commit. So the HEAD tree is often filled with the last snapshot you created. But‚Äîas we will see later‚Äîwe can move the HEAD pointer around through other ways. So the HEAD tree can be populated by any snapshot in your project history.\n\n\n\n\n\n\nNoteGit trees video",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Inspecting changes"
    ]
  },
  {
    "objectID": "git/intro_changes.html#git-diff",
    "href": "git/intro_changes.html#git-diff",
    "title": "Inspecting changes",
    "section": "git diff",
    "text": "git diff\nThe command git diff prints the differences between any two Git objects. In particular, it allows to compare any two of the three trees with each other.\n\nDiff between working directory & index\n\ngit diff displays the differences between the working directory (the uncompressed files) and the index (the staging area):\ngit diff\nRight now, git diff does not return anything because our working tree and staging area are at the same point.\nLet‚Äôs make some changes in our proposal:\nnano ms/proposal.md\nNow, if we run git diff again, we get:\ndiff --git a/ms/proposal.md b/ms/proposal.md\nindex 0fb5cc8..4fdc1b0 100644\n--- a/ms/proposal.md\n+++ b/ms/proposal.md\n@@ -16,4 +16,4 @@ We hope to achieve a lot.\n\n # Conclusion\n\n-This is truly a great proposal.\n+This is truly a great proposal, but it needs a little more work.\n\n\nDiff between index & last commit\n\nTo see what would be committed if you ran git commit (that is the differences between the index and the last commit), you need to run instead:\ngit diff --cached\nWe aren‚Äôt getting any output because we haven‚Äôt staged anything that isn‚Äôt in our last commit. Let‚Äôs stage our changes and try again:\ngit add .\ngit diff --cached\ndiff --git a/ms/proposal.md b/ms/proposal.md\nindex 0fb5cc8..4fdc1b0 100644\n--- a/ms/proposal.md\n+++ b/ms/proposal.md\n@@ -16,4 +16,4 @@ We hope to achieve a lot.\n\n # Conclusion\n\n-This is truly a great proposal.\n+This is truly a great proposal, but it needs a little more work.\nThe changes are now between the staging area and HEAD.\n\nIf we run git diff now, we aren‚Äôt getting any output because the staging area has caught up with the working tree: they are now the same, so no differences.\n\ngit diff --cached is very convenient to check what will enter in the next commit.\n\n\nDiff between working directory & last commit\n\nFinally, to see the differences between your working directory and HEAD, you run:\ngit diff HEAD\nThis will be the sum of the previous two.\nRight now, git diff --cached and git diff HEAD print the same result, but if we make new changes, they will become different since git diff HEAD will reflect all the changes between the working tree and the last commit, while git diff --cached will only contain the differences between the staging area and the last commit.\n\n\nYour turn:\n\nModify one of the tracked files to visualize this.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Inspecting changes"
    ]
  },
  {
    "objectID": "git/intro_aliases.html",
    "href": "git/intro_aliases.html",
    "title": "Aliases",
    "section": "",
    "text": "You might find it convenient to replace some long Git commands with shorter versions.\nFor example, wouldn‚Äôt it be nice if instead of typing git status you could type git st? It turns out this is easy to do via Git aliases.\n\nHere is the syntax to create a Git alias for all your Git repos:\ngit config --global alias.st 'status'\nThis creates a new Git command git st that expands to git status.\nOf course, this is particularly useful with longer commands.\n\nHere is an example to list all files in a repository:\n\ngit config --global alias.list 'ls-tree --full-tree -r HEAD'\nTo get the list of files, you can now simply run:\ngit list\nGlobal aliases are stored in your ~/.gitconfig file. You can print them with:\ngit config --list\n\nYou can set aliases for specific repos without the --global flag (although, it is unclear to me why you would ever want to do this).\n\n\nHere is another example:\n\ngit config --global alias.graph \\\n \"log --graph \\\n      --date-order \\\n      --date=short \\\n      --pretty=format:'%C(cyan)%h %C(yellow)%ar %C(auto)%s%+b %C(green)%ae'\"\nNow, git graph will give you the log in the form of a compact graph with nice colour-coding.\n\nHere is a more complex example involving an argument and a Unix command:\n\nImagine that you want to create an alias that allows you to easily run commands such as: git grep \"test\" $(git rev-list --all).\nThis searches for the string ‚Äútest‚Äù in all previous commits. This command takes an argument (the string ‚Äútest‚Äù) and it uses the output from another Unix command (git rev-list --all) as its input.\nTo turn this into an alias, you need to create an executable bash script and place it in your $PATH environment variable:\n# Assuming that `$HOME/bin` is listed in your `$PATH`\n\n# Create a Bash script in `$HOME/bin`\ncat &lt;&lt; EOF &gt; $HOME/bin/git-search\n#!/bin/bash\ngit grep \\${1} \\$(git rev-list --all)\nEOF\n\n# Make it executable\nchmod u+x $HOME/bin/git-search\nYou can now run git search test to search the entire Git project history for the string ‚Äútest‚Äù.\nOf course, it works with any other string: git search Methods will search for the string ‚ÄúMethods‚Äù.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Aliases"
    ]
  },
  {
    "objectID": "git/col_setup.html",
    "href": "git/col_setup.html",
    "title": "GitHub account setup",
    "section": "",
    "text": "In this course, we are using GitHub as an example, but other services such as GitLab and Bitbucket offer similar services.\nBefore starting to use GitHub, you need to create and configure an account. We will do this in this section.",
    "crumbs": [
      "Git",
      "<b><em>Collaborating on GitHub</em></b>",
      "GitHub account setup"
    ]
  },
  {
    "objectID": "git/col_setup.html#create-a-free-github-account",
    "href": "git/col_setup.html#create-a-free-github-account",
    "title": "GitHub account setup",
    "section": "Create a free GitHub account",
    "text": "Create a free GitHub account\nIf you don‚Äôt already have one, go to the GitHub website and create a free account.",
    "crumbs": [
      "Git",
      "<b><em>Collaborating on GitHub</em></b>",
      "GitHub account setup"
    ]
  },
  {
    "objectID": "git/col_setup.html#connect-to-github",
    "href": "git/col_setup.html#connect-to-github",
    "title": "GitHub account setup",
    "section": "Connect to GitHub",
    "text": "Connect to GitHub\nThe 2 main ways to push data to GitHub are:\n\nusing a token,\nusing SSH.\n\n\nThere are alternative methods but you will have to look for information on your own:\n\nIf you use Edge, there is an integration with GitHub since they are both owned by Microsoft.\n\nThe GitHub Desktop application gives additional options to connect.\n\nIf you use the GitHub app, it also gives authentication methods.\n\n\n\nUsing a token\nA token can be generated directly within GitHub settings, which seems convenient. However, if you use a token, you will have to communicate with GitHub via HTTPS and enter your token whenever you push and pull to your GitHub directories. It is quite tedious.\nIf you have to use a token, here is the workflow:\n\nIn the upper-right corner of any page on GitHub, click your profile photo, then click Settings.\nIn the left sidebar, click Developer settings.\nIn the left sidebar, under Personal access tokens, click Fine-grained tokens.\nClick Generate new token.\nUnder Token name, enter a name for the token.\nUnder Repository access, select which repositories you want the token to access.\nUnder Permissions, select which permissions to grant the token.\nClick Generate token.\nMake sure to copy the token and save it to your computer.\n\nWhen you push to GitHub, you will be asked for your username and password. Your username is your GitHub username and the password is your token.\n\n\nUsing SSH\nAn SSH key pair is a set of 2 files: the private key and the public key. You keep the private key securely on your machine‚Äîthink of it as a key to open a lock‚Äîand you upload the public key to GitHub (or other places such as the Alliance clusters)‚Äîthink of that as a lock.\nYour private key allows to ‚Äúopen the lock‚Äù if it matches the public key.\nPeople can see your public key, but they can‚Äôt generate the private key from it. Since you are the only one having the matching private key, you are the only one able to open that lock and log in securely‚Äîunless someone steals your private key (if they get access to your computer).\nTo add a level of safety, you can set a passphrase when you generate an SSH key pair. That way, to open that lock (public key), not only you need to have the matching private key, but you also need to enter the passphrase.\n\nGenerate SSH key pair\nFrom Git Bash (Windows), Terminal (macOS), or your usual terminal emulator (Linux), run:\nssh-keygen\n\nWhen prompted to Enter a file in which to save the key, you can press Enter to accept the default file name and location. If you have already created SSH key pairs, ssh-keygen may ask to overwrite another pair. In that case, give your new key a custom name.\nWhen prompted to enter a passphrase, do so, then when prompted to enter it again, do so again.\n\n\n\nSSH agent\nIf you do not want to enter the passphrase of your SSH key pair each time you push to GitHub, you can use an SSH agent to cache your passphrase.\n\nLinux\nFor those using Linux, you can refer to the Arch Linux wiki section on SSH agent.\n\n\nmacOS\nOn macOS, you will be prompted for your passphrase the first time you use your key, but it will then be saved automatically in your keychain.\n\n\nWindows\nOn Windows, you first add your SSH key to the SSH agent, then you can set your SSH agent to launch automatically when you open Git Bash.\n\n\n\nAdd the public key to GitHub\nHere are the steps:\n\nCopy the content of your public key.\n\n\nTo do this, you can cat its content to the terminal with (modify the file name if you used a custom name):\ncat ~/.ssh/id_rsa.pub\nSelect the output and copy it.\n\n\nGo to your GitHub account, click your profile photo in the top right corner, then click Settings.\nIn the Access section of the sidebar, click SSH and GPG keys.\nClick New SSH key.\nIn the Title field, add a description for the key.\nSelect authentication as the type of key.\nIn the Key field, paste your public key.\nClick Add SSH key.\n\n\nIf you are having issue setting up SSH for GitHub, you can use a token today and look into this later.",
    "crumbs": [
      "Git",
      "<b><em>Collaborating on GitHub</em></b>",
      "GitHub account setup"
    ]
  },
  {
    "objectID": "git/col_access.html",
    "href": "git/col_access.html",
    "title": "Working with write access",
    "section": "",
    "text": "Small teams often collaborate by granting everybody permission to write directly to the project. If you work on a paper with your thesis supervisor or a few co-authors, you will probably work this way. This is what we will cover in this section.\nBigger teams (e.g.¬†research labs, big organizations) usually have a different workflow that we will cover in the next section.",
    "crumbs": [
      "Git",
      "<b><em>Collaborating on GitHub</em></b>",
      "Working with write access"
    ]
  },
  {
    "objectID": "git/col_access.html#setup",
    "href": "git/col_access.html#setup",
    "title": "Working with write access",
    "section": "Setup",
    "text": "Setup\n\nYou initiate the project\nIn this situation, you are the author of a project (you have a project under version control on your own machine) and you want to initiate a collaboration with others using GitHub as a remote.\n\nCreate a remote on GitHub\nYou need to create a remote on GitHub.\n\nCreate a repository on GitHub\n\nGo to the GitHub website, login, and go to your home page.\nLook for the Repositories tab & click the green New button.\nEnter the name you want for your repo, without spaces.\nMake the repository public or private.\n\n\n\nLink GitHub repo to local repo\nClick on the Code green drop-down button, select SSH if you have set SSH for your GitHub account or HTTPS and copy the address.\nIn the command line, cd inside your project, and add the remote:\ngit remote add &lt;remote-name&gt; &lt;remote-address&gt;\nremote-name is a convenience name to identify that remote. You can choose any name, but since Git automatically call the remote origin when you clone a repo, it is common practice to use origin as the name for the first remote.\n\nExample (using an SSH address):\n\ngit remote add origin git@github.com:&lt;user&gt;/&lt;repo&gt;.git\n\nExample (using an HTTPS address):\n\ngit remote add origin https://github.com/&lt;user&gt;/&lt;repo&gt;.git\nIf you don‚Äôt want to grant others write access to the project, and you only accept contributions through pull requests, you are set.\nIf you want to grant your collaborators write access to the project however, you need to add them to it.\n\n\n\nInvite collaborators\n\nGo to your GitHub project page.\nClick on the Settings tab.\nClick on the Manage access section on the left-hand side (you will be prompted for your GitHub password).\nClick on the Invite a collaborator green button.\nInvite your collaborators with one of their GitHub user name, their email address, or their full name.\n\n\n\n\nYou are invited to a project\nIn this second situation, someone else started a project and they are inviting you to collaborate to it, giving you write access to the project.\nIn this case, you need to clone the project: cd to the location where you want your local copy, then:\ngit clone &lt;remote-address&gt; &lt;local-name&gt;\nThis sets the project as a remote to your new local copy and that remote is automatically called origin.\nWithout &lt;local-name&gt;, the repo will have the name of the last part of the remote address.",
    "crumbs": [
      "Git",
      "<b><em>Collaborating on GitHub</em></b>",
      "Working with write access"
    ]
  },
  {
    "objectID": "git/col_access.html#collaborative-workflow",
    "href": "git/col_access.html#collaborative-workflow",
    "title": "Working with write access",
    "section": "Collaborative workflow",
    "text": "Collaborative workflow\n\nPulling and pushing\nThe remotes section of our introductory course to Git covers pushing and pulling to a remote. Remember that to update a remote with your changes, you ‚Äúpush‚Äù them with git push.\nWhen you collaborate with others however, you will not be the only person accessing a remote. Git is extremely powerful in that it allows for collaborators to work on a project synchronously, but if one of your collaborators has made changes to the remote (pushing from their own local version of the project), you won‚Äôt be able to push.\nInstead, you will get the following message:\nTo &lt;your-project&gt;.git\n ! [rejected]        main -&gt; main (fetch first)\nerror: failed to push some refs to 'xxx.git'\nhint: Updates were rejected because the remote contains work that you do\nhint: not have locally. This is usually caused by another repository pushing\nhint: to the same ref. You may want to first integrate the remote changes\nhint: (e.g., 'git pull ...') before pushing again.\nhint: See the 'Note about fast-forwards' in 'git push --help' for details.\nSo how does this work?\n\n\n\nFrom crystallize.com\n\n\nYou first have to update your local version of the project with their change by running git pull.\nIf there are no conflicts (the same lines of the same files having conflicting versions) Git will automatically merge their changes with yours and now you can push the merged changes back to the remote.\nNow‚Ä¶ what if there are conflicts?\n\n\nResolving conflicts\nGit works line by line. As long as your collaborators and you aren‚Äôt working on the same line(s) of the same file(s) at the same time, there will not be any problem. If however you modified one or more of the same line(s) of the same file(s), Git will not be able to decide which version should be kept.\nWhen you git pull their work on your machine, the automatic merging will get interrupted and Git will ask you to resolve the conflict(s) before the merge can resume. It will conveniently tell you which file(s) contain the conflict(s).\nThere are fancy tools to resolve conflicts, but you can do it in any text editor: simply open the file(s) listed by Git as having conflicts and look for the following markers:\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nThis is your version.\n=======\nThis is the alternative version of the same section of the file.\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; alternative version\nThese markers are added by Git to signal the areas of conflict. It is up to you to choose between the two versions (or create a third one) and remove the conflict markers. After that, you can stage the file(s) which contained the conflicts to finish the merge (and then you can commit).",
    "crumbs": [
      "Git",
      "<b><em>Collaborating on GitHub</em></b>",
      "Working with write access"
    ]
  },
  {
    "objectID": "emacs/wb_python.html",
    "href": "emacs/wb_python.html",
    "title": "Full Python IDE in Emacs",
    "section": "",
    "text": "There are quite a few packages that can turn Emacs into a Python IDE (a classic example is elpy and since version 29, eglot‚Äîan LSP client‚Äîcomes shipped with Emacs).\nAfter playing with many of the options, I settled on a selection of packages that turn Emacs into a truly impressive Python IDE:\n\nlsp-mode, lsp-ui, and lsp-pyright provide astounding code completion, debugging, code navigation, and many helpers,\npy-vterm-interaction.el runs your favourite Python shell (Python REPL, ipython, ptpython, or ptipython) in a much improved Emacs terminal emulator,\nemacs-reformatter reformats your code with the linter of your choice (e.g.¬†black or the much faster ruff).\n\n\nComing up in spring 2026.",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "Full Python IDE in Emacs"
    ]
  },
  {
    "objectID": "emacs/wb_new_tools_content.html",
    "href": "emacs/wb_new_tools_content.html",
    "title": "Modern Emacs",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "Modern, faster & better Emacs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_new_tools_content.html#faster-emacs",
    "href": "emacs/wb_new_tools_content.html#faster-emacs",
    "title": "Modern Emacs",
    "section": "Faster Emacs",
    "text": "Faster Emacs\n\nLexical binding\n\nIntroduced in version 24.\nLexical binding can be used instead of dynamic binding for Emacs Lisp code.\nSet as a file local variable.\n\n\nDynamic binding\nName resolution depends on program state (runtime context), determined at run time.\nGlobal environment for all variables.\nMakes modifying behaviour easy.\n\n\nLexical binding\nName resolution depends on lexical context (static context), determined at compile time.\nLocal environments of functions and let, defconst, defvar, etc. expressions.\nMakes compiler optimization much easier ‚Üí faster Elisp code = faster Emacs.\n\n\n\nJIT native compilation\n\nIntroduced in version 28.\nRequires libgccjit.\nBuild Emacs --with-native-compilation.\nPackages can also be compiled natively (automatic with straight).\n\nProvides:\n\nFaster startup.\nSpeedup of 2.5 to 5 compared to corresponding byte-compiled code.\n\n\n\nLazy loading\n\nBuilt-in since version 29.\nFine-tuned loading of packages with use-package.\nIntegrates nicely with straight.\n\nProvides:\n\nFaster startup time.\nMore organized init file.\nEasier to reload configurations for single package.",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "Modern, faster & better Emacs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_new_tools_content.html#perfect-parsing",
    "href": "emacs/wb_new_tools_content.html#perfect-parsing",
    "title": "Modern Emacs",
    "section": "Perfect parsing",
    "text": "Perfect parsing\n\nAccurate syntax tree\n\nBuilt-in since version 29.\nTree-sitter for Emacs.\nCode is parsed accurately instead of using regexp.\n\nProvides:\n\nPerfect syntax highlighting, indentation, and navigation.\nFaster.\n\nSimplest setup with treesit-auto:\n(use-package treesit-auto\n  :config\n  (treesit-auto-add-to-auto-mode-alist 'all))",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "Modern, faster & better Emacs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_new_tools_content.html#more-efficient-completions",
    "href": "emacs/wb_new_tools_content.html#more-efficient-completions",
    "title": "Modern Emacs",
    "section": "More efficient completions",
    "text": "More efficient completions\n\nHistory of code completion\n\nIDO\n\n\n\nFrom Xah Emacs Blog\n\n\n\n\nIDO vertical\n\n\n\nFrom oremacs\n\n\n\n\nHELM\n\n\n\nFrom oracleyue\n\n\n\n\nIvy\nWith optional Counsel & Swiper.\n\n\n\nFrom abo-abo/swiper\n\n\n\n\n\nA new framework\n\nExternal packages.\nUse default Emacs functions (less code).\nFaster, flexible, customizable with discrete units.\n\n\nPackages\n\n\n\nMinibuffer\n\nvertico\norderless\nconsult\nmarginalia\nembark\n\n\n\n¬†\nFrontend completion UI Backend completion style Backend completion functions Annotations Actions on completion buffer\n\n\nIn buffer\n\ncorfu\norderless\ncape\neglot\n\n\n\n¬†\nFrontend completion UI Backend completion style Backend completion functions Backend LSP client\n\n\n\n\n\nAdvantages\n\nIntegrates beautifully with internal Emacs functions.\nEasy jump back & forth between buffer and completion buffer.\nMuch faster than HELM.\nLightning fast previews with auto-closing buffers.\nEasy customization.\n\n\n\nExample configuration\nVertico (frontend for completion in minibuffer).\n(use-package vertico\n  :init\n  (vertico-mode 1)\n  (vertico-multiform-mode 1)\n  :config\n  (setq vertico-multiform-commands\n    '((consult-line buffer)\n      (consult-line-thing-at-point buffer)\n      (consult-recent-file buffer)\n      (consult-mode-command buffer)\n      (consult-complex-command buffer)\n      (embark-bindings buffer)\n      (consult-locate buffer)\n      (consult-project-buffer buffer)\n      (consult-ripgrep buffer)\n      (consult-fd buffer)))\n  :bind (:map vertico-map\n          (\"C-k\" . kill-whole-line)\n          (\"C-u\" . kill-whole-line)\n          (\"C-o\" . vertico-next-group)\n          (\"&lt;tab&gt;\" . minibuffer-complete)\n          (\"M-&lt;return&gt;\" . minibuffer-force-complete-and-exit)))\n\n;; save search history\n(use-package savehist\n  :init\n  (savehist-mode 1))\n\n\n\nLanguage Server Protocol client\n\nBuilt-in since version 29.\n\nEglot (Emacs Polyglot) allows to connect to a programming language server.\n\nExample: Julia\nNeed to install an LSP for Julia:\n(straight-use-package 'eglot-jl)\nThen run eglot-jl-init\nNow eglot in a Julia buffer connects to the server.\n\nSimilarly, you can install an LSP for R or Python or any language and use Eglot with R, Python, or whatever language.\n\n\n\n\n‚ù§Ô∏è to all Emacs developers\nIn particular:\n\ndevelopers, maintainers, and contributors to Emacs core,\ndevelopers and maintainers to some of the mentioned packages:\n\nDaniel Mendler,\nOmar Antol√≠n Camarena,\nJo√£o T√°vora,\nRobb Enzmann,\nJohn Wiegley,\nAdam B,\nand all their contributors.",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "Modern, faster & better Emacs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_modes_slides.html#why-use-emacs",
    "href": "emacs/wb_modes_slides.html#why-use-emacs",
    "title": "Understanding Emacs modes",
    "section": "Why use Emacs?",
    "text": "Why use Emacs?\n\n\n\n To brag."
  },
  {
    "objectID": "emacs/wb_modes_slides.html#why-use-emacs-1",
    "href": "emacs/wb_modes_slides.html#why-use-emacs-1",
    "title": "Understanding Emacs modes",
    "section": "Why use Emacs?",
    "text": "Why use Emacs?\n\n\n To brag. Obviously."
  },
  {
    "objectID": "emacs/wb_modes_slides.html#why-use-emacs-2",
    "href": "emacs/wb_modes_slides.html#why-use-emacs-2",
    "title": "Understanding Emacs modes",
    "section": "Why use Emacs?",
    "text": "Why use Emacs?\n But there are other reasons:\n\nFree and open source\nEndlessly customizable\nAmazing diff\nMacros\nText and file searching\nGreat programming IDE\nLossless and endless undo/redo\nFun!\n‚Ä¶"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#now-getting-started-can-be-daunting",
    "href": "emacs/wb_modes_slides.html#now-getting-started-can-be-daunting",
    "title": "Understanding Emacs modes",
    "section": "Now ‚Ä¶ getting started can be daunting",
    "text": "Now ‚Ä¶ getting started can be daunting"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#and-it-doesnt-necessarily-get-easier",
    "href": "emacs/wb_modes_slides.html#and-it-doesnt-necessarily-get-easier",
    "title": "Understanding Emacs modes",
    "section": "‚Ä¶ and it doesn‚Äôt necessarily get easier",
    "text": "‚Ä¶ and it doesn‚Äôt necessarily get easier\n\n\n\n\n\n\n\nBut it‚Äôs all worth it!"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#emacs-lisp",
    "href": "emacs/wb_modes_slides.html#emacs-lisp",
    "title": "Understanding Emacs modes",
    "section": "Emacs Lisp",
    "text": "Emacs Lisp\nEmacs Lisp is a dialect of the Lisp programming language developed especially to write the editing functionality of the Emacs text editor (the rest of Emacs and its interpreter are written in C)\nEmacs is endlessly customizable to anyone with a basic knowledge of Emacs Lisp. In particular, variables and functions setting the behaviour and appearance of the text editor can be created or modified\nThe language is well documented"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#graphical-display",
    "href": "emacs/wb_modes_slides.html#graphical-display",
    "title": "Understanding Emacs modes",
    "section": "Graphical display",
    "text": "Graphical display"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#graphical-display-1",
    "href": "emacs/wb_modes_slides.html#graphical-display-1",
    "title": "Understanding Emacs modes",
    "section": "Graphical display",
    "text": "Graphical display"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#graphical-display-2",
    "href": "emacs/wb_modes_slides.html#graphical-display-2",
    "title": "Understanding Emacs modes",
    "section": "Graphical display",
    "text": "Graphical display"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#graphical-display-3",
    "href": "emacs/wb_modes_slides.html#graphical-display-3",
    "title": "Understanding Emacs modes",
    "section": "Graphical display",
    "text": "Graphical display"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#graphical-display-4",
    "href": "emacs/wb_modes_slides.html#graphical-display-4",
    "title": "Understanding Emacs modes",
    "section": "Graphical display",
    "text": "Graphical display"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#graphical-display-5",
    "href": "emacs/wb_modes_slides.html#graphical-display-5",
    "title": "Understanding Emacs modes",
    "section": "Graphical display",
    "text": "Graphical display"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#graphical-display-6",
    "href": "emacs/wb_modes_slides.html#graphical-display-6",
    "title": "Understanding Emacs modes",
    "section": "Graphical display",
    "text": "Graphical display"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#graphical-display-7",
    "href": "emacs/wb_modes_slides.html#graphical-display-7",
    "title": "Understanding Emacs modes",
    "section": "Graphical display",
    "text": "Graphical display"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#graphical-display-8",
    "href": "emacs/wb_modes_slides.html#graphical-display-8",
    "title": "Understanding Emacs modes",
    "section": "Graphical display",
    "text": "Graphical display"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#graphical-display-9",
    "href": "emacs/wb_modes_slides.html#graphical-display-9",
    "title": "Understanding Emacs modes",
    "section": "Graphical display",
    "text": "Graphical display"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#keybindings-kbd",
    "href": "emacs/wb_modes_slides.html#keybindings-kbd",
    "title": "Understanding Emacs modes",
    "section": "Keybindings (kbd)",
    "text": "Keybindings (kbd)\n\n\n\nFrom Ecol LG #134 by Javier Malonda"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#kbd-notations",
    "href": "emacs/wb_modes_slides.html#kbd-notations",
    "title": "Understanding Emacs modes",
    "section": "Kbd notations",
    "text": "Kbd notations\nC-c means press the Control key and the C key together\nM-x means press the Alt (Windows) or Option (macOS) key and the X key together\nC-c m means press the Control key and the C key together, then press the M key\nC-c C-x m means press Ctl+C, then Ctl+X, then M\nC-x C-c M-w C-m M-v M-t M-u means that you probably should choose another kbd"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#command-execution",
    "href": "emacs/wb_modes_slides.html#command-execution",
    "title": "Understanding Emacs modes",
    "section": "Command execution",
    "text": "Command execution\nA useful way to execute a command interactively, when it is not bound to a kbd, is to type M-x (this brings up the minibuffer, a place in which to type inputs) followed by the command name\n\nFor example, M-x count-words will output the number of lines, sentences, words, and characters of the current buffer in the echo area"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#major-modes",
    "href": "emacs/wb_modes_slides.html#major-modes",
    "title": "Understanding Emacs modes",
    "section": "Major modes",
    "text": "Major modes\nDifferent types of text require different behaviours, syntax highlighting, formatting, functions, variables, etc.\nEach type of buffer (e.g.¬†Python script, Markdown document, Julia REPL, Bash shell, directory editor, pdf) is associated with a different major mode\nFile extensions, particular markers in the file, or other elements tell Emacs to automatically switch to the appropriate major mode\nOnly one major mode is active at a time\nSwitching to a different major mode is possible by running the corresponding major mode command (e.g.¬†M-x python-mode will switch to Python mode)"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#fundamental-mode",
    "href": "emacs/wb_modes_slides.html#fundamental-mode",
    "title": "Understanding Emacs modes",
    "section": "Fundamental mode",
    "text": "Fundamental mode\nfundamental-mode is the most basic major mode, with no particular feature\nThis is the mode enabled by default if Emacs cannot detect what specific major mode to enable"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#minor-modes",
    "href": "emacs/wb_modes_slides.html#minor-modes",
    "title": "Understanding Emacs modes",
    "section": "Minor modes",
    "text": "Minor modes\nMinor modes provide additional and optional features that can be turned on or off (e.g.¬†spell checking, auto-completion, auto-indentation, fancy undo behaviour, fancy parenthesis matching highlighting)\nMinor modes can be turned on/off by running the corresponding minor mode commands (e.g.¬†M-x flyspell-mode will turn spell checking on/off). The command consult-minor-mode-menu from the package consult makes this particularly easy\nEach mode comes with a set of commands. consult‚Äôs command consult-mode-command makes it easy to search for commands within each mode\nAny number of minor modes can be active at the same time"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#list-of-enabled-modes",
    "href": "emacs/wb_modes_slides.html#list-of-enabled-modes",
    "title": "Understanding Emacs modes",
    "section": "List of enabled modes",
    "text": "List of enabled modes\nBy default, &lt;f1&gt; m or M-x describe-mode will open a list and description of the active modes\nThe major mode can also be determined with &lt;f1&gt; v major-mode (&lt;f1&gt; v runs the command describe-variable)\nA list of minor modes can also be viewed with &lt;f1&gt; v minor-mode-list\nAgain, consult‚Äôs consult-minor-mode-menu makes all this much nicer"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#the-mode-line",
    "href": "emacs/wb_modes_slides.html#the-mode-line",
    "title": "Understanding Emacs modes",
    "section": "The mode line",
    "text": "The mode line\nAnother way to get information about enabled modes is the mode line"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#hooks",
    "href": "emacs/wb_modes_slides.html#hooks",
    "title": "Understanding Emacs modes",
    "section": "Hooks",
    "text": "Hooks\nMinor modes can be automatically enabled when other modes (major or minor) are enabled thanks to hooks\n\nFor example, to enable the aggressive indent minor mode whenever the ESS R major mode is enabled, you can add to your init file:\n\n(add-hook 'ess-r-mode-hook 'aggressive-indent-mode)\n\nOr, using use-package, now part of base Emacs:\n\n(use-package aggressive-indent\n:hook (ess-r-mode . aggressive-indent-mode))"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#modes-source-code",
    "href": "emacs/wb_modes_slides.html#modes-source-code",
    "title": "Understanding Emacs modes",
    "section": "Modes source code",
    "text": "Modes source code\nTo see the source code of a mode, run &lt;f1&gt; v (or M-x describe-variable) followed by the name of the mode map\nThis will open a help buffer with a link to the source code file\n\nFor example &lt;f1&gt; v text-mode-map will open a help buffer with a link to text-mode.el\n\n\nThe help buffer opened by &lt;f1&gt; m or M-x describe-mode also gives a link to the source code of the major mode\n\nLooking at the source code of a mode is very useful to customize it"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#customizing-modes",
    "href": "emacs/wb_modes_slides.html#customizing-modes",
    "title": "Understanding Emacs modes",
    "section": "Customizing modes",
    "text": "Customizing modes\nIn Emacs, everything is customizable\nTo customize modes, you can write Emacs Lisp code in your init file (the configuration file that gets loaded when Emacs launches) or you can use the easy customization interface\n\nFor example, to customize the Markdown major mode, you would run M-x customize-group markdown"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#evaluation-order",
    "href": "emacs/wb_modes_slides.html#evaluation-order",
    "title": "Understanding Emacs modes",
    "section": "Evaluation order",
    "text": "Evaluation order\nIf you write your own Emacs code, be careful that functions and variables take the value of their last loaded version. The order in which Emacs code is evaluated thus matters\nYou want to evaluate as little as possible when you launch Emacs to speed up start-up time (lazy evaluation): you don‚Äôt want to load every single package that you have installed\nThis means that if you overwrite a function or variable of a mode in your init file, the init file is read at start-up, but when that mode is launched, the default function/variable will overwrite the custom one you wrote in your init file"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#evaluation-order-1",
    "href": "emacs/wb_modes_slides.html#evaluation-order-1",
    "title": "Understanding Emacs modes",
    "section": "Evaluation order",
    "text": "Evaluation order\nTo by-pass this problem, you can use eval-after-load\n\nExample:\n(eval-after-load\n \"markdown\"\n '(defun markdown-demote ()\n    ...))\n\n\nuse-package has the :init and :config keyword symbols that ensure that the following expressions are evaluated respectively before or after the loading of a package"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#customizing-kbd",
    "href": "emacs/wb_modes_slides.html#customizing-kbd",
    "title": "Understanding Emacs modes",
    "section": "Customizing kbd",
    "text": "Customizing kbd\nMost modes come with specific keymaps: sets of kbd only active when the mode is enabled. These kbd of course can be customized\n\nFor example, to modify the kbd for the function markdown-outline-previous in the markdown-mode-map:\n\n(define-key markdown-mode-map (kbd \"M-p\") 'markdown-outline-previous)\n\nOr, using use-package:\n\n(use-package markdown-mode\n    :bind (:map markdown-mode-map\n                (\"M-p\" . markdown-outline-previous)))"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#polymode",
    "href": "emacs/wb_modes_slides.html#polymode",
    "title": "Understanding Emacs modes",
    "section": "Polymode",
    "text": "Polymode\nWhile it is normally impossible to associate multiple major modes with a single buffer, Polymode allows to insert sections of a major mode within another major mode\nThis is extremely convenient for instance to embed sections of code within human text, or even to have code executed within human text (e.g.¬†R Markdown or its successor Quarto, Org Babel)"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#polymode-1",
    "href": "emacs/wb_modes_slides.html#polymode-1",
    "title": "Understanding Emacs modes",
    "section": "Polymode",
    "text": "Polymode\nmarkdown-mode with snippets of julia-mode:\nJulia has \"assignment by operation\" operators:\n\n```{julia}\na = 2;\na += 7    # this is the same as a = a + 7\n```\n\nThere is a *left* division operator:\n\n```{julia}\n2\\8 == 8/2\n```"
  },
  {
    "objectID": "emacs/wb_modes_slides.html#polymode-2",
    "href": "emacs/wb_modes_slides.html#polymode-2",
    "title": "Understanding Emacs modes",
    "section": "Polymode",
    "text": "Polymode\nRendered by Quarto into:"
  },
  {
    "objectID": "emacs/wb_modes.html",
    "href": "emacs/wb_modes.html",
    "title": "Understanding Emacs modes",
    "section": "",
    "text": "At the core of Emacs functioning are modes: major modes set the appearance and behaviour of Emacs for various types of texts (e.g.¬†a Python script and a Markdown document will display different syntax highlighting and have different functions activated), while minor modes provide additional features that can be turned on or off (e.g.¬†spell checking). Understanding how modes work is key to customizing Emacs and exploiting its strengths.\nIn this webinar, I will explain the functioning of Emacs modes and show how to manage and even customize them. Finally, I will demo how the package Polymode allows to embed sections of a type of text in another type (e.g.¬†snippets of code in a Markdown document).\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "Understanding Emacs modes"
    ]
  },
  {
    "objectID": "emacs/wb_llms_content.html",
    "href": "emacs/wb_llms_content.html",
    "title": "AI pair programming & LLMs chats in Emacs",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "AI pair programming in Emacs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_llms_content.html#a-few-warnings",
    "href": "emacs/wb_llms_content.html#a-few-warnings",
    "title": "AI pair programming & LLMs chats in Emacs",
    "section": "A few warnings",
    "text": "A few warnings\n\nWarning about my setup\nI normally don‚Äôt share my Emacs init code because it relies on a remapping of the semi-colon as a ring-map which makes my keybindings absurd on another machine. I also use straight.el for packages installations and it itself requires to be installed first.\nBut I keep being asked for my code after each webinar. So this time, I am sharing it.\nDon‚Äôt copy-paste it in your init file: it would break your Emacs. Instead, use it to inspire your potential setup or, better still, go to the packages READMEs. They provide a much better place to start.\nYou have been warned‚Ä¶ üôÇ\n\n\nPrivacy warning\nMost companies offer a free tier. These may come with lower speed, limited tokens, older models.\nThe free tier always come with a lack of privacy: your LLM usage is used for model training.\nPaid services normally come with more privacy protections, but the landscape is fast evolving and accidents happen. Be mindful of what you type when you interact with LLMs. Do not type sensitive information in your prompt.\n\n\nSafe API key storage\nYour LLMs API keys, login credentials, or passwords should never appear as plain text in your init file.\nSome packages provide mechanisms for safe storing or logging. Others don‚Äôt. In that case, there are multiple options. My favourites are based on auth-source and GPG.\n\nauthinfo.gpg\nCreate a ~/.authinfo.gpg file with your keys in the format:\nmachine &lt;hostname&gt; login &lt;username&gt; password &lt;password&gt;\nIf you need a function to retrieve your key, use:\n(lambda ()\n  (auth-source-pick-first-password\n    :host \"&lt;hostname&gt;\"\n    :user \"&lt;username&gt;\"))\nIf you need a string, simply use:\n(auth-source-pick-first-password\n  :host \"&lt;hostname&gt;\"\n  :user \"&lt;username&gt;\")\n\n\npass\nUse the standard Unix password manager to store your API key by running in a Unix shell:\npass insert &lt;key-name&gt;\n# enter your API key twice when prompted\nFunction:\n(lambda ()\n  (auth-source-pass-get 'secret \"&lt;key-name&gt;\"))\nString:\n(auth-source-pass-get 'secret \"&lt;key-name&gt;\")",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "AI pair programming in Emacs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_llms_content.html#copilot.el",
    "href": "emacs/wb_llms_content.html#copilot.el",
    "title": "AI pair programming & LLMs chats in Emacs",
    "section": "copilot.el",
    "text": "copilot.el\nGitHub copilot code completion (built on top of the GitHub copilot-language-server).\n\nRequirements\n\nAccess to GitHub copilot\n\n\nFree tier available to everybody\nPro available free for students, teachers, maintainers of popular open-source projects\nPaid subscriptions for Pro and Pro+\n\n\nEmacs ‚â• 27\nNode.js ‚â• 22\n\n\n\nInstallation\n\nInstall and load the package and dependency with your favourite method.\nInstall the copilot server with M-x copilot-install-server.\nLogin to Copilot with M-x copilot-login and follow the instructions.\n\n\nYou can test the setup with M-x copilot-diagnose.\n\n\n\nMy setup (see warning)\n;; dependency\n(straight-use-package 'editorconfig)\n\n(use-package copilot\n    :straight (:host github\n               :repo \"copilot-emacs/copilot.el\"\n               :files (\"dist\" \"*.el\"))\n    :bind ((\"C-8\" . copilot-complete)\n           (\"; j c\" . copilot-mode)\n           :map copilot-completion-map\n           (\"C-j\" . copilot-accept-completion)\n           (\"C-f\" . copilot-accept-completion-by-word)\n           (\"C-t\" . copilot-accept-completion-by-line)\n           (\"M-n\" . copilot-next-completion)\n           (\"M-p\" . copilot-previous-completion)))",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "AI pair programming in Emacs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_llms_content.html#copilot-chat.el",
    "href": "emacs/wb_llms_content.html#copilot-chat.el",
    "title": "AI pair programming & LLMs chats in Emacs",
    "section": "copilot-chat.el",
    "text": "copilot-chat.el\nGitHub copilot chat\n\nRequirements\nAccess to GitHub copilot.\n\n\nFunctionality\nChat with a model.\n\nMarkdown or Org markup\nChats can be saved and restored\nBuffers can be added or removed as context\nCan choose model\n\nAI pair programming.\n\nWrite tests\nExplain code/function at point/symbol at point\nReview code\nDocument code\nFix code\nOptimize code\nModify code\nCustomize prompts\n\nGenerate commit messages.\n\n\nMy setup (see warning)\n;; dependency\n(straight-use-package 'magit)\n\n(use-package copilot-chat\n  :straight (:host github:repo \"chep/copilot-chat.el\" :files (\"*.el\"))\n  :after (org markdown-mode)\n  :bind ((\"; c c\" . copilot-chat)\n         (\"; c y\" . copilot-chat-yank)\n         (\"; c m\" . copilot-chat-set-model)\n         :map prog-mode-map\n         ;; explain symbol under point\n         (\"; c e s\" . copilot-chat-explain-symbol-at-line)\n         ;; explain function under point\n         (\"; c e f\" . copilot-chat-explain-defun)\n         ;; explain selected code\n         (\"; c e c\" . copilot-chat-explain)\n         ;; review selected code\n         (\"; c r c\" . copilot-chat-review)\n         ;; review current buffer\n         (\"; c r b\" . copilot-chat-review-whole-buffer)\n         ;; document selected code\n         (\"; c d\" . copilot-chat-doc)\n         ;; fix selected code\n         (\"; c f c\" . copilot-chat-fix)\n         ;; optimize selected code\n         (\"; c o\" . copilot-chat-optimize)\n         ;; write tests for selected code\n         (\"; c t\" . copilot-chat-test)\n         ;; apply a custom prompt to the function body under point\n         ;; (instruct on how to refactor the function)\n         (\"; c f f\" . copilot-chat-custom-prompt-function)\n         :map copilot-chat-org-prompt-mode-map\n         (\"C-&lt;return&gt;\" . copilot-chat-prompt-send)\n         :map org-mode-map\n         (\"; c g\" . copilot-chat-prompt-split-and-list)))",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "AI pair programming in Emacs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_llms_content.html#gptel",
    "href": "emacs/wb_llms_content.html#gptel",
    "title": "AI pair programming & LLMs chats in Emacs",
    "section": "gptel",
    "text": "gptel\nAccess LLMs from any buffer.\n\nRequirements\nAPI key(s) for model(s), GitHub copilot, or model(s) running locally.\n\n\nFunctionality\nChat in dedicated buffer or from any buffer.\n\nMarkdown or Org markup\nChoose model\nAdd/remove context (including media)\nSet temperature\n\nA number of packages are built on top of gptel\n\n\nMy setup (see warning)\n(use-package gptel\n  :config\n  (setq\n   gptel-model 'gemini-2.5-pro\n   gptel-backend (gptel-make-gemini \"Gemini\"\n                   :key #'gptel-api-key-from-auth-source\n                   :stream t))\n  :bind ((\"; g g\" . gptel)\n         (\"; g s\" . gptel-send)\n         (\"; g m\" . gptel-menu)))",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "AI pair programming in Emacs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_llms_content.html#mcp.el",
    "href": "emacs/wb_llms_content.html#mcp.el",
    "title": "AI pair programming & LLMs chats in Emacs",
    "section": "mcp.el",
    "text": "mcp.el\nEmacs client for MCP.\n\nFunctionality\nmcp.el integrates easily with gptel and copilot-chat.el.\nThe LLMs you use can then access any MCP server you setup.\n\n\nMy setup (see warning)\n\nI use the Context7 MCP server.\n\n(use-package mcp\n  :after (:any gptel copilot-chat)\n  :custom (mcp-hub-servers\n           `((\"context7\" . (:command \"npx\"\n                :args (\"-y\" \"@upstash/context7-mcp@latest\" \"--api-key\" ,(auth-source-pick-first-password\n                                                                         :host \"context7_api_key\"\n                                                                         :user \"secret\"))))))\n  :config (require 'mcp-hub)\n  :hook (after-init . mcp-hub-start-all-server))\n\n\nIntegration with gptel\nTo have gptel integrate with mcp.el and automatically use the servers you have set, add to the gptel :config declaration:\n(require 'gptel-integrations) ; always needed\n(gptel-mcp-connect)           ; to connect automatically\n\nAlternatively, you can call gptel-mcp-connect and gptel-mcp-disconnect to enable/disable servers manually.\n\n\n\nIntegration with copilot-chat.el\nUse copilot-chat-set-mcp-servers to enable or disable servers.",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "AI pair programming in Emacs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_llms_content.html#chatgpt-shell",
    "href": "emacs/wb_llms_content.html#chatgpt-shell",
    "title": "AI pair programming & LLMs chats in Emacs",
    "section": "chatgpt-shell",
    "text": "chatgpt-shell\nA shell to access LLMs.\n\nRequirements\nAPI key(s) for model(s) or local model(s).\n\n\nFunctionality\nChat in an Emacs shell.\n\nChoose and swap models\nDescribe code\nProofread text\nWrite commits messages\nSave/restore transcripts\n\n\n\nMy setup (see warning)\n;; dependency\n(use-package shell-maker\n  :straight (:type git :host github :repo \"xenodium/shell-maker\"))\n\n(use-package chatgpt-shell\n  :straight (:type git :host github\n             :repo \"xenodium/chatgpt-shell\"\n             :files (\"chatgpt-shell*.el\"))\n  :init\n  (setq chatgpt-shell-google-key\n    (lambda ()\n      (auth-source-pick-first-password\n       :host \"google_api_key\" :user \"secret\")))\n  :bind (\"; c s\" . chatgpt-shell))",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "AI pair programming in Emacs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_llms_content.html#aidermacs",
    "href": "emacs/wb_llms_content.html#aidermacs",
    "title": "AI pair programming & LLMs chats in Emacs",
    "section": "aidermacs",
    "text": "aidermacs\naider in Emacs (forget about Cursor).\n\nRequirements\n\nAPI key(s) for model(s) or local model(s)\nEmacs ‚â• 26.1\naider\ntransient\n\n\n\nFunctionality\n\nEdiff of AI-generated changes\nCustom prompts\nCode/chat/help/architect modes\nIntegrates with vterm\nAuto-detects project root\nVoice commands\nRetrieves web content\nWrites tests\nDebugs code\nWeak model for fast easy tasks\nTRAMP support\nEasy passing of aider options\n\n\n\nMy setup (see warning)\n(use-package aidermacs\n  :bind ((\"; c a\" . aidermacs-transient-menu))\n  :config\n  (setenv \"GOOGLE_API_KEY\" (auth-source-pick-first-password\n                :host \"google_api_key\"\n                :user \"secret\"))\n  :custom\n  (aidermacs-default-chat-mode 'architect)\n  (aidermacs-default-model \"gemini\"))\n\n\nAlternative: aider.el\naider.el is the initial project aidermacs was forked from.\n\naider.el is closer to aider (the original CLI tool).\naidermacs integrates more into Emacs.",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "AI pair programming in Emacs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_ide_slides.html#helm",
    "href": "emacs/wb_ide_slides.html#helm",
    "title": "Emacs as a programming IDE",
    "section": "Helm",
    "text": "Helm\nSearching in buffer\n\nNavigating open buffers and recent files\n\n\nNavigating file sections\n\n\nSelecting from kill ring\n\n\nMoving in mark ring\n\n\nLooking at active modes"
  },
  {
    "objectID": "emacs/wb_ide_slides.html#completion",
    "href": "emacs/wb_ide_slides.html#completion",
    "title": "Emacs as a programming IDE",
    "section": "Completion",
    "text": "Completion\ncompany-mode\n\nyasnippet\n\n\nDynamic abbrev expansion"
  },
  {
    "objectID": "emacs/wb_ide_slides.html#undoingredoing-with-undo-tree",
    "href": "emacs/wb_ide_slides.html#undoingredoing-with-undo-tree",
    "title": "Emacs as a programming IDE",
    "section": "Undoing/redoing with undo-tree",
    "text": "Undoing/redoing with undo-tree"
  },
  {
    "objectID": "emacs/wb_ide.html",
    "href": "emacs/wb_ide.html",
    "title": "Emacs as a programming IDE",
    "section": "",
    "text": "Once upon a time (not that long ago), powerful text editors such as Vim and Emacs were the only nice interfaces to work with code. Nowadays, there are countless sleek and more GUI-oriented tools such as VS Code, RStudio, or JupyterLab that provide amazing IDEs, without the learning curve.\nSo why would one still use Emacs as a programming IDE?\nWhat does that even look like?\nIn this webinar, I will show some of the many reasons why I can‚Äôt let go of Emacs, then show how it can be used as a programming IDE for Python, R, and Julia.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "Emacs as a programming IDE"
    ]
  },
  {
    "objectID": "emacs/top_intro.html",
    "href": "emacs/top_intro.html",
    "title": "Getting started with Emacs",
    "section": "",
    "text": "Emacs is more than ever a very powerful text editor with many exciting new developments.\nThis course will show you what makes Emacs such a fantastic tool and get you started in a smooth and gentle way. You will learn the basic concepts of Emacs, how to customize it, how to manage packages efficiently, and how to use it remotely.\n\n Start course ‚û§",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>"
    ]
  },
  {
    "objectID": "emacs/intro_undo.html",
    "href": "emacs/intro_undo.html",
    "title": "Undoing and redoing",
    "section": "",
    "text": "Undoing and redoing are operations so common while editing files that we don‚Äôt think about them much. Most software however have a poor undo/redo system in which edits get lost all the time.\nEmacs‚Äô undos never loses edits and undo-tree brings a wonderful undo/redo system to it.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Undoing and redoing"
    ]
  },
  {
    "objectID": "emacs/intro_undo.html#undo-systems",
    "href": "emacs/intro_undo.html#undo-systems",
    "title": "Undoing and redoing",
    "section": "Undo systems",
    "text": "Undo systems\n\nLinear systems: classic undo/redo\n\nYou have some file:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nYou make some edit:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \"))---2((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nYou make another edit:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nAnd another one:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \"))---4((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nYou can undo:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \")):::current---4((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nYou can undo some more:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \"))---2((\" \")):::current---3((\" \"))---4((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nYou can also redo:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \")):::current---4((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nNow, you make some new edit. From this point on, some edits are lost:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \"))-.-4((\" \")):::lost\n   3((\" \"))---5((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px\n   classDef lost stroke-dasharray: 3 4\n\n\n\n\n\n\n\nYou can still undo:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \")):::current-.-4((\" \")):::lost\n   3((\" \"))---5((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px\n   classDef lost stroke-dasharray: 3 4\n\n\n\n\n\n\n\nAnd you can redo your last undo, but you can‚Äôt access all previous states of the file:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \"))-.-4((\" \")):::lost\n   3((\" \"))---5((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px\n   classDef lost stroke-dasharray: 3 4\n\n\n\n\n\n\n\n\nLinear systems: Emacs\n\nYou have some file:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((1)):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nYou make some edit:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((1))---2((2)):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nYou make another edit:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((1))---2((2))---3((3)):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nAnd another one:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((1))---2((2))---3((3))---4((4)):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nThe first undo adds a new point to the chain of edits, reversing the effects of the last edit:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((1))---2((2))---3((3))---4((4))---5((3)):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nMore undoing keeps adding points to the chain:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((1))---2((2))---3((3))---4((4))---5((3))---6((2)):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nThere is no proper redo. Instead, you stop undoing, then start again to undo the undo:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((1))---2((2))---3((3))---4((4))---5((3))---6((2))---7((3)):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nYou can make new edits\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((1))---2((2))---3((3))---4((4))---5((3))---6((2))---7((3))---8((5)):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nNothing ever gets lost, but you might get headaches. For instance, to go back to the beginning, you have to do:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((1))---2((2))---3((3))---4((4))---5((3))---6((2))---7((3))---8((5))---9((3))---10((2))---11((3))---12((4))---13((3))---14((2))---15((1)):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\n\nNon linear system: undo-tree\n\nYou have some file:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nYou make some edit:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \"))---2((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nYou make another edit:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nAnd another one:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \"))---4((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nYou can undo:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \")):::current---4((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nYou can undo some more:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \"))---2((\" \")):::current---3((\" \"))---4((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nYou can also redo:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \")):::current---4((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nNow, you make some new edit:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \"))---4((\" \"))\n   3((\" \"))---5((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nYou can still undo:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \"))---4((\" \"))\n   3((\" \")):::current---5((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nYou can switch branch and redo the old version:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \"))---4((\" \")):::current\n   3((\" \"))---5((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nNothing ever gets lost and it is a lot more sane to navigate the history.\n\n\nTo to back to the beginning, you only have to do:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((\" \")):::current---2((\" \"))---3((\" \"))---4((\" \"))\n   3((\" \"))---5((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nCompare this with the insane Emacs default system:\n\n\n\n\n\n\n%%{init: { 'flowchart': {'rankSpacing':20} } }%%\n\nflowchart TD\n   1((1))---2((2))---3((3))---4((4))---5((3))---6((2))---7((3))---8((5))---9((3))---10((2))---11((3))---12((4))---13((3))---14((2))---15((1)):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\nAnd this is an exceedingly simple example only involving 5 different file states. I let you imagine how it quickly explodes in complexity in real life situations üôÇ\nNow, the default Emacs system has the huge benefit to never lose any edit. It is already a huge improvement over the default system on most software! The thing is that when we undo and redo changes, linear systems are not ideal. A tree structure that can be fully navigated is just a more sensible solution.\n\nUndo-tree was initially developed for Vim, so Vim can also use an ideal undo/redo system.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Undoing and redoing"
    ]
  },
  {
    "objectID": "emacs/intro_undo.html#installing-and-customizing-undo-tree",
    "href": "emacs/intro_undo.html#installing-and-customizing-undo-tree",
    "title": "Undoing and redoing",
    "section": "Installing and customizing undo-tree",
    "text": "Installing and customizing undo-tree\nThis is a personal affair.\nThe minimal configuration when using straight (to download the package) and use-package to load it and customize it, looks like this:\n(use-package undo-tree\n  :straight t)\nMy personal configuration looks like this:\n(use-package undo-tree\n    :straight t\n    :init\n    (global-undo-tree-mode 1)\n    :bind ((\"C-l\" . undo-tree-undo)\n           (\"C-r\" . undo-tree-redo)\n           (\"s-t\" . undo-tree-visualize)\n           :map undo-tree-visualizer-mode-map\n           ;; go to selected undo state\n           (\"&lt;return&gt;\" . undo-tree-visualizer-quit)\n           ;; cancel (return to state before calling undo-tree-visualize)\n           (\"q\" . undo-tree-visualizer-abort)))",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Undoing and redoing"
    ]
  },
  {
    "objectID": "emacs/intro_shells.html",
    "href": "emacs/intro_shells.html",
    "title": "Other functionalities",
    "section": "",
    "text": "In the previous section, we saw that, besides text editing, Emacs can be used as a file manager. In this section, we will see that Emacs can be used for many other tasks.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Other functionalities"
    ]
  },
  {
    "objectID": "emacs/intro_shells.html#calendar",
    "href": "emacs/intro_shells.html#calendar",
    "title": "Other functionalities",
    "section": "Calendar",
    "text": "Calendar\nM-x calendar opens a little calendar that can be navigated and to which events can be added.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Other functionalities"
    ]
  },
  {
    "objectID": "emacs/intro_shells.html#calculator",
    "href": "emacs/intro_shells.html#calculator",
    "title": "Other functionalities",
    "section": "Calculator",
    "text": "Calculator\nM-x calculator launches well ‚Ä¶ a calculator.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Other functionalities"
    ]
  },
  {
    "objectID": "emacs/intro_shells.html#man-pages",
    "href": "emacs/intro_shells.html#man-pages",
    "title": "Other functionalities",
    "section": "Man pages",
    "text": "Man pages\nMan pages can be open in Emacs with M-x man.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Other functionalities"
    ]
  },
  {
    "objectID": "emacs/intro_shells.html#running-processes",
    "href": "emacs/intro_shells.html#running-processes",
    "title": "Other functionalities",
    "section": "Running processes",
    "text": "Running processes\nEmacs can run processes in what are called inferior modes.\n\nScripting shells and terminals\nEmacs can talk to external shells installed on your system (e.g.¬†Bash, Zsh) or play the role of a terminal emulator.\n\nTerminal emulators\nIf you want to run a terminal emulator directly in Emacs, you can use the pre-installed term (M-x term) or the similar ansi-term (M-x ansi-term).\nThe package multi-term allows to run multiple terminal buffers at the same time (similar to terminal multiplexers such as tmux).\nFor a better terminal emulator, you can install vterm.\n\n\nShells\nAny scripting shell installed on your system can be run directly in Emacs with M-x shell (it‚Äôll use your default shell if you don‚Äôt customize it). The documentation will give you the list of kbds.\nOr you can run Emacs‚Äô own shell Eshell with M-x eshell.\nEshell doesn‚Äôt talk to Bash or Zsh. It is its own shell, written entirely in Emacs Lisp. Consequently, it‚Äôll provide you a Bash-like scripting shell on Windows.\nIt can also accept commands in Elisp (even mixed in with classic shell commands).\nFor more information on Eshell, you can read this excellent demo (also available as a lightning talk) or this article of Mastering Emacs.\nIf you want to run a single shell command, you can use the minibuffer with M-x shell-command or M-!.\n\n\n\nREPL and interpreter shells\nProgramming shells such as Python, R, Julia‚Ä¶ can also be run in Emacs. Some come out of the box, while others require specific packages to be installed.\nPython runs in Emacs out of the box: M-x run-python.\nYou can also use Emacs as a fully-fledged IDE for programming languages. See our webinar for use with R, Julia, and Python. Later in this course, we will try it with R.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Other functionalities"
    ]
  },
  {
    "objectID": "emacs/intro_resources.html",
    "href": "emacs/intro_resources.html",
    "title": "Resources",
    "section": "",
    "text": "Here is a list of resources to get started with Emacs.\n\n\nInternal documentation\nYou can access Emacs internal documentation with the following kbds:\n\nC-h r: Emacs manual\nC-h t: Emacs tutorial\nC-h i: Emacs info directory\nC-h k: info on kbd\nC-h f: info on function (command)\nC-h v: info on variable\nC-h a: info on command matching regexp\n\n\n\nOfficial documentation\n\nGNU Emacs website\nGuided tour of Emacs\nGNU Emacs manual\nManuals for specific features\nEmacs wiki\n\n\n\nQ&A\n\nStack Overflow [emacs] tag\nEmacs Stack Exchange\n\n\n\nGNU Emacs Lisp\n\nOfficial Reference manual",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Resources"
    ]
  },
  {
    "objectID": "emacs/intro_packages.html",
    "href": "emacs/intro_packages.html",
    "title": "Packages",
    "section": "",
    "text": "Emacs is a huge and endlessly customizable toolkit out of the box. In addition, countless external packages have been (and continue to be) developed to add yet more functionality. This section will cover the basics of package installation and customization.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Packages"
    ]
  },
  {
    "objectID": "emacs/intro_packages.html#package-manager",
    "href": "emacs/intro_packages.html#package-manager",
    "title": "Packages",
    "section": "Package manager",
    "text": "Package manager\nThere are multiple ways to manage external Emacs packages. package.el is the built-in package manager. Several packages provide alternative package management systems. My favourite by far is straight. It allows to install packages from anywhere (MELPA, ELPA, Emacsmirror, local server, GitLab, GitHub‚Ä¶). Packages are cloned as Git repos instead of tarballs, making it easy to revert to an old version, edit, etc. Packages are also compiled natively for better efficiency.\nTo install straight, you need to put the following in your init file:\n;; Install straight\n(defvar bootstrap-version)\n(let ((bootstrap-file\n       (expand-file-name \"straight/repos/straight.el/bootstrap.el\" user-emacs-directory))\n      (bootstrap-version 6))\n  (unless (file-exists-p bootstrap-file)\n    (with-current-buffer\n        (url-retrieve-synchronously\n         \"https://raw.githubusercontent.com/radian-software/straight.el/develop/install.el\"\n         'silent 'inhibit-cookies)\n      (goto-char (point-max))\n      (eval-print-last-sexp)))\n  (load bootstrap-file nil 'nomessage))\nThen you need to evaluate this code. For this, you can close and re-open Emacs. Alternatively, you can select the paragraph and run M-x eval-region.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Packages"
    ]
  },
  {
    "objectID": "emacs/intro_packages.html#package-location",
    "href": "emacs/intro_packages.html#package-location",
    "title": "Packages",
    "section": "Package location",
    "text": "Package location\nExcept for the init file which, by default, lives directly in your home directory, all Emacs configuration files get created in a directory called .emacs.d located in your home directory. This is where Emacs will store your installed packages.\nIf you use straight to manage your packages, a straight directory will be created in ~/.emacs.d and in it, you will see two subdirectories:\n\nrepos which holds the cloned Git repos of the packages and\nbuild which holds the built packages.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Packages"
    ]
  },
  {
    "objectID": "emacs/intro_packages.html#package-loading-and-configuration",
    "href": "emacs/intro_packages.html#package-loading-and-configuration",
    "title": "Packages",
    "section": "Package loading and configuration",
    "text": "Package loading and configuration\nUse-package is a modern package that allows lazy loading of packages for a speedy startup and a neat way to configure Emacs package by package.\nDue to the huge popularity of this package, starting with Emacs 29, use-package ships with Emacs and doesn‚Äôt need to be installed. Prior to Emacs 29, it can be installed (using straight) with:\n;; Install use-package (unnecessary for Emacs &gt;= 29)\n(straight-use-package 'use-package)",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Packages"
    ]
  },
  {
    "objectID": "emacs/intro_packages.html#installing-packages",
    "href": "emacs/intro_packages.html#installing-packages",
    "title": "Packages",
    "section": "Installing packages",
    "text": "Installing packages\nWhen you install a new package, the best thing to do is to read the README carefully and start with minimal configuration. A growing number of packages will give you configuration instructions using use-package.\nWith usage, you can add more configurations, either in your use-package declaration or using the easy customization interface.\n\nExample: ESS package\nFirst, let‚Äôs create a file called test.R with the following R code in it:\na &lt;- c(1, 2, 3)\n\nb &lt;- 5L\n\n\nYour turn:\n\n\nWhat is the major mode used by Emacs?\n\nWhy do you think that is?\n\n\nTo get the proper major mode which will give us syntax highlighting and indentation for R, as well as a lot of additional functionality, we need to install the package ESS (Emacs Speaks Statistics).\nTo install it using straight, you can put the following in your init file:\n(straight-use-package 'ess)\nOr you can use the perfectly equivalent expression:\n(use-package ess\n    :straight t)\nThe advantage of this second syntax is that you can now add any customization you want to the use-package declaration.\n\n\nYour turn:\n\nAfter evaluating this snippet of code in your init file, re-open test.R.\n- What is the major mode now?\n- Notice that we now also have syntax highlighting for R.\n\nNow that we have a proper mode for R, we can even use Emacs as an IDE.\nFirst, of course, we will need to have R available. Send Emacs to the background with C-z and load the R module:\nmodule load r/4.3.1\nThen bring the test.R file back to the foreground by typing fg and Enter in the terminal.\nNow, you can use the kbd C-c C-c, bound to ess-eval-region-or-function-or-paragraph-and-step, to send sections of code from the script to a buffer containing a running R console.\nIf you want to have two windows, one with your script on the left and one with your running R process on the right, you need to split windows, select the proper buffers to display in each window, and move the cursor to the script. This is easy to do, but a bit annoying to have to do each time you want to run R from script.\nInstead, you could save a keyboard macro with all these commands and set a kbd for it. Or you can define a function doing all this and set a kbd. Let‚Äôs do it as an example of configuration using use-package:\n(use-package ess-r-mode\n    :straight (ess)\n    :config\n    (defun my-start-r ()\n      (interactive)\n      (split-window-right)\n      (R)\n      (other-window 1))\n    :bind (:map ess-r-mode-map\n                ;; start R process from script\n                (\"C-c r\" . my-start-r)))\n\nNote that we had to edit our use-package declaration a little because ESS provides modes for both R and Julia. This is a weird case. Usually, you don‚Äôt have to make any such change when you add configuration to the use-package declaration.\n\nAfter evaluating this declaration, you can now launch an R process from any R script, in a window to the right, with the kbd C-c r (after which you can evaluate your R script chunk by chunk with C-c C-c).",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Packages"
    ]
  },
  {
    "objectID": "emacs/intro_kbd.html",
    "href": "emacs/intro_kbd.html",
    "title": "Emacs keybindings",
    "section": "",
    "text": "In this section, we will explore the endlessly humoristic topic of Emacs keybindings.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Key bindings"
    ]
  },
  {
    "objectID": "emacs/intro_kbd.html#on-emacs-keybindings",
    "href": "emacs/intro_kbd.html#on-emacs-keybindings",
    "title": "Emacs keybindings",
    "section": "On Emacs keybindings",
    "text": "On Emacs keybindings\nOne of the strengths and weaknesses of Emacs are its keybindings (kbd). Strength because everything can be bound to a kbd and kbd are‚Äîas everything else in Emacs‚Äîfully customizable. This means that you can make Emacs truly your own and work on text very quickly from the keyboard. Weakness because the default kbds are overwhelming to new users and the gymnastics they involve has lead to a lot of jokes.\n\n\n\nFrom Ecol LG #134 by Javier Malonda.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Key bindings"
    ]
  },
  {
    "objectID": "emacs/intro_kbd.html#kbd-notations",
    "href": "emacs/intro_kbd.html#kbd-notations",
    "title": "Emacs keybindings",
    "section": "Kbd notations",
    "text": "Kbd notations\nFirst of all, a note about notations:\n\nC-c means press the Control key and the C key together,\nM-x means press the Alt (Windows) or Option (macOS) key and the X key together,\nC-c m means press the Control key and the C key together, then press the M key,\nC-c C-x m means press Ctl+C, then Ctl+X, then M,\nDEL means press the Backspace key,\nSPC means press the Space bar,\nS-SPC means press Shift and the Space bar together,\nESC means press the Escape key,\ns-t means press the Window key (Windows) or Command key (macOS) and the T key together,\nC-x C-c M-w C-m M-v M-t M-u means that you probably should choose another kbd.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Key bindings"
    ]
  },
  {
    "objectID": "emacs/intro_kbd.html#main-kbds",
    "href": "emacs/intro_kbd.html#main-kbds",
    "title": "Emacs keybindings",
    "section": "Main kbds",
    "text": "Main kbds\nFor the rest of this course, you should have this page open in a separate tab (or even monitor if you can) as the reference you will need to look at constantly as we work in Emacs. Within a few days though, you will know these and they will become second nature‚Äîso much so that you will start truly missing them when you work outside Emacs!\nMost important\n\nC-g         Cancel beginning of command\nC-x C-c     Save file and exit Emacs\nC-z         Send Emacs to the background to get back to the terminal\n            The Emacs window can be brought back from the terminal with: fg (foreground)\nESC ESC ESC Get out command (exit minibuffer, close other windows, etc.)\n\nBuffers\n\nC-x b       Switch buffer\nC-x C-b     List buffers\nC-x k       Kill buffer\n\nWindows\n\nC-x 1       Delete other windows\nC-x 2       Split window below\nC-x 3       Split window right\nC-x o       Jump to other window\nC-M-v       Scroll other window\n\nFiles\n\nC-x C-f     Find file\nC-x C-s     Save file\n\nNavigation\n\nC-f         Move forward one character\nC-b         Move backward one character\n\nC-p         Move to previous line\nC-n         Move to next line\n\nC-a         Move to beginning of line\nC-e         Move to end of line\n\nM-a         Move to beginning of sentence\nM-e         Move to end of sentence\n\nM-f         Move forward one word\nM-b         Move backward one word\n\nC-v         Move forward one screenful\nM-v         Move backward one screenful\n\nC-l         Center text around cursor\n\nM-&lt;         Move to beginning of buffer\nM-&gt;         Move to end of buffer\n\nC-u         Universal argument:\nC-u 3 C-f   Move forward three characters\nC-u -4 C-f  Move backward four characters\nC-u 5 M-e   Move forward five sentences\nC-u 6 t     Type six characters t\n\nEditing\n\nDEL         Delete character before cursor\nC-d         Delete character after cursor\n\nM-DEL       Kill word before cursor\nM-d         Kill word after cursor\n\nC-k         Kill to end of line\nM-k         Kill to end of sentence\n\nC-SPC       Set mark to select region\nC-x h       Select all\n\nC-w         Kill region (cut)\nM-w         Copy region\nC-y         Yank killed text (paste)\nM-y         Following C-y: go back in kill ring to yank\n\nC-/         Undo (to redo, use C-g followed by another C-/)\n\nSearching\n\nC-s         Increamental search forward (repeat for next occurance)\nC-r         Incremental search backward (repeat for previous occurance)\nM-n         While in search: go forward in search history\nM-p         While in search: go backward in search history\n\nEmacs was so influential in the early days of computing that many other software actually use Emacs kbds. This is the case for instance of all shells, REPLs, terminals, and consoles.\nNext time you are in Bash, or in your Python/Julia/R shell, try the commands above and you will see that many of them will work.\n\nAll of these kbds are of course customizable.\nThis list is not exhaustive. You can also associate a new kbd to any command.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Key bindings"
    ]
  },
  {
    "objectID": "emacs/intro_kbd.html#emacs-pinky",
    "href": "emacs/intro_kbd.html#emacs-pinky",
    "title": "Emacs keybindings",
    "section": "Emacs pinky",
    "text": "Emacs pinky\nBecause so many Emacs kbds involve the Control key, it can be very tiresome for the pinky finger. Most Emacs users remap their keyboard to have the Caps lock key into another Control key. This page gives information on how to do this with most operating systems.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Key bindings"
    ]
  },
  {
    "objectID": "emacs/intro_kbd.html#practice",
    "href": "emacs/intro_kbd.html#practice",
    "title": "Emacs keybindings",
    "section": "Practice",
    "text": "Practice\nLet‚Äôs practice those common kbds thanks to the Emacs tutorial: launch Emacs, navigate to the link ‚ÄúEmacs tutorial‚Äù (use C-n four times for that), and press Enter. This will open a buffer with the Emacs tutorial. The tutorial covers the kbds above and provides an opportunity to play with an Emacs text.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Key bindings"
    ]
  },
  {
    "objectID": "emacs/intro_kbd.html#executing-commands-without-kbds",
    "href": "emacs/intro_kbd.html#executing-commands-without-kbds",
    "title": "Emacs keybindings",
    "section": "Executing commands without kbds",
    "text": "Executing commands without kbds\nAnother way to execute commands interactively is to type M-x (this brings up the minibuffer, a place in which to type inputs) followed by the command name. This is useful if a command is not bound to a kbd or if you don‚Äôt remember its kbd.\n\nFor example, M-x count-words will output the number of lines, sentences, words, and characters of the current buffer in the echo area.\n\n\nCommands are series of words separated by hyphens (-), but you can type spaces instead: Emacs will add the hyphens automatically for you.\nAfter you have entered M-x, you can use the tab key for autocompletion and you can use the kbds M-p and M-n to go back and forth in the command history.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Key bindings"
    ]
  },
  {
    "objectID": "emacs/intro_dired.html",
    "href": "emacs/intro_dired.html",
    "title": "Directory editor",
    "section": "",
    "text": "Once you are used to the Emacs environment and you have made it your own with customizations, it can be very comfortable to work in it. For this reason, many people do much more than text editing in Emacs. One of its strengths is actually that it can replace many other tools, letting you do most of your work with the same kbds and habits.\nAmong many other things, Emacs is is a powerful file manager.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Directory editor"
    ]
  },
  {
    "objectID": "emacs/intro_dired.html#what-is-dired",
    "href": "emacs/intro_dired.html#what-is-dired",
    "title": "Directory editor",
    "section": "What is Dired?",
    "text": "What is Dired?\nDired (directory editor) can be launched with M-x dired or C-x d and choosing the directory to open in the Dired buffer. You can also use wildcards to select a subset of files matching some pattern.\nYou can quit Dired with the usual C-x k, but also simply with q.\nMuch can be done with it and we won‚Äôt have time to cover it all, but if you want to learn more, you can go over the Dired manual. You will see that you can really do a lot in Dired and configure the ls flags launched by default. The sections below only cover a subset of commands.\nLet‚Äôs launch Dired.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Directory editor"
    ]
  },
  {
    "objectID": "emacs/intro_dired.html#navigation",
    "href": "emacs/intro_dired.html#navigation",
    "title": "Directory editor",
    "section": "Navigation",
    "text": "Navigation\nTo up or down a line in the Dired buffer, you can use the classic C-n and C-p, but you can also simply use n or SPC and p.\nYou can jump to a file with j followed by the file name.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Directory editor"
    ]
  },
  {
    "objectID": "emacs/intro_dired.html#opening-files",
    "href": "emacs/intro_dired.html#opening-files",
    "title": "Directory editor",
    "section": "Opening files",
    "text": "Opening files\nFiles can be opened with f or RET (the Enter key), they can be opened in another window with o, opened in another window but without jumping to it with C-o, or they can simply be viewed with v.\n‚ÄúViewing a file‚Äù means that the minor mode View Mode is enabled. The file cannot be edited, but it can be read quickly by scrolling up and down by entire screen-full with SPC and S-SPC or DEL. You can quit the file with q or turn off View Mode while keeping the position in the file with e.\n\n\nYour turn:\n\nNavigate to your .bashrc file and view it.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Directory editor"
    ]
  },
  {
    "objectID": "emacs/intro_dired.html#deleting-files",
    "href": "emacs/intro_dired.html#deleting-files",
    "title": "Directory editor",
    "section": "Deleting files",
    "text": "Deleting files\nd flags a file for deletion, u unflags it, and x deletes the files flagged for deletion.\n# deletes all auto-save files and ~ deletes all backup files (see section on Backup files).\n% d regexp RET flags for deletion files matching regexp.\n\nBe careful that deleting files this way is equivalent to running rm from the command line: files don‚Äôt go to a garbage bin, but are truly deleted.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Directory editor"
    ]
  },
  {
    "objectID": "emacs/intro_dired.html#other-operations",
    "href": "emacs/intro_dired.html#other-operations",
    "title": "Directory editor",
    "section": "Other operations",
    "text": "Other operations\nYou can mark several files with m (you will see a star * appear at the start of the line) and perform the operations below on all marked files at once. To remove all marks, press U. If no file is marked, these operations are performed on the current file (file where the cursor is).\nYou can copy files with C, delete them with D, rename them with R, create hard links with H or symlinks with S.\nYou can also change mode with M, change group with G, or change owner with O.\nYou can run touch (change the timestamp) with T or compress the file with Z.\nA will search files for a regexp and Q will replace regexp with whatever expression you provide.\nYou can also apply shell commands with !.\n% u turns names to upper case, % l to lower case, % R, % C, % H, and % S will rename, copy, create hard links and symlinks of selected files based on a regexp. This is extremely convenient to quickly renaming many files.\nFinally, you can compare files with = (this will run diff on both files).",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Directory editor"
    ]
  },
  {
    "objectID": "emacs/intro_dired.html#subdirectories",
    "href": "emacs/intro_dired.html#subdirectories",
    "title": "Directory editor",
    "section": "Subdirectories",
    "text": "Subdirectories\nThe content of subdirectories can be viewed in a section below with i. Sections can then be contracted or extended with $.\n\n\nYour turn:\n\nDisplay the content of the subdirectory projects.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Directory editor"
    ]
  },
  {
    "objectID": "emacs/intro_dired.html#editing-files",
    "href": "emacs/intro_dired.html#editing-files",
    "title": "Directory editor",
    "section": "Editing files",
    "text": "Editing files\nC-x C-q toggles Wdired mode‚Äîa mode in which you can directly edit file and directory names. Once you have edited what you wanted, save the changes with C-c C-c.\nTo edit permissions, you need to set the variable wdired-allow-to-change-permissions to 1 or 2. For this, run M-x customize variable wdired-allow-to-change-permissions, navigate to ‚ÄúValue Menu‚Äù, press Enter, type 1 or 2, press Enter, then navigate to ‚ÄúState‚Äù, press Enter, and save the change.\nYou can now edit the file permissions simply by typing r, w, or x directly in the WDired buffer.\n\n\nYour turn:\n\nChange the permission of the .bash_logout file to rw-rw----.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Directory editor"
    ]
  },
  {
    "objectID": "emacs/intro_completion.html",
    "href": "emacs/intro_completion.html",
    "title": "Selection and completion frameworks",
    "section": "",
    "text": "One of the reasons why I love working in Emacs is the ease to find and jump to files or specific locations in files. Whether it is reopening a recent document, jumping to a bookmark, hopping to a specific header, looking for an expression, it can all be done smoothly and with previews thanks to a powerful modern selection framework.\nAnother strength is the countless options to auto-complete text. The same modern framework can also be used here.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Completion frameworks"
    ]
  },
  {
    "objectID": "emacs/intro_completion.html#the-backends",
    "href": "emacs/intro_completion.html#the-backends",
    "title": "Selection and completion frameworks",
    "section": "The backends",
    "text": "The backends\nEmacs has a bookmark system, it can open files with M-x find-file, look for recently opened files with M-x recentf, search in a buffer with M-x isearch, switch to another open buffer with M-x switch-to-buffer, jump to previous positions in the mark ring, yank text from the kill ring, and countless other functionalities.\nUsing such functions directly works, but it doesn‚Äôt make for the best user experience. Accessing them via a frontend that expands the minibuffer, shows available options, narrows them down through incremental search, and offers previews is a huge improvement.\nMultiple such frontends, increasingly powerful and/or efficient, have been developed over time. All of them are still available.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Completion frameworks"
    ]
  },
  {
    "objectID": "emacs/intro_completion.html#a-history-of-completion-frameworks-in-emacs",
    "href": "emacs/intro_completion.html#a-history-of-completion-frameworks-in-emacs",
    "title": "Selection and completion frameworks",
    "section": "A history of completion frameworks in Emacs",
    "text": "A history of completion frameworks in Emacs\n\nIn the minibuffer\nA number of completions in Emacs happen in the minibuffer. Those are governed by the completing-read function.\nBy default, the minibuffer is a single line with no offer of available options. It is quite dry‚Ä¶ but many packages have improved it.\nFirst, came IDO (‚ÄúInteractively DO things‚Äù), part of Emacs. It expands the minibuffer and shows options to choose from.\n\n\n\nFrom Xah Emacs Blog\n\n\nThen, the IDO vertical package made the list of options in the minibuffer vertical, which is a big visual improvement.\n\n\n\nFrom oremacs\n\n\nHELM came and revolutionized the Emacs world. It became so popular that replacements for many basic Emacs functions got written to work with the HELM frontend.\nHELM doesn‚Äôt just expands the minibuffer, it turns it into a fully-fledged buffer for much improved functionality.\n\n\n\nFrom oracleyue\n\n\nBecause HELM is such a heavy duty tool, it tends to be slow. It also requires rewrites for all of the common function. Ivy came about to bring the snappiness of IDO back. Optional Counsel & Swiper make it nicer with function rewrites.\n\n\n\nFrom abo-abo/swiper\n\n\n\n\nIn the editing buffer\nIn-buffer completions, governed by completion-at-point are completions that happen in the buffer itself.\nBy default, the available options are displayed in a *Completions* buffer that is quite clunky to navigate. A number of packages have instead allowed them to happen in small pop-ups.\nFirst came auto-complete.\n\n\n\nFrom auto-complete\n\n\nThen came company-mode.\n\n\n\nFrom company-mode website",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Completion frameworks"
    ]
  },
  {
    "objectID": "emacs/intro_completion.html#a-modern-framework",
    "href": "emacs/intro_completion.html#a-modern-framework",
    "title": "Selection and completion frameworks",
    "section": "A modern framework",
    "text": "A modern framework\nIn recent years, a new set of packages came about which integrate closely Emacs internal functions. Lightweight, they are incredibly fast. Each package works on its own and you can pick and choose which functionality you want.\n\nList of packages\n\n\nMinibuffer\n\nvertico ‚ÄÉ‚ÄÉ¬†Frontend completion UI\norderless ‚ÄÉ¬†Backend completion style\nconsult ‚ÄÉ‚ÄÉBackend completion functions\nmarginalia ‚ÄÇ¬†Annotations\nembark ‚ÄÉ‚ÄÉActions on completion buffer\n\n\nIn-buffer\n\ncorfu ‚ÄÉ‚ÄÉ‚ÄÇFrontend completion UI\norderless ‚ÄÇ¬†Backend completion style\ncape ‚ÄÉ‚ÄÉ‚ÄÇBackend completion functions\n\n\n\nI will demo usage of these packages in class.\n\n\nConfiguration\nThese packages are extremely well documented and you will find in the READMEs all the information you need to install and configure them to your liking.\nAs an example, I am sharing here my own configurations (menus most kbds which rely on an exotic self-made system), including those for eglot‚ÄîEmacs client for Language Server Protocol servers, Abbrevs‚ÄîEmacs abbreviation system, yasnippet‚Äîa template system for Emacs, and copilot, an Emacs plug-in to GitHub Copilot.\nIt wouldn‚Äôt make much sense to copy-paste this to your init file blindly: instead, read careful the README of the various packages, decide which you want to use, and start with a minimal configuration based on the packages‚Äô authors suggestions.\n\n\n\n\n\n\nNoteExample\n\n\n\n\n\n;; completion utilities\n\n;; orderless\n;; backend completion matching style (regexp, flex, initialism...)\n(use-package orderless\n    :straight t\n    :custom\n    (completion-styles '(orderless basic))\n    (completion-category-overrides '((file (styles basic partial-completion))\n                                     (eglot (styles orderless)))))  ; use orderless with eglot\n\n;; embark\n(use-package embark\n    :straight t\n    :init\n    (setq prefix-help-command #'embark-prefix-help-command)\n    :config\n    (defun my-embark-bindings-global ()\n      (interactive)\n      (embark-bindings t))\n    ;; hide the mode line of the embark live/completions buffers\n    (add-to-list 'display-buffer-alist\n                 '(\"\\\\`\\\\*Embark Collect \\\\(Live\\\\|Completions\\\\)\\\\*\"\n                   nil\n                   (window-parameters (mode-line-format . none))))\n    (defun my-embark-kill (&optional arg)\n      (interactive \"P\")\n      (require 'embark)\n      (if-let ((targets (embark--targets)))\n          (let* ((target\n                  (or (nth\n                       (if (or (null arg) (minibufferp))\n                           0\n                           (mod (prefix-numeric-value arg) (length targets)))\n                       targets)))\n                 (type (plist-get target :type)))\n            (cond\n              ((eq type 'buffer)\n               (let ((embark-pre-action-hooks))\n                 (embark--act 'kill-buffer target)))))))\n    :bind ((\"&lt;f1&gt; b\" . my-embark-bindings-global)\n           :map minibuffer-local-map\n           (\"C-;\" . embark-dwim)\n           (\"C-SPC\" . embark-act-all)\n           (\"C-,\" . embark-act)\n           (\"M-k\" . my-embark-kill)))\n\n(use-package embark-consult\n  :hook\n  (embark-collect-mode . consult-preview-at-point-mode))\n\n;; marginalia\n(use-package marginalia\n    :straight t\n    :init\n    (marginalia-mode 1)\n    :bind (:map minibuffer-local-map\n                (\"M-a\" . marginalia-cycle)))\n\n;; minibuffer completion\n\n;; vertico\n;; frontend for completion in minibuffer\n(use-package vertico\n    :straight t\n    :init\n    (vertico-mode 1)\n    ;; config of display for each function\n    (vertico-multiform-mode 1)\n    :config\n    (setq vertico-multiform-commands\n          '((consult-line buffer)\n            (consult-line-thing-at-point buffer)\n            (consult-recent-file buffer)\n            (consult-mode-command buffer)\n            (consult-complex-command buffer)\n            (consult-locate buffer)\n            (consult-project-buffer buffer)\n            (consult-ripgrep buffer)\n            (consult-fd buffer)\n            (telega-msg-add-reaction buffer)))\n    (defun my-exit-keeping-point ()\n      (interactive)\n      (let ((location (with-minibuffer-selected-window (point-marker))))\n        (run-at-time 0 nil #'consult--jump location)\n        (exit-minibuffer)))\n    :bind (:map vertico-map\n                (\"C-k\" . kill-whole-line)\n                (\"C-u\" . kill-whole-line)\n                (\"C-o\" . vertico-next-group)\n                (\"&lt;tab&gt;\" . minibuffer-complete)\n                (\"M-&lt;return&gt;\" . minibuffer-force-complete-and-exit)\n                (\"C-&lt;return&gt;\" . my-exit-keeping-point)))\n\n;; save search history\n(use-package savehist\n    :init\n    (savehist-mode 1))\n\n;; consult\n;; backend completion functions\n(use-package consult\n    :straight t\n    ;; buffers, files, etc\n    :config\n    (defun my-get-major-mode-name ()\n      (interactive)\n      (message \"`%s'\" major-mode))\n    (defalias 'consult-line-thing-at-point 'consult-line)\n    (consult-customize\n     consult-line-thing-at-point\n     :initial (thing-at-point 'symbol)))\n    \n;; completion at point\n\n;; corfu\n(use-package corfu\n    :straight t\n    :init\n    (global-corfu-mode 1)\n    :bind (:map corfu-map\n                ;; Configure SPC for separator insertion\n                (\"SPC\" . corfu-insert-separator)\n                (\"&lt;tab&gt;\" . corfu-next)\n                (\"C-n\" . corfu-next)\n                (\"C-p\" . corfu-previous)))\n\n;; dabbrev\n(use-package dabbrev\n    :custom\n    (dabbrev-ignored-buffer-regexps '(\"\\\\.\\\\(?:pdf\\\\|jpe?g\\\\|png\\\\)\\\\'\"))\n    :bind ((\"&lt;tab&gt;\" . dabbrev-expand)\n           (\"; &lt;tab&gt;\" . dabbrev-completion)))\n\n;; cape\n(use-package cape\n    :straight t\n    :bind (\"C-'\" . completion-at-point))\n\n;; abbrev\n(use-package abbrev\n  :straight nil\n  :config\n  (setq-default abbrev-mode t)\n  :bind (\"C-c &lt;tab&gt;\" . add-global-abbrev))\n\n;; yasnippet\n(use-package yasnippet\n    :straight t\n    :init\n    (yas-global-mode 1)\n    :config\n    (setq yas-snippet-dirs '(\"~/.emacs.d/snippets\"))\n    :bind ((\"C-c y n\" . yas-new-snippet)         ; y=yas, n=new\n           (\"C-c y e\" . yas-visit-snippet-file)  ; y=yas, e=edit\n           (\"C-c y r\" . yas-reload-all)          ; y=yas, r=reload\n           ;; and rebind open-line (C-o)\n           (\"; C-o\" . open-line)\n           ;; when yas-minor-mode-map is active\n           :map yas-minor-mode-map\n           (\"&lt;tab&gt;\" . nil)\n           (\"C-o\" . yas-expand)\n           ;; during snippet completion\n           :map yas-keymap\n           (\"&lt;tab&gt;\" . nil)\n           (\"C-o\" . yas-next-field-or-maybe-expand)))\n\n;; yasnippet-capf\n(use-package yasnippet-capf\n    :straight t\n    :after cape)\n\n;; auto-yasnippet\n(use-package auto-yasnippet\n    :straight t\n    :bind (\"C-c y a\" . aya-create))\n\n;; eglot\n(straight-use-package 'eglot-jl)\n\n;; copilot\n;; copilot dependency\n(straight-use-package 'editorconfig)\n\n(use-package copilot\n    :straight (:host github :repo \"copilot-emacs/copilot.el\" :files (\"dist\" \"*.el\"))\n    :bind ((\"C-8\" . copilot-complete)\n           :map copilot-completion-map\n           (\"C-j\" . copilot-accept-completion)\n           (\"C-f\" . copilot-accept-completion-by-word)\n           (\"C-t\" . copilot-accept-completion-by-line)\n           (\"M-n\" . copilot-next-completion)\n           (\"M-p\" . copilot-previous-completion)))",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Completion frameworks"
    ]
  },
  {
    "objectID": "emacs/intro_automation.html",
    "href": "emacs/intro_automation.html",
    "title": "Automation",
    "section": "",
    "text": "A good text editor should make your work easier and more efficient. At the core of efficiency is automation which can be achieved by various techniques such as powerful search and replace, usage of regular expressions, definition of functions, or keyboard macros.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Automation"
    ]
  },
  {
    "objectID": "emacs/intro_automation.html#search-and-replace",
    "href": "emacs/intro_automation.html#search-and-replace",
    "title": "Automation",
    "section": "Search and replace",
    "text": "Search and replace\nOpen a new file (you can call it exercise if you want).\n\nRemember that one option is to launch Emacs (or emacsclient if you have an Emacs server running), then find a new file with C-x C-f. Another option is to launch Emacs (or emacsclient) directly with a new file open (with emacs exercise or emacsclient exercise).\n\nNow, yank (C-y) the following text in it:\nThis is a list:\n\n- Item one\n- Item two\n- Item three\n- Item four\n- Item five\n- Item six\n- Item seven\n- Item eight\n- Item nine\n- Item ten\nWe want to turn this list into a different style, with each item in lower case and a coma at the end.\nIn this particular example, because all items start with the same word, we can use a search and replace method.\n\nfirst, go to the start of the buffer (with M-&lt;),\nthen use the query-replace command. You can access it with M-x query-replace or with the kbd M-%,\nnow, enter what you want to look for (‚ÄúItem‚Äù) and press RET (the &lt;return&gt; key labelled ‚ÄúEnter‚Äù on your keyboard),\nfinally type what you want to replace the query by (‚Äúitem‚Äù) and press RET again.\n\nEmacs tells you that you can press ? for help. If you do so, you will see how to navigate the search and replace interface. Here are the most important kbds to remember:\nSPC to replace one match\nn to skip to next match\nRET to exit\n! to replace all remaining matches in this buffer\nSince we want to replace all instances, we can press !.\nNow, for the addition of comas at the end of items:\n\nmove back to the top of the buffer again,\nlaunch another query-replace,\nfor the query, type C-q C-j then `RET,\nfor the replacement, type , C-q C-j and RET.\n\nC-q is a way to quote the next character, in effect entering it in the search query rather than applying its effect. C-j inserts a new line (what we want since we want to add , before new lines), but if pressed unquoted, it has the same effect as pressing RET, which would move the query-replace questions along‚Äînot what we want.\n\nTry pressing C-j to see that it will insert a new line in your buffer.\n\nNow, we don‚Äôt want to add , at the end of the first or second lines, so press n (for ‚Äúno‚Äù) twice. Then you can either press the space bar until the end of the list or press ! to replace the remaining matches.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Automation"
    ]
  },
  {
    "objectID": "emacs/intro_automation.html#search-and-replace-with-regexp",
    "href": "emacs/intro_automation.html#search-and-replace-with-regexp",
    "title": "Automation",
    "section": "Search and replace with regexp",
    "text": "Search and replace with regexp\nLet‚Äôs consider a different list. Copy it, go back to your buffer, press C-x h to select all its content, press DEL (backspace key) to erase the highlighted region, then yank what you had copied below with C-y.\nThis is a list:\n\n- First item\n- Second item\n- Third item\n- Fourth item\n- Fifth item\n- Sixth item\n- Seventh item\n- Eighth item\n- Ninth item\n- Tenth item\nIn this case, we can‚Äôt replace the first item with its lower case version with a simple search and replace. We can however do it using a regular expression:\n\ngo to the top of the buffer,\nenter the command query-replace-regexp or C-M-%,\nfor the query entry type: - \\(.\\),\nand for the replacement entry type: - \\,(downcase \\1).\n\nWhat we are doing here is to replace the first character after ‚Äú-‚Äù (which we place in a group) with ‚Äú-‚Äù followed by its lower case version. \\, enables us to use an Elisp expression as part of the transformation. The Elisp expression is between parenthesis and uses the command downcase. \\1 replaces the grouped expression.\n\nIf you have never used regular expression, I recommend having a look at this site which covers the topic in a very clear fashion. For Emacs specific regexps, you can find information in the manual.\n\nFor the end of line coma, we can replace the regexp $ with ,.\n\n\nYour turn:\n\nTry this yourself.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Automation"
    ]
  },
  {
    "objectID": "emacs/intro_automation.html#keyboard-macros",
    "href": "emacs/intro_automation.html#keyboard-macros",
    "title": "Automation",
    "section": "Keyboard macros",
    "text": "Keyboard macros\n\nWhat are keyboard macros?\nKeyboard macros are recordings of key presses. They are extremely convenient because they allow to automate any task, on the fly, without having to define functions or use complex regular expressions.\nThis is how it works:\n\nyou initiate the recording with C-x ( or &lt;f3&gt;,\nthen you do whatever task you wish to repeat,\nfinally you end the recording with C-x ) or &lt;f4&gt;.\n\nNow, to repeat the task you recorded, you just have to press C-x e or &lt;f4&gt;.\nYou can use the macro any number of times, either in succession or at any later time in your editing session. You can apply them on any buffer and you can apply them multiple times in a row with the usual repeat kbds (e.g.¬†C-u 10 &lt;f4&gt;).\n\n\nNaming macros\nIf you define a new macro, it will replace the previously recorded one. If you want to use multiple macros at the same time, you can give them names using M-x name-last-kbd-macro. That way, there is no limit in how many you have access to simultaneously. To access any of these macros, call with as you would a command with M-x.\n\n\nSaving macros\nIf you want to save named macros for future sessions, you can add them to your init file by running M-x insert-kbd-macro.\nYou can even give them a kbd with (global-set-key (kbd \"&lt;your kbd&gt;\") '&lt;your macro&gt;).\n\n\nYour turn:\n\nGo back to your buffer, undo the changes with C-/ until the comas are gone and the items are capitalized again, then try using a keyboard macro to re-edit it efficiently.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Automation"
    ]
  },
  {
    "objectID": "emacs/advanced_customize.html#evaluation-order",
    "href": "emacs/advanced_customize.html#evaluation-order",
    "title": "Advanced Emacs customizations",
    "section": "Evaluation order",
    "text": "Evaluation order\nIf you write your own Emacs code, be careful that functions and variables take the value of their last loaded version. The order in which Emacs code is evaluated thus matters.\nYou want to evaluate as little as possible when you launch Emacs to speed up start-up time (lazy evaluation): you don‚Äôt want to load every single package that you have installed.\nThis means that if you overwrite a function or variable of a mode in your init file, the init file is read at start-up, but when that mode is launched, the default function/variable will overwrite the custom one you wrote in your init file.\nTo by-pass this problem, you can use eval-after-load.\n\nExample:\n(eval-after-load\n \"markdown\"\n '(defun markdown-demote ()\n    ...))\n\n\nuse-package has the :init and :config keyword symbols that ensure that the following expressions are evaluated respectively before or after the loading of a package."
  },
  {
    "objectID": "emacs/advanced_customize.html#customizing-kbd",
    "href": "emacs/advanced_customize.html#customizing-kbd",
    "title": "Advanced Emacs customizations",
    "section": "Customizing kbd",
    "text": "Customizing kbd\nLike everything else, kbds can be customized.\n\nGlobal kbd\nMost modes come with specific keymaps: sets of kbd only active when the mode is enabled.\n\nFor example, to modify the kbd for the function markdown-outline-previous in the markdown-mode-map:\n\n(define-key markdown-mode-map (kbd \"M-p\") 'markdown-outline-previous)\n\nOr, using use-package:\n\n(use-package markdown-mode\n    :bind (:map markdown-mode-map\n                (\"M-p\" . markdown-outline-previous)))"
  },
  {
    "objectID": "calendar.html",
    "href": "calendar.html",
    "title": "Upcoming training events",
    "section": "",
    "text": "Our training events also get posted on our main site."
  },
  {
    "objectID": "bash/wb_tools3_slides.html#how-to-choose-tools",
    "href": "bash/wb_tools3_slides.html#how-to-choose-tools",
    "title": "Modern shell utilities",
    "section": "How to choose tools?",
    "text": "How to choose tools?\n\nPopularity (GitHub stars)\nIs it maintained? (date of last commit)\nHow polished is the documentation?\nHow fast is it? (what language is it written in?)\n\nShell/Python will be slower\nCompiled languages (Rust, C, Go) will be faster"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#what-is-eza",
    "href": "bash/wb_tools3_slides.html#what-is-eza",
    "title": "Modern shell utilities",
    "section": "What is eza?",
    "text": "What is eza?\neza is a replacement for ls\n\nAdds colours\nBetter default options\nAdd tree feature"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#installation",
    "href": "bash/wb_tools3_slides.html#installation",
    "title": "Modern shell utilities",
    "section": "Installation",
    "text": "Installation\nOn your machine\nInstructions here\nOn the Alliance clusters\neza is not installed on the Alliance clusters, so you have to install it locally under your own user. This is easy to do because it is written in Rust and can be installed with the Rust package manager\nLoad a Rust module, install eza, and make sure ~/.cargo/bin is in your path:\nmodule load rust/1.76.0\ncargo install eza\n\nYou only need to do this once. Once installed, eza will be accessible on subsequent sessions"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#usage",
    "href": "bash/wb_tools3_slides.html#usage",
    "title": "Modern shell utilities",
    "section": "Usage",
    "text": "Usage\neza\n‚ûî Different colours for directories, symlinks, and different types of files and better defaults (compare ls -al with eza -al)\neza by default shows the output in a human readable format and without the group\nThe flags are similar to those of ls with the additional -T, equivalent to running the tree utility:\neza -T python/"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#alias",
    "href": "bash/wb_tools3_slides.html#alias",
    "title": "Modern shell utilities",
    "section": "Alias",
    "text": "Alias\nYou can alias it to ls by adding to your .bashrc or .zshrc file:\nalias ls=eza\nIf you ever want to use the true ls utility, you can do so with \\ls"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#alternative",
    "href": "bash/wb_tools3_slides.html#alternative",
    "title": "Modern shell utilities",
    "section": "Alternative",
    "text": "Alternative\nIf you want a simpler and more lightweight way to add colours to your ls outputs, you can look at LS_COLORS (I did this for years until I found eza)\nTo install it locally in the Alliance clusters, you download and uncompress a script, and copy it to a proper location:\nmkdir ./LS_COLORS &&\n    curl -L https://api.github.com/repos/trapd00r/LS_COLORS/tarball/master |\n        tar xzf - --directory=./LS_COLORS --strip=1 &&\n    mkdir -p ~/.local/share &&\n    cp ~/LS_COLORS/lscolors.sh ~/.local/share &&\n    rm -r ~/LS_COLORS\nThen you add to your .bashrc/.zshrc file the sourcing of the script and an alias to ls:\nsource ~/.local/share/lscolors.sh\nalias ls='ls --color'"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#what-is-bat",
    "href": "bash/wb_tools3_slides.html#what-is-bat",
    "title": "Modern shell utilities",
    "section": "What is bat?",
    "text": "What is bat?\nbat is a replacement for cat\n\nAdds syntax highlighting for most programming languages\nAdds line numbers\nAdds pager-like search\nAdds pager-like navigation"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#installation-1",
    "href": "bash/wb_tools3_slides.html#installation-1",
    "title": "Modern shell utilities",
    "section": "Installation",
    "text": "Installation\nOn your machine\nInstructions here\nOn the Alliance clusters\nbat is already installed on the Alliance clusters"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#usage-1",
    "href": "bash/wb_tools3_slides.html#usage-1",
    "title": "Modern shell utilities",
    "section": "Usage",
    "text": "Usage\nUse bat as you would use cat:\nbat /home/marie/parvus/prog/progpy/pydoc/basics.py\nthen you are in your default pager\nAmong other options, you can disable the frame with -n\nand also remove the line numbers with -p"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#what-is-fd",
    "href": "bash/wb_tools3_slides.html#what-is-fd",
    "title": "Modern shell utilities",
    "section": "What is fd?",
    "text": "What is fd?\nfd is a replacement for find\n\nWritten in Rust, automatic parallelism ‚ûî with vastly improved performance\nMore friendly syntax\nBy default excludes binaries as well as hidden files and directories\nBy default excludes patterns from .gitignore or other .ignore files"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#installation-2",
    "href": "bash/wb_tools3_slides.html#installation-2",
    "title": "Modern shell utilities",
    "section": "Installation",
    "text": "Installation\nOn your machine\nInstructions here\nOn the Alliance clusters\nfd is already installed on the Alliance clusters"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#basic-usage",
    "href": "bash/wb_tools3_slides.html#basic-usage",
    "title": "Modern shell utilities",
    "section": "Basic usage",
    "text": "Basic usage\nSearch file names for a pattern recursively in current directory:\nfd jx\n\nfd uses regexp by default, so you can use pattern symbols:\nfd jx.*txt\n\n Search file names recursively in another directory:\nfd top bash/"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#print-all-files-in-some-directory-to-stdout",
    "href": "bash/wb_tools3_slides.html#print-all-files-in-some-directory-to-stdout",
    "title": "Modern shell utilities",
    "section": "Print all files in some directory to stdout",
    "text": "Print all files in some directory to stdout\nCurrent directory:\nfd\nAnother directory:\nfd . bash/"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#options",
    "href": "bash/wb_tools3_slides.html#options",
    "title": "Modern shell utilities",
    "section": "Options",
    "text": "Options\nSearch for files with a particular file extension:\nfd -e txt\nUse a globbing pattern instead of regexp:\nfd -g wb* bash/\nExecute command for each result of fd in parallel:\nfd top bash/ -x rg layout\nExecute command once with all results of fd as arguments:\nfd top bash/ -X rg layout"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#excluded-files-and-directories",
    "href": "bash/wb_tools3_slides.html#excluded-files-and-directories",
    "title": "Modern shell utilities",
    "section": "Excluded files and directories",
    "text": "Excluded files and directories\nBy default, fd excludes hidden files/directories and patterns in .gitignore (you can disable this with -H and -I respectively)\nThis makes fd combined with tree sometimes more useful than tree alone\nCompare tree bash/ with:\nfd . bash/ | tree --fromfile\n\nYou can make this a function:\nft () { fd $@ | tree --fromfile }\n\nExclude additional directories or patterns:\nfd -E *.txt -E img/ . bash/"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#my-personal-alias",
    "href": "bash/wb_tools3_slides.html#my-personal-alias",
    "title": "Modern shell utilities",
    "section": "My personal alias",
    "text": "My personal alias\nI prefer to disable the default settings and exclude patterns based on a file I created:\nalias fd='fd -u --ignore-file /home/marie/.fdignore'"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#what-is-ripgrep",
    "href": "bash/wb_tools3_slides.html#what-is-ripgrep",
    "title": "Modern shell utilities",
    "section": "What is ripgrep?",
    "text": "What is ripgrep?\nripgrep provides the rg utility‚Äîa replacement for grep\n\nWritten in Rust, automatic parallelism ‚ûî with vastly improved performance\nBy default excludes patterns from .gitignore or other .ignore files\nBy default excludes binaries as well as hidden files and directories\nBy default doesn‚Äôt follow symlinks"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#installation-3",
    "href": "bash/wb_tools3_slides.html#installation-3",
    "title": "Modern shell utilities",
    "section": "Installation",
    "text": "Installation\nOn your machine\nInstructions here\nOn the Alliance clusters\nrg is already installed on the Alliance clusters"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#usage-2",
    "href": "bash/wb_tools3_slides.html#usage-2",
    "title": "Modern shell utilities",
    "section": "Usage",
    "text": "Usage\nSearch lines in a file matching a pattern:\nrg colour /home/marie/parvus/prog/mint/bash/wb_tools3_slides.qmd\nSearch lines matching pattern in all files in current directory (recursively):\nrg colour\nrg and fd follow the same principles:\n\nUse regexp by default\nUse globbing pattern instead with -g\nSearch recursively by default\nSame excluded files"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#what-is-zoxide",
    "href": "bash/wb_tools3_slides.html#what-is-zoxide",
    "title": "Modern shell utilities",
    "section": "What is zoxide?",
    "text": "What is zoxide?\nzoxide allows to easily jump to any directory"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#installation-4",
    "href": "bash/wb_tools3_slides.html#installation-4",
    "title": "Modern shell utilities",
    "section": "Installation",
    "text": "Installation\nOn your machine\nInstructions here\n\nfzf (see below) adds cool functionality to it, so you might want to install it as well"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#choose-a-different-command-name",
    "href": "bash/wb_tools3_slides.html#choose-a-different-command-name",
    "title": "Modern shell utilities",
    "section": "Choose a different command name",
    "text": "Choose a different command name\nUse this instead to use the command of your choice (e.g.¬†j and ji)\ninstead of the default z and zi:\neval \"$(zoxide init --cmd j bash)\""
  },
  {
    "objectID": "bash/wb_tools3_slides.html#usage-3",
    "href": "bash/wb_tools3_slides.html#usage-3",
    "title": "Modern shell utilities",
    "section": "Usage",
    "text": "Usage\nType z (or whatever command you chose) instead of cd\nYou can simplify the path to just a few characters\nIf there are multiple locations matching your entry, the algorithm will chose the highest ranking one based on your visit frequency and how recently you visited a path\nThis means that you can visit your usual places with a few key strokes. For less frequent places, add more info\nFinally, if you want to choose amongst all possible options in a completion framework, use zi instead and zoxide will open fzf"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#alternative-1",
    "href": "bash/wb_tools3_slides.html#alternative-1",
    "title": "Modern shell utilities",
    "section": "Alternative",
    "text": "Alternative\nA tool that served me well until someone pointed zoxide to me is autojump\nInstallation\nInstructions here for your machine\nautojump is installed on the Alliance clusters, but you need add to your .bashrc or .zshrc:\n[[ -s $EPREFIX/etc/profile.d/autojump.sh ]] && source $EPREFIX/etc/profile.d/autojump.sh\nUsage\nSimilar to zoxide but you first need to visit directories so that they get entered in a database\nj is a wrapper for autojump, jc jumps to subdirectories of current directory"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#what-is-fzf",
    "href": "bash/wb_tools3_slides.html#what-is-fzf",
    "title": "Modern shell utilities",
    "section": "What is fzf?",
    "text": "What is fzf?\nfzf allows to find elements of any list through incremental completion and fuzzy matching. It can be paired with any number of commands"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#installation-6",
    "href": "bash/wb_tools3_slides.html#installation-6",
    "title": "Modern shell utilities",
    "section": "Installation",
    "text": "Installation\nOn your machine\nInstructions here\nOn the Alliance clusters\nfzf is already installed on the Alliance clusters\nTo get fzf kbds and fuzzy completion in your shell, add to your .bashrc:\neval \"$(fzf --bash)\"\nand/or your .zshrc:\nsource &lt;(fzf --zsh)"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#direct-usage",
    "href": "bash/wb_tools3_slides.html#direct-usage",
    "title": "Modern shell utilities",
    "section": "Direct usage",
    "text": "Direct usage\nIf you run fzf directly, it will search the current directory recursively, do a narrowing selection, and print the result:\nfzf\nYou can make use of fd to remove unnecessary entries:\nexport FZF_DEFAULT_COMMAND='fd -u --ignore-file /home/marie/.fdignore'"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#fzf-kbds",
    "href": "bash/wb_tools3_slides.html#fzf-kbds",
    "title": "Modern shell utilities",
    "section": "fzf kbds",
    "text": "fzf kbds\nThere are 3 default kbds:\n\nCtl+t ‚ûî paste selected file/dir into the command\nCtl+r ‚ûî paste selected command from history into the command\nAlt+c ‚ûî cd into selected dir"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#pipe-to-fzf",
    "href": "bash/wb_tools3_slides.html#pipe-to-fzf",
    "title": "Modern shell utilities",
    "section": "Pipe to fzf",
    "text": "Pipe to fzf\nYou can also pipe the output of any command that returns a list of elements into fzf\nLook for a file/directory:\nls | fzf\n Many flags to select order of entries, type of completion, preview, case-sensitivity, and more\nLook for a running process:\nps -ef | fzf --cycle -i -e +s --tac --reverse"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#what-is-a-tui",
    "href": "bash/wb_tools3_slides.html#what-is-a-tui",
    "title": "Modern shell utilities",
    "section": "What is a TUI?",
    "text": "What is a TUI?\nTerminal user interfaces (TUIs) are the predecessors to graphical user interfaces (GUIs) which are entirely text based and run in terminals\nThey have remained very popular among command line aficionados because they are fast, efficient, powerful, and keyboard-driven, while being friendly and visual\nFantastic modern ones keep being built for tasks as diverse as interfaces to Git, music players, games, emails, dashboards, and, for our purpose here, file system management"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#formerly-most-popular-file-system-tuis",
    "href": "bash/wb_tools3_slides.html#formerly-most-popular-file-system-tuis",
    "title": "Modern shell utilities",
    "section": "Formerly most popular file system TUIs",
    "text": "Formerly most popular file system TUIs\nThere are many file system TUIs and all of them are actually really good. The two most notable ones used to be:\n\nranger\n\nExtremely sophisticated, easy to customize, tons of features\n\nBuilt in Python, it can be slow for operations in directories with thousands of files\n\n\nnnn\n\nMinimalist and very fast (written in C)\n\nNot easy to customize (many customizations require compiling from source). Most functionalities rely on plugins that need to be installed. Not easy to get started with"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#the-new-kid-yazi",
    "href": "bash/wb_tools3_slides.html#the-new-kid-yazi",
    "title": "Modern shell utilities",
    "section": "The new kid: yazi",
    "text": "The new kid: yazi\nyazi is a brand new fs TUI that has quickly become the most popular\nIt is extremely modern, very fast (written in Rust), very well documented, intuitive, easy to customize, and integrates with modern utilities such as fd, rg, zoxide, and fzf out of the box\nOnly at version 0.4, it is not fully mature yet, but it has already more stars on GitHub than ranger and nnn because it combines ease of customization and sophistication with speed"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#alternatives",
    "href": "bash/wb_tools3_slides.html#alternatives",
    "title": "Modern shell utilities",
    "section": "Alternatives",
    "text": "Alternatives\nIn decreasing number of stars on GitHub:\n\nbroot\nsuperfile\nlf\nxplr\nfff (now archived)\nvifm\nmc"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#my-3-favourite-plugins",
    "href": "bash/wb_tools3_slides.html#my-3-favourite-plugins",
    "title": "Modern shell utilities",
    "section": "My 3 favourite plugins",
    "text": "My 3 favourite plugins\nThere are many plugins for Z shell and the (very bloated) Oh My Zsh, but I am sticking to 3 great plugins inspired or directly coming from the Fish shell:\n\nSyntax highlighting\nAutosuggestions\nHistory substring search"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#installation-7",
    "href": "bash/wb_tools3_slides.html#installation-7",
    "title": "Modern shell utilities",
    "section": "Installation",
    "text": "Installation\nAll plugins can be installed (info in their README) or simply Git cloned. zsh-syntax-highlighting is already installed on the Alliance clusters, so you only need to clone the other two:\n# create a directory to store the scripts\nmkdir ~/.zsh_plugins\n# autosuggestions\ngit clone https://github.com/zsh-users/zsh-autosuggestions.git ~/.zsh_plugins/zsh-autosuggestions\n# history substring search\ngit clone https://github.com/zsh-users/zsh-history-substring-search.git ~/.zsh_plugins/zsh-history-substring-search\nThen you need to source them (including zsh-syntax-highlighting), so add to your .zshrc file:\nsource $EPREFIX/usr/share/zsh/site-functions/zsh-syntax-highlighting.zsh\nsource ~/.zsh_plugins/zsh-history-substring-search/zsh-history-substring-search.zsh\nsource ~/.zsh_plugins/zsh-autosuggestions/zsh-autosuggestions.zsh"
  },
  {
    "objectID": "bash/wb_tools3_slides.html#usage-5",
    "href": "bash/wb_tools3_slides.html#usage-5",
    "title": "Modern shell utilities",
    "section": "Usage",
    "text": "Usage\nYou now have syntax highlighting in your shell inputs\nTo use the history substring search, start typing some command\nthen press Alt+p or Alt+n\nIt will cycle through all entries in your history that start that way\nFinally, the autosuggestion will suggest commands based on your history and/or classic suggestions\nAccept the whole command with Ctl+e or a single word with Alt+f"
  },
  {
    "objectID": "bash/wb_tools3.html",
    "href": "bash/wb_tools3.html",
    "title": "Modern shell utilities",
    "section": "",
    "text": "In recent years, a number of open-source utilities for the Unix shell have emerged. Some are meant as replacements for classic tools with improved performance, better defaults, or nicer-looking outputs; others add novel functionality. Several of them were recently installed on the Alliance clusters.\nIn this webinar I will cover a selection of tools that are very popular, well-maintained, and that have served me well in my daily workflows:\n\nls in colours: eza,\nsmart cd: zoxide,\na cat with wings: bat,\nRIP grep: ripgrep,\nfaster find: fd,\nfuzzy finder: fzf,\nfile system TUIs.\n\nI will also talk about three useful Zsh plugins:\n\na syntax highlighter,\nautosuggestions,\nan improved history searcher.\n\nFor each tool/plugin, I will talk about installation on a personal computer and on the Alliance clusters and I will give live demos.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities"
    ]
  },
  {
    "objectID": "bash/wb_tools1.html",
    "href": "bash/wb_tools1.html",
    "title": "Fun tools to simplify your life in the shell",
    "section": "",
    "text": "Working in the command-line has many advantages and it is often necessary, but can it be fun?\nIn this webinar, aimed at any command-line user, I intend to demonstrate that yes, it can! by introducing three free and open source utilities which make navigating your system and your outputs a lot easier:\n\nfzf is a simple, yet extremely powerful interactive fuzzy finder allowing for incremental completion and narrowing selection of any command line output. I will show you how to build simple shell functions which harvest its power to instantly refresh your memory on your custom keybindings or aliases, navigate your command history, find and kill processes, and explore and checkout your git commits. After this, you will be able to use fzf for any number of other applications in your work in the command-line.\nautojump lets you jump anywhere you want in your directories in just a few keystrokes (no more of this painful navigation writing down long paths).\nWith the ranger file manager, you can browse (with preview!), open, copy, move, delete, etc. your files and directories in a friendly way from the command line. Added bonus: you can use fzf and autojump within ranger!\n\nWarning: too much fun in the command-line can lead to addiction and geek behaviours. Use in moderation.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Webinars</em></b>",
      "Fun tools for the command line"
    ]
  },
  {
    "objectID": "bash/top_wb.html",
    "href": "bash/top_wb.html",
    "title": "Bash webinars",
    "section": "",
    "text": "Fun tools for the command line\n\n\n\n\nMore fun tools for the command line\n\n\n\n\nModern shell utilities",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Webinars</em></b>"
    ]
  },
  {
    "objectID": "bash/molecules/intro_wildcards.html",
    "href": "bash/molecules/intro_wildcards.html",
    "title": "Wildcards",
    "section": "",
    "text": "Wildcards are a convenient way to select items matching patterns.\n\n\n\n\n\n\n\nNoteData for this section\n\n\n\n\n\nFor this section, we will play with files created by The Carpentries.\nYou can download them into a zip file called data.zip with:\ncurl --output data.zip https://mint.westdri.ca/bash/data.zip\nYou can then unzip that file with:\nunzip data.zip\nYou should now have a data directory.\ncd into it:\ncd data\n\n\n\nLet‚Äôs list the files in this directory:\nls\ncubane.pdb  ethane.pdb  methane.pdb  octane.pdb  pentane.pdb  propane.pdb\nYou could do the same with:\nls *\nThe star expands to all files/directories matching any pattern. It is a wildcard.\nOf course, you can match more interesting patterns.\nFor instance, to list all files starting with the letter o, we can run:\nls o*\noctane.pdb\nTo list all files containing the letter o anywhere in their name, you can use:\nls *o*\noctane.pdb  propane.pdb\nThis saves a lot of typing and is a powerful way to apply a command to a subset of files/directories.\n\n\nYour turn:\n\nWildcards are often used to select all files with a certain extension.\nLet‚Äôs create 3 new files:\ntouch file1.txt file2.txt file3.md\nHow would you list all files with the .txt extension and only those?",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Wildcards"
    ]
  },
  {
    "objectID": "bash/molecules/intro_redirections.html",
    "href": "bash/molecules/intro_redirections.html",
    "title": "Redirections & pipes",
    "section": "",
    "text": "By default, commands that produce an output print it to the terminal. This output can however be redirected to be printed elsewhere (e.g.¬†to a file) or to be passed as the argument of another command.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Redirections & pipes"
    ]
  },
  {
    "objectID": "bash/molecules/intro_redirections.html#redirections",
    "href": "bash/molecules/intro_redirections.html#redirections",
    "title": "Redirections & pipes",
    "section": "Redirections",
    "text": "Redirections\nBy default, commands that produce an output print it to standard output‚Äîthat is, the terminal. This is what we have been doing so far.\nThe output can however be redirected with the &gt; sign. For instance, it can be redirected to a file, which is very handy if you want to save the result.\n\nExample:\n\nLet‚Äôs print the number of lines in each .pdb file in the molecules directory:\n\nwc -l *.pdb\n\n  20 gas_cubane.pdb\n  12 gas_ethane.pdb\n   9 gas_methane.pdb\n  30 gas_octane.pdb\n  21 gas_pentane.pdb\n  15 gas_propane.pdb\n 107 total\n\n\n\n\nYour turn:\n\n\nWhat does the wc command do?\nWhat does the -l flag for this command do?\nHow did you find out?\n\n\nTo save this result into a file called lengths.txt, we run:\n\nwc -l *.pdb &gt; lengths.txt\n\n\nNote that &gt; always creates a new file. If a file called lengths.txt already exists, it will be overwritten. Be careful not to lose data this way!\nIf you don‚Äôt want to lose the content of the old file, you can append the output to the existing file with &gt;&gt; (&gt;&gt; will create a file lengths.txt if it doesn‚Äôt exist yet, but if it exists, it will append the new content below the old one).\n\n\n\nYour turn:\n\nHow can you make sure that you did create a file called lengths.txt?\n\nLet‚Äôs print its content to the terminal:\n\ncat lengths.txt\n\n  20 gas_cubane.pdb\n  12 gas_ethane.pdb\n   9 gas_methane.pdb\n  30 gas_octane.pdb\n  21 gas_pentane.pdb\n  15 gas_propane.pdb\n 107 total\n\n\nAs you can see, it contains the output of the command wc -l *.pdb.\nOf course, we can print the content of the file with modification. For instance, we can sort it:\n\nsort -n lengths.txt\n\n   9 gas_methane.pdb\n  12 gas_ethane.pdb\n  15 gas_propane.pdb\n  20 gas_cubane.pdb\n  21 gas_pentane.pdb\n  30 gas_octane.pdb\n 107 total\n\n\nAnd we can redirect this new output to a new file:\n\nsort -n lengths.txt &gt; sorted.txt\n\nInstead of printing an entire file to the terminal, you can print only part of it.\nLet‚Äôs print the first line of the new file sorted.txt:\n\nhead -1 sorted.txt\n\n   9 gas_methane.pdb",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Redirections & pipes"
    ]
  },
  {
    "objectID": "bash/molecules/intro_redirections.html#pipes",
    "href": "bash/molecules/intro_redirections.html#pipes",
    "title": "Redirections & pipes",
    "section": "Pipes",
    "text": "Pipes\nAnother form of redirection is the Bash pipe. Instead of redirecting the output to a different stream for printing, the output is passed as an argument to another command. This is very convenient because it allows to chain multiple commands without having to create files or variables to save intermediate results.\nFor instance, we could run the three commands we ran previously at once, without the creation of the two intermediate files:\n\nwc -l *.pdb | sort -n | head -1\n\n   9 gas_methane.pdb\n\n\nIn each case, the output of the command on the left-hand side (LHS) is passed as the input of the command on the right-hand side (RHS).\n\n\nYour turn:\n\nIn a directory we want to find the 3 files that have the least number of lines. Which command would work for this?\n\nwc -l * &gt; sort -n &gt; head -3\nwc -l * | sort -n | head 1-3\nwc -l * | sort -n | head -3\nwc -l * | head -3 | sort -n\n\n\nHere is a video of a previous version of this workshop.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Redirections & pipes"
    ]
  },
  {
    "objectID": "bash/molecules/intro_control_flow.html",
    "href": "bash/molecules/intro_control_flow.html",
    "title": "Control flow",
    "section": "",
    "text": "By default, scripts get executed linearly from top to bottom. Often however, you want to control what gets executed when.\nThis section covers various ways to control the flow of execution through a script.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Control flow"
    ]
  },
  {
    "objectID": "bash/molecules/intro_control_flow.html#normal-execution-of-commands",
    "href": "bash/molecules/intro_control_flow.html#normal-execution-of-commands",
    "title": "Control flow",
    "section": "Normal execution of commands",
    "text": "Normal execution of commands\nCommands get executed from top to bottom and from left to right. Different commands are separated by a line break and/or a semi-colon.\n\nExample:\n\nLook at the following commands:\nunzip bash.zip\nrm bash.zip\nThis is equivalent to:\nunzip bash.zip;\nrm bash.zip\nand to:\nunzip bash.zip; rm bash.zip\nThis is what we did to get the data for the past few sessions.\nIn all three cases, both commands will try to run. Now, if for some reason, the unzipping fails, the zip file still gets deleted. That‚Äôs a bummer.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Control flow"
    ]
  },
  {
    "objectID": "bash/molecules/intro_control_flow.html#conditional-on-previous-command",
    "href": "bash/molecules/intro_control_flow.html#conditional-on-previous-command",
    "title": "Control flow",
    "section": "Conditional on previous command",
    "text": "Conditional on previous command\n\nExecution conditional on success\nCommands can be limited to running only if the previous command ran successfully thanks to the double-ampersand (&&).\n\nExample:\n\nunzip bash.zip &&\n    rm bash.zip\nThis is equivalent to:\nunzip bash.zip && rm bash.zip\nIf the unzipping works (if it returns a zero exit status), then the Zip file gets deleted. If however, the unzipping fails (if it returns a non-zero exit status), the script aborts and we haven‚Äôt lost our Zip file.\n\n\nExecution conditional on failure\nThe opposite of && is ||: the second command only gets executed if the first one failed.\n\nExample:\n\nunzip bash.zip || echo \"Unzipping failed\"\nThis can also be written as:\nunzip bash.zip ||\n    echo \"Unzipping failed\"",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Control flow"
    ]
  },
  {
    "objectID": "bash/molecules/intro_control_flow.html#conditional-executions",
    "href": "bash/molecules/intro_control_flow.html#conditional-executions",
    "title": "Control flow",
    "section": "Conditional executions",
    "text": "Conditional executions\nCommands can be executed or not depending on some conditions. To achieve this, we first need to have expressions that define these conditions.\n\nPredicates\nPredicates are expressions that, when evaluated, return either true or false.\nHere are examples of predicates:\n[ $var == 'text' ] checks whether var is equal to 'text'.\n[ $var == number ] checks whether var is equal to number.\n[ -e name ] checks whether name exists.\n[ -d name ] checks whether name is a directory.\n[ -f name ] checks whether name is a file.\nMake sure to have spaces around each bracket.\n\n\nYour turn:\n\n\nCreate a directory d1 and a file f1.\n\n\n\n\n\n\nWrite the predicates that test whether:\nd1 exists,\nd1 is a file,\nd1 is a directory,\nf1 is a file,\nf1 is a directory.\n\n\n\n\nIf statements\n\nSyntax\nIn its simplest form, if statements look like:\nif [ predicate ]\nthen\n    command1\n    command2\n    ...\nfi\n\nThis can also be written as:\nif [ predicate ]; then command1; command2; ...; fi\n\nIf the condition is true, the commands are executed, if the condition is false, nothing happens.\n\n\nExamples\n\nvar=f1\n\nif [ -e $var ]\nthen\n    echo \"$var exists\"\nfi\n\nf1 exists\n\n\n\nvar=f2\n\nif [ -e $var ]\nthen\n    echo \"$var exists\"\nfi\n\n\n\nYour turn:\n\nWrite a conditional expression that prints ‚Äúd1 is a directory‚Äù if d1 is a directory and test it.\n\n\n\n\nIf else statements\n\nSyntax\nIf you want a different set of commands to be executed when the condition is false, you add an else statement:\nif [ predicate ]\nthen\n    command1\n    command2\n    ...\nelse\n    command3\n    command4\n    ...\nfi\n\n\nExamples\n\nvar=f1\n\nif [ -e $var ]\nthen\n    echo \"$var exists\"\nelse\n    echo \"$var does not exist\"\nfi\n\nf1 exists\n\n\n\nvar=f2\n\nif [ -e $var ]\nthen\n    echo \"$var exists\"\nelse\n    echo \"$var does not exist\"\nfi\n\nf2 does not exist\n\n\n\n\n\nIf elif else statements\nOf course, you can have multiple conditions defining trees of if statements. In that case, you use elif (any number of times):\n\nSyntax\nif [ predicate1 ]\nthen\n    command1\n    command2\n    ...\nelif [ predicate2 ]\nthen\n    command3\n    command4\n    ...\nelse\n    command5\n    command6\n    ...\nfi\n\n\nExamples\n\nvar=4\n\nif (( $var &lt; 0 ))\nthen\n    echo \"$var is negative\"\nelif (( $var &gt; 0 ))\nthen\n    echo \"$var is positive\"\nelse\n    echo \"$var is equal to zero\"\nfi\n\n4 is positive\n\n\n\n\nYour turn:\n\nPlay with the value of var to test our if elif else statement.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Control flow"
    ]
  },
  {
    "objectID": "bash/molecules/intro_control_flow.html#conditionally-repeated-executions",
    "href": "bash/molecules/intro_control_flow.html#conditionally-repeated-executions",
    "title": "Control flow",
    "section": "Conditionally repeated executions",
    "text": "Conditionally repeated executions\nCommands can be executed as long as a condition returns True thanks to while loops.\n\nSyntax\nThe syntax of a while loop in Bash is:\nwhile [ predicate ]\ndo\n    command1\n    command2\n    ...\ndone\n\n\nExample\n\nvar=0\n\nwhile (($var&lt;10))\ndo\n    echo \"$var\"\n    ((var++))\ndone\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nBe careful that while loops can lead to infinite loops. Such loops need to be manually interrupted (by pressing &lt;Ctrl+C&gt;).\n\nExample of infinite loop:\n\nvar=1\n\nwhile (($var&gt;0))\ndo\n    echo \"$var (Press &lt;Ctrl+C&gt; to stop)\"\n    ((var++))\n    sleep 1\ndone",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Control flow"
    ]
  },
  {
    "objectID": "bash/molecules/intro_control_flow.html#executions-repeated-over-a-collection",
    "href": "bash/molecules/intro_control_flow.html#executions-repeated-over-a-collection",
    "title": "Control flow",
    "section": "Executions repeated over a collection",
    "text": "Executions repeated over a collection\nCommands can be repeated for each element of a list thanks to for loops.\n\nCollections\nFor loops run a set of commands for each item of a collection. How do you create those collections?\n\nListing items one by one\nThe least efficient method is to list all the items one by one:\n\nfor i in file1 file2 file3\ndo\n    echo $i\ndone\n\nfile1\nfile2\nfile3\n\n\n\n\nWildcards\n\nls *.pdb\n\ncubane.pdb\nethane.pdb\nmethane.pdb\noctane.pdb\npentane.pdb\npropane.pdb\n\n\n\n\nBrace expansion\nCollections can also be created with brace expansion.\n\nExamples:\n\n\necho {1,2,5}\n\n1 2 5\n\n\n\nMake sure not to add a space after the commas.\n\n\necho {list,of,strings}\n\nlist of strings\n\n\n\necho {file1,file2}.sh\n\nfile1.sh file2.sh\n\n\n\nls {ethane,methane,pentane}.pdb\n\nethane.pdb\nmethane.pdb\npentane.pdb\n\n\n\necho {1..5}\n\n1 2 3 4 5\n\n\n\necho {01..10}\n\n01 02 03 04 05 06 07 08 09 10\n\n\n\necho {r..v}\n\nr s t u v\n\n\n\necho {v..r}\n\nv u t s r\n\n\n\necho {a..e}{1..3}\n\na1 a2 a3 b1 b2 b3 c1 c2 c3 d1 d2 d3 e1 e2 e3\n\n\n\necho {a..c}{a..c}\n\naa ab ac ba bb bc ca cb cc\n\n\n\necho {1..5}.txt\n\n1.txt 2.txt 3.txt 4.txt 5.txt\n\n\n\necho file{3..6}.sh\n\nfile3.sh file4.sh file5.sh file6.sh\n\n\n\n\nSequences\nCollections can also be sequences:\n\nseq 1 2 10\n\n1\n3\n5\n7\n9\n\n\n\nHere, 1 is the start of the sequence, 10 is the end, and 2 is the step.\n\n\n\n\nFor loops\n\nSyntax\nThe general structure of a for loop is as follows:\nfor iterable in collection\ndo\n    command1\n    command2\n    ...\ndone\n\n\nExamples\nThe molecules directory contains a number of .pdb files. We want to rename them by prepending ‚Äúgas_‚Äù to their current names.\nWe can do this by creating a collection with a wildcard and applying the command to each element of the collection with a for loop:\nfor file in *.pdb\ndo\n    mv $file gas_$file\ndone\n\nThis can also be written as:\nfor file in *.pdb; do mv $file gas_$file; done\n\nHere is a for loop using a collection created by a sequence:\n\nfor i in $(seq 1 2 10)\ndo\n    echo file$i.txt\ndone\n\nfile1.txt\nfile3.txt\nfile5.txt\nfile7.txt\nfile9.txt\n\n\n\n\n\n\n\n\n\n\n\nYour turn:\n\nIn a directory the command ls returns:\nfructose.dat  glucose.dat  sucrose.dat  maltose.txt\nWhat would be the output of the following loop?\nfor datafile in *.dat\ndo\n  cat $datafile &gt;&gt; sugar.dat\ndone\n\nAll of the text from fructose.dat, glucose.dat and sucrose.dat would be concatenated and saved to a file called sugar.dat.\nThe text from sucrose.dat will be saved to a file called sugar.dat.\nAll of the text from fructose.dat, glucose.dat, sucrose.dat, and maltose.txt would be concatenated and saved to a file called sugar.dat.\nAll of the text from fructose.dat, glucose.dat and sucrose.dat will be printed to the screen and saved into a file called sugar.dat.\n\n\n\n\n\n\nHere is a video of a previous version of this workshop.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Control flow"
    ]
  },
  {
    "objectID": "bash/intro_wildcards.html",
    "href": "bash/intro_wildcards.html",
    "title": "Wildcards",
    "section": "",
    "text": "Wildcards are a convenient way to select items matching patterns.\n\n\n\n\n\n\n\nNoteData for this section\n\n\n\n\n\nFor this section, we will play with files created by The Carpentries.\nYou can download them into a zip file called data.zip with:\ncurl --output data.zip https://mint.westdri.ca/bash/data.zip\nYou can then unzip that file with:\nunzip data.zip\nYou should now have a data directory.\ncd into it:\ncd data\n\n\n\nLet‚Äôs list the files in this directory:\nls\ncubane.pdb  ethane.pdb  methane.pdb  octane.pdb  pentane.pdb  propane.pdb\nYou could do the same with:\nls *\nThe star expands to all files/directories matching any pattern. It is a wildcard.\nOf course, you can match more interesting patterns.\nFor instance, to list all files starting with the letter o, we can run:\nls o*\noctane.pdb\nTo list all files containing the letter o anywhere in their name, you can use:\nls *o*\noctane.pdb  propane.pdb\nThis saves a lot of typing and is a powerful way to apply a command to a subset of files/directories.\n\n\nYour turn:\n\nWildcards are often used to select all files with a certain extension.\nLet‚Äôs create 3 new files:\ntouch file1.txt file2.txt file3.md\nHow would you list all files with the .txt extension and only those?"
  },
  {
    "objectID": "bash/intro_transfer.html",
    "href": "bash/intro_transfer.html",
    "title": "Transferring files",
    "section": "",
    "text": "If you want to use the Alliance clusters to run some of your heavy computations, you will have to move files back and forth between your machine and the clusters.\nThis section covers various ways to do this.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Transferring files"
    ]
  },
  {
    "objectID": "bash/intro_transfer.html#remote-copies-with-scp",
    "href": "bash/intro_transfer.html#remote-copies-with-scp",
    "title": "Transferring files",
    "section": "Remote copies with scp",
    "text": "Remote copies with scp\nSecure copy protocol (SCP) allows to copy files over the Secure Shell Protocol (SSH) with the scp utility. scp follows a syntax similar to that of the cp command.\nNote that you need to run it from your local machines (not from the cluster).\n\nCopy from your pc to the cluster\n# Copy a local file to your home directory on the cluster\nscp /local/path/file &lt;username&gt;@&lt;hostname-address&gt;:\n\n\nExample:\n\nscp ~/thesis/chap1/src/analysis1.py jdoe@fir.alliancecan.ca:\nOr, if John Doe has an SSH config file on their machine:\nscp ~/thesis/chap1/src/analysis1.py fir:\n\n# Copy a local file to some path on the cluster\nscp /local/path/file &lt;username&gt;@&lt;hostname-address&gt;:/remote/path\n\n\nCopy from the cluster to your pc\n# Copy a file from the cluster to some path on your machine\nscp &lt;username&gt;@&lt;hostname-address&gt;:/remote/path/file /local/path\n# Copy a file from the cluster to your current location on your machine\nscp &lt;username&gt;@&lt;hostname-address&gt;:/remote/path/file .\nYou can also use wildcards to transfer multiple files:\n# Copy all the Bash scripts from your cluster home dir to some local path\nscp &lt;username&gt;@&lt;hostname-address&gt;:*.sh /local/path\n\n\nCopying directories\nTo copy a directory, you need to add the -r (recursive) flag:\nscp -r /local/path/folder &lt;username&gt;@&lt;hostname-address&gt;:/remote/path\n\n\nCopying for Windows users\nMobaXterm users (on Windows) can copy files by dragging them between the local and remote machines in the GUI. Alternatively, they can use the download and upload buttons.\n\n\nYour turn:\n\nCopy a file from your local computer to your home directory in the training cluster.\n\nHere is a video of a previous version of this workshop.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Transferring files"
    ]
  },
  {
    "objectID": "bash/intro_transfer.html#interactive-transfers-with-sftp",
    "href": "bash/intro_transfer.html#interactive-transfers-with-sftp",
    "title": "Transferring files",
    "section": "Interactive transfers with sftp",
    "text": "Interactive transfers with sftp\nThe Secure File Transfer Protocol (SFTP) is more sophisticated and allows additional operations. The sftp command provided by OpenSSH and other packages launches an SFTP client:\nsftp &lt;username&gt;@&lt;hostname-address&gt;\n\nLook at your prompt: your usual Bash/Zsh prompt has been replaced with sftp&gt;.\n\nFrom this prompt, you can access a number of SFTP commands. Type help for a list:\nsftp&gt; help\nAvailable commands:\nbye                                Quit sftp\ncd path                            Change remote directory to 'path'\nchgrp [-h] grp path                Change group of file 'path' to 'grp'\nchmod [-h] mode path               Change permissions of file 'path' to 'mode'\nchown [-h] own path                Change owner of file 'path' to 'own'\ncopy oldpath newpath               Copy remote file\ncp oldpath newpath                 Copy remote file\ndf [-hi] [path]                    Display statistics for current directory or\n                                   filesystem containing 'path'\nexit                               Quit sftp\nget [-afpR] remote [local]         Download file\nhelp                               Display this help text\nlcd path                           Change local directory to 'path'\nlls [ls-options [path]]            Display local directory listing\nlmkdir path                        Create local directory\nln [-s] oldpath newpath            Link remote file (-s for symlink)\nlpwd                               Print local working directory\nls [-1afhlnrSt] [path]             Display remote directory listing\nlumask umask                       Set local umask to 'umask'\nmkdir path                         Create remote directory\nprogress                           Toggle display of progress meter\nput [-afpR] local [remote]         Upload file\npwd                                Display remote working directory\nquit                               Quit sftp\nreget [-fpR] remote [local]        Resume download file\nrename oldpath newpath             Rename remote file\nreput [-fpR] local [remote]        Resume upload file\nrm path                            Delete remote file\nrmdir path                         Remove remote directory\nsymlink oldpath newpath            Symlink remote file\nversion                            Show SFTP version\n!command                           Execute 'command' in local shell\n!                                  Escape to local shell\n?                                  Synonym for help\nAs this list shows, you have access to a number of classic Unix command such as cd, pwd, ls, etc. These commands will be executed on the remote machine.\nIn addition, there are a number of commands of the form l&lt;command&gt;. ‚Äúl‚Äù stands for ‚Äúlocal‚Äù.\nThese commands will be executed on your local machine.\nFor instance, ls will list the files in your current directory in the remote machine while lls (‚Äúlocal ls‚Äù) will list the files in your current directory on your computer.\nThis means that you are now able to navigate two file systems at once: your local machine and the remote machine.\n\nHere are a few examples:\n\nsftp&gt; pwd              # print remote working directory\nsftp&gt; lpwd             # print local working directory\nsftp&gt; ls               # list files in remote working directory\nsftp&gt; lls              # list files in local working directory\nsftp&gt; cd               # change the remote directory\nsftp&gt; lcd              # change the local directory\nsftp&gt; put local_file   # upload a file\nsftp&gt; get remote_file  # download a file\n\nCopying directories\nTo upload/download directories, you first need to create them in the destination, then copy the content with the -r (recursive) flag.\n\nIf you have a local directory called dir and you want to copy it to the cluster you need to run:\n\nsftp&gt; mkdir dir    # First create the directory\nsftp&gt; put -r dir   # Then copy the content\nTo terminate the session, press &lt;Ctrl+D&gt;.\n\n\nYour turn:\n\nIn an SFTP session:\n\nList the content of projects (projects is in your home on the training cluster).\nCopy a file from the training cluster to your local computer.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Transferring files"
    ]
  },
  {
    "objectID": "bash/intro_transfer.html#syncing",
    "href": "bash/intro_transfer.html#syncing",
    "title": "Transferring files",
    "section": "Syncing",
    "text": "Syncing\nIf, instead of an occasional copying of files between your machine and the cluster, you want to keep a directory in sync between both machines, you might want to use rsync instead. You can look at the Alliance wiki page on rsync for complete instructions.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Transferring files"
    ]
  },
  {
    "objectID": "bash/intro_transfer.html#heavy-transfers",
    "href": "bash/intro_transfer.html#heavy-transfers",
    "title": "Transferring files",
    "section": "Heavy transfers",
    "text": "Heavy transfers\nWhile the methods covered above work very well for limited amounts of data, if you need to make large transfers, you should use globus instead, following the instructions in the Alliance wiki page on this service.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Transferring files"
    ]
  },
  {
    "objectID": "bash/intro_transfer.html#windows-line-endings",
    "href": "bash/intro_transfer.html#windows-line-endings",
    "title": "Transferring files",
    "section": "Windows line endings",
    "text": "Windows line endings\nOn modern Mac operating systems and on Linux, lines in files are terminated with a newline (\\n). On Windows, they are terminated with a carriage return + newline (\\r\\n).\nWhen you transfer files between Windows and Linux (the cluster uses Linux), this creates a mismatch. Most modern software handle this correctly, but you may occasionally run into problems.\nThe solution is to convert a file from Windows encoding to Unix encoding with:\ndos2unix file\nTo convert a file back to Windows encoding, run:\nunix2dos file",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Transferring files"
    ]
  },
  {
    "objectID": "bash/intro_string.html",
    "href": "bash/intro_string.html",
    "title": "String manipulation",
    "section": "",
    "text": "This section shows how to subset, search, replace, or concatenate strings simply using the Bash variable extraction syntax.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "String manipulation"
    ]
  },
  {
    "objectID": "bash/intro_string.html#getting-a-subset",
    "href": "bash/intro_string.html#getting-a-subset",
    "title": "String manipulation",
    "section": "Getting a subset",
    "text": "Getting a subset\n\nvar=\"hello\"\necho ${var:2}      # Print from character 2\necho ${var:2:1}    # Print 1 character from character 2\n\nllo\nl\n\n\n\nBash indexes from 0.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "String manipulation"
    ]
  },
  {
    "objectID": "bash/intro_string.html#search-and-replace",
    "href": "bash/intro_string.html#search-and-replace",
    "title": "String manipulation",
    "section": "Search and replace",
    "text": "Search and replace\n\nvar=\"hello\"\necho ${var/l/L}    # Replace the first match of l by L\necho ${var//l/L}   # Replace all matches of l by L\n\nheLlo\nheLLo",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "String manipulation"
    ]
  },
  {
    "objectID": "bash/intro_string.html#string-concatenation",
    "href": "bash/intro_string.html#string-concatenation",
    "title": "String manipulation",
    "section": "String concatenation",
    "text": "String concatenation\nIf you want to concatenate the expanded variable with another string, you need to use curly braces or quotes.\n\nThis does not return anything because there is no variable called varshine:\n\n\nvar=sun\necho $varshine\n\n\nThese two syntaxes do work:\n\n\nvar=sun\necho ${var}shine\necho \"$var\"shine\n\nsunshine\nsunshine",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "String manipulation"
    ]
  },
  {
    "objectID": "bash/intro_script.html",
    "href": "bash/intro_script.html",
    "title": "Writing scripts",
    "section": "",
    "text": "There are series of commands that you need to run regularly. Instead of having to type them each time, you can write them in a text file (called a script) with a .sh extension and execute that file whenever you want to run that set of commands. This is a great way to automate work.\nThis section covers scripts syntax and execution."
  },
  {
    "objectID": "bash/intro_script.html#writing-and-executing-scripts",
    "href": "bash/intro_script.html#writing-and-executing-scripts",
    "title": "Writing scripts",
    "section": "Writing and executing scripts",
    "text": "Writing and executing scripts\n\nScripts as arguments to bash\nA shell script is simply a text file. You can create it with a text editor such as nano which is installed on most systems.\nLet‚Äôs try to create one that we will call test.sh:\nnano test.sh\nIn the file, write the command: echo This is my first script.\nThis is the content of our test.sh file:\n\n\ntest.sh\n\necho This is my first script\n\nNow, how do we run this?\nWe simply pass it as an argument to the bash command:\nbash test.sh\nThis is my first script\nAnd it worked!\n\n\nShebang\nThere is another way to write and execute scripts: we can use a shebang.\nA shebang consists of the characters #! followed by the path of an executable. Here, the executable we want is bash and its path is /bin/bash.\nSo our script becomes:\n\n\ntest.sh\n\n#!/bin/bash\n\necho This is my first script.\n\nNow, the cool thing about this is that we don‚Äôt need to pass the script as an argument of the bash command anymore since the information that this should be executed by Bash is already written in the shebang. Instead, we can execute it with ./test.sh.\nBut there is a little twist:\n./test.sh\nbash: ./test.sh: Permission denied\nWe first need to make the file executable by changing its permissions.\n\n\nUnix permissions\nUnix systems such as Linux use POSIX permissions.\nTo add an executable permission to a file, you need to run:\nchmod u+x test.sh\nNow that our script is executable, we can run:\n./test.sh\nThis is my first script\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere and here are two videos of a previous version of this workshop."
  },
  {
    "objectID": "bash/intro_script.html#comments",
    "href": "bash/intro_script.html#comments",
    "title": "Writing scripts",
    "section": "Comments",
    "text": "Comments\nAnything to the right of the symbol # is ignored by the interpreter and is for human consumption only.\n# You can write full-line comments\n\npwd       # You can also write comments after a command\nComments are used to document scripts. DO USE THEM: future you will thank you."
  },
  {
    "objectID": "bash/intro_regexp.html",
    "href": "bash/intro_regexp.html",
    "title": "Regular expressions",
    "section": "",
    "text": "Regular expressions (regex or regexp) are a more powerful system than globing patterns to look for matches of a particular pattern. They are extremely useful and implemented in most programming and scripting languages.\n\nWe do not have time to cover regexp in this course, but there is an excellent site that covers them in detail in a clear fashion.\nThere are many sites such as this that allow you to test your regexps.\nIf you find the syntax daunting, don‚Äôt despair: any LLM (large language model) will tell you what syntax to use. We offered a webinar on this in 2023 with an early version of ChatGPT:",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Regular expressions"
    ]
  },
  {
    "objectID": "bash/intro_functions.html",
    "href": "bash/intro_functions.html",
    "title": "Functions",
    "section": "",
    "text": "As in programming language, shell functions are blocks of code that can be accessed by their names.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Functions"
    ]
  },
  {
    "objectID": "bash/intro_functions.html#function-definition",
    "href": "bash/intro_functions.html#function-definition",
    "title": "Functions",
    "section": "Function definition",
    "text": "Function definition\n\nSyntax\nYou define a new function with the following syntax:\nname() {\n    command1\n    command2\n    ...\n}\n\n\nExample\ngreetings() {\n  echo hello\n}",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Functions"
    ]
  },
  {
    "objectID": "bash/intro_functions.html#storing-functions",
    "href": "bash/intro_functions.html#storing-functions",
    "title": "Functions",
    "section": "Storing functions",
    "text": "Storing functions\nYou can define a new function directly in the terminal. Such function would however only be available during your current session. Since functions contain code that is intended to be run repeatedly, it makes sense to store function definitions in a file. Before functions become available, the file needs to be sourced (e.g.¬†source file.sh).\nA convenient file is ~/.bashrc. The file is automatically sourced every time you start a shell so your functions will always be defined and ready for use.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere is a video of a previous version of this workshop.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Functions"
    ]
  },
  {
    "objectID": "bash/intro_filesystem.html",
    "href": "bash/intro_filesystem.html",
    "title": "The Unix filesystem",
    "section": "",
    "text": "Unix shells allow to give instructions to a Unix operating system. The first thing you will need to know is how storage is organized on such a system.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "The Unix filesystem"
    ]
  },
  {
    "objectID": "bash/intro_filesystem.html#structure",
    "href": "bash/intro_filesystem.html#structure",
    "title": "The Unix filesystem",
    "section": "Structure",
    "text": "Structure\nThe Unix filesystem is a rooted tree of directories. The root is denoted by /.\nSeveral directories exist under the root. Here are a few:\n\n/bin ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇThis is where binaries are stored.\n/boot ‚ÄÉ‚ÄÉ‚ÄÉThere, you can find the files necessary for booting the system.\n/home ‚ÄÉ‚ÄÉ‚ÄÉThis directory contains all the users‚Äô home directories.\n\nThese directories in turn can contain other directories. /home for instance contains the directories:\n\n/home/user01\n/home/user02\n/home/user03\n‚Ä¶\n\nThe home directory of each user in turn contains their files and directories.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "The Unix filesystem"
    ]
  },
  {
    "objectID": "bash/intro_filesystem.html#navigation",
    "href": "bash/intro_filesystem.html#navigation",
    "title": "The Unix filesystem",
    "section": "Navigation",
    "text": "Navigation\n\nWorking directory\nThe current working directory can be obtained with:\npwd\n\nStands for print working directory.\n\n\n\nYour turn:\n\nWhat is your current working directory?\n\n\n\nChanging directory\nTo navigate to another directory, use cd (change directory) followed by the path of the directory.\n\nExample:\n\ncd /home\nBecause /home was the parent directory of our working directory (one level above in the rooted tree), we could have also gotten there with cd .. ‚Äî the two dots represent one level up (a single dot represents the working directory).\n\n\nYour turn:\n\n\nWhat will happen if you run cd .. from /home?\nWhat will happen if you run cd . from /home?\n\n\nFrom any location, you can always go back to your home directory (e.g.¬†/home/user09) by running cd without argument. Alternatively, you can use cd ~. This is because ~ gets expanded by the shell into the path of your home. Finally, you can use cd $HOME. $HOME is an environment variable representing the path of your home.\n\n\nYour turn:\n\nTry using cd - (that‚Äôs the minus sign) a few times. What does this command do?\n\n\n\nAbsolute and relative paths\n\nAbsolute paths give the full path from the root (e.g.¬†/bin, /home/user09/file).\nRelative paths give the path relative to the working directory (e.g.¬†../dir/file, dir/subdir).\n\n\n\nYour turn:\n\nIs ~ an absolute or relative path?\n\n\nIn the filesystem below, the current working directory is /home/user01.\n\nWhat is the output of ls?\nWhat is the output of ls ../..?\nThe output of ls /thesis/src is:\n\n\nls: cannot access ‚Äò/thesis/src‚Äô: No such file or directory\n\n‚ÄÉ‚ÄÉWhy?\n\nWhat are 2 ways to navigate to the results directory?\nFrom the results directory, what are 2 ways to print the content of the src directory?\n\n\n\n\n\n\n\n\n\ncluster\n\n\n\n\nuser01--.bashrc\n\n\n\n\nuser01--.bash_profile\n\n\n\n\nuser01--thesis\n\n\n\n\n/--bin\n\n\n\n\n/--boot\n\n\n\n\n/--home\n\n\n\n\nhome--user01\n\n\n\n\nhome--user02\n\n\n\n\nhome--user03\n\n\n\n\nthesis--data\n\n\n\n\nthesis--ms\n\n\n\n\nthesis--results\n\n\n\n\nthesis--src\n\n\n\n\nresults--graph1\n\n\n\n\nresults--graph2\n\n\n\n\nsrc--script1\n\n\n\n\n.bashrc\n.bashrc\n\n\n\n.bash_profile\n.bash_profile\n\n\n\ngraph1\ngraph1\n\n\n\ngraph2\ngraph2\n\n\n\nscript1\nscript1\n\n\n\nuser01\n\nuser01\n\n\n\n/\n\n/\n\n\n\nbin\n\nbin\n\n\n\nboot\n\nboot\n\n\n\nhome\n\nhome\n\n\n\nuser02\n\nuser02\n\n\n\nuser03\n\nuser03\n\n\n\nthesis\n\nthesis\n\n\n\ndata\n\ndata\n\n\n\nms\n\nms\n\n\n\nresults\n\nresults\n\n\n\nsrc\n\nsrc",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "The Unix filesystem"
    ]
  },
  {
    "objectID": "bash/intro_filesystem.html#creating-files-and-directories",
    "href": "bash/intro_filesystem.html#creating-files-and-directories",
    "title": "The Unix filesystem",
    "section": "Creating files and directories",
    "text": "Creating files and directories\nFiles can be created with a text editor.\n\nExample using nano, a simple text editor available on many systems:\n\nnano newfile.txt\n\nThis opens the text editor ‚Äúnano‚Äù with a blank file. The file actually gets created when you save it from within the text editor.\n\nor with the command touch:\ntouch newfile.txt\n\n\nYour turn:\n\n\nWhat does the command touch do?\n\nHow did you figure it out?\n\nWhat is the content of newfile.txt?\n\nHow did you figure it out?\n\n\ntouch can create multiple files at once:\ntouch file1 file2 file3\nNew directories can be created with mkdir. This command can also accept multiple arguments to create multiple directories at once:\nmkdir dir1 dir2",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "The Unix filesystem"
    ]
  },
  {
    "objectID": "bash/intro_filesystem.html#deleting",
    "href": "bash/intro_filesystem.html#deleting",
    "title": "The Unix filesystem",
    "section": "Deleting",
    "text": "Deleting\nFiles can be deleted with the command rm followed by their paths:\nrm file1 file2\nDirectories can be deleted with rm -r (‚Äúrecursive‚Äù) followed by their paths or‚Äîif they are empty‚Äîwith rmdir:\nrm -r dir1\nrmdir dir2   # only works if dir2 is empty\nBe careful that these commands are irreversible. By default, there is no trash in Linux systems.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "The Unix filesystem"
    ]
  },
  {
    "objectID": "bash/intro_filesystem.html#copying-moving-and-renaming",
    "href": "bash/intro_filesystem.html#copying-moving-and-renaming",
    "title": "The Unix filesystem",
    "section": "Copying, moving, and renaming",
    "text": "Copying, moving, and renaming\nCopying is done with the cp command:\ncp thesis/src/script1 thesis/ms\nMoving and renaming are both done with the mv command:\n# rename script1 to script\nmv thesis/src/script1 thesis/src/script\n\n# move graph1 to the ms directory\nmv thesis/results/graph1 thesis/ms\n# this also works:\n# mv thesis/results/graph1 thesis/ms/graph1\n\n\nYour turn:\n\nWhy is there only one command to move and rename?",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "The Unix filesystem"
    ]
  },
  {
    "objectID": "bash/intro_basics.html",
    "href": "bash/intro_basics.html",
    "title": "Shell basics",
    "section": "",
    "text": "What does it feel like to work in a shell?\nHere is a first basic orientation.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Shell basics"
    ]
  },
  {
    "objectID": "bash/intro_basics.html#the-prompt",
    "href": "bash/intro_basics.html#the-prompt",
    "title": "Shell basics",
    "section": "The prompt",
    "text": "The prompt\nIn command-line interfaces, a command prompt is a sequence of characters indicating that the interpreter is ready to accept input. It can also provide some information (e.g.¬†time, error types, username, hostname, etc.)\nThe Bash prompt is customizable. By default, it gives the username and the hostname, and it ends with the dollar sign ($).",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Shell basics"
    ]
  },
  {
    "objectID": "bash/intro_basics.html#commands",
    "href": "bash/intro_basics.html#commands",
    "title": "Shell basics",
    "section": "Commands",
    "text": "Commands\nBash comes with a number of commands: directives to the shell to perform particular tasks.\n\nExamples of commands:\n\n\nPrint working directory: pwd\nChange directory: cd\nPrint: echo\nPrint content of a file: cat\nList files and directories in working directory: ls\nCopy: cp\nMove or rename: mv\nCreate a new directory: mkdir\nCreate a new file: touch\n\nTo execute a command, you type it, then press the &lt;enter&gt;.\n\n\nYour turn:\n\nRun your first command:\nls\n\n\nCommand options\nCommands come with a number of flags (options).\nSome flags are short (a single hyphen followed by a single letter), others are long (two hyphens followed by a word or a series of words separated by hyphens). Some flags have both a long and short forms (in which case, both are totally equivalent).\n\nExamples of flags for the ls command:\n\n\nList all files and directories (not ignoring hidden files): ls -a or ls --all\nList files and directories in a long format: ls -l\nList files and directories in a human readable format (using units such as K, M, G): ls -h or ls --human-readable\n\nShort flags can be combined and the flag order doesn‚Äôt matter, so the followings are all equivalent:\n\nls -alh\nls -a -l -h\nls -ahl\nls -l -ha\nls --human-readable -al\nls --all --human-readable -l\n‚Ä¶\n\n\n\nCommands documentation\n\nMan pages\nThe manual page for a command can be accessed with the command man:\nman &lt;command&gt;\n\nThe &lt; and &gt; symbols are used to delineate a generic placeholder that you should replace by the value of your choice (here, for instance, man ls).\n\n\nMan pages open in a pager (usually less).\nUseful keybindings when you are in the pager:\nSPACE      scroll one screen down\nb          back one screen\nq          quit the pager\ng          go to the top of the document\n7g         go to line 7 from the top\nG          go to the bottom of the document\n/          search for a term\n           n will take you to the next result\n           N to the previous result\n\n\n\nYour turn:\n\n\nOpen the man page for the ls command.\nNavigate down a few pages, then navigate back up.\nSearch for the first 5 occurrences of the word ‚Äúdirectory‚Äù.\nWhat does ls -r do?\nFinally, leave the pager.\n\n\n\n\nHelp on commands\nHelp for commands can be printed to the standard output (the terminal) with:\n&lt;command&gt; --help\n\n\nYour turn:\n\nPrint the help for the ls command in your terminal.\n\n\n\nType of commands\nTo know the nature of a command (e.g.¬†shell built-in function, an alias that you created, or the path of an utility) run either of:\ncommand -V &lt;command&gt;\ntype &lt;command&gt;\n\n\nYour turn:\n\nWhat is the nature of the pwd command?",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Shell basics"
    ]
  },
  {
    "objectID": "bash/intro_basics.html#shell-keybindings",
    "href": "bash/intro_basics.html#shell-keybindings",
    "title": "Shell basics",
    "section": "Shell keybindings",
    "text": "Shell keybindings\nHere are useful keybindings that you can use in the shell (they all come from the text editor Emacs):\ntab        auto-complete command\nC-l        clear the terminal\nC-p        navigate the command history backward\nC-n        navigate the command history forward\nC-a        go to the beginning of the line\nC-e        go to the end of the line\nC-k        delete to the end of the line\nC-u        delete to the beginning of the line\nC-f        go forward one character\nC-b        go backward one character\nM-f        go forward one word\nM-b        go backward one word\n\nC-l means: press the Ctrl (Windows) or Command key ‚åò (macOS) and l keys at the same time.\nM-f means: press the Alt (Windows) or Option (macOS) and f keys at the same time.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Shell basics"
    ]
  },
  {
    "objectID": "bash/intro_aliases.html",
    "href": "bash/intro_aliases.html",
    "title": "Aliases",
    "section": "",
    "text": "Aliases are a convenient way to assign a custom command to a name. You can use new names or re-assign existing command names.\n\nalias myip=\"ip -json route get 8.8.8.8 | jq -r '.[].prefsrc'\"\nalias ls='ls -F'\nYou can retrieve the definition of an alias by running the alias command without argument. To remove an alias, use unalias.\nYou can use the non-aliased version of a command with \\ (e.g.¬†\\ls).",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Aliases"
    ]
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#ml-allows-to-achieve-previously-impossible-tasks",
    "href": "ai/ws_hss_intro_slides.html#ml-allows-to-achieve-previously-impossible-tasks",
    "title": "Introduction to machine learning for the humanities",
    "section": "ML allows to achieve previously impossible tasks",
    "text": "ML allows to achieve previously impossible tasks\n\nLet‚Äôs take the example of image recognition:\n\nIn typical computing, a programmer writes code that gives a computer detailed instructions of what to do\nCoding all the possible ways‚Äîpixel by pixel‚Äîthat an image can represent, say, a dog is an impossibly large task: there are many breeds of dogs, the image can be a picture, a blurred picture, a drawing, a cartoon, the dog can be in all sorts of positions, wearing clothes, etc.\nThere just aren‚Äôt enough resources to make the traditional programming approach able to create a computer program that can identify a dog in images\nBy feeding a very large number of dog images to a neural network however, we can train that network to recognize dogs in images that it has never seen (without explicitly programming how it does this!)"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#old-concept-new-computing-power",
    "href": "ai/ws_hss_intro_slides.html#old-concept-new-computing-power",
    "title": "Introduction to machine learning for the humanities",
    "section": "Old concept ‚Ä¶ new computing power",
    "text": "Old concept ‚Ä¶ new computing power\nThe concept is everything but new: Arthur Samuel came up with it in 1949 and built a self-learning Checkers-playing program in 1959\n\n\nMachine learning consists of feeding vast amounts of data to algorithms to strengthen pathways, so the excitement for the approach became somewhat dormant due to the lack of computing power and the lack of training data at the time\nThe advent of powerful computers, GPUs, and massive amounts of data have brought the old concept to the forefront\n\n\n\n\n\n\nfrom xkcd.com"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#supervised-learning",
    "href": "ai/ws_hss_intro_slides.html#supervised-learning",
    "title": "Introduction to machine learning for the humanities",
    "section": "Supervised learning",
    "text": "Supervised learning\n\nRegression is a form of supervised learning with continuous outputs\nClassification is supervised learning with discrete outputs\n\nSupervised learning uses training data in the form of example input/output pairs\nGoal\nFind the relationship between inputs and outputs"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#unsupervised-learning",
    "href": "ai/ws_hss_intro_slides.html#unsupervised-learning",
    "title": "Introduction to machine learning for the humanities",
    "section": "Unsupervised learning",
    "text": "Unsupervised learning\nClustering, social network analysis, market segmentation, PCA ‚Ä¶ are all forms of unsupervised learning\nUnsupervised learning uses unlabelled data\nGoal\nFind structure within the data"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#reinforcement-learning",
    "href": "ai/ws_hss_intro_slides.html#reinforcement-learning",
    "title": "Introduction to machine learning for the humanities",
    "section": "Reinforcement learning",
    "text": "Reinforcement learning\nThe algorithm explores by performing random actions and these actions are rewarded or punished (bonus points or penalties)\nThis is how algorithms learn to play games"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#decide-on-an-architecture",
    "href": "ai/ws_hss_intro_slides.html#decide-on-an-architecture",
    "title": "Introduction to machine learning for the humanities",
    "section": "Decide on an architecture",
    "text": "Decide on an architecture\n\nThe architecture won‚Äôt change during training\nThe type of architecture you choose (e.g.¬†CNN, Transformer) depends on the type of data you have (e.g.¬†vision, textual). The depth and breadth of your network depend on the amount of data and computing resource you have"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#set-some-initial-parameters",
    "href": "ai/ws_hss_intro_slides.html#set-some-initial-parameters",
    "title": "Introduction to machine learning for the humanities",
    "section": "Set some initial parameters",
    "text": "Set some initial parameters\n\nYou can initialize them randomly or get much better ones through transfer learning\nWhile the parameters are also part of the model, those will change during training"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#get-some-labelled-data",
    "href": "ai/ws_hss_intro_slides.html#get-some-labelled-data",
    "title": "Introduction to machine learning for the humanities",
    "section": "Get some labelled data",
    "text": "Get some labelled data\n\nWhen we say that we need a lot of data for machine learning, we mean ‚Äúlots of labelled data‚Äù as this is what gets used for training models"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#make-sure-to-keep-some-data-for-testing",
    "href": "ai/ws_hss_intro_slides.html#make-sure-to-keep-some-data-for-testing",
    "title": "Introduction to machine learning for the humanities",
    "section": "Make sure to keep some data for testing",
    "text": "Make sure to keep some data for testing\n\nThose data won‚Äôt be used for training the model. Often people keep around 20% of their data for testing"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#pass-data-and-parameters-through-the-architecture",
    "href": "ai/ws_hss_intro_slides.html#pass-data-and-parameters-through-the-architecture",
    "title": "Introduction to machine learning for the humanities",
    "section": "Pass data and parameters through the architecture",
    "text": "Pass data and parameters through the architecture\n\nThe train data are the inputs and the process of calculating the outputs is the forward pass"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#the-outputs-of-the-model-are-predictions",
    "href": "ai/ws_hss_intro_slides.html#the-outputs-of-the-model-are-predictions",
    "title": "Introduction to machine learning for the humanities",
    "section": "The outputs of the model are predictions",
    "text": "The outputs of the model are predictions"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#compare-those-predictions-to-the-train-labels",
    "href": "ai/ws_hss_intro_slides.html#compare-those-predictions-to-the-train-labels",
    "title": "Introduction to machine learning for the humanities",
    "section": "Compare those predictions to the train labels",
    "text": "Compare those predictions to the train labels\n\nSince our data was labelled, we know what the true outputs are"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#calculate-train-loss",
    "href": "ai/ws_hss_intro_slides.html#calculate-train-loss",
    "title": "Introduction to machine learning for the humanities",
    "section": "Calculate train loss",
    "text": "Calculate train loss\n\nThe deviation of our predictions from the true outputs gives us a measure of training loss"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#adjust-parameters",
    "href": "ai/ws_hss_intro_slides.html#adjust-parameters",
    "title": "Introduction to machine learning for the humanities",
    "section": "Adjust parameters",
    "text": "Adjust parameters\n\nThe parameters get automatically adjusted to reduce the training loss through the mechanism of backpropagation. This is the actual training part\nThis process is repeated many times. Training models is pretty much a giant for loop"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#from-model-to-program",
    "href": "ai/ws_hss_intro_slides.html#from-model-to-program",
    "title": "Introduction to machine learning for the humanities",
    "section": "From model to program",
    "text": "From model to program\n\nRemember that the model architecture is fixed, but that the parameters change at each iteration of the training process"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#section",
    "href": "ai/ws_hss_intro_slides.html#section",
    "title": "Introduction to machine learning for the humanities",
    "section": "¬†",
    "text": "While the labelled data are key to training, what we are really interested in is the combination of architecture + final parameters"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#section-1",
    "href": "ai/ws_hss_intro_slides.html#section-1",
    "title": "Introduction to machine learning for the humanities",
    "section": "¬†",
    "text": "When the training is over, the parameters become fixed. Which means that our model now behaves like a classic program"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#evaluate-the-model",
    "href": "ai/ws_hss_intro_slides.html#evaluate-the-model",
    "title": "Introduction to machine learning for the humanities",
    "section": "Evaluate the model",
    "text": "Evaluate the model\n\nWe can now use the testing set (which was never used to train the model) to evaluate our model: if we pass the test inputs through our program, we get some predictions that we can compare to the test labels (which are the true outputs)\nThis gives us the test loss: a measure of how well our model performs"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#use-the-model",
    "href": "ai/ws_hss_intro_slides.html#use-the-model",
    "title": "Introduction to machine learning for the humanities",
    "section": "Use the model",
    "text": "Use the model\n\nNow that we have a program, we can use it on unlabelled inputs to get what people ultimately want: unknown outputs\nThis is when we put our model to actual use to solve some problem"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#learning",
    "href": "ai/ws_hss_intro_slides.html#learning",
    "title": "Introduction to machine learning for the humanities",
    "section": "Learning",
    "text": "Learning\n\n\nThe process of learning in biological NN happens through neuron death or growth and the creation or loss of synaptic connections between neurons\n\n\n\nIn ANN, learning happens through optimization algorithms such as gradient descent which minimize cross entropy loss functions by adjusting the weights and biases connecting each layer of neurons over many iterations"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#fully-connected-neural-networks",
    "href": "ai/ws_hss_intro_slides.html#fully-connected-neural-networks",
    "title": "Introduction to machine learning for the humanities",
    "section": "Fully connected neural networks",
    "text": "Fully connected neural networks\n\n\n\n\n\nfrom Glosser.ca, Wikipedia\n\n\n\nEach neuron receives inputs from every neuron of the previous layer and passes its output to every neuron of the next layer"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#convolutional-neural-networks",
    "href": "ai/ws_hss_intro_slides.html#convolutional-neural-networks",
    "title": "Introduction to machine learning for the humanities",
    "section": "Convolutional neural networks",
    "text": "Convolutional neural networks\n\nfrom Programming Journeys by Rensu TheartConvolutional neural networks (CNN) are used for spatially structured data (e.g.¬†images)\nImages have huge input sizes and would require a very large number of neurons in a fully connected neural net. In convolutional layers, neurons receive input from a subarea (called local receptive field) of the previous layer. This greatly reduces the number of parameters. Optionally, pooling (combining the outputs of neurons in a subarea) reduces the data dimensions"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#recurrent-neural-networks",
    "href": "ai/ws_hss_intro_slides.html#recurrent-neural-networks",
    "title": "Introduction to machine learning for the humanities",
    "section": "Recurrent neural networks",
    "text": "Recurrent neural networks\n\nfrom fdeloche, WikipediaRecurrent neural networks (RNN) such as Long Short-Term Memory (LSTM) are used for chain structured data (e.g.¬†text)\nThey are not feedforward networks (i.e.¬†networks for which the information moves only in the forward direction without any loop)"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#transformers",
    "href": "ai/ws_hss_intro_slides.html#transformers",
    "title": "Introduction to machine learning for the humanities",
    "section": "Transformers",
    "text": "Transformers\nA combination of two RNNs (the encoder and the decoder) is used in sequence to sequence models for translation or picture captioning\nIn 2014 the concept of attention (giving added weight to important words) was developed, greatly improving the ability of such models to process a lot of data\nThe problem with recurrence is that it is not easily to parallelize (and thus to run fast on GPUs)\nIn 2017, a new model‚Äîthe transformer‚Äîwas proposed: by using only attention mechanisms and no recurrence, the transformer achieves better results in an easily parallelizable fashion\nWith the addition of transfer learning, powerful transformers emerged in the field of NLP (e.g.¬†Bidirectional Encoder Representations from Transformers (BERT) from Google and Generative Pre-trained Transformer-3 (GPT-3) from OpenAI)"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#data-bias",
    "href": "ai/ws_hss_intro_slides.html#data-bias",
    "title": "Introduction to machine learning for the humanities",
    "section": "Data bias",
    "text": "Data bias\nBias is always present in data\nDocument the limitations and scope of your data as best as possible\nProblems to watch for:\n\nOut of domain data: data used for training are not relevant to the model application\nDomain shift: model becoming inadapted as conditions evolve\nFeedback loop: initial bias exacerbated over the time"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#transformation-of-subjects",
    "href": "ai/ws_hss_intro_slides.html#transformation-of-subjects",
    "title": "Introduction to machine learning for the humanities",
    "section": "Transformation of subjects",
    "text": "Transformation of subjects\nAlgorithms are supposed to help us, not transform us (e.g.¬†YouTube recommendation algorithms)"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#bugs",
    "href": "ai/ws_hss_intro_slides.html#bugs",
    "title": "Introduction to machine learning for the humanities",
    "section": "Bugs",
    "text": "Bugs\nExample of bug with real life consequences"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#many-options",
    "href": "ai/ws_hss_intro_slides.html#many-options",
    "title": "Introduction to machine learning for the humanities",
    "section": "Many options",
    "text": "Many options\nHere are just a few:\n\nscikit-learn: a Python ML library built on top of SciPy\nNatural Language Toolkit (NLTK): a suite of Python libraries geared towards teaching and research\nspaCy: Python library geared towards production\ntorchtext, part of the PyTorch project (and many options of added layers on top such as PyTorch-NLP): Python library\nGenSim: Python library\nStanford CoreNLP: Java library\nMany libraries in the Julia programming language"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#which-one-to-choose",
    "href": "ai/ws_hss_intro_slides.html#which-one-to-choose",
    "title": "Introduction to machine learning for the humanities",
    "section": "Which one to choose?",
    "text": "Which one to choose?\nChoose an open source tool (i.e.¬†stay away from proprietary software such as MATLAB)\n\nResearchers who do not have access to the tool cannot reproduce your methods (open tools = open equitable research)\nOnce you graduate, you may not have access to the tool anymore\nYour university may stop paying for a license\nYou may get locked-in\nProprietary tools are often black boxes\nLong-term access is not guaranty (problem to replicate studies)\nThe licenses you have access to may be limiting and a cause of headache\nProprietary tools fall behind popular open-source tools\nProprietary tools often fail to address specialized edge cases needed in research"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#neural-nets",
    "href": "ai/ws_hss_intro_slides.html#neural-nets",
    "title": "Introduction to machine learning for the humanities",
    "section": "Neural nets",
    "text": "Neural nets\n3Blue1Brown by Grant Sanderson has a series of 4 videos on neural networks which is easy to watch, fun, and does an excellent job at introducing the functioning of a simple neural network\n\nWhat are NN? (19 min)\nHow do NN learn? (21 min)\nWhat is backpropagation? (14 min)\nHow does backpropagation work? (10 min)\n\n\nAs you develop your own ML models, if you find that your mathematical background is shaky, 3blue1brown also has an excellent series of videos on linear algebra and an equally great one on calculus"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#open-access-preprints",
    "href": "ai/ws_hss_intro_slides.html#open-access-preprints",
    "title": "Introduction to machine learning for the humanities",
    "section": "Open-access preprints",
    "text": "Open-access preprints\n\nArxiv Sanity Preserver by Andrej Karpathy\nML papers in the computer science category on arXiv\nML papers in the stats category on arXiv\nDistill ML research online journal"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#advice-and-sources",
    "href": "ai/ws_hss_intro_slides.html#advice-and-sources",
    "title": "Introduction to machine learning for the humanities",
    "section": "Advice and sources",
    "text": "Advice and sources\n\nAdvice and sources from ML research student"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#getting-help",
    "href": "ai/ws_hss_intro_slides.html#getting-help",
    "title": "Introduction to machine learning for the humanities",
    "section": "Getting help",
    "text": "Getting help\nStack Overflow:\n\n[machine-learning] tag\n[deep-learning] tag\n[supervised-learning] tag\n[unsupervised-learning] tag\n[semisupervised-learning] tag\n[reinforcement-learning] tag\n[transfer-learning] tag\n[machine-learning-model] tag\n[learning-rate] tag"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#open-datasets",
    "href": "ai/ws_hss_intro_slides.html#open-datasets",
    "title": "Introduction to machine learning for the humanities",
    "section": "Open datasets",
    "text": "Open datasets\n\nbenchmarks.ai\nAIBench\nkaggle\nWikipedia"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#pytorch",
    "href": "ai/ws_hss_intro_slides.html#pytorch",
    "title": "Introduction to machine learning for the humanities",
    "section": "PyTorch",
    "text": "PyTorch\n\nDocumentation\nTutorials\nExamples\n\nGetting help\n\nPyTorch Discourse forum\nStack Overflow [pytorch] tag\n\nPre-trained models\n\nPyTorch Hub"
  },
  {
    "objectID": "ai/ws_hss_intro_slides.html#python",
    "href": "ai/ws_hss_intro_slides.html#python",
    "title": "Introduction to machine learning for the humanities",
    "section": "Python",
    "text": "Python\nIDE\n\nProject Jupyter\nList of IDEs with description\nComparison of IDEs\nEmacs Python IDE\n\nGetting help\n\nStack Overflow [python] tag"
  },
  {
    "objectID": "ai/ws_hss_intro.html",
    "href": "ai/ws_hss_intro.html",
    "title": "Intro to ML for the humanities",
    "section": "",
    "text": "We hear about it all the time, but what really is machine learning? And what about deep learning? Neural networks?? How can any of this help me with my work? And how? Which tools do I need to make use of the transformative advances happening in that field??\nThis workshop will answer these questions in a non-technical manner to give you a high level overview of a discipline that has become crucial in all fields of research.\n\nSlides (Click and wait: the presentation might take a few instants to load) \n\n Slides content for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro ML for the humanities"
    ]
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_content.html",
    "href": "ai/ws_dl_nlp_llm_content.html",
    "title": "Intro to deep learning, NLP, and LLMs",
    "section": "",
    "text": "Content from the workshop slides for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro to DL, NLP, and LLMs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_content.html#definitions",
    "href": "ai/ws_dl_nlp_llm_content.html#definitions",
    "title": "Intro to deep learning, NLP, and LLMs",
    "section": "Definitions",
    "text": "Definitions\n\nArtificial intelligence (AI)\nAny human-made system mimicking animal intelligence. This is a large and very diverse field.\n\n\nMachine learning (ML)\nA subfield of AI that can be defined as computer programs whose performance at a task improves with experience. This includes statistical inference and deep learning.\n\n\nDeep learning (DL)\nA subfield of ML using artificial neural networks with two or more hidden layers.\n\n\nNatural language processing (NLP)\nA subfield of AI focused on human languages. It can use statistical inference or deep learning.",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro to DL, NLP, and LLMs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_content.html#why-has-ml-become-so-popular",
    "href": "ai/ws_dl_nlp_llm_content.html#why-has-ml-become-so-popular",
    "title": "Intro to deep learning, NLP, and LLMs",
    "section": "Why has ML become so popular?",
    "text": "Why has ML become so popular?\n\nNew types of tasks\nML allows to achieve previously impossible tasks.\n\nLet‚Äôs take the example of image recognition:\n\nIn typical computing, a programmer writes code that gives a computer detailed instructions of what to do.\nCoding all the possible ways‚Äîpixel by pixel‚Äîthat an image can represent, say, a dog is an impossibly large task: there are many breeds of dogs, the image can be a picture, a blurred picture, a drawing, a cartoon, the dog can be in all sorts of positions, wearing clothes, etc.\nThere just aren‚Äôt enough resources to make the traditional programming approach able to create a computer program that can identify a dog in images.\nBy feeding a very large number of dog images to a neural network however, we can train that network to recognize dogs in images that it has never seen (without explicitly programming how it does this!).\n\n\nOld concept ‚Ä¶\n‚Ä¶ new computing power.\nThe concept is everything but new: Arthur Samuel came up with it in 1949 and built a self-learning Checkers-playing program in 1959.\n\n\n\nMachine learning consists of feeding vast amounts of data to algorithms to strengthen pathways, so the excitement for the approach became somewhat dormant due to the lack of computing power and the lack of training data at the time.\n The advent of powerful computers, GPUs, and massive amounts of data have brought the old concept to the forefront.\n\n\n\n\n\n\nFrom xkcd.com",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro to DL, NLP, and LLMs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_content.html#so-how-does-it-all-work",
    "href": "ai/ws_dl_nlp_llm_content.html#so-how-does-it-all-work",
    "title": "Intro to deep learning, NLP, and LLMs",
    "section": "So how does it all work?",
    "text": "So how does it all work?\nIt depends on the type of learning.\n\nSupervised learning\n\nRegression is a form of supervised learning with continuous outputs.\nClassification is supervised learning with discrete outputs.\n\nSupervised learning uses training data in the form of example input/output pairs.\nGoal: find the relationship between inputs and outputs.\n\n\nUnsupervised learning\nClustering, social network analysis, market segmentation, PCA ‚Ä¶ are all forms of unsupervised learning.\nUnsupervised learning uses unlabelled data.\nGoal: find structure within the data.\n\n\nReinforcement learning\nThe algorithm explores by performing random actions and these actions are rewarded or punished (bonus points or penalties).\nThis is how algorithms learn to play games.",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro to DL, NLP, and LLMs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_content.html#the-case-of-supervised-learning",
    "href": "ai/ws_dl_nlp_llm_content.html#the-case-of-supervised-learning",
    "title": "Intro to deep learning, NLP, and LLMs",
    "section": "The case of supervised learning",
    "text": "The case of supervised learning\n\nDecide on an architecture\n\nThe architecture won‚Äôt change during training.\nThe type of architecture you choose (e.g.¬†CNN, Transformer) depends on the type of data you have (e.g.¬†vision, textual). The depth and breadth of your network depend on the amount of data and computing resource you have.\n\n\nSet some initial parameters\n\nYou can initialize them randomly or get much better ones through transfer learning.\nWhile the parameters are also part of the model, those will change during training.\n\n\nGet some labelled data\n\nWhen we say that we need a lot of data for machine learning, we mean ‚Äúlots of labelled data‚Äù as this is what gets used for training models.\n\n\nMake sure to keep data for testing\n\nThose data won‚Äôt be used for training the model. Often people keep around 20% of their data for testing.\n\n\nPass data and parameters\n\nThe train data are the inputs and the process of calculating the outputs is the forward pass.\n\n\nThe outputs are predictions\n\n\n\nCompare predictions with labels\n\nSince our data was labelled, we know what the true outputs are.\n\n\nCalculate train loss\n\nThe deviation of our predictions from the true outputs gives us a measure of training loss.\n\n\nAdjust parameters\n\nThe parameters get automatically adjusted to reduce the training loss through the mechanism of backpropagation. This is the actual training part.\nThis process is repeated many times. Training models is pretty much a giant for loop.\n\n\nFrom model to program\n\nRemember that the model architecture is fixed, but that the parameters change at each iteration of the training process.\n\nWhile the labelled data are key to training, what we are really interested in is the combination of architecture + final parameters.\n\nWhen the training is over, the parameters become fixed. Which means that our model now behaves like a classic program.\n\n\nEvaluate the model\n\nWe can now use the testing set (which was never used to train the model) to evaluate our model: if we pass the test inputs through our program, we get some predictions that we can compare to the test labels (which are the true outputs).\nThis gives us the test loss: a measure of how well our model performs.\n\n\nUse the model\n\nNow that we have a program, we can use it on unlabelled inputs to get what people ultimately want: unknown outputs.\nThis is when we put our model to actual use to solve some problem.",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro to DL, NLP, and LLMs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_content.html#artificial-neural-networks",
    "href": "ai/ws_dl_nlp_llm_content.html#artificial-neural-networks",
    "title": "Intro to deep learning, NLP, and LLMs",
    "section": "Artificial neural networks",
    "text": "Artificial neural networks\n\n\n\nIn biological networks, the information consists of action potentials (neuron membrane rapid depolarizations) propagating through the network. In artificial ones, the information consists of tensors (multidimensional arrays) of weights and biases: each unit passes a weighted sum of an input tensor with an additional‚Äîpossibly weighted‚Äîbias through an activation function before passing on the output tensor to the next layer of units.\n\n\n\n\nArtificial neural networks are a series of layered units mimicking the concept of biological neurons: inputs are received by every unit of a layer, computed, then transmitted to units of the next layer. In the process of learning, experience strengthens some connections between units and weakens others.\n\n\n\n\n\n\nSchematic of a biological neuron:\n\n\n\n\nFrom Dhp1080, Wikipedia\n\n\n\n\n\nSchematic of an artificial neuron:\n\n\n\n\nModified from O.C. Akgun & J. Mei 2019\n\n\n\n\nWhile biological neurons are connected in extremely intricate patterns, artificial ones follow a layered structure. Another difference in complexity is in the number of units: the human brain has 65‚Äì90 billion neurons. ANN have much fewer units.\n\n\n\n\nNeurons in mouse cortex:\n\n\n\n\nNeurons are in green, the dark branches are blood vessels. Image by Na Ji, UC Berkeley\n\n\n\n\n\nNeural network with 2 hidden layers:\n\n\n\n\nFrom The Maverick Meerkat\n\n\n\n\nThe information in biological neurons is an all-or-nothing electrochemical pulse or action potential. Greater stimuli don‚Äôt produce stronger signals but increase firing frequency. In contrast, artificial neurons pass the computation of their inputs through an activation function and the output can take any of the values possible with that function.\n\n\n\nThreshold potential in biological neurons:\n\n\n\n\nModified from Blacktc, Wikimedia\n\n\n\n\nSome common activation functions in ANNs:\n\n\n\n\nFrom Diganta Misra 2019\n\n\n\n\n\nLearning\n\n\nThe process of learning in biological NN happens through neuron death or growth and the creation or loss of synaptic connections between neurons.\n\n\n\nIn ANN, learning happens through optimization algorithms such as gradient descent which minimize cross entropy loss functions by adjusting the weights and biases connecting each layer of neurons over many iterations.",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro to DL, NLP, and LLMs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_content.html#types-of-ann",
    "href": "ai/ws_dl_nlp_llm_content.html#types-of-ann",
    "title": "Intro to deep learning, NLP, and LLMs",
    "section": "Types of ANN",
    "text": "Types of ANN\n\nFully connected neural networks\n\n\n\n\n\nFrom Glosser.ca, Wikipedia\n\n\n\nEach neuron receives inputs from every neuron of the previous layer and passes its output to every neuron of the next layer.\n\n\n\n\nConvolutional neural networks\n\n\n\nFrom Programming Journeys by Rensu Theart\n\n\nConvolutional neural networks (CNN) are used for spatially structured data (e.g.¬†images).\nImages have huge input sizes and would require a very large number of neurons in a fully connected neural net. In convolutional layers, neurons receive input from a subarea (called local receptive field) of the previous layer. This greatly reduces the number of parameters. Optionally, pooling (combining the outputs of neurons in a subarea) reduces the data dimensions.\n\n\nRecurrent neural networks\n\n\n\nFrom fdeloche, Wikipedia\n\n\nRecurrent neural networks (RNN) such as Long Short-Term Memory (LSTM) are used for chain structured data (e.g.¬†text).\nThey are not feedforward networks (i.e.¬†networks for which the information moves only in the forward direction without any loop).\n\n\nTransformers\nA combination of two RNNs (the encoder and the decoder) is used in sequence to sequence models for translation or picture captioning.\nIn 2014 the concept of attention (giving added weight to important words) was developed, greatly improving the ability of such models to process a lot of data.\nThe problem with recurrence is that it is not easily to parallelize (and thus to run fast on GPUs).\nIn 2017, a new model‚Äîthe transformer‚Äîwas proposed: by using only attention mechanisms and no recurrence, the transformer achieves better results in an easily parallelizable fashion.\nWith the addition of transfer learning, powerful transformers emerged in the field of NLP (e.g.¬†Bidirectional Encoder Representations from Transformers (BERT) from Google and Generative Pre-trained Transformer-3 (GPT-3) from OpenAI).",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro to DL, NLP, and LLMs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_content.html#ml-limitations",
    "href": "ai/ws_dl_nlp_llm_content.html#ml-limitations",
    "title": "Intro to deep learning, NLP, and LLMs",
    "section": "ML limitations",
    "text": "ML limitations\n\nData bias\nBias is always present in data.\nDocument the limitations and scope of your data as best as possible.\nProblems to watch for:\n\nOut of domain data: data used for training are not relevant to the model application.\nDomain shift: model becoming inadapted as conditions evolve.\nFeedback loop: initial bias exacerbated over the time.\n\n\n\nThe last one is particularly problematic whenever the model outputs the next round of data based on interactions of the current round of data with the real world.\nSolution: ensure there are human circuit breakers and oversight.\n\n\n\n\n\n\nFrom xkcd.com\n\n\n\n\n\n\nTransformation of subjects\nAlgorithms are supposed to help us, not transform us (e.g.¬†YouTube recommendation algorithms).\n\n\nBugs\nExample of bug with real life consequences",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro to DL, NLP, and LLMs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_content.html#natural-language-processing",
    "href": "ai/ws_dl_nlp_llm_content.html#natural-language-processing",
    "title": "Intro to deep learning, NLP, and LLMs",
    "section": "Natural language processing",
    "text": "Natural language processing\n\nWhat is NLP?\nNatural language processing is simply the application of machine learning to human (natural) language.\n\n\nApplications\n\nSpam detection\nTranslation\nSentiment analysis\nPredictive text\nText classification\nSpeech recognition\nNatural language generation\nChatbots\nSearch results\n\n\n\nData processing\n\nTokenization: split text into sentences (sentence tokenization) and words (word tokenization).\nRemove punctuation and stopwords (e.g.¬†‚Äúthe‚Äù, ‚Äúa‚Äù, ‚Äúand‚Äù, ‚Äúis‚Äù, ‚Äúare‚Äù).\nTurn all words to lower case.\nKeep only the lemma of words (lemmatization).\n\n\nAn alternative and simpler method is stemming.\n\n\nIdentify word collocations (groups of words that often occur together, such as the bigrams ‚ÄúUnited States‚Äù or ‚Äúopen source‚Äù)\nTagging\nModel training",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro to DL, NLP, and LLMs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_content.html#tools",
    "href": "ai/ws_dl_nlp_llm_content.html#tools",
    "title": "Intro to deep learning, NLP, and LLMs",
    "section": "Tools",
    "text": "Tools\n\nMany options\nHere are just a few:\n\nscikit-learn: a Python ML library built on top of SciPy.\nNatural Language Toolkit (NLTK): a suite of Python libraries geared towards teaching and research.\nspaCy: Python library geared towards production.\ntorchtext, part of the PyTorch project (and many options of added layers on top such as PyTorch-NLP): Python library.\nGenSim: Python library.\nStanford CoreNLP: Java library.\nMany libraries in the Julia programming language.\n\n\n\nWhich one to choose?\nChoose an open source tool (i.e.¬†stay away from proprietary software such as MATLAB).\n\nResearchers who do not have access to the tool cannot reproduce your methods (open tools = open equitable research).\nOnce you graduate, you may not have access to the tool anymore.\nYour university may stop paying for a license.\nYou may get locked-in.\nProprietary tools are often black boxes.\nLong-term access is not guaranty (problem to replicate studies).\nThe licenses you have access to may be limiting and a cause of headache.\nProprietary tools fall behind popular open-source tools.\nProprietary tools often fail to address specialized edge cases needed in research.",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro to DL, NLP, and LLMs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_content.html#resources",
    "href": "ai/ws_dl_nlp_llm_content.html#resources",
    "title": "Intro to deep learning, NLP, and LLMs",
    "section": "Resources",
    "text": "Resources\n\nNeural nets\n3Blue1Brown by Grant Sanderson has a series of 4 videos on neural networks which is easy to watch, fun, and does an excellent job at introducing the functioning of a simple neural network:\n\nWhat are NN? (19 min)\nHow do NN learn? (21 min)\nWhat is backpropagation? (14 min)\nHow does backpropagation work? (10 min)\n\n\nAs you develop your own ML models, if you find that your mathematical background is shaky, 3blue1brown also has an excellent series of videos on linear algebra and an equally great one on calculus.\n\n\n\nOpen-access preprints\n\nArxiv Sanity Preserver by Andrej Karpathy\nML papers in the computer science category on arXiv\nML papers in the stats category on arXiv\nDistill ML research online journal\n\n\n\nAdvice and sources\n\nAdvice and sources from ML research student\n\n\n\nGetting help\nStack Overflow:\n\n[machine-learning] tag\n[deep-learning] tag\n[supervised-learning] tag\n[unsupervised-learning] tag\n[semisupervised-learning] tag\n[reinforcement-learning] tag\n[transfer-learning] tag\n[machine-learning-model] tag\n[learning-rate] tag\n\n\n\nOpen datasets\n\nbenchmarks.ai\nAIBench\nkaggle\nWikipedia\n\n\n\nPyTorch\n\nDocumentation\nTutorials\nExamples\n\n\nGetting help\n\nPyTorch Discourse forum\nStack Overflow [pytorch] tag\n\n\n\nPre-trained models\n\nPyTorch Hub\n\n\n\n\nPython\n\nIDE\n\nProject Jupyter\nList of IDEs with description\nComparison of IDEs\nEmacs Python IDE\n\n\n\nGetting help\n\nStack Overflow [python] tag",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro to DL, NLP, and LLMs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/wb_frameworks_slides.html#disclaimers",
    "href": "ai/wb_frameworks_slides.html#disclaimers",
    "title": "A map of current ML frameworks",
    "section": "Disclaimers",
    "text": "Disclaimers\nKeeping up with the ever evolving field of machine learning is daunting. This webinar aims to bring a little help in this navigation and maybe inspire you to explore new tools. It is however flawed in several ways:\n\nit is not exhaustive and focuses on the most used frameworks accessible through 3 popular languages,\na lot of the content could be accused of being biased and subjective,\nit will be outdated quickly.\n\nUltimately, the best frameworks are the ones that work best for you and your needs. The only piece of advice I would give is to always use open source tools."
  },
  {
    "objectID": "ai/wb_frameworks.html",
    "href": "ai/wb_frameworks.html",
    "title": "A map of current ML frameworks",
    "section": "",
    "text": "We are in a period of active development of new deep learning techniques, adding to the already mature area of traditional machine learning. This is leading to a vast and ever evolving field of implementations which can be disorienting.\nIn this webinar, I will guide you through a map of the current frameworks, organizing them based on their domain (machine learning vs deep learning) and the languages required to use them. I will also talk about the various automatic differentiation options available.\nTo narrow such a large topic, I am limiting the map to frameworks that can be used from Python, Julia, and R.\n\nSlides (Click and wait: this reveal.js presentation is heavy and takes some time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Current ML frameworks"
    ]
  },
  {
    "objectID": "ai/wb_dvc_slides.html#on-version-control",
    "href": "ai/wb_dvc_slides.html#on-version-control",
    "title": "Version control for data science & machine learning with DVC",
    "section": "On version control",
    "text": "On version control\nI won‚Äôt introduce here the benefits of using a good version control system such as Git\n\n\n\nOn the benefits of VCS"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#extending-git-for-data",
    "href": "ai/wb_dvc_slides.html#extending-git-for-data",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Extending Git for data",
    "text": "Extending Git for data\nWhile Git is a wonderful tool for text files versioning (code, writings in markup formats), it isn‚Äôt a tool to manage changes to datasets\nSeveral open source tools‚Äîeach with a different structure and functioning‚Äîextend Git capabilities to track data: Git LFS, git-annex, lakeFS, Dolt, DataLad"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#extending-git-for-models-and-experiments",
    "href": "ai/wb_dvc_slides.html#extending-git-for-models-and-experiments",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Extending Git for models and experiments",
    "text": "Extending Git for models and experiments\nReproducible research and collaboration on data science and machine learning projects involve more than datasets management:\nExperiments and the models they produce also need to be tracked"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#many-moving-parts",
    "href": "ai/wb_dvc_slides.html#many-moving-parts",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Many moving parts",
    "text": "Many moving parts\n\n*hp = hyperparameter\n\n\n\n\n\n\n\n\n\n\ndata1\n\ndata1\n\n\n\nmodel1\n\nmodel1\n\n\n\ndata1-&gt;model1\n\n\n\n\n\nmodel2\n\nmodel2\n\n\n\ndata1-&gt;model2\n\n\n\n\n\nmodel3\n\nmodel3\n\n\n\ndata1-&gt;model3\n\n\n\n\n\ndata2\n\ndata2\n\n\n\ndata2-&gt;model1\n\n\n\n\n\ndata2-&gt;model2\n\n\n\n\n\ndata2-&gt;model3\n\n\n\n\n\ndata3\n\ndata3\n\n\n\ndata3-&gt;model1\n\n\n\n\n\ndata3-&gt;model2\n\n\n\n\n\ndata3-&gt;model3\n\n\n\n\n\nhp1\n\nhp1\n\n\n\nhp1-&gt;model1\n\n\n\n\n\nhp1-&gt;model2\n\n\n\n\n\nhp1-&gt;model3\n\n\n\n\n\nhp2\n\nhp2\n\n\n\nhp2-&gt;model1\n\n\n\n\n\nhp2-&gt;model2\n\n\n\n\n\nhp2-&gt;model3\n\n\n\n\n\nhp3\n\nhp3\n\n\n\nhp3-&gt;model1\n\n\n\n\n\nhp3-&gt;model2\n\n\n\n\n\nhp3-&gt;model3\n\n\n\n\n\nperformance\n\nperformance1 ... performance27\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\n\n\n\n\n\n\nHow did we get performance17 again? ü§Ø"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#dvc-principles",
    "href": "ai/wb_dvc_slides.html#dvc-principles",
    "title": "Version control for data science & machine learning with DVC",
    "section": "DVC principles",
    "text": "DVC principles\nLarge files (datasets, models‚Ä¶) are kept outside Git\nEach large file or directory put under DVC tracking has an associated .dvc file\nGit only tracks the .dvc files (metadata)\n\nWorkflows can be tracked for collaboration and reproducibility\n\n\nDVC functions as a Makefile and allows to only rerun what is necessary"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#installation",
    "href": "ai/wb_dvc_slides.html#installation",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Installation",
    "text": "Installation\nFor Linux (other OSes, refer to the doc):\n\npip:\npip install dvc\nconda\npipx (if you want dvc available everywhere without having to activate virtual envs):\npipx install dvc\n\n\nOptional dependencies [s3], [gdrive], etc. for remote storage"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#how-to-run",
    "href": "ai/wb_dvc_slides.html#how-to-run",
    "title": "Version control for data science & machine learning with DVC",
    "section": "How to run",
    "text": "How to run\nMultiple options:\n\nTerminal:\ndvc ...\nVS Code extension\nPython library if installed via pip or conda:\nimport dvc.api\n\n\nIn this webinar, I will use DVC through the command line"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#acknowledgements",
    "href": "ai/wb_dvc_slides.html#acknowledgements",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nCode and data for this webinar modified from:\n\nReal Python\nDataLad handbook\nDVC documentation"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#the-project",
    "href": "ai/wb_dvc_slides.html#the-project",
    "title": "Version control for data science & machine learning with DVC",
    "section": "The project",
    "text": "The project\ntree -L 3\n‚îú‚îÄ‚îÄ LICENSE\n‚îú‚îÄ‚îÄ data\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ prepared\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ raw\n‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ train\n‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ val\n‚îú‚îÄ‚îÄ metrics\n‚îú‚îÄ‚îÄ model\n‚îú‚îÄ‚îÄ requirements.txt\n‚îî‚îÄ‚îÄ src\n    ‚îú‚îÄ‚îÄ evaluate.py\n    ‚îú‚îÄ‚îÄ prepare.py\n    ‚îî‚îÄ‚îÄ train.py"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#initialize-git-repo",
    "href": "ai/wb_dvc_slides.html#initialize-git-repo",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Initialize Git repo",
    "text": "Initialize Git repo\ngit init\nInitialized empty Git repository in dvc/.git/\n\nThis creates the .git directory\n\n\ngit status\nOn branch main\n\nNo commits yet\n\nUntracked files:\n    LICENSE\n    data/\n    requirements.txt\n    src/"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#initialize-dvc-project",
    "href": "ai/wb_dvc_slides.html#initialize-dvc-project",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Initialize DVC project",
    "text": "Initialize DVC project\ndvc init\nInitialized DVC repository.\n\nYou can now commit the changes to git.\n\nYou will also see a note about usage analytics collection and info on how to opt out\n\n\nA .dvc directory and a .dvcignore file got created"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#commit-dvc-system-files",
    "href": "ai/wb_dvc_slides.html#commit-dvc-system-files",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Commit DVC system files",
    "text": "Commit DVC system files\nDVC automatically staged its system file for us:\ngit status\nOn branch main\n\nNo commits yet\n\nChanges to be committed:\n    new file:   .dvc/.gitignore\n    new file:   .dvc/config\n    new file:   .dvcignore\n\nUntracked files:\n    LICENSE\n    data/\n    requirements.txt\n    src/"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#commit-dvc-system-files-1",
    "href": "ai/wb_dvc_slides.html#commit-dvc-system-files-1",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Commit DVC system files",
    "text": "Commit DVC system files\nSo we can directly commit:\ngit commit -m \"Initialize DVC\""
  },
  {
    "objectID": "ai/wb_dvc_slides.html#prepare-repo",
    "href": "ai/wb_dvc_slides.html#prepare-repo",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Prepare repo",
    "text": "Prepare repo\nLet‚Äôs work in a virtual environment:\n# Create venv and add to .gitignore\npython -m venv venv && echo venv &gt; .gitignore\n\n# Activate venv\nsource venv/bin/activate\n\n# Update pip\npython -m pip install --upgrade pip\n\n# Install packages needed\npython -m pip install -r requirements.txt"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#clean-working-tree",
    "href": "ai/wb_dvc_slides.html#clean-working-tree",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Clean working tree",
    "text": "Clean working tree\ngit add .gitignore LICENSE requirements.txt\ngit commit -m \"Add general files\"\ngit add src\ngit commit -m \"Add scripts\"\ngit status\nOn branch main\nUntracked files:\n    data/\n\n\nNow, it is time to deal with the data"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#put-data-under-dvc-tracking",
    "href": "ai/wb_dvc_slides.html#put-data-under-dvc-tracking",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Put data under DVC tracking",
    "text": "Put data under DVC tracking\nWe are still not tracking any data:\ndvc status\nThere are no data or pipelines tracked in this project yet.\nYou can choose what to track as a unit (i.e.¬†each picture individually, the whole data directory as a unit)\nLet‚Äôs break it down by set:\ndvc add data/raw/train\ndvc add data/raw/val"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#section",
    "href": "ai/wb_dvc_slides.html#section",
    "title": "Version control for data science & machine learning with DVC",
    "section": "",
    "text": "This adds data to .dvc/cache/files and created 3 files in data/raw:\n\n.gitignore\ntrain.dvc\nval.dvc\n\nThe .gitignore tells Git not to track the data:\ncat data/raw/.gitignore\n/train\n/val\nThe .dvc files contain the metadata for the cached directories"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#tracked-data",
    "href": "ai/wb_dvc_slides.html#tracked-data",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Tracked data",
    "text": "Tracked data\nWe are all good:\ndvc status\nData and pipelines are up to date."
  },
  {
    "objectID": "ai/wb_dvc_slides.html#data-deduplication",
    "href": "ai/wb_dvc_slides.html#data-deduplication",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Data (de)duplication",
    "text": "Data (de)duplication\nLink between checked-out version of a file/directory and the cache:\n\nCache ‚ü∑ working directory\n\n\n\n\n\n\n\n\nDuplication\nEditable\n\n\n\n\nReflinks*\nOnly when needed\nYes\n\n\nHardlinks/Symlinks\nNo\nNo\n\n\nCopies\nYes\nYes\n\n\n\n\n*Reflinks only available for a few file systems (Btrfs, XFS, OCFS2, or APFS)"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#commit-the-metafiles",
    "href": "ai/wb_dvc_slides.html#commit-the-metafiles",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Commit the metafiles",
    "text": "Commit the metafiles\nThe metafiles should be put under Git version control\n\nYou can configure DVC to automatically stage its newly created system files:\ndvc config [--system] [--global] core.autostage true\n\nYou can then commit directly:\ngit commit -m \"Initial version of data\"\ngit status\nOn branch main\nnothing to commit, working tree clean"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#track-changes-to-the-data",
    "href": "ai/wb_dvc_slides.html#track-changes-to-the-data",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Track changes to the data",
    "text": "Track changes to the data\nLet‚Äôs make some change to the data:\nrm data/raw/val/n03445777/ILSVRC2012_val*\n\nRemember that Git is not tracking the data:\ngit status\nOn branch main\nnothing to commit, working tree clean\n\n\nBut DVC is:\ndvc status\ndata/raw/val.dvc:\n    changed outs:\n            modified:           data/raw/val"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#add-changes-to-dvc",
    "href": "ai/wb_dvc_slides.html#add-changes-to-dvc",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Add changes to DVC",
    "text": "Add changes to DVC\ndvc add data/raw/val\ndvc status\nData and pipelines are up to date.\n\nNow we need to commit the changes to the .dvc file to Git:\ngit status\nOn branch main\nChanges to be committed:\n    modified:   data/raw/val.dvc\n\nStaging happened automatically because I have set the autostage option to true on my system\n\ngit commit -m \"Delete data/raw/val/n03445777/ILSVRC2012_val*\""
  },
  {
    "objectID": "ai/wb_dvc_slides.html#check-out-older-versions",
    "href": "ai/wb_dvc_slides.html#check-out-older-versions",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Check out older versions",
    "text": "Check out older versions\nWhat if we want to go back to the 1st version of our data?\nFor this, we first use Git to checkout the proper commit, then run dvc checkout to have the data catch up to the .dvc file\nTo avoid forgetting to run the commands that will make DVC catch up to Git, we can automate this process by installing Git hooks:\ndvc install"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#git-workflows",
    "href": "ai/wb_dvc_slides.html#git-workflows",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Git workflows",
    "text": "Git workflows\ngit checkout is ok to have a look, but a detached HEAD is not a good place to create new commits\nLet‚Äôs create a new branch and switch to it:\ngit switch -c alternative\nSwitched to a new branch 'alternative'\nGoing back and forth between both versions of our data is now as simple as switching branch:\ngit switch main\ngit switch alternative"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#classic-workflow",
    "href": "ai/wb_dvc_slides.html#classic-workflow",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Classic workflow",
    "text": "Classic workflow\nThe Git project (including .dvc files) go to a Git remote (GitHub/GitLab/Bitbucket/server)\nThe data go to a DVC remote (AWS/Azure/Google Drive/server/etc.)"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#dvc-remotes",
    "href": "ai/wb_dvc_slides.html#dvc-remotes",
    "title": "Version control for data science & machine learning with DVC",
    "section": "DVC remotes",
    "text": "DVC remotes\nDVC can use many cloud storage or remote machines/server via SSH, WebDAV, etc.\nLet‚Äôs create a local remote here:\n# Create a directory outside the project\nmkdir ../remote\n\n# Setup default (-d) remote\ndvc remote add -d local_remote ../remote\nSetting 'local_remote' as a default remote.\ncat .dvc/config\n[core]\n    remote = local_remote\n['remote \"local_remote\"']\n    url = ../../remote"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#commit-remote-config",
    "href": "ai/wb_dvc_slides.html#commit-remote-config",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Commit remote config",
    "text": "Commit remote config\nThe new remote configuration should be committed:\ngit status\nOn branch alternative\n\nChanges not staged for commit:\n    modified:   .dvc/config\ngit add .\ngit commit -m \"Config remote\""
  },
  {
    "objectID": "ai/wb_dvc_slides.html#push-to-remotes",
    "href": "ai/wb_dvc_slides.html#push-to-remotes",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Push to remotes",
    "text": "Push to remotes\nLet‚Äôs push the data from the cache (.dvc/cache) to the remote:\ndvc push\n2702 files pushed\n\nWith Git hooks installed, dvc push is automatically run after git push\n(But the data is pushed to the DVC remote while the files tracked by Git get pushed to the Git remote)\n\nBy default, the entire data cache gets pushed to the remote, but there are many options\n\nExample: only push data corresponding to a certain .dvc files\ndvc push data/raw/val.dvc"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#pull-from-remotes",
    "href": "ai/wb_dvc_slides.html#pull-from-remotes",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Pull from remotes",
    "text": "Pull from remotes\ndvc fetch downloads data from the remote into the cache. To have it update the working directory, follow by dvc checkout\nYou can do these 2 commands at the same time with dvc pull"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#dvc-pipelines",
    "href": "ai/wb_dvc_slides.html#dvc-pipelines",
    "title": "Version control for data science & machine learning with DVC",
    "section": "DVC pipelines",
    "text": "DVC pipelines\nDVC pipelines create reproducible workflows and are functionally similar to Makefiles\nEach step in a pipeline is created with dvc stage add and add an entry to a dvc.yaml file\n\ndvc stage add options:\n-n: name of stage\n-d: dependency\n-o: output\n\n\nEach stage contains:\n\ncmd: the command executed\ndeps: the dependencies\nouts: the outputs\n\nThe file is then used to visualize the pipeline and run it"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#example",
    "href": "ai/wb_dvc_slides.html#example",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Example",
    "text": "Example\nLet‚Äôs create a pipeline to run a classifier on our data\nThe pipeline contains 3 steps:\n\nprepare\ntrain\nevaluate"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#create-a-pipeline",
    "href": "ai/wb_dvc_slides.html#create-a-pipeline",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Create a pipeline",
    "text": "Create a pipeline\n1st stage (data preparation):\ndvc stage add -n prepare -d src/prepare.py -d data/raw \\\n    -o data/prepared/train.csv -o data/prepared/test.csv \\\n    python src/prepare.py\nAdded stage 'prepare' in 'dvc.yaml'"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#create-a-pipeline-1",
    "href": "ai/wb_dvc_slides.html#create-a-pipeline-1",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Create a pipeline",
    "text": "Create a pipeline\n2nd stage (training)\ndvc stage add -n train -d src/train.py -d data/prepared/train.csv \\\n    -o model/model.joblib \\\n    python src/train.py\nAdded stage `train` in 'dvc.yaml'"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#create-a-pipeline-2",
    "href": "ai/wb_dvc_slides.html#create-a-pipeline-2",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Create a pipeline",
    "text": "Create a pipeline\n3rd stage (evaluation)\ndvc stage add -n evaluate -d src/evaluate.py -d model/model.joblib \\\n    -M metrics/accuracy.json \\\n    python src/evaluate.py\nAdded stage `evaluate` in 'dvc.yaml'"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#commit-pipeline",
    "href": "ai/wb_dvc_slides.html#commit-pipeline",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Commit pipeline",
    "text": "Commit pipeline\ngit commit -m \"Define pipeline\"\nprepare:\n    changed deps:\n            modified:           data/raw\n            modified:           src/prepare.py\n    changed outs:\n            deleted:            data/prepared/test.csv\n            deleted:            data/prepared/train.csv\ntrain:\n    changed deps:\n            deleted:            data/prepared/train.csv\n            modified:           src/train.py\n    changed outs:\n            deleted:            model/model.joblib\nevaluate:\n    changed deps:\n            deleted:            model/model.joblib\n            modified:           src/evaluate.py\n    changed outs:\n            deleted:            metrics/accuracy.json\n[main 4aa331b] Define pipeline\n 3 files changed, 27 insertions(+)\n create mode 100644 data/prepared/.gitignore\n create mode 100644 dvc.yaml\n create mode 100644 model/.gitignore"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#visualize-pipeline-in-a-dag",
    "href": "ai/wb_dvc_slides.html#visualize-pipeline-in-a-dag",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Visualize pipeline in a DAG",
    "text": "Visualize pipeline in a DAG\ndvc dag\n+--------------------+         +------------------+\n| data/raw/train.dvc |         | data/raw/val.dvc |\n+--------------------+         +------------------+\n                  ***           ***\n                     **       **\n                       **   **\n                    +---------+\n                    | prepare |\n                    +---------+\n                          *\n                          *\n                          *\n                      +-------+\n                      | train |\n                      +-------+\n                          *\n                          *\n                          *\n                    +----------+\n                    | evaluate |\n                    +----------+"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#run-pipeline",
    "href": "ai/wb_dvc_slides.html#run-pipeline",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Run pipeline",
    "text": "Run pipeline\ndvc repro\n'data/raw/train.dvc' didn't change, skipping\n'data/raw/val.dvc' didn't change, skipping\nRunning stage 'prepare':\n&gt; python src/prepare.py\nGenerating lock file 'dvc.lock'\nUpdating lock file 'dvc.lock'\n\nRunning stage 'train':\n&gt; python src/train.py\nUpdating lock file 'dvc.lock'\n\nRunning stage 'evaluate':\n&gt; python src/evaluate.py\nUpdating lock file 'dvc.lock'\nUse `dvc push` to send your updates to remote storage."
  },
  {
    "objectID": "ai/wb_dvc_slides.html#dvc-repro-breakdown",
    "href": "ai/wb_dvc_slides.html#dvc-repro-breakdown",
    "title": "Version control for data science & machine learning with DVC",
    "section": "dvc repro breakdown",
    "text": "dvc repro breakdown\n\ndvc repro runs the dvc.yaml file in a Makefile fashion\nFirst, it looks at the dependencies: the data didn‚Äôt change\nThen it ran the commands to produce the outputs (since it is our first run, we had no outputs)\nWhen the 1st stage is run, a dvc.lock is created with information on that part of the run\nWhen the 2nd and 3rd stages are run, dvc.lock is updated\nAt the end of the run dvc.lock contains all the info about the run we just did (version of the data used, etc.)\nA new directory called runs is created in .dvc/cache with cached data for this run"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#results-of-the-run",
    "href": "ai/wb_dvc_slides.html#results-of-the-run",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Results of the run",
    "text": "Results of the run\n\nThe prepared data was created in data/prepared (with a .gitignore to exclude it from Git‚Äîyou don‚Äôt want to track results in Git, but the scripts that can reproduce them)\nA model was saved in model (with another .gitignore file)\nThe accuracy of this run was created in metrics"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#clean-working-tree-1",
    "href": "ai/wb_dvc_slides.html#clean-working-tree-1",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Clean working tree",
    "text": "Clean working tree\nNow, we definitely want to create a commit with the dvc.lock\nWe could add the metrics resulting from this run in the same commit:\ngit add metrics\ngit commit -m \"First pipeline run and results\"\n\nOur working tree is now clean and our data/pipeline up to date:\ngit status\nOn branch alternative\nnothing to commit, working tree clean\ndvc status\nData and pipelines are up to date."
  },
  {
    "objectID": "ai/wb_dvc_slides.html#modify-pipeline",
    "href": "ai/wb_dvc_slides.html#modify-pipeline",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Modify pipeline",
    "text": "Modify pipeline\nFrom now on, if we edit one of the scripts, or one of the dependencies, dvc status will tell us what changed and dvc repro will only rerun the parts of the pipeline to update the result, pretty much as a Makefile would"
  },
  {
    "objectID": "ai/wb_dvc_slides.html#going-further-next-time",
    "href": "ai/wb_dvc_slides.html#going-further-next-time",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Going further ‚Ä¶ next time",
    "text": "Going further ‚Ä¶ next time\n DVC is a sophisticated tool with many additional features:\n\nCreation of data registries\nDVCLive\nA Python library to log experiment metrics\nVisualize the performance logs as plots\nContinuous integration\nWith the sister project CML (Continuous Machine Learning)"
  },
  {
    "objectID": "ai/wb_dvc.html",
    "href": "ai/wb_dvc.html",
    "title": "Version control for data science and machine learning with DVC",
    "section": "",
    "text": "Data version control (DVC) is an open source tool that brings all the versioning and collaboration capabilities you use on your code with Git to your data and machine learning workflow.\nIf you use datasets in your work, it makes it easy to track their evolution.\nIf you are in the field of machine learning, it additionally allows you to track your models, manage your pipelines from parameters to metrics, collaborate on your experiments, and integrate with the continuous integration tool for machine learning projects CML.\nThis webinar will show you how to get started with DVC, first in the simple case where you just want to put your data under version control, then in the more complex situation where you want to manage your machine learning workflow in a more organized and reproducible fashion.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Data & model version control"
    ]
  },
  {
    "objectID": "ai/wb_copilot_content.html",
    "href": "ai/wb_copilot_content.html",
    "title": "AI-powered programming with Copilot",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "AI-powered coding",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/wb_copilot_content.html#coding-in-the-age-of-generative-ai",
    "href": "ai/wb_copilot_content.html#coding-in-the-age-of-generative-ai",
    "title": "AI-powered programming with Copilot",
    "section": "Coding in the age of generative AI",
    "text": "Coding in the age of generative AI\n\nCodex\nOpenAI Codex‚Äîbased on GPT-3‚Äîis the model behind GitHub Copilot.\nAll the big corporate companies are rushing to launch a growing number of similar (and not free, not open source) productivity products (e.g.¬†tabnine, Microsoft Visual Studio IntelliCode, Amazon CodeWhisperer).\nThese products generate code in a narrow context (auto-completion or transformation of natural language to code or vise-versa).\n\n\nAlphaCode 2\nGoogle DeepMind AlphaCode 2‚Äîbased on Gemini‚Äîstands out as a totally different (and for now totally unavailable) product generating code at the level of competitive programming (reaching the 85th percentile).\nThink of it as code evolution by ‚Äúnatural‚Äù selection:\n\na very large number of code samples are generated (think ‚Äúmutations‚Äù),\na filtering and scoring system selects for the best candidates (that‚Äôs the selection part).\n\nAlphaCode 2 is able to solve much more open-ended problems.\n\n\nWhat about FOSS?\n\nFree\nThese models are large and most convenient to run on servers.\n‚ÄÉ‚Üí Price of cloud service.\nSome self-hosted options exist. A very promising one is Tabby. Not practical for everyone.\n\n\nOpen source\nWhile these models feed from open source code, they are themselves not open source üôÅ\nThe open source community is trying to provide open source alternatives (e.g.¬†Tabby). Despite the much more limited resources, the performance of some of these alternatives is very good.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "AI-powered coding",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/wb_copilot_content.html#github-copilot",
    "href": "ai/wb_copilot_content.html#github-copilot",
    "title": "AI-powered programming with Copilot",
    "section": "GitHub Copilot",
    "text": "GitHub Copilot\n(not free, not open source‚Ä¶)\n\nWhat is GitHub Copilot?\n¬†‚Üí Cloud-hosted AI programming assistant.\nDeveloped by GitHub (Microsoft).\nRunning Codex, a model by OpenAI derived from the LLM GPT-3 and trained on open source code.\n\n\nAccess\nIndividual or organization GitHub accounts.\nRequires subscription.\nStudents, teachers, and maintainers of popular open source projects can apply for free access.\n\n\nSafety\nFilters are in place for offensive words, but‚Ä¶\nGenerated code comes with no guaranty of safety or quality.\nA lawsuit is open against GitHub Copilot for licenses violation.\n\n\nSupported languages\nAny language used in public repos.\nQuality of suggestions is higher for languages with lots of data.\n\n\nHow to use it?\nStart typing code and get autocomplete suggestions.\nWrite comments describing what the code should do and get code generation based on context.\nIt is easy to:\n‚ÄÉ‚ÄÉ‚Üí accept suggestions word by word\n‚ÄÉ‚ÄÉ‚Üí line by line\n‚ÄÉ‚ÄÉ‚Üí for entire functions\n‚ÄÉ‚ÄÉ‚Üí cycle through different suggestions\n\n\nInterface\nExtensions to text editors:\n‚ÄÉ‚ÄÇ‚Üí Visual Studio Code/Visual Studio\n‚ÄÉ‚ÄÇ‚Üí Vim/Neovim/Emacs\n‚ÄÉ‚ÄÇ‚Üí JetBrains IDEs\n‚ÄÉ‚ÄÇ‚Üí Azure Data Studio",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "AI-powered coding",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/wb_copilot_content.html#setup",
    "href": "ai/wb_copilot_content.html#setup",
    "title": "AI-powered programming with Copilot",
    "section": "Setup",
    "text": "Setup\n\nGet a subscription\nGo to your GitHub account page:\n‚ÄÉ‚ÄÇ‚Üí Settings\n‚ÄÉ‚ÄÇ‚Üí Copilot\n‚ÄÉ‚ÄÇ‚Üí Enable\nProvide free access or payment method.\nSet settings.\n\n\nVS Code\nInstall the GitHub Copilot extension.\nAlt+]       Next suggestion\nAlt+[       Previous suggestion\n\nEsc         Reject suggestion\nTab         Accept suggestion\nCtrl+‚Üí      Accept next suggested word\n\nCtrl+Enter  Open new tab with options\n\nSet your own key binding for editor.action.inlineSuggest.acceptNextLine to accept next suggested line.\n\nYou can also hover over suggestions.\n\n\nVim/Neovim\nInstall Node.js.\nClone https://github.com/github/copilot.vim.\nConfigure:\n:Copilot setup\nEnable:\n:Copilot enable\nGet help:\n:help copilot\n\n\nEmacs\nInstall Node.js.\nAssuming straight is installed:\n(straight-use-package 'editorconfig)                   ; Copilot dependency\n\n(use-package copilot\n    :straight (:host github\n                     :repo \"copilot-emacs/copilot.el\"\n                     :files (\"dist\" \"*.el\"))\n    :hook (prog-mode . copilot-mode)                   ; Settings up to you\n    :bind ((\"C-8\" . copilot-complete)\n           :map copilot-completion-map\n           (\"C-j\" . copilot-accept-completion)\n           (\"C-f\" . copilot-accept-completion-by-word)\n           (\"C-t\" . copilot-accept-completion-by-line)\n           (\"C-n\" . copilot-next-completion)\n           (\"C-p\" . copilot-previous-completion)))\nLogin to your GitHub account (only needs to be done once): M-x copilot-login.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "AI-powered coding",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/wb_copilot_content.html#copilot-in-the-cli",
    "href": "ai/wb_copilot_content.html#copilot-in-the-cli",
    "title": "AI-powered programming with Copilot",
    "section": "Copilot in the CLI",
    "text": "Copilot in the CLI\n\nWhat is Copilot in the CLI?\nIn beta.\nAn extension to GitHub CLI (GitHub operations from the CLI).\n‚ÄÉ‚Üí Generate commands from natural language.\n‚ÄÉ‚Üí Generate natural language explanations from commands.\nTrained on data up to 2021.\nLower performance for natural languages ‚â† English.\nBe very careful: the command line is powerful and you can delete your data or mess up your system if you don‚Äôt know what you are doing. Check commands carefully!\n\n\nSetup\nInstall GitHub CLI.\nConnect to your GitHub account:\ngh auth login\nInstall Copilot in the CLI:\ngh extension install github/gh-copilot\n\nUpdate with: gh extension upgrade gh-copilot.\n\n\n\nUsage\nGet code explanations:\ngh copilot explain\nGet code from natural language:\ngh copilot suggest\n\n\nResources\n\nGitHub support portal\nGitHub Copilot documentation\nStack Overflow [github-copilot] tag\ncopilot.el (unofficial Emacs plug-in)",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "AI-powered coding",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/top_ws.html",
    "href": "ai/top_ws.html",
    "title": "AI workshops",
    "section": "",
    "text": "Audio DataLoader with ¬†\n\n\n\n\nFinding pre-trained models\n\n\n\n\nIntro ML for the humanities\n\n\n\n\nQuick intro to DL, NLP, and LLMs",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>"
    ]
  },
  {
    "objectID": "ai/top_pt.html",
    "href": "ai/top_pt.html",
    "title": "Getting started with PyTorch",
    "section": "",
    "text": "This introductory course to deep learning and neural networks with the PyTorch framework does not assume any prior knowledge in machine learning. Some basic Python is useful, but not strictly necessary.\n\n Start course ‚û§",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>"
    ]
  },
  {
    "objectID": "ai/top_jx.html",
    "href": "ai/top_jx.html",
    "title": "An introduction to JAX",
    "section": "",
    "text": "JAX is an open source Python library for high-performance array computing and flexible automatic differentiation.\nHigh-performance computing is achieved by asynchronous dispatch, just-in-time compilation, the XLA compiler for linear algebra, and full compatibility with accelerators (GPUs and TPUs).\nAutomatic differentiation uses Autograd and works with complex control flows (conditions, recursions), second and third-order derivatives, forward and reverse modes. This makes JAX ideal for machine learning and neural network libraries such as Flax are built on it.\n\n Start course ‚û§",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>"
    ]
  },
  {
    "objectID": "ai/sk_workflow.html",
    "href": "ai/sk_workflow.html",
    "title": "Sklearn workflow",
    "section": "",
    "text": "Scikit-learn has a very clean and consistent API, making it very easy to use: a similar workflow can be applied to most techniques. Let‚Äôs go over two examples.\nThis code was modified from Matthew Greenberg.",
    "crumbs": [
      "AI",
      "<b><em>ML with Scikit-learn</em></b>",
      "Sklearn workflow"
    ]
  },
  {
    "objectID": "ai/sk_workflow.html#load-packages",
    "href": "ai/sk_workflow.html#load-packages",
    "title": "Sklearn workflow",
    "section": "Load packages",
    "text": "Load packages\n\nfrom sklearn.datasets import fetch_california_housing, load_breast_cancer\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import (\n    mean_squared_error,\n    mean_absolute_percentage_error,\n    accuracy_score\n)\n\nimport pandas as pd\n\nimport matplotlib\nfrom matplotlib import pyplot as plt\n\nimport numpy as np\n\nfrom collections import Counter",
    "crumbs": [
      "AI",
      "<b><em>ML with Scikit-learn</em></b>",
      "Sklearn workflow"
    ]
  },
  {
    "objectID": "ai/sk_workflow.html#example-1-california-housing-dataset",
    "href": "ai/sk_workflow.html#example-1-california-housing-dataset",
    "title": "Sklearn workflow",
    "section": "Example 1: California housing dataset",
    "text": "Example 1: California housing dataset\n\nLoad and explore the data\n\ncal_housing = fetch_california_housing()\ntype(cal_housing)\n\nsklearn.utils._bunch.Bunch\n\n\nLet‚Äôs look at the attributes of cal_housing:\n\ndir(cal_housing)\n\n['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']\n\n\n\ncal_housing.feature_names\n\n['MedInc',\n 'HouseAge',\n 'AveRooms',\n 'AveBedrms',\n 'Population',\n 'AveOccup',\n 'Latitude',\n 'Longitude']\n\n\n\nprint(cal_housing.DESCR)\n\n.. _california_housing_dataset:\n\nCalifornia Housing dataset\n--------------------------\n\n**Data Set Characteristics:**\n\n:Number of Instances: 20640\n\n:Number of Attributes: 8 numeric, predictive attributes and the target\n\n:Attribute Information:\n    - MedInc        median income in block group\n    - HouseAge      median house age in block group\n    - AveRooms      average number of rooms per household\n    - AveBedrms     average number of bedrooms per household\n    - Population    block group population\n    - AveOccup      average number of household members\n    - Latitude      block group latitude\n    - Longitude     block group longitude\n\n:Missing Attribute Values: None\n\nThis dataset was obtained from the StatLib repository.\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n\nThe target variable is the median house value for California districts,\nexpressed in hundreds of thousands of dollars ($100,000).\n\nThis dataset was derived from the 1990 U.S. census, using one row per census\nblock group. A block group is the smallest geographical unit for which the U.S.\nCensus Bureau publishes sample data (a block group typically has a population\nof 600 to 3,000 people).\n\nA household is a group of people residing within a home. Since the average\nnumber of rooms and bedrooms in this dataset are provided per household, these\ncolumns may take surprisingly large values for block groups with few households\nand many empty houses, such as vacation resorts.\n\nIt can be downloaded/loaded using the\n:func:`sklearn.datasets.fetch_california_housing` function.\n\n.. rubric:: References\n\n- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n  Statistics and Probability Letters, 33 (1997) 291-297\n\n\n\n\nX = cal_housing.data\ny = cal_housing.target\n\n\nThis can also be obtained with X, y = fetch_california_housing(return_X_y=True).\n\nLet‚Äôs have a look at the shape of X and y:\n\nX.shape\n\n(20640, 8)\n\n\n\ny.shape\n\n(20640,)\n\n\nWhile not at all necessary, we can turn this bunch object into a more familiar data frame to explore the data further:\n\ncal_housing_df = pd.DataFrame(cal_housing.data, columns=cal_housing.feature_names)\n\n\ncal_housing_df.head()\n\n\n\n\n\n\n\n\nMedInc\nHouseAge\nAveRooms\nAveBedrms\nPopulation\nAveOccup\nLatitude\nLongitude\n\n\n\n\n0\n8.3252\n41.0\n6.984127\n1.023810\n322.0\n2.555556\n37.88\n-122.23\n\n\n1\n8.3014\n21.0\n6.238137\n0.971880\n2401.0\n2.109842\n37.86\n-122.22\n\n\n2\n7.2574\n52.0\n8.288136\n1.073446\n496.0\n2.802260\n37.85\n-122.24\n\n\n3\n5.6431\n52.0\n5.817352\n1.073059\n558.0\n2.547945\n37.85\n-122.25\n\n\n4\n3.8462\n52.0\n6.281853\n1.081081\n565.0\n2.181467\n37.85\n-122.25\n\n\n\n\n\n\n\n\ncal_housing_df.tail()\n\n\n\n\n\n\n\n\nMedInc\nHouseAge\nAveRooms\nAveBedrms\nPopulation\nAveOccup\nLatitude\nLongitude\n\n\n\n\n20635\n1.5603\n25.0\n5.045455\n1.133333\n845.0\n2.560606\n39.48\n-121.09\n\n\n20636\n2.5568\n18.0\n6.114035\n1.315789\n356.0\n3.122807\n39.49\n-121.21\n\n\n20637\n1.7000\n17.0\n5.205543\n1.120092\n1007.0\n2.325635\n39.43\n-121.22\n\n\n20638\n1.8672\n18.0\n5.329513\n1.171920\n741.0\n2.123209\n39.43\n-121.32\n\n\n20639\n2.3886\n16.0\n5.254717\n1.162264\n1387.0\n2.616981\n39.37\n-121.24\n\n\n\n\n\n\n\n\ncal_housing_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 20640 entries, 0 to 20639\nData columns (total 8 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   MedInc      20640 non-null  float64\n 1   HouseAge    20640 non-null  float64\n 2   AveRooms    20640 non-null  float64\n 3   AveBedrms   20640 non-null  float64\n 4   Population  20640 non-null  float64\n 5   AveOccup    20640 non-null  float64\n 6   Latitude    20640 non-null  float64\n 7   Longitude   20640 non-null  float64\ndtypes: float64(8)\nmemory usage: 1.3 MB\n\n\n\ncal_housing_df.describe() \n\n\n\n\n\n\n\n\nMedInc\nHouseAge\nAveRooms\nAveBedrms\nPopulation\nAveOccup\nLatitude\nLongitude\n\n\n\n\ncount\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n\n\nmean\n3.870671\n28.639486\n5.429000\n1.096675\n1425.476744\n3.070655\n35.631861\n-119.569704\n\n\nstd\n1.899822\n12.585558\n2.474173\n0.473911\n1132.462122\n10.386050\n2.135952\n2.003532\n\n\nmin\n0.499900\n1.000000\n0.846154\n0.333333\n3.000000\n0.692308\n32.540000\n-124.350000\n\n\n25%\n2.563400\n18.000000\n4.440716\n1.006079\n787.000000\n2.429741\n33.930000\n-121.800000\n\n\n50%\n3.534800\n29.000000\n5.229129\n1.048780\n1166.000000\n2.818116\n34.260000\n-118.490000\n\n\n75%\n4.743250\n37.000000\n6.052381\n1.099526\n1725.000000\n3.282261\n37.710000\n-118.010000\n\n\nmax\n15.000100\n52.000000\n141.909091\n34.066667\n35682.000000\n1243.333333\n41.950000\n-114.310000\n\n\n\n\n\n\n\nWe can even plot it:\n\nplt.hist(y)\n\n(array([ 877., 3612., 4099., 3771., 2799., 1769., 1239.,  752.,  479.,\n        1243.]),\n array([0.14999 , 0.634992, 1.119994, 1.604996, 2.089998, 2.575   ,\n        3.060002, 3.545004, 4.030006, 4.515008, 5.00001 ]),\n &lt;BarContainer object of 10 artists&gt;)\n\n\n\n\n\n\n\n\n\n\n\nCreate and fit a model\nLet‚Äôs start with a very simple model: linear regression.\n\nmodel = LinearRegression().fit(X, y)\n\n\nThis is equivalent to:\nmodel = LinearRegression()\nmodel.fit(X, y)\nFirst, we create an instance of the class LinearRegression, then we call .fit() on it to fit the model.\n\n\nmodel.coef_\n\narray([ 4.36693293e-01,  9.43577803e-03, -1.07322041e-01,  6.45065694e-01,\n       -3.97638942e-06, -3.78654265e-03, -4.21314378e-01, -4.34513755e-01])\n\n\n\nTrailing underscores indicate that an attribute is estimated. .coef_ here is an estimated value.\n\n\nmodel.coef_.shape\n\n(8,)\n\n\n\nmodel.intercept_\n\nnp.float64(-36.94192020718422)\n\n\nWe can now get our predictions:\n\ny_hat = model.predict(X)\n\nAnd calculate some measures of error:\n\nSum of squared errors\n\n\nnp.sum((y - y_hat) ** 2)\n\nnp.float64(10821.985154850292)\n\n\n\nMean squared error\n\n\nmean_squared_error(y, y_hat)\n\n0.5243209861846072\n\n\n\nMSE could also be calculated with np.mean((y - y_hat)**2).\n\n\nmean_absolute_percentage_error(y, y_hat)\n\n0.31715404597233515\n\n\nIndex of minimum value:\n\nmodel.coef_.argmin()\n\nnp.int64(7)\n\n\nIndex of maximum value:\n\nmodel.coef_.argmax()\n\nnp.int64(3)\n\n\n\nXX = np.concatenate([np.ones((len(X), 1)), X], axis=1)\n\nbeta = np.linalg.lstsq(XX, y, rcond=None)[0]\nintercept_, *coef_ = beta\n\nintercept_, model.intercept_\n\n(np.float64(-36.94192020718429), np.float64(-36.94192020718422))\n\n\n\nnp.allclose(coef_, model.coef_)\n\nTrue\n\n\n\nThis means that the two arrays are equal element-wise, within a certain tolerance.\n\n\nX_test = np.random.normal(size=(10, X.shape[1]))\nX_test.shape\n\n(10, 8)\n\n\n\ny_test = X_test @ coef_ + intercept_\ny_test\n\narray([-37.7624766 , -35.43989534, -37.62776124, -36.16743807,\n       -36.70282941, -36.91231298, -36.84916   , -37.72509389,\n       -35.90083768, -36.00753365])\n\n\n\nmodel.predict(X_test)\n\narray([-37.7624766 , -35.43989534, -37.62776124, -36.16743807,\n       -36.70282941, -36.91231298, -36.84916   , -37.72509389,\n       -35.90083768, -36.00753365])\n\n\nOf course, instead of LinearRegression(), we could have used another model such as a random forest regressor (a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting) for instance:\n\nmodel = RandomForestRegressor().fit(X, y).predict(X_test)\nmodel\n\narray([1.4199201, 1.2526101, 1.5110801, 1.4515   , 1.5110801, 1.4446701,\n       1.4515   , 1.5110801, 1.4479301, 1.1729801])\n\n\n\nWhich is equivalent to:\nmodel = RandomForestRegressor()\nmodel.fit(X, y).predict(X_test)",
    "crumbs": [
      "AI",
      "<b><em>ML with Scikit-learn</em></b>",
      "Sklearn workflow"
    ]
  },
  {
    "objectID": "ai/sk_workflow.html#example-2-breast-cancer",
    "href": "ai/sk_workflow.html#example-2-breast-cancer",
    "title": "Sklearn workflow",
    "section": "Example 2: breast cancer",
    "text": "Example 2: breast cancer\n\nLoad and explore the data\n\nb_cancer = load_breast_cancer()\n\nLet‚Äôs print the description of this dataset:\n\nprint(b_cancer.DESCR)\n\n.. _breast_cancer_dataset:\n\nBreast cancer wisconsin (diagnostic) dataset\n--------------------------------------------\n\n**Data Set Characteristics:**\n\n:Number of Instances: 569\n\n:Number of Attributes: 30 numeric, predictive attributes and the class\n\n:Attribute Information:\n    - radius (mean of distances from center to points on the perimeter)\n    - texture (standard deviation of gray-scale values)\n    - perimeter\n    - area\n    - smoothness (local variation in radius lengths)\n    - compactness (perimeter^2 / area - 1.0)\n    - concavity (severity of concave portions of the contour)\n    - concave points (number of concave portions of the contour)\n    - symmetry\n    - fractal dimension (\"coastline approximation\" - 1)\n\n    The mean, standard error, and \"worst\" or largest (mean of the three\n    worst/largest values) of these features were computed for each image,\n    resulting in 30 features.  For instance, field 0 is Mean Radius, field\n    10 is Radius SE, field 20 is Worst Radius.\n\n    - class:\n            - WDBC-Malignant\n            - WDBC-Benign\n\n:Summary Statistics:\n\n===================================== ====== ======\n                                        Min    Max\n===================================== ====== ======\nradius (mean):                        6.981  28.11\ntexture (mean):                       9.71   39.28\nperimeter (mean):                     43.79  188.5\narea (mean):                          143.5  2501.0\nsmoothness (mean):                    0.053  0.163\ncompactness (mean):                   0.019  0.345\nconcavity (mean):                     0.0    0.427\nconcave points (mean):                0.0    0.201\nsymmetry (mean):                      0.106  0.304\nfractal dimension (mean):             0.05   0.097\nradius (standard error):              0.112  2.873\ntexture (standard error):             0.36   4.885\nperimeter (standard error):           0.757  21.98\narea (standard error):                6.802  542.2\nsmoothness (standard error):          0.002  0.031\ncompactness (standard error):         0.002  0.135\nconcavity (standard error):           0.0    0.396\nconcave points (standard error):      0.0    0.053\nsymmetry (standard error):            0.008  0.079\nfractal dimension (standard error):   0.001  0.03\nradius (worst):                       7.93   36.04\ntexture (worst):                      12.02  49.54\nperimeter (worst):                    50.41  251.2\narea (worst):                         185.2  4254.0\nsmoothness (worst):                   0.071  0.223\ncompactness (worst):                  0.027  1.058\nconcavity (worst):                    0.0    1.252\nconcave points (worst):               0.0    0.291\nsymmetry (worst):                     0.156  0.664\nfractal dimension (worst):            0.055  0.208\n===================================== ====== ======\n\n:Missing Attribute Values: None\n\n:Class Distribution: 212 - Malignant, 357 - Benign\n\n:Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n\n:Donor: Nick Street\n\n:Date: November, 1995\n\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\nhttps://goo.gl/U2Uwz2\n\nFeatures are computed from a digitized image of a fine needle\naspirate (FNA) of a breast mass.  They describe\ncharacteristics of the cell nuclei present in the image.\n\nSeparating plane described above was obtained using\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\nConstruction Via Linear Programming.\" Proceedings of the 4th\nMidwest Artificial Intelligence and Cognitive Science Society,\npp. 97-101, 1992], a classification method which uses linear\nprogramming to construct a decision tree.  Relevant features\nwere selected using an exhaustive search in the space of 1-4\nfeatures and 1-3 separating planes.\n\nThe actual linear program used to obtain the separating plane\nin the 3-dimensional space is that described in:\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\nProgramming Discrimination of Two Linearly Inseparable Sets\",\nOptimization Methods and Software 1, 1992, 23-34].\n\nThis database is also available through the UW CS ftp server:\n\nftp ftp.cs.wisc.edu\ncd math-prog/cpo-dataset/machine-learn/WDBC/\n\n.. dropdown:: References\n\n  - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction\n    for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on\n    Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n    San Jose, CA, 1993.\n  - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and\n    prognosis via linear programming. Operations Research, 43(4), pages 570-577,\n    July-August 1995.\n  - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n    to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994)\n    163-171.\n\n\n\n\nb_cancer.feature_names\n\narray(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n       'mean smoothness', 'mean compactness', 'mean concavity',\n       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n       'radius error', 'texture error', 'perimeter error', 'area error',\n       'smoothness error', 'compactness error', 'concavity error',\n       'concave points error', 'symmetry error',\n       'fractal dimension error', 'worst radius', 'worst texture',\n       'worst perimeter', 'worst area', 'worst smoothness',\n       'worst compactness', 'worst concavity', 'worst concave points',\n       'worst symmetry', 'worst fractal dimension'], dtype='&lt;U23')\n\n\n\nb_cancer.target_names\n\narray(['malignant', 'benign'], dtype='&lt;U9')\n\n\n\nX = b_cancer.data\ny = b_cancer.target\n\n\nHere again, we could have used instead X, y = load_breast_cancer(return_X_y=True).\n\n\nX.shape\n\n(569, 30)\n\n\n\ny.shape\n\n(569,)\n\n\n\nset(y)\n\n{np.int64(0), np.int64(1)}\n\n\n\nCounter(y)\n\nCounter({np.int64(1): 357, np.int64(0): 212})\n\n\n\n\nCreate and fit a first model\n\nmodel = LogisticRegression(max_iter=10000)\ny_hat = model.fit(X, y).predict(X)\n\nGet some measure of accuracy:\n\naccuracy_score(y, y_hat)\n\n0.9578207381370826\n\n\n\nThis can also be obtained with:\nnp.mean(y_hat == y)\n\n\ndef sigmoid(x):\n  return 1/(1 + np.exp(-x))\n\nx = np.linspace(-10, 10, 100)\nplt.plot(x, sigmoid(x), lw=3)\nplt.title(\"The Sigmoid Function $\\\\sigma(x)$\")\n\nText(0.5, 1.0, 'The Sigmoid Function $\\\\sigma(x)$')\n\n\n\n\n\n\n\n\n\n\ny_pred = 1*(sigmoid(X @ model.coef_.squeeze() + model.intercept_) &gt; 0.5)\nassert np.all(y_pred == model.predict(X))\n\nnp.allclose(\n    model.predict_proba(X)[:, 1],\n    sigmoid(X @ model.coef_.squeeze() + model.intercept_)\n)\n\nTrue\n\n\n\ndef make_spirals(k=20, s=1.0, n=2000):\n    X = np.zeros((n, 2))\n    y = np.round(np.random.uniform(size=n)).astype(int)\n    r = np.random.uniform(size=n)*k*np.pi\n    rr = r**0.5\n    theta = rr + np.random.normal(loc=0, scale=s, size=n)\n    theta[y == 1] = theta[y == 1] + np.pi\n    X[:,0] = rr*np.cos(theta)\n    X[:,1] = rr*np.sin(theta)\n    return X, y\n\nX, y = make_spirals()\ncmap = matplotlib.colormaps[\"viridis\"]\n\na = cmap(0)\na = [*a[:3], 0.3]\nb = cmap(0.99)\nb = [*b[:3], 0.3]\n\nplt.figure(figsize=(7,7))\nax = plt.gca()\nax.set_aspect(\"equal\")\nax.plot(X[y == 0, 0], X[y == 0, 1], 'o', color=a, ms=8, label=\"$y=0$\")\nax.plot(X[y == 1, 0], X[y == 1, 1], 'o', color=b, ms=8, label=\"$y=1$\")\nplt.title(\"Spirals\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nCreate and fit a second model\nHere, we use a logistic regression:\n\nmodel = LogisticRegression()\ny_hat = model.fit(X, y).predict(X)\naccuracy_score(y, y_hat)\n\n0.5785\n\n\n\nu = np.linspace(-8, 8, 100)\nv = np.linspace(-8, 8, 100)\nU, V = np.meshgrid(u, v)\nUV = np.array([U.ravel(), V.ravel()]).T\nU.shape, V.shape, UV.shape\n\n((100, 100), (100, 100), (10000, 2))\n\n\n\nnp.ravel returns a contiguous flattened array.\n\n\nW = model.predict(UV).reshape(U.shape)\nW.shape\n\n(100, 100)\n\n\n\nplt.pcolormesh(U, V, W)\n\n\n\n\n\n\n\n\n\n\nCreate and fit a third model\nLet‚Äôs use a k-nearest neighbours classifier this time:\n\nmodel = KNeighborsClassifier(n_neighbors=5)\ny_hat = model.fit(X, y).predict(X)\naccuracy_score(y, y_hat)\n\n0.8965\n\n\n\nu = np.linspace(-8, 8, 100)\nv = np.linspace(-8, 8, 100)\nU, V = np.meshgrid(u, v)\nUV = np.array([U.ravel(), V.ravel()]).T\nU.shape, V.shape, UV.shape\n\n((100, 100), (100, 100), (10000, 2))\n\n\n\nW = model.predict(UV).reshape(U.shape)\nW.shape\n\n(100, 100)\n\n\n\nplt.pcolormesh(U, V, W)\n\n\n\n\n\n\n\n\nWe can iterate over various values of k to see how the accuracy and pseudocolor plot evolve:\n\nfig, axes = plt.subplots(2, 4, figsize=(9.8, 5))\nfig.suptitle(\"Decision Regions\")\n\nu = np.linspace(-8, 8, 100)\nv = np.linspace(-8, 8, 100)\nU, V = np.meshgrid(u, v)\nUV = np.array([U.ravel(), V.ravel()]).T\n\nks = np.arange(1, 16, 2)\n\nfor k, ax in zip(ks, axes.ravel()):\n  model = KNeighborsClassifier(n_neighbors=k)\n  model.fit(X, y)\n  acc = accuracy_score(y, model.predict(X))\n  W = model.predict(UV).reshape(U.shape)\n  ax.imshow(W, origin=\"lower\", cmap=cmap)\n  ax.set_axis_off()\n  ax.set_title(f\"$k$={k}, acc={acc:.2f}\")",
    "crumbs": [
      "AI",
      "<b><em>ML with Scikit-learn</em></b>",
      "Sklearn workflow"
    ]
  },
  {
    "objectID": "ai/pt/ws_pretrained_models.html",
    "href": "ai/pt/ws_pretrained_models.html",
    "title": "Finding pretrained models for transfer learning",
    "section": "",
    "text": "Training models from scratch requires way too much data, time, and computing power (or money) to be a practical option. This is why transfer learning has become such a common practice: by starting with models trained on related problems, you are saving time and achieving good results with little data.\nNow, where do you find such models?\nIn this workshop, we will see how to use pre-trained models included in PyTorch libraries, have a look at some of the most popular pre-trained models repositories, and learn how to search models in the literature and on GitHub.",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Finding pre-trained models"
    ]
  },
  {
    "objectID": "ai/pt/ws_pretrained_models.html#what-are-pre-trained-models",
    "href": "ai/pt/ws_pretrained_models.html#what-are-pre-trained-models",
    "title": "Finding pretrained models for transfer learning",
    "section": "What are pre-trained models?",
    "text": "What are pre-trained models?\n\nTransfer learning\nIf you build models from scratch, expect their performance to be mediocre. Totally naive models with random weights and biases usually need to be trained for a long time on very large datasets, using vast amounts of computing resources, before they produce competitive results. You may not even have enough data to train a model from scratch.\nInstead of starting from zero however, you can use a model that has been trained on a similar task. For instance, if your goal is to create a model able to identify bird species from pictures, you could look for a model developed for image recognition tasks trained on a classic dataset such as ImageNet. Classic such models include AlexNet (2012) and ResNet (2015). These models will already have features that are useful to you and you will get better performance with less training time and fewer data. This is called transfer learning.\n\n\nHow transfer learning works\nTypically, you remove the last layer (for instance, with AlexNet, you would remove the classification layer), replace it with a layer suitable to your task, then, optionally, you can fine tune the model.\nFine tuning a model consists of freezing the first layers (fixing their weights and biases) while retraining the model with data specific to the new task. This will only train the last few layers, greatly reducing the size of the model actually being trained and taking advantage of the early features from the source model.\nI will talk about transfer learning in another workshop, but today, we are focusing on finding a suitable pre-trained model.\nNote that the most powerful recent transformers such as GPT-3 and 4 and their competitors perform well in different tasks without the need for re-training.\n\n\nHow to find a pre-trained model\nKey to transfer learning is the search for an appropriate source model. The great news is that the world of machine learning research is incredibly open: many teams make their papers and models available online. But you need a way to navigate this abundance of resource.\nThings you should probably care about when looking for a pre-trained model include:\n\nHow pertinent is the model relative to your task?\nDoes the model have an open license?\nIs the performance good?\nIs the model size suitable for the resources I have?",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Finding pre-trained models"
    ]
  },
  {
    "objectID": "ai/pt/ws_pretrained_models.html#models-in-pytorch-libraries",
    "href": "ai/pt/ws_pretrained_models.html#models-in-pytorch-libraries",
    "title": "Finding pretrained models for transfer learning",
    "section": "Models in PyTorch libraries",
    "text": "Models in PyTorch libraries\nThe PyTorch ecosystem contains domain specific libraries (e.g.¬†torchvision, torchtext, torchaudio). Among many domain specific utilities, these libraries contain many pretrained models in vision, text, and audio.\nThese models benefit from optimum convenience since they are entirely integrated into PyTorch.\n\nLoading ResNet-18 is as simple as:\n\nimport torchvision\nmodel = torchvision.models.resnet18()\n\nInitializing a pretrained ResNet-50 model with the best currently available weights is as simple as:\n\nfrom torchvision.models import resnet50, ResNet50_Weights\nmodel = resnet50(weights=ResNet50_Weights.DEFAULT)",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Finding pre-trained models"
    ]
  },
  {
    "objectID": "ai/pt/ws_pretrained_models.html#pytorch-hub",
    "href": "ai/pt/ws_pretrained_models.html#pytorch-hub",
    "title": "Finding pretrained models for transfer learning",
    "section": "PyTorch Hub",
    "text": "PyTorch Hub\nPyTorch Hub is a repository of pretrained models.\n\nLoading ResNet-18 from the hub is done with:\n\nimport torch\nmodel = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n\n\nYour turn:\n\nLook for a small image classification model in the PyTorch Hub.",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Finding pre-trained models"
    ]
  },
  {
    "objectID": "ai/pt/ws_pretrained_models.html#hugging-face",
    "href": "ai/pt/ws_pretrained_models.html#hugging-face",
    "title": "Finding pretrained models for transfer learning",
    "section": "Hugging Face",
    "text": "Hugging Face\nHugging Face, launched in 2016, provides a Model Hub. Let‚Äôs explore it together.\n\nNote that Hugging Face also has a Dataset Hub.\n\n\n\nYour turn:\n\nFind a pre-trained model for image classification in PyTorch, trained on ImageNet, with an open license, and less than 100MB in size.\n\n\ntimm\nFor computer vision specifically, the timm (PyTorch Image Models) library contains more than 700 pretrained models, as well as scripts, utilities, optimizers, data-loaders, etc. The repo can be found here.\nYou can load models from the Hugging Face Hub with:\nimport timm\nmodel = timm.create_model('hf_hub:author/model', pretrained=True)",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Finding pre-trained models"
    ]
  },
  {
    "objectID": "ai/pt/ws_pretrained_models.html#github",
    "href": "ai/pt/ws_pretrained_models.html#github",
    "title": "Finding pretrained models for transfer learning",
    "section": "GitHub",
    "text": "GitHub\nA large number of open source models are hosted on GitHub and the platform can be searched directly for specific models.\n\n\nYour turn:\n\nDo a search on GitHub, trying to find pre-trained models in PyTorch for image classification.",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Finding pre-trained models"
    ]
  },
  {
    "objectID": "ai/pt/ws_pretrained_models.html#literature",
    "href": "ai/pt/ws_pretrained_models.html#literature",
    "title": "Finding pretrained models for transfer learning",
    "section": "Literature",
    "text": "Literature\nWhile a less direct way to find pre-trained models, the literature is invaluable to (try to) keep up with what people are doing in the field.\nPapers With Code gathers machine learning papers with open source code.\narXiv is an open-source repository of scientific preprints created by Paul Ginsparg from Cornell University in 1991. It contains a huge number of e-prints on machine learning in the computer science and the statistics fields. arxiv-sanity, created by Andrej Karpathy, tracks arXiv machine learning papers and is easier to browse.",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Finding pre-trained models"
    ]
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#can-be-broken-down-into-2-main-periods",
    "href": "ai/pt/wb_upscaling_slides.html#can-be-broken-down-into-2-main-periods",
    "title": "Super-resolution with PyTorch",
    "section": "Can be broken down into 2 main periods:",
    "text": "Can be broken down into 2 main periods:\n\nA rather slow history with various interpolation algorithms of increasing complexity before deep neural networks\nAn incredibly fast evolution since the advent of deep learning (DL)"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#sr-history-pre-dl",
    "href": "ai/pt/wb_upscaling_slides.html#sr-history-pre-dl",
    "title": "Super-resolution with PyTorch",
    "section": "SR history Pre-DL",
    "text": "SR history Pre-DL\nPixel-wise interpolation prior to DL\nVarious methods ranging from simple (e.g.¬†nearest-neighbour, bicubic) to complex (e.g.¬†Gaussian process regression, iterative FIR Wiener filter) algorithms"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#sr-history-pre-dl-1",
    "href": "ai/pt/wb_upscaling_slides.html#sr-history-pre-dl-1",
    "title": "Super-resolution with PyTorch",
    "section": "SR history Pre-DL",
    "text": "SR history Pre-DL\nNearest-neighbour interpolation\nSimplest method of interpolation\nSimply uses the value of the nearest pixel\nBicubic interpolation\nConsists of determining the 16 coefficients \\(a_{ij}\\) in:\n\\[p(x, y) = \\sum_{i=0}^3\\sum_{i=0}^3 a\\_{ij} x^i y^j\\]"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#sr-history-with-dl",
    "href": "ai/pt/wb_upscaling_slides.html#sr-history-with-dl",
    "title": "Super-resolution with PyTorch",
    "section": "SR history with DL",
    "text": "SR history with DL\nDeep learning has seen a fast evolution marked by the successive emergence of various frameworks and architectures over the past 10 years\nSome key network architectures and frameworks:\n\nCNN\nGAN\nTransformers\n\nThese have all been applied to SR"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#srcnn",
    "href": "ai/pt/wb_upscaling_slides.html#srcnn",
    "title": "Super-resolution with PyTorch",
    "section": "SRCNN",
    "text": "SRCNN\n\nDong, C., Loy, C. C., He, K., & Tang, X. (2015). Image super-resolution using deep convolutional networks. IEEE transactions on pattern analysis and machine intelligence, 38(2), 295-307\nGiven a low-resolution image Y, the first convolutional layer of the SRCNN extracts a set of feature maps. The second layer maps these feature maps nonlinearly to high-resolution patch representations. The last layer combines the predictions within a spatial neighbourhood to produce the final high-resolution image F(Y)"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#srcnn-1",
    "href": "ai/pt/wb_upscaling_slides.html#srcnn-1",
    "title": "Super-resolution with PyTorch",
    "section": "SRCNN",
    "text": "SRCNN\nCan use sparse-coding-based methods\n\nDong, C., Loy, C. C., He, K., & Tang, X. (2015). Image super-resolution using deep convolutional networks. IEEE transactions on pattern analysis and machine intelligence, 38(2), 295-307"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#srgan",
    "href": "ai/pt/wb_upscaling_slides.html#srgan",
    "title": "Super-resolution with PyTorch",
    "section": "SRGAN",
    "text": "SRGAN\nDo not provide the best PSNR, but can give more realistic results by providing more texture (less smoothing)"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#gan",
    "href": "ai/pt/wb_upscaling_slides.html#gan",
    "title": "Super-resolution with PyTorch",
    "section": "GAN",
    "text": "GAN\n\nStevens E., Antiga L., & Viehmann T. (2020). Deep Learning with PyTorch"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#srgan-1",
    "href": "ai/pt/wb_upscaling_slides.html#srgan-1",
    "title": "Super-resolution with PyTorch",
    "section": "SRGAN",
    "text": "SRGAN\n\nLedig, C., Theis, L., Husz√°r, F., Caballero, J., Cunningham, A., Acosta, A., ‚Ä¶ & Shi, W. (2017). Photo-realistic single image super-resolution using a generative adversarial network. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp.¬†4681-4690)"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#srgan-2",
    "href": "ai/pt/wb_upscaling_slides.html#srgan-2",
    "title": "Super-resolution with PyTorch",
    "section": "SRGAN",
    "text": "SRGAN\nFollowed by the ESRGAN and many other flavours of SRGANs"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#attention",
    "href": "ai/pt/wb_upscaling_slides.html#attention",
    "title": "Super-resolution with PyTorch",
    "section": "Attention",
    "text": "Attention\n\nMnih, V., Heess, N., & Graves, A. (2014). Recurrent models of visual attention. In Advances in neural information processing systems (pp.¬†2204-2212)\n\n(cited 2769 times)\n\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ‚Ä¶ & Polosukhin, I. (2017). Attention is all you need. In Advances in neural information processing systems (pp.¬†5998-6008)\n\n(cited 30999 times‚Ä¶)"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#transformers",
    "href": "ai/pt/wb_upscaling_slides.html#transformers",
    "title": "Super-resolution with PyTorch",
    "section": "Transformers",
    "text": "Transformers\n\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ‚Ä¶ & Polosukhin, I. (2017). Attention is all you need. In Advances in neural information processing systems (pp.¬†5998-6008)"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#transformers-1",
    "href": "ai/pt/wb_upscaling_slides.html#transformers-1",
    "title": "Super-resolution with PyTorch",
    "section": "Transformers",
    "text": "Transformers\nInitially used for NLP to replace RNN as they allow parallelization Now entering the domain of vision and others Very performant with relatively few parameters"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#swin-transformer",
    "href": "ai/pt/wb_upscaling_slides.html#swin-transformer",
    "title": "Super-resolution with PyTorch",
    "section": "Swin Transformer",
    "text": "Swin Transformer\nThe Swin Transformer improved the use of transformers to the vision domain\nSwin = Shifted WINdows"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#swin-transformer-1",
    "href": "ai/pt/wb_upscaling_slides.html#swin-transformer-1",
    "title": "Super-resolution with PyTorch",
    "section": "Swin Transformer",
    "text": "Swin Transformer\nSwin transformer (left) vs transformer as initially applied to vision (right):\n\nLiu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., ‚Ä¶ & Guo, B. (2021). Swin transformer: Hierarchical vision transformer using shifted windows. arXiv preprint arXiv:2103.14030"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#swinir-1",
    "href": "ai/pt/wb_upscaling_slides.html#swinir-1",
    "title": "Super-resolution with PyTorch",
    "section": "SwinIR",
    "text": "SwinIR\n\nLiang, J., Cao, J., Sun, G., Zhang, K., Van Gool, L., & Timofte, R. (2021). SwinIR: Image restoration using swin transformer. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp.¬†1833-1844)"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#training-sets-used",
    "href": "ai/pt/wb_upscaling_slides.html#training-sets-used",
    "title": "Super-resolution with PyTorch",
    "section": "Training sets used",
    "text": "Training sets used\nDIV2K, Flickr2K, and other datasets"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#models-assessment",
    "href": "ai/pt/wb_upscaling_slides.html#models-assessment",
    "title": "Super-resolution with PyTorch",
    "section": "Models assessment",
    "text": "Models assessment\n3 metrics commonly used:\nPeak sign-to-noise ratio (PSNR) measured in dB\n\\(\\frac{\\text{Maximum possible power of signal}}{\\text{Power of noise (calculated as the mean squared error)}}\\)\nCalculated at the pixel level\nStructural similarity index measure (SSIM)\nPrediction of perceived image quality based on a ‚Äúperfect‚Äù reference image\nMean opinion score (MOS)\nMean of subjective quality ratings"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#models-assessment-1",
    "href": "ai/pt/wb_upscaling_slides.html#models-assessment-1",
    "title": "Super-resolution with PyTorch",
    "section": "Models assessment",
    "text": "Models assessment\nPeak sign-to-noise ratio (PSNR) measured in dB\n\\[PSNR = 10\\,\\cdot\\,log_{10}\\,\\left(\\frac{MAX_I^2}{MSE}\\right)\\]\nStructural similarity index measure (SSIM)\n\\[SSIM(x,y) = \\frac{(2\\mu_x\\mu_y + c_1) + (2 \\sigma _{xy} + c_2)}\n    {(\\mu_x^2 + \\mu_y^2+c_1) (\\sigma_x^2 + \\sigma_y^2+c_2)}\\]\nMean opinion score (MOS)\n\\[MOS = \\frac{\\sum_{n=1}^N R\\_n}{N}\\]"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#metrics-implementation",
    "href": "ai/pt/wb_upscaling_slides.html#metrics-implementation",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics implementation",
    "text": "Metrics implementation\n\nImplement them yourself (using torch.log10, etc.)\nUse some library that implements them (e.g.¬†kornia)\nUse code of open source project with good implementation (e.g.¬†SwinIR)\nUse some higher level library that provides them (e.g.¬†ignite)"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#metrics-implementation-1",
    "href": "ai/pt/wb_upscaling_slides.html#metrics-implementation-1",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics implementation",
    "text": "Metrics implementation\n\nImplement them yourself (using torch.log10, etc.)\nUse some library that implements them (e.g.¬†kornia)\nUse code of open source project with good implementation (e.g.¬†SwinIR)\nUse some higher level library that provides them (e.g.¬†ignite)"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#metrics-implementation-2",
    "href": "ai/pt/wb_upscaling_slides.html#metrics-implementation-2",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics implementation",
    "text": "Metrics implementation\nimport kornia\n\npsnr_value = kornia.metrics.psnr(input, target, max_val)\nssim_value = kornia.metrics.ssim(img1, img2, window_size, max_val=1.0, eps=1e-12)\nSee the Kornia documentation for more info on kornia.metrics.psnr & kornia.metrics.ssim"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#benchmark-datasets",
    "href": "ai/pt/wb_upscaling_slides.html#benchmark-datasets",
    "title": "Super-resolution with PyTorch",
    "section": "Benchmark datasets",
    "text": "Benchmark datasets\nSet5\n\nSet14\n\nBSD100 (Berkeley Segmentation Dataset)"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#benchmark-datasets-1",
    "href": "ai/pt/wb_upscaling_slides.html#benchmark-datasets-1",
    "title": "Super-resolution with PyTorch",
    "section": "Benchmark datasets",
    "text": "Benchmark datasets\nSet5\n\nSet14\n\nBSD100 (Berkeley Segmentation Dataset)"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#the-set5-dataset",
    "href": "ai/pt/wb_upscaling_slides.html#the-set5-dataset",
    "title": "Super-resolution with PyTorch",
    "section": "The Set5 dataset",
    "text": "The Set5 dataset\nA dataset consisting of 5 images which has been used for at least 18 years to assess SR methods"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#how-to-get-the-dataset",
    "href": "ai/pt/wb_upscaling_slides.html#how-to-get-the-dataset",
    "title": "Super-resolution with PyTorch",
    "section": "How to get the dataset?",
    "text": "How to get the dataset?\nFrom the HuggingFace Datasets Hub with the HuggingFace datasets package:\nfrom datasets import load_dataset\n\nset5 = load_dataset('eugenesiow/Set5', 'bicubic_x4', split='validation')"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#dataset-exploration",
    "href": "ai/pt/wb_upscaling_slides.html#dataset-exploration",
    "title": "Super-resolution with PyTorch",
    "section": "Dataset exploration",
    "text": "Dataset exploration\nprint(set5)\nlen(set5)\nset5[0]\nset5.shape\nset5.column_names\nset5.features\nset5.set_format('torch', columns=['hr', 'lr'])\nset5.format"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#benchmarks",
    "href": "ai/pt/wb_upscaling_slides.html#benchmarks",
    "title": "Super-resolution with PyTorch",
    "section": "Benchmarks",
    "text": "Benchmarks\nA 2012 review of interpolation methods for SR gives the metrics for a series of interpolation methods (using other datasets)"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#interpolation-methods",
    "href": "ai/pt/wb_upscaling_slides.html#interpolation-methods",
    "title": "Super-resolution with PyTorch",
    "section": "Interpolation methods",
    "text": "Interpolation methods"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#dl-methods",
    "href": "ai/pt/wb_upscaling_slides.html#dl-methods",
    "title": "Super-resolution with PyTorch",
    "section": "DL methods",
    "text": "DL methods\nThe Papers with Code website lists available benchmarks on Set5"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#lets-use-swinir",
    "href": "ai/pt/wb_upscaling_slides.html#lets-use-swinir",
    "title": "Super-resolution with PyTorch",
    "section": "Let‚Äôs use SwinIR",
    "text": "Let‚Äôs use SwinIR\n# Get the model\ngit clone git@github.com:JingyunLiang/SwinIR.git\ncd SwinIR\n\n# Copy our test images in the repo\ncp -r &lt;some/path&gt;/my_tests /testsets/my_tests\n\n# Run the model on our images\npython main_test_swinir.py --tile 400 --task real_sr --scale 4 --large_model --model_path model_zoo/swinir/003_realSR_BSRGAN_DFOWMFC_s64w8_SwinIR-L_x4_GAN.pth --folder_lq testsets/my_tests\nRan in 9 min on my machine with one GPU and 32GB of RAM"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#results",
    "href": "ai/pt/wb_upscaling_slides.html#results",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#results-1",
    "href": "ai/pt/wb_upscaling_slides.html#results-1",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#results-2",
    "href": "ai/pt/wb_upscaling_slides.html#results-2",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#results-3",
    "href": "ai/pt/wb_upscaling_slides.html#results-3",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#results-4",
    "href": "ai/pt/wb_upscaling_slides.html#results-4",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#results-5",
    "href": "ai/pt/wb_upscaling_slides.html#results-5",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#results-6",
    "href": "ai/pt/wb_upscaling_slides.html#results-6",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#results-7",
    "href": "ai/pt/wb_upscaling_slides.html#results-7",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#results-8",
    "href": "ai/pt/wb_upscaling_slides.html#results-8",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#results-9",
    "href": "ai/pt/wb_upscaling_slides.html#results-9",
    "title": "Super-resolution with PyTorch",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#metrics",
    "href": "ai/pt/wb_upscaling_slides.html#metrics",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics",
    "text": "Metrics\nWe could use the PSNR and SSIM implementations from SwinIR, but let‚Äôs try the Kornia functions we mentioned earlier:\n\nkornia.metrics.psnr\nkornia.metrics.ssim"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#metrics-1",
    "href": "ai/pt/wb_upscaling_slides.html#metrics-1",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics",
    "text": "Metrics\nLet‚Äôs load the libraries we need:\nimport kornia\nfrom PIL import Image\nimport torch\nfrom torchvision import transforms"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#metrics-2",
    "href": "ai/pt/wb_upscaling_slides.html#metrics-2",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics",
    "text": "Metrics\nThen, we load one pair images (LR and HR):\nberlin1_lr = Image.open(\"&lt;some/path&gt;/lr/berlin_1945_1.jpg\")\nberlin1_hr = Image.open(\"&lt;some/path&gt;/hr/berlin_1945_1.png\")\n We can display these images with:\nberlin1_lr.show()\nberlin1_hr.show()"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#metrics-3",
    "href": "ai/pt/wb_upscaling_slides.html#metrics-3",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics",
    "text": "Metrics\nNow, we need to resize them so that they have identical dimensions and turn them into tensors:\npreprocess = transforms.Compose([\n        transforms.Resize(256),\n        transforms.ToTensor()\n        ])\n\nberlin1_lr_t = preprocess(berlin1_lr)\nberlin1_hr_t = preprocess(berlin1_hr)"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#metrics-4",
    "href": "ai/pt/wb_upscaling_slides.html#metrics-4",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics",
    "text": "Metrics\nberlin1_lr_t.shape\nberlin1_hr_t.shape\ntorch.Size([3, 267, 256])\ntorch.Size([3, 267, 256])\nWe now have tensors with 3 dimensions:\n\nthe channels (RGB)\nthe height of the image (in pixels)\nthe width of the image (in pixels)"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#metrics-5",
    "href": "ai/pt/wb_upscaling_slides.html#metrics-5",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics",
    "text": "Metrics\nAs data processing is done in batch in ML, we need to add a 4th dimension: the batch size\n(It will be equal to 1 since we have a batch size of a single image)\nbatch_berlin1_lr_t = torch.unsqueeze(berlin1_lr_t, 0)\nbatch_berlin1_hr_t = torch.unsqueeze(berlin1_hr_t, 0)"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#metrics-6",
    "href": "ai/pt/wb_upscaling_slides.html#metrics-6",
    "title": "Super-resolution with PyTorch",
    "section": "Metrics",
    "text": "Metrics\nOur new tensors are now ready:\nbatch_berlin1_lr_t.shape\nbatch_berlin1_hr_t.shape\ntorch.Size([1, 3, 267, 256])\ntorch.Size([1, 3, 267, 256])"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#psnr",
    "href": "ai/pt/wb_upscaling_slides.html#psnr",
    "title": "Super-resolution with PyTorch",
    "section": "PSNR",
    "text": "PSNR\npsnr_value = kornia.metrics.psnr(batch_berlin1_lr_t, batch_berlin1_hr_t, max_val=1.0)\npsnr_value.item()\n33.379642486572266"
  },
  {
    "objectID": "ai/pt/wb_upscaling_slides.html#ssim",
    "href": "ai/pt/wb_upscaling_slides.html#ssim",
    "title": "Super-resolution with PyTorch",
    "section": "SSIM",
    "text": "SSIM\nssim_map = kornia.metrics.ssim(\n    batch_berlin1_lr_t, batch_berlin1_hr_t, window_size=5, max_val=1.0, eps=1e-12)\n\nssim_map.mean().item()\n0.9868119359016418"
  },
  {
    "objectID": "ai/pt/wb_upscaling.html",
    "href": "ai/pt/wb_upscaling.html",
    "title": "Image upscaling",
    "section": "",
    "text": "Super-resolution‚Äîthe process of (re)creating high resolution images from low resolution ones‚Äîis an old field, but deep neural networks have seen a sudden surge of new and very impressive methods over the past 10 years, from SRCCN to SRGAN to Transformers.\nIn this webinar, I will give a quick overview of these methods and show how the latest state-of-the-art model‚ÄîSwinIR‚Äîperforms on a few test images. We will use PyTorch as our framework.\n\nSlides (Click and wait: this reveal.js presentation is heavy and takes some time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Image upscaling"
    ]
  },
  {
    "objectID": "ai/pt/wb_torchtensors_content.html",
    "href": "ai/pt/wb_torchtensors_content.html",
    "title": "Everything you wanted to know (and more!) about PyTorch tensors",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "PyTorch tensors in depth",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/wb_torchtensors_content.html#notes",
    "href": "ai/pt/wb_torchtensors_content.html#notes",
    "title": "Everything you wanted to know (and more!) about PyTorch tensors",
    "section": "Notes",
    "text": "Notes\n\nAcknowledgements\nMany drawings in this webinar come from the book:\n\nThe section on storage is also highly inspired by it.\n\n\nUsing tensors locally\nYou need to have Python and PyTorch installed.\nAdditionally, you might want to use an IDE such as elpy if you are an Emacs user, JupyterLab, etc.\n\nNote that PyTorch does not yet support Python 3.10 except in some Linux distributions or on systems where a wheel has been built For the time being, you might have to use it with Python 3.9.\n\n\n\nUsing tensors on CC clusters\nList available wheels and compatible Python versions (in the terminal):\navail_wheels \"torch*\"\nList available Python versions:\nmodule avail python\nGet setup:\nmodule load python/3.9.6             # Load a sensible Python version\nvirtualenv --no-download env         # Create a virtual env\nsource env/bin/activate              # Activate the virtual env\npip install --no-index --upgrade pip # Update pip\npip install --no-index torch         # Install PyTorch\nYou can then launch jobs with sbatch or salloc.\nLeave the virtual env with the command: deactivate.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "PyTorch tensors in depth",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/wb_torchtensors_content.html#outline",
    "href": "ai/pt/wb_torchtensors_content.html#outline",
    "title": "Everything you wanted to know (and more!) about PyTorch tensors",
    "section": "Outline",
    "text": "Outline\n\nWhat is a PyTorch tensor?\nMemory storage\nData type (dtype)\nBasic operations\nWorking with NumPy\nLinear algebra\nHarvesting the power of GPUs\nDistributed operations",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "PyTorch tensors in depth",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/wb_torchtensors_content.html#why-tensor-objects",
    "href": "ai/pt/wb_torchtensors_content.html#why-tensor-objects",
    "title": "Everything you wanted to know (and more!) about PyTorch tensors",
    "section": "Why tensor objects?",
    "text": "Why tensor objects?\nANN do not process information directly:\n\n\n\nModified from Stevens, E., Antiga, L., & Viehmann, T. (2020). Deep learning with PyTorch. Manning Publications\n\n\nThe information needs to be converted to numbers:\n\n\n\nModified from Stevens, E., Antiga, L., & Viehmann, T. (2020). Deep learning with PyTorch. Manning Publications\n\n\nThese numbers must be stored in a data structure:\nPyTorch tensors are Python objects holding multidimensional arrays.\n\n\n\nStevens, E., Antiga, L., & Viehmann, T. (2020). Deep learning with PyTorch. Manning Publications\n\n\n\nWhy a new object?\n(Particularly when NumPy already exists).\n\nCan run on accelerators (GPUs, TPUs‚Ä¶).\nKeep track of computation graphs, allowing automatic differentiation.\nFuture plan for sharded tensors to run distributed computations.\n\n\n\nWhat is a PyTorch tensor?\nPyTorch is foremost a deep learning library.\nIn deep learning, the information contained in objects of interest (e.g.¬†images, texts, sounds) is converted to floating-point numbers (e.g.¬†pixel values, token values, frequencies).\nAs this information is complex, multiple dimensions are required (e.g.¬†two dimensions for the width and height of an image, plus one dimension for the RGB colour channels).\nAdditionally, items are grouped into batches to be processed together, adding yet another dimension.\nMultidimensional arrays are thus particularly well suited for deep learning.\nArtificial neurons perform basic computations on these tensors.\nTheir number however is huge and computing efficiency is paramount.\nGPUs/TPUs are particularly well suited to perform many simple operations in parallel.\nThe very popular NumPy library has, at its core, a mature multidimensional array object well integrated into the scientific Python ecosystem.\nBut the PyTorch tensor has additional efficiency characteristics ideal for machine learning and it can be converted to/from NumPy‚Äôs ndarray if needed.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "PyTorch tensors in depth",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/wb_torchtensors_content.html#efficient-memory-storage",
    "href": "ai/pt/wb_torchtensors_content.html#efficient-memory-storage",
    "title": "Everything you wanted to know (and more!) about PyTorch tensors",
    "section": "Efficient memory storage",
    "text": "Efficient memory storage\nIn Python, collections (lists, tuples) are groupings of boxed Python objects.\nPyTorch tensors and NumPy ndarrays are made of unboxed C numeric types.\n\n\n\nStevens, E., Antiga, L., & Viehmann, T. (2020). Deep learning with PyTorch. Manning Publications\n\n\nThey are usually contiguous memory blocks, but the main difference is that they are unboxed: floats will thus take 4 (32-bit) or 8 (64-bit) bytes each.\nBoxed values take up more memory (memory for the pointer + memory for the primitive).\n\n\n\nStevens, E., Antiga, L., & Viehmann, T. (2020). Deep learning with PyTorch. Manning Publications\n\n\n\nImplementation\nUnder the hood, the values of a PyTorch tensor are stored as a torch.Storage instance which is a one-dimensional array.\nimport torch\nt = torch.arange(10.).view(2, 5); print(t) # Functions explained later\ntensor([[ 0.,  1.,  2., 3.,  4.],\n        [ 5.,  6.,  7.,  8.,  9.]])\nstorage = t.storage(); print(storage)\n 0.0\n 1.0\n 2.0\n 3.0\n 4.0\n 5.0\n 6.0\n 7.0\n 8.0\n 9.0\n[torch.FloatStorage of size 10]\nThe storage can be indexed:\nstorage[3]\n3.0\nstorage[3] = 10.0; print(storage)\n 0.0\n 1.0\n 2.0\n 10.0\n 4.0\n 5.0\n 6.0\n 7.0\n 8.0\n 9.0\n[torch.FloatStorage of size 10]\nTo view a multidimensional array from storage, we need metadata:\n\nthe size (shape in NumPy) sets the number of elements in each dimension,\nthe offset indicates where the first element of the tensor is in the storage,\nthe stride establishes the increment between each element.\n\n\n\nStorage metadata\n\n\n\nStevens, E., Antiga, L., & Viehmann, T. (2020). Deep learning with PyTorch. Manning Publications\n\n\nt.size()\nt.storage_offset()\nt.stride()\ntorch.Size([2, 5])\n0\n(5, 1)\n\n\n\n¬†\n\n\n\n\nSharing storage\nMultiple tensors can use the same storage, saving a lot of memory since the metadata is a lot lighter than a whole new array.\n\n\n\nStevens, E., Antiga, L., & Viehmann, T. (2020). Deep learning with PyTorch. Manning Publications\n\n\n\n\nTransposing in 2 dimensions\nt = torch.tensor([[3, 1, 2], [4, 1, 7]]); print(t)\nt.size()\nt.t()\nt.t().size()\ntensor([[3, 1, 2],\n        [4, 1, 7]])\ntorch.Size([2, 3])\ntensor([[3, 4],\n        [1, 1],\n        [2, 7]])\ntorch.Size([3, 2])\nThis is the same as flipping the stride elements around.\n\n\n\nStevens, E., Antiga, L., & Viehmann, T. (2020). Deep learning with PyTorch. Manning Publications\n\n\n\n\nTransposing in higher dimensions\ntorch.t() is a shorthand for torch.transpose(0, 1):\ntorch.equal(t.t(), t.transpose(0, 1))\nTrue\nWhile torch.t() only works for 2D tensors, torch.transpose() can be used to transpose 2 dimensions in tensors of any number of dimensions:\nt = torch.zeros(1, 2, 3); print(t)\n\nt.size()\nt.stride()\ntensor([[[0., 0., 0.],\n         [0., 0., 0.]]])\n\ntorch.Size([1, 2, 3])\n(6, 3, 1)\nt.transpose(0, 1)\n\nt.transpose(0, 1).size()\nt.transpose(0, 1).stride()\ntensor([[[0., 0., 0.]],\n        [[0., 0., 0.]]])\n\ntorch.Size([2, 1, 3])\n(3, 6, 1)  # Notice how transposing flipped 2 elements of the stride\nt.transpose(0, 2)\n\nt.transpose(0, 2).size()\nt.transpose(0, 2).stride()\ntensor([[[0.],\n         [0.]],\n        [[0.],\n         [0.]],\n        [[0.],\n         [0.]]])\n\ntorch.Size([3, 2, 1])\n(1, 3, 6)\nt.transpose(1, 2)\n\nt.transpose(1, 2).size()\nt.transpose(1, 2).stride()\ntensor([[[0., 0.],\n         [0., 0.],\n         [0., 0.]]])\n\ntorch.Size([1, 3, 2])\n(6, 1, 3)",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "PyTorch tensors in depth",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/wb_torchtensors_content.html#default-dtype",
    "href": "ai/pt/wb_torchtensors_content.html#default-dtype",
    "title": "Everything you wanted to know (and more!) about PyTorch tensors",
    "section": "Default dtype",
    "text": "Default dtype\nSince PyTorch tensors were built with utmost efficiency in mind for neural networks, the default data type is 32-bit floating points.\nThis is sufficient for accuracy and much faster than 64-bit floating points.\n\nNote that, by contrast, NumPy ndarrays use 64-bit as their default.\n\n\nList of PyTorch tensor dtypes\n\n\n\ntorch.float16 / torch.half\n\n\n‚ÄÉ‚ÄÉ\n\n\n16-bit / half-precision floating-point\n\n\n\n\ntorch.float32 / torch.float\n\n\n\n\n32-bit / single-precision floating-point\n\n\n\n\ntorch.float64 / torch.double\n\n\n\n\n64-bit / double-precision floating-point\n\n\n\n\n\n\n\n\n\n\ntorch.uint8\n\n\n\n\nunsigned 8-bit integers\n\n\n\n\ntorch.int8\n\n\n\n\nsigned 8-bit integers\n\n\n\n\ntorch.int16 / torch.short\n\n\n\n\nsigned 16-bit integers\n\n\n\n\ntorch.int32 / torch.int\n\n\n\n\nsigned 32-bit integers\n\n\n\n\ntorch.int64 / torch.long\n\n\n\n\nsigned 64-bit integers\n\n\n\n\n\n\n\n\n\n\n\n\ntorch.bool\n\n\n\n\nboolean\n\n\n\n\n\nChecking and changing dtype\nt = torch.rand(2, 3)\nprint(t)\n\n# Remember that the default dtype for PyTorch tensors is float32\nt.dtype\n\n# If dtype ‚â† default, it is printed\nt2 = t.type(torch.float64)\nprint(t2)\n\nt2.dtype\ntensor([[0.8130, 0.3757, 0.7682],\n        [0.3482, 0.0516, 0.3772]])\n\ntorch.float32\n\ntensor([[0.8130, 0.3757, 0.7682],\n        [0.3482, 0.0516, 0.3772]], dtype=torch.float64)\n\ntorch.float64",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "PyTorch tensors in depth",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/wb_torchtensors_content.html#creating-tensors",
    "href": "ai/pt/wb_torchtensors_content.html#creating-tensors",
    "title": "Everything you wanted to know (and more!) about PyTorch tensors",
    "section": "Creating tensors",
    "text": "Creating tensors\n\ntorch.tensor: ‚ÄÉ‚ÄÉ¬†Input individual values\ntorch.arange: ‚ÄÉ‚ÄÉ¬†Similar to range but creates a 1D tensor\ntorch.linspace: ‚ÄÉ¬†1D linear scale tensor\ntorch.logspace: ‚ÄÉ¬†1D log scale tensor\ntorch.rand: ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇRandom numbers from a uniform distribution on [0, 1)\ntorch.randn: ‚ÄÉ‚ÄÉ‚ÄÉNumbers from the standard normal distribution\ntorch.randperm: ‚ÄÉ¬†Random permutation of integers\ntorch.empty: ‚ÄÉ‚ÄÉ‚ÄÉUninitialized tensor\ntorch.zeros: ‚ÄÉ‚ÄÉ‚ÄÉTensor filled with 0\ntorch.ones: ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇTensor filled with 1\ntorch.eye: ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ¬†Identity matrix\n\ntorch.manual_seed(0)  # If you want to reproduce the result\ntorch.rand(1)\n\ntorch.manual_seed(0)  # Run before each operation to get the same result\ntorch.rand(1).item()  # Extract the value from a tensor\ntensor([0.4963])\n\n0.49625658988952637\ntorch.rand(1)\ntorch.rand(1, 1)\ntorch.rand(1, 1, 1)\ntorch.rand(1, 1, 1, 1)\ntensor([0.6984])\ntensor([[0.5675]])\ntensor([[[0.8352]]])\ntensor([[[[0.2056]]]])\ntorch.rand(2)\ntorch.rand(2, 2, 2, 2)\ntensor([0.5932, 0.1123])\ntensor([[[[0.1147, 0.3168],\n          [0.6965, 0.9143]],\n         [[0.9351, 0.9412],\n          [0.5995, 0.0652]]],\n        [[[0.5460, 0.1872],\n          [0.0340, 0.9442]],\n         [[0.8802, 0.0012],\n          [0.5936, 0.4158]]]])\ntorch.rand(2)\ntorch.rand(3)\ntorch.rand(1, 1)\ntorch.rand(1, 1, 1)\ntorch.rand(2, 6)\ntensor([0.7682, 0.0885])\ntensor([0.1320, 0.3074, 0.6341])\ntensor([[0.4901]])\ntensor([[[0.8964]]])\ntensor([[0.4556, 0.6323, 0.3489, 0.4017, 0.0223, 0.1689],\n        [0.2939, 0.5185, 0.6977, 0.8000, 0.1610, 0.2823]])\ntorch.rand(2, 4, dtype=torch.float64)  # You can set dtype\ntorch.ones(2, 1, 4, 5)\ntensor([[0.6650, 0.7849, 0.2104, 0.6767],\n        [0.1097, 0.5238, 0.2260, 0.5582]], dtype=torch.float64)\ntensor([[[[1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1.]]],\n        [[[1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1.]]]])\nt = torch.rand(2, 3); print(t)\ntorch.zeros_like(t)             # Matches the size of t\ntorch.ones_like(t)\ntorch.randn_like(t)\ntensor([[0.4051, 0.6394, 0.0871],\n        [0.4509, 0.5255, 0.5057]])\ntensor([[0., 0., 0.],\n        [0., 0., 0.]])\ntensor([[1., 1., 1.],\n        [1., 1., 1.]])\ntensor([[-0.3088, -0.0104,  1.0461],\n        [ 0.9233,  0.0236, -2.1217]])\ntorch.arange(2, 10, 4)    # From 2 to 10 in increments of 4\ntorch.linspace(2, 10, 4)  # 4 elements from 2 to 10 on the linear scale\ntorch.logspace(2, 10, 4)  # Same on the log scale\ntorch.randperm(4)\ntorch.eye(3)\ntensor([2, 6])\ntensor([2.0000,  4.6667,  7.3333, 10.0000])\ntensor([1.0000e+02, 4.6416e+04, 2.1544e+07, 1.0000e+10])\ntensor([1, 3, 2, 0])\ntensor([[1., 0., 0.],\n        [0., 1., 0.],\n        [0., 0., 1.]])",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "PyTorch tensors in depth",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/wb_torchtensors_content.html#tensor-information",
    "href": "ai/pt/wb_torchtensors_content.html#tensor-information",
    "title": "Everything you wanted to know (and more!) about PyTorch tensors",
    "section": "Tensor information",
    "text": "Tensor information\nt = torch.rand(2, 3); print(t)\nt.size()\nt.dim()\nt.numel()\ntensor([[0.5885, 0.7005, 0.1048],\n        [0.1115, 0.7526, 0.0658]])\ntorch.Size([2, 3])\n2\n6",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "PyTorch tensors in depth",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/wb_torchtensors_content.html#tensor-indexing",
    "href": "ai/pt/wb_torchtensors_content.html#tensor-indexing",
    "title": "Everything you wanted to know (and more!) about PyTorch tensors",
    "section": "Tensor indexing",
    "text": "Tensor indexing\nx = torch.rand(3, 4)\nx[:]                 # With a range, the comma is implicit: same as x[:, ]\nx[:, 2]\nx[1, :]\nx[2, 3]\ntensor([[0.6575, 0.4017, 0.7391, 0.6268],\n        [0.2835, 0.0993, 0.7707, 0.1996],\n        [0.4447, 0.5684, 0.2090, 0.7724]])\ntensor([0.7391, 0.7707, 0.2090])\ntensor([0.2835, 0.0993, 0.7707, 0.1996])\ntensor(0.7724)\nx[-1:]        # Last element (implicit comma, so all columns)\n\n# No range, no implicit comma\n# Indexing from a list of tensors, so the result is a one dimensional tensor\n# (Each dimension is a list of tensors of the previous dimension)\nx[-1]\n\nx[-1].size()  # Same number of dimensions than x (2 dimensions)\n\nx[-1:].size() # We dropped one dimension\ntensor([[0.8168, 0.0879, 0.2642, 0.3777]])\n\ntensor([0.8168, 0.0879, 0.2642, 0.3777])\n\ntorch.Size([4])\n\ntorch.Size([1, 4])\nx[0:1]     # Python ranges are inclusive to the left, not the right\nx[:-1]     # From start to one before last (and implicit comma)\nx[0:3:2]   # From 0th (included) to 3rd (excluded) in increment of 2\ntensor([[0.5873, 0.0225, 0.7234, 0.4538]])\ntensor([[0.5873, 0.0225, 0.7234, 0.4538],\n        [0.9525, 0.0111, 0.6421, 0.4647]])\ntensor([[0.5873, 0.0225, 0.7234, 0.4538],\n        [0.8168, 0.0879, 0.2642, 0.3777]])\nx[None]          # Adds a dimension of size one as the 1st dimension\nx.size()\nx[None].size()\ntensor([[[0.5873, 0.0225, 0.7234, 0.4538],\n         [0.9525, 0.0111, 0.6421, 0.4647],\n         [0.8168, 0.0879, 0.2642, 0.3777]]])\ntorch.Size([3, 4])\ntorch.Size([1, 3, 4])\n\nA word of caution about indexing\nWhile indexing elements of a tensor to extract some of the data as a final step of some computation is fine, you should not use indexing to run operations on tensor elements in a loop as this would be extremely inefficient.\nInstead, you want to use vectorized operations.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "PyTorch tensors in depth",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/wb_torchtensors_content.html#operations-on-tensors",
    "href": "ai/pt/wb_torchtensors_content.html#operations-on-tensors",
    "title": "Everything you wanted to know (and more!) about PyTorch tensors",
    "section": "Operations on tensors",
    "text": "Operations on tensors\n\nVectorized operations\nSince PyTorch tensors are homogeneous (i.e.¬†made of a single data type), as with NumPy‚Äôs ndarrays, operations are vectorized and thus staggeringly fast.\nNumPy is mostly written in C and PyTorch in C++. With either library, when you run vectorized operations on arrays/tensors, you don‚Äôt use raw Python (slow) but compiled C/C++ code (much faster).\nHere is an excellent post explaining Python vectorization and why it makes such a big difference.\n\nComparison\nRaw Python method:\n# Create tensor. We use float64 here to avoid truncation errors\nt = torch.rand(10**6, dtype=torch.float64)\n\n# Initialize sum\nsu# Run loop\nfor i in range(len(t)): sum += t[i]\n\n# Print result\nprint(sum)\nVectorized function:\nt.sum()\nBoth methods give the same result.\n\nThis is why we used float64:\nWhile the accuracy remains excellent with float32 if we use the PyTorch function torch.sum(), the raw Python loop gives a fairly inaccurate result.\n\ntensor(500023.0789, dtype=torch.float64)\ntensor(500023.0789, dtype=torch.float64)\n\n\nTiming\nLet‚Äôs compare the timing with PyTorch built-in benchmark utility:\n# Load utility\nimport torch.utils.benchmark as benchmark\n\n# Create a function for our loop\ndef sum_loop(t, sum):\n    for i in range(len(t)): sum += t[i]\nNow we can create the timers:\nt0 = benchmark.Timer(\n    stmt='sum_loop(t, sum)',\n    setup='from __main__ import sum_loop',\n    globals={'t': t, 'sum': sum})\n\nt1 = benchmark.Timer(\n    stmt='t.sum()',\n    globals={'t': t})\nLet‚Äôs time 100 runs to have a reliable benchmark:\nprint(t0.timeit(100))\nprint(t1.timeit(100))\n\nI ran the code on my laptop with a dedicated GPU and 32GB RAM.\n\nTiming of raw Python loop:\nsum_loop(t, sum)\nsetup: from __main__ import sum_loop\n  1.37 s\n  1 measurement, 100 runs , 1 thread\nTiming of vectorized function:\nt.sum()\n  191.26 us\n  1 measurement, 100 runs , 1 thread\nSpeedup:\n1.37/(191.26 * 10**-6) = 7163\nThe vectorized function runs more than 7,000 times faster!!!\n\n\nEven more important on GPUs\nWe will talk about GPUs in detail later.\nTiming of raw Python loop on GPU (actually slower on GPU!)\nsum_loop(t, sum)\nsetup: from __main__ import sum_loop\n  4.54 s\n  1 measurement, 100 runs , 1 thread\nTiming of vectorized function on GPU (here we do get a speedup):\nt.sum()\n  50.62 us\n  1 measurement, 100 runs , 1 thread\nSpeedup:\n4.54/(50.62 * 10**-6) = 89688\nOn GPUs, it is even more important not to index repeatedly from a tensor.\nOn GPUs, the vectorized function runs almost 90,000 times faster!!!\n\n\n\nSimple mathematical operations\nt1 = torch.arange(1, 5).view(2, 2); print(t1)\nt2 = torch.tensor([[1, 1], [0, 0]]); print(t2)\n\nt1 + t2 # Operation performed between elements at corresponding locations\nt1 + 1  # Operation applied to each element of the tensor\ntensor([[1, 2],\n        [3, 4]])\ntensor([[1, 1],\n        [0, 0]])\n\ntensor([[2, 3],\n        [3, 4]])\ntensor([[2, 3],\n        [4, 5]])\n\n\nReduction\nt = torch.ones(2, 3, 4); print(t)\nt.sum()   # Reduction over all entries\ntensor([[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]])\ntensor(24.)\n\nOther reduction functions (e.g.¬†mean) behave the same way.\n\n# Reduction over a specific dimension\nt.sum(0)\nt.sum(1)\nt.sum(2)\ntensor([[2., 2., 2., 2.],\n        [2., 2., 2., 2.],\n        [2., 2., 2., 2.]])\ntensor([[3., 3., 3., 3.],\n        [3., 3., 3., 3.]])\ntensor([[4., 4., 4.],\n        [4., 4., 4.]])\n# Reduction over multiple dimensions\nt.sum((0, 1))\nt.sum((0, 2))\nt.sum((1, 2))\ntensor([6., 6., 6., 6.])\ntensor([8., 8., 8.])\ntensor([12., 12.])\n\n\nIn-place operations\nWith operators post-fixed with _:\nt1 = torch.tensor([1, 2]); print(t1)\nt2 = torch.tensor([1, 1]); print(t2)\nt1.add_(t2); print(t1)\nt1.zero_(); print(t1)\ntensor([1, 2])\ntensor([1, 1])\ntensor([2, 3])\ntensor([0, 0])\n\nIn-place operations vs reassignments\nt1 = torch.ones(1); t1, hex(id(t1))\nt1.add_(1); t1, hex(id(t1))        # In-place operation: same address\nt1 = t1.add(1); t1, hex(id(t1))    # Reassignment: new address in memory\nt1 = t1 + 1; t1, hex(id(t1))       # Reassignment: new address in memory\n(tensor([1.]), '0x7fc61accc3b0')\n(tensor([2.]), '0x7fc61accc3b0')\n(tensor([3.]), '0x7fc61accc5e0')\n(tensor([4.]), '0x7fc61accc6d0')\n\n\n\nLogical operations\nt1 = torch.randperm(5); print(t1)\nt2 = torch.randperm(5); print(t2)\nt1 &gt; 3                            # Test each element\nt1 &lt; t2                           # Test corresponding pairs of elements\ntensor([4, 1, 0, 2, 3])\ntensor([0, 4, 2, 1, 3])\ntensor([ True, False, False, False, False])\ntensor([False,  True,  True, False, False])\n\n\nTensor views\nt = torch.tensor([[1, 2, 3], [4, 5, 6]]); print(t)\nt.size()\nt.view(6)\nt.view(3, 2)\nt.view(3, -1) # Same: with -1, the size is inferred from other dimensions\ntensor([[1, 2, 3],\n        [4, 5, 6]])\ntorch.Size([2, 3])\ntensor([1, 2, 3, 4, 5, 6])\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\nNote the difference\nt1 = torch.tensor([[1, 2, 3], [4, 5, 6]]); print(t1)\nt2 = t1.t(); print(t2)\nt3 = t1.view(3, 2); print(t3)\ntensor([[1, 2, 3],\n        [4, 5, 6]])\ntensor([[1, 4],\n        [2, 5],\n        [3, 6]])\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "PyTorch tensors in depth",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/wb_torchtensors_content.html#conversion-without-copy",
    "href": "ai/pt/wb_torchtensors_content.html#conversion-without-copy",
    "title": "Everything you wanted to know (and more!) about PyTorch tensors",
    "section": "Conversion without copy",
    "text": "Conversion without copy\nPyTorch tensors can be converted to NumPy ndarrays and vice-versa in a very efficient manner as both objects share the same memory:\nt = torch.rand(2, 3); print(t)     # PyTorch Tensor\nt_np = t.numpy(); print(t_np)      # NumPy ndarray\ntensor([[0.8434, 0.0876, 0.7507],\n        [0.1457, 0.3638, 0.0563]])\n\n[[0.84344184 0.08764815 0.7506627 ]\n [0.14567494 0.36384273 0.05629885]]\n\nMind the different defaults\nt_np.dtype\ndtype('float32')\n\nRemember that PyTorch tensors use 32-bit floating points by default\n(because this is what you want in neural networks).\n\n\nBut NumPy defaults to 64-bit.\nDepending on your workflow, you might have to change dtype.\n\n\n\nFrom NumPy to PyTorch\nimport numpy as np\na = np.random.rand(2, 3); print(a)\na_pt = torch.from_numpy(a); print(a_pt)    # From ndarray to tensor\n[[0.55892276 0.06026952 0.72496545]\n [0.65659463 0.27697739 0.29141587]]\n\ntensor([[0.5589, 0.0603, 0.7250],\n        [0.6566, 0.2770, 0.2914]], dtype=torch.float64)\n\nHere again, you might have to change dtype.\n\n\n\nNotes copies\nt and t_np are objects of different Python types, so, as far as Python is concerned, they have different addresses:\nid(t) == id(t_np)\nFalse\nHowever‚Äîthat‚Äôs quite confusing‚Äîthey share an underlying C array in memory and modifying one in-place also modifies the other:\nt.zero_()\nprint(t_np)\ntensor([[0., 0., 0.],\n        [0., 0., 0.]])\n\n[[0. 0. 0.]\n [0. 0. 0.]]\nLastly, as NumPy only works on CPU, to convert a PyTorch tensor allocated to the GPU, the content will have to be copied to the CPU first.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "PyTorch tensors in depth",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/wb_torchtensors_content.html#linear-algebra",
    "href": "ai/pt/wb_torchtensors_content.html#linear-algebra",
    "title": "Everything you wanted to know (and more!) about PyTorch tensors",
    "section": "Linear algebra",
    "text": "Linear algebra\n\ntorch.linalg module\nAll functions from numpy.linalg implemented (with accelerator and automatic differentiation support) + additional functions.\n\nRequires torch &gt;= 1.9.\nLinear algebra support was less developed before the introduction of this module.\n\n\n\nSystem of linear equations solver\nLet‚Äôs have a look at an extremely basic example:\n2x + 3y - z = 5\nx - 2y + 8z = 21\n6x + y - 3z = -1\nWe are looking for the values of x, y, and z that would satisfy this system.\nWe create a 2D tensor A of size (3, 3) with the coefficients of the equations and a 1D tensor b of size 3 with the right hand sides values of the equations:\nA = torch.tensor([[2., 3., -1.], [1., -2., 8.], [6., 1., -3.]]); print(A)\nb = torch.tensor([5., 21., -1.]); print(b)\ntensor([[ 2.,  3., -1.],\n        [ 1., -2.,  8.],\n        [ 6.,  1., -3.]])\ntensor([ 5., 21., -1.])\nSolving this system is as simple as running the torch.linalg.solve function:\nx = torch.linalg.solve(A, b); print(x)\ntensor([1., 2., 3.])\nOur solution is:\nx = 1\ny = 2\nz = 3\nVerify our result:\ntorch.allclose(A @ x, b)\nTrue\nHere is another simple example:\n# Create a square normal random matrix\nA = torch.randn(4, 4); print(A)\n# Create a tensor of right hand side values\nb = torch.randn(4); print(b)\n\n# Solve the system\nx = torch.linalg.solve(A, b); print(x)\n\n# Verify\ntorch.allclose(A @ x, b)\n(Results)\nA (coefficients):\ntensor([[ 1.5091,  2.0820,  1.7067,  2.3804],\n        [-1.1256, -0.3170, -1.0925, -0.0852],\n        [ 0.3276, -0.7607, -1.5991,  0.0185],\n        [-0.7504,  0.1854,  0.6211,  0.6382]])\nb (right hand side values):\ntensor([-1.0886, -0.2666,  0.1894, -0.2190])\nx (our solution):\ntensor([ 0.1992, -0.7011,  0.2541, -0.1526])\nVerification:\nTrue\n\n\nWith 2 multidimensional tensors\nA = torch.randn(2, 3, 3)              # Must be batches of square matrices\nB = torch.randn(2, 3, 5)              # Dimensions must be compatible\nX = torch.linalg.solve(A, B); print(X)\ntorch.allclose(A @ X, B)\ntensor([[[-0.0545, -0.1012,  0.7863, -0.0806, -0.0191],\n         [-0.9846, -0.0137, -1.7521, -0.4579, -0.8178],\n         [-1.9142, -0.6225, -1.9239, -0.6972,  0.7011]],\n        [[ 3.2094,  0.3432, -1.6604, -0.7885,  0.0088],\n         [ 7.9852,  1.4605, -1.7037, -0.7713,  2.7319],\n         [-4.1979,  0.0849,  1.0864,  0.3098, -1.0347]]])\nTrue\n\n\nMatrix inversions\n\nIt is faster and more numerically stable to solve a system of linear equations directly than to compute the inverse matrix first.\n\nLimit matrix inversions to situations where it is truly necessary.\nA = torch.rand(2, 3, 3)      # Batch of square matrices\nA_inv = torch.linalg.inv(A)  # Batch of inverse matrices\nA @ A_inv                    # Batch of identity matrices\ntensor([[[ 1.0000e+00, -6.0486e-07,  1.3859e-06],\n         [ 5.5627e-08,  1.0000e+00,  1.0795e-06],\n         [-1.4133e-07,  7.9992e-08,  1.0000e+00]],\n        [[ 1.0000e+00,  4.3329e-08, -3.6741e-09],\n         [-7.4627e-08,  1.0000e+00,  1.4579e-07],\n         [-6.3580e-08,  8.2354e-08,  1.0000e+00]]])\n\n\nOther linear algebra functions\ntorch.linalg contains many more functions:\n\ntorch.tensordot which generalizes matrix products,\ntorch.linalg.tensorsolve which computes the solution X to the system torch.tensordot(A, X) = B,\ntorch.linalg.eigvals which computes the eigenvalues of a square matrix,\n‚Ä¶",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "PyTorch tensors in depth",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/wb_torchtensors_content.html#device-attribute",
    "href": "ai/pt/wb_torchtensors_content.html#device-attribute",
    "title": "Everything you wanted to know (and more!) about PyTorch tensors",
    "section": "Device attribute",
    "text": "Device attribute\nTensor data can be placed in the memory of various processor types:\n\nthe RAM of CPU,\nthe RAM of a GPU with CUDA support,\nthe RAM of a GPU with AMD‚Äôs ROCm support,\nthe RAM of an XLA device (e.g.¬†Cloud TPU) with the torch_xla package.\n\nThe values for the device attributes are:\n\nCPU: ¬†'cpu'\nGPU (CUDA and AMD‚Äôs ROCm): ¬†'cuda'\nXLA: ¬†xm.xla_device()\n\nThis last option requires to load the torch_xla package first:\nimport torch_xla\nimport torch_xla.core.xla_model as xm\n\nCreating a tensor on a specific device\nBy default, tensors are created on the CPU:\nt1 = torch.rand(2); print(t1)\ntensor([0.1606, 0.9771])  # Implicit: device='cpu'\n\nPrinted tensors only display attributes with values ‚â† default values.\n\nYou can create a tensor on an accelerator by specifying the device attribute:\nt2_gpu = torch.rand(2, device='cuda'); print(t2_gpu)\ntensor([0.0664, 0.7829], device='cuda:0')  # :0 means the 1st GPU\n\n\nCopying a tensor to a specific device\nYou can also make copies of a tensor on other devices:\n# Make a copy of t1 on the GPU\nt1_gpu = t1.to(device='cuda'); print(t1_gpu)\nt1_gpu = t1.cuda()  # Same as above written differently\n\n# Make a copy of t2_gpu on the CPU\nt2 = t2_gpu.to(device='cpu'); print(t2)\nt2 = t2_gpu.cpu()   # For the altenative form\ntensor([0.1606, 0.9771], device='cuda:0')\ntensor([0.0664, 0.7829]) # Implicit: device='cpu'\n\n\nMultiple GPUs\nIf you have multiple GPUs, you can optionally specify which one a tensor should be created on or copied to:\nt3_gpu = torch.rand(2, device='cuda:0')  # Create a tensor on 1st GPU\nt4_gpu = t1.to(device='cuda:0')          # Make a copy of t1 on 1st GPU\nt5_gpu = t1.to(device='cuda:1')          # Make a copy of t1 on 2nd GPU\nOr the equivalent short forms for the last two:\nt4_gpu = t1.cuda(0)\nt5_gpu = t1.cuda(1)\n\n\nTiming\nLet‚Äôs compare the timing of some matrix multiplications on CPU and GPU with PyTorch built-in benchmark utility:\n# Load utility\nimport torch.utils.benchmark as benchmark\n# Define tensors on the CPU\nA = torch.randn(500, 500)\nB = torch.randn(500, 500)\n# Define tensors on the GPU\nA_gpu = torch.randn(500, 500, device='cuda')\nB_gpu = torch.randn(500, 500, device='cuda')\n\nI ran the code on my laptop with a dedicated GPU and 32GB RAM.\n\nLet‚Äôs time 100 runs to have a reliable benchmark:\nt0 = benchmark.Timer(\n    stmt='A @ B',\n    globals={'A': A, 'B': B})\n\nt1 = benchmark.Timer(\n    stmt='A_gpu @ B_gpu',\n    globals={'A_gpu': A_gpu, 'B_gpu': B_gpu})\n\nprint(t0.timeit(100))\nprint(t1.timeit(100))\nA @ B\n  2.29 ms\n  1 measurement, 100 runs , 1 thread\n\nA_gpu @ B_gpu\n  108.02 us\n  1 measurement, 100 runs , 1 thread\nSpeedup:\n(2.29 * 10**-3)/(108.02 * 10**-6) = 21\nThis computation was 21 times faster on my GPU than on CPU.\nBy replacing 500 with 5000, we get:\nA @ B\n  2.21 s\n  1 measurement, 100 runs , 1 thread\n\nA_gpu @ B_gpu\n  57.88 ms\n  1 measurement, 100 runs , 1 thread\nSpeedup:\n2.21/(57.88 * 10**-3) = 38\nThe larger the computation, the greater the benefit: now 38 times faster.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "PyTorch tensors in depth",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/wb_torchtensors_content.html#parallel-tensor-operations",
    "href": "ai/pt/wb_torchtensors_content.html#parallel-tensor-operations",
    "title": "Everything you wanted to know (and more!) about PyTorch tensors",
    "section": "Parallel tensor operations",
    "text": "Parallel tensor operations\nPyTorch already allows for distributed training of ML models.\nThe implementation of distributed tensor operations‚Äîfor instance for linear algebra‚Äîis in the work through the use of a ShardedTensor primitive that can be sharded across nodes.\nSee also this issue for more comments about upcoming developments on (among other things) tensor sharding.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "PyTorch tensors in depth",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/wb_fastai.html",
    "href": "ai/pt/wb_fastai.html",
    "title": "fastai",
    "section": "",
    "text": "fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains. This webinar will take a closer look at the features and functionality of fastai.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Easier PyTorch with fastai"
    ]
  },
  {
    "objectID": "ai/pt/pt_training.html",
    "href": "ai/pt/pt_training.html",
    "title": "Training",
    "section": "",
    "text": "After you have created the data loaders and defined your model, it is time to improve the weights and biases through training."
  },
  {
    "objectID": "ai/pt/pt_training.html#chose-hyperparameters",
    "href": "ai/pt/pt_training.html#chose-hyperparameters",
    "title": "Training",
    "section": "Chose hyperparameters",
    "text": "Chose hyperparameters\nWhile the learning parameters of a model (weights and biases) are the values that get adjusted through training (and they will become part of the final program, along with the model architecture, once training is over), hyperparameters control the training process.\nThey include:\n\nthe batch size: number of samples passed through the model before the parameters are updated,\nthe number of epochs: number iterations,\nthe learning rate (lr): size of the incremental changes to model parameters at each iteration. Smaller values yield slow learning speed, while large values may miss minima.\n\nLet‚Äôs define them here:\nlearning_rate = 1e-3\nbatch_size = 64\nepochs = 5"
  },
  {
    "objectID": "ai/pt/pt_training.html#define-the-loss-function",
    "href": "ai/pt/pt_training.html#define-the-loss-function",
    "title": "Training",
    "section": "Define the loss function",
    "text": "Define the loss function\nTo assess the predicted outputs of our model against the true values from the labels, we also need a loss function (e.g.¬†mean square error for regressions: nn.MSELoss or negative log likelihood for classification: nn.NLLLoss)\nThe machine learning literature is rich in information about various loss functions.\nHere is an example with nn.CrossEntropyLoss which combines nn.LogSoftmax and nn.NLLLoss:\nloss_fn = nn.CrossEntropyLoss()"
  },
  {
    "objectID": "ai/pt/pt_training.html#initialize-the-optimizer",
    "href": "ai/pt/pt_training.html#initialize-the-optimizer",
    "title": "Training",
    "section": "Initialize the optimizer",
    "text": "Initialize the optimizer\nThe optimization algorithm determines how the model parameters get adjusted at each iteration.\nThere are many optimizers and you need to search in the literature which one performs best for your time of model and data.\nBelow is an example with stochastic gradient descent:\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n\nlr is the learning rate.\nmomentum is a method increasing convergence rate and reducing oscillation for SDG."
  },
  {
    "objectID": "ai/pt/pt_training.html#define-the-train-and-test-loops",
    "href": "ai/pt/pt_training.html#define-the-train-and-test-loops",
    "title": "Training",
    "section": "Define the train and test loops",
    "text": "Define the train and test loops\nFinally, we need to define the train and test loops.\nThe train loop:\n\ngets a batch of training data from the DataLoader,\nresets the gradients of model parameters with optimizer.zero_grad(),\ncalculates predictions from the model for an input batch,\ncalculates the loss for that set of predictions vs.¬†the labels on the dataset,\ncalculates the backward gradients over the learning parameters (that‚Äôs the backpropagation) with loss.backward(),\nadjusts the parameters by the gradients collected in the backward pass with optimizer.step().\n\nThe test loop evaluates the model‚Äôs performance against the test data.\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    for batch, (X, y) in enumerate(dataloader):\n        # Compute prediction and loss\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), batch * len(X)\n            print(f\"loss: {loss:&gt;7f}  [{current:&gt;5d}/{size:&gt;5d}]\")\n\n\ndef test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    test_loss, correct = 0, 0\n\n    with torch.no_grad():\n        for X, y in dataloader:\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n\n    test_loss /= num_batches\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):&gt;0.1f}%, Avg loss: {test_loss:&gt;8f} \\n\")"
  },
  {
    "objectID": "ai/pt/pt_training.html#train",
    "href": "ai/pt/pt_training.html#train",
    "title": "Training",
    "section": "Train",
    "text": "Train\nTo train our model, we run the loop over the epochs:\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, model, loss_fn, optimizer)\n    test(test_dataloader, model, loss_fn)\nprint(\"Training completed\")"
  },
  {
    "objectID": "ai/pt/pt_supervised_learning.html",
    "href": "ai/pt/pt_supervised_learning.html",
    "title": "Understanding supervised learning",
    "section": "",
    "text": "In supervised learning, neural networks learn by adjusting their parameters automatically in an iterative manner. This is derived from Arthur Samuel‚Äôs concept.\nIt is important to get a good understanding of this process, so let‚Äôs go over it step by step."
  },
  {
    "objectID": "ai/pt/pt_supervised_learning.html#decide-on-an-architecture",
    "href": "ai/pt/pt_supervised_learning.html#decide-on-an-architecture",
    "title": "Understanding supervised learning",
    "section": "Decide on an architecture",
    "text": "Decide on an architecture\n\nThe architecture won‚Äôt change during training. This is set. The type of architecture you choose (e.g.¬†CNN, Transformer, etc.) depends on the type of data you have (e.g.¬†vision, textual, etc.). The depth and breadth of your network depend on the amount of data and computing resource you have."
  },
  {
    "objectID": "ai/pt/pt_supervised_learning.html#set-some-initial-parameters",
    "href": "ai/pt/pt_supervised_learning.html#set-some-initial-parameters",
    "title": "Understanding supervised learning",
    "section": "Set some initial parameters",
    "text": "Set some initial parameters\n\nYou can initialize them randomly or get much better ones through transfer learning.\nWhile the parameters are also part of the model, those will change during training."
  },
  {
    "objectID": "ai/pt/pt_supervised_learning.html#get-some-labelled-data",
    "href": "ai/pt/pt_supervised_learning.html#get-some-labelled-data",
    "title": "Understanding supervised learning",
    "section": "Get some labelled data",
    "text": "Get some labelled data\n\nWhen we say that we need a lot of data for machine learning, we mean ‚Äúlots of labelled data‚Äù as this is what gets used for training models."
  },
  {
    "objectID": "ai/pt/pt_supervised_learning.html#make-sure-to-keep-some-data-for-testing",
    "href": "ai/pt/pt_supervised_learning.html#make-sure-to-keep-some-data-for-testing",
    "title": "Understanding supervised learning",
    "section": "Make sure to keep some data for testing",
    "text": "Make sure to keep some data for testing\n\nThose data won‚Äôt be used for training the model. Often people keep around 20% of their data for testing."
  },
  {
    "objectID": "ai/pt/pt_supervised_learning.html#pass-data-and-parameters-through-the-architecture",
    "href": "ai/pt/pt_supervised_learning.html#pass-data-and-parameters-through-the-architecture",
    "title": "Understanding supervised learning",
    "section": "Pass data and parameters through the architecture",
    "text": "Pass data and parameters through the architecture\n\nThe train data are the inputs and the process of calculating the outputs is the forward pass."
  },
  {
    "objectID": "ai/pt/pt_supervised_learning.html#the-outputs-of-the-model-are-predictions",
    "href": "ai/pt/pt_supervised_learning.html#the-outputs-of-the-model-are-predictions",
    "title": "Understanding supervised learning",
    "section": "The outputs of the model are predictions",
    "text": "The outputs of the model are predictions"
  },
  {
    "objectID": "ai/pt/pt_supervised_learning.html#compare-those-predictions-to-the-train-labels",
    "href": "ai/pt/pt_supervised_learning.html#compare-those-predictions-to-the-train-labels",
    "title": "Understanding supervised learning",
    "section": "Compare those predictions to the train labels",
    "text": "Compare those predictions to the train labels\n\nSince our data was labelled, we know what the true outputs are."
  },
  {
    "objectID": "ai/pt/pt_supervised_learning.html#calculate-train-loss",
    "href": "ai/pt/pt_supervised_learning.html#calculate-train-loss",
    "title": "Understanding supervised learning",
    "section": "Calculate train loss",
    "text": "Calculate train loss\n\nThe deviation of our predictions from the true outputs gives us a measure of training loss."
  },
  {
    "objectID": "ai/pt/pt_supervised_learning.html#adjust-parameters",
    "href": "ai/pt/pt_supervised_learning.html#adjust-parameters",
    "title": "Understanding supervised learning",
    "section": "Adjust parameters",
    "text": "Adjust parameters\n\nThe parameters get automatically adjusted to reduce the training loss through the mechanism of backpropagation.\nThis is the actual training part.\nThis process is repeated many times. Training models is pretty much a giant for loop."
  },
  {
    "objectID": "ai/pt/pt_supervised_learning.html#from-model-to-program",
    "href": "ai/pt/pt_supervised_learning.html#from-model-to-program",
    "title": "Understanding supervised learning",
    "section": "From model to program",
    "text": "From model to program\n\nRemember that the model architecture is fixed, but that the parameters change at each iteration of the training process.\nWhile the labelled data are key to training, what we are really interested in is the combination of architecture + final parameters.\n\nWhen the training is over, the parameters become fixed. Which means that our model now behaves like a classic program."
  },
  {
    "objectID": "ai/pt/pt_supervised_learning.html#evaluate-the-model",
    "href": "ai/pt/pt_supervised_learning.html#evaluate-the-model",
    "title": "Understanding supervised learning",
    "section": "Evaluate the model",
    "text": "Evaluate the model\n\nWe can now use the testing set (which was never used to train the model) to evaluate our model: if we pass the test inputs through our program, we get some predictions that we can compare to the test labels (which are the true outputs).\nThis gives us the test loss: a measure of how well our model performs."
  },
  {
    "objectID": "ai/pt/pt_supervised_learning.html#use-the-model",
    "href": "ai/pt/pt_supervised_learning.html#use-the-model",
    "title": "Understanding supervised learning",
    "section": "Use the model",
    "text": "Use the model\n\nNow that we have a program, we can use it on unlabelled inputs to get what people ultimately want: unknown outputs. This is when we put our model to actual use to solve some problem."
  },
  {
    "objectID": "ai/pt/pt_pytorch.html",
    "href": "ai/pt/pt_pytorch.html",
    "title": "The PyTorch API",
    "section": "",
    "text": "PyTorch is a free and open-source machine learning and scientific computing framework based on Torch. While Torch uses a scripting language based on Lua, PyTorch has a Python and a C++ interface.\nCreated by Meta AI (formerly Facebook, Inc.) in 2017, it is now a project of The Linux Foundation.\nPyTorch is widely used in academia and research. Part of its popularity stems from the fact that the Python interface is truly pythonic in nature, making it easier to learn than other popular frameworks such as TensorFlow.\nThe PyTorch API is vast and complex. This section links to the key components to get you started.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "The PyTorch API"
    ]
  },
  {
    "objectID": "ai/pt/pt_pytorch.html#domain-specific-libraries",
    "href": "ai/pt/pt_pytorch.html#domain-specific-libraries",
    "title": "The PyTorch API",
    "section": "Domain-specific libraries",
    "text": "Domain-specific libraries\nPyTorch is a large framework with domain-specific libraries:\n\nTorchVision for computer vision,\nTorchText for natural languages,\nTorchAudio for audio and signal processing.\n\nThese libraries contain standard datasets and utilities specific to the data in those fields.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "The PyTorch API"
    ]
  },
  {
    "objectID": "ai/pt/pt_pytorch.html#loading-data",
    "href": "ai/pt/pt_pytorch.html#loading-data",
    "title": "The PyTorch API",
    "section": "Loading data",
    "text": "Loading data\ntorch.utils.data contains everything you need create data loaders (iterables that present the data to a model).",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "The PyTorch API"
    ]
  },
  {
    "objectID": "ai/pt/pt_pytorch.html#building-models",
    "href": "ai/pt/pt_pytorch.html#building-models",
    "title": "The PyTorch API",
    "section": "Building models",
    "text": "Building models\ntorch.nn contains the elements you need to build your model architecture and chose a loss function.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "The PyTorch API"
    ]
  },
  {
    "objectID": "ai/pt/pt_pytorch.html#training",
    "href": "ai/pt/pt_pytorch.html#training",
    "title": "The PyTorch API",
    "section": "Training",
    "text": "Training\nTraining a model consists of optimizing the model parameters.\ntorch.autograd contains the tools for automatic differentiation (to compute the gradients, that is the tensors containing the partial derivatives of the error with respect to the parameters of the functions in the model) and torch.optim contains optimization algorithms that can be used for gradient descent.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "The PyTorch API"
    ]
  },
  {
    "objectID": "ai/pt/pt_nn_content.html",
    "href": "ai/pt/pt_nn_content.html",
    "title": "NN vs biological neurons Types of NN",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.\nWhile biological neurons are connected in extremely intricate patterns, artificial ones follow a layered structure. Another difference in complexity is in the number of units: the human brain has 65‚Äì90 billion neurons. ANN have much fewer units.\nThe information in biological neurons is an all-or-nothing electrochemical pulse or action potential. Greater stimuli don‚Äôt produce stronger signals but increase firing frequency. In contrast, artificial neurons pass the computation of their inputs through an activation function and the output can take any of the values possible with that function.\nCentral to both systems is the concept of learning.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Introduction to NN",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/pt_nn_content.html#fully-connected-neural-networks",
    "href": "ai/pt/pt_nn_content.html#fully-connected-neural-networks",
    "title": "NN vs biological neurons Types of NN",
    "section": "Fully connected neural networks",
    "text": "Fully connected neural networks\n\n\n\n\n\nFrom Glosser.ca, Wikipedia\n\n\n\nEach neuron receives inputs from every neuron of the previous layer and passes its output to every neuron of the next layer.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Introduction to NN",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/pt_nn_content.html#convolutional-neural-networks",
    "href": "ai/pt/pt_nn_content.html#convolutional-neural-networks",
    "title": "NN vs biological neurons Types of NN",
    "section": "Convolutional neural networks",
    "text": "Convolutional neural networks\n\n\n\nFrom Programming Journeys by Rensu Theart\n\n\nConvolutional neural networks (CNN) are used for spatially structured data (e.g.¬†images).\nImages have huge input sizes and would require a very large number of neurons in a fully connected neural net. In convolutional layers, neurons receive input from a subarea (called local receptive field) of the previous layer. This greatly reduces the number of parameters. Optionally, pooling (combining the outputs of neurons in a subarea) reduces the data dimensions.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Introduction to NN",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/pt_nn_content.html#recurrent-neural-networks",
    "href": "ai/pt/pt_nn_content.html#recurrent-neural-networks",
    "title": "NN vs biological neurons Types of NN",
    "section": "Recurrent neural networks",
    "text": "Recurrent neural networks\n\n\n\nFrom fdeloche, Wikipedia\n\n\nRecurrent neural networks (RNN) such as Long Short-Term Memory (LSTM) are used for chain structured data (e.g.¬†text).\nThey are not feedforward networks (i.e.¬†networks for which the information moves only in the forward direction without any loop).",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Introduction to NN",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/pt_nn_content.html#transformers",
    "href": "ai/pt/pt_nn_content.html#transformers",
    "title": "NN vs biological neurons Types of NN",
    "section": "Transformers",
    "text": "Transformers\nA combination of two RNNs (the encoder and the decoder) is used in sequence to sequence models for translation or picture captioning.\nIn 2014 the concept of attention (giving added weight to important words) was developed, greatly improving the ability of such models to process a lot of data.\nThe problem with recurrence is that it is not easily to parallelize (and thus to run fast on GPUs).\nIn 2017, a new model‚Äîthe transformer‚Äîwas proposed: by using only attention mechanisms and no recurrence, the transformer achieves better results in an easily parallelizable fashion.\nWith the addition of transfer learning, powerful transformers emerged in the field of NLP (e.g.¬†Bidirectional Encoder Representations from Transformers (BERT) from Google and Generative Pre-trained Transformer-3 (GPT-3) from OpenAI).\n\n\n\n\n\n\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ‚Ä¶ & Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing systems, 30",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Introduction to NN",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/pt_model.html",
    "href": "ai/pt/pt_model.html",
    "title": "Building a model",
    "section": "",
    "text": "Key to creating neural networks in PyTorch is the torch.nn package which contains the nn.Module and a forward method which returns an output from some input.\nLet‚Äôs build a neural network to classify the MNIST.\n\nFirst, we need to define the architecture of the network. There are many types of architectures. For images, CNN are well suited.\nIn Python, you can define a subclass of an existing class with:\nclass YourSubclass(BaseClass):\n    &lt;definition of your subclass&gt;        \nThe subclass is derived from the base class and inherits its properties. PyTorch contains the class torch.nn.Module which is used as the base class when defining a neural network.\n\n# Load packages\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    # Define the architecture of the network\n    def __init__(self):\n        super(Net, self).__init__()\n        # 1 input image channel, 6 output channels,\n        # 5x5 square convolution kernel\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        # an affine operation: y = Wx + b\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    # Set the flow of data through the network for the forward pass\n    # x represents the data\n    def forward(self, x):\n        # Max pooling over a (2, 2) window\n        # F.relu is the rectified-linear activation function\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        # If the size is a square, you can specify with a single number\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        # flatten all dimensions except the batch dimension\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nLet‚Äôs create an instance of Net and print its structure:\n\nnet = Net()\nprint(net)\n\nNet(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)\n\n\n\nparams = list(net.parameters())\nprint(len(params))\nprint(params[0].size())  # conv1's .weight\n\n10\ntorch.Size([6, 1, 5, 5])"
  },
  {
    "objectID": "ai/pt/pt_intro_slides.html#ml-allows-to-achieve-previously-impossible-tasks",
    "href": "ai/pt/pt_intro_slides.html#ml-allows-to-achieve-previously-impossible-tasks",
    "title": "Introduction to machine learning",
    "section": "ML allows to achieve previously impossible tasks",
    "text": "ML allows to achieve previously impossible tasks\n\nLet‚Äôs take the example of image recognition:\n\nIn typical computing, a programmer writes code that gives a computer detailed instructions of what to do\nCoding all the possible ways‚Äîpixel by pixel‚Äîthat an image can represent, say, a dog is an impossibly large task: there are many breeds of dogs, the image can be a picture, a blurred picture, a drawing, a cartoon, the dog can be in all sorts of positions, wearing clothes, etc\nThere just aren‚Äôt enough resources to make the traditional programming approach able to create a computer program that can identify a dog in images\nBy feeding a very large number of dog images to a neural network however, we can train that network to recognize dogs in images that it has never seen (without explicitly programming how it does this!)"
  },
  {
    "objectID": "ai/pt/pt_intro_slides.html#old-concept-new-computing-power",
    "href": "ai/pt/pt_intro_slides.html#old-concept-new-computing-power",
    "title": "Introduction to machine learning",
    "section": "Old concept ‚Ä¶ new computing power",
    "text": "Old concept ‚Ä¶ new computing power\nThe concept is everything but new: Arthur Samuel came up with it in 1949 and built a self-learning Checkers-playing program in 1959\n\n\nMachine learning consists of feeding vast amounts of data to algorithms to strengthen pathways, so the excitement for the approach became somewhat dormant due to the lack of computing power and the lack of training data at the time\nThe advent of powerful computers, GPUs, and massive amounts of data have brought the old concept to the forefront\n\n\n\n\n\n\nFrom xkcd.com"
  },
  {
    "objectID": "ai/pt/pt_intro_slides.html#supervised-learning",
    "href": "ai/pt/pt_intro_slides.html#supervised-learning",
    "title": "Introduction to machine learning",
    "section": "Supervised learning",
    "text": "Supervised learning\n\nRegression is a form of supervised learning with continuous outputs\nClassification is supervised learning with discrete outputs\n\nSupervised learning uses training data in the form of example input/output pairs\nGoal\nFind the relationship between inputs and outputs"
  },
  {
    "objectID": "ai/pt/pt_intro_slides.html#unsupervised-learning",
    "href": "ai/pt/pt_intro_slides.html#unsupervised-learning",
    "title": "Introduction to machine learning",
    "section": "Unsupervised learning",
    "text": "Unsupervised learning\nClustering, social network analysis, market segmentation, PCA ‚Ä¶ are all forms of unsupervised learning\nUnsupervised learning uses unlabelled data\nGoal\nFind structure within the data"
  },
  {
    "objectID": "ai/pt/pt_intro_slides.html#reinforcement-learning",
    "href": "ai/pt/pt_intro_slides.html#reinforcement-learning",
    "title": "Introduction to machine learning",
    "section": "Reinforcement learning",
    "text": "Reinforcement learning\nThe algorithm explores by performing random actions and these actions are rewarded or punished (bonus points or penalties)\nThis is how algorithms learn to play games"
  },
  {
    "objectID": "ai/pt/pt_intro_slides.html#decide-on-an-architecture",
    "href": "ai/pt/pt_intro_slides.html#decide-on-an-architecture",
    "title": "Introduction to machine learning",
    "section": "Decide on an architecture",
    "text": "Decide on an architecture\n\nThe architecture won‚Äôt change during training\nThe type of architecture you choose (e.g.¬†CNN, Transformer) depends on the type of data you have (e.g.¬†vision, textual). The depth and breadth of your network depend on the amount of data and computing resource you have"
  },
  {
    "objectID": "ai/pt/pt_intro_slides.html#set-some-initial-parameters",
    "href": "ai/pt/pt_intro_slides.html#set-some-initial-parameters",
    "title": "Introduction to machine learning",
    "section": "Set some initial parameters",
    "text": "Set some initial parameters\n\nYou can initialize them randomly or get much better ones through transfer learning\nWhile the parameters are also part of the model, those will change during training"
  },
  {
    "objectID": "ai/pt/pt_intro_slides.html#get-some-labelled-data",
    "href": "ai/pt/pt_intro_slides.html#get-some-labelled-data",
    "title": "Introduction to machine learning",
    "section": "Get some labelled data",
    "text": "Get some labelled data\n\nWhen we say that we need a lot of data for machine learning, we mean ‚Äúlots of labelled data‚Äù as this is what gets used for training models"
  },
  {
    "objectID": "ai/pt/pt_intro_slides.html#make-sure-to-keep-some-data-for-testing",
    "href": "ai/pt/pt_intro_slides.html#make-sure-to-keep-some-data-for-testing",
    "title": "Introduction to machine learning",
    "section": "Make sure to keep some data for testing",
    "text": "Make sure to keep some data for testing\n\nThose data won‚Äôt be used for training the model. Often people keep around 20% of their data for testing"
  },
  {
    "objectID": "ai/pt/pt_intro_slides.html#pass-data-and-parameters-through-the-architecture",
    "href": "ai/pt/pt_intro_slides.html#pass-data-and-parameters-through-the-architecture",
    "title": "Introduction to machine learning",
    "section": "Pass data and parameters through the architecture",
    "text": "Pass data and parameters through the architecture\n\nThe train data are the inputs and the process of calculating the outputs is the forward pass"
  },
  {
    "objectID": "ai/pt/pt_intro_slides.html#the-outputs-of-the-model-are-predictions",
    "href": "ai/pt/pt_intro_slides.html#the-outputs-of-the-model-are-predictions",
    "title": "Introduction to machine learning",
    "section": "The outputs of the model are predictions",
    "text": "The outputs of the model are predictions"
  },
  {
    "objectID": "ai/pt/pt_intro_slides.html#compare-those-predictions-to-the-train-labels",
    "href": "ai/pt/pt_intro_slides.html#compare-those-predictions-to-the-train-labels",
    "title": "Introduction to machine learning",
    "section": "Compare those predictions to the train labels",
    "text": "Compare those predictions to the train labels\n\nSince our data was labelled, we know what the true outputs are"
  },
  {
    "objectID": "ai/pt/pt_intro_slides.html#calculate-train-loss",
    "href": "ai/pt/pt_intro_slides.html#calculate-train-loss",
    "title": "Introduction to machine learning",
    "section": "Calculate train loss",
    "text": "Calculate train loss\n\nThe deviation of our predictions from the true outputs gives us a measure of training loss"
  },
  {
    "objectID": "ai/pt/pt_intro_slides.html#adjust-parameters",
    "href": "ai/pt/pt_intro_slides.html#adjust-parameters",
    "title": "Introduction to machine learning",
    "section": "Adjust parameters",
    "text": "Adjust parameters\n\nThe parameters get automatically adjusted to reduce the training loss through the mechanism of backpropagation. This is the actual training part\nThis process is repeated many times. Training models is pretty much a giant for loop"
  },
  {
    "objectID": "ai/pt/pt_intro_slides.html#from-model-to-program",
    "href": "ai/pt/pt_intro_slides.html#from-model-to-program",
    "title": "Introduction to machine learning",
    "section": "From model to program",
    "text": "From model to program\n\nRemember that the model architecture is fixed, but that the parameters change at each iteration of the training process"
  },
  {
    "objectID": "ai/pt/pt_intro_slides.html#evaluate-the-model",
    "href": "ai/pt/pt_intro_slides.html#evaluate-the-model",
    "title": "Introduction to machine learning",
    "section": "Evaluate the model",
    "text": "Evaluate the model\n\nWe can now use the testing set (which was never used to train the model) to evaluate our model: if we pass the test inputs through our program, we get some predictions that we can compare to the test labels (which are the true outputs)\nThis gives us the test loss: a measure of how well our model performs"
  },
  {
    "objectID": "ai/pt/pt_intro_slides.html#use-the-model",
    "href": "ai/pt/pt_intro_slides.html#use-the-model",
    "title": "Introduction to machine learning",
    "section": "Use the model",
    "text": "Use the model\n\nNow that we have a program, we can use it on unlabelled inputs to get what people ultimately want: unknown outputs\nThis is when we put our model to actual use to solve some problem"
  },
  {
    "objectID": "ai/pt/pt_intro.html",
    "href": "ai/pt/pt_intro.html",
    "title": "Introduction to machine learning",
    "section": "",
    "text": "This presentation gives a high-level overview of machine learning.\nI will define concepts, present the different types of learning, and explain the basic functioning of neural networks.\n\nSlides (Click and wait: the presentation might take a few instants to load)\nSlides content for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Introduction"
    ]
  },
  {
    "objectID": "ai/pt/pt_high_level_frameworks.html",
    "href": "ai/pt/pt_high_level_frameworks.html",
    "title": "High-level frameworks for PyTorch",
    "section": "",
    "text": "Several popular higher-level frameworks are built on top of PyTorch and make the code easier to write and run:\nThe following tag trends on Stack Overflow might give an idea of the popularity of these frameworks over time (catalyst doesn‚Äôt have any Stack Overflow tag):\nIf this data is to be believed, ignite never really took off (it also has a lower number of stars on GitHub), fast-ai was extremely popular when it came out, but its usage is going down, and PyTorch-lightning is currently the most popular.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "High-level frameworks"
    ]
  },
  {
    "objectID": "ai/pt/pt_high_level_frameworks.html#should-you-use-one-and-which-one",
    "href": "ai/pt/pt_high_level_frameworks.html#should-you-use-one-and-which-one",
    "title": "High-level frameworks for PyTorch",
    "section": "Should you use one (and which one)?",
    "text": "Should you use one (and which one)?\nLearning raw PyTorch is probably the best option for research. PyTorch is stable and here to stay. Higher-level frameworks may rise and drop in popularity and today‚Äôs popular one may see little usage tomorrow.\nRaw PyTorch is also the most flexible, the closest to the actual computations happening in your model, and probably the easiest to debug.\nDepending on your deep learning trajectory, you might find some of these tools useful though:\n\nIf you work in industry, you might want or need to get results quickly\nSome operations (e.g.¬†parallel execution on multiple GPUs) can be tricky in raw PyTorch, while being extremely streamlined when using e.g.¬†PyTorch-lightning\nEven in research, it might make sense to spend more time thinking about the structure of your model and the functioning of a network instead of getting bogged down in writing code\n\n\nBefore moving to any of these tools, it is probably a good idea to get a good knowledge of raw PyTorch: use these tools to simplify your workflow, not cloud your understanding of what your code is doing.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "High-level frameworks"
    ]
  },
  {
    "objectID": "ai/pt/pt_concepts.html",
    "href": "ai/pt/pt_concepts.html",
    "title": "Concepts:",
    "section": "",
    "text": "Artificial intelligence is a vast field: any system mimicking animal intelligence falls in its scope.\nMachine learning (ML) is a subfield of artificial intelligence that can be defined as computer programs whose performance at a task improves with experience.\nSince this experience comes in the form of data, ML consists of feeding vast amounts of data to algorithms to strengthen pathways.\n\n\n\nfrom xkcd.com\n\n\n\n\nCoding all the possible ways‚Äîpixel by pixel‚Äîthat a picture can represent a certain object is an impossibly large task. By feeding examples of images of that object to a neural network however, we can train it to recognize that object in images that it has never seen (without explicitly programming how it does this!).\n\n\n\nfrom xkcd.com"
  },
  {
    "objectID": "ai/pt/pt_concepts.html#what-is-machine-learning",
    "href": "ai/pt/pt_concepts.html#what-is-machine-learning",
    "title": "Concepts:",
    "section": "",
    "text": "Artificial intelligence is a vast field: any system mimicking animal intelligence falls in its scope.\nMachine learning (ML) is a subfield of artificial intelligence that can be defined as computer programs whose performance at a task improves with experience.\nSince this experience comes in the form of data, ML consists of feeding vast amounts of data to algorithms to strengthen pathways.\n\n\n\nfrom xkcd.com\n\n\n\n\nCoding all the possible ways‚Äîpixel by pixel‚Äîthat a picture can represent a certain object is an impossibly large task. By feeding examples of images of that object to a neural network however, we can train it to recognize that object in images that it has never seen (without explicitly programming how it does this!).\n\n\n\nfrom xkcd.com"
  },
  {
    "objectID": "ai/pt/pt_concepts.html#types-of-learning",
    "href": "ai/pt/pt_concepts.html#types-of-learning",
    "title": "Concepts:",
    "section": "Types of learning",
    "text": "Types of learning\nThere are now more types of learning than those presented here. But these initial types are interesting because they will already be familiar to you.\n\nSupervised learning\nYou have been doing supervised machine learning for years without looking at it in the framework of machine learning:\n\nRegression is a form of supervised learning with continuous outputs\nClassification is supervised learning with discrete outputs\n\nSupervised learning uses training data in the form of example input/output \\((x_i, y_i)\\) pairs.\nGoal:\nIf \\(X\\) is the space of inputs and \\(Y\\) the space of outputs, the goal is to find a function \\(h\\) so that\nfor each \\(x_i \\in X\\):\n\n\\(h_\\theta(x_i)\\) is a predictor for the corresponding value \\(y_i\\)\n\n(\\(\\theta\\) represents the set of parameters of \\(h_\\theta\\)).\n\n‚Üí i.e.¬†we want to find the relationship between inputs and outputs.\n\n\nUnsupervised learning\nHere too, you are familiar with some forms of unsupervised learning that you weren‚Äôt thinking about in such terms:\nClustering, social network analysis, market segmentation, PCA ‚Ä¶ are all forms of unsupervised learning.\nUnsupervised learning uses unlabelled data (training set of \\(x_i\\)).\nGoal:\nFind structure within the data.\n\n\n\nfrom xkcd.com"
  },
  {
    "objectID": "ai/pt/pt_concepts.html#artificial-neural-networks",
    "href": "ai/pt/pt_concepts.html#artificial-neural-networks",
    "title": "Concepts:",
    "section": "Artificial neural networks",
    "text": "Artificial neural networks\nArtificial neural networks (ANN) are one of the machine learning models (other models include decision trees or Bayesian networks). Their potential and popularity has truly exploded in recent years and this is what we will focus on in this course.\nArtificial neural networks are a series of layered units mimicking the concept of biological neurons: inputs are received by every unit of a layer, computed, then transmitted to units of the next layer. In the process of learning, experience strengthens some connections between units and weakens others.\nIn biological networks, the information consists of action potentials (neuron membrane rapid depolarizations) propagating through the network. In artificial ones, the information consists of tensors (multidimensional arrays) of weights and biases: each unit passes a weighted sum of an input tensor with an additional‚Äîpossibly weighted‚Äîbias through an activation function before passing on the output tensor to the next layer of units.\n\n\nThe bias allows to shift the output of the activation function to the right or to the left (i.e.¬†it creates an offset).\n\nSchematic of a biological neuron:\n\n\n\nfrom Dhp1080, Wikipedia\n\n\nSchematic of an artificial neuron:\n\n\n\nModified from O.C. Akgun & J. Mei 2019\n\n\nWhile biological neurons are connected in extremely intricate patterns, artificial ones follow a layered structure. Another difference in complexity is in the number of units: the human brain has 65‚Äì90 billion neurons. ANN have much fewer units.\nNeurons in mouse cortex:\n\n\n\nNeurons are in green, the dark branches are blood vessels. Image by Na Ji, UC Berkeley\n\n\nNeural network with 2 hidden layers:\n\n\n\nfrom The Maverick Meerkat\n\n\nThe information in biological neurons is an all-or-nothing electrochemical pulse or action potential. Greater stimuli don‚Äôt produce stronger signals but increase firing frequency. In contrast, artificial neurons pass the computation of their inputs through an activation function and the output can take any of the values possible with that function.\nThreshold potential in biological neurons:\n\n\n\nModified from Blacktc, Wikimedia\n\n\nSome of the most common activation functions in artificial neurons:\n\n\n\nfrom Diganta Misra 2019\n\n\nWhich activation function to use depends on the type of problem and the available computing budget. Some early functions have fallen out of use while new ones have emerged (e.g.¬†sigmoid got replaced by ReLU which is easier to train).\n\nLearning\nThe process of learning in biological NN happens through neuron death or growth and through the creation or loss of synaptic connections between neurons. In ANN, learning happens through optimization algorithms such as gradient descent which minimize cross entropy loss functions by adjusting the weights and biases connecting each layer of neurons over many iterations (cross entropy is the difference between the predicted and the real distributions).\n\n\n\nfrom xkcd.com\n\n\n\n\nGradient descent\nThere are several gradient descent methods:\nBatch gradient descent uses all examples in each iteration and is thus slow for large datasets (the parameters are adjusted only after all the samples have been processed).\nMini-batch gradient descent is an intermediate approach: it uses mini-batch sized examples in each iteration. This allows a vectorized approach (and hence parallelization).\nThe Adam optimization algorithm is a popular variation of mini-batch gradient descent.\nStochastic gradient descent uses one example in each iteration. It is thus much faster than batch gradient descent (the parameters are adjusted after each example). But it does not allow any vectorization.\n\n\n\nfrom Imad Dabbura\n\n\n\n\n3Blue1Brown by Grant Sanderson videos\n3Blue1Brown by Grant Sanderson has a series of 4 videos on neural networks which is easy to watch, fun, and does an excellent job at introducing the functioning of a simple neural network.\n\nWhat are NN? (19 min)\n\nWatch this video beyond the acknowledgement as the function ReLU (a really important function in modern neural networks) is introduced at the very end.\n\n\n\nAs you develop your own ML models, if you find that your mathematical background is shaky, 3blue1brown also has an excellent series of videos on linear algebra and an equally great one on calculus.\n\n\n\nHow do NN learn? (21 min)\n\n\n\nWhat is backpropagation? (14 min)\n\n\nThere is one minor terminological error in this video: they call the use of mini-batches stochastic gradient descent. In fact, this is called mini-batch gradient descent. Stochastic gradient descent uses a single example at each iteration.\n\n\n\nHow does backpropagation work? (10 min)\n\n\n\n\nTypes of ANN\n\nFully connected neural networks\n\n\n\nfrom Glosser.ca, Wikipedia\n\n\nEach neuron receives inputs from every neuron of the previous layer and passes its output to every neuron of the next layer.\n\n\nConvolutional neural networks\n\n\n\nfrom Programming Journeys by Rensu Theart\n\n\nConvolutional neural networks (CNN) are used for spatially structured data (e.g.¬†in image recognition).\nImages have huge input sizes and would require a very large number of neurons in a fully connected neural net. In convolutional layers, neurons receive input from a subarea (called local receptive field) of the previous layer. This greatly reduces the number of parameters.\nOptionally, pooling (combining the outputs of neurons in a subarea) reduces the data dimensions. The stride then dictates how the subarea is moved across the image. Max-pooling is one of the forms of pooling which uses the maximum for each subarea.\n\n\nRecurrent neural networks\n\n\n\nfrom fdeloche, Wikipedia\n\n\nRecurrent neural networks (RNN) such as Long Short-Term Memory (LSTM) are used for chain structured data (e.g.¬†in speech recognition).\nThey are not feedforward networks (i.e.¬†networks for which the information moves only in the forward direction without any loop).\n\n\nTransformers\nA combination of two RNNs or sets of RNNs (the encoder and the decoder) is used in sequence to sequence models for translation or picture captioning. Such models were slow to process a lot of data.\nIn 2014 and 2015, the concept of attention (giving added weight to important words) was developed, greatly improving the ability of such models to process a lot of data.\nThis blog post by Jay Alammar‚Äîa blogger whose high-quality posts have been referenced in MIT and Stanford courses‚Äîexplains this in a high-level visual fashion.\nThe problem with recurrence is that it is not easily to parallelize (and thus to run fast on GPUs).\nIn 2017, a new model‚Äîthe transformer‚Äîwas proposed: by using only attention mechanisms and no recurrence, the transformer achieves better results in an easily parallelizable fashion.\nJay Alammar has also a blog post on the transformer. The post includes a 30 min video.\nWith the addition of transfer learning, powerful transformers emerged in the field of NLP (Natural Language Processing). Examples include BERT (Bidirectional Encoder Representations from Transformers) from Google and GPT-3 (Generative Pre-trained Transformer-3) from OpenAI.\nJay Alammar has yet another great blog post on these advanced NLP models.\n\n\n\nDeep learning\nThe first layer of a neural net is the input layer. The last one is the output layer. All the layers in-between are called hidden layers. Shallow neural networks have only one hidden layer and deep networks have two or more hidden layers. When an ANN is deep, we talk about Deep Learning (DL).\n\n\n\nfrom xkcd.com"
  },
  {
    "objectID": "ai/pt/pt_checkpoints.html",
    "href": "ai/pt/pt_checkpoints.html",
    "title": "Saving/loading models and checkpointing",
    "section": "",
    "text": "After you have trained your model, obviously you will want to save it to use it thereafter. You will then need to load it in any session in which you want to use it.\nIn addition to saving or loading a fully trained model, it is important to know how to create regular checkpoints: training ML models takes a long time and a cluster crash or countless other issues might interrupt the training process. You don‚Äôt want to have to restart from scratch if that happens.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Creating checkpoints"
    ]
  },
  {
    "objectID": "ai/pt/pt_checkpoints.html#savingloading-models",
    "href": "ai/pt/pt_checkpoints.html#savingloading-models",
    "title": "Saving/loading models and checkpointing",
    "section": "Saving/loading models",
    "text": "Saving/loading models\n\nSaving models\nYou can save a model by serializing its internal state dictionary. The state dictionary is a Python dictionary that contains the learnable parameters of your model (weights and biases).\ntorch.save(model.state_dict(), \"model.pt\")\n\n\nLoading models\nTo recreate your model, you first need to recreate its structure:\nmodel = TheModelClass(*args, **kwargs)\nThen you can load the state dictionary containing the parameters values into it:\nmodel.load_state_dict(torch.load(\"model.pt\"))\nAssuming you want to use your model for inference, you also must run:\nmodel.eval()\n\nIf instead you want to do more training on your model, you would of course run model.train() instead.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Creating checkpoints"
    ]
  },
  {
    "objectID": "ai/pt/pt_checkpoints.html#checkpointing",
    "href": "ai/pt/pt_checkpoints.html#checkpointing",
    "title": "Saving/loading models and checkpointing",
    "section": "Checkpointing",
    "text": "Checkpointing\n\nCreating a checkpoint\ntorch.save({\n    'epoch': epoch,\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'loss': loss,\n    ...\n}, \"model.pt\")\n\n\nResuming training\nRecreate the state of your model from the checkpoint:\nmodel = TheModelClass(*args, **kwargs)\noptimizer = TheOptimizerClass(*args, **kwargs)\n\ncheckpoint = torch.load(\"model.pt\")\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\nResume training:\nmodel.train()",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Creating checkpoints"
    ]
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#lots-of-moving-parts",
    "href": "ai/mlops/wb_mlflow_slides.html#lots-of-moving-parts",
    "title": "Experiment tracking with",
    "section": "Lots of moving parts ‚Ä¶",
    "text": "Lots of moving parts ‚Ä¶\nAI experiments come with a lot of components:\n\nDatasets\nModel architectures\nHyperparameters\n\nWhile developing an efficient model, various datasets will be trained on various architectures tuned with various hyperparameters"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#making-for-challenging-tracking",
    "href": "ai/mlops/wb_mlflow_slides.html#making-for-challenging-tracking",
    "title": "Experiment tracking with",
    "section": "‚Ä¶ making for challenging tracking",
    "text": "‚Ä¶ making for challenging tracking\n\n*hp = hyperparameter\n\n\n\n\n\n\n\n\n\n\ndata1\n\ndata1\n\n\n\nmodel1\n\nmodel1\n\n\n\ndata1-&gt;model1\n\n\n\n\n\nmodel2\n\nmodel2\n\n\n\ndata1-&gt;model2\n\n\n\n\n\nmodel3\n\nmodel3\n\n\n\ndata1-&gt;model3\n\n\n\n\n\ndata2\n\ndata2\n\n\n\ndata2-&gt;model1\n\n\n\n\n\ndata2-&gt;model2\n\n\n\n\n\ndata2-&gt;model3\n\n\n\n\n\ndata3\n\ndata3\n\n\n\ndata3-&gt;model1\n\n\n\n\n\ndata3-&gt;model2\n\n\n\n\n\ndata3-&gt;model3\n\n\n\n\n\nhp1\n\nhp1\n\n\n\nhp1-&gt;model1\n\n\n\n\n\nhp1-&gt;model2\n\n\n\n\n\nhp1-&gt;model3\n\n\n\n\n\nhp2\n\nhp2\n\n\n\nhp2-&gt;model1\n\n\n\n\n\nhp2-&gt;model2\n\n\n\n\n\nhp2-&gt;model3\n\n\n\n\n\nhp3\n\nhp3\n\n\n\nhp3-&gt;model1\n\n\n\n\n\nhp3-&gt;model2\n\n\n\n\n\nhp3-&gt;model3\n\n\n\n\n\nperformance\n\nperformance1 ... performance27\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\n\n\n\n\n\n\nHow did we get performance19 again? ü§Ø"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#experiment-tracking-tools",
    "href": "ai/mlops/wb_mlflow_slides.html#experiment-tracking-tools",
    "title": "Experiment tracking with",
    "section": "Experiment tracking tools",
    "text": "Experiment tracking tools\nThe solution to this complexity is to use an experiment tracking tool such as MLflow and, optionally, a data versioning tool such as DVC\n\nSee our webinar on DVC"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#platform-for-ai-life-cycle",
    "href": "ai/mlops/wb_mlflow_slides.html#platform-for-ai-life-cycle",
    "title": "Experiment tracking with",
    "section": "Platform for AI life cycle",
    "text": "Platform for AI life cycle\n\n\n\nfrom MLflow website"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#use-cases",
    "href": "ai/mlops/wb_mlflow_slides.html#use-cases",
    "title": "Experiment tracking with",
    "section": "Use cases",
    "text": "Use cases\n\nCompare algorithms\nKeep track of pipelines\nGenerate SHAP plots (relative contributions of features to the prediction)\nTrack models at checkpoints\nCompare models with different datasets\nTrack hyperparameter tuning experiments\nVisualize plots of logged metrics in UI\nKeep models and model versions in a registry"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#foss-compatible",
    "href": "ai/mlops/wb_mlflow_slides.html#foss-compatible",
    "title": "Experiment tracking with",
    "section": "FOSS & compatible",
    "text": "FOSS & compatible\n\nOpen-source\nWorks with any ML or DL framework\nVendor-neutral if you run a server on a commercial platform\nCan be combined with dvc for dataset versioning\nWorks with any hyperparameter tuning framework ¬†‚ûî ¬†e.g.¬†integration with Optuna\n¬†‚ÄÇ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇ¬†integration with Ray Tune\n¬†‚ÄÇ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇ¬†integration with hyperopt"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#used-by-many-proprietary-tools",
    "href": "ai/mlops/wb_mlflow_slides.html#used-by-many-proprietary-tools",
    "title": "Experiment tracking with",
    "section": "Used by many proprietary tools",
    "text": "Used by many proprietary tools\nThe foundation of many proprietary no-code/low-code tuning platforms that just add a layer on top to interface with the user with text rather than code \n\ne.g.¬†Microsoft Fabric, FLAML"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#limitations",
    "href": "ai/mlops/wb_mlflow_slides.html#limitations",
    "title": "Experiment tracking with",
    "section": "Limitations",
    "text": "Limitations\n\nMessy documentation (code typos, circular, confusing, many ‚ÄúGetting started‚Äù sections)\nuv not fully integrated (not supported in MLflow projects)\nThe UI can be unstable and inconsistent\nServers are not very resilient to by bad workflows, deletion and recreation of files, etc.\nNested runs don‚Äôt get logged as children runs if the workflow is not followed carefully"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#install-mlflow",
    "href": "ai/mlops/wb_mlflow_slides.html#install-mlflow",
    "title": "Experiment tracking with",
    "section": "Install MLflow",
    "text": "Install MLflow\nWith uv\nCreate a uv project:\nuv init --bare\nInstall MLflow:\nuv add mlflow\n\nuv is an amazing Python projects/versions/virtual envs manager and I recommend using it on your machine. However, it is currently not supported on the Alliance clusters where you need to keep using pip or risk issues with undetected modules"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#install-mlflow-1",
    "href": "ai/mlops/wb_mlflow_slides.html#install-mlflow-1",
    "title": "Experiment tracking with",
    "section": "Install MLflow",
    "text": "Install MLflow\nWhile installing MLflow with uv works without issues, MLflow models artifacts contain a conda.yaml file which expects pip\nTo prevent getting the annoying warning:\nWARNING mlflow.utils.environment: Failed to resolve installed pip version.\n``pip`` will be added to conda.yaml environment spec\nwithout a version specifier.\neach time you log a model, you can install pip even if you never use it\n(or you can just ignore the warnings):\nuv add pip"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#definitions-in-mlflow-context",
    "href": "ai/mlops/wb_mlflow_slides.html#definitions-in-mlflow-context",
    "title": "Experiment tracking with",
    "section": "Definitions in MLflow context",
    "text": "Definitions in MLflow context\nParent run:\nOne experiment (e.g.¬†optimization task) containing multiple children (nested) runs\nChild run:\nIndividual execution of a model training event\nModel signature:\nDescription of a model input and output data structure, data types, and features names\nModel artifacts:\nOutputs of model training process: trained model, checkpoints, and associated metadata\nModel Uniform Resource Identifier (URI):\nUnique sequence of characters that identifies a model artifacts"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#mlflow-tracking-workflow",
    "href": "ai/mlops/wb_mlflow_slides.html#mlflow-tracking-workflow",
    "title": "Experiment tracking with",
    "section": "MLflow tracking workflow",
    "text": "MLflow tracking workflow\n\nCreate an experiment\nLaunch an MLflow server\nOpen the user interface in a browser to visualize the logged data\nLog tracking data (e.g.¬†train or tune a model)"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#mlflow-tracking-setup",
    "href": "ai/mlops/wb_mlflow_slides.html#mlflow-tracking-setup",
    "title": "Experiment tracking with",
    "section": "MLflow tracking setup",
    "text": "MLflow tracking setup\nYou can setup MLflow tracking locally or on a remote server, using databases or not1\nIn the next slides, I am breaking down the workflow for the various configurations\n\n\n1Usage without databases will be deprecated at some point and is not recommended"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section",
    "href": "ai/mlops/wb_mlflow_slides.html#section",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Create an experiment\n\n\n\n\n\n\nLocal\nimport mlflow\n\nmlflow.set_experiment(\"&lt;experiment-name&gt;\")\n Logs get stored in an mlruns directory\n\nThis method will be deprecated, so prefer the use of a database"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-1",
    "href": "ai/mlops/wb_mlflow_slides.html#section-1",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Create an experiment\n\n\n\n\n\n\nLocal with database\nimport mlflow\n\nmlflow.set_tracking_uri(\n    \"sqlite:///&lt;database-name&gt;.db\"\n)\nmlflow.set_experiment(\"&lt;experiment-name&gt;\")\nLogs get stored in a &lt;database-name&gt;.db file\n\nHere we use SQLite which works well for a local database"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-2",
    "href": "ai/mlops/wb_mlflow_slides.html#section-2",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Create an experiment\n\n\n\n\n\n\nRemote tracking server\n\nFor team development\n\n\nimport mlflow\n\nmlflow.set_tracking_uri(\"http://&lt;host&gt;:&lt;port&gt;\")\nmlflow.set_experiment(\"&lt;experiment-name&gt;\")"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-3",
    "href": "ai/mlops/wb_mlflow_slides.html#section-3",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Launch MLflow server\n\n\n\n\n\n\nLocal\nmlflow server\n\nThe server listens on http://localhost:5000 by default\n\nTo listen to another port (e.g.¬†8080):\nmlflow server --port 8080"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-4",
    "href": "ai/mlops/wb_mlflow_slides.html#section-4",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Launch MLflow server\n\n\n\n\n\n\nLocal with database\nmlflow server \\\n       --backend-store-uri \\\n       sqlite:///&lt;database-name&gt;.db\n\n\nDefault port is 5000. To use another port (e.g.¬†8080):\nmlflow server \\\n       --backend-store-uri \\\n       sqlite:///&lt;database-name&gt;.db \\\n       --port 8080"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-5",
    "href": "ai/mlops/wb_mlflow_slides.html#section-5",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Launch MLflow server\n\n\n\n\n\n\nRemote tracking server\nmlflow server \\\n       --host &lt;host&gt; \\\n       --backend-store-uri \\\n       postgresql+psycopg2://&lt;username&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/mlflowdb \\\n       --port &lt;port&gt;\n\n\nHere we use PostgreSQL which works well to manage a database in a collaborative remote client-server system\n(Requires installing the psycopg2 package)"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-6",
    "href": "ai/mlops/wb_mlflow_slides.html#section-6",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Launch MLflow server\nAlliance clusters\n\nLaunch the MLflow server in the background (with a trailing &) as part of your job\nUse the local workflow with the additional argument --host 0.0.0.0\n\n\nExample job:\n\n#!/bin/bash\n#SBATCH ...\n#SBATCH ...\n\nmlflow server \\\n       --backend-store-uri sqlite:///&lt;database-name&gt;.db --host 0.0.0.0 &\n\npython &lt;script&gt;.py"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-7",
    "href": "ai/mlops/wb_mlflow_slides.html#section-7",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Access the UI\nOpen http://&lt;host&gt;:&lt;port&gt; in a browser to view logs in the UI\n\nExample:\nFor a local server on port 5000 (the default), open http://localhost:5000"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-8",
    "href": "ai/mlops/wb_mlflow_slides.html#section-8",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Access the UI\nAlliance clusters\nOnce the job is running, you need to create a connection between the compute node running the server and your computer\nFirst, you need to find the hostname of the compute node running the server. This is the value under NODELIST for your job when you run sq\nThen, from your computer, run the SSH tunnelling command:\nssh -N -f -L localhost:5000:&lt;node&gt;:5000 &lt;user&gt;@&lt;cluster&gt;.alliancecan.ca\n\nReplace &lt;node&gt; by the compute node you identified, &lt;user&gt; by your user name, and &lt;cluster&gt; by the name of the Alliance cluster (e.g.¬†fir)\n\nFinally, open a browser (on your computer) and go to http://localhost:5000"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-9",
    "href": "ai/mlops/wb_mlflow_slides.html#section-9",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Log tracking data\nDefine and run the experiment you want to track\n\nExamples:\nTrain a model,\nTune hyperparameters,\nRun a model with different datasets,\n‚Ä¶"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#benefits-of-using-mlflow",
    "href": "ai/mlops/wb_mlflow_slides.html#benefits-of-using-mlflow",
    "title": "Experiment tracking with",
    "section": "Benefits of using MLflow",
    "text": "Benefits of using MLflow\n\nMonitor model metrics (e.g.¬†loss, accuracy)\nMonitor system metrics (e.g.¬†GPU, memory)\nSave checkpoints with metrics\nRecord hyperparameters and optimizer settings\nSnapshot library versions for reproducibility"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#workflow",
    "href": "ai/mlops/wb_mlflow_slides.html#workflow",
    "title": "Experiment tracking with",
    "section": "Workflow",
    "text": "Workflow\n\nCreate an experiment\nLaunch an MLflow server\nOpen the user interface in a browser to visualize the logged data\nLog tracking data:\n\nPrepare data\nDefine model\nDefine training parameters and optimizer\nTrain"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#model-demo",
    "href": "ai/mlops/wb_mlflow_slides.html#model-demo",
    "title": "Experiment tracking with",
    "section": "Model demo",
    "text": "Model demo\n\nmodified from MLflow website\n\nWe need several packages for this demo. I create a bare uv project:\nuv init --bare\nand install the packages in its virtual environment:\nuv add mlflow psutil torch torchvision\nI also install ptpython because I like to use it instead of the default Python shell, but this is not necessary to run the demo (which is why I am adding it in the dev group):\nuv add --dev ptpython\nI can now launch ptpython (or python) to run the code:\nuv run ptpython"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-10",
    "href": "ai/mlops/wb_mlflow_slides.html#section-10",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Create an experiment\nimport mlflow\n\nmlflow.set_tracking_uri(\"sqlite:///demos.db\")\nmlflow.set_experiment(\"model_tracking_demo\")\n\nmlflow.config.enable_system_metrics_logging()\nmlflow.config.set_system_metrics_sampling_interval(1)\n\nYou can see that the database file demos.db gets created"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-11",
    "href": "ai/mlops/wb_mlflow_slides.html#section-11",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Launch MLflow server\nIn Bash (not Python):\nuv run mlflow server --backend-store-uri sqlite:///demos.db"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-12",
    "href": "ai/mlops/wb_mlflow_slides.html#section-12",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Access the UI\nOpen http://localhost:5000 in a browser to view logs in the UI\nYou can see our model_tracking_demo experiment\nClick on it to see the interface where the runs will be logged as we train our model"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-13",
    "href": "ai/mlops/wb_mlflow_slides.html#section-13",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Log tracking data\nIn this demo, we log a checkpoint and its metrics after each epoch, as well as the final model for the training of a basic PyTorch classification neural network on the classic Fashion-MNIST dataset"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-14",
    "href": "ai/mlops/wb_mlflow_slides.html#section-14",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Prepare data\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\n# Define device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load and prepare data\ntransform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n)\ntrain_dataset = datasets.FashionMNIST(\n    \"data\", train=True, download=True, transform=transform\n)\ntest_dataset = datasets.FashionMNIST(\"data\", train=False, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=1000)"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-15",
    "href": "ai/mlops/wb_mlflow_slides.html#section-15",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Define model\nimport torch.nn as nn\n\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28 * 28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10),\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\nmodel = NeuralNetwork().to(device)"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-16",
    "href": "ai/mlops/wb_mlflow_slides.html#section-16",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Set training conditions\nimport torch.optim as optim\n\n# Training parameters\nparams = {\n    \"epochs\": 4,\n    \"learning_rate\": 1e-3,\n    \"batch_size\": 64,\n    \"optimizer\": \"SGD\",\n    \"model_type\": \"MLP\",\n    \"hidden_units\": [512, 512],\n}\n\n# Define optimizer and loss function\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=params[\"learning_rate\"])"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-17",
    "href": "ai/mlops/wb_mlflow_slides.html#section-17",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Train\nwith mlflow.start_run(run_name=\"run_1\") as run:\n    # Log training parameters\n    mlflow.log_params(params)\n\n    for epoch in range(params[\"epochs\"]):\n        model.train()\n        train_loss, correct, total = 0, 0, 0\n\n        for batch_idx, (data, target) in enumerate(train_loader):\n            data, target = data.to(device), target.to(device)\n\n            # Forward pass\n            optimizer.zero_grad()\n            output = model(data)\n            loss = loss_fn(output, target)\n\n            # Backward pass\n            loss.backward()\n            optimizer.step()\n\n            # Calculate metrics\n            train_loss += loss.item()\n            _, predicted = output.max(1)\n            total += target.size(0)\n            correct += predicted.eq(target).sum().item()\n\n            # Log batch metrics (every 100 batches)\n            if batch_idx % 100 == 0:\n                batch_loss = train_loss / (batch_idx + 1)\n                batch_acc = 100.0 * correct / total\n                mlflow.log_metrics(\n                    {\"batch_loss\": batch_loss, \"batch_accuracy\": batch_acc},\n                    step=epoch * len(train_loader) + batch_idx,\n                )\n\n        # Calculate epoch metrics\n        epoch_loss = train_loss / len(train_loader)\n        epoch_acc = 100.0 * correct / total\n\n        # Validation\n        model.eval()\n        val_loss, val_correct, val_total = 0, 0, 0\n        with torch.no_grad():\n            for data, target in test_loader:\n                data, target = data.to(device), target.to(device)\n                output = model(data)\n                loss = loss_fn(output, target)\n\n                val_loss += loss.item()\n                _, predicted = output.max(1)\n                val_total += target.size(0)\n                val_correct += predicted.eq(target).sum().item()\n\n        # Calculate and log epoch validation metrics\n        val_loss = val_loss / len(test_loader)\n        val_acc = 100.0 * val_correct / val_total\n\n        # Log epoch metrics\n        mlflow.log_metrics(\n            {\n                \"train_loss\": epoch_loss,\n                \"train_accuracy\": epoch_acc,\n                \"val_loss\": val_loss,\n                \"val_accuracy\": val_acc,\n            },\n            step=epoch,\n        )\n        # Log checkpoint at the end of each epoch\n        mlflow.pytorch.log_model(\n            model,\n            name=f\"fashionmnist_1_checkpoint_{epoch}\"\n        )\n\n        print(\n            f\"Epoch {epoch+1}/{params['epochs']}, \"\n            f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}%, \"\n            f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\"\n        )\n\n    # Log the final trained model\n    model_info = mlflow.pytorch.log_model(\n        model,\n        name=\"fashionmnist_1_trained\"\n    )"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-18",
    "href": "ai/mlops/wb_mlflow_slides.html#section-18",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Visualize metrics during training\nGo to the UI in the browser\nIf you haven‚Äôt done so yet, click on the experiment we called model_tracking_demo\nThen click on the run we called run_1\n(if you don‚Äôt name runs, they get automatically generated names)\nFinally go to the Model metrics tab to see the metrics logged in real time\nThe System metrics tab allows you to monitor your resource usage"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-19",
    "href": "ai/mlops/wb_mlflow_slides.html#section-19",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Visualize metrics during training\nAlternatively, you can click on the experiment and click on  (Chart view button)\nThis is a great method if you want to compare multiple runs"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-20",
    "href": "ai/mlops/wb_mlflow_slides.html#section-20",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Create a new run\nWe can create new runs by training the model again:\nwith mlflow.start_run(run_name=\"run_2\") as run:\n    # Log training parameters\n    mlflow.log_params(params)\n\n    for epoch in range(params[\"epochs\"]):\n        model.train()\n        train_loss, correct, total = 0, 0, 0\n\n        for batch_idx, (data, target) in enumerate(train_loader):\n            data, target = data.to(device), target.to(device)\n\n            # Forward pass\n            optimizer.zero_grad()\n            output = model(data)\n            loss = loss_fn(output, target)\n\n            # Backward pass\n            loss.backward()\n            optimizer.step()\n\n            # Calculate metrics\n            train_loss += loss.item()\n            _, predicted = output.max(1)\n            total += target.size(0)\n            correct += predicted.eq(target).sum().item()\n\n            # Log batch metrics (every 100 batches)\n            if batch_idx % 100 == 0:\n                batch_loss = train_loss / (batch_idx + 1)\n                batch_acc = 100.0 * correct / total\n                mlflow.log_metrics(\n                    {\"batch_loss\": batch_loss, \"batch_accuracy\": batch_acc},\n                    step=epoch * len(train_loader) + batch_idx,\n                )\n\n        # Calculate epoch metrics\n        epoch_loss = train_loss / len(train_loader)\n        epoch_acc = 100.0 * correct / total\n\n        # Validation\n        model.eval()\n        val_loss, val_correct, val_total = 0, 0, 0\n        with torch.no_grad():\n            for data, target in test_loader:\n                data, target = data.to(device), target.to(device)\n                output = model(data)\n                loss = loss_fn(output, target)\n\n                val_loss += loss.item()\n                _, predicted = output.max(1)\n                val_total += target.size(0)\n                val_correct += predicted.eq(target).sum().item()\n\n        # Calculate and log epoch validation metrics\n        val_loss = val_loss / len(test_loader)\n        val_acc = 100.0 * val_correct / val_total\n\n        # Log epoch metrics\n        mlflow.log_metrics(\n            {\n                \"train_loss\": epoch_loss,\n                \"train_accuracy\": epoch_acc,\n                \"val_loss\": val_loss,\n                \"val_accuracy\": val_acc,\n            },\n            step=epoch,\n        )\n        # Log checkpoint at the end of each epoch\n        mlflow.pytorch.log_model(\n            model,\n            name=f\"fashionmnist_2_checkpoint_{epoch}\"\n        )\n\n        print(\n            f\"Epoch {epoch+1}/{params['epochs']}, \"\n            f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}%, \"\n            f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\"\n        )\n\n    # Log the final trained model\n    model_info = mlflow.pytorch.log_model(\n        model,\n        name=\"fashionmnist_2_trained\"\n    )"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#goal-of-hyperparameter-tuning",
    "href": "ai/mlops/wb_mlflow_slides.html#goal-of-hyperparameter-tuning",
    "title": "Experiment tracking with",
    "section": "Goal of hyperparameter tuning",
    "text": "Goal of hyperparameter tuning\nFind the optimal set of hyperparameters that maximize a model‚Äôs predictive accuracy and performance\n‚ûî find the right balance between high bias (underfitting) and high variance (overfitting) to improve the model‚Äôs ability to generalize and perform well on new, unseen data"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#tuning-frameworks",
    "href": "ai/mlops/wb_mlflow_slides.html#tuning-frameworks",
    "title": "Experiment tracking with",
    "section": "Tuning frameworks",
    "text": "Tuning frameworks\nHyperparameters optimization used to be done manually following a systematic grid pattern. This was extremely inefficient\nNowadays, there are many frameworks that do it automatically, faster, and better\n\nExample:\n\n\nOptuna\nHyperopt\nRay Tune"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#workflow-1",
    "href": "ai/mlops/wb_mlflow_slides.html#workflow-1",
    "title": "Experiment tracking with",
    "section": "Workflow",
    "text": "Workflow\n\nCreate an experiment\nLaunch an MLflow server\nOpen the user interface in a browser to visualize the logged data\nLog tracking data:\n\nPrepare data\nDefine an objective function\nRun an optimization task"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#tuning-demo",
    "href": "ai/mlops/wb_mlflow_slides.html#tuning-demo",
    "title": "Experiment tracking with",
    "section": "Tuning demo",
    "text": "Tuning demo\n\nmodified from MLflow website\n\nFor this demo, we will use optuna as the hyperparameter optimization framework, so we need to install it (in Bash, not Python):\nuv add optuna"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-21",
    "href": "ai/mlops/wb_mlflow_slides.html#section-21",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Create an experiment\nimport mlflow\n\nmlflow.set_tracking_uri(\"sqlite:///demos.db\")\nmlflow.set_experiment(\"tuning_demo\")\n\nWe are using the same database, but you could of course create a new one"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-22",
    "href": "ai/mlops/wb_mlflow_slides.html#section-22",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Launch MLflow server\nIn Bash/zsh (not in Python!) at root of project\nmlflow server --backend-store-uri sqlite:///demos.db\n\nIf you are using the same database as in the previous demo and you kept the server running, you don‚Äôt have to do anything"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-23",
    "href": "ai/mlops/wb_mlflow_slides.html#section-23",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Access the UI\nOpen http://localhost:5000 in a browser\nSelect the experiment tuning_demo"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-24",
    "href": "ai/mlops/wb_mlflow_slides.html#section-24",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Log tracking data\nIn this demo, we train a random forest regressor model on the classic scikit-learn California housing dataset\nand tune its hyperparameters (random forest max depth, number of estimators, and max features) by minimizing the mean squared error between the predicted and validation values\nusing the hyperparameter optimization package optuna"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-25",
    "href": "ai/mlops/wb_mlflow_slides.html#section-25",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Prepare data\nimport sklearn\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import fetch_california_housing\n\nX, y = fetch_california_housing(return_X_y=True)\nX_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-26",
    "href": "ai/mlops/wb_mlflow_slides.html#section-26",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Define an objective function\ndef objective(trial):\n    # Setting nested=True will create a child run under the parent run.\n    with mlflow.start_run(\n            nested=True,\n            run_name=f\"trial_{trial.number}\"\n    ) as child_run:\n        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 2, 32)\n        rf_n_estimators = trial.suggest_int(\n            \"rf_n_estimators\",\n            50,\n            300,\n            step=10\n        )\n        rf_max_features = trial.suggest_float(\"rf_max_features\", 0.2, 1.0)\n        params = {\n            \"max_depth\": rf_max_depth,\n            \"n_estimators\": rf_n_estimators,\n            \"max_features\": rf_max_features,\n        }\n        # Log current trial's parameters\n        mlflow.log_params(params)\n\n        regressor_obj = sklearn.ensemble.RandomForestRegressor(**params)\n        regressor_obj.fit(X_train, y_train)\n\n        y_pred = regressor_obj.predict(X_val)\n        error = sklearn.metrics.mean_squared_error(y_val, y_pred)\n        # Log current trial's error metric\n        mlflow.log_metrics({\"error\": error})\n\n        # Log the model file\n        mlflow.sklearn.log_model(regressor_obj, name=\"calhousing_1\")\n        # Make it easy to retrieve the best-performing child run later\n        trial.set_user_attr(\"run_id\", child_run.info.run_id)\n        return error"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-27",
    "href": "ai/mlops/wb_mlflow_slides.html#section-27",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Run an optimization task\nimport optuna\n\n# Create a parent run that contains all child runs for different trials\nwith mlflow.start_run(run_name=\"calhousing_1_optimization_1\") as run:\n    # Log the experiment settings\n    n_trials = 5\n    mlflow.log_param(\"n_trials\", n_trials)\n\n    study = optuna.create_study(direction=\"minimize\")\n    study.optimize(objective, n_trials=n_trials)\n\n    # Log the best trial and its run ID\n    mlflow.log_params(study.best_trial.params)\n    mlflow.log_metrics({\"best_error\": study.best_value})\n    if best_run_id := study.best_trial.user_attrs.get(\"run_id\"):\n        mlflow.log_param(\"best_child_run_id\", best_run_id)"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-28",
    "href": "ai/mlops/wb_mlflow_slides.html#section-28",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Visualize trials errors during run\nGo to the UI in the browser\nIf you haven‚Äôt done so yet, click on the experiment we called tuning_demo\nThen click on the + sign next to our optimization experiment to expand it\nFinally click on  (Chart view button) to compare the trials"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#benefits",
    "href": "ai/mlops/wb_mlflow_slides.html#benefits",
    "title": "Experiment tracking with",
    "section": "Benefits",
    "text": "Benefits\n\nTracks development pipelines of models\nTracks model versions\nCentral place for all models (local or remote for collaborations)\nAliases, tags, annotations, metadata associated with models"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#register-models",
    "href": "ai/mlops/wb_mlflow_slides.html#register-models",
    "title": "Experiment tracking with",
    "section": "Register models",
    "text": "Register models\nWhenever you care about a model, you should add it to the model registry\nYou can do so when you log it by adding a value to the registered_model_name argument of the log_model function\nBut often, you will do so afterwards, once you have looked at the logs and decided that they look good"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-29",
    "href": "ai/mlops/wb_mlflow_slides.html#section-29",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Register models in the UI\n\n\nVersion 1\n\nClick on the experiment name containing the model\nClick on Models in the left menus\nClick on the model to register\nClick on the Register model button in top right corner\nIn drop-down menu click Create New Model\nEnter name of model\nClick Register\n\n\n\n\nVersions 2+\n\n\n\n\n\nIn drop-down menu select model for which you want to create a new version\nClick Register"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-30",
    "href": "ai/mlops/wb_mlflow_slides.html#section-30",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Register models programmatically\nFrom model ID:\n\nClick on the experiment name containing the model\nClick on Models in the left menus\nClick on the model to register\n\nThen run:\nmlflow.register_model(\"models:/&lt;model-id&gt;\", \"&lt;name-of-registered-model&gt;\")\n\n\n&lt;model-id&gt; = the letters and digits after Model ID\n&lt;name-of-registered-model&gt; = the name you give to your registered model"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-31",
    "href": "ai/mlops/wb_mlflow_slides.html#section-31",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Register models programmatically\nFrom run ID:\nNavigate to and click on the model to register\nThen run:\nmlflow.register_model(\n    \"runs:/&lt;source-run-id&gt;/&lt;model-name&gt;\",\n    \"&lt;name-of-registered-model&gt;\"\n)\n\n\n&lt;source-run-id&gt; = the digits in top right corner after Source run ID\n&lt;model-name&gt; = the name of the model in top left corner (the model you just clicked on)\n&lt;name-of-registered-model&gt; = the name you give to your registered model"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#load-registered-model",
    "href": "ai/mlops/wb_mlflow_slides.html#load-registered-model",
    "title": "Experiment tracking with",
    "section": "Load registered model",
    "text": "Load registered model\nYou can then load any of your registered models with:\nmlflow.&lt;flavour&gt;.load_model(\n    \"models:/&lt;your_registered_model_name&gt;/&lt;model_version&gt;\"\n)\n\n&lt;flavour&gt; = any ML/DL flavour such as pytorch, sklearn,\nor any other named flavour (predefined code for supported ML/DL frameworks),\nor a custom PyFunc for unsupported frameworks"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#model-registry-demo",
    "href": "ai/mlops/wb_mlflow_slides.html#model-registry-demo",
    "title": "Experiment tracking with",
    "section": "Model registry demo",
    "text": "Model registry demo\nIn the previous demos, we logged a number of models:\n\nthe checkpoints of both our FashionMNIST runs\nthe final models of those two runs\nthe trials (child runs) of the California housing tuning experiment\n\nLet‚Äôs register some of these models"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-32",
    "href": "ai/mlops/wb_mlflow_slides.html#section-32",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Register models in the UI\n\n\nFashionMNIST:\n\nClick on model_tracking_demo\nClick on Models in the left menus\nClick on fashionmnist_1_trained\nClick on the Register model button in top right corner\nIn drop-down menu click Create New Model\nEnter: ‚Äúfashionmnist_1‚Äù\nClick Register\n\n\n\n\nCalifornia housing:\n\nClick on tuning_demo\nClick on Models in the left menus\nClick on the calhousing_1 line corresponding to our best trial run\nClick on the Register model button in top right corner\nIn drop-down menu click Create New Model\nEnter: ‚Äúcalhousing_1_best‚Äù\nClick Register"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-33",
    "href": "ai/mlops/wb_mlflow_slides.html#section-33",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Register models in Python\nIn the UI:\n\nClick on model_tracking_demo\nClick on Models in the left menus\nClick on fashionmnist_2_trained\n\nThen run:\nmlflow.register_model(\n    \"models:/m-a7a4cd35cc4c4fe4b2e3d839b1307b5d\",\n    \"fashionmnist_2\"\n)"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-34",
    "href": "ai/mlops/wb_mlflow_slides.html#section-34",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Register models in Python\nIn the UI:\n\nClick on model_tracking_demo\nClick on Models in the left menus\nClick on fashionmnist_2_trained\n\nAlternatively:\nmlflow.register_model(\n    \"runs:/1a2844d0125e40cfac528ae44c4ae76a/fashionmnist_2_trained\",\n    \"fashionmnist_2\"\n)"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-35",
    "href": "ai/mlops/wb_mlflow_slides.html#section-35",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Load registered models\nYou can load back any registered model by its name and version number:\nfashionmnist_1 = mlflow.pytorch.load_model(\"models:/fashionmnist_1/1\")\ncalhousing_1_best = mlflow.sklearn.load_model(\"models:/calhousing_1_best/1\")\nfashionmnist_1\ncalhousing_1_best"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#benefits-of-models-signatures",
    "href": "ai/mlops/wb_mlflow_slides.html#benefits-of-models-signatures",
    "title": "Experiment tracking with",
    "section": "Benefits of models signatures",
    "text": "Benefits of models signatures\nModel signatures describe the schema of inputs and outputs\nThey help in model understanding and define how the model should be used"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#input-examples",
    "href": "ai/mlops/wb_mlflow_slides.html#input-examples",
    "title": "Experiment tracking with",
    "section": "Input examples",
    "text": "Input examples\nInput examples illustrate the data type and format that should be used with models and ensures validation that the models work properly\nMLflow can infer a model signature for a model from an input example\nThe input example also provides a test for the model during logging\nIt thus a good practice to add an input example whenever a model is logged"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#example",
    "href": "ai/mlops/wb_mlflow_slides.html#example",
    "title": "Experiment tracking with",
    "section": "Example",
    "text": "Example\nLet‚Äôs go back to the objective function we defined in the tuning demo as an example\nand let‚Äôs add the first the first element of the X ndarray an input example"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-36",
    "href": "ai/mlops/wb_mlflow_slides.html#section-36",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Define an objective function\ndef objective(trial):\n    # Setting nested=True will create a child run under the parent run.\n    with mlflow.start_run(\n            nested=True,\n            run_name=f\"trial_{trial.number}\"\n    ) as child_run:\n        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 2, 32)\n        rf_n_estimators = trial.suggest_int(\n            \"rf_n_estimators\",\n            50,\n            300,\n            step=10\n        )\n        rf_max_features = trial.suggest_float(\"rf_max_features\", 0.2, 1.0)\n        params = {\n            \"max_depth\": rf_max_depth,\n            \"n_estimators\": rf_n_estimators,\n            \"max_features\": rf_max_features,\n        }\n        # Log current trial's parameters\n        mlflow.log_params(params)\n\n        regressor_obj = sklearn.ensemble.RandomForestRegressor(**params)\n        regressor_obj.fit(X_train, y_train)\n\n        y_pred = regressor_obj.predict(X_val)\n        error = sklearn.metrics.mean_squared_error(y_val, y_pred)\n        # Log current trial's error metric\n        mlflow.log_metrics({\"error\": error})\n\n        # Log the model file\n        mlflow.sklearn.log_model(regressor_obj, name=\"calhousing_1\")\n        # Make it easy to retrieve the best-performing child run later\n        trial.set_user_attr(\"run_id\", child_run.info.run_id)\n        return error"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-37",
    "href": "ai/mlops/wb_mlflow_slides.html#section-37",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Define an objective function\ndef objective(trial):\n    # Setting nested=True will create a child run under the parent run.\n    with mlflow.start_run(\n            nested=True,\n            run_name=f\"trial_{trial.number}\"\n    ) as child_run:\n        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 2, 32)\n        rf_n_estimators = trial.suggest_int(\n            \"rf_n_estimators\",\n            50,\n            300,\n            step=10\n        )\n        rf_max_features = trial.suggest_float(\"rf_max_features\", 0.2, 1.0)\n        params = {\n            \"max_depth\": rf_max_depth,\n            \"n_estimators\": rf_n_estimators,\n            \"max_features\": rf_max_features,\n        }\n        # Log current trial's parameters\n        mlflow.log_params(params)\n\n        regressor_obj = sklearn.ensemble.RandomForestRegressor(**params)\n        regressor_obj.fit(X_train, y_train)\n\n        y_pred = regressor_obj.predict(X_val)\n        error = sklearn.metrics.mean_squared_error(y_val, y_pred)\n        # Log current trial's error metric\n        mlflow.log_metrics({\"error\": error})\n\n        # Log the model file\n        mlflow.sklearn.log_model(\n            regressor_obj,\n            name=\"calhousing_1\",\n            input_example=X[[0]]\n        )\n        # Make it easy to retrieve the best-performing child run later\n        trial.set_user_attr(\"run_id\", child_run.info.run_id)\n        return error"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-38",
    "href": "ai/mlops/wb_mlflow_slides.html#section-38",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Define an objective function\ndef objective(trial):\n    # Setting nested=True will create a child run under the parent run.\n    with mlflow.start_run(\n            nested=True,\n            run_name=f\"trial_{trial.number}\"\n    ) as child_run:\n        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 2, 32)\n        rf_n_estimators = trial.suggest_int(\n            \"rf_n_estimators\",\n            50,\n            300,\n            step=10\n        )\n        rf_max_features = trial.suggest_float(\"rf_max_features\", 0.2, 1.0)\n        params = {\n            \"max_depth\": rf_max_depth,\n            \"n_estimators\": rf_n_estimators,\n            \"max_features\": rf_max_features,\n        }\n        # Log current trial's parameters\n        mlflow.log_params(params)\n\n        regressor_obj = sklearn.ensemble.RandomForestRegressor(**params)\n        regressor_obj.fit(X_train, y_train)\n\n        y_pred = regressor_obj.predict(X_val)\n        error = sklearn.metrics.mean_squared_error(y_val, y_pred)\n        # Log current trial's error metric\n        mlflow.log_metrics({\"error\": error})\n\n        # Log the model file\n        mlflow.sklearn.log_model(\n            regressor_obj,\n            name=\"calhousing_1\",\n            input_example=X[[0]]\n        )\n        # Make it easy to retrieve the best-performing child run later\n        trial.set_user_attr(\"run_id\", child_run.info.run_id)\n        return error"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-39",
    "href": "ai/mlops/wb_mlflow_slides.html#section-39",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Run an optimization task\nIf we re-run our optimization task now, we don‚Äôt get any warnings about missing signatures anymore\nimport optuna\n\n# Create a parent run that contains all child runs for different trials\nwith mlflow.start_run(run_name=\"calhousing_1_optimization_1\") as run:\n    # Log the experiment settings\n    n_trials = 5\n    mlflow.log_param(\"n_trials\", n_trials)\n\n    study = optuna.create_study(direction=\"minimize\")\n    study.optimize(objective, n_trials=n_trials)\n\n    # Log the best trial and its run ID\n    mlflow.log_params(study.best_trial.params)\n    mlflow.log_metrics({\"best_error\": study.best_value})\n    if best_run_id := study.best_trial.user_attrs.get(\"run_id\"):\n        mlflow.log_param(\"best_child_run_id\", best_run_id)"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-40",
    "href": "ai/mlops/wb_mlflow_slides.html#section-40",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Signature test\nYou can do a sanity check of your signature by running your input example in the model\nFirst, register the model and load it (let‚Äôs use the model we already registered):\ncalhousing_1_best = mlflow.sklearn.load_model(\"models:/calhousing_1_best/1\")\nThen test the input example:\ntry:\n    result = calhousing_1_best.predict(X[[0]])\n    print(\"‚úÖ Signature validation passed\")\nexcept Exception as e:\n    print(f\"‚ùå Signature issue: {e}\")\n‚úÖ Signature validation passed"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#section-41",
    "href": "ai/mlops/wb_mlflow_slides.html#section-41",
    "title": "Experiment tracking with",
    "section": "",
    "text": "Signature test\nIf you used a bad input sample, you will get some informative error:\ntry:\n    result = calhousing_1_best.predict(X[0])\n    print(\"‚úÖ Signature validation passed\")\nexcept Exception as e:\n    print(f\"‚ùå Signature issue: {e}\")\n‚ùå Signature issue: Expected 2D array, got 1D array instead:\narray=[   8.3252      41.           6.984127     1.0238096  322.\n    2.5555556   37.88      -122.23     ].\nReshape your data either using array.reshape(-1, 1) if your data has \na single feature or array.reshape(1, -1) if it contains a single sample."
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#benefits-1",
    "href": "ai/mlops/wb_mlflow_slides.html#benefits-1",
    "title": "Experiment tracking with",
    "section": "Benefits",
    "text": "Benefits\n\nKeep data and models together for reproducibility\nKeep data versions for traceability\nRecord metadata and data sources\nShare data for collaborations (when using remote servers)"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#supported-data-types",
    "href": "ai/mlops/wb_mlflow_slides.html#supported-data-types",
    "title": "Experiment tracking with",
    "section": "Supported data types",
    "text": "Supported data types\n\nPandasDataset: Pandas DataFrames\nSparkDataset: Apache Spark DataFrames\nNumpyDataset: NumPy arrays\nPolarsDataset: Polars DataFrames\nHuggingFaceDataset: Hugging Face datasets\nTensorFlowDataset: TensorFlow datasets\nMetaDataset: metadata-only datasets (no actual data storage)\n\nNon supported data types (e.g.¬†torchvision datasets) need to be converted to supported types or logged via custom functions"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_slides.html#example-1",
    "href": "ai/mlops/wb_mlflow_slides.html#example-1",
    "title": "Experiment tracking with",
    "section": "Example",
    "text": "Example\nimport polars as pl\n\ntrain_data = pl.DataFrame({\"X\": X_train, \"y\": y_train})\nval_data = pl.DataFrame({\"X\": X_val, \"y\": y_val})\n\ntrain_dataset = mlflow.data.from_polars(train_data, name=\"calhousing_train\")\nval_dataset = mlflow.data.from_polars(val_data, name=\"calhousing_val\")\n\nwith mlflow.start_run():\n    mlflow.log_input(train_dataset, context=\"training\")\n    mlflow.log_input(val_dataset, context=\"validation\")"
  },
  {
    "objectID": "ai/mlops/wb_mlflow.html",
    "href": "ai/mlops/wb_mlflow.html",
    "title": "ML experiment tracking with MLflow",
    "section": "",
    "text": "While developing a machine learning or deep learning model, several datasets might be trained on diverse architectures tuned with various hyperparameters. It is extremely challenging to keep track of so many moving parts and this causes problems for reproducibility, efficient organization, compliance to requirements, and pipeline management.\nExperiment tracking tools bring sanity to this complexity, but most of them are proprietary. MLflow is a free, open-source, and popular platform for AI experiment tracking. Very flexible, it can:\n\nbe combined with any machine learning or deep learning framework,\nwork with any hyperparameter optimization tool,\nrun a server anywhere.\n\nWhile tracking models, datasets, and tuning experiments, it logs metrics, saves checkpoints, and provides an interactive user interface to visualize model performance and system usage. It can also displays SHAP (SHapley Additive exPlanations) charts and provides a model registry to store and organize models.\nIn this webinar, I will show you how to get started with MLflow and demo some of its most useful experiment tracking features.\nMLflow also provides tools for deployment, LLM and agents evaluation, prompt management, and AI applications tracking, but these go beyond the scope of classic usage in data science and will not be covered here.\n\nSlides (Click and wait: this reveal.js presentation is heavy and takes some time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "ML experiment tracking"
    ]
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_content.html",
    "href": "ai/jxbayesian/wb_bayesian_content.html",
    "title": "Bayesian inference in JAX",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Bayesian inference in JAX",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_content.html#on-probabilities",
    "href": "ai/jxbayesian/wb_bayesian_content.html#on-probabilities",
    "title": "Bayesian inference in JAX",
    "section": "On probabilities",
    "text": "On probabilities\n\nTwo interpretations of probabilities\n\n\n\n\nFrequentist\n\n\n\n\nfrom https://www.kdnuggets.com/2023/05/bayesian-frequentist-statistics-data-science.html\n\n\n\n\n\nBayesian\n\n\n\n\nfrom https://vitalflux.com/bayesian-machine-learning-applications-examples/\n\n\n\n\n\n\n\nFrequentist\nFrequentist approach to probabilities: assigns probabilities to the long-run frequency of events.\nIt doesn‚Äôt assign probabilities to non-random variables such as hypotheses or parameters.\nInstead, the probability is assigned to the limit of the relative frequencies of events in infinite trials and we can assign a probability to the fact that a new random sample would produce a confidence interval that contains the unknown parameter.\nThis is not how we intuitively think and the results are hard to interpret. This approach is also often artificially constrained and limits the integration of various forms of information.\nIt is however computationally simple and fast: samples are randomly selected from the sample space and it returns test statistics such as p-values and confidence intervals. This is why it was the dominant approach for a long time: we knew how to do it.\n\n\nBayesian\nBayesian approach: assigns probabilities to our beliefs about an event.\nBased on Bayes‚Äô theorem of conditional probabilities which allows to calculate the probability of a cause given its effect:\n\\[ P(A \\vert X) = \\frac{P(X \\vert A) P(A)}{P(X)} \\]\nwhere:\n\n\\(P(A)\\) is the prior probability of \\(A\\)‚Äîour belief about event \\(A\\).\n\\(P(X)\\) is the marginal probability of event \\(X\\) (some observed data).\n\\(P(X \\vert A)\\) is the likelihood or conditional probability of observing \\(X\\) given \\(A\\).\n\\(P(A \\vert X)\\) is the posterior probability‚Äîour updated belief about \\(A\\) given the data.\n\n\n\nWhich approach to choose?\nBayesian statistics:\n\nis more intuitive to the way we think about the world (easier to interpret),\nallows for the incorporation of prior information and diverse data,\nis more informative as it provides a measure of uncertainty (returns probabilities),\nis extremely valuable when there is little data (the inference is unstable and frequentist estimates have large variance and confidence intervals).\n\nBut beyond extremely simple examples, Bayesian inference is mathematically extremely arduous.\nIt is also much more computationally heavy and only became possible to apply widely with the advent of powerful computers and new algorithms such as Markov chain Monte Carlo (MCMC).",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Bayesian inference in JAX",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_content.html#bayesian-computing",
    "href": "ai/jxbayesian/wb_bayesian_content.html#bayesian-computing",
    "title": "Bayesian inference in JAX",
    "section": "Bayesian computing",
    "text": "Bayesian computing\n\nAlgorithms\nA Bayesian approach to statistics often leads to posterior probability distributions that are too complex or too highly dimensional to be studied by analytical techniques.\nMarkov chain Monte Carlo (MCMC) is a class of sampling algorithms which explore such distributions.\nDifferent algorithms move in different ways across the N-dimensional space of the parameters, accepting or rejecting each new position based on its adherence to the prior distribution and the data.\nThe sequence of accepted positions constitute the traces.\n\n\nPPL\nProbabilistic programming language (PPL), explained simply in this (a bit outdated) blog post, are computer languages specialized in creating probabilistic models and making inference.\nModel components are first-class primitives.\nThey can be based on a general programming language (e.g.¬†Python, Julia) or domain specific.\n\n\nFirst Bayesian PPLs\nRelied on Gibbs sampling:\n\nWinBUGS replaced by OpenBUGS, written in Component Pascal,\nJAGS, written in C++.\n\nBUGS = Bayesian inference Using Gibbs Sampling\nJAGS = Just Another Gibbs Sampler\n\n\nStan\nStan (see also website and paper) is a domain-specific language.\nStan scripts can be executed from R, Python, or the shell via RStan, PyStan, etc.\nAlso used as the backend for the R package brms which doesn‚Äôt require learning Stan but only works for simple models.\nRelies on No-U-Turn sampler (NUTS), a variant of Hamiltonian Monte Carlo (HMC) (see also HMC paper).\nHMC and variants require burdensome calculations of derivatives. Stan solved that by creating its own reverse-mode automatic differentiation engine.\nSuperior to Gibbs sampler ‚ûî made Stan a very popular PPL for years.\n\n\nPPLs based on DL frameworks\nSince HMC and NUTS require autodiff, many Python PPLs have emerged in recent years, following the explosion of deep learning.\nExamples:\n\nPyro based on PyTorch,\nEdward, then Edward2 as well as TensorFlow Probability based on TensorFlow.\n\n\n\nEnters JAX\n\nHad JAX existed when we started coding Stan in 2011, we would‚Äôve used that rather than rolling our own autodiff system.\n\n\nBob Carpenter, one of Stan‚Äôs creators, in a recent blog post.\n\n\n\nWhat is JAX?\nJAX is a library for Python that:\n\nmakes use of the extremely performant XLA compiler,\nruns on accelerators (GPUs/TPUs),\nprovides automatic differentiation,\nuses just-in-time compilation,\nallows batching and parallelization.\n\n‚áí perfect tool for Bayesian statistics.\nSee our introductory JAX course and webinar for more details.\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\n Just-in-time \n(JIT)\ncompilation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\n Transformations \n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\n Just-in-time \n(JIT)\ncompilation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\nVectorization\nParallelization\n ¬†¬†Differentiation ¬†\n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\njit\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\nvmap\npmap\ngrad\n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla\n\n\n\n\n\n\n\n\n\n\n\nJAX idiosyncrasies\nJAX is sublanguage of Python requiring pure functions instead of Python‚Äôs object-oriented style.\nIt has other quirks.\nThe only one you really need to understand for use in PPLs is the pseudorandom number generation.\n\n\nPRNG keys\nTraditional pseudorandom number generators are based on nondeterministic state of the OS. This is slow and problematic for parallel executions.\nJAX relies on an explicitly-set random state called a key:\nfrom jax import random\nkey = random.key(18)\nEach key can only be used for one random function, but it can be split into new keys:\nkey, subkey = random.split(key)\n\nThe first key can‚Äôt be used anymore. We overwrote it with a new key to ensure we don‚Äôt accidentally reuse it.\n\nWe can now use subkey in random functions in our code (and keep key to generate new subkeys as needed).\n\n\nJAX use cases\n\n\n\n\nNew JAX backends\nNew JAX backends are getting added to many PPLs.\nEdward2 and TensorFlow Probability can now use JAX as backend.\nPyMC relies on building a static graph. It is based on PyTensor which provides JAX compilation (PyTensor is a fork of aesara, itself a fork of Theano).\n\n\nNumPyro\nNumPyro is a library based on Pyro but using NumPy and JAX.\n\n\n\n\nBlackjax\nNot a PPL but a library of MCMC samplers built on JAX.\nCan be used directly if you want to define your own log-probability density functions or can be used with several PPLs to define your model (make sure to translate it to a log-probability function).\nAlso provides building blocks for experimentation with new algorithms.\n\n\n\n\nExample Blackjax sampler: HMC\n\n\n\n\nExample Blackjax sampler: NUTS\n\n\n\n\nWhich tool to choose?\nAll these tools are in active development (JAX was released and started shaking the field in 2018). Things are fast evolving. Reading blogs of main developers, posts on Hacker News, discourse forums, etc. helps to keep an eye on evolutions in the field.\nThis recent conversation between Bob Carpenter (Stan core developer) and Ricardo Vieira (PyMC core developer) in the PyMC discourse forum is interesting.\nA lot of it also comes down to user preferences.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Bayesian inference in JAX",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_content.html#resources",
    "href": "ai/jxbayesian/wb_bayesian_content.html#resources",
    "title": "Bayesian inference in JAX",
    "section": "Resources",
    "text": "Resources\n\nBayesian computing\nSome good resources to get started with Bayesian computing:\n\nthe book Probabilistic Programming & Bayesian Methods for Hackers by Cameron Davidson-Pilon provides a code-based (using PyMC) and math-free introduction to Bayesian methods for the real beginner,\nseveral resources on the PyMC website including intro Bayesian with PyMC,\nNumPyro tutorials.\n\nMore advanced: tutorials from Blackjax Sampling Book Project.\n\n\nFrom Stan to a JAX-based PPL\nThe code to the classic Bayesian textbook Statistical Rethinking by Richard McElreath got translated by various people to modern JAX-based PPLs and might help you transition from Stan:",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Bayesian inference in JAX",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_training.html",
    "href": "ai/jxai/jxai_training.html",
    "title": "Training",
    "section": "",
    "text": "It is now time to train our model.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Training"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_training.html#hyperparameters",
    "href": "ai/jxai/jxai_training.html#hyperparameters",
    "title": "Training",
    "section": "Hyperparameters",
    "text": "Hyperparameters\nWe need to define the hyperparameters that will control the training process:\n\nimport optax\n\nnum_epochs = 3\nlearning_rate = 0.001\nmomentum = 0.8\ntotal_steps = len(nabirds_train) // train_batch_size\n\nlr_schedule = optax.linear_schedule(learning_rate, 0.0, num_epochs * total_steps)\n\niterate_subsample = np.linspace(0, num_epochs * total_steps, 100)\n\noptimizer = nnx.ModelAndOptimizer(model, optax.sgd(lr_schedule, momentum, nesterov=True))\n\nWe can plot the learning rate schedule:\n\nimport matplotlib.pyplot as plt\n\nplt.plot(\n    np.linspace(0, num_epochs, len(iterate_subsample)),\n    [lr_schedule(i) for i in iterate_subsample],\n    lw=3,\n)\nplt.title('Learning rate')\nplt.xlabel('Epochs')\nplt.ylabel('Learning rate')\nplt.grid()\nplt.xlim((0, num_epochs))\nplt.show()\n\n\n\n\n\n\n\n\n\nLoss function\n\ndef compute_losses_and_logits(model: nnx.Module, imgs: jax.Array, species: jax.Array):\n    logits = model(imgs)\n\n    loss = optax.softmax_cross_entropy_with_integer_labels(\n        logits=logits, species=species\n    ).mean()\n    return loss, logits",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Training"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_training.html#define-train-and-eval-steps",
    "href": "ai/jxai/jxai_training.html#define-train-and-eval-steps",
    "title": "Training",
    "section": "Define train and eval steps",
    "text": "Define train and eval steps\n\ndef train_step(\n    model: nnx.Module, optimizer: nnx.Optimizer, batch: dict[str, np.ndarray]\n):\n    # Convert np.ndarray to jax.Array on GPU\n    imgs = jnp.array(batch['img'])\n    species = jnp.array(batch['species_id'], dtype=jnp.int32)\n\n    grad_fn = nnx.value_and_grad(compute_losses_and_logits, has_aux=True)\n    (loss, logits), grads = grad_fn(model, imgs, species)\n\n    optimizer.update(grads)  # In-place updates.\n\n    return loss\n\ndef eval_step(\n    model: nnx.Module, batch: dict[str, np.ndarray], eval_metrics: nnx.MultiMetric\n):\n    # Convert np.ndarray to jax.Array on GPU\n    imgs = jnp.array(batch['img'])\n    species = jnp.array(batch['species_id'], dtype=jnp.int32)\n    loss, logits = compute_losses_and_logits(model, imgs, species)\n\n    eval_metrics.update(\n        loss=loss,\n        logits=logits,\n        species=species,\n    )",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Training"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_training.html#metrics",
    "href": "ai/jxai/jxai_training.html#metrics",
    "title": "Training",
    "section": "Metrics",
    "text": "Metrics\n\neval_metrics = nnx.MultiMetric(\n    loss=nnx.metrics.Average('loss'),\n    accuracy=nnx.metrics.Accuracy(),\n)\n\ntrain_metrics_history = {\n    'train_loss': [],\n}\n\neval_metrics_history = {\n    'val_loss': [],\n    'val_accuracy': [],\n}",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Training"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_training.html#training-and-evaluation-functions",
    "href": "ai/jxai/jxai_training.html#training-and-evaluation-functions",
    "title": "Training",
    "section": "Training and evaluation functions",
    "text": "Training and evaluation functions\n\nimport tqdm\n\nbar_format = '{desc}[{n_fmt}/{total_fmt}]{postfix} [{elapsed}&lt;{remaining}]'\n\n@nnx.jit              # To JIT compile and automatically use GPU/TPU if available\ndef train_one_epoch(epoch):\n    model.train()  # Set model to the training mode: e.g. update batch statistics\n    with tqdm.tqdm(\n        desc=f\"[train] epoch: {epoch}/{num_epochs}, \",\n        total=total_steps,\n        bar_format=bar_format,\n        leave=True,\n    ) as pbar:\n        for batch in train_loader:\n            loss = train_step(model, optimizer, batch)\n            train_metrics_history['train_loss'].append(loss.item())\n            pbar.set_postfix({'loss': loss.item()})\n            pbar.update(1)\n\n@nnx.jit\ndef evaluate_model(epoch):\n    # Computes the metrics on the training and test sets after each training epoch.\n    model.eval()  # Sets model to evaluation model: e.g. use stored batch statistics.\n\n    eval_metrics.reset()  # Reset the eval metrics\n    for val_batch in val_loader:\n        eval_step(model, val_batch, eval_metrics)\n\n    for metric, value in eval_metrics.compute().items():\n        eval_metrics_history[f'val_{metric}'].append(value)\n\n    print(f\"[val] epoch: {epoch + 1}/{num_epochs}\")\n    print(f\"- total loss: {eval_metrics_history['val_loss'][-1]:0.4f}\")\n    print(f\"- Accuracy: {eval_metrics_history['val_accuracy'][-1]:0.4f}\")",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Training"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_training.html#training",
    "href": "ai/jxai/jxai_training.html#training",
    "title": "Training",
    "section": "Training",
    "text": "Training\nTime to run the training loop:\n%%time\n\nfor epoch in range(num_epochs):\n    train_one_epoch(epoch)\n    evaluate_model(epoch)\nValueError: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 77463552 bytes.\nAs you can see, I ran into an out of memory (OOM) problem running this code on my machine (on CPU and on GPU).\nThis is where you would have to take the problem to the clusters.\nIf this happens to you, you can also reduce the batch size from 32 to 16 as we saw earlier.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Training"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_training.html#plot-metrics",
    "href": "ai/jxai/jxai_training.html#plot-metrics",
    "title": "Training",
    "section": "Plot metrics",
    "text": "Plot metrics\nIf you have the hardware to do the training, you can plot the metrics.\nEvolution of training loss:\nplt.plot(train_metrics_history['train_loss'], label='Loss value during the training')\nplt.legend()\nEvolution of validation loss and accuracy:\nfig, axs = plt.subplots(1, 2, figsize=(10, 10))\naxs[0].set_title('Loss value on validation set')\naxs[0].plot(eval_metrics_history['val_loss'])\naxs[1].set_title('Accuracy on validation set')\naxs[1].plot(eval_metrics_history['val_accuracy'])\nYou can also use TensorBoard for this or‚Äîeven better‚Äîexperiment tracking tools such as MLflow that will allow you to compare various training experiments.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Training"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_training.html#next-steps-for-harder-problems",
    "href": "ai/jxai/jxai_training.html#next-steps-for-harder-problems",
    "title": "Training",
    "section": "Next steps for harder problems",
    "text": "Next steps for harder problems\nFine-tuning a classification model shouldn‚Äôt take many epochs and this approach should be sufficient for our example.\nFor some problems however, you will need A LOT more training. In that case, there are additional steps you need to take.\n\nCheckpointing\nCheckpointing becomes essential if you train for a long time. This will save you from loosing days of training if something happens (cluster issue, power outage, computer failure, training interruption‚Ä¶)\nOrbax provides checkpointing utilities for JAX.\n\n\nStopping\nIf the training is very long, how do you know how many epochs you need to choose?\nYou don‚Äôt want to take a random guess. You also don‚Äôt want to spend your days and nights staring at TensorBoard or MLflow. So you need to set things up to have the training stop automatically.\n\nMonitoring\nThe training loss always goes down (eventually to 0) as the accuracy keeps going up. So what you want to monitor is the validation loss.\nThe validation loss should go down as the model improves, then flatten out, and eventually start going up again as you start overfitting. At that point, the model is learning all the idiosyncrasies of the training set (which is why it is doing better and better on it), to a point that it is learning features that are not applicable to images that are not part of the training set (hence why the validation loss starts to deteriorate).\n\n\nEarly stopping\nThe way to set things up for automatic stopping is to choose a large number of epochs (e.g.¬†50)‚Äîmany more than you expect to need, and stop the model when the validation loss goes up.\nYou can use, for instance, an if/else statement to automatically stop training when you get to that point.\nTo be more sophisticated, instead of stopping as soon as this happens, one hyperparameter that can be set is patience.\nPatience is the number of epochs the model should continue training after the validation loss goes up (usually 3 to 5). This allows the model to recover from temporary plateaus and avoids the problem of double descent.\nOnce that patience value is reached, you should use the checkpoint for the best validation loss (before the patience period) as your trained model.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Training"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_preprocess.html",
    "href": "ai/jxai/jxai_preprocess.html",
    "title": "Data preprocessing",
    "section": "",
    "text": "In this section, we look at the images and create new ones that we save to disk as a preprocessing step.\nWe also create a Dataset class and instantiate one instance for the training set and one for the evaluation set using the preprocessed images.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data preprocessing"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_preprocess.html#load-the-metadata-dataframe",
    "href": "ai/jxai/jxai_preprocess.html#load-the-metadata-dataframe",
    "title": "Data preprocessing",
    "section": "Load the metadata DataFrame",
    "text": "Load the metadata DataFrame\nbase_dir = '&lt;path-of-the-nabirds-dir&gt;'\n\nTo be replaced by actual path: in our training cluster, the base_dir is at /project/def-sponsor00/nabirds:\nbase_dir = '/project/def-sponsor00/nabirds'\n\nLet‚Äôs read our Parquet file back in:\n\nimport polars as pl\n\nmetadata = pl.read_parquet('metadata.parquet')",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data preprocessing"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_preprocess.html#read-in-images",
    "href": "ai/jxai/jxai_preprocess.html#read-in-images",
    "title": "Data preprocessing",
    "section": "Read in images",
    "text": "Read in images\nTo read in the images, there are many options, including:\n\nPIL.Image.open from Pillow,\ncv2.imread from OpenCV,\nskimage.io.imread from scikit-image.\n\nHere, we are using imageio.imread from imageio which is an excellent option because it automatically creates a NumPy ndarrays, choosing a dtype based on the image, and it is faster than other options (scikit-image actually uses it now instead of their own implementation).",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data preprocessing"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_preprocess.html#initial-dataset-class",
    "href": "ai/jxai/jxai_preprocess.html#initial-dataset-class",
    "title": "Data preprocessing",
    "section": "Initial Dataset class",
    "text": "Initial Dataset class\n\nimport os\nimport imageio.v3 as iio\n\nclass NABirdsDataset:\n    \"\"\"NABirds dataset class.\"\"\"\n    def __init__(self, metadata, data_dir):\n        self.metadata = metadata\n        self.data_dir = data_dir\n    def __len__(self):\n        return len(self.metadata)\n    def __getitem__(self, idx):\n        path = os.path.join(\n            self.data_dir,\n            self.metadata.get_column('path')[idx]\n        )\n        img = iio.imread(path)\n        species_name = self.metadata.get_column('species_name')[idx]\n        species_id = self.metadata.get_column('species_id')[idx]\n        photographer = self.metadata.get_column('photographer')[idx]\n        bbx = self.metadata.get_column('bb_x')[idx]\n        bby = self.metadata.get_column('bb_y')[idx]\n        bbw = self.metadata.get_column('bb_width')[idx]\n        bbh = self.metadata.get_column('bb_height')[idx]\n        element = {\n            'img': img,\n            'species_name': species_name,\n            'species_id': species_id,\n            'photographer': photographer,\n            'bbx' : bbx,\n            'bby' : bby,\n            'bbw' : bbw,\n            'bbh' : bbh\n        }\n        return element\n\n\n\n\n\n\n\nTipEquivalent using PyTorch\n\n\n\n\n\nPyTorch provides torch.utils.data.Dataset, an abstract class representing a dataset. You need to write a subclass of torch.utils.data.Dataset (let‚Äôs call it NABirdsDataset) so that it inherits from torch.utils.data.Dataset, but with characteristics matching our own dataset.\nA PyTorch custom Dataset class must implement three methods:\n\n__init__: initializes a new instance (object) of the class,\n__len__: returns the number of elements in the new dataset class, and\n__getitem__: loads and returns an element from the dataset at a given index idx:\n\nfrom torch.utils.data import Dataset\n\nclass NABirdsDatasetPyTorch(Dataset):\n    \"\"\"NABirds dataset class.\"\"\"\n    def __init__(self, metadata, data_dir, transform=None):\n        self.metadata = metadata\n        self.data_dir = data_dir\n        self.transform = transform\n    def __len__(self):\n        return len(self.metadata)\n    def __getitem__(self, idx):\n        path = os.path.join(\n            self.data_dir,\n            self.metadata.get_column('path')[idx]\n        )\n        img = iio.imread(path)\n        species_name = self.metadata.get_column('species_name')[idx]\n        species_id = self.metadata.get_column('species_id')[idx]\n        photographer = self.metadata.get_column('photographer')[idx]\n        bbx = self.metadata.get_column('bb_x')[idx]\n        bby = self.metadata.get_column('bb_y')[idx]\n        bbw = self.metadata.get_column('bb_width')[idx]\n        bbh = self.metadata.get_column('bb_height')[idx]\n        element = {\n            'img': img,\n            'species_name': species_name,\n            'species_id': species_id,\n            'photographer': photographer,\n            'bbx' : bbx,\n            'bby' : bby,\n            'bbw' : bbw,\n            'bbh' : bbh\n        }\n        if self.transform:\n            element = self.transform(element)\n        return element",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data preprocessing"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_preprocess.html#instantiate-initial-class",
    "href": "ai/jxai/jxai_preprocess.html#instantiate-initial-class",
    "title": "Data preprocessing",
    "section": "Instantiate initial class",
    "text": "Instantiate initial class\n\nimg_dir = os.path.join(base_dir, 'images')\n\nnabirds_initial = NABirdsDataset(\n    metadata,\n    img_dir\n)",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data preprocessing"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_preprocess.html#print-an-element",
    "href": "ai/jxai/jxai_preprocess.html#print-an-element",
    "title": "Data preprocessing",
    "section": "Print an element",
    "text": "Print an element\n\nnext(iter(nabirds_initial))\n\n{'img': array([[[ 48,  46,  49],\n         [ 52,  50,  53],\n         [ 54,  52,  53],\n         ...,\n         [ 84,  84,  82],\n         [ 86,  86,  84],\n         [ 90,  90,  88]],\n \n        [[ 47,  45,  48],\n         [ 50,  48,  51],\n         [ 52,  50,  51],\n         ...,\n         [ 84,  84,  82],\n         [ 85,  85,  83],\n         [ 88,  88,  86]],\n \n        [[ 51,  49,  50],\n         [ 53,  51,  52],\n         [ 54,  52,  53],\n         ...,\n         [ 83,  83,  81],\n         [ 83,  83,  81],\n         [ 87,  87,  85]],\n \n        ...,\n \n        [[222, 221, 226],\n         [221, 220, 225],\n         [221, 220, 225],\n         ...,\n         [ 88,  88,  88],\n         [ 87,  85,  88],\n         [ 89,  87,  90]],\n \n        [[220, 219, 224],\n         [220, 219, 224],\n         [220, 219, 224],\n         ...,\n         [ 88,  88,  88],\n         [ 86,  84,  87],\n         [ 88,  86,  89]],\n \n        [[220, 219, 224],\n         [220, 219, 224],\n         [220, 219, 224],\n         ...,\n         [ 88,  88,  88],\n         [ 85,  83,  86],\n         [ 87,  85,  88]]], shape=(341, 296, 3), dtype=uint8),\n 'species_name': 'Oak Titmouse',\n 'species_id': 260,\n 'photographer': 'Ruth Cantwell',\n 'bbx': 83,\n 'bby': 59,\n 'bbw': 128,\n 'bbh': 228}\n\n\n\nNote the image values between 0 and 255.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data preprocessing"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_preprocess.html#display-a-sample-of-data",
    "href": "ai/jxai/jxai_preprocess.html#display-a-sample-of-data",
    "title": "Data preprocessing",
    "section": "Display a sample of data",
    "text": "Display a sample of data\nLet‚Äôs display the first 4 images and their bounding boxes (remember that we have to display the photographers names as a requirement of this dataset):\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nfig = plt.figure(figsize=(8, 9))\n\nfor i, element in enumerate(nabirds_initial):\n    ax = plt.subplot(2, 2, i + 1)\n    plt.tight_layout()\n    ax.set_title(\n        f\"\"\"\n        {element['species_name']}\n        Picture by {element['photographer']}\n        \"\"\",\n        fontsize=9,\n        linespacing=1.5\n    )\n    ax.axis('off')\n    plt.imshow(element['img'])\n    rect = patches.Rectangle(\n        (element['bbx'], element['bby']),\n        element['bbw'],\n        element['bbh'],\n        linewidth=1,\n        edgecolor='r',\n        facecolor='none'\n    )\n    ax.add_patch(rect)\n    if i == 3:\n        plt.show()\n        break",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data preprocessing"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_preprocess.html#print-info-on-a-sample-of-data",
    "href": "ai/jxai/jxai_preprocess.html#print-info-on-a-sample-of-data",
    "title": "Data preprocessing",
    "section": "Print info on a sample of data",
    "text": "Print info on a sample of data\n\nfor i, element in enumerate(nabirds_initial):\n    print(f\"Image dimensions: {element['img'].shape}, data type: {element['img'].dtype}\")\n    if i == 3:\n        break\n\nImage dimensions: (341, 296, 3), data type: uint8\nImage dimensions: (427, 640, 3), data type: uint8\nImage dimensions: (1024, 730, 3), data type: uint8\nImage dimensions: (680, 1024, 3), data type: uint8\n\n\nNotice how the images are all of different sizes. This is a problem because neural networks need images of the same size.\nWe are also not making use of the bounding boxes this dataset comes with. This means that we have a large number of pixels we know do not contain any bird part.\nLastly, our images are fairly large (often up to 1024 pixels in width or height). Classification models often come with a few variants for a handful of different image sizes, but the most standard size is 224 by 224 (good compromise between detail and speed).",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data preprocessing"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_preprocess.html#cleaning-dataset-class",
    "href": "ai/jxai/jxai_preprocess.html#cleaning-dataset-class",
    "title": "Data preprocessing",
    "section": "Cleaning Dataset class",
    "text": "Cleaning Dataset class\nWe want to crop the unnecessary parts of images, then resize them (without distortion that could invalidate the labels) to a size of 224 x 224. We will treat the training and evaluation images differently.\nWe want to randomly crop the training images as one of our augmentation technique. We want the randomly cropped images to be 224 x 224. So we don‚Äôt want to resize them to 224 x 224 before the random crops or they‚Äôll end up smaller, then re-enlarged and we will loose some resolution unnecessarily. So instead we crop them to the bounding box with an additional 20% margin and resize them to 269 x 269. the random crop will bring them back to the final size of 224 x 224.\nFor the evaluation set, we crop to the bounding boxes (no margin) and directly resize to 224 x 224.\nThen we will save all the images to files since this step only needs to happen once (remember our strategy).\nWe could write a function to clean our images, but another more elegant approach, is to create a class.\nTo downsize the images without distortion, we use skimage.transform.resize.\n\nfrom skimage.transform import resize\nimport numpy as np\n\nclass CleaningDataset:\n    \"\"\"Cleaning dataset class.\"\"\"\n    def __init__(self, metadata, source_dir, target_dir, target_size, margin_factor):\n        self.metadata = metadata\n        self.source_dir = source_dir\n        self.target_dir = target_dir\n        self.target_size = target_size\n        self.margin_factor = margin_factor\n\n    def __len__(self):\n        return len(self.metadata)\n\n    def __getitem__(self, idx):\n        \"\"\"Returns cropped, resized image and save path.\"\"\"\n\n        # Build paths\n        read_path = os.path.join(\n            self.source_dir,\n            self.metadata.get_column('path')[idx]\n        )\n        save_path = os.path.join(\n            self.target_dir,\n            self.metadata.get_column('path')[idx]\n        )\n\n        # Load image\n        try:\n            img = iio.imread(read_path)\n        except Exception as e:\n            print(f\"Error loading {filename}: {e}\")\n            return None, None\n\n        # If a file has an alpha channel, drop it\n1        if img.shape[2] == 4:\n            img = img[:,:,:3]\n\n        # Get bounding box data\n        bbx = self.metadata.get_column('bb_x')[idx]\n        bby = self.metadata.get_column('bb_y')[idx]\n        bbw = self.metadata.get_column('bb_width')[idx]\n        bbh = self.metadata.get_column('bb_height')[idx]\n\n        # Crop image with a 20% margin:\n        # 1. Get the image dimensions (to make sure we don't go out of bounds)\n        height, width = img.shape[:2]\n\n        # 2. Calculate the margin size\n        # We use int() because pixel coordinates must be integers\n        margin_w = int(bbw * self.margin_factor)\n        margin_h = int(bbh * self.margin_factor)\n\n        # 3. Calculate the new coordinates with the margin\n        x1 = bbx - margin_w\n        y1 = bby - margin_h\n        x2 = bbx + bbw + margin_w\n        y2 = bby + bbh + margin_h\n\n        # 4. Set limits to coordinates to ensure they stay inside the image\n        # x1 and y1 cannot be less than 0\n        # x2 and y2 cannot be larger than the image width/height\n        x1 = max(0, x1)\n        y1 = max(0, y1)\n        x2 = min(width, x2)\n        y2 = min(height, y2)\n\n        # 5. Crop\n        img_cropped = img[y1:y2, x1:x2]\n\n        # 6. Resize\n        # Resize img to target size with padding to avoid distortion\n        h, w, _ = img_cropped.shape\n        target_h = target_w = self.target_size\n\n        # Calculate the scaling factor to fit the image inside the box\n        scale = min(target_h / h, target_w / w)\n\n        # Calculate the new dimensions of the image\n        new_h, new_w = int(h * scale), int(w * scale)\n\n        # Resize\n        img_resized = resize(img_cropped, (new_h, new_w), anti_aliasing=True)\n\n        # Create a black canvas (zeros) of the target size\n        out_img = np.zeros((target_h, target_w, img.shape[2]), dtype=img_resized.dtype)\n\n        # Place the resized image in the center of the canvas\n        y_offset = (target_h - new_h) // 2\n        x_offset = (target_w - new_w) // 2\n        out_img[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = img_resized\n\n        # Convert back to uint8 (0-255)\n2        final_img = (out_img * 255).astype(np.uint8)\n\n        return final_img, save_path\n\n\n1\n\nReason for this step: see note below.\n\n2\n\nskimage returns elements with a dtype(float64) (values from 0 to 1), but we want to save space on disk.\n\n\n\n\n\nEven serious, well curated datasets often contain inconsistent or erroneous data. After playing with this dataset, I realized that at least one image has 4 channels (RGBA, i.e.¬†RGB and the alpha channel). This means that its NumPy array version has 4 instead of 3 dimensions‚Ä¶\nThis didn‚Äôt make any sense to me since all the images were JPEG (it is easy to verify that with command line utilities such as fd) and JPEG images do not have an alpha channel.\nSo I wrote a function that would return the path of the (first) image with an extra channel and I got 0344/3b69ce35b9404f3eb321100c93dd2b43.jpg.\nIt appears to be a JPEG image. However, when passing it to the identify command from ImageMagick, I realized that it was in fact a PNG image mislabelled as a JPEG‚Ä¶\nHere is an equivalent way to show this in Python:\n\nfrom PIL import Image\n\nimg = os.path.join(img_dir, '0344/3b69ce35b9404f3eb321100c93dd2b43.jpg')\n\nwith Image.open(img) as img:\n    print(f\"The actual format of the image is {img.format}.\")\n\nThe actual format of the image is PNG.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data preprocessing"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_preprocess.html#create-the-clean-data-in-parallel",
    "href": "ai/jxai/jxai_preprocess.html#create-the-clean-data-in-parallel",
    "title": "Data preprocessing",
    "section": "Create the clean data in parallel",
    "text": "Create the clean data in parallel\nBuilt-in multiprocessing in Python can be done with either of the ProcessPoolExecutor class from the concurrent.futures module or the Pool class from the multiprocessing package.\nLet‚Äôs use the first one:\n\nfrom concurrent.futures import ProcessPoolExecutor\nfrom tqdm import tqdm  # to display a progress bar\n\nLet‚Äôs instantiate our CleaningDataset for the training set:\n\ncleaned_img_dir = os.path.join(base_dir, 'cleaned_images')\n\n# Filter only training set from the metadata DataFrame:\nmetadata_train = metadata.filter(pl.col('is_training_img') == 1)\n\ntrain_dataset_to_clean = CleaningDataset(\n    metadata=metadata_train,\n    source_dir=img_dir,\n    target_dir=cleaned_img_dir,\n    target_size=269,              # 224 with a 20% margin\n    margin_factor=0.2\n)\n\nAnd let‚Äôs create an instance for the validation set:\n\n# Filter the validation metadata in our DataFrame:\nmetadata_val = metadata.filter(pl.col('is_training_img') == 0)\n\nval_dataset_to_clean = CleaningDataset(\n    metadata=metadata_val,\n    source_dir=img_dir,\n    target_dir=cleaned_img_dir,\n    target_size=224,\n    margin_factor=0\n)\n\nWe can now create helper functions:\n\ndef process_train_idx(i):\n    \"\"\"Helper function for the parallel worker.\"\"\"\n    img, path = train_dataset_to_clean[i]\n    if img is not None:\n        # Create target directory if it doesn't exist\n        os.makedirs(os.path.dirname(path), exist_ok=True)\n        # Save cleaned image\n        iio.imwrite(path, img)\n        return 1 # Success\n    return 0 # Failure\n\n\ndef process_val_idx(i):\n    \"\"\"Helper function for the parallel worker.\"\"\"\n    img, path = val_dataset_to_clean[i]\n    if img is not None:\n        # Create target directory if it doesn't exist\n        os.makedirs(os.path.dirname(path), exist_ok=True)\n        # Save cleaned image\n        iio.imwrite(path, img)\n        return 1 # Success\n    return 0 # Failure\n\nAnd run them in parallel:\n\nNote that you will not be able to run the actual processing chunks:\n\nCropping and resizing 50,000 images takes a lot on the CPUs and if we do it all, we will probably crash the cluster.\nAdditionally, we would all be trying to write to the same path, creating weird file conflicts.\n\nI ran this ahead of time and already created the cropped and resized files and I did not give you write access to the dataset.\nIf you want to run the code and experiment with various numbers of CPUs, you can do this later on your machine or on a production cluster.\n\n\n\nDon't try to run this chunk in the training cluster.\n\n# Use as many workers as you have CPU cores\nwith ProcessPoolExecutor() as executor:\n    # Map indices to the process function\n    results = list(tqdm(\n        executor.map(process_train_idx, range(len(train_dataset_to_clean))),\n        total=len(train_dataset_to_clean),\n        desc='Cleaning Images'\n    ))\n\nprint(f\"Done. {sum(results)} training images processed.\")\n\nDone. 23929 training images processed.\n\n\nDon't try to run this chunk in the training cluster.\n\n# Use as many workers as you have CPU cores\nwith ProcessPoolExecutor() as executor:\n    # Map indices to the process function\n    results = list(tqdm(\n        executor.map(process_val_idx, range(len(val_dataset_to_clean))),\n        total=len(val_dataset_to_clean),\n        desc='Cleaning Images'\n    ))\n\nprint(f\"Done. {sum(results)} validation images processed.\")\n\nDone. 24633 validation images processed.\nYou can watch the parallel work live with an application such as htop (on your machine or the cluster) or btop (on your machine).\nHere is a screenshot I took from btop on my machine while creating the cleaned images. You can see that my 16 cores are working in parallel:",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data preprocessing"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_preprocess.html#final-dataset-class",
    "href": "ai/jxai/jxai_preprocess.html#final-dataset-class",
    "title": "Data preprocessing",
    "section": "Final Dataset class",
    "text": "Final Dataset class\nNow we can create a new, simplified Dataset class (we don‚Äôt need the bounding boxes anymore):\n\nclass NABirdsDataset:\n    \"\"\"NABirds dataset class.\"\"\"\n    def __init__(self, metadata, data_dir):\n        self.metadata = metadata\n        self.data_dir = data_dir\n\n    def __len__(self):\n        return len(self.metadata)\n\n    def __getitem__(self, idx):\n        path = os.path.join(self.data_dir, self.metadata.get_column('path')[idx])\n        img = iio.imread(path)\n        species_name = self.metadata.get_column('species_name')[idx]\n        species_id = self.metadata.get_column('species_id')[idx]\n        photographer = self.metadata.get_column('photographer')[idx]\n        element = {\n            'img': img,\n            'species_name': species_name,\n            'species_id': species_id,\n            'photographer': photographer,\n        }\n\n        return element",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data preprocessing"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_preprocess.html#training-set",
    "href": "ai/jxai/jxai_preprocess.html#training-set",
    "title": "Data preprocessing",
    "section": "Training set",
    "text": "Training set\nWe instantiate this Dataset class with the training set, using the cropped and resized images:\n\n# Create Dataset class instance:\nnabirds_train = NABirdsDataset(metadata_train, cleaned_img_dir)",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data preprocessing"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_preprocess.html#validation-set",
    "href": "ai/jxai/jxai_preprocess.html#validation-set",
    "title": "Data preprocessing",
    "section": "Validation set",
    "text": "Validation set\nAnd for the validation set, we need to instantiate a Dataset class with our validation data on the cropped and resized images:\n\n# Instantiate a Dataset class with the validation data:\nnabirds_val = NABirdsDataset(metadata_val, cleaned_img_dir)",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data preprocessing"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_preprocess.html#print-info-on-samples",
    "href": "ai/jxai/jxai_preprocess.html#print-info-on-samples",
    "title": "Data preprocessing",
    "section": "Print info on samples",
    "text": "Print info on samples\nLet‚Äôs print info on a sample of our training set:\n\nfor i, element in enumerate(nabirds_train):\n    print(f\"Image new dimensions: {element['img'].shape}, data type: {element['img'].dtype}\")\n    if i == 3:\n        break\n\nImage new dimensions: (269, 269, 3), data type: uint8\nImage new dimensions: (269, 269, 3), data type: uint8\nImage new dimensions: (269, 269, 3), data type: uint8\nImage new dimensions: (269, 269, 3), data type: uint8\n\n\n\nNotice that all the images are now of the same size: 269 x 269.\n\nAnd on a sample of our evaluation set:\n\nfor i, element in enumerate(nabirds_val):\n    print(f\"Image new dimensions: {element['img'].shape}, data type: {element['img'].dtype}\")\n    if i == 3:\n        break\n\nImage new dimensions: (224, 224, 3), data type: uint8\nImage new dimensions: (224, 224, 3), data type: uint8\nImage new dimensions: (224, 224, 3), data type: uint8\nImage new dimensions: (224, 224, 3), data type: uint8\n\n\n\nNotice that all the images are now of the same size: 224 x 224.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data preprocessing"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_preprocess.html#display-samples",
    "href": "ai/jxai/jxai_preprocess.html#display-samples",
    "title": "Data preprocessing",
    "section": "Display samples",
    "text": "Display samples\nLet‚Äôs display the first 4 cleaned images in our training set to make sure they look like what we expect:\n\nfig = plt.figure(figsize=(8, 9))\n\nfor i, element in enumerate(nabirds_train):\n    ax = plt.subplot(2, 2, i + 1)\n    plt.tight_layout()\n    ax.set_title(\n        f\"\"\"\n        {element['species_name']}\n        Picture by {element['photographer']}\n        \"\"\",\n        fontsize=9,\n        linespacing=1.5\n    )\n    ax.axis('off')\n    plt.imshow(element['img'])\n    if i == 3:\n        plt.show()\n        break\n\n\n\n\n\n\n\n\n\nNotice the lower resolution (since we downsized) compared to the first few images we displayed. This resolution is still adequate (the distinctive bird features are still perfectly visible).\nNotice also the margin around the birds.\n\nAnd let‚Äôs do the same for the evaluation set:\n\nfig = plt.figure(figsize=(8, 9))\n\nfor i, element in enumerate(nabirds_val):\n    ax = plt.subplot(2, 2, i + 1)\n    plt.tight_layout()\n    ax.set_title(\n        f\"\"\"\n        {element['species_name']}\n        Picture by {element['photographer']}\n        \"\"\",\n        fontsize=9,\n        linespacing=1.5\n    )\n    ax.axis('off')\n    plt.imshow(element['img'])\n    if i == 3:\n        plt.show()\n        break\n\n\n\n\n\n\n\n\n\nNotice how the cropping was done without margin on the evaluation set (matching the bounding boxes just around the birds).",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data preprocessing"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_metadata.html",
    "href": "ai/jxai/jxai_metadata.html",
    "title": "Compiling the metadata",
    "section": "",
    "text": "In this section, we process some of the metadata associated with the NABirds dataset by creating a Polars DataFrame collecting all the information we will need while processing the images and training our model. This allows us to get some information about the dataset.\nPolars is a modern and ultra fast package that you should use instead of pandas whenever you can if you care about performance.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Compiling the metadata"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_metadata.html#metadata-files",
    "href": "ai/jxai/jxai_metadata.html#metadata-files",
    "title": "Compiling the metadata",
    "section": "Metadata files",
    "text": "Metadata files\nIn addition to images, the dataset comes with a number of text files. To understand the dataset, of course, the place to start is by reading ‚Ä¶ the README.\nYou can find it in full in this accordion box, with a summary below:\n\n\n\n\n\n\nNoteREADME\n\n\n\n\n\n\nThe nabirds dataset\n\nVersions\nv0 - June 2015: initial release\nFor more information about the dataset, visit the project websites:\nhttp://www.vision.caltech.edu/visipedia http://vision.cornell.edu/se3/projects/visipedia/ http://dl.allaboutbirds.org/nabirds\nIf you use the dataset in a publication, please cite the dataset in the style described on the dataset website (see url above).\nPlease see the nabirds.py file for example code on using the data. You can visualize images and annotations by running: python nabirds.py Make sure you are in the nabirds/ directory.\n\n\nDirectory information\n\nimages/\nThe images organized in subdirectories based on species. See IMAGES AND CLASS LABELS section below for more info.\nparts/\n11 part locations per image. See PART LOCATIONS section below for more info.\n\n\n\n\nImages and class labels\nImages are contained in the directory images/, with 555 subdirectories (one for each bird category).\n\nList of image files (images.txt)\nThe list of image file names is contained in the file images.txt, with each line corresponding to one image:\n \n\n\nTrain/test split (train_test_split.txt)\nThe suggested train/test split is contained in the file train_test_split.txt, with each line corresponding to one image:\n \nwhere  corresponds to the ID in images.txt, and a value of 1 or 0 for  denotes that the file is in the training or test set, respectively.\n\n\nImage sizes (sizes.txt)\nThe size of each image in pixels:\n  \nwhere  corresponds to the ID in images.txt, and  and  correspond to the width and height of the image in pixels.\n\n\nImage photographers (photographers.txt)\nThe photographer for each image:\n \nwhere  corresponds to the ID in images.txt, and  corresponds to the name of the photographer that took the photo. Please be considerate and display the photographer‚Äôs name when displaying their image.\n\n\nList of class names (classes.txt)\nThe list of class names (bird species) is contained in the file classes.txt, with each line corresponding to one class:\n \n\n\nImage class labels (image_class_labels.txt)\nThe ground truth class labels (bird species labels) for each image are contained in the file image_class_labels.txt, with each line corresponding to one image:\n \nwhere  and  correspond to the IDs in images.txt and classes.txt, respectively.\n\n\nClass hierarchy (hierarchy.txt)\nThe ground truth class labels (bird species labels) for each image are contained in the file image_class_labels.txt, with each line corresponding to one image:\n \nwhere  and  correspond to the IDs in classes.txt.\n\n\n\nBounding boxes\nEach image contains a single bounding box label. Bounding box labels are contained in the file bounding_boxes.txt, with each line corresponding to one image:\n    \nwhere  corresponds to the ID in images.txt, and , , , and  are all measured in pixels.\n\n\nPart locations\n\nList of part names (parts/parts.txt)\nThe list of all part names is contained in the file parts/parts.txt, with each line corresponding to one part:\n \n\n\nPart locations (parts/part_locs.txt)\nThe set of all ground truth part locations is contained in the file parts/part_locs.txt, with each line corresponding to the annotation of a particular part in a particular image:\n    \nwhere  and  correspond to the IDs in images.txt and parts/parts.txt, respectively.  and  denote the pixel location of the center of the part.  is 0 if the part is not visible in the image and 1 otherwise.\n\n\n\n\n\nEach image is associated with a UUID.\nWe won‚Äôt need all the information provided with this dataset for this course, but what we need is contained in the following files:\n\n\n\n\n\n\n\nName\nContent\n\n\n\n\nbounding_boxes.txt\nList of UUIDs and their corresponding bounding boxes (one bounding box per image, just around the bird)\n\n\nclasses.txt\nList of class ids and corresponding class names\n\n\nimage_class_labels.txt\nList of UUIDs and their corresponding class ids\n\n\nimages.txt\nList of UUIDs and their corresponding file names\n\n\nphotographers.txt\nList of UUIDs and their corresponding photographers\n\n\nsizes.txt\nList of UUIDs and their corresponding width and height\n\n\ntrain_test_split.txt\nList of UUIDs and 1 or 0 depending on whether the image is for training or validation respectively (the dataset comes with a suggested split)\n\n\n\nThe README has one request:\n\nPlease be considerate and display the photographer‚Äôs name when displaying their image.\n\nWe will make sure to follow it.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Compiling the metadata"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_metadata.html#clean-problem-files",
    "href": "ai/jxai/jxai_metadata.html#clean-problem-files",
    "title": "Compiling the metadata",
    "section": "Clean problem files",
    "text": "Clean problem files\nTwo of the files are problematic because they are jagged: the number of elements per line is inconsistent.\nLet‚Äôs create cleaning functions that write cleaned up copies of these files.\nTo clean the classes.txt file:\n\ndef clean_classes_file(input_filepath, output_filepath):\n    \"\"\"\n    Remove commas, remove parenthesis, and replace all spaces except the first space\n    on each line and the space between species name and subcategory info with underscores.\n\n    Args:\n        input_filepath (str): the path of the input file.\n        output_filepath (str): the path of the output file.\n    \"\"\"\n    with open(input_filepath, 'r') as infile, \\\n         open(output_filepath, 'w') as outfile:\n\n        for line in infile:\n            # Remove commas and ending parenthesis\n            cleaned_line = line.replace(',', '').replace(')', '')\n\n            # Strip newline characters\n            cleaned_line = cleaned_line.strip()\n\n            # Split line into two parts based on the first space\n            parts = cleaned_line.split(' ', 1)\n\n            # Replace spaces in the second part with underscores\n            part2_cleaned = parts[1].replace(' ', '_').replace('_(', ' ')\n\n            final_line = f'{parts[0]} {part2_cleaned}\\n'\n\n            outfile.write(final_line)\n\nTo clean the photographers.txt file:\n\ndef clean_photographer_file(input_filepath, output_filepath):\n    \"\"\"\n    Remove commas, remove quotes, and replace all spaces except the first space\n    on each line with underscores.\n\n    Args:\n        input_filepath (str): the path of the input file.\n        output_filepath (str): the path of the output file.\n    \"\"\"\n    with open(input_filepath, 'r') as infile, \\\n         open(output_filepath, 'w') as outfile:\n\n        for line in infile:\n            # Remove quotes and commas\n            cleaned_line = line.replace('\"', '').replace(',', '')\n\n            # Strip newline characters\n            cleaned_line = cleaned_line.strip()\n\n            # Split line into two parts based on the first space\n            parts = cleaned_line.split(' ', 1)\n\n            # Replace spaces in the second part with underscores\n            part2_cleaned = parts[1].replace(' ', '_')\n\n            final_line = f'{parts[0]} {part2_cleaned}\\n'\n\n            outfile.write(final_line)\n\nThen we can apply the function on our files:\nbase_dir = '&lt;path-of-the-nabirds-dir&gt;'\n\nTo be replaced by actual path: in our training cluster, the base_dir is at /project/def-sponsor00/nabirds:\nbase_dir = '/project/def-sponsor00/nabirds'\n\n\nYou will not be able to run the following chunk in the training cluster because I did not give you write access to the dataset. This is on purpose to avoid everyone trying to write to the same file at the same time.\nI already created the cleaned files.\n\n\nimport os\n\nclean_photographer_file(\n    os.path.join(base_dir, 'photographers.txt'),\n    os.path.join(base_dir, 'photographers_cleaned.txt')\n)\n\nclean_classes_file(\n    os.path.join(base_dir, 'classes.txt'),\n    os.path.join(base_dir, 'classes_cleaned.txt')\n)",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Compiling the metadata"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_metadata.html#create-variables",
    "href": "ai/jxai/jxai_metadata.html#create-variables",
    "title": "Compiling the metadata",
    "section": "Create variables",
    "text": "Create variables\nFor convenience, let‚Äôs create variables with the path of the various files we need:\n\nbb_file = os.path.join(base_dir, 'bounding_boxes.txt')\nclass_id_to_name_file = os.path.join(base_dir, 'classes_cleaned.txt')\nclass_id_file = os.path.join(base_dir, 'image_class_labels.txt')\npath_file = os.path.join(base_dir, 'images.txt')\nphotographer_file = os.path.join(base_dir, 'photographers_cleaned.txt')\nsize_file = os.path.join(base_dir, 'sizes.txt')\ntrain_test_split_file = os.path.join(base_dir, 'train_test_split.txt')",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Compiling the metadata"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_metadata.html#create-a-dataframe",
    "href": "ai/jxai/jxai_metadata.html#create-a-dataframe",
    "title": "Compiling the metadata",
    "section": "Create a DataFrame",
    "text": "Create a DataFrame\nNow it‚Äôs time to put all the data together in one DataFrame.\nFirst, we create a series of DataFrames from each text file:\n\nimport polars as pl\n\nbb = pl.read_csv(\n    bb_file,\n    separator=' ',\n    has_header=False,\n    new_columns=['UUID', 'bb_x', 'bb_y', 'bb_width', 'bb_height']\n)\n\nclass_id = pl.read_csv(\n    class_id_file,\n    separator=' ',\n    has_header=False,\n    new_columns=['UUID', 'class_id']\n)\n\nThe class_id_to_name_file is also fairly complicated: some bird species name are followed by additional information (e.g.¬†‚ÄúAdult‚Äù or ‚ÄúImmature‚Äù) in parenthesis. If we want to train a model to identify bird species (rather than classes including the subcategories), we need to separate the two (see also section below for more explanations on this).\n\nAn easy way to quickly check what that additional information looks like is to run in the terminal, not in Python:\nrg \"\\(\" /project/def-sponsor00/nabirds/classes.txt | fzf\n\nIn order to split species name on the one hand and additional information on the other, we need to create 3 columns instead of 2 for this file. The problem is that many rows only have 2 elements (the additional info is not often present).\nThe shell command above allows to quickly look for the first occurrence of the additional info: it appears at line 295.\nPolars scans the first 100 elements by default to determine the schema or mapping for the DataFrame. We need to increase this value to at least 295 to make sure that it detects the 3rd column during the reading in of the file:\n\nclass_id_to_name = pl.read_csv(\n    class_id_to_name_file,\n    separator=' ',\n    has_header=False,\n    infer_schema_length=296,\n    new_columns=['class_id', 'species', 'subcategory']\n)\n\n\npath = pl.read_csv(\n    path_file,\n    separator=' ',\n    has_header=False,\n    new_columns=['UUID', 'path']\n)\n\nphotographer = pl.read_csv(\n    photographer_file,\n    separator=' ',\n    has_header=False,\n    new_columns=['UUID', 'photographer']\n)\n\nsize = pl.read_csv(\n    size_file,\n    separator=' ',\n    has_header=False,\n    new_columns=['UUID', 'width', 'height']\n)\n\ntrain_test_split = pl.read_csv(\n    train_test_split_file,\n    separator=' ',\n    has_header=False,\n    new_columns=['UUID', 'is_training_img']\n)\n\n\nWe can use polars.read_csv even though we have text files because our files are space separated value files. So they function like CSV files with the exception that we have to set the value of the separator argument to .\n\nThen we can combine the two DataFrames dealing with classes so that the birds identifications becomes directly associated with the birds UUIDs:\n\nclasses_metadata = (\n    class_id.join(class_id_to_name, on='class_id')\n)\n\nFinally, we combine all the DataFrames:\n\ninitial_metadata = (\n    bb.join(classes_metadata, on='UUID')\n    .join(path, on='UUID')\n    .join(photographer, on='UUID')\n    .join(size, on='UUID')\n    .join(train_test_split, on='UUID')\n)",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Compiling the metadata"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_metadata.html#format-strings",
    "href": "ai/jxai/jxai_metadata.html#format-strings",
    "title": "Compiling the metadata",
    "section": "Format strings",
    "text": "Format strings\nWe now have all those underscores in the species, subcategory, and photographer columns. We needed them to read in the files properly into DataFrames, but we now want to format those strings properly:\n\nformatted_metadata = initial_metadata.with_columns(\n    pl.col('species').str.replace_all(r'_', ' ').alias('species_name'),\n    pl.col('subcategory').str.replace_all(r'_', ' '),\n    pl.col('photographer').str.replace_all(r'_', ' ')\n).drop('species')\n\n\nWe are also renaming species to species_name because we will add a species_id in the section below.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Compiling the metadata"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_metadata.html#create-species-mapping",
    "href": "ai/jxai/jxai_metadata.html#create-species-mapping",
    "title": "Compiling the metadata",
    "section": "Create species mapping",
    "text": "Create species mapping\nWe could use class_id as our training labels. The problem with that is that not all the labels are disjunct. For instance:\n\nclass_id 175 is the species Red-shouldered Haw with the subcategory None\nclass_id 359 is the species Red-shouldered Haw with the subcategory Adult\nclass_id 658 is the species Red-shouldered Haw with the subcategory Immature\n\nAnd a Red-shouldered Haw is either an immature or an adult. So class_id 175 overlaps with either of the other two. This is not good to train our model.\nThis emphasizes that you need to know your data very well before you start training a model with it. It is important to spend the time to explore it at length, otherwise the training will fail or perform poorly and you will not understand why.\nThere is an additional file in this dataset called hierarchy.txt that gives a hierarchy of the various classes. In the example above, this shows that both 658 and 359 fall under the category 175. So we could play with that to solve the problem.\nIn this exercise though, I decided that I didn‚Äôt want to train a model that identifies birds at the level of these categories (Red-shouldered Haw adult vs Red-shouldered Haw immature), but at the level of the species (i.e.¬†simply Red-shouldered Haw).\nHow you approach this depends on the model you want to create and what exactly you want it to be able to do.\nIf we use species as the labels, we need to create a mapping for them because models cannot calculate loss on strings‚Äîthey need numeric labels corresponding to the output neurons of your final layer. So we need to associate each species with an integer. This can be done directly in a Polars DataFrame with a dense ranking:\n\nmetadata = formatted_metadata.with_columns(\n    pl.col('species_name').rank('dense').alias('species_id')\n)",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Compiling the metadata"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_metadata.html#sanity-checks",
    "href": "ai/jxai/jxai_metadata.html#sanity-checks",
    "title": "Compiling the metadata",
    "section": "Sanity checks",
    "text": "Sanity checks\nLet‚Äôs see what our DataFrame looks like:\nmetadata\n\n\nshape: (48_562, 14)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ UUID          ‚îÜ bb_x ‚îÜ bb_y ‚îÜ bb_width ‚îÜ ‚Ä¶ ‚îÜ height ‚îÜ is_training_i ‚îÜ species_name  ‚îÜ species_id ‚îÇ\n‚îÇ ---           ‚îÜ ---  ‚îÜ ---  ‚îÜ ---      ‚îÜ   ‚îÜ ---    ‚îÜ mg            ‚îÜ ---           ‚îÜ ---        ‚îÇ\n‚îÇ str           ‚îÜ i64  ‚îÜ i64  ‚îÜ i64      ‚îÜ   ‚îÜ i64    ‚îÜ ---           ‚îÜ str           ‚îÜ u32        ‚îÇ\n‚îÇ               ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ i64           ‚îÜ               ‚îÜ            ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 0000139e-21dc ‚îÜ 83   ‚îÜ 59   ‚îÜ 128      ‚îÜ ‚Ä¶ ‚îÜ 341    ‚îÜ 0             ‚îÜ Oak Titmouse  ‚îÜ 260        ‚îÇ\n‚îÇ -4d0c-bfe1-4c ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ ae3c‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ 0000d9fc-4e02 ‚îÜ 328  ‚îÜ 88   ‚îÜ 163      ‚îÜ ‚Ä¶ ‚îÜ 427    ‚îÜ 0             ‚îÜ Ovenbird      ‚îÜ 264        ‚îÇ\n‚îÇ -4c06-a0af-a5 ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ 5cfb‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ 00019306-9d83 ‚îÜ 174  ‚îÜ 367  ‚îÜ 219      ‚îÜ ‚Ä¶ ‚îÜ 1024   ‚îÜ 0             ‚îÜ Savannah      ‚îÜ 322        ‚îÇ\n‚îÇ -4334-b255-a4 ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ Sparrow       ‚îÜ            ‚îÇ\n‚îÇ 4774‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ 0001afd4-99a1 ‚îÜ 307  ‚îÜ 179  ‚îÜ 492      ‚îÜ ‚Ä¶ ‚îÜ 680    ‚îÜ 1             ‚îÜ Eared Grebe   ‚îÜ 145        ‚îÇ\n‚îÇ -4a67-b940-d4 ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ 1941‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ 000332b8-997c ‚îÜ 395  ‚îÜ 139  ‚îÜ 262      ‚îÜ ‚Ä¶ ‚îÜ 682    ‚îÜ 0             ‚îÜ Eastern       ‚îÜ 149        ‚îÇ\n‚îÇ -4540-9647-2f ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ Phoebe        ‚îÜ            ‚îÇ\n‚îÇ 0a84‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ ‚Ä¶             ‚îÜ ‚Ä¶    ‚îÜ ‚Ä¶    ‚îÜ ‚Ä¶        ‚îÜ ‚Ä¶ ‚îÜ ‚Ä¶      ‚îÜ ‚Ä¶             ‚îÜ ‚Ä¶             ‚îÜ ‚Ä¶          ‚îÇ\n‚îÇ fff86e8b-795f ‚îÜ 344  ‚îÜ 163  ‚îÜ 291      ‚îÜ ‚Ä¶ ‚îÜ 819    ‚îÜ 1             ‚îÜ Canyon Towhee ‚îÜ 101        ‚îÇ\n‚îÇ -400a-91e8-56 ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ 5bbb‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ fff926d7-ccad ‚îÜ 330  ‚îÜ 180  ‚îÜ 339      ‚îÜ ‚Ä¶ ‚îÜ 956    ‚îÜ 1             ‚îÜ Rough-legged  ‚îÜ 310        ‚îÇ\n‚îÇ -4788-839e-97 ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ Hawk          ‚îÜ            ‚îÇ\n‚îÇ af2d‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ fffa33ef-a765 ‚îÜ 184  ‚îÜ 94   ‚îÜ 258      ‚îÜ ‚Ä¶ ‚îÜ 800    ‚îÜ 1             ‚îÜ Swallow-taile ‚îÜ 345        ‚îÇ\n‚îÇ -408d-8d66-6e ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ d Kite        ‚îÜ            ‚îÇ\n‚îÇ fc7f‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ ffff0d87-bc84 ‚îÜ 102  ‚îÜ 210  ‚îÜ 461      ‚îÜ ‚Ä¶ ‚îÜ 1024   ‚îÜ 0             ‚îÜ Broad-billed  ‚îÜ 77         ‚îÇ\n‚îÇ -4ef2-a47e-a4 ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ Hummingbird   ‚îÜ            ‚îÇ\n‚îÇ bfa4‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ fffff3a5-2a75 ‚îÜ 281  ‚îÜ 164  ‚îÜ 524      ‚îÜ ‚Ä¶ ‚îÜ 683    ‚îÜ 0             ‚îÜ Black-throate ‚îÜ 57         ‚îÇ\n‚îÇ -47d0-887f-03 ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ d Gray        ‚îÜ            ‚îÇ\n‚îÇ 871e‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ Warbler       ‚îÜ            ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\nAnd then let‚Äôs explore a number of characteristics:\n\nprint(metadata.columns)\nprint(metadata.row(0))\nprint(metadata.row(-1))\n\n['UUID', 'bb_x', 'bb_y', 'bb_width', 'bb_height', 'class_id', 'subcategory', 'path', 'photographer', 'width', 'height', 'is_training_img', 'species_name', 'species_id']\n('0000139e-21dc-4d0c-bfe1-4cae3c85c829', 83, 59, 128, 228, 817, None, '0817/0000139e21dc4d0cbfe14cae3c85c829.jpg', 'Ruth Cantwell', 296, 341, 0, 'Oak Titmouse', 260)\n('fffff3a5-2a75-47d0-887f-03871e3f9a37', 281, 164, 524, 279, 880, None, '0880/fffff3a52a7547d0887f03871e3f9a37.jpg', 'Dominic Sherony', 1024, 683, 0, 'Black-throated Gray Warbler', 57)\n\n\nmetadata.head()\n\n\nshape: (5, 14)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ UUID          ‚îÜ bb_x ‚îÜ bb_y ‚îÜ bb_width ‚îÜ ‚Ä¶ ‚îÜ height ‚îÜ is_training_i ‚îÜ species_name  ‚îÜ species_id ‚îÇ\n‚îÇ ---           ‚îÜ ---  ‚îÜ ---  ‚îÜ ---      ‚îÜ   ‚îÜ ---    ‚îÜ mg            ‚îÜ ---           ‚îÜ ---        ‚îÇ\n‚îÇ str           ‚îÜ i64  ‚îÜ i64  ‚îÜ i64      ‚îÜ   ‚îÜ i64    ‚îÜ ---           ‚îÜ str           ‚îÜ u32        ‚îÇ\n‚îÇ               ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ i64           ‚îÜ               ‚îÜ            ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 0000139e-21dc ‚îÜ 83   ‚îÜ 59   ‚îÜ 128      ‚îÜ ‚Ä¶ ‚îÜ 341    ‚îÜ 0             ‚îÜ Oak Titmouse  ‚îÜ 260        ‚îÇ\n‚îÇ -4d0c-bfe1-4c ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ ae3c‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ 0000d9fc-4e02 ‚îÜ 328  ‚îÜ 88   ‚îÜ 163      ‚îÜ ‚Ä¶ ‚îÜ 427    ‚îÜ 0             ‚îÜ Ovenbird      ‚îÜ 264        ‚îÇ\n‚îÇ -4c06-a0af-a5 ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ 5cfb‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ 00019306-9d83 ‚îÜ 174  ‚îÜ 367  ‚îÜ 219      ‚îÜ ‚Ä¶ ‚îÜ 1024   ‚îÜ 0             ‚îÜ Savannah      ‚îÜ 322        ‚îÇ\n‚îÇ -4334-b255-a4 ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ Sparrow       ‚îÜ            ‚îÇ\n‚îÇ 4774‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ 0001afd4-99a1 ‚îÜ 307  ‚îÜ 179  ‚îÜ 492      ‚îÜ ‚Ä¶ ‚îÜ 680    ‚îÜ 1             ‚îÜ Eared Grebe   ‚îÜ 145        ‚îÇ\n‚îÇ -4a67-b940-d4 ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ 1941‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ 000332b8-997c ‚îÜ 395  ‚îÜ 139  ‚îÜ 262      ‚îÜ ‚Ä¶ ‚îÜ 682    ‚îÜ 0             ‚îÜ Eastern       ‚îÜ 149        ‚îÇ\n‚îÇ -4540-9647-2f ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ Phoebe        ‚îÜ            ‚îÇ\n‚îÇ 0a84‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\nmetadata.tail()\n\n\nshape: (5, 14)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ UUID          ‚îÜ bb_x ‚îÜ bb_y ‚îÜ bb_width ‚îÜ ‚Ä¶ ‚îÜ height ‚îÜ is_training_i ‚îÜ species_name  ‚îÜ species_id ‚îÇ\n‚îÇ ---           ‚îÜ ---  ‚îÜ ---  ‚îÜ ---      ‚îÜ   ‚îÜ ---    ‚îÜ mg            ‚îÜ ---           ‚îÜ ---        ‚îÇ\n‚îÇ str           ‚îÜ i64  ‚îÜ i64  ‚îÜ i64      ‚îÜ   ‚îÜ i64    ‚îÜ ---           ‚îÜ str           ‚îÜ u32        ‚îÇ\n‚îÇ               ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ i64           ‚îÜ               ‚îÜ            ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ fff86e8b-795f ‚îÜ 344  ‚îÜ 163  ‚îÜ 291      ‚îÜ ‚Ä¶ ‚îÜ 819    ‚îÜ 1             ‚îÜ Canyon Towhee ‚îÜ 101        ‚îÇ\n‚îÇ -400a-91e8-56 ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ 5bbb‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ fff926d7-ccad ‚îÜ 330  ‚îÜ 180  ‚îÜ 339      ‚îÜ ‚Ä¶ ‚îÜ 956    ‚îÜ 1             ‚îÜ Rough-legged  ‚îÜ 310        ‚îÇ\n‚îÇ -4788-839e-97 ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ Hawk          ‚îÜ            ‚îÇ\n‚îÇ af2d‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ fffa33ef-a765 ‚îÜ 184  ‚îÜ 94   ‚îÜ 258      ‚îÜ ‚Ä¶ ‚îÜ 800    ‚îÜ 1             ‚îÜ Swallow-taile ‚îÜ 345        ‚îÇ\n‚îÇ -408d-8d66-6e ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ d Kite        ‚îÜ            ‚îÇ\n‚îÇ fc7f‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ ffff0d87-bc84 ‚îÜ 102  ‚îÜ 210  ‚îÜ 461      ‚îÜ ‚Ä¶ ‚îÜ 1024   ‚îÜ 0             ‚îÜ Broad-billed  ‚îÜ 77         ‚îÇ\n‚îÇ -4ef2-a47e-a4 ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ Hummingbird   ‚îÜ            ‚îÇ\n‚îÇ bfa4‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îÇ fffff3a5-2a75 ‚îÜ 281  ‚îÜ 164  ‚îÜ 524      ‚îÜ ‚Ä¶ ‚îÜ 683    ‚îÜ 0             ‚îÜ Black-throate ‚îÜ 57         ‚îÇ\n‚îÇ -47d0-887f-03 ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ d Gray        ‚îÜ            ‚îÇ\n‚îÇ 871e‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ Warbler       ‚îÜ            ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\nimport random\n\nrandom.seed(123)\nmetadata.sample()\n\n\nshape: (1, 14)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ UUID          ‚îÜ bb_x ‚îÜ bb_y ‚îÜ bb_width ‚îÜ ‚Ä¶ ‚îÜ height ‚îÜ is_training_i ‚îÜ species_name  ‚îÜ species_id ‚îÇ\n‚îÇ ---           ‚îÜ ---  ‚îÜ ---  ‚îÜ ---      ‚îÜ   ‚îÜ ---    ‚îÜ mg            ‚îÜ ---           ‚îÜ ---        ‚îÇ\n‚îÇ str           ‚îÜ i64  ‚îÜ i64  ‚îÜ i64      ‚îÜ   ‚îÜ i64    ‚îÜ ---           ‚îÜ str           ‚îÜ u32        ‚îÇ\n‚îÇ               ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ i64           ‚îÜ               ‚îÜ            ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ b20cc001-80f0 ‚îÜ 382  ‚îÜ 236  ‚îÜ 308      ‚îÜ ‚Ä¶ ‚îÜ 723    ‚îÜ 0             ‚îÜ Red-winged    ‚îÜ 300        ‚îÇ\n‚îÇ -4280-9cd5-b9 ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ Blackbird     ‚îÜ            ‚îÇ\n‚îÇ b569‚Ä¶         ‚îÜ      ‚îÜ      ‚îÜ          ‚îÜ   ‚îÜ        ‚îÜ               ‚îÜ               ‚îÜ            ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\nprint(metadata.schema)\nprint(metadata.shape)\n\nSchema({'UUID': String, 'bb_x': Int64, 'bb_y': Int64, 'bb_width': Int64, 'bb_height': Int64, 'class_id': Int64, 'subcategory': String, 'path': String, 'photographer': String, 'width': Int64, 'height': Int64, 'is_training_img': Int64, 'species_name': String, 'species_id': UInt32})\n(48562, 14)\n\n\n\nprint(metadata.glimpse())\n\nRows: 48562\nColumns: 14\n$ UUID            &lt;str&gt; '0000139e-21dc-4d0c-bfe1-4cae3c85c829', '0000d9fc-4e02-4c06-a0af-a55cfb16b12b', '00019306-9d83-4334-b255-a447742edce3', '0001afd4-99a1-4a67-b940-d419413e23b3', '000332b8-997c-4540-9647-2f0a8495aecf', '000343bd-5215-49ba-ab9c-7c97a70ac1a5', '0004ff8d-0cc8-47ee-94ba-43352a8b9eb4', '0007181f-a727-4481-ad89-591200c61b9d', '00071e20-8156-4bd8-b5ca-6445c2560ee5', '0007acfc-c0e6-4393-9ab6-02215a82ef63'\n$ bb_x            &lt;i64&gt; 83, 328, 174, 307, 395, 120, 417, 47, 260, 193\n$ bb_y            &lt;i64&gt; 59, 88, 367, 179, 139, 210, 109, 194, 146, 291\n$ bb_width        &lt;i64&gt; 128, 163, 219, 492, 262, 587, 221, 819, 578, 526\n$ bb_height       &lt;i64&gt; 228, 298, 378, 224, 390, 357, 467, 573, 516, 145\n$ class_id        &lt;i64&gt; 817, 860, 900, 645, 929, 652, 951, 900, 988, 400\n$ subcategory     &lt;str&gt; null, null, null, 'Nonbreeding/juvenile', null, 'Immature', null, null, 'Female/Immature Male', 'Adult'\n$ path            &lt;str&gt; '0817/0000139e21dc4d0cbfe14cae3c85c829.jpg', '0860/0000d9fc4e024c06a0afa55cfb16b12b.jpg', '0900/000193069d834334b255a447742edce3.jpg', '0645/0001afd499a14a67b940d419413e23b3.jpg', '0929/000332b8997c454096472f0a8495aecf.jpg', '0652/000343bd521549baab9c7c97a70ac1a5.jpg', '0951/0004ff8d0cc847ee94ba43352a8b9eb4.jpg', '0900/0007181fa7274481ad89591200c61b9d.jpg', '0988/00071e2081564bd8b5ca6445c2560ee5.jpg', '0400/0007acfcc0e643939ab602215a82ef63.jpg'\n$ photographer    &lt;str&gt; 'Ruth Cantwell', 'Christopher L. Wood Chris Wood', 'Ryan Schain', 'Laura Erickson', 'Dan Irizarry', 'Ken Schneider', 'Velma Knowles', 'Matt Tillett', 'Terry Gray', 'Cory Gregory'\n$ width           &lt;i64&gt; 296, 640, 730, 1024, 1024, 1024, 1024, 1024, 1024, 1024\n$ height          &lt;i64&gt; 341, 427, 1024, 680, 682, 768, 683, 819, 768, 681\n$ is_training_img &lt;i64&gt; 0, 0, 0, 1, 0, 0, 0, 1, 1, 0\n$ species_name    &lt;str&gt; 'Oak Titmouse', 'Ovenbird', 'Savannah Sparrow', 'Eared Grebe', 'Eastern Phoebe', 'Yellow-crowned Night-Heron', 'Florida Scrub-Jay', 'Savannah Sparrow', 'Yellow-headed Blackbird', 'Herring Gull'\n$ species_id      &lt;u32&gt; 260, 264, 322, 145, 149, 401, 158, 322, 402, 195\n\nNone\n\n\nmetadata.describe()\n\n\nshape: (9, 15)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ statistic ‚îÜ UUID      ‚îÜ bb_x      ‚îÜ bb_y      ‚îÜ ‚Ä¶ ‚îÜ height    ‚îÜ is_traini ‚îÜ species_n ‚îÜ species_ ‚îÇ\n‚îÇ ---       ‚îÜ ---       ‚îÜ ---       ‚îÜ ---       ‚îÜ   ‚îÜ ---       ‚îÜ ng_img    ‚îÜ ame       ‚îÜ id       ‚îÇ\n‚îÇ str       ‚îÜ str       ‚îÜ f64       ‚îÜ f64       ‚îÜ   ‚îÜ f64       ‚îÜ ---       ‚îÜ ---       ‚îÜ ---      ‚îÇ\n‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ f64       ‚îÜ str       ‚îÜ f64      ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ count     ‚îÜ 48562     ‚îÜ 48562.0   ‚îÜ 48562.0   ‚îÜ ‚Ä¶ ‚îÜ 48562.0   ‚îÜ 48562.0   ‚îÜ 48562     ‚îÜ 48562.0  ‚îÇ\n‚îÇ null_coun ‚îÜ 0         ‚îÜ 0.0       ‚îÜ 0.0       ‚îÜ ‚Ä¶ ‚îÜ 0.0       ‚îÜ 0.0       ‚îÜ 0         ‚îÜ 0.0      ‚îÇ\n‚îÇ t         ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n‚îÇ mean      ‚îÜ null      ‚îÜ 221.68531 ‚îÜ 158.53412 ‚îÜ ‚Ä¶ ‚îÜ 712.33555 ‚îÜ 0.492752  ‚îÜ null      ‚îÜ 204.6341 ‚îÇ\n‚îÇ           ‚îÜ           ‚îÜ           ‚îÜ 1         ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ 17       ‚îÇ\n‚îÇ std       ‚îÜ null      ‚îÜ 133.05486 ‚îÜ 80.976264 ‚îÜ ‚Ä¶ ‚îÜ 152.49441 ‚îÜ 0.499953  ‚îÜ null      ‚îÜ 116.4767 ‚îÇ\n‚îÇ           ‚îÜ           ‚îÜ 4         ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ 52       ‚îÇ\n‚îÇ min       ‚îÜ 0000139e- ‚îÜ 0.0       ‚îÜ 0.0       ‚îÜ ‚Ä¶ ‚îÜ 98.0      ‚îÜ 0.0       ‚îÜ Abert's   ‚îÜ 1.0      ‚îÇ\n‚îÇ           ‚îÜ 21dc-4d0c ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ Towhee    ‚îÜ          ‚îÇ\n‚îÇ           ‚îÜ -bfe1-4ca ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n‚îÇ           ‚îÜ e3c‚Ä¶      ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n‚îÇ 25%       ‚îÜ null      ‚îÜ 115.0     ‚îÜ 99.0      ‚îÜ ‚Ä¶ ‚îÜ 639.0     ‚îÜ 0.0       ‚îÜ null      ‚îÜ 107.0    ‚îÇ\n‚îÇ 50%       ‚îÜ null      ‚îÜ 205.0     ‚îÜ 149.0     ‚îÜ ‚Ä¶ ‚îÜ 683.0     ‚îÜ 0.0       ‚îÜ null      ‚îÜ 204.0    ‚îÇ\n‚îÇ 75%       ‚îÜ null      ‚îÜ 315.0     ‚îÜ 208.0     ‚îÜ ‚Ä¶ ‚îÜ 780.0     ‚îÜ 1.0       ‚îÜ null      ‚îÜ 303.0    ‚îÇ\n‚îÇ max       ‚îÜ fffff3a5- ‚îÜ 837.0     ‚îÜ 799.0     ‚îÜ ‚Ä¶ ‚îÜ 1024.0    ‚îÜ 1.0       ‚îÜ Yellow-th ‚îÜ 405.0    ‚îÇ\n‚îÇ           ‚îÜ 2a75-47d0 ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ roated    ‚îÜ          ‚îÇ\n‚îÇ           ‚îÜ -887f-038 ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ Warbler   ‚îÜ          ‚îÇ\n‚îÇ           ‚îÜ 71e‚Ä¶      ‚îÜ           ‚îÜ           ‚îÜ   ‚îÜ           ‚îÜ           ‚îÜ           ‚îÜ          ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Compiling the metadata"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_metadata.html#learn-about-the-data",
    "href": "ai/jxai/jxai_metadata.html#learn-about-the-data",
    "title": "Compiling the metadata",
    "section": "Learn about the data",
    "text": "Learn about the data\nNow that we have the metadata organized, let‚Äôs get to know our data:\n\nprint(f\"There are {len(metadata)} images in the dataset.\")\n\nThere are 48562 images in the dataset.\n\n\n\nmetadata_train = metadata.filter(pl.col('is_training_img') == 1)\nprint(f\"\"\"\nThere are:\n- {len(metadata_train)} images in the training set,\n- {len(metadata) - len(metadata_train)} in the validation set.\n\"\"\")\n\n\nThere are:\n- 23929 images in the training set,\n- 24633 in the validation set.\n\n\n\n\nclass_id = metadata.unique(pl.col('class_id'))\nspecies = metadata.unique(pl.col('species_id'))\nprint(f\"There are {len(class_id)} different classes and {len(species)} different species in the dataset.\")\n\nThere are 555 different classes and 405 different species in the dataset.\n\n\n\ntrain_class_id_group_length = metadata_train.group_by(pl.col('class_id')).len()\nprint(f\"\"\"\nThe number of images per class in the training set varies from {train_class_id_group_length.select(pl.min('len')).item()} to {train_class_id_group_length.select(pl.max('len')).item()},\nwith an average of {round(train_class_id_group_length.select(pl.mean('len')).item())} images per class.\n\"\"\")\n\n\nThe number of images per class in the training set varies from 4 to 60,\nwith an average of 43 images per class.\n\n\n\n\ntrain_species_group_length = metadata_train.group_by(pl.col('species_id')).len()\nprint(f\"\"\"\nThe number of images per species in the training set varies from {train_species_group_length.select(pl.min('len')).item()} to {train_species_group_length.select(pl.max('len')).item()},\nwith an average of {round(train_species_group_length.select(pl.mean('len')).item())} images per species.\n\"\"\")\n\n\nThe number of images per species in the training set varies from 6 to 221,\nwith an average of 59 images per species.\n\n\n\n\nsubcategory = metadata.unique(pl.col(\"subcategory\"))\nexample_list = subcategory.get_column('subcategory').drop_nulls().head(10).to_list()\nexample_list_cleaned = [x.replace('_', ' ') for x in example_list]\nprint(f\"\"\"\nThere are {len(subcategory)} species subcategories, such as:\n- {'\\n- '.join(example_list_cleaned)}\n- etc.\n\"\"\")\n\n\nThere are 61 species subcategories, such as:\n- Nonbreeding Adult\n- Female/Immature Male\n- Adult\n- Nonbreeding/juvenile\n- Adult Subadult\n- Female/Nonbreeding male\n- Breeding Audubon's\n- Immature/Juvenile\n- Winter/juvenile Myrtle\n- Breeding Adult\n- etc.\n\n\n\n\nprint(f\"\"\"\nThe images widths vary from {metadata.select(pl.min('width')).item()} to {metadata.select(pl.max('width')).item()}, with a mean of {round(metadata.select(pl.mean('width')).item())}\nwhile the heights vary from {metadata.select(pl.min('height')).item()} to {metadata.select(pl.max('height')).item()} with a mean of {round(metadata.select(pl.mean('height')).item())}.\n\"\"\")\n\n\nThe images widths vary from 90 to 1024, with a mean of 899\nwhile the heights vary from 98 to 1024 with a mean of 712.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Compiling the metadata"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_metadata.html#summary-metadata",
    "href": "ai/jxai/jxai_metadata.html#summary-metadata",
    "title": "Compiling the metadata",
    "section": "Summary metadata",
    "text": "Summary metadata\nLet‚Äôs summarize the info we gathered from the metadata:\n\n\n\nCategory\nValue\n\n\n\n\nImages\n48_562\n\n\nTraining images\n23_929\n\n\nValidation images\n24_633\n\n\nClasses (species with their subcategories)\n555\n\n\nSpecies\n405\n\n\nAverage number of images per class in the training set\n43\n\n\nAverage number of images per species in the training set\n59\n\n\nImages min width (px)\n90\n\n\nImages max width (px)\n1024\n\n\nImages mean width (px)\n899\n\n\nImages min height (px)\n98\n\n\nImages max height (px)\n1024\n\n\nImages mean height (px)\n712",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Compiling the metadata"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_metadata.html#save-dataframe-to-parquet",
    "href": "ai/jxai/jxai_metadata.html#save-dataframe-to-parquet",
    "title": "Compiling the metadata",
    "section": "Save DataFrame to Parquet",
    "text": "Save DataFrame to Parquet\nTo make it easier to retrieve information from the metadata later on, we can save the DataFrame to file.\nParquet is an open-source, columnar, and extremely efficient binary file format for tabular data. Unlike in CSV or JSON files, the data is compressed, making it efficient for storage space. It is also excellent for query performance. Always prefer it over text-based formats.\n\nmetadata.write_parquet('metadata.parquet')\n\nOur metadata is ready. We can now start working with the pictures.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Compiling the metadata"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_jaxstack_slides.html#section",
    "href": "ai/jxai/jxai_jaxstack_slides.html#section",
    "title": "The JAX AI stack",
    "section": "",
    "text": "High-performance accelerator-oriented array computing library for Python developed by Google\nComposition, JIT-compilation, transformation, and automatic differentiation of numerical programs\nNumPy-like and lower-level APIs\nRequires strict functional programming"
  },
  {
    "objectID": "ai/jxai/jxai_jaxstack_slides.html#fast",
    "href": "ai/jxai/jxai_jaxstack_slides.html#fast",
    "title": "The JAX AI stack",
    "section": "Fast",
    "text": "Fast\n\nDefault data type suited for deep learning\nLike PyTorch, uses float32 as default. This level of precision is suitable for deep learning and increases efficiency (by contrast, NumPy defaults to float64)\nJIT compilation\nThe same code can run on CPUs or on accelerators (GPUs and TPUs)\nXLA (Accelerated Linear Algebra) optimization\nAsynchronous dispatch\nVectorization, data parallelism, and sharding\nAll levels of shared and distributed memory parallelism are supported"
  },
  {
    "objectID": "ai/jxai/jxai_jaxstack_slides.html#great-ad",
    "href": "ai/jxai/jxai_jaxstack_slides.html#great-ad",
    "title": "The JAX AI stack",
    "section": "Great AD",
    "text": "Great AD\n\n\n\n\n\n\n\n\n\n01\n\n\nAutodiff method\n\n\n\n1\nStatic graph\nand XLA\n\n\n\n\n02\n\n\nFramework\n\n\n\n\n2\nDynamic graph\n\n\n\n1-&gt;2\n\n\n\n\n\na\n\nTensorFlow\n\n\n\n\n4\nDynamic graph\nand XLA\n\n\n\n2-&gt;4\n\n\n\n\n\nb\n\nPyTorch\n\n\n\n\n5\nPseudo-dynamic\nand XLA\n\n\n\n4-&gt;5\n\n\n\n\n\nd\n\nTensorFlow2\n\n\n\n\ne\n\nJAX\n\n\n\n\n\n03\n\n\nAdvantage\n\n\n\n\n\n7\nMostly\noptimized AD\n\n\n\n\n\n8\nConvenient\n\n\n\n\n\n9\nConvenient\n\n\n\n\n10\nConvenient and\nmostly optimized AD\n\n\n\n\n\n04\n\n\nDisadvantage\n\n\n\n\n\nA\nManual writing of IR\n\n\n\n\n\nB\nLimited AD optimization\n\n\n\n\n\nD\nDisappointing speed\n\n\n\n\nE\nPure functions only\n(subset of Python)\n\n\n\n\n\n\n\n\n\n\n\n\n\n‚ÄÉ‚ÄÉSummarized from a blog post by Chris Rackauckas"
  },
  {
    "objectID": "ai/jxai/jxai_jaxstack_slides.html#close-to-the-math",
    "href": "ai/jxai/jxai_jaxstack_slides.html#close-to-the-math",
    "title": "The JAX AI stack",
    "section": "Close to the math",
    "text": "Close to the math\nConsidering the function f:\nf = lambda x: x**3 + 2*x**2 - 3*x + 8\nWe can create a new function dfdx that computes the gradient of f w.r.t. x:\nfrom jax import grad\n\ndfdx = grad(f)\ndfdx returns the derivatives:\nprint(dfdx(1.))\n4.0"
  },
  {
    "objectID": "ai/jxai/jxai_jaxstack_slides.html#forward-and-reverse-modes",
    "href": "ai/jxai/jxai_jaxstack_slides.html#forward-and-reverse-modes",
    "title": "The JAX AI stack",
    "section": "Forward and reverse modes",
    "text": "Forward and reverse modes\n\nreverse-mode vector-Jacobian products: jax.vjp\nforward-mode Jacobian-vector products: jax.jvp"
  },
  {
    "objectID": "ai/jxai/jxai_jaxstack_slides.html#higher-order-differentiation",
    "href": "ai/jxai/jxai_jaxstack_slides.html#higher-order-differentiation",
    "title": "The JAX AI stack",
    "section": "Higher-order differentiation",
    "text": "Higher-order differentiation\nWith a single variable, the grad function calls can be nested:\nd2fdx = grad(dfdx)   # function to compute 2nd order derivatives\nd3fdx = grad(d2fdx)  # function to compute 3rd order derivatives\n...\nWith several variables, you have to use the functions:\n\njax.jacfwd for forward-mode,\njax.jacrev for reverse-mode."
  },
  {
    "objectID": "ai/jxai/jxai_jaxstack_slides.html#section-1",
    "href": "ai/jxai/jxai_jaxstack_slides.html#section-1",
    "title": "The JAX AI stack",
    "section": "",
    "text": "tracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\nTransformation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\n Transformations \n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla"
  },
  {
    "objectID": "ai/jxai/jxai_jaxstack_slides.html#section-2",
    "href": "ai/jxai/jxai_jaxstack_slides.html#section-2",
    "title": "The JAX AI stack",
    "section": "",
    "text": "tracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\n Just-in-time \n(JIT)\ncompilation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\nVectorization\nParallelization\n ¬†¬†Differentiation ¬†\n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla"
  },
  {
    "objectID": "ai/jxai/jxai_jaxstack_slides.html#section-3",
    "href": "ai/jxai/jxai_jaxstack_slides.html#section-3",
    "title": "The JAX AI stack",
    "section": "",
    "text": "tracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\njax.jit\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\njax.vmap\njax.pmap\njax.grad\n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla"
  },
  {
    "objectID": "ai/jxai/jxai_jaxstack_slides.html#jax-itself-is-not-a-deep-learning-library",
    "href": "ai/jxai/jxai_jaxstack_slides.html#jax-itself-is-not-a-deep-learning-library",
    "title": "The JAX AI stack",
    "section": "JAX itself is not a deep learning library ‚Ä¶",
    "text": "JAX itself is not a deep learning library ‚Ä¶\n\n\n\n\n\n\n\n\n\njx\n\nJAX\n\n\n\ndl\nDeep learning\n\n\n\njx-&gt;dl\n\n\n\n\n\nop\nOptimizers\n\n\n\njx-&gt;op\n\n\n\n\n\npp\nProbabilistic\nprogramming\n\n\n\njx-&gt;pp\n\n\n\n\n\npm\nProbabilistic\nmodeling\n\n\n\njx-&gt;pm\n\n\n\n\n\nll\nLLMs\n\n\n\nll-&gt;jx\n\n\n\n\n\nso\nSolvers\n\n\n\nso-&gt;jx\n\n\n\n\n\nph\nPhysics\nsimulations\n\n\n\nph-&gt;jx"
  },
  {
    "objectID": "ai/jxai/jxai_jaxstack_slides.html#but-a-python-sublanguage-ideal-for-deep-learning",
    "href": "ai/jxai/jxai_jaxstack_slides.html#but-a-python-sublanguage-ideal-for-deep-learning",
    "title": "The JAX AI stack",
    "section": "‚Ä¶ but a Python sublanguage ideal for deep learning",
    "text": "‚Ä¶ but a Python sublanguage ideal for deep learning\n\n\n\n\n\n\n\n\n\njx\n\nJAX\n\n\n\ndl\nDeep learning\n\n\n\njx-&gt;dl\n\n\n\n\n\nop\nOptimizers\n\n\n\njx-&gt;op\n\n\n\n\n\npp\nProbabilistic\nprogramming\n\n\n\njx-&gt;pp\n\n\n\n\n\npm\nProbabilistic\nmodeling\n\n\n\njx-&gt;pm\n\n\n\n\n\nll\nLLMs\n\n\n\nll-&gt;jx\n\n\n\n\n\nso\nSolvers\n\n\n\nso-&gt;jx\n\n\n\n\n\nph\nPhysics\nsimulations\n\n\n\nph-&gt;jx"
  },
  {
    "objectID": "ai/jxai/jxai_jaxstack_slides.html#modular-approach",
    "href": "ai/jxai/jxai_jaxstack_slides.html#modular-approach",
    "title": "The JAX AI stack",
    "section": "Modular approach",
    "text": "Modular approach\n\n\n\nfrom the JAX AI Stack website"
  },
  {
    "objectID": "ai/jxai/jxai_jaxstack.html",
    "href": "ai/jxai/jxai_jaxstack.html",
    "title": "The JAX AI stack",
    "section": "",
    "text": "JAX is a powerful library for Python arrays that runs the same code on any hardware (CPU, GPU, TPU), but allows efficient JIT-compilation on accelerators. It also performs composable transformations such as vectorization and automatic differentiation.\nWhile it can be used in other fields (Bayesian statistics/probabilistic programming, physics simulations, solvers‚Ä¶), it has all the characteristics required for deep learning and is heavily used for it in combination with AI-specific libraries built on top of it.\nThe JAX AI stack combines JAX with a selection of such libraries also developed by Google for easier installation and integration. It is based on a modular approach which means that any package can be replaced by whatever tool the user prefers (e.g.¬†you can use a PyTorch DataLoader, TorchVision transformations, and train your model with JAX).\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.)\nSlides content for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "The JAX stack"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_getdata.html",
    "href": "ai/jxai/jxai_getdata.html",
    "title": "Getting the data",
    "section": "",
    "text": "An important step if you want to train models on the Alliance clusters using your own dataset is to transfer it to the cluster.\nIn this section, I discuss several options.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Getting the data"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_getdata.html#download-data",
    "href": "ai/jxai/jxai_getdata.html#download-data",
    "title": "Getting the data",
    "section": "Download data",
    "text": "Download data\nThe first step is to download the data.\nIf you can use curl or wget to do so, download it directly to the cluster. That the best and simplest option.\nUnfortunately, the data source for our example does not provide a direct URL. Instead, you have to log in before ending up in a DropBox. So the only option is to download it to your own machine first, then transfer it to the cluster.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Getting the data"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_getdata.html#transfer-data-to-clusters",
    "href": "ai/jxai/jxai_getdata.html#transfer-data-to-clusters",
    "title": "Getting the data",
    "section": "Transfer data to clusters",
    "text": "Transfer data to clusters\n\nGlobus\nGlobus is by far the best method in this case. Our wiki explains how to use it on our clusters.\nAll clusters have a Globus collection name specified in the table on top of their respective wiki page.\n\nExample:\nThe wiki page for the Fir cluster lists its Globus collection name and provides a direct link: alliancecan#fir-globus.\n\nYou also need to install Globus Connect Personal on your computer to create an endpoint for your machine.\nDuring transfers, the endpoint needs to be active. On Linux, if you install the command-line version of Globus Connect Personal, the command is:\nglobusconnect -start\nOnce the transfer is complete, you receive an email similar to this one:\nTASK DETAILS\nTask ID: ce0c341d-d247-11f0-8471-0ed8a6a59ea5\nTask Type: TRANSFER\nStatus: SUCCEEDED\nSource: xxxxxxxxxxxxxxxxxxxxxxx\nDestination: computecanada#cedar-globus & alliancecan#fir-globus\nLabel: n/a\nRequest Time: 2025-12-06 02:03:49.999679 (UTC)\nCompletion Time: 2025-12-06 02:15:44.150358 (UTC)\nFiles Transfered: 48562\nDirectories Transfered: 556\nBytes Transfered: 9950162482\nEffective Speed: 13932861 Bytes per Second\nTransfer Settings:\n - verify file integrity after transfer\n - transfer is not encrypted\n - overwriting all files on destination\n\n\nAlternative methods\nIf neither direct downloads nor Globus are possible, there are other methods, although for large datasets, you might run into problems.\n\nA trick that will make any of the following commands involving the path to a remote cluster easier is to create an SSH config file as ~/.ssh/config.\n\n\n~/.ssh/config\n\nHost &lt;name-of-your-choice&gt;\n    Hostname &lt;hostname-address&gt;\n    User &lt;username&gt;\n\n\nMany additional configurations can be added to this file to create agent forwarding, persistent logins, etc.\n\nOnce you have created this file, you can use the &lt;name-of-your-choice&gt; in lieu of &lt;username&gt;@&lt;hostname-address&gt;. This makes commands a lot easier to type.\n\nExample:\n\n\n\n~/.ssh/config\n\nHost fir\n    Hostname fir.alliancecan.ca\n    User jdoe\n\nNow, you can replace jdoe@fir.alliancecan.ca in all commands by fir.\n\n\nRemote copies with scp\nSecure copy protocol (SCP) allows to copy files over the Secure Shell Protocol (SSH) with the scp utility. scp follows a syntax similar to that of the cp command.\nNote that you need to run scp from your local machines (not from the cluster as your firewall would block it).\n\nCreate a compressed archive\nBefore moving a dataset this way, create a compressed tar archive.\n\nExample:\n\ntar -zcvf nabirds.tar.gz nabirds\n\n\nCopy from your machine\n# Copy a local file to your home directory on the cluster\nscp /local/path/file &lt;username&gt;@&lt;hostname-address&gt;:\n\n\nExample:\n\nscp ~/data/nabirds.tar.gz jdoe@fir.alliancecan.ca:\nOr, if John Doe has an SSH config file on their machine:\nscp ~/data/nabirds.tar.gz fir:\n\n# Copy a local file to some path on the cluster\nscp /local/path/file &lt;username&gt;@&lt;hostname-address&gt;:/remote/path\n\n\nCopy from the cluster\nIf you need to get your transformed dataset back, you can scp a tar archive back with (still from your machine):\n# Copy a file from the cluster to some path on your machine\nscp &lt;username&gt;@&lt;hostname-address&gt;:/remote/path/file /local/path\n# Copy a file from the cluster to your current location on your machine\nscp &lt;username&gt;@&lt;hostname-address&gt;:/remote/path/file .\nYou can also use wildcards to transfer multiple files:\n# Copy all the Bash scripts from your cluster home dir to some local path\nscp &lt;username&gt;@&lt;hostname-address&gt;:*.sh /local/path\n\n\nCopying directories\nTo copy a directory, you need to add the -r (recursive) flag:\nscp -r /local/path/folder &lt;username&gt;@&lt;hostname-address&gt;:/remote/path\n\n\nCopying for Windows users\nMobaXterm users (on Windows) can copy files by dragging them between the local and remote machines in the GUI. Alternatively, they can use the download and upload buttons.\n\n\nUncompress archive\nAfter the transfer, you can uncompress your archive with:\ntar -xvzf nabirds.tar.gz\n\n\n\nInteractive transfers with sftp\nThe Secure File Transfer Protocol (SFTP) is more sophisticated and allows additional operations. The sftp command provided by OpenSSH and other packages launches an SFTP client:\nsftp &lt;username&gt;@&lt;hostname-address&gt;\n\nLook at your prompt: your usual Bash/Zsh prompt has been replaced with sftp&gt;.\n\nFrom this prompt, you can access a number of SFTP commands. Type help for a list:\nsftp&gt; help\nAvailable commands:\nbye                                Quit sftp\ncd path                            Change remote directory to 'path'\nchgrp [-h] grp path                Change group of file 'path' to 'grp'\nchmod [-h] mode path               Change permissions of file 'path' to 'mode'\nchown [-h] own path                Change owner of file 'path' to 'own'\ncopy oldpath newpath               Copy remote file\ncp oldpath newpath                 Copy remote file\ndf [-hi] [path]                    Display statistics for current directory or\n                                   filesystem containing 'path'\nexit                               Quit sftp\nget [-afpR] remote [local]         Download file\nhelp                               Display this help text\nlcd path                           Change local directory to 'path'\nlls [ls-options [path]]            Display local directory listing\nlmkdir path                        Create local directory\nln [-s] oldpath newpath            Link remote file (-s for symlink)\nlpwd                               Print local working directory\nls [-1afhlnrSt] [path]             Display remote directory listing\nlumask umask                       Set local umask to 'umask'\nmkdir path                         Create remote directory\nprogress                           Toggle display of progress meter\nput [-afpR] local [remote]         Upload file\npwd                                Display remote working directory\nquit                               Quit sftp\nreget [-fpR] remote [local]        Resume download file\nrename oldpath newpath             Rename remote file\nreput [-fpR] local [remote]        Resume upload file\nrm path                            Delete remote file\nrmdir path                         Remove remote directory\nsymlink oldpath newpath            Symlink remote file\nversion                            Show SFTP version\n!command                           Execute 'command' in local shell\n!                                  Escape to local shell\n?                                  Synonym for help\nAs this list shows, you have access to a number of classic Unix command such as cd, pwd, ls, etc. These commands will be executed on the remote machine.\nIn addition, there are a number of commands of the form l&lt;command&gt;. ‚Äúl‚Äù stands for ‚Äúlocal‚Äù.\nThese commands will be executed on your local machine.\nFor instance, ls will list the files in your current directory in the remote machine while lls (‚Äúlocal ls‚Äù) will list the files in your current directory on your computer.\nThis means that you are now able to navigate two file systems at once: your local machine and the remote machine.\n\nHere are a few examples:\n\nsftp&gt; pwd              # print remote working directory\nsftp&gt; lpwd             # print local working directory\nsftp&gt; ls               # list files in remote working directory\nsftp&gt; lls              # list files in local working directory\nsftp&gt; cd               # change the remote directory\nsftp&gt; lcd              # change the local directory\nsftp&gt; put local_file   # upload a file\nsftp&gt; get remote_file  # download a file\n\nCopying directories\nTo upload/download directories, you first need to create them in the destination, then copy the content with the -r (recursive) flag.\n\nIf you have a local directory called dir and you want to copy it to the cluster you need to run:\n\nsftp&gt; mkdir dir    # First create the directory\nsftp&gt; put -r dir   # Then copy the content\nTo terminate the session, press &lt;Ctrl+D&gt;.\n\n\n\nSyncing\nIf, instead of a single copying of the dataset between your machine and the cluster, you want to keep a directory in sync between both machines, you might want to use rsync instead. You can look at the Alliance wiki page on rsync for complete instructions.\n\n\nWindows line endings\nOn modern Mac operating systems and on Linux, lines in files are terminated with a newline (\\n). On Windows, they are terminated with a carriage return + newline (\\r\\n).\nWhen you transfer files between Windows and Linux (the cluster uses Linux), this creates a mismatch. Most modern software handle this correctly, but you may occasionally run into problems.\nThe solution is to convert a file from Windows encoding to Unix encoding with:\ndos2unix file\nTo convert a file back to Windows encoding, run:\nunix2dos file",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Getting the data"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_dataloader.html",
    "href": "ai/jxai/jxai_dataloader.html",
    "title": "DataLoaders",
    "section": "",
    "text": "A critical part of deep learning is the loading of data to the model during the training loops.\nDataLoaders handle the choice of which sample to load and in what order; they optimize the process in parallel by managing workers; they set several hyperparameters such as batch size and number of epochs.\nIn this section we explore DataLoaders with the Grain library [1].",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "DataLoaders"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_dataloader.html#goal-of-dataloaders",
    "href": "ai/jxai/jxai_dataloader.html#goal-of-dataloaders",
    "title": "DataLoaders",
    "section": "Goal of DataLoaders",
    "text": "Goal of DataLoaders\nWe can access elements of our Dataset class (as we did in the previous section) with:\n\nfor i, element in enumerate(nabirds_train):\n    print(element['img'].shape)\n    if i == 3:\n        break\n\n(269, 269, 3)\n(269, 269, 3)\n(269, 269, 3)\n(269, 269, 3)\n\n\nAnd we can return the next object by creating an iterator from of iterable dataset:\n\nnext(iter(nabirds_train))\n\n{'img': array([[[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n \n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n \n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n \n        ...,\n \n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n \n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n \n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]]], shape=(269, 269, 3), dtype=uint8),\n 'species_name': 'Eared Grebe',\n 'species_id': 145,\n 'photographer': 'Laura Erickson'}\n\n\n\nWe are getting all these 0 because we padded the images with black.\n\nBut all this is extremely limited.\nDataLoaders feed data to the model during training. They handle batching, shuffling, sharding across machines, the number of epochs, etc. All things that would be very inconvenient to implement from scratch.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "DataLoaders"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_dataloader.html#grain-dataloaders",
    "href": "ai/jxai/jxai_dataloader.html#grain-dataloaders",
    "title": "DataLoaders",
    "section": "Grain DataLoaders",
    "text": "Grain DataLoaders\nThe JAX AI stack includes the Grain library [1] to create DataLoaders, but it can also be done using PyTorch, TensorFlow Datasets, Hugging Face Datasets, or any method you are used to. That‚Äôs the advantage of the modular philosophy that the stack relies on. Grain is extremely efficient and does not rely on a huge set of dependencies as PyTorch and TensorFlow do.\nIn Grain, a DataLoader requires 3 components:\n\nA data source\nTransforms\nA sampler",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "DataLoaders"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_dataloader.html#data-source",
    "href": "ai/jxai/jxai_dataloader.html#data-source",
    "title": "DataLoaders",
    "section": "Data source",
    "text": "Data source\nWe already have that: our data sources are our instances of Dataset class nabirds_train and nabirds_val for training and validation respectively.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "DataLoaders"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_dataloader.html#transformations",
    "href": "ai/jxai/jxai_dataloader.html#transformations",
    "title": "DataLoaders",
    "section": "Transformations",
    "text": "Transformations\nWe need to split the data into batches. Batches can be defined with the grain.Batch method as a DataLoader transformation.\nLet‚Äôs use batches of 32 with grain.Batch(batch_size=32).\n\n\n\n\n\n\nNoteHow to choose the batch size?\n\n\n\n\n\nThe batch size is a crucial hyperparameter: it impacts your training speed, model stability, and final accuracy.\n\nDefault strategy\nIf you are unsure where to start, use a batch size of 32.\n32 is small enough to provide a regularizing effect (helping the model generalize) but large enough to benefit from parallel processing on GPUs.\n\n\nStandard values\nAlways use powers of 2 (32, 64, 128, 256) because GPUs and CPUs are optimized for binary operations, and this aligns memory allocation efficiently.\n\n\n\n\n\n\n\n\n\nSmall batch size\nLarge batch size\n\n\n\n\nTraining speed\nSlower: less efficient use of GPU\nFaster: maximizes GPU throughput\n\n\nGeneralization\nBetter: the ‚Äúnoise‚Äù in the gradient helps the model escape sharp local minima\nWorse: can lead to overfitting\n\n\nConvergence\nNoisy training curve: loss fluctuates\nSmoother training curve: stable descent\n\n\nMemory usage\nLow: good for limited VRAM\nHigh: risk of OOM\n\n\n\n\n\nTuning the batch size\n\nCeiling\nYour maximum batch size is dictated by your GPU memory (VRAM).\nIf you hit an out of memory (OOM) error, you need to back down to the the previous successful power of 2 (this is your hardware maximum).\n\n\nPerformance\nJust because you can fit a batch size of 4096 doesn‚Äôt mean you should.\nIf training is stable but slow, double to 64, then double again to 128. You can increase the batch size to the hardware maximum to speed up epochs.\nIf the model overfits or diverges, try reducing the batch size. The ‚Äúnoisy‚Äù updates act like regularization, preventing the model from memorizing the data too perfectly.\n\n\n\nAdvanced techniques\n\nGradient accumulation:\n\nIf you need a batch size of 64 for stability but your GPU only fits 16, you can use gradient accumulation. You process 4 mini-batches of 16, accumulate the gradients, and update the weights once. This mathematically simulates a batch size of 64.\n\nDynamic batching:\n\nSome advanced training regimes start with a small batch size to stabilize early training and increase it over time to speed up convergence (similar to learning rate decay).\n\n\nLearning rate\nIf you change your batch size significantly, you should adjust your learning rate.\nA rule that works well until you get to very large batch sizes is to double the learning rate when you double the batch size.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "DataLoaders"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_dataloader.html#samplers",
    "href": "ai/jxai/jxai_dataloader.html#samplers",
    "title": "DataLoaders",
    "section": "Samplers",
    "text": "Samplers\nThere are 2 types of Grain samplers: sequential and index samplers.\n\nSequential sampler\nGrain comes with a basic sequential sampler.\n\nimport grain.python as grain\n\nnabirds_train_seqsampler = grain.SequentialSampler(\n    num_records=4\n)\n\nfor record_metadata in nabirds_train_seqsampler:\n    print(record_metadata)\n\nRecordMetadata(index=0, record_key=0, rng=None)\nRecordMetadata(index=1, record_key=1, rng=None)\nRecordMetadata(index=2, record_key=2, rng=None)\nRecordMetadata(index=3, record_key=3, rng=None)\n\n\n\n\nIndex sampler\nGrain index sampler is the one you should use as it allows for global shuffling of the dataset, setting the number of epochs, etc.\n\nnabirds_train_isampler = grain.IndexSampler(\n    num_records=200,\n    shuffle=True,\n    seed=0\n)\n\nfor i, record_metadata in enumerate(nabirds_train_isampler):\n  print(record_metadata)\n  if i == 3:\n      break\n\nRecordMetadata(index=0, record_key=134, rng=Generator(Philox))\nRecordMetadata(index=1, record_key=133, rng=Generator(Philox))\nRecordMetadata(index=2, record_key=10, rng=Generator(Philox))\nRecordMetadata(index=3, record_key=136, rng=Generator(Philox))",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "DataLoaders"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_dataloader.html#lets-experiment-with-dataloaders",
    "href": "ai/jxai/jxai_dataloader.html#lets-experiment-with-dataloaders",
    "title": "DataLoaders",
    "section": "Let‚Äôs experiment with DataLoaders",
    "text": "Let‚Äôs experiment with DataLoaders\n\nWith sequential sampler\n\nnabirds_train_dl = grain.DataLoader(\n    data_source=nabirds_train,\n    sampler=nabirds_train_seqsampler,\n    worker_count=0\n)\n\nWe can plot images in this sequential DataLoader:\n\nimport matplotlib.pyplot as plt\n\nfig = plt.figure(figsize=(8, 9))\n\nfor i, element in enumerate(nabirds_train_dl):\n    ax = plt.subplot(2, 2, i + 1)\n    plt.tight_layout()\n    ax.set_title(\n        f\"\"\"\n        {element['species_name']}\n        Picture by {element['photographer']}\n        \"\"\",\n        fontsize=9,\n        linespacing=1.5\n    )\n    ax.axis('off')\n    plt.imshow(element['img'])\n\nplt.show()\n\n\n\n\n\n\n\n\n\nNotice that, unlike last time we displayed some images, we aren‚Äôt looping through our Dataset (nabirds_train) anymore, but through our DataLoader (nabirds_train_dl).\nBecause we set the number of records to 4 in the sampler, we don‚Äôt have to break the loop.\n\n\n\nWith index sampler\n\nnabirds_train_dl = grain.DataLoader(\n    data_source=nabirds_train,\n    sampler=nabirds_train_isampler,\n    worker_count=0\n)\n\nLet‚Äôs plot these as well:\n\nfig = plt.figure(figsize=(8, 9))\n\nfor i, element in enumerate(nabirds_train_dl):\n    ax = plt.subplot(2, 2, i + 1)\n    plt.tight_layout()\n    ax.set_title(\n        f\"\"\"\n        {element['species_name']}\n        Picture by {element['photographer']}\n        \"\"\",\n        fontsize=9,\n        linespacing=1.5\n    )\n    ax.axis('off')\n    plt.imshow(element['img'])\n    if i == 3:\n        plt.show()\n        break\n\n\n\n\n\n\n\n\n\n\nAdding batch sizes\nYou can add the batch size in the operations argument of grain.DataLoader:\n\nnabirds_train_dl = grain.DataLoader(\n    data_source=nabirds_train,\n    sampler=nabirds_train_isampler,\n    worker_count=0,\n    operations=[\n        grain.Batch(batch_size=32)\n    ]\n)\n\nNow we can access the next batch with:\n\nnext(iter(nabirds_train_dl))\n\n{'img': array([[[[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         ...,\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]]],\n \n \n        [[[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         ...,\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]]],\n \n \n        [[[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         ...,\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]]],\n \n \n        ...,\n \n \n        [[[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         ...,\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]]],\n \n \n        [[[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         ...,\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]],\n \n         [[ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          ...,\n          [ 0,  0,  0],\n          [ 0,  0,  0],\n          [ 0,  0,  0]]],\n \n \n        [[[ 4,  0,  0],\n          [ 8,  2,  4],\n          [11,  7,  8],\n          ...,\n          [ 0,  0,  7],\n          [ 1,  0,  8],\n          [ 2,  1,  9]],\n \n         [[ 4,  0,  0],\n          [ 6,  0,  0],\n          [ 5,  1,  0],\n          ...,\n          [ 0,  0,  2],\n          [ 0,  0,  2],\n          [ 0,  0,  2]],\n \n         [[ 7,  2,  0],\n          [ 4,  0,  0],\n          [ 3,  0,  0],\n          ...,\n          [ 1,  4,  0],\n          [ 1,  4,  0],\n          [ 1,  5,  0]],\n \n         ...,\n \n         [[ 0,  2,  0],\n          [ 0,  2,  0],\n          [ 0,  2,  0],\n          ...,\n          [ 0,  5,  0],\n          [ 0,  6,  0],\n          [ 0,  6,  0]],\n \n         [[ 0,  4,  3],\n          [ 0,  5,  1],\n          [ 0,  4,  3],\n          ...,\n          [ 2,  2,  4],\n          [ 1,  3,  2],\n          [ 2,  2,  0]],\n \n         [[ 0,  1,  2],\n          [ 0,  1,  0],\n          [ 0,  0,  2],\n          ...,\n          [ 1,  0,  9],\n          [ 0,  0,  7],\n          [ 1,  0,  7]]]], shape=(32, 269, 269, 3), dtype=uint8),\n 'photographer': array(['Jerry Ting', 'Jerry Ting', 'Robert Steffens', 'Dave Sanders',\n        'Jon Isacoff', 'Bob Gunderson', 'Joe Turner', 'Lois Manowitz',\n        'Ken Schneider', 'Phil Jeffrey', 'Ken Schneider', 'Laura Erickson',\n        'Tripp Davenport', 'Ned Harris',\n        'Stephen Ramirez www.birdsiview.org', 'Terry Gray', 'Jason Daly',\n        'Laura Erickson', 'Christopher Ciccone', 'Ned Harris',\n        'Ruth Sullivan', 'Allan Claybon', 'Ken Schneider', 'Nancy Landry',\n        'Muriel Neddermeyer', 'Conrad Tan', 'Tripp Davenport',\n        'Bill Schmoker', 'Chris Cochems', 'Terry Gray', 'Davor Desancic',\n        'Terry Gray'], dtype='&lt;U34'),\n 'species_id': array([367,  22, 202, 105, 207, 134,  65, 359, 156, 112, 236, 269,  24,\n        384, 347, 276, 142, 145, 339, 231,  28, 228,  22,  17, 316, 350,\n         87, 370, 267, 252, 384, 295]),\n 'species_name': array(['Western Kingbird', 'Bald Eagle', 'House Finch', 'Carolina Wren',\n        'Indigo Bunting', 'Common Yellowthroat', 'Blue-winged Teal ',\n        'Verdin', 'Field Sparrow', 'Cedar Waxwing', 'Mottled Duck',\n        'Palm Warbler', 'Band-tailed Pigeon', 'White-winged Dove',\n        'Tennessee Warbler', 'Pine Grosbeak', 'Double-crested Cormorant',\n        'Eared Grebe', \"Steller's Jay\", 'Merlin', 'Barred Owl', 'Mallard',\n        'Bald Eagle', 'American Wigeon', 'Ruffed Grouse', 'Tree Swallow',\n        'Bufflehead', 'Western Screech-Owl', 'Pacific-slope Flycatcher',\n        'Northern Pygmy-Owl', 'White-winged Dove', 'Red-naped Sapsucker'],\n       dtype='&lt;U24')}",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "DataLoaders"
    ]
  },
  {
    "objectID": "ai/jxai/gemini_chat.html",
    "href": "ai/jxai/gemini_chat.html",
    "title": "Research Computing",
    "section": "",
    "text": "Using PIX (dm-pix) with Grain requires bridging two different paradigms: Grain uses NumPy/Python on the CPU for loading, while PIX is designed for JAX on accelerators (GPU/TPU).\nYou have two main options to integrate them. Option 1 (Best Practice) is to apply PIX after the dataloader yields a batch, leveraging JAX‚Äôs speed. Option 2 is to apply PIX inside the Grain pipeline, which is useful if you need to augment images before batching (e.g., for variable-size images).\n\n\nThis method is fastest. Use Grain to load and batch clean NumPy arrays, then use jax.vmap and jax.jit to apply PIX transformations on the GPU/TPU.\nimport grain.python as grain\nimport dm_pix as pix\nimport jax\nimport jax.numpy as jnp\nimport numpy as np\n\n# 1. Define your augmentation function (runs on GPU/TPU)\ndef augment_batch(batch, rng_key):\n    # Split rng key for different operations\n    rng1, rng2 = jax.random.split(rng_key)\n    \n    images = batch['image']\n    \n    # Example: Random flip and brightness\n    # PIX functions expect (H, W, C), so we use vmap to handle (Batch, H, W, C)\n    images = jax.vmap(pix.flip_left_right)(images)\n    images = jax.vmap(lambda i, k: pix.random_brightness(k, i, max_delta=0.2))(images, jax.random.split(rng1, images.shape[0]))\n    \n    return {**batch, 'image': images}\n\n# JIT compile the augmentation for maximum speed\naugment_batch_jit = jax.jit(augment_batch)\n\n# 2. Setup standard Grain loader (loads NumPy arrays)\n# Assume 'source' is your DataSource\nloader = grain.DataLoader(\n    data_source=source,\n    sampler=grain.IndexSampler(\n        num_records=len(source),\n        shard_options=grain.ShardOptions(shard_count=1, shard_index=0),\n        shuffle=True,\n        seed=42\n    ),\n    operations=[\n        grain.Batch(batch_size=32), # Batching happens here\n    ]\n)\n\n# 3. Training Loop\nrng = jax.random.key(0)\n\nfor batch in loader:\n    # Split RNG for this step\n    rng, step_rng = jax.random.split(rng)\n    \n    # Move data to device (GPU/TPU)\n    # Note: Grain yields numpy arrays, so we convert them to JAX arrays here\n    batch_jax = jax.tree.map(jnp.array, batch)\n    \n    # Apply augmentations on device\n    augmented_batch = augment_batch_jit(batch_jax, step_rng)\n    \n    # ... proceed to model training ...\n\n\n\nIf you must augment before batching (e.g., cropping high-res images to a smaller fixed size), you can use grain.RandomMapTransform.\nCritical Detail: Grain provides a NumPy rng (generator), but PIX needs a JAX PRNGKey. You must convert the seed manually.\nimport grain.python as grain\nimport dm_pix as pix\nimport jax\nimport numpy as np\n\nclass PixAugmentation(grain.RandomMapTransform):\n    def random_map(self, element, rng: np.random.Generator):\n        # 1. Convert Grain's Numpy RNG to a JAX PRNGKey\n        # We generate a large integer seed from the Numpy generator\n        seed = rng.integers(0, 2**32 - 1)\n        jax_key = jax.random.key(seed)\n        \n        image = element['image'] # Expecting numpy array\n        \n        # 2. Apply PIX transformations\n        # Note: PIX accepts numpy arrays but converts them to JAX arrays internally.\n        # This runs on CPU because Grain workers are CPU processes.\n        \n        # Random Crop example\n        # PIX random functions need a key\n        key1, key2 = jax.random.split(jax_key)\n        \n        image = pix.random_crop(\n            key=key1,\n            image=image,\n            crop_sizes=(224, 224, 3)\n        )\n        \n        image = pix.random_flip_left_right(\n            key=key2,\n            image=image\n        )\n        \n        # 3. Return as numpy array (Grain expects standard Python/Numpy types)\n        return {**element, 'image': np.array(image)}\n\n# Usage in loader\nloader = grain.DataLoader(\n    data_source=source,\n    sampler=grain.IndexSampler(...),\n    operations=[\n        PixAugmentation(), # Apply per-item augmentation\n        grain.Batch(batch_size=32)\n    ]\n)\n\n\n\n\n\n\n\n\n\n\n\nFeature\nOption 1 (On-Device)\nOption 2 (In-Loader)\n\n\n\n\nExecution\nGPU / TPU\nCPU (Multiprocessing)\n\n\nSpeed\nExtremely Fast (Vectorized)\nSlower (CPU bound)\n\n\nBatching\nAugments entire batch at once\nAugments one image at a time\n\n\nUse Case\nColor jitters, standard resizing, flips\nVariable size inputs -&gt; Fixed size"
  },
  {
    "objectID": "ai/jxai/gemini_chat.html#how-to-use-pix-with-grain",
    "href": "ai/jxai/gemini_chat.html#how-to-use-pix-with-grain",
    "title": "Research Computing",
    "section": "",
    "text": "Using PIX (dm-pix) with Grain requires bridging two different paradigms: Grain uses NumPy/Python on the CPU for loading, while PIX is designed for JAX on accelerators (GPU/TPU).\nYou have two main options to integrate them. Option 1 (Best Practice) is to apply PIX after the dataloader yields a batch, leveraging JAX‚Äôs speed. Option 2 is to apply PIX inside the Grain pipeline, which is useful if you need to augment images before batching (e.g., for variable-size images).\n\n\nThis method is fastest. Use Grain to load and batch clean NumPy arrays, then use jax.vmap and jax.jit to apply PIX transformations on the GPU/TPU.\nimport grain.python as grain\nimport dm_pix as pix\nimport jax\nimport jax.numpy as jnp\nimport numpy as np\n\n# 1. Define your augmentation function (runs on GPU/TPU)\ndef augment_batch(batch, rng_key):\n    # Split rng key for different operations\n    rng1, rng2 = jax.random.split(rng_key)\n    \n    images = batch['image']\n    \n    # Example: Random flip and brightness\n    # PIX functions expect (H, W, C), so we use vmap to handle (Batch, H, W, C)\n    images = jax.vmap(pix.flip_left_right)(images)\n    images = jax.vmap(lambda i, k: pix.random_brightness(k, i, max_delta=0.2))(images, jax.random.split(rng1, images.shape[0]))\n    \n    return {**batch, 'image': images}\n\n# JIT compile the augmentation for maximum speed\naugment_batch_jit = jax.jit(augment_batch)\n\n# 2. Setup standard Grain loader (loads NumPy arrays)\n# Assume 'source' is your DataSource\nloader = grain.DataLoader(\n    data_source=source,\n    sampler=grain.IndexSampler(\n        num_records=len(source),\n        shard_options=grain.ShardOptions(shard_count=1, shard_index=0),\n        shuffle=True,\n        seed=42\n    ),\n    operations=[\n        grain.Batch(batch_size=32), # Batching happens here\n    ]\n)\n\n# 3. Training Loop\nrng = jax.random.key(0)\n\nfor batch in loader:\n    # Split RNG for this step\n    rng, step_rng = jax.random.split(rng)\n    \n    # Move data to device (GPU/TPU)\n    # Note: Grain yields numpy arrays, so we convert them to JAX arrays here\n    batch_jax = jax.tree.map(jnp.array, batch)\n    \n    # Apply augmentations on device\n    augmented_batch = augment_batch_jit(batch_jax, step_rng)\n    \n    # ... proceed to model training ...\n\n\n\nIf you must augment before batching (e.g., cropping high-res images to a smaller fixed size), you can use grain.RandomMapTransform.\nCritical Detail: Grain provides a NumPy rng (generator), but PIX needs a JAX PRNGKey. You must convert the seed manually.\nimport grain.python as grain\nimport dm_pix as pix\nimport jax\nimport numpy as np\n\nclass PixAugmentation(grain.RandomMapTransform):\n    def random_map(self, element, rng: np.random.Generator):\n        # 1. Convert Grain's Numpy RNG to a JAX PRNGKey\n        # We generate a large integer seed from the Numpy generator\n        seed = rng.integers(0, 2**32 - 1)\n        jax_key = jax.random.key(seed)\n        \n        image = element['image'] # Expecting numpy array\n        \n        # 2. Apply PIX transformations\n        # Note: PIX accepts numpy arrays but converts them to JAX arrays internally.\n        # This runs on CPU because Grain workers are CPU processes.\n        \n        # Random Crop example\n        # PIX random functions need a key\n        key1, key2 = jax.random.split(jax_key)\n        \n        image = pix.random_crop(\n            key=key1,\n            image=image,\n            crop_sizes=(224, 224, 3)\n        )\n        \n        image = pix.random_flip_left_right(\n            key=key2,\n            image=image\n        )\n        \n        # 3. Return as numpy array (Grain expects standard Python/Numpy types)\n        return {**element, 'image': np.array(image)}\n\n# Usage in loader\nloader = grain.DataLoader(\n    data_source=source,\n    sampler=grain.IndexSampler(...),\n    operations=[\n        PixAugmentation(), # Apply per-item augmentation\n        grain.Batch(batch_size=32)\n    ]\n)\n\n\n\n\n\n\n\n\n\n\n\nFeature\nOption 1 (On-Device)\nOption 2 (In-Loader)\n\n\n\n\nExecution\nGPU / TPU\nCPU (Multiprocessing)\n\n\nSpeed\nExtremely Fast (Vectorized)\nSlower (CPU bound)\n\n\nBatching\nAugments entire batch at once\nAugments one image at a time\n\n\nUse Case\nColor jitters, standard resizing, flips\nVariable size inputs -&gt; Fixed size"
  },
  {
    "objectID": "ai/jxai/gemini_chat.html#is-grain-really-cpu-only",
    "href": "ai/jxai/gemini_chat.html#is-grain-really-cpu-only",
    "title": "Research Computing",
    "section": "Is Grain really CPU only?",
    "text": "Is Grain really CPU only?\nUse of the documentation you provided is appreciated. However, looking closely at the code in that tutorial, it actually confirms that Grain runs on the CPU and explicitly transfers data to the GPU afterwards.\nIn the ‚ÄúLoading Data with Grain‚Äù section of your link, the training loop explicitly calls:\nx, y = device_put(x), device_put(y)\nThis demonstrates the standard workflow: Grain (CPU) ‚Üí RAM ‚Üí device_put ‚Üí GPU.\nBecause Grain workers are Python multiprocessing processes (which run on the CPU), using PIX inside the Grain pipeline forces JAX to run on the CPU. This is significantly slower than using standard libraries like OpenCV or Pillow.\nThe recommendation remains the same, but here is the clarified context based on your link:\n\nBest Practice: Augment After device_put (On-Device)\nSince your goal with PIX is to leverage JAX‚Äôs speed on the GPU/TPU, you should apply PIX transformations after the data has left the Grain loader and arrived on the device.\n\nGrain (CPU): Loads clean, raw images (using Pillow/OpenCV). Batches them.\nTransfer: You move the batch to GPU (e.g., jax.device_put or implicitly via jit).\nPIX (GPU): You apply the augmentations inside your training step (jit-compiled).\n\n# 1. Grain Loader (Runs on CPU)\nloader = grain.DataLoader(\n    data_source=source,\n    operations=[grain.Batch(batch_size=32)] \n)\n\n# 2. Augmentation Function (Runs on GPU via JIT)\n@jax.jit\ndef augment_and_train(state, batch, key):\n    images = batch['image']\n    \n    # Split key for PIX\n    key, subkey = jax.random.split(key)\n    \n    # PIX runs blindingly fast here because it's vectorized on the GPU\n    images = jax.vmap(pix.flip_left_right)(images)\n    images = jax.vmap(lambda i, k: pix.random_brightness(k, i, max_delta=0.2))(\n        images, jax.random.split(subkey, images.shape[0])\n    )\n    \n    # ... rest of your training step ...\n    return state, key\n\n# 3. Loop\nfor batch in loader:\n    # Data is moved to GPU here (implicitly or explicitly)\n    state, key = augment_and_train(state, batch, key)\n\n\nWhy not use PIX inside grain.DataLoader?\nIf you put PIX inside a grain.MapTransform, it executes inside a CPU worker process. * Performance Hit: JAX is optimized for accelerators. Running JAX image ops on a CPU one-by-one is often slower than using Pillow or OpenCV. * Resource Conflict: JAX pre-allocates memory. Spawning multiple Grain workers that all try to initialize JAX can lead to memory contention or crashes (OOM) unless you carefully manage JAX_PLATFORMS=cpu.\nSummary: Grain handles the ‚Äúfeed‚Äù (CPU), and PIX handles the ‚Äúchew‚Äù (GPU). Keep them separate for maximum performance."
  },
  {
    "objectID": "ai/jxai/gemini_chat.html#should-i-save-the-cleaned-images-to-file",
    "href": "ai/jxai/gemini_chat.html#should-i-save-the-cleaned-images-to-file",
    "title": "Research Computing",
    "section": "Should I save the cleaned images to file?",
    "text": "Should I save the cleaned images to file?\nYes, it would be significantly faster to save the cleaned (cropped and resized) images to files as a separate step.\nHere is the breakdown of why your current approach is likely creating a bottleneck and how to fix it.\n\nWhy your current approach is slow\n\nRepeated Deterministic Work: Your BbCrop and PaddingResize operations are deterministic (the result is always the same for a specific image). Currently, you are forcing the CPU to re-calculate the crop and the expensive skimage.resize (which involves convolutions) for every single image, in every single epoch.\nI/O Inefficiency: You are likely loading large original images (e.g., 1920x1080) just to shrink them down to 224x224. This wastes disk bandwidth reading unnecessary pixels.\nMultiprocessing Overhead (Float32): In NormAndCast, you convert images to float32. A 224x224x3 image in uint8 is ~150KB. In float32, it is ~600KB. Grain uses multiprocessing; moving larger float32 data between worker processes and the main process is 4x slower than moving uint8.\nJAX in CPU Workers: You are using jnp.array inside NormAndCast. Since Grain workers run on the CPU, this initializes JAX on the CPU inside every worker process. This is not only slower than NumPy for simple element-wise division but can cause memory contention issues.\n\n\n\nThe Recommended Workflow\nYou should split your pipeline into two stages: Offline Pre-processing and Training.\n\nStep 1: Offline Pre-processing (Run this once)\nWrite a script that iterates through your dataset and performs the deterministic steps: Crop and Resize. * Save the output as standard image files (PNG or JPG) or .npy files. * Crucial: Save them as uint8 (0-255), not float32.\n# Pseudo-code for a cleaning script\nimport numpy as np\nfrom skimage.io import imread, imsave\nfrom skimage.transform import resize\n\n# Define your logic here (using standard Numpy, not JAX)\ndef process_and_save(image_path, bbox, save_path):\n    img = imread(image_path)\n    \n    # 1. Crop (BbCrop logic)\n    img_cropped = img[bbox.y:bbox.y+bbox.h, bbox.x:bbox.x+bbox.w]\n    \n    # 2. Resize with Padding (PaddingResize logic)\n    # ... (Your resize logic) ...\n    # Ensure output is uint8 to save space\n    img_final = (resized_img_float * 255).astype(np.uint8)\n    \n    # 3. Save\n    imsave(save_path, img_final)\n\n\nStep 2: Optimized Training Pipeline\nNow your Grain loader only needs to read small, pre-cropped files. This changes your transforms significantly.\nRemove BbCrop and PaddingResize from Grain. Move NormAndCast to the GPU (after batching).\n# 1. Grain Loader (Runs on CPU)\n# Only responsible for I/O and Batching\nloader = grain.DataLoader(\n    data_source=cleaned_source, # Points to your pre-processed files\n    operations=[\n        grain.Batch(batch_size=32) \n        # Note: No map transforms needed if data is pre-saved!\n    ]\n)\n\n# 2. GPU Step (JAX)\n@jax.jit\ndef train_step(state, batch):\n    # a. Move to GPU (implicitly done when passing to JIT)\n    images = batch['image']\n    \n    # b. Normalize and Cast (Done on GPU = Blazing Fast)\n    # This replaces your 'NormAndCast' Grain transform\n    images = images.astype(jnp.float32) / 255.0\n    \n    # c. Augmentation (PIX)\n    # Apply random things that change every epoch\n    images = jax.vmap(pix.flip_left_right)(images)\n    \n    # ... model training ...\n\n\n\nSummary of Wins\n\nStorage Read Speed: Reading a 224x224 file is instant compared to reading a full-res image.\nCPU Load: You eliminate the heavy resize math during training, freeing up the CPU to just feed data.\nThroughput: Your GPU will no longer wait for the CPU to finish resizing images."
  },
  {
    "objectID": "ai/jxai/gemini_chat.html#shouldnt-i-use-a-class-rather-than-a-for-loop",
    "href": "ai/jxai/gemini_chat.html#shouldnt-i-use-a-class-rather-than-a-for-loop",
    "title": "Research Computing",
    "section": "Shouldn‚Äôt I use a class rather than a for loop?",
    "text": "Shouldn‚Äôt I use a class rather than a for loop?\nYes, your intuition is correct. Creating a simple Dataset class is much cleaner and easier to manage than writing a raw loop over a DataFrame. It encapsulates all the ‚Äúmessy‚Äù logic (paths, cropping math, resizing) in one place.\nSince this is an offline cleaning step (running once to save files to disk), you don‚Äôt even need to use Grain or PyTorch. You can use a standard Python class and multiprocessing to make it fly.\nHere is the best way to structure this.\n\n1. The CleaningDataset Class\nThis class handles one single job: ‚ÄúGive me an index, and I will give you the cleaned image and where to save it.‚Äù\nimport os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom skimage.transform import resize\n\nclass CleaningDataset:\n    def __init__(self, df, source_dir, target_dir, target_size=(224, 224)):\n        self.df = df\n        self.source_dir = source_dir\n        self.target_dir = target_dir\n        self.target_size = target_size\n        \n        # Create target directory if it doesn't exist\n        os.makedirs(self.target_dir, exist_ok=True)\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        \"\"\"Returns (processed_image_array, save_path)\"\"\"\n        row = self.df.iloc[idx]\n        \n        # 1. Build Paths\n        # Assuming your DF has a column 'filename'\n        filename = row['filename'] \n        img_path = os.path.join(self.source_dir, filename)\n        save_path = os.path.join(self.target_dir, filename)\n        \n        # 2. Load Image (Use PIL or skimage)\n        try:\n            # converting to RGB prevents issues with Alpha channels or Grayscale\n            img = np.array(Image.open(img_path).convert('RGB'))\n        except Exception as e:\n            print(f\"Error loading {filename}: {e}\")\n            return None, None\n\n        # 3. Crop (BbCrop Logic)\n        bbx, bby = int(row['bbx']), int(row['bby'])\n        bbw, bbh = int(row['bbwidth']), int(row['bbheight'])\n        \n        # Safety check for bounds\n        img_cropped = img[bby:bby+bbh, bbx:bbx+bbw]\n        \n        # Handle cases where crop is empty (bad bbox data)\n        if img_cropped.size == 0:\n            return None, None\n\n        # 4. Resize with Padding (Your logic)\n        h, w, _ = img_cropped.shape\n        target_h, target_w = self.target_size\n        scale = min(target_h / h, target_w / w)\n        new_h, new_w = int(h * scale), int(w * scale)\n        \n        # Resize\n        resized = resize(img_cropped, (new_h, new_w), anti_aliasing=True)\n        \n        # Pad\n        out_img = np.zeros((target_h, target_w, 3), dtype=resized.dtype)\n        y_off = (target_h - new_h) // 2\n        x_off = (target_w - new_w) // 2\n        out_img[y_off:y_off+new_h, x_off:x_off+new_w] = resized\n        \n        # Convert back to uint8 (0-255) for saving! \n        # skimage returns float (0-1), but we want to save space on disk\n        final_img = (out_img * 255).astype(np.uint8)\n        \n        return final_img, save_path\n\n\n2. The Execution (Make it Fast)\nSince you are resizing images, this is CPU bound. If you just use a for loop, it will run on a single core. To speed this up by 8x-16x, use multiprocessing.\nHere is the script to run the dataset:\nfrom tqdm import tqdm\nfrom concurrent.futures import ProcessPoolExecutor\n\n# Setup\ndataset = CleaningDataset(\n    df=my_dataframe,\n    source_dir=\"./raw_images\",\n    target_dir=\"./cleaned_images\"\n)\n\ndef process_idx(i):\n    \"\"\"Helper function for the parallel worker\"\"\"\n    img, path = dataset[i]\n    if img is not None:\n        # Save using PIL for easy compression control\n        Image.fromarray(img).save(path, quality=95)\n        return 1 # Success\n    return 0 # Failure\n\n# Run in Parallel\nif __name__ == \"__main__\":\n    # Use as many workers as you have CPU cores\n    with ProcessPoolExecutor() as executor:\n        # Map indices to the process function\n        results = list(tqdm(\n            executor.map(process_idx, range(len(dataset))), \n            total=len(dataset),\n            desc=\"Cleaning Images\"\n        ))\n        \n    print(f\"Done! Processed {sum(results)} images.\")\n\n\nWhy this is better than your previous approach:\n\nIsolation: If your resizing logic changes, you edit one place (__getitem__).\nSpeed: The ProcessPoolExecutor allows you to process 8, 16, or 32 images simultaneously (depending on your CPU cores), which is massive for image resizing.\nMemory: It processes one image, saves it, and dumps the memory. It never holds the whole dataset in RAM."
  },
  {
    "objectID": "ai/jxai/gemini_chat.html#should-i-use-to-torchvision-then-since-grain-only-works-on-cpu",
    "href": "ai/jxai/gemini_chat.html#should-i-use-to-torchvision-then-since-grain-only-works-on-cpu",
    "title": "Research Computing",
    "section": "Should I use to TorchVision then since Grain only works on CPU?",
    "text": "Should I use to TorchVision then since Grain only works on CPU?\nThe short answer is no. You should not switch to TorchVision for this specific task.\nUsing TorchVision would likely make your offline cleaning step slower and your training setup more complicated (since you are using JAX/Grain).\nHere is the breakdown of why using GPU/TorchVision is the wrong tool for these specific jobs.\n\n1. Regarding the Offline Cleaning Step (Resizing & Saving)\nYou asked if TorchVision on GPU would make this faster. It will generally be slower.\n\nThe Bottleneck is Disk I/O, not Math: In a cleaning pipeline, the computer spends most of its time reading the file from the hard drive and writing the new file back. The actual math of resizing a 224x224 image is trivial for a CPU.\nThe ‚ÄúTransfer Tax‚Äù: To use the GPU, you must:\n\nLoad image to RAM (CPU).\nTransfer image to GPU (PCIe bus).\nResize (GPU - fast).\nTransfer back to RAM (PCIe bus).\nSave to disk (CPU). For simple resizing, the time spent moving the data back and forth to the GPU takes longer than just doing the math on the CPU.\n\nJPEG Encoding is mostly CPU: Standard TorchVision save_image still uses CPU libraries (like libpng or libjpeg) to encode the final file. You don‚Äôt gain speed there.\n\nWinner: The CPU Multiprocessing script provided in the previous answer. It saturates your disk bandwidth, which is the physical speed limit.\n\n\n2. Regarding the Training DataLoader\nYou are using JAX (indicated by your use of dm-pix and jax.numpy).\n\nEcosystem Clash: TorchVision is built for PyTorch. Grain is built for JAX/Flax. While you can use TorchVision with JAX, you have to manually convert PyTorch Tensors to Numpy/JAX arrays. This adds overhead and extra dependencies.\nGPU Transforms:\n\nTorchVision: Can run transforms on GPU (using v2.transforms).\nJAX (Your setup): You are already planning to use PIX (dm-pix) on the GPU.\nResult: Switching to TorchVision gives you no advantage because PIX already handles GPU acceleration natively in JAX.\n\n\n\n\nSummary: The Fastest Architecture\nDo not change your tools; just organize them correctly.\n\nOffline Cleaning (Step 1):\n\nTool: Python + PIL/Numpy + Multiprocessing (CPU).\nWhy: Parallel CPU cores handle disk I/O and simple resizing fastest without GPU transfer overhead.\n\nData Loading (Step 2):\n\nTool: Grain (CPU).\nWhy: Optimized for JAX, handles pre-fetching efficiently.\n\nAugmentation (Step 3):\n\nTool: DM-PIX (GPU).\nWhy: Happens after the batch is loaded onto the GPU, leveraging JAX‚Äôs speed for complex math (rotations, color jitters).\n\n\nStick with the plan: Use the ProcessPoolExecutor script for cleaning, and use Grain + PIX for training."
  },
  {
    "objectID": "ai/jxai/gemini_chat.html#what-is-the-best-strategy-for-data-augmentation-with-the-pix-httpsgithub.comgoogle-deepminddm_pix-library-to-train-a-classification-model-in-jax-using-the-nabirds-httpsdl.allaboutbirds.orgnabirds-dataset",
    "href": "ai/jxai/gemini_chat.html#what-is-the-best-strategy-for-data-augmentation-with-the-pix-httpsgithub.comgoogle-deepminddm_pix-library-to-train-a-classification-model-in-jax-using-the-nabirds-httpsdl.allaboutbirds.orgnabirds-dataset",
    "title": "Research Computing",
    "section": "What is the best strategy for data augmentation with the PIX (https://github.com/google-deepmind/dm_pix) library to train a classification model in JAX using the NABirds (https://dl.allaboutbirds.org/nabirds) dataset?",
    "text": "What is the best strategy for data augmentation with the PIX (https://github.com/google-deepmind/dm_pix) library to train a classification model in JAX using the NABirds (https://dl.allaboutbirds.org/nabirds) dataset?\nFor the NABirds dataset‚Äîa fine-grained classification task where distinguishing features are often subtle color patterns, beak shapes, or plumage textures‚Äîthe ‚Äúbest‚Äù strategy balances increasing data diversity with preserving the precise visual cues required to distinguish species.\nSince dm-pix (PIX) provides low-level, JAX-native image processing primitives, you must compose them into a pipeline yourself. Unlike libraries like imgaug or torchvision, PIX requires explicit management of JAX random keys (PRNGKey).\nHere is the recommended strategy and a concrete implementation pattern.\n\nThe Strategy: ‚ÄúLook Closer, Don‚Äôt Change Colors‚Äù\n\nGeometric Augmentation (Crucial):\n\nRandom Resized Crop: This is the most important augmentation for fine-grained tasks. It forces the model to learn from specific parts of the bird (head, wing, tail) rather than just the whole silhouette.\nHorizontal Flip: Birds are bilaterally symmetric (mostly); flipping is a safe way to double your dataset.\nAvoid Vertical Flips/90¬∞ Rotations: Unless the bird is flying, these orientations are unnatural and can confuse the model regarding gravity-dependent features.\n\nPhotometric Augmentation (Caution Needed):\n\nBrightness/Contrast: Safe and recommended to simulate different lighting conditions.\nSaturation: Use moderately.\nHue: Avoid or use extremely sparingly. Distinguishing a ‚ÄúScarlet Tanager‚Äù from a ‚ÄúSummer Tanager‚Äù relies heavily on exact shades of red. Shifting the hue too far invalidates the label.\n\nAdvanced (Batch-Level):\n\nMixUp / CutMix: While not strictly inside PIX, these are standard for fine-grained classification to prevent the model from memorizing backgrounds. You implement these on the batch after the PIX pipeline.\n\n\n\n\n\nImplementation with dm-pix\nBelow is a JAX-compatible augmentation pipeline using dm-pix. This setup assumes you are using pmap or vmap for parallelism.\nimport jax\nimport jax.numpy as jnp\nimport dm_pix as pix\n\ndef augment_image(key, image, training=True):\n    \"\"\"\n    Applies data augmentation to a single image for NABirds.\n    \n    Args:\n        key: A jax.random.PRNGKey.\n        image: A float32 JAX array of shape [H, W, 3] in range [0, 1].\n        training: Boolean, whether to apply random augmentations.\n        \n    Returns:\n        Augmented image of shape [224, 224, 3].\n    \"\"\"\n    # 1. Define target size (standard for ResNet/ViT)\n    target_h, target_w = 224, 224\n\n    if training:\n        # Split keys for each stochastic operation\n        k_crop, k_flip, k_color = jax.random.split(key, 3)\n        k_bright, k_cont, k_sat = jax.random.split(k_color, 3)\n\n        # --- Geometric Transformations ---\n        \n        # Random Resized Crop (Simulated)\n        # PIX's random_crop produces a crop of fixed size. To get \"Inception-style\" \n        # random resized cropping, we typically crop randomly then resize.\n        # Ideally, you crop a random region covering 50%-100% of the image.\n        # Here is a simplified version using PIX primitives:\n        \n        # Random flip left/right (probability 0.5 is default)\n        image = pix.random_flip_left_right(k_flip, image)\n\n        # Random Crop: For fine-grained, we want to zoom in.\n        # We'll take a crop slightly larger than target and resize, \n        # or just crop to target if image is large enough.\n        # (Assuming input images are larger than 224x224)\n        image = pix.random_crop(k_crop, image, (target_h, target_w, 3))\n\n        # --- Photometric Transformations (Color Jitter) ---\n        \n        # Adjust Brightness (delta usually roughly 0.1 to 0.2)\n        image = pix.random_brightness(k_bright, image, max_delta=0.2)\n\n        # Adjust Contrast (factor between 0.8 and 1.2)\n        image = pix.random_contrast(k_cont, image, lower=0.8, upper=1.2)\n\n        # Adjust Saturation (factor between 0.8 and 1.2)\n        # Avoid removing color entirely (factor=0) for birds\n        image = pix.random_saturation(k_sat, image, lower=0.8, upper=1.2)\n\n        # NOTE: Intentionally skipping random_hue to preserve species colors.\n\n    else:\n        # Validation Strategy: Resize then Center Crop\n        # Note: 'resize' is usually done via jax.image.resize before calling this,\n        # or we use pix.resize_with_crop_or_pad for simple centering.\n        image = pix.resize_with_crop_or_pad(image, target_h, target_w)\n\n    # Standard ImageNet normalization (if model expects it)\n    # Mean and Std for ImageNet in [0, 1] range\n    mean = jnp.array([0.485, 0.456, 0.406])\n    std = jnp.array([0.229, 0.224, 0.225])\n    image = (image - mean) / std\n\n    return image\n\n# Usage with vmap for batch processing\ndef augment_batch(key, images, training=True):\n    batch_size = images.shape[0]\n    keys = jax.random.split(key, batch_size)\n    return jax.vmap(augment_image, in_axes=(0, 0, None))(keys, images, training)\n\n\nWhy this configuration?\n\nrandom_crop vs center_crop: NABirds images often have the bird in the center, but not always. Random cropping helps the model become invariant to the bird‚Äôs position and, critically, acts as a ‚Äúzoom‚Äù augmentation, training the model to recognize a bird by just its head or wing texture.\nExplicit Key Splitting: JAX is stateless. You generally cannot just call ‚Äúrandom‚Äù functions. You must split the PRNGKey and pass a unique sub-key to every random operation (random_brightness, random_flip, etc.).\nHue Exclusion: In generic object detection, a green car is still a car. In bird classification, a Red-winged Blackbird without the red wing is just a Blackbird (or a different species entirely). Omitting random_hue prevents generating false negatives.\n\n\n\nAdvanced Tip: JAX Performance\nPIX functions are written to be compiled. Ensure you wrap your training step (which includes this augmentation) in jax.jit. Because image augmentation creates a lot of intermediate arrays, JAX‚Äôs XLA compiler is very good at fusing these operations into a single GPU kernel, making this pipeline extremely fast compared to CPU-based loaders like standard PyTorch DataLoader."
  },
  {
    "objectID": "ai/jxai/gemini_chat.html#how-to-choose-which-augmentation-to-use",
    "href": "ai/jxai/gemini_chat.html#how-to-choose-which-augmentation-to-use",
    "title": "Research Computing",
    "section": "How to choose which augmentation to use?",
    "text": "How to choose which augmentation to use?\n\nThe standard stack\nFor 90% of classification tasks (e.g., ResNet/EfficientNet on natural images), use this baseline. It consists of 3 distinct operations:\n\nGeometric (Spatial): Random Resized Crop (The single most important augmentation).\nOrientation: Horizontal Flip (If the object isn‚Äôt text or directional).\nPhotometric (Color): Mild Color Jitter (Brightness/Contrast/Saturation).\n\nWhy this works: It forces the model to learn that the object is the same regardless of scale, position, orientation, or lighting.\n\n\nAdvanced Techniques (MixUp / CutMix)\nOnce you have your standard stack (Crop/Flip/Color), you can add one ‚Äúregularization‚Äù technique on top. These are mixed into the batch training: * MixUp: Blending two images together. * CutMix: Cutting a square from one image and pasting it onto another.\nRecommendation: Do not count these as ‚Äústandard‚Äù augmentations. Treat them as a final boosting layer. Use one of them if your validation loss is plateauing too early.\n\n\nSummary Checklist\n\nStart with 3: Random Resized Crop + Horizontal Flip + Color Jitter.\nVisualize: Look at a batch of 32 images. If they look destroyed, reduce the intensity or probability.\nUse Automation: If using PyTorch or TensorFlow, implement RandAugment (N=2, M=9) and stop worrying about manual selection.\n\n\n\nThe danger of too many\nThe biggest mistake beginners make is Sequential Stacking. * Bad: Apply Rotation AND Shear AND Blur AND Noise AND Gamma AND Jitter to every image. * Result: The image becomes a gray blob. The model learns nothing.\nThe Solution: Use Probabilities or ‚ÄúOneOf‚Äù blocks. * Probability: Set p=0.5 for each technique. The statistical chance of an image getting hit by all 5 augmentations becomes very low (\\(0.5^5 \\approx 3\\%\\)). * OneOf (Albumentations): Define a block of 3 techniques (e.g., Blur, Noise, Compression) and tell the pipeline: ‚ÄúPick exactly one of these to apply.‚Äù\n\n\nModern Best Practice: ‚ÄúRandAugment‚Äù\nIf you are struggling to decide how many to pick, stop guessing and use RandAugment (or TrivialAugment).\nThis is the standard for State-of-the-Art models today. instead of you manually picking ‚ÄúRotation‚Äù and ‚ÄúShear,‚Äù you set two parameters: 1. N (Number): How many transformations to apply sequentially (usually N=2). 2. M (Magnitude): How strong the effect is (usually M=9 out of 10).\nThe algorithm then randomly selects 2 augmentations from a bank of 14 possibilities for each batch. This saves you from tuning hyperparameters."
  },
  {
    "objectID": "ai/jxai/gemini_chat.html#should-i-cropresize-my-eval-set-the-same-way",
    "href": "ai/jxai/gemini_chat.html#should-i-cropresize-my-eval-set-the-same-way",
    "title": "Research Computing",
    "section": "Should I crop/resize my eval set the same way?",
    "text": "Should I crop/resize my eval set the same way?\nYes, you should crop and resize the evaluation set to the bounding boxes, just as you did for the training set.\nSince you trained your model on cropped images (showing only the bird), your model has learned to expect close-up, centered features. If you evaluate on full images (which include trees, sky, and background noise), your model will likely fail because the input data distribution will be completely different from what it learned.\n\nThe Standard Protocols for Fine-Grained Classification (NABirds / CUB-200)\nIn fine-grained visual classification research (like NABirds), there are two distinct evaluation settings. You are currently in the ‚ÄúOracle‚Äù setting.\n\nOracle Setting (Your current path):\n\nMethod: You use the ground-truth bounding boxes during both training and evaluation.\nGoal: This tests the classification capacity of your model in isolation. It asks: ‚ÄúAssuming we perfectly located the bird, can the model identify the species?‚Äù\nAction: Crop the evaluation set using the provided bounding boxes, then resize to \\(224 \\times 224\\).\n\nRealistic / ‚ÄúIn the Wild‚Äù Setting:\n\nMethod: You use bounding boxes during training, but not during evaluation.\nGoal: This tests the entire system‚Äôs ability to find and identify birds in raw images.\nAction: You would need a separate object detection model (like YOLO or Faster R-CNN) to predict bounding boxes on the test set first, and then feed those predicted crops into your classifier.\n\n\n\n\nRecommended Preprocessing Steps\nTo get the most accurate evaluation of your current model, follow this pipeline for your evaluation set:\n\nCrop: Crop the image using the ground-truth bounding box coordinates.\nResize (with Aspect Ratio preservation):\n\nIdeally: Resize the cropped bird image so the smaller edge is 256 pixels, then Center Crop to \\(224 \\times 224\\). This prevents distorting the bird (e.g., making a fat bird look skinny).\nAlternatively (if you did this in training): Direct resize (squish) to \\(224 \\times 224\\). If you squished images during training, you must squish them during evaluation.\n\nNormalize: Apply the exact same mean and standard deviation normalization you used for the training set (usually ImageNet defaults).\n\n\n\nSummary\nIf you do not crop the evaluation set, your accuracy will drop significantly, not because the model is bad, but because it is looking at ‚Äúbackground‚Äù data it was taught to ignore. Stick to the crops for a fair evaluation.\nYes, you absolutely should apply the exact same ‚ÄúCrop \\(\\rightarrow\\) Proportional Resize \\(\\rightarrow\\) Save‚Äù steps to your evaluation set.\nBecause you have already baked a specific geometric transformation (proportional resizing with no squishing) into your training data files, your evaluation data must match that structure exactly to be valid.\nHere is the breakdown of how your pipeline should look to ensure your evaluation is fair and accurate:\n\n\n1. The ‚ÄúSave to Disk‚Äù Phase (Preprocessing)\nAction: Perform identical operations on both Training and Evaluation sets.\n\nCrop: Crop to the bird‚Äôs bounding box.\nResize: Perform your ‚Äúproportional resize‚Äù to \\(224 \\times 224\\).\n\nNote: Since you mentioned ‚Äúno squishing,‚Äù you likely padded the images with black borders (or another color) to make them square, or you saved them as non-square files. Whatever logic you used (e.g., ‚Äúfit within \\(224 \\times 224\\) and pad‚Äù), you must use the exact same logic for the evaluation set.\nWhy? If your model learned to see birds with ‚Äúblack bars‚Äù (padding) or specific aspect ratios during training, it will be confused if the evaluation images don‚Äôt have them.\n\n\n\n\n2. The ‚ÄúLoad & Augment‚Äù Phase (Runtime)\nAction: This is where the two sets diverge.\nEven though the files on disk were created the same way, how you load them into your model differs:\n\n\n\n\n\n\n\n\nFeature\nTraining Pipeline\nEvaluation Pipeline\n\n\n\n\nInput\nYour pre-processed \\(224 \\times 224\\) files\nYour pre-processed \\(224 \\times 224\\) files\n\n\nAugmentation\nRandom Flip, Color Jitter, etc.\nNone (or Center Crop if needed)\n\n\nNormalization\nStandard (e.g., ImageNet mean/std)\nSame (ImageNet mean/std)\n\n\n\n\n\nA Critical Warning on Resolution\nYou mentioned you resized to \\(224 \\times 224\\) before saving to disk. * The Risk: Standard training often uses RandomResizedCrop, which zooms into a random part of the image. If your starting image is already only \\(224 \\times 224\\), zooming in further will result in very blurry, low-resolution crops (e.g., a \\(150 \\times 150\\) crop stretched back to \\(224 \\times 224\\)). * The Fix: If you plan to use RandomResizedCrop during training, it is usually better to save your images at a larger size (e.g., \\(400 \\times 400\\) or \\(512 \\times 512\\)) and let the data loader handle the final resize to \\(224\\). * If you are NOT cropping during training: If your augmentation is just flipping/rotating (no zooming), then your current method is perfectly fine.\nSummary: Yes, run the exact same skimage proportional resize script on your evaluation folder before running your evaluation script."
  },
  {
    "objectID": "ai/jxai/gemini_chat.html#should-i-random-crop",
    "href": "ai/jxai/gemini_chat.html#should-i-random-crop",
    "title": "Research Computing",
    "section": "Should I random crop?",
    "text": "Should I random crop?\nFor the NABirds dataset, using the ‚ÄúRandom Resized Crop‚Äù (RRC) augmentation during training typically yields better results than training on static, perfectly centered crops, but you must be careful with how aggressive it is.\nSince you are working with fine-grained classification (where the difference between two species might just be the beak shape or wing bar), here is the specific breakdown of how to handle this for the best performance.\n\n1. The Short Answer\n\nTraining Set: Yes, use Random Resized Crop, but with a ‚Äúgentler‚Äù scale range (e.g., 0.5 to 1.0) so you don‚Äôt cut off too many identifying features.\nEvaluation Set: No.¬†Use Deterministic Resize (resize the bounding box crop directly to 224x224).\n\n\n\n2. Why Random Cropping Helps (Even for Birds)\nYou might think that because you have bounding boxes, you should just show the model the perfect ‚Äúbird box‚Äù every time. However, this often leads to overfitting. * The Problem with Static Crops: If you only train on the perfect bounding box, the model expects the bird to always be perfectly framed. If your test set crop is slightly off (or if you eventually deploy this model on real-world images where your detector isn‚Äôt perfect), the model will fail. * The Solution: By using RandomResizedCrop on the training set, you simulate ‚Äúimperfect‚Äù detection. The model learns to recognize the bird even if it‚Äôs slightly zoomed in, slightly off-center, or if the tail is cut off.\n\n\n3. The ‚ÄúTrap‚Äù in Your Current Workflow\nYou mentioned you already saved your training images as 224x224 files. * The Issue: Standard RandomResizedCrop works by taking a crop (e.g., 50% of the image) and resizing it down to 224x224. * Your Constraint: Since your files are already 224x224, if you try to crop 50% of the image, you are taking a 112x112 patch and stretching it back up to 224x224. This creates a blurry, pixelated image that destroys the fine details (feather patterns) necessary for identifying bird species.\n\n\n4. Recommended Pipeline for Best Results\nTo get state-of-the-art results on NABirds, you should ideally modify your pipeline to perform cropping online (during training) rather than offline (saving to disk).\n\nA. The ‚ÄúGold Standard‚Äù Pipeline\nIf you can reload your original images, do this: 1. Load the original high-res image. 2. Crop to the bounding box (plus a small margin, e.g., 10-20% context, which helps significantly with birds). 3. Apply Augmentation (Train only): * RandomResizedCrop(224, scale=(0.7, 1.0)) -&gt; Note the high minimum scale. Don‚Äôt go down to 0.08 like ImageNet. * RandomHorizontalFlip() 4. Evaluation Phase: * Crop to Bounding Box. * Resize(256) -&gt; CenterCrop(224) OR just Resize((224, 224)).\n\n\nB. The ‚ÄúFixed Files‚Äù Pipeline (If you must stick to your saved 224x224 files)\nIf you cannot redo the dataset creation, do not use RandomResizedCrop. It will blur your images too much. Instead use: * Training: RandomCrop(224, padding=28) (this pads the image slightly and shifts it around without losing resolution) + RandomHorizontalFlip. * Evaluation: Standard Resize((224, 224)) of the bounding box crop."
  },
  {
    "objectID": "ai/jxai/gemini_chat.html#should-i-save-to-disk-after-cropping-to-bb",
    "href": "ai/jxai/gemini_chat.html#should-i-save-to-disk-after-cropping-to-bb",
    "title": "Research Computing",
    "section": "Should I save to disk after cropping to bb?",
    "text": "Should I save to disk after cropping to bb?\nYes, you should save the cropped images to disk to speed up training, but you must be careful about when you resize them.\nFor the best results on the NABirds dataset, use this specific ‚ÄúHybrid‚Äù approach:\n\nThe Recommended Workflow\n\nPreprocessing Step (Run Once):\n\nCrop: Crop the original high-resolution image to the bounding box (plus a small margin, e.g., 10-20%).\nAction: Save this cropped image to disk at its native resolution (e.g., if the crop is \\(600 \\times 600\\), save it as \\(600 \\times 600\\)).\nDo NOT Resize yet: Do not shrink these to \\(224 \\times 224\\) during this step.\n\nTraining Step (Run Many Times):\n\nLoad: Your dataloader reads the saved (smaller, faster) crop files.\nAugment: Apply RandomResizedCrop(224) on these loaded images.\nWhy this works: Since your saved files are still large (e.g., \\(500\\)+ pixels), the random cropper has plenty of pixels to zoom in and out of without making the image blurry.\n\nEvaluation Step:\n\nLoad: Read the same saved crop files.\nResize: Apply Resize(256) \\(\\rightarrow\\) CenterCrop(224).\n\n\n\n\nWhy this is better than your current plan\nIf you resize to \\(224 \\times 224\\) before saving to disk, you lock your data into a low resolution. If you then try to use data augmentation (like zooming in on the head), you are zooming into an already pixelated image, which will look blurry and hurt your model‚Äôs accuracy on fine-grained bird features.\nSummary: Save the crops to disk (for speed), but keep them large (for quality)."
  },
  {
    "objectID": "ai/jxai/gemini_chat.html#should-i-just-skip-the-cropping-part-entirely",
    "href": "ai/jxai/gemini_chat.html#should-i-just-skip-the-cropping-part-entirely",
    "title": "Research Computing",
    "section": "Should I just skip the cropping part entirely?",
    "text": "Should I just skip the cropping part entirely?\nIt is generally better to crop and save to disk (the ‚Äúoffline‚Äù method) rather than doing it on-the-fly, primarily for training speed.\nHowever, in terms of model accuracy, both methods are identical if implemented correctly.\nHere is the breakdown of the trade-offs so you can decide which fits your setup:\n\n1. Training Speed (Winner: Save to Disk)\nThis is the main reason researchers pre-crop datasets like NABirds or CUB-200. * The Problem with ‚ÄúOn-the-Fly‚Äù: If your original image is 4000x3000 pixels (12MP) but the bird only occupies a 500x500 region, your computer has to load a huge file, decode the entire JPEG, and then throw away 90% of the pixels every single time the model sees that image (thousands of times during training). This creates a massive bottleneck on your CPU and Hard Drive/SSD, often leaving your GPU waiting for data. * The Benefit of ‚ÄúSave to Disk‚Äù: By saving the crop (e.g., a 50KB file instead of a 5MB file), you reduce the I/O load significantly. Your training epochs will likely run 2x to 5x faster.\n\n\n2. Flexibility (Winner: On-the-Fly)\n\nThe Benefit: If you decide later that you want to include more background context (e.g., you want the crop to be 1.5x the size of the bounding box instead of 1.1x), you can just change a number in your code.\nThe Downside of ‚ÄúSave to Disk‚Äù: If you saved tight crops and realize later you needed more background, you have to re-run your preprocessing script to generate the dataset again.\n\n\n\n3. Accuracy (Tie)\nAs long as the pixels feeding into the neural network are the same, the model doesn‚Äôt care if they were cropped 5 minutes ago or 5 milliseconds ago.\n\n\n\nThe ‚ÄúSweet Spot‚Äù Recommendation\nTo get the best of both worlds (Speed + Flexibility), stick to the ‚ÄúHigh-Res Crop with Margin‚Äù strategy I mentioned earlier:\n\nScript: Load Original Image.\nCrop: Extract the bounding box + 20% margin (extra background).\nSave: Save this as a high-quality JPG/PNG to a new folder.\nTrain: Point your dataloader at this new folder.\n\nWhy this wins: * Speed: You get the speed boost because you aren‚Äôt loading the full megapixels of the original photo. * Flexibility: The 20% margin gives your RandomResizedCrop augmentation enough ‚Äúwiggle room‚Äù to shift the bird around or zoom out slightly without hitting the edge of the image.\nVerdict: Don‚Äôt skip the ‚Äúsave to disk‚Äù step unless your dataset is very small or you have an incredibly fast CPU/SSD combo that can handle decoding full images in real-time without slowing down the GPU."
  },
  {
    "objectID": "ai/jxai/gemini_chat.html#details-for-the-eval-set",
    "href": "ai/jxai/gemini_chat.html#details-for-the-eval-set",
    "title": "Research Computing",
    "section": "Details for the eval set",
    "text": "Details for the eval set\nHere is the detailed breakdown for the Evaluation Set within the ‚ÄúHigh-Res Crop \\(\\rightarrow\\) Save \\(\\rightarrow\\) Load‚Äù workflow.\nThis approach ensures you evaluate on the highest quality data while avoiding the risk of cutting off the bird‚Äôs head or tail (which can happen with standard center cropping on rectangular birds).\n\nPhase 1: Preprocessing (Saving to Disk)\nRule: You must treat the evaluation set exactly like the training set during the saving phase.\nIf you saved your training data with a 20% margin, you must save your evaluation data with a 20% margin. If you don‚Äôt, the model will see the bird ‚Äúcloser up‚Äù during evaluation than it did during training, which will skew your results.\n\nInput: Original Test Images + Bounding Boxes.\nAction:\n\nCalculate Bounding Box coordinates.\nExpand coordinates by your chosen margin (e.g., 20%).\nCrop the image.\nSave to disk at native resolution (Do not resize to 224 yet).\n\n\n\n\nPhase 2: The Runtime Pipeline (The Code)\nThis is where the Evaluation strategy deviates from Training.\nSince you are working with crops of birds (which are often rectangular‚Äîthink of a standing heron vs.¬†a flying duck), using the standard CenterCrop can be dangerous because it might chop off the head or tail.\nInstead, for fine-grained Bounding Box classification, the standard approach is a Direct Resize (Squish).\n\nThe Code (PyTorch Example)\nfrom torchvision import transforms\n\n# 1. Training Transforms (For context)\n# We use RandomResizedCrop here. This teaches the model to handle\n# zoom, missing parts, and ASPECT RATIO DISTORTION (squishing).\ntrain_transforms = transforms.Compose([\n    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)), \n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# 2. Evaluation Transforms (The Recommendation)\n# We use a direct Resize.\nval_transforms = transforms.Compose([\n    # Resize directly to 224x224. \n    # This ensures the WHOLE bird (and your margin) is visible.\n    transforms.Resize((224, 224)), \n    \n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n\n\nWhy ‚ÄúDirect Resize‚Äù instead of ‚ÄúResize & Crop‚Äù?\nYou might be worried that Resize((224, 224)) distorts the aspect ratio (squishing a wide bird to be square). Here is why this is actually the best choice for this specific workflow:\n\nSafety: If you use the standard ImageNet method (Resize(256) -&gt; CenterCrop(224)), you risk cutting off features.\n\nExample: You have a wide image of a flying eagle (\\(400 \\times 200\\)).\nIf you resize the short edge to \\(256\\), the image becomes \\(512 \\times 256\\).\nIf you then CenterCrop(224), you only see the middle feathers. The head and tail are gone. The model cannot identify the bird.\n\nRobustness: Because your Training Set uses RandomResizedCrop, your model has already learned to be robust to aspect ratio changes. RandomResizedCrop inherently stretches and squishes images as it selects random areas. Therefore, the model will not be confused by the ‚Äúsquish‚Äù in the evaluation set.\n\n\n\nAlternative: The ‚ÄúBlack Bars‚Äù Method (Padding)\nIf you absolutely cannot tolerate squishing (distortion) because you feel the beak shape is being ruined, you can use a ‚ÄúLetterbox‚Äù resize: 1. Resize the longest edge to 224. 2. Pad the shorter edge with black pixels (zeros) to reach 224.\nHowever, for most modern CNNs (ResNet, EfficientNet, ViT) trained with standard augmentation, the Direct Resize method described above usually yields higher accuracy than padding.\n\n\nSummary of Eval Workflow\n\nFile on Disk: High-res crop of the bird + 20% background.\nDataloader: Loads file \\(\\rightarrow\\) Squishes to \\(224 \\times 224\\) \\(\\rightarrow\\) Normalizes.\nModel: Predicts class."
  },
  {
    "objectID": "ai/jxai/gemini_chat.html#which-model-to-use",
    "href": "ai/jxai/gemini_chat.html#which-model-to-use",
    "title": "Research Computing",
    "section": "Which model to use?",
    "text": "Which model to use?\nTo train a model on the NABirds dataset, you should start with ResNet-50 pre-trained on ImageNet.\nFor a specific task like identifying 400+ species of birds, you need a balance between a model that is powerful enough to see fine details (like beak shape or wing patterns) and one that is easy to train without requiring a supercomputer.\n\nThe Recommendation: ResNet-50\n\nWhy start here? ResNet-50 is the ‚Äúgold standard‚Äù baseline in computer vision. It is deep enough to capture complex features but stable enough that it rarely fails to converge.\nAvailability: Every major deep learning library (PyTorch, TensorFlow/Keras, FastAI) has it built-in with a single line of code.\nPerformance: You can expect remarkably high accuracy (often &gt;85-90%) on bird datasets just by fine-tuning this model.\n\n\n\nThe ‚ÄúPro‚Äù Alternative: EfficientNet (B0 or B2)\nIf you are comfortable with slightly more modern architectures, EfficientNet-B0 or EfficientNet-B2 are excellent choices. * Pros: They often achieve higher accuracy than ResNet while using fewer parameters (making the model smaller and faster). * Cons: They can sometimes be a bit trickier to tune (e.g., they are sensitive to learning rates and optimizers) compared to the robust ResNet.\n\n\n\nStep-by-Step Strategy for NABirds\nSince NABirds is a fine-grained classification task (distinguishing between very similar sub-species), training from scratch will likely fail. You must use Transfer Learning.\n\n1. Use Pre-trained Weights (Crucial)\nDo not initialize your model with random weights. Start with weights pre-trained on ImageNet. * Context: ImageNet contains 1,000 classes, including many birds (e.g., ‚Äúgoldfinch,‚Äù ‚Äúrobin,‚Äù ‚Äúeagle‚Äù). Your model will start already knowing what a feather, a beak, and a wing look like. * Advanced Tip: If you want to squeeze out the absolute best performance later, look for model weights pre-trained on the iNaturalist dataset. This dataset is entirely nature-focused and handles the ‚Äúlong tail‚Äù of rare species better than ImageNet, but these weights are harder to find and load than standard ImageNet ones.\n\n\n2. Resolution Matters\nBirds are often small in the frame or distinguished by tiny markings. * Standard: Standard models use \\(224 \\times 224\\) pixel inputs. * Better for Birds: If your GPU memory allows, try increasing the input size to \\(448 \\times 448\\). This is often the single most effective trick for boosting accuracy in fine-grained bird classification.\n\n\n3. Data Augmentation\nBird photos are taken in various lighting conditions and angles. You should use aggressive data augmentation during training to prevent overfitting: * Essential: Random rotation, horizontal flips (a bird facing left is the same species as one facing right), and brightness/contrast adjustments. * Useful: Random cropping (zooming in) to simulate different distances.\n\n\n\nCode Snippet (PyTorch Example)\nHere is how you would load the recommended starting point in PyTorch:\nimport torchvision.models as models\nimport torch.nn as nn\n\n# 1. Load the ResNet50 model with ImageNet weights\nweights = models.ResNet50_Weights.DEFAULT\nmodel = models.resnet50(weights=weights)\n\n# 2. Modify the final layer for NABirds (which has roughly 400-555 classes depending on version)\n# Replace 'num_classes' with the exact number of species in your dataset split\nnum_classes = 555 \nmodel.fc = nn.Linear(model.fc.in_features, num_classes)\n\n# 3. Now you are ready to train (fine-tune)\nSummary: Start with ResNet-50 using ImageNet weights. It is the path of least resistance and will give you a high-quality baseline. If you need more speed, swap to EfficientNet-B0. If you need more accuracy, increase image resolution."
  },
  {
    "objectID": "ai/jxai/gemini_chat.html#how-to-do-it-in-jax",
    "href": "ai/jxai/gemini_chat.html#how-to-do-it-in-jax",
    "title": "Research Computing",
    "section": "How to do it in JAX?",
    "text": "How to do it in JAX?\nIt is excellent that you are looking to use JAX. It is a powerful framework, but for a task like NABirds (fine-grained classification), you face a specific challenge: Transfer Learning.\nTo get high accuracy on birds, you cannot train from scratch; you must start with a model pre-trained on ImageNet. While Bonsai contains an implementation of EfficientNet, it is a ‚Äúminimal, lightweight‚Äù library. As of late 2024, it often lacks the robust ‚Äúmodel zoo‚Äù features (like automatic downloading and aligning of pre-trained weights) that libraries like PyTorch‚Äôs timm provide.\nHere is the best way to get started with EfficientNet in the JAX ecosystem for your specific dataset.\n\n1. The Challenge with Bonsai\nIf you use the jax-ml/bonsai repository directly, you will get the EfficientNet architecture, but likely initialized with random weights. Training this on NABirds will probably result in poor performance (likely &lt;50% accuracy) because the model hasn‚Äôt learned the basic features of ‚Äúseeing‚Äù (edges, textures, shapes) that it gets from ImageNet.\nRecommendation: Unless you want to manually write a script to port weights from PyTorch to JAX, do not start with Bonsai alone.\n\n\n2. The Solution: efficientnet-jax (or jimm)\nThe standard, battle-tested way to use EfficientNet in JAX with pre-trained weights is the efficientnet-jax repository. It is maintained by Ross Wightman (the creator of the famous timm library) and specifically supports Flax (the neural network library for JAX).\nThis library allows you to load ImageNet weights that have been ported to JAX, which is exactly what you need.\n\n\n3. Step-by-Step Implementation Guide\n\nStep 1: Install the necessary libraries\nYou will need JAX, Flax, Optax (for optimization), and the EfficientNet library.\npip install jax jaxlib flax optax efficientnet-jax\n\n\nStep 2: Load the Pre-trained Model\nHere is how you initialize the model with ImageNet weights and modify it for NABirds (which has ~555 classes).\nimport jax.numpy as jnp\nfrom efficientnet_jax import EfficientNetB0\n\n# 1. Initialize the model with pre-trained ImageNet weights\n# 'pretrained=True' downloads and loads the weights automatically.\nmodel = EfficientNetB0(pretrained=True)\n\n# 2. Inspect the model structure (optional)\n# In Flax/JAX, models are stateless. You get a 'params' dictionary.\n# To use it for NABirds, we need to replace the final layer.\n# However, efficientnet-jax is often used via its functional API or Linen wrapper.\n\n# A more robust Flax pattern for Transfer Learning:\nfrom flax import linen as nn\n\nclass BirdModel(nn.Module):\n    num_classes: int\n    \n    @nn.compact\n    def __call__(self, x, training: bool):\n        # Load the base EfficientNet (features only)\n        # Note: In a real script, you would load the pretrained backbone state here\n        # For simplicity, many JAX users use the 'rwightman/efficientnet-jax' \n        # specifically for the .apply function or similar logic.\n        \n        # ... (There is slightly more boilerplate in JAX than PyTorch for this) ...\n        pass\nWait‚ÄîSimpler Alternative for Beginners: Because JAX is ‚Äúpurely functional,‚Äù handling state dictionaries for transfer learning can be verbose. If you are new to JAX, the easiest path that still uses the JAX stack is to use Hugging Face Transformers with a Flax backend, if available, or simply PyTorch for data loading + JAX for training.\nHowever, since you want a pure JAX stack, here is the cleanest current snippet using efficientnet-jax:\nimport jax\nimport jax.numpy as jnp\nfrom efficientnet_jax import load_pretrained_model\n\n# Load EfficientNet-B0 with ImageNet weights\n# This function handles the messy weight porting for you\nmodel, params = load_pretrained_model(\"efficientnet-b0\")\n\n# The 'model' is a Flax Linen module.\n# You can now wrap this or modify the 'params' to change the final layer.\n# The final layer weights in EfficientNet are usually keys like 'predictions/kernel' \n# or 'head/dense/kernel'.\n\n# Strategy:\n# 1. Keep 'params' for all layers EXCEPT the last one.\n# 2. Randomly initialize a new last layer for 555 bird classes.\n\n\n\n4. Summary of Strategy for NABirds\n\nDon‚Äôt use jax-ml/bonsai yet: It is better for reading code than for practical transfer learning.\nUse efficientnet-jax: This gives you the pre-trained weights you need.\nResolution: Train at \\(224 \\times 224\\) first, but for birds, bumping up to \\(300 \\times 300\\) (EfficientNet-B3 size) often yields better results if your GPU fits it.\nLearning Rate: When fine-tuning in JAX, use a low learning rate (e.g., \\(1e-4\\)) so you don‚Äôt destroy the pre-trained weights."
  },
  {
    "objectID": "ai/jxai/gemini_chat.html#option-without-outdated-libraries",
    "href": "ai/jxai/gemini_chat.html#option-without-outdated-libraries",
    "title": "Research Computing",
    "section": "Option without outdated libraries",
    "text": "Option without outdated libraries\nSince Flax NNX is very new (released late 2024), there is no official ‚ÄúNNX Model Zoo‚Äù yet. Native NNX implementations of EfficientNet with pre-trained weights simply do not exist in a mature, ready-to-use library.\nHowever, you can achieve exactly what you want by combining Hugging Face Transformers (which is active and maintains pre-trained Linen weights) with the flax.nnx.bridge API. This allows you to run a modern NNX training loop while utilizing the battle-tested weights from the older Linen API.\nHere is the modern, non-archived solution.\n\nThe Strategy\n\nSource: Use transformers to download the pre-trained EfficientNet (Linen version).\nBridge: Use flax.nnx.bridge.ToNNX to convert the Linen module into an NNX graph.\nSurgery: Graph the pre-trained weights into the new NNX module variables.\nModel: Wrap it all in a clean nnx.Module with your custom classifier head.\n\n\n\nThe Code\nYou will need transformers and flax installed.\nimport jax\nimport jax.numpy as jnp\nfrom flax import nnx\nfrom flax.nnx import bridge\nfrom transformers import FlaxEfficientNetModel\n\nclass NABirdsEfficientNet(nnx.Module):\n    def __init__(self, num_classes=555, *, rngs: nnx.Rngs):\n        # 1. Load the pre-trained Linen model structure & weights from Hugging Face\n        hf_model = FlaxEfficientNetModel.from_pretrained(\"google/efficientnet-b0\")\n        \n        # 2. Extract the underlying Linen module and its variables\n        linen_module = hf_model.module\n        linen_variables = hf_model.params\n        # HF stores batch_stats in 'batch_stats' if they exist, or inside params.\n        # EfficientNet usually has 'batch_stats'. We merge them for the bridge.\n        if hasattr(hf_model, 'batch_stats'):\n            linen_variables = {**linen_variables, **hf_model.batch_stats}\n\n        # 3. Create the NNX Bridge\n        # We wrap the Linen module. ToNNX creates the structure.\n        self.backbone = bridge.ToNNX(linen_module, rngs=rngs)\n        \n        # 4. WEIGHT SURGERY (The Critical Step)\n        # We must initialize the bridge to create the NNX variable structure,\n        # then replace those random variables with the pre-trained ones.\n        dummy_input = jnp.ones((1, 224, 224, 3))\n        self.backbone.lazy_init(dummy_input)\n        \n        # Transfer weights: Linen dict -&gt; NNX State\n        # The bridge maps Linen collections to NNX variable types automatically.\n        # 'params' -&gt; nnx.Param, 'batch_stats' -&gt; nnx.BatchStat\n        _, backbone_state = nnx.split(self.backbone)\n        \n        # This function recursively matches keys and updates the state\n        def copy_weights(target_state, source_dict):\n            for key, value in source_dict.items():\n                if isinstance(value, dict) or hasattr(value, 'items'):\n                    # Traverse deeper if it's a dict/FrozenDict\n                    copy_weights(target_state[key], value)\n                else:\n                    # We found a leaf (array). Update the NNX Variable's value.\n                    # Note: target_state[key] is a Variable (Param/BatchStat) wrapper\n                    target_state[key].value = value\n\n        copy_weights(backbone_state, linen_variables)\n        nnx.update(self.backbone, backbone_state)\n\n        # 5. Define your new Custom Head (Pure NNX)\n        # EfficientNet-B0 output is 1280 dim\n        self.head = nnx.Linear(1280, num_classes, rngs=rngs)\n\n    def __call__(self, x):\n        # Run backbone (bridge)\n        # HF models output a generic object; we need 'last_hidden_state'\n        # shape: [batch, 7, 7, 1280] for B0\n        outputs = self.backbone(x)\n        features = outputs.last_hidden_state\n        \n        # Global Average Pooling (standard for EfficientNet)\n        features = jnp.mean(features, axis=(1, 2))\n        \n        # Classification\n        return self.head(features)\n\n# --- Usage Example ---\n\n# 1. Initialize\nrngs = nnx.Rngs(params=0, dropout=1)\nmodel = NABirdsEfficientNet(num_classes=555, rngs=rngs)\n\n# 2. Forward Pass\nx = jax.random.normal(jax.random.key(0), (1, 224, 224, 3))\nlogits = model(x)\n\nprint(f\"Logits shape: {logits.shape}\") # (1, 555)\nprint(\"Model initialized and pre-trained weights loaded via NNX bridge.\")\n\n\nWhy this is the correct approach\n\nNo Archived Libraries: It uses transformers (very active) and flax.nnx (brand new).\nStateful: The NABirdsEfficientNet class is fully stateful. You don‚Äôt need to pass params dictionaries around manually; model.w holds the data, just like in PyTorch.\nHybrid Power: You get the mature, accurate weights from the Linen ecosystem but can write your training loop, loss functions, and new layers using the clean NNX API.\n\n\n\nFine-Tuning Advice\nWhen training this model: 1. Freeze the Backbone (Optional): In NNX, you can easily filter parameters. If you want to train only the head first: ```python # Split model into params and graph graph, params = nnx.split(model)\n# Filter to get only the head parameters\nhead_params = nnx.filter(params, lambda path, _: 'head' in path)\n\n# Pass ONLY head_params to your optimizer\n```\n\nBatch Statistics: Remember that EfficientNet has BatchNorm layers. In NNX, you need to handle BatchStat updates. Ensure your training step returns the updated state for these statistics alongside the gradients."
  },
  {
    "objectID": "ai/jxai/gemini_chat.html#flaxefficientnetmodel-doesnt-exist",
    "href": "ai/jxai/gemini_chat.html#flaxefficientnetmodel-doesnt-exist",
    "title": "Research Computing",
    "section": "FlaxEfficientNetModel doesn‚Äôt exist",
    "text": "FlaxEfficientNetModel doesn‚Äôt exist\nYou are correct; FlaxEfficientNetModel is not currently implemented in the main Hugging Face transformers library, and efficientnet-jax relies on older APIs.\nSince you want to use NNX with a non-archived, modern library, the best supported path is to use the ResNet or Vision Transformer (ViT) implementations available directly in Hugging Face transformers. These are actively maintained and have native Flax weights.\nFor bird identification (NABirds), ResNet-50 is still the safest baseline, but ViT-Base is a powerful modern alternative.\nHere is how to load a pre-trained ResNet-50 (which does exist in transformers as FlaxResNetForImageClassification) and wrap it into a modern NNX module using the bridge.\n\nThe Solution: ResNet-50 via Transformers + NNX Bridge\nThis approach gives you: 1. Modern Stack: Uses active transformers and flax.nnx. 2. Pre-trained Weights: Loads ‚Äúmicrosoft/resnet-50‚Äù (trained on ImageNet). 3. NNX API: You interact with the model using the new NNX state management.\nimport jax\nimport jax.numpy as jnp\nfrom flax import nnx\nfrom flax.nnx import bridge\nfrom transformers import FlaxResNetForImageClassification\n\nclass BirdClassifier(nnx.Module):\n    def __init__(self, num_classes=555, *, rngs: nnx.Rngs):\n        # 1. Load the official Flax ResNet from Hugging Face\n        # We drop the original classification head to attach our own\n        hf_model = FlaxResNetForImageClassification.from_pretrained(\n            \"microsoft/resnet-50\",\n            num_labels=num_classes,\n            ignore_mismatched_sizes=True # Necessary to overwrite the 1000-class head\n        )\n        \n        # 2. Bridge the Linen module to NNX\n        # 'hf_model.module' is the underlying Linen module\n        # 'hf_model.params' contains the pre-trained weights\n        self.backbone = bridge.ToNNX(hf_model.module, rngs=rngs)\n        \n        # 3. Initialize and Load Weights\n        # ToNNX requires a lazy initialization to structure the variables\n        dummy_input = jnp.zeros((1, 3, 224, 224)) # ResNet expects NCHW by default in HF\n        self.backbone.lazy_init(dummy_input)\n        \n        # Extract the empty NNX state\n        _, backbone_state = nnx.split(self.backbone)\n        \n        # Copy weights from the loaded HF model into the NNX state\n        # We define a helper to recursively copy the dictionary structure\n        def copy_weights(target_state, source_dict):\n            for key, value in source_dict.items():\n                if isinstance(value, dict) or hasattr(value, 'items'):\n                    copy_weights(target_state[key], value)\n                else:\n                    # Assign the weight to the NNX Variable\n                    target_state[key].value = value\n\n        # HF stores weights in .params and batch stats in .batch_stats (if applicable)\n        # We merge them to match the structure expected by the bridge\n        full_linen_vars = {**hf_model.params}\n        if hasattr(hf_model, 'batch_stats'):\n            full_linen_vars['batch_stats'] = hf_model.batch_stats\n\n        copy_weights(backbone_state, full_linen_vars)\n        \n        # Update the bridge with the loaded weights\n        nnx.update(self.backbone, backbone_state)\n\n    def __call__(self, x):\n        # HF ResNet expects NCHW format (channels first)\n        # If your data is NHWC (standard for JAX), transpose it:\n        # x = jnp.transpose(x, (0, 3, 1, 2))\n        \n        # Run the bridged model\n        logits = self.backbone(x).logits\n        return logits\n\n# --- Usage ---\nrngs = nnx.Rngs(params=0, dropout=1)\nmodel = BirdClassifier(num_classes=555, rngs=rngs)\n\n# Test forward pass\ndummy_img = jax.random.normal(jax.random.key(0), (1, 3, 224, 224))\nlogits = model(dummy_img)\nprint(f\"Output shape: {logits.shape}\") # (1, 555)\n\n\nWhy this is better\n\nMicrosoft/ResNet-50 is a very strong, standard baseline.\nNative Support: Unlike EfficientNet, this model has a dedicated Flax implementation (FlaxResNetForImageClassification) inside the transformers library, so you don‚Äôt need to hack older repos.\nBridge: The bridge.ToNNX allows you to treat this legacy Linen model exactly like a native NNX object (mutable state, no apply/init functional boilerplate) in your training loop.\n\n\n\nAlternative: Vision Transformer (ViT)\nIf you prefer a Transformer-based architecture, simply replace \"microsoft/resnet-50\" with \"google/vit-base-patch16-224\" and FlaxResNetForImageClassification with FlaxViTForImageClassification. The bridge logic remains identical. ViT is excellent but can be heavier to train; ResNet is often ‚Äúsafer‚Äù for fine-grained tasks with medium-sized datasets like NABirds."
  },
  {
    "objectID": "ai/jx/wb_jax_content.html",
    "href": "ai/jx/wb_jax_content.html",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Accelerated array & AD",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/jx/wb_jax_content.html#context",
    "href": "ai/jx/wb_jax_content.html#context",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "Context",
    "text": "Context\n\nWhat is JAX?\n\nLibrary for Python developed by Google.\nKey data structure: Array.\nComposition, transformation, and differentiation of numerical programs.\nCompilation for CPUs, GPUs, and TPUs.\nNumPy-like and lower-level APIs.\nRequires strict functional programming.\n\n\n\nWhy JAX?\n\n\n\n\n\n\n\n\n\n01\n\n\nAutodiff method\n\n\n\n1\nStatic graph\nand XLA\n\n\n\n\n02\n\n\nFramework\n\n\n\n\n2\nDynamic graph\n\n\n\n1-&gt;2\n\n\n\n\n\na\n\nTensorFlow\n\n\n\n\n4\nDynamic graph\nand XLA\n\n\n\n2-&gt;4\n\n\n\n\n\nb\n\nPyTorch\n\n\n\n\n5\nPseudo-dynamic\nand XLA\n\n\n\n4-&gt;5\n\n\n\n\n\nd\n\nTensorFlow2\n\n\n\n\ne\n\nJAX\n\n\n\n\n\n03\n\n\nAdvantage\n\n\n\n\n\n7\nMostly\noptimized AD\n\n\n\n\n\n8\nConvenient\n\n\n\n\n\n9\nConvenient\n\n\n\n\n10\nConvenient and\nmostly optimized AD\n\n\n\n\n\n04\n\n\nDisadvantage\n\n\n\n\n\nA\nManual writing of IR\n\n\n\n\n\nB\nLimited AD optimization\n\n\n\n\n\nD\nDisappointing speed\n\n\n\n\nE\nPure functions\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummarized from a blog post by Chris Rackauckas.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Accelerated array & AD",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/jx/wb_jax_content.html#getting-started",
    "href": "ai/jx/wb_jax_content.html#getting-started",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "Getting started",
    "text": "Getting started\n\nInstallation\n Install from pip wheels:\n\nPersonal computer: use wheels installation commands from official site.\nAlliance clusters: python -m pip install jax --no-index.\n\n\nWindows: GPU support only via WSL.\n\n\n\nThe NumPy API\n\nNumPyJAX NumPy\n\n\n\nimport numpy as np\n\nprint(np.array([(1, 2, 3), (4, 5, 6)]))\n\n[[1 2 3]\n [4 5 6]]\n\n\n\nprint(np.arange(5))\n\n[0 1 2 3 4]\n\n\n\nprint(np.zeros(2))\n\n[0. 0.]\n\n\n\nprint(np.linspace(0, 2, 9))\n\n[0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ]\n\n\n\n\nimport jax.numpy as jnp\n\nprint(jnp.array([(1, 2, 3), (4, 5, 6)]))\n[[1 2 3]\n [4 5 6]]\nprint(jnp.arange(5))\n[0 1 2 3 4]\nprint(jnp.zeros(2))\n[0. 0.]\nprint(jnp.linspace(0, 2, 9))\n[0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ]",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Accelerated array & AD",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/jx/wb_jax_content.html#but-jax-numpy-is-not-numpy",
    "href": "ai/jx/wb_jax_content.html#but-jax-numpy-is-not-numpy",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "But JAX NumPy is not NumPy‚Ä¶",
    "text": "But JAX NumPy is not NumPy‚Ä¶\n\nDifferent types\n\nNumpyJAX NumPy\n\n\n\ntype(np.zeros((2, 3)))\n\nnumpy.ndarray\n\n\n\n\ntype(jnp.zeros((2, 3)))\njaxlib.xla_extension.ArrayImpl\n\n\n\n\n\nDifferent default data types\n\nNumpyJAX NumPy\n\n\n\nnp.zeros((2, 3)).dtype\n\ndtype('float64')\n\n\n\n\njnp.zeros((2, 3)).dtype\ndtype('float32')\n\nStandard for DL and libraries built for accelerators.\nFloat64 are very slow on GPUs and not supported on TPUs.\n\n\n\n\n\n\nImmutable arrays\n\nNumpyJAX NumPy\n\n\n\na = np.arange(5)\na[0] = 9\nprint(a)\n\n[9 1 2 3 4]\n\n\n\n\na = jnp.arange(5)\na[0] = 9\nTypeError: '&lt;class 'jaxlib.xla_extension.ArrayImpl'&gt;' object does not support item assignment. JAX arrays are immutable.\nb = a.at[0].set(9)\nprint(b)\n[9 1 2 3 4]\n\n\n\n\n\nStrict input control\n\nNumpyJAX NumPy\n\n\nNumPy is easy-going:\n\nnp.sum([1.0, 2.0])  # argument is a list\n\nnp.float64(3.0)\n\n\n\nnp.sum((1.0, 2.0))  # argument is a tuple\n\nnp.float64(3.0)\n\n\n\n\nTo avoid inefficiencies, JAX will only accept arrays:\njnp.sum([1.0, 2.0])\nTypeError: sum requires ndarray or scalar arguments, got &lt;class 'list'&gt;\njnp.sum((1.0, 2.0))\nTypeError: sum requires ndarray or scalar arguments, got &lt;class 'tuple'&gt;\n\n\n\n\n\nOut of bounds indexing\n\nNumpyJAX NumPy\n\n\nNumPy will error if you index out of bounds:\n\nprint(np.arange(5)[10])\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[10], line 1\n----&gt; 1 print(np.arange(5)[10])\n\nIndexError: index 10 is out of bounds for axis 0 with size 5\n\n\n\n\n\nJAX will silently return the closest boundary:\nprint(jnp.arange(5)[10])\n4\n\n\n\n\n\nPRNG\nTraditional pseudorandom number generators are based on nondeterministic state of OS.\nSlow and problematic for parallel executions.\nJAX relies on explicitly-set random state called a key:\nfrom jax import random\n\ninitial_key = random.PRNGKey(18)\nprint(initial_key)\n[ 0 18]\nEach key can only be used for one random function, but it can be split into new keys:\nnew_key1, new_key2 = random.split(initial_key)\n\ninitial_key can‚Äôt be used anymore now.\n\nprint(new_key1)\n[4197003906 1654466292]\nprint(new_key2)\n[1685972163 1654824463]\nWe need to keep one key to split whenever we need and we can use the other one.\nTo make sure we don‚Äôt reuse a key by accident, it is best to overwrite the initial key with one of the new ones.\nHere are easier names:\nkey = random.PRNGKey(18)\nkey, subkey = random.split(key)\nWe can now use subkey to generate a random array:\nx = random.normal(subkey, (3, 2))\n\n\nBenchmarking\nJAX uses asynchronous dispatch.\nInstead of waiting for a computation to complete before control returns to Python, the computation is dispatched to an accelerator and a future is created.\nTo get proper timings, we need to make sure the future is resolved by using the block_until_ready() method.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Accelerated array & AD",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/jx/wb_jax_content.html#jax-functioning",
    "href": "ai/jx/wb_jax_content.html#jax-functioning",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "JAX functioning",
    "text": "JAX functioning\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\n Just-in-time \n(JIT)\ncompilation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\n Transformations \n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\n Just-in-time \n(JIT)\ncompilation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\nVectorization\nParallelization\n ¬†¬†Differentiation ¬†\n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Accelerated array & AD",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/jx/wb_jax_content.html#jit-compilation",
    "href": "ai/jx/wb_jax_content.html#jit-compilation",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "JIT compilation",
    "text": "JIT compilation\n\nJIT syntax\nfrom jax import jit\n\nkey = random.PRNGKey(8)\nkey, subkey1, subkey2 = random.split(key, 3)\n\na = random.normal(subkey1, (500, 500))\nb = random.normal(subkey2, (500, 500))\n\ndef sum_squared_error(a, b):\n    return jnp.sum((a-b)**2)\nOur function could simply be used as:\nsse = sum_squared_error(a, b)\nOur code will run faster if we create a JIT compiled version and use that instead:\nsum_squared_error_jit = jit(sum_squared_error)\n\nsse = sum_squared_error_jit(a, b)\nAlternatively, this can be written as:\nsse = jit(sum_squared_error)(a, b)\nOr with the @jit decorator:\n@jit\ndef sum_squared_error(a, b):\n    return jnp.sum((a - b) ** 2)\n\nsse = sum_squared_error(a, b)\n\n\nStatic vs traced variables\n@jit\ndef cond_func(x):\n    if x &lt; 0.0:\n        return x ** 2.0\n    else:\n        return x ** 3.0\n\nprint(cond_func(1.0))\njax.errors.TracerBoolConversionError: Attempted boolean conversion of traced array with shape bool[]\nJIT compilation uses tracing of the code based on shape and dtype so that the same compiled code can be reused for new values with the same characteristics.\nTracer objects are not real values but abstract representation that are more general.\nHere, an abstract general value does not work as it wouldn‚Äôt know which branch to take.\nOne solution is to tell jit() to exclude the problematic arguments from tracing ‚Ä¶\n‚Ä¶ with arguments positions:\ndef cond_func(x):\n    if x &lt; 0.0:\n        return x ** 2.0\n    else:\n        return x ** 3.0\n\ncond_func_jit = jit(cond_func, static_argnums=(0,))\n\nprint(cond_func_jit(2.0))\nprint(cond_func_jit(-2.0))\n8.0\n4.0\n‚Ä¶ with arguments names:\ndef cond_func(x):\n    if x &lt; 0.0:\n        return x ** 2.0\n    else:\n        return x ** 3.0\n\ncond_func_jit_alt = jit(cond_func, static_argnames=\"x\")\n\nprint(cond_func_jit_alt(2.0))\nprint(cond_func_jit_alt(-2.0))\n8.0\n4.0\n\n\nControl flow primitives\nAnother solution, is to use one of the structured control flow primitives:\nfrom jax import lax\n\nlax.cond(False, lambda x: x ** 2.0, lambda x: x ** 3.0, jnp.array([2.]))\nArray([8.], dtype=float32)\nlax.cond(True, lambda x: x ** 2.0, lambda x: x ** 3.0, jnp.array([-2.]))\nArray([4.], dtype=float32)\nOther control flow primitives:\n\nlax.while_loop\nlax.fori_loop\nlax.scan\n\nOther pseudo dynamic control flow functions:\n\nlax.select (NumPy API jnp.where and jnp.select)\nlax.switch (NumPy API jnp.piecewise)\n\n\n\nStatic vs traced operations\nSimilarly, you can mark problematic operations as static so that they don‚Äôt get traced during JIT compilation:\n@jit\ndef f(x):\n    return x.reshape(jnp.array(x.shape).prod())\n\nx = jnp.ones((2, 3))\nprint(f(x))\nTypeError: Shapes must be 1D sequences of concrete values of integer type, got [Traced&lt;ShapedArray(int32[])&gt;with&lt;DynamicJaxprTrace(level=1/0)&gt;]\nThe problem here is that the shape of the argument to prod() depends on the value of x which is unknown at compilation time.\nOne solution is to use the NumPy version of prod():\nimport numpy as np\n\n@jit\ndef f(x):\n    return x.reshape((np.prod(x.shape)))\n\nprint(f(x))\n[1. 1. 1. 1. 1. 1.]",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Accelerated array & AD",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/jx/wb_jax_content.html#functionally-pure-functions",
    "href": "ai/jx/wb_jax_content.html#functionally-pure-functions",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "Functionally pure functions",
    "text": "Functionally pure functions\n\nJaxprs\nimport jax\n\nx = jnp.array([1., 4., 3.])\ny = jnp.array([8., 1., 2.])\n\ndef f(x, y):\n    return 2 * x**jax.make_jaxpr(f)(x, y) \n{ lambda ; a:f32[3] b:f32[3]. let\n    c:f32[3] = integer_pow[y=2] a\n    d:f32[3] = mul 2.0 c\n    e:f32[3] = add d b\n  in (e,) }\n\n\nOutputs only based on inputs\ndef f(x):\n    return a + x\nf uses the variable a from the global environment.\nThe output does not solely depend on the inputs: not a pure function.\na = jnp.ones(3)\nprint(a)\n[1. 1. 1.]\ndef f(x):\n    return print(jit(f)(jnp.ones(3)))\n[2. 2. 2.]\n\nThings seem ok here because this is the first run (tracing).\n\nNow, let‚Äôs change the value of a to an array of zeros:\na = jnp.zeros(3)\nprint(a)\n[0. 0. 0.]\nAnd rerun the same code:\nprint(jit(f)(jnp.ones(3)))\n[2. 2. 2.]\n\nOur cached compiled program is run and we get a wrong result.\n\nThe new value for a will only take effect if we re-trigger tracing by changing the shape and/or dtype of x:\na = jnp.zeros(4)\nprint(a)\n[0. 0. 0. 0.]\nprint(jit(f)(jnp.ones(4)))\n[1. 1. 1. 1.]\nPassing to f() an argument of a different shape forced retracing.\n\n\nNo side effects\nSide effects: anything beside returned output.\nExamples:\n\nPrinting to standard output\nReading from file/writing to file\nModifying a global variable\n\nThe side effects will happen during tracing, but not on subsequent runs. You cannot rely on side effects in your code.\ndef f(a, b):\n    print(\"Calculating sum\")\n    return print(jit(f)(jnp.arange(3), jnp.arange(3)))\nCalculating sum\n[0 2 4]\n\nPrinting happened here because this is the first run.\n\nLet‚Äôs rerun the function:\nprint(jit(f)(jnp.arange(3), jnp.arange(3)))\n[0 2 4]\nThis time, no printing.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Accelerated array & AD",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/jx/wb_jax_content.html#other-transformations",
    "href": "ai/jx/wb_jax_content.html#other-transformations",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "Other transformations",
    "text": "Other transformations\n\nAutomatic differentiation\nConsidering the function f:\nf = lambda x: x**3 + 2*x**2 - 3*x + 8\nWe can create a new function dfdx that computes the gradient of f w.r.t. x:\nfrom jax import grad\n\ndfdx = grad(f)\ndfdx returns the derivatives.\nprint(dfdx(1.))\n4.0\n\n\nComposing transformations\nTransformations can be composed:\nprint(jit(grad(f))(1.))\n4.0\nprint(grad(jit(f))(1.))\n4.0\n\n\nForward and reverse modes\nOther autodiff methods:\n\nReverse-mode vector-Jacobian products: jax.vjp\nForward-mode Jacobian-vector products: jax.jvp\n\n\n\nHigher-order differentiation\nWith a single variable, the grad function calls can be nested:\nd2fdx = grad(dfdx)   # function to compute 2nd order derivatives\nd3fdx = grad(d2fdx)  # function to compute 3rd order derivatives\n...\nWith several variables:\n\njax.jacfwd for forward-mode\njax.jacrev for reverse-mode\n\n\n\nPytrees\nJAX has a nested container structure: pytree extremely useful for DNN.\n\n\nVectorization and parallelization\nOther transformations for parallel run of computations across batches of arrays:\n\nAutomatic vectorization with jax.vmap\nParallelization across devices with jax.pmap",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Accelerated array & AD",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/jx/wb_jax_content.html#pushing-optimizations-further",
    "href": "ai/jx/wb_jax_content.html#pushing-optimizations-further",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "Pushing optimizations further",
    "text": "Pushing optimizations further\n\nLax API\njax.numpy is a high-level NumPy-like API wrapped around jax.lax.\njax.lax is a more efficient lower-level API itself wrapped around XLA.\n\n\nPallas: extension to write GPU and TPU kernels\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\n Just-in-time \n(JIT)\ncompilation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\ntriton\n\nTriton\n\n\n\nGPU\n\nGPU\n\n\n\ntriton-&gt;GPU\n\n\n\n\n\nmosaic\n\nMosaic\n\n\n\nTPU\n\nTPU\n\n\n\nmosaic-&gt;TPU\n\n\n\n\n\ntransform\n\nVectorization\nParallelization\n ¬†¬†Differentiation ¬†\n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;triton\n\n\n\n\nhlo-&gt;mosaic",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Accelerated array & AD",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/jx/jx_why.html",
    "href": "ai/jx/jx_why.html",
    "title": "Why JAX?",
    "section": "",
    "text": "There are many excellent and popular deep learning frameworks already (e.g.¬†PyTorch). So why did Google‚Äîalready behind the successful TensorFlow project‚Äîstart developing JAX?\nIn this section, we will look at the advantages brought by JAX‚Äînamely speed and flexible automatic differentiation.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Why JAX?"
    ]
  },
  {
    "objectID": "ai/jx/jx_why.html#what-is-jax",
    "href": "ai/jx/jx_why.html#what-is-jax",
    "title": "Why JAX?",
    "section": "What is JAX?",
    "text": "What is JAX?\nJAX is a library for Python developed by Google. Its key data structure is the array. It can perform composition, transformation, and differentiation of numerical programs as well as compilation for CPUs, GPUs, and TPUs.\nIt comes with a NumPy-like API as well as a lower-level API called lax. While the NumPy-like API looks familiar to NumPy users, JAX requires strict functional programming (i.e.¬†functions should only depend on their inputs and should only return outputs).",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Why JAX?"
    ]
  },
  {
    "objectID": "ai/jx/jx_why.html#a-relatively-new-project",
    "href": "ai/jx/jx_why.html#a-relatively-new-project",
    "title": "Why JAX?",
    "section": "A relatively new project",
    "text": "A relatively new project\nIt is clear that JAX is not a widely adopted project yet.\n\nTrends of Google searches\n\n\n\nAs of October 16, 2023.\n\n\n\n\n\nTrends of Stack Overflow tags\n\n\n\nAs of October 16, 2023.\n\n\n\nSo why JAX?",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Why JAX?"
    ]
  },
  {
    "objectID": "ai/jx/jx_why.html#jax-is-fast",
    "href": "ai/jx/jx_why.html#jax-is-fast",
    "title": "Why JAX?",
    "section": "JAX is fast",
    "text": "JAX is fast\nJAX was built with performance in mind. Its speed relies on design decisions at all levels.\n\nDefault data type\nLike PyTorch‚Äîa popular deep learning library‚ÄîJAX uses float32 as its default data type. This level of precision is perfectly suitable for deep learning and increases efficiency (by contrast, NumPy defaults to float64).\nJIT compilation\nJIT compilation combines computations, avoids the allocation of memory to temporary objects, and more generally optimizes code for the XLA.\nAccelerators\nThe same code can run on CPUs or on accelerators (GPUs and TPUs).\nXLA optimization\nXLA (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra that takes JIT-compiled JAX programs and optimizes them for the available hardware (CPUs, GPUs, or TPUs).\nAsynchronous dispatch\nComputations are executed on the accelerators asynchronously.\nVectorization, data parallelism, and sharding\nAll levels of shared and distributed memory parallelism are supported in JAX.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Why JAX?"
    ]
  },
  {
    "objectID": "ai/jx/jx_why.html#flexible-differentiation",
    "href": "ai/jx/jx_why.html#flexible-differentiation",
    "title": "Why JAX?",
    "section": "Flexible differentiation",
    "text": "Flexible differentiation\nAutomatic differentiation (autodiff or AD) is the evaluation by computer programs of the partial derivatives of functions. It is a key part of deep learning since training a model mostly consists of updating its weights and biases to decrease some loss function and this is done thanks to various gradient-based optimizations.\nSeveral implementations have been developed by different teams over time. This post by Chris Rackauckas summarizes the trade-offs of the various strategies.\nRemoving Julia (which by the way has a lot to offer in the field of AD) and PyTorch‚Äôs stale attempt at JIT compilation, Chris Rackauckas‚Äô post can be summarized this way:\n\n\n\n\n\n\n\n\n\n01\n\n\nAutodiff method\n\n\n\n1\nStatic graph\nand XLA\n\n\n\n\n02\n\n\nFramework\n\n\n\n\n2\nDynamic graph\n\n\n\n1-&gt;2\n\n\n\n\n\na\n\nTensorFlow\n\n\n\n\n4\nDynamic graph\nand XLA\n\n\n\n2-&gt;4\n\n\n\n\n\nb\n\nPyTorch\n\n\n\n\n5\nPseudo-dynamic\nand XLA\n\n\n\n4-&gt;5\n\n\n\n\n\nd\n\nTensorFlow2\n\n\n\n\ne\n\nJAX\n\n\n\n\n\n03\n\n\nAdvantage\n\n\n\n\n\n7\nMostly\noptimized AD\n\n\n\n\n\n8\nConvenient\n\n\n\n\n\n9\nConvenient\n\n\n\n\n10\nConvenient and\nmostly optimized AD\n\n\n\n\n\n04\n\n\nDisadvantage\n\n\n\n\n\nA\nManual writing of IR\n\n\n\n\n\nB\nLimited AD optimization\n\n\n\n\n\nD\nDisappointing speed\n\n\n\n\nE\nPure functions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTensorFlow‚Äôs initial approach with static computational graphs in a domain-specific language‚Äîwhile efficient thanks to the intermediate representation (IR) and XLA‚Äîwas inconvenient, limited, and hard to debug. Mostly, users had to write the IR themselves.\nPyTorch came with dynamic graphs‚Äîan approach so much more convenient that it marked the beginning of the decline of TensorFlow. The operations are stored during the forward pass which allows for easy automatic differentiation. However this ‚Äúper value‚Äù AD does not allow for a lot of optimizations.\nTensorFlow2 tried to bring dynamic graphs, but it was a poor match for the XLA.\nThis leaves room for new strategies. Julia offers several promising approaches, but implementations are not straightforward and projects are not always mature. It is an exciting avenue for developers, not necessarily an easy one for end users.\nJAX is another attempt at bringing both optimization and flexibility to autodiff. With Google behind it, it is a new but fast growing project.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Why JAX?"
    ]
  },
  {
    "objectID": "ai/jx/jx_pytree.html",
    "href": "ai/jx/jx_pytree.html",
    "title": "Pytrees",
    "section": "",
    "text": "It is convenient to store data, model parameters, gradients, etc. in container structures such as lists or dicts. JAX has a container-like structure, the pytree that is flexible, can be nested, and is supported by many JAX functions, making for convenient workflows.\nThis section introduces pytrees and their functioning.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Pytrees"
    ]
  },
  {
    "objectID": "ai/jx/jx_pytree.html#a-tree-like-structure",
    "href": "ai/jx/jx_pytree.html#a-tree-like-structure",
    "title": "Pytrees",
    "section": "A tree-like structure",
    "text": "A tree-like structure\nThe pytree container registry contains, by default, lists, tuples, and dicts. It can be extended to other containers.\nObjects in the pytree container registry are pytrees. Other objects are leaf pytrees (so pytrees are recursive).\nPytrees are great for holding data and parameters, keeping everything organized, even for complex models. The leaves are usually made of arrays. Many JAX functions can be applied to pytrees.\n\nExamples of pytrees:\n\n(1, 2, 3),\n[1, 1., \"string\", True],\njnp.arange(2),\n{'key1': 3.4, 'key2': 6.},\n[3., (1, 2), {'key1': 'val1', 'key2': 'val2', 'key3': 'val3'}],\n(3, 2, (6, 0), 2, ()),\njnp.zeros(3)\n\n\n\n\n\n\nNoteCluster setup\n\n\n\n\n\nLet‚Äôs kill our previous interactive job with a GPU:\nexit\nThen start an interactive job with a CPU:\nsalloc --time=2:0:0 --mem-per-cpu=5500M\nLoad the ipython module:\nmodule load ipython-kernel/3.11\nActivate the virtual python environment:\nsource /project/60055/env/bin/activate\nLaunch IPython:\nipython",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Pytrees"
    ]
  },
  {
    "objectID": "ai/jx/jx_pytree.html#extracting-leaves",
    "href": "ai/jx/jx_pytree.html#extracting-leaves",
    "title": "Pytrees",
    "section": "Extracting leaves",
    "text": "Extracting leaves\nTrees can be flattened and their leaves extracted into a list with jax.tree.leaves:\njax.tree.leaves([3., (1, 2), {'key1': 'val1', 'key2': 'val2', 'key3': 'val3'}])\n[3.0, 1, 2, 'val1', 'val2', 'val3']\nLet‚Äôs create a list of pytrees and extract their leaves to look at more examples:\nimport jax\nimport jax.numpy as jnp\n\nlist_trees = [\n    (1, 2, 3),\n    [1, 1., \"string\", True],\n    jnp.arange(2),\n    {'key1': 3.4, 'key2': 6.},\n    [3., (1, 2), {'key1': 'val1', 'key2': 'val2', 'key3': 'val3'}],\n    (3, 2, (6, 0, 9), 2, ()),\n    jnp.zeros(3)\n    ]\n\nfor pytree in list_trees:\n  leaves = jax.tree.leaves(pytree)\n  print(f\"{len(leaves)} leaves: {leaves}\")\n3 leaves: [1, 2, 3]\n4 leaves: [1, 1.0, 'string', True]\n1 leaves: [Array([0, 1], dtype=int32)]\n2 leaves: [3.4, 6.0]\n6 leaves: [3.0, 1, 2, 'val1', 'val2', 'val3']\n5 leaves: [3, 2, 6, 0, 9, 2]\n1 leaves: [Array([0., 0., 0.], dtype=float32)]\n\nBe careful that leaves are not the same as container elements:\n\nwhile an array contains many elements, it is a single leaf,\nwhile a nested list or tuple represent a single element of the parent container, all the elements of nested tuples and lists are leaves,\nan empty tuple or list is a pytree without children and is not counted as a leaf.\n\nContrast this with the length (i.e.¬†the number of elements of containers):\nfor pytree in list_trees:\n  print(f\"{len(pytree)} elements\")\n3 elements\n4 elements\n2 elements\n2 elements\n3 elements\n5 elements\n3 elements",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Pytrees"
    ]
  },
  {
    "objectID": "ai/jx/jx_pytree.html#structure-of-pytrees",
    "href": "ai/jx/jx_pytree.html#structure-of-pytrees",
    "title": "Pytrees",
    "section": "Structure of pytrees",
    "text": "Structure of pytrees\nAs we just saw, JAX can extract the leaves of pytrees. This is useful to run functions on them. But JAX also records their structure and is able to recreate them. The structure can be obtained with jax.tree.structure:\njax.tree.structure([3., (1, 2), {'key1': 'val1', 'key2': 'val2', 'key3': 'val3'}])\nPyTreeDef([*, (*, *), {'key1': *, 'key2': *, 'key3': *}])\nSo each pytree can be turned into a tuple of the list of its leaves and its structure and that tuple can be turned back into the pytree.\njax.tree.flatten([3., (1, 2), {'key1': 'val1', 'key2': 'val2', 'key3': 'val3'}])\n([3.0, 1, 2, 'val1', 'val2', 'val3'],\n PyTreeDef([*, (*, *), {'key1': *, 'key2': *, 'key3': *}]))\nvalues, structure = jax.tree.flatten(\n    [3., (1, 2), {'key1': 'val1', 'key2': 'val2', 'key3': 'val3'}]\n)\njax.tree.unflatten(structure, values)\n[3.0, (1, 2), {'key1': 'val1', 'key2': 'val2', 'key3': 'val3'}]\nThe path to each leaf can be obtained with jax.tree_util.tree_flatten_with_path:\njax.tree_util.tree_flatten_with_path(\n    [3., (1, 2), {'key1': 'val1', 'key2': 'val2', 'key3': 'val3'}]\n)\n([((SequenceKey(idx=0),), 3.0),\n  ((SequenceKey(idx=1), SequenceKey(idx=0)), 1),\n  ((SequenceKey(idx=1), SequenceKey(idx=1)), 2),\n  ((SequenceKey(idx=2), DictKey(key='key1')), 'val1'),\n  ((SequenceKey(idx=2), DictKey(key='key2')), 'val2'),\n  ((SequenceKey(idx=2), DictKey(key='key3')), 'val3')],\n PyTreeDef([*, (*, *), {'key1': *, 'key2': *, 'key3': *}]))",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Pytrees"
    ]
  },
  {
    "objectID": "ai/jx/jx_pytree.html#pytree-operations",
    "href": "ai/jx/jx_pytree.html#pytree-operations",
    "title": "Pytrees",
    "section": "Pytree operations",
    "text": "Pytree operations\nJAX can run operations on pytrees. Let‚Äôs create a few pytrees to play with:\ntree1 = {'key1': 1., 'key2': 2., 'key3': 3.}\ntree2 = {'key1': 4., 'key2': 5., 'key3': 6.}\ntree3 = {'key1': 7., 'key2': 8., 'key3': 9.}\njax.tree.map allows to apply functions to each leaf of a tree:\njax.tree.map(lambda x: 3 * x, tree1)\n{'key1': 3.0, 'key2': 6.0, 'key3': 9.0}\nAs long as pytrees share the same structure (including the same dicts keys), operations combining multiple pytrees also work:\njax.tree.map(lambda x, y, z: x * y + z, tree1, tree2, tree3)\n{'key1': 11.0, 'key2': 18.0, 'key3': 27.0}\nHere are a few more examples:\ntree4 = [[1, 1, 1], (2, 2, 2, 2), 3]\ntree5 = [[0, 5, 1], (2, 2, 2, 2), 3]\ntree6 = [[0, 5, 1, 2], (2, 2, 2), 3]\njax.tree.map(lambda x, y: x + y, tree4, tree5)\n[[1, 6, 2], (4, 4, 4, 4), 6]\nThis won‚Äôt work though as the structures are different:\njax.tree.map(lambda x, y: x + y, tree5, tree6)\nValueError: Tuple arity mismatch: 3 != 4; tuple: (2, 2, 2).",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Pytrees"
    ]
  },
  {
    "objectID": "ai/jx/jx_pytree.html#pytree-transposition",
    "href": "ai/jx/jx_pytree.html#pytree-transposition",
    "title": "Pytrees",
    "section": "Pytree transposition",
    "text": "Pytree transposition\nA list of pytrees can be transposed into a pytree of lists.\nLet‚Äôs create a list with a few of our previous pytrees:\ntrees = [tree1, tree2, tree3]\nprint(trees)\n[{'key1': 1.0, 'key2': 2.0, 'key3': 3.0}, {'key1': 1.0, 'key2': 2.0, 'key3': 3.0}, {'key1': 1.0, 'key2': 2.0, 'key3': 3.0}]\nHere is how to transpose this list of pytrees:\njax.tree.map(lambda *x: list(x), *trees)\n{'key1': [1.0, 1.0, 1.0], 'key2': [2.0, 2.0, 2.0], 'key3': [3.0, 3.0, 3.0]}",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Pytrees"
    ]
  },
  {
    "objectID": "ai/jx/jx_pytree.html#pytrees-in-nn",
    "href": "ai/jx/jx_pytree.html#pytrees-in-nn",
    "title": "Pytrees",
    "section": "Pytrees in NN",
    "text": "Pytrees in NN\nPytrees are very useful when using JAX for deep learning. Our course on DL with Flax will show this, but below is a basic example modified from the JAX documentation.\nimport jax\nimport jax.numpy as jnp\nfrom jax import random\nThe parameters of a multi-layer perceptron can be initialized with:\ndef init_params(layer_width):\n  params = []\n  key = random.PRNGKey(11)\n  key, subkey = random.split(key)\n  for n_in, n_out in zip(layer_width[:-1], layer_width[1:]):\n    params.append(\n        dict(weights=random.normal(subkey, (n_in, n_out)) * jnp.sqrt(2/n_in),\n             biases=jnp.ones(n_out)\n            )\n    )\n  return params\n\nparams = init_params([1, 128, 128, 1])\nparams is a pytree:\njax.tree.map(lambda x: x.shape, params)\n[{'biases': (128,), 'weights': (1, 128)},\n {'biases': (128,), 'weights': (128, 128)},\n {'biases': (1,), 'weights': (128, 1)}]\nTo train our MLP, we need to define a function for the forward pass:\n@jax.jit\ndef forward(params, x):\n  *hidden, last = params\n  for layer in hidden:\n    x = jax.nn.relu(x @ layer['weights'] + layer['biases'])\n  return x @ last['weights'] + last['biases']\nAnd a loss function:\n@jax.jit\ndef loss_fn(params, x, y):\n  return jnp.mean((forward(params, x) - y) ** 2)\nThen we choose a learning rate and define a function for the backpropagation:\nlr = 0.0001\n\n@jax.jit\ndef update(params, x, y):\n  grads = jax.grad(loss_fn)(params, x, y)\n  return jax.tree.map(\n      lambda p, g: p - lr * g, params, grads\n  )\n\nBecause jax.grad can accept pytrees, we can create a new pytree grads by passing the params pytree to it.\nThe gradient descent can be applied using both pytrees thanks to jax.tree.map.\n\nThen of course we could train our model:\nkey = random.PRNGKey(3)\nkey, subkey = random.split(key)\n\nx = random.normal(subkey, (128, 1))\ny = x ** 2\n\nfor _ in range(1000):\n  params = update(params, x, y)",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Pytrees"
    ]
  },
  {
    "objectID": "ai/jx/jx_pallas.html",
    "href": "ai/jx/jx_pallas.html",
    "title": "Pallas",
    "section": "",
    "text": "tracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\n Just-in-time \n(JIT)\ncompilation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\ntriton\n\nTriton\n\n\n\nGPU\n\nGPU\n\n\n\ntriton-&gt;GPU\n\n\n\n\n\nmosaic\n\nMosaic\n\n\n\nTPU\n\nTPU\n\n\n\nmosaic-&gt;TPU\n\n\n\n\n\ntransform\n\nVectorization\nParallelization\n ¬†¬†Differentiation ¬†\n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;triton\n\n\n\n\nhlo-&gt;mosaic"
  },
  {
    "objectID": "ai/jx/jx_numpy.html",
    "href": "ai/jx/jx_numpy.html",
    "title": "Relation to NumPy",
    "section": "",
    "text": "NumPy is a popular Python scientific API at the core of many libraries. JAX uses a NumPy-inspired API. There are however important differences that we will explore in this section.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Relation to NumPy"
    ]
  },
  {
    "objectID": "ai/jx/jx_numpy.html#a-numpy-inspired-api",
    "href": "ai/jx/jx_numpy.html#a-numpy-inspired-api",
    "title": "Relation to NumPy",
    "section": "A NumPy-inspired API",
    "text": "A NumPy-inspired API\nNumPy being so popular, JAX comes with a convenient high-level wrapper to NumPy: jax.numpy.\n\nBeing familiar with NumPy is thus an advantage to get started with JAX. The NumPy quickstart is a useful resource.\n\n\nFor a more efficient usage, JAX also comes with a lower-level API: jax.lax.\n\n\nNumPyJAX NumPy\n\n\n\nimport numpy as np\n\n\nprint(np.array([(1, 2, 3), (4, 5, 6)]))\n\n[[1 2 3]\n [4 5 6]]\n\n\n\nprint(np.zeros((2, 3)))\n\n[[0. 0. 0.]\n [0. 0. 0.]]\n\n\n\nprint(np.ones((2, 3, 2)))\n\n[[[1. 1.]\n  [1. 1.]\n  [1. 1.]]\n\n [[1. 1.]\n  [1. 1.]\n  [1. 1.]]]\n\n\n\nprint(np.arange(24).reshape(2, 3, 4))\n\n[[[ 0  1  2  3]\n  [ 4  5  6  7]\n  [ 8  9 10 11]]\n\n [[12 13 14 15]\n  [16 17 18 19]\n  [20 21 22 23]]]\n\n\n\nprint(np.linspace(0, 2, 9))\n\n[0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ]\n\n\n\nprint(np.linspace(0, 2, 9)[::-1])\n\n[2.   1.75 1.5  1.25 1.   0.75 0.5  0.25 0.  ]\n\n\n\n\nimport jax.numpy as jnp\nprint(jnp.array([(1, 2, 3), (4, 5, 6)]))\n[[1 2 3]\n [4 5 6]]\nprint(jnp.zeros((2, 3)))\n[[0. 0. 0.]\n [0. 0. 0.]]\nprint(jnp.ones((2, 3, 2)))\n[[[1. 1.]\n  [1. 1.]\n  [1. 1.]]\n\n [[1. 1.]\n  [1. 1.]\n  [1. 1.]]]\nprint(jnp.arange(24).reshape(2, 3, 4))\n[[[ 0  1  2  3]\n  [ 4  5  6  7]\n  [ 8  9 10 11]]\n\n [[12 13 14 15]\n  [16 17 18 19]\n  [20 21 22 23]]]\nprint(jnp.linspace(0, 2, 9))\n[0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ]\nprint(jnp.linspace(0, 2, 9)[::-1])\n[2.   1.75 1.5  1.25 1.   0.75 0.5  0.25 0.  ]\n\n\n\nDespite the similarities, there are important differences between JAX and NumPy.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Relation to NumPy"
    ]
  },
  {
    "objectID": "ai/jx/jx_numpy.html#differences-with-numpy",
    "href": "ai/jx/jx_numpy.html#differences-with-numpy",
    "title": "Relation to NumPy",
    "section": "Differences with NumPy",
    "text": "Differences with NumPy\n\nDifferent types\ntype(np.zeros((2, 3))) == type(jnp.zeros((2, 3)))\nFalse\n\nNumpyJAX NumPy\n\n\n\ntype(np.zeros((2, 3)))\n\nnumpy.ndarray\n\n\n\n\ntype(jnp.zeros((2, 3)))\njaxlib.xla_extension.ArrayImpl\n\n\n\n\n\nDifferent default data types\n\nNumpyJAX NumPy\n\n\n\nnp.zeros((2, 3)).dtype\n\ndtype('float64')\n\n\n\n\njnp.zeros((2, 3)).dtype\ndtype('float32')\n\n\n\n\nLower numerical precision improves speed and reduces memory usage at no cost while training neural networks and is thus a net benefit. Having been built with deep learning in mind, JAX defaults align with that of other DL libraries (e.g.¬†PyTorch, TensorFlow).\n\n\n\nImmutable arrays\n\nNumpyJAX NumPy\n\n\nIn NumPy, you can modify ndarrays:\n\na = np.arange(5)\na[0] = 9\nprint(a)\n\n[9 1 2 3 4]\n\n\n\n\nJAX arrays are immutable:\na = jnp.arange(5)\na[0] = 9\nTypeError: '&lt;class 'jaxlib.xla_extension.ArrayImpl'&gt;' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html\nInstead, you need to create a copy of the array with the mutation. This is done with:\nb = a.at[0].set(9)\nprint(b)\n[9 1 2 3 4]\nOf course, you can overwrite a:\na = a.at[0].set(9)\n\n\n\n\n\nPseudorandom number generation\nProgramming languages usually come with automated pseudorandom number generator (PRNG) based on nondeterministic data from the operating system. They are extremely convenient, but slow, based on repeats, and problematic in parallel executions.\nJAX relies on an explicitly set random state called a key.\nfrom jax import random\n\nkey = random.key(18)\nprint(key)\n[ 0 18]\nEach time you call a random function, you need a subkey split from your key. Keys should only ever be used once in your code. The key is what makes your code reproducible, but you don‚Äôt want to reuse it within your code as it would create spurious correlations.\nHere is the workflow:\n\nyou split your key into a new key and one or multiple subkeys,\nyou discard the old key (because it was used to do the split‚Äîso its entropy budget, so to speak, has been used),\nyou use the subkey(s) to run your random function(s) and keep the new key for a future split.\n\n\nSubkeys are of the same nature as keys. This is just a terminology.\n\nTo make sure not to reuse the old key, you can overwrite it by the new one:\nkey, subkey = random.split(key)\nprint(key)\n[4197003906 1654466292]\n\nThat‚Äôs the value of our new key for future splits.\n\nprint(subkey)\n[1685972163 1654824463]\n\nThis is the value of the subkey that we can use to call a random function.\n\nLet‚Äôs use that subkey now:\nprint(random.normal(subkey))\n1.1437175\n\nTo split your key into more subkeys, pass an argument to random.split:\nkey, subkey1, subkey2, subkey3 = random.split(key, 4)\n\n\n\nStrict input control\n\nNumpyJAX NumPy\n\n\nNumPy‚Äôs fundamental object is the ndarray, but NumPy is very tolerant as to the type of input.\n\nnp.sum([1.0, 2.0])  # here we are using a list\n\nnp.float64(3.0)\n\n\n\nnp.sum((1.0, 2.0))  # here is a tuple\n\nnp.float64(3.0)\n\n\n\n\nTo avoid inefficiencies, JAX will only accept arrays.\njnp.sum([1.0, 2.0])\nTypeError: sum requires ndarray or scalar arguments, got &lt;class 'list'&gt; at position 0.\njnp.sum((1.0, 2.0))\nTypeError: sum requires ndarray or scalar arguments, got &lt;class 'tuple'&gt; at position 0.\n\n\n\n\n\nOut of bounds indexing\n\nNumpyJAX NumPy\n\n\nNumPy will warn you with an error message if you try to index out of bounds:\n\nprint(np.arange(5)[10])\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[13], line 1\n----&gt; 1 print(np.arange(5)[10])\n\nIndexError: index 10 is out of bounds for axis 0 with size 5\n\n\n\n\n\nBe aware that JAX will not raise an error. Instead, it will silently return the closest boundary:\nprint(jnp.arange(5)[10])\n4\n\n\n\n\n\nFunctionally pure functions\nMore importantly, only functionally pure functions‚Äîthat is, functions for which the outputs are only based on the inputs and which have no side effects‚Äîcan be used with JAX.\n\nOutputs only based on inputs\nConsider the function:\ndef f(x):\n    return a + x\nwhich uses the variable a from the global environment.\nThis function is not functionally pure because the outputs (the results of the function) do not solely depend on the arguments (the values given to x) passed to it. They also depend on the value of a.\nRemember how tracing works: new inputs with the same shape and dtype use the cached compiled program directly. If the value of a changes in the global environment, a new tracing is not triggered and the cached compiled program uses the old value of a (the one that was used during tracing).\nIt is only if the code is run on an input x with a different shape and/or dtype that tracing happens again and that the new value for a takes effect.\n\nTo demo this, we need to use JIT compilation that we will explain in a later section.\n\nfrom jax import jit\n\na = jnp.ones(3)\nprint(a)\n[1. 1. 1.]\ndef f(x):\n    return a + x\n\nprint(jit(f)(jnp.ones(3)))\n[2. 2. 2.]\n\nAll good here because this is the first run (tracing).\n\nNow, let‚Äôs change the value of a to an array of zeros:\na = jnp.zeros(3)\nprint(a)\n[0. 0. 0.]\nAnd rerun the same code:\nprint(jit(f)(jnp.ones(3)))\n[2. 2. 2.]\nWe should have an array of ones, but we get the same result we got earlier. Why? because we are running a cached program with the value that a had during tracing.\nThe new value for a will only take effect if we re-trigger tracing by changing the shape and/or dtype of x:\na = jnp.zeros(4)\nprint(a)\n[0. 0. 0. 0.]\nprint(jit(f)(jnp.ones(4)))\n[1. 1. 1. 1.]\nPassing an argument of a different shape to f forced recompilation. Using a different data type (e.g.¬†with jnp.arange(3)) would have done the same.\n\n\nNo side effects\nA function is said to have a side effect if it changes something outside of its local environment (if it does anything beside returning an output).\nExamples of side effects include:\n\nprinting to standard output/shell,\nreading from file/writing to file,\nmodifying a global variable.\n\nIn JAX, the side effects will happen during the first run (tracing), but will not happen on subsequent runs. You thus cannot rely on side effects in your code.\ndef f(a, b):\n    print(\"Calculating sum\")\n    return a + b\n\nprint(jit(f)(jnp.arange(3), jnp.arange(3)))\nCalculating sum\n[0 2 4]\n\nPrinting (the side effect) happened here because this is the first run.\n\nLet‚Äôs rerun the function:\nprint(jit(f)(jnp.arange(3), jnp.arange(3)))\n[0 2 4]\nThis time, no printing.\n\nUnderstanding jaxprs\nJaxprs are created by tracers wrapping the Python code during compilation (the first run). They contain information on the shape and data type of arrays as well as the operations performed on these arrays. Jaxprs do not however contain information on values: this allows the compiled program to be general enough to be rerun with any new arrays of the same shape and data type without having to rerun the slow Python code and recompile.\nJaxprs also do not contain any information on elements that are not part of the inputs such as external variables, nor do they contain information on side effects.\nJaxprs can be visualized with the jax.make_jaxpr function:\nimport jax\n\nx = jnp.array([1., 4., 3.])\ny = jnp.array([8., 1., 2.])\n\ndef f(x, y):\n    return 2 * x**2 + y\n\njax.make_jaxpr(f)(x, y) \n{ lambda ; a:f32[3] b:f32[3]. let\n    c:f32[3] = integer_pow[y=2] a\n    d:f32[3] = mul 2.0 c\n    e:f32[3] = add d b\n  in (e,) }\nLet‚Äôs add a print function to f:\ndef f(x, y):\n    print(\"This is a function with side-effect\")\n    return 2 * x**2 + y\n\njax.make_jaxpr(f)(x, y)\n{ lambda ; a:f32[3] b:f32[3]. let\n    c:f32[3] = integer_pow[y=2] a\n    d:f32[3] = mul 2.0 c\n    e:f32[3] = add d b\n  in (e,) }\nThe jaxpr is exactly the same. This is why printing will happen during tracing (when the Python code is run), but not afterwards (when the compiled code using the jaxpr is run).",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Relation to NumPy"
    ]
  },
  {
    "objectID": "ai/jx/jx_numpy.html#why-the-constraints",
    "href": "ai/jx/jx_numpy.html#why-the-constraints",
    "title": "Relation to NumPy",
    "section": "Why the constraints?",
    "text": "Why the constraints?\nThe more constraints you add to a programming language, the more optimization you can get from the compiler. Speed comes at the cost of convenience.\nFor instance, consider a Python list. It is an extremely convenient and flexible object: heterogeneous, mutable‚Ä¶ You can do anything with it. But computations on lists are extremely slow.\nNumPy‚Äôs ndarrays are more constrained (homogeneous), but the type constraint permits the creation of a much faster language (NumPy is written in C and Fortran as well as Python) with vectorization, optimizations, and a greatly improved performance.\nJAX takes it further: by using an intermediate representation and very strict constraints on type, pure functional programming, etc., yet more optimizations can be achieved and you can optimize your own functions with JIT compilation and the XLA. Ultimately, this is what makes JAX so fast.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Relation to NumPy"
    ]
  },
  {
    "objectID": "ai/jx/jx_libraries.html",
    "href": "ai/jx/jx_libraries.html",
    "title": "Libraries built on JAX",
    "section": "",
    "text": "JAX is an efficient and flexible framework for array operations and program transformations (including automatic differentiation) built to run on accelerators. Its goal is not to develop specialized applications, but to focus on these chore tasks.\nWhile it is possible to use JAX directly in applications (e.g.¬†to build a NN from scratch), it makes sense to use specialized libraries that are built on top of JAX, make use of its characteristics, and provide convenience functions for specialized tasks.\nThe list of libraries built on JAX keeps growing, but here are a few of the currently important ones.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Libraries built on JAX"
    ]
  },
  {
    "objectID": "ai/jx/jx_libraries.html#neural-networks",
    "href": "ai/jx/jx_libraries.html#neural-networks",
    "title": "Libraries built on JAX",
    "section": "Neural networks",
    "text": "Neural networks\nFlax is an NN library initially developed by Google Brain and now by Google DeepMind. It is the deep learning library officially recommended by the JAX developers. This is the library that we will use in this course.\nEquinox is another DL library, relying on models as pytrees. While its syntax is a lot more user-friendly and familiar to PyTorch users, it has limitations.\nKeras can now use JAX as a backend.\n\nIt is worth noting that PyTorch is attempting to incorporate JAX‚Äôs ideas with a new library under development, functorch.\nHaiku was the initial library developed by Google DeepMind. While it is still maintained, development has been stopped in favour of Flax and it is thus not advisable to get started with it unless you are already using it.\n\nOptax is a gradient manipulation and optimization library developed by Google DeepMind.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Libraries built on JAX"
    ]
  },
  {
    "objectID": "ai/jx/jx_libraries.html#bayesian-statistics",
    "href": "ai/jx/jx_libraries.html#bayesian-statistics",
    "title": "Libraries built on JAX",
    "section": "Bayesian statistics",
    "text": "Bayesian statistics\nNumPyro and PyMC are probabilistic programming languages.\nBlackJAX is a library of samples.\nFor a basic and high-level introduction, you can have a look at our webinar on Bayesian inference in JAX.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Libraries built on JAX"
    ]
  },
  {
    "objectID": "ai/jx/jx_libraries.html#probabilistic-state-space-models",
    "href": "ai/jx/jx_libraries.html#probabilistic-state-space-models",
    "title": "Libraries built on JAX",
    "section": "Probabilistic state space models",
    "text": "Probabilistic state space models\nDynamax provides state and parameter estimation for, among others:\n\nhidden markov models,\nlinear gaussian state space models,\nnonlinear gaussian state space models,\ngeneralized gaussian state space models.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Libraries built on JAX"
    ]
  },
  {
    "objectID": "ai/jx/jx_jit.html",
    "href": "ai/jx/jx_jit.html",
    "title": "JIT compilation",
    "section": "",
    "text": "JIT compilation is a key component to JAX efficiency. For the most part, it is very easy to use, but there are subtleties to be aware of.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "JIT compilation"
    ]
  },
  {
    "objectID": "ai/jx/jx_jit.html#jit",
    "href": "ai/jx/jx_jit.html#jit",
    "title": "JIT compilation",
    "section": "JIT",
    "text": "JIT\nJAX functions are already compiled and optimized, but user functions can also be optimized for the XLA by JIT compilation which will combine computations.\nRemember the map of JAX functioning:\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxpr\n(JAX expression)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\nJIT\n compilation \n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\n Transformations \n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla\n\n\n\n\n\n\n\n\n\nThis is done by the jax.jit() function or the equivalent decorator @jit.\nLet‚Äôs consider this code:\nimport jax.numpy as jnp\nfrom jax import jit\nfrom jax import random\n\nkey = random.PRNGKey(8)\nkey, subkey1, subkey2 = random.split(key, 3)\n\na = random.normal(subkey1, (500, 500))\nb = random.normal(subkey2, (500, 500))\n\ndef sum_squared_error(a, b):\n    return jnp.sum((a-b)**2)\nOur function can simply be used as:\nprint(sum_squared_error(a, b))\nOur code will run faster if we create a JIT compiled version and use that instead (we will see how to benchmark JAX code later in the course. There are some subtleties for that too, so for now, just believe that it is faster. You will be able to test it later):\nsum_squared_error_jit = jit(sum_squared_error)\nprint(sum_squared_error_jit(a, b))\n502084.75\nAlternatively, this can be written as:\nprint(jit(sum_squared_error)(a, b))\n502084.75\nOr as:\n@jit\ndef sum_squared_error(a, b):\n    return jnp.sum((a - b) ** 2)\n\nprint(sum_squared_error(a, b))\n502084.75\n\nUnderstanding jaxprs\nLet‚Äôs have a look at the jaxpr of a jit-compiled function.\nThis is what the jaxpr of the non-jit-compiled function looks like:\nimport jax\n\ndef sum_squared_error(a, b):\n    return jnp.sum((a - b) ** 2)\n\njax.make_jaxpr(sum_squared_error)(x, y)\n{ lambda ; a:f32[3] b:f32[3]. let\n    c:f32[3] = sub a b\n    d:f32[3] = integer_pow[y=2] c\n    e:f32[] = reduce_sum[axes=(0,)] d\n  in (e,) }\nThe jaxpr of the jit-compiled function looks like this:\n@jit\ndef sum_squared_error(a, b):\n    return jnp.sum((a - b) ** 2)\n\njax.make_jaxpr(sum_squared_error)(x, y)\n{ lambda ; a:f32[3] b:f32[3]. let\n    c:f32[] = pjit[\n      name=sum_squared_error\n      jaxpr={ lambda ; d:f32[3] e:f32[3]. let\n          f:f32[3] = sub d e\n          g:f32[3] = integer_pow[y=2] f\n          h:f32[] = reduce_sum[axes=(0,)] g\n        in (h,) }\n    ] a b\n  in (c,) }",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "JIT compilation"
    ]
  },
  {
    "objectID": "ai/jx/jx_jit.html#jit-constraints",
    "href": "ai/jx/jx_jit.html#jit-constraints",
    "title": "JIT compilation",
    "section": "JIT constraints",
    "text": "JIT constraints\nUsing jit in the example above was very easy. There are situations however in which tracing will fail.\n\nControl flow\nOne example can arise with control flow:\n@jit\ndef cond_func(x):\n    if x &lt; 0.0:\n        return x ** 2.0\n    else:\n        return x ** 3.0\n\nprint(cond_func(1.0))\njax.errors.TracerBoolConversionError: Attempted boolean conversion of traced array with shape bool[]..\nThe error occurred while tracing the function cond_func at jx_jit.qmd:85 for jit. This concrete value was not available in Python because it depends on the value of the argument x.\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError\nJIT compilation uses tracing of the code based on shape and dtype so that the same compiled code can be reused for new values with the same characteristics. The tracer objects are not real values but abstract representation that are more general. In control flow situations such as the one we have here, an abstract general value does not work as it wouldn‚Äôt know which branch to take.\n\nStatic variables\nOne solution is to tell jit() to exclude the problematic arguments (in our example the argument: x) from tracing (i.e.¬†to consider them as static). Of course, those elements will not be optimized, but the rest of the code will, so it is a lot better than not JIT compiling the function at all.\nYou can either use the static_argnums parameter which takes an integer or a collection of integers to specify the position of the arguments to treat as static:\ndef cond_func(x):\n    if x &lt; 0.0:\n        return x ** 2.0\n    else:\n        return x ** 3.0\n\ncond_func_jit = jit(cond_func, static_argnums=(0,))\n\nprint(cond_func_jit(2.0))\nprint(cond_func_jit(-2.0))\n8.0\n4.0\nOr you can use static_argnames which accepts argument names:\ndef cond_func(x):\n    if x &lt; 0.0:\n        return x ** 2.0\n    else:\n        return x ** 3.0\n\ncond_func_jit_alt = jit(cond_func, static_argnames='x')\n\nprint(cond_func_jit_alt(2.0))\nprint(cond_func_jit_alt(-2.0))\n8.0\n4.0\nYou cannot use the @jit decorator when you need to pass arguments to the jit function, but you can still use a decorator:\nfrom functools import partial\n\n@partial(jit, static_argnums=(0,))\ndef cond_func(x):\n    if x &lt; 0.0:\n        return x ** 2.0\n    else:\n        return x ** 3.0\nor:\n@partial(jit, static_argnames=['x'])\ndef cond_func(x):\n    if x &lt; 0.0:\n        return x ** 2.0\n    else:\n        return x ** 3.0\n\n\nControl flow primitives\nIf you don‚Äôt want the code to recompile for each new value, another solution, is to use one of the structured control flow primitives:\nfrom jax import lax\n\nlax.cond(False, lambda x: x ** 2.0, lambda x: x ** 3.0, jnp.array([2.]))\nArray([8.], dtype=float32)\nlax.cond(True, lambda x: x ** 2.0, lambda x: x ** 3.0, jnp.array([-2.]))\nArray([4.], dtype=float32)\nThere are other control flow primitives:\n\nlax.while_loop\nlax.fori_loop\nlax.scan\n\nand other pseudo dynamic control flow functions:\n\nlax.select (NumPy API jnp.where and jnp.select)\nlax.switch (NumPy API jnp.piecewise)\n\n\n\n\nStatic operations\nSimilarly, you will need to mark problematic operations as static so that they don‚Äôt get traced during JIT compilation:\n@jit\ndef f(x):\n    return x.reshape(jnp.array(x.shape).prod())\n\nx = jnp.ones((2, 3))\nprint(f(x))\nTypeError: Shapes must be 1D sequences of concrete values of integer type, got [Traced&lt;ShapedArray(int32[])&gt;with&lt;DynamicJaxprTrace(level=1/0)&gt;].\nIf using `jit`, try using `static_argnums` or applying `jit` to smaller subfunctions.\nThe problem here is that the shape of the argument to jnp.reshape is traced while it needs to be static.\nOne solution is to use the NumPy version of prod which will not create a traced result:\nimport numpy as np\n\n@jit\ndef f(x):\n    return x.reshape(np.prod(x.shape))\n\nprint(f(x))\n[1. 1. 1. 1. 1. 1.]",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "JIT compilation"
    ]
  },
  {
    "objectID": "ai/jx/jx_benchmark.html",
    "href": "ai/jx/jx_benchmark.html",
    "title": "Benchmarking JAX code",
    "section": "",
    "text": "You have to be careful when benchmarking JAX code to actually measure the computation time and not the dispatch time.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Benchmarking JAX code"
    ]
  },
  {
    "objectID": "ai/jx/jx_benchmark.html#asynchronous-dispatch",
    "href": "ai/jx/jx_benchmark.html#asynchronous-dispatch",
    "title": "Benchmarking JAX code",
    "section": "Asynchronous dispatch",
    "text": "Asynchronous dispatch\nOne of the efficiencies of JAX is its use of asynchronous execution.\nLet‚Äôs consider the code:\nimport jax.numpy as jnp\nfrom jax import random\n\nkey = random.PRNGKey(11)\nkey, subkey1, subkey2 = random.split(key, 3)\n\nx = random.normal(subkey1, (1000, 1000))\ny = random.normal(subkey2, (1000, 1000))\n\nz = jnp.dot(x, y)\nInstead of having to wait for the computation to complete before control returns to Python, this computation is dispatched to an accelerator and a future is created. This future is a jax.Array and can be passed to further computations immediately.\nOf course, if you print the result or convert it to a NumPy ndarray, JAX forces Python to wait for the result of the computation.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Benchmarking JAX code"
    ]
  },
  {
    "objectID": "ai/jx/jx_benchmark.html#consequence-for-benchmarking",
    "href": "ai/jx/jx_benchmark.html#consequence-for-benchmarking",
    "title": "Benchmarking JAX code",
    "section": "Consequence for benchmarking",
    "text": "Consequence for benchmarking\nTiming jnp.dot(x, y) would not give us the time it takes for the computation to take place, but the time it takes to dispatch the computation.\nOn my laptop which has one dedicated GPU I get:\n%timeit jnp.dot(x, y)\n496 ¬µs ¬± 948 ns per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)\n\n%timeit is an IPython built-in magic command. In Python, you would have to use the timeit module.\n\nTo get a proper timing, we need to make sure that the future is resolved using the block_until_ready method:\nOn the same machine:\n%timeit jnp.dot(x, y).block_until_ready()\n598 ¬µs ¬± 10.4 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)\nThe difference here is not huge because the GPU executes the matrix multiplication rapidly. Nevertheless, this is the true timing. If you benchmark your JAX code, make sure to do it this way.\n\nIf you are running small computations such as this one without accelerator, the computation will be dispatched on the thread running the Python process because the overhead of the asynchronous execution would be larger than the speedup you would gain from it. This means that, if you are running the above code on CPUs, you should get the same time with and without block_until_ready.\nNevertheless, because it is difficult to predict when the dispatch will be asynchronous, you should always use block_until_ready in your benchmarks.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Benchmarking JAX code"
    ]
  },
  {
    "objectID": "ai/jx/jx_accelerator.html",
    "href": "ai/jx/jx_accelerator.html",
    "title": "Accelerators",
    "section": "",
    "text": "One of the efficiencies of JAX is its use of accelerators. In this section, we can see how easily this is done.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Accelerators"
    ]
  },
  {
    "objectID": "ai/jx/jx_accelerator.html#auto-detection",
    "href": "ai/jx/jx_accelerator.html#auto-detection",
    "title": "Accelerators",
    "section": "Auto-detection",
    "text": "Auto-detection\nOne of the convenience of the XLA used by JAX (and TensorFlow) is that the same code runs on any device without modification.\n\nThis is in contrast with PyTorch where tensors are created on the CPU by default and can be moved to the GPU using the .to method.\nOr tensors need to be created explicitly on a device (e.g.¬†for GPU, x = torch.ones(2, 4, device='cuda')).\nAlternatively, the code can be made more robust with the creation of a device handle which will allow it to run without modification on CPU or GPU:\nimport torch\n\ndevice = (\n    \"cuda\"\n    if torch.cuda.is_available()\n    else \"mps\"\n    if torch.backends.mps.is_available()\n    else \"cpu\"\n)\n\nx = torch.ones(2, 4, device=device)\n\nMPS = Apple Metal Performance Shaders (GPU on macOS).\n\nAnd there are methods to run PyTorch on TPU with the torch_xla package, with tricks of scalability.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Accelerators"
    ]
  },
  {
    "objectID": "ai/jx/jx_accelerator.html#interactive-job-with-a-gpu",
    "href": "ai/jx/jx_accelerator.html#interactive-job-with-a-gpu",
    "title": "Accelerators",
    "section": "Interactive job with a GPU",
    "text": "Interactive job with a GPU\nThe Alliance wiki documents how to use GPUs on Alliance clusters.\nFor now, let‚Äôs relinquish our current interactive job. It is important not to run nested jobs by running salloc inside a running job.\nKill the current job by running (from Bash, not from ipython):\nexit\nThen, start an interactive job with a GPU:\nsalloc --time=1:0:0 --gpus-per-node=1 --mem=22000M\nReload the ipython module:\nmodule load ipython-kernel/3.11\nRe-activate the virtual python environment:\nsource /project/60055/env/bin/activate\nFinally, relaunch IPython:\nipython",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Accelerators"
    ]
  },
  {
    "objectID": "ai/jx/jx_accelerator.html#effect-on-timing",
    "href": "ai/jx/jx_accelerator.html#effect-on-timing",
    "title": "Accelerators",
    "section": "Effect on timing",
    "text": "Effect on timing\nHere is an example of the difference that a GPU makes compared to CPUs for a simple computation.\nThe following times are on my laptop which has one dedicated GPU.\nFirst, let‚Äôs set things up:\nimport jax. numpy as jnp\nfrom jax import random, device_put\nimport numpy as np\n\nseed = 0\nkey = random.PRNGKey(seed)\nkey, subkey = random.split(key)\n\nsize = 3000\nNow, let‚Äôs time a dot product of two arrays using NumPy (which only uses CPUs):\nx_np = np.random.normal(size=(size, size)).astype(np.float32)\n%timeit np.dot(x_np, x_np.T)\n58.6 ms ¬± 2.67 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)\nWe can use the NumPy ndarrays in a JAX dot product function:\n%timeit jnp.dot(x_np, x_np.T).block_until_ready()\n31.1 ms ¬± 1.82 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)\n\nRemember that whenever you benchmark JAX computations, you need to use the block_until_ready method, due to asynchronous dispatch, to ensure that you are timing the computation and not the creation of a future.\n\nIf you want to use NumPy ndarrays in JAX and you have accelerators available, a much better approach is to transfer them to the accelerators with the device_put method:\nx_to_gpu = device_put(x_np)\n%timeit jnp.dot(x_to_gpu, x_to_gpu.T).block_until_ready()\n13.2 ms ¬± 27.9 ¬µs per loop (mean ¬± std. dev. of 7 runs, 100 loops each)\nThis is much faster and similar to the full JAX code would be:\nx_jx = random.normal(key, (size, size), dtype=jnp.float32)\n\n%timeit jnp.dot(x_jx, x_jx.T).block_until_ready()\n13.3 ms ¬± 33.3 ¬µs per loop (mean ¬± std. dev. of 7 runs, 100 loops each)",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Accelerators"
    ]
  },
  {
    "objectID": "ai/fl/fl_training.html",
    "href": "ai/fl/fl_training.html",
    "title": "Training the model",
    "section": "",
    "text": "We talked about how Flax handles state, about loading data, and about model architecture. It is now time to talk about training.\nTraining models is the crux of deep learning. This is the part that requires a lot of time and resources (and money if you use commercial cloud services). This is also where issues with convergence, underfitting or overfitting, and vanishing or exploding gradients can come in.\nConsequently, this is where optimizations and JAX‚Äôs performance tricks (e.g.¬†JIT compilation) matter the most. This is also where understanding of deep learning theory is important.\nIn this section, we will point to strategies and resources to navigate training. We will also see how to use the Alliance clusters to train your models."
  },
  {
    "objectID": "ai/fl/fl_training.html#cluster-setup",
    "href": "ai/fl/fl_training.html#cluster-setup",
    "title": "Training the model",
    "section": "Cluster setup",
    "text": "Cluster setup\nFirst, let‚Äôs start an interactive job:\nsalloc --time=30 --mem-per-cpu=3500M\nNowadays, IPython (Interactive Python) is known as the kernel used by Jupyter when running Python. Before the existence of Jupyter however, this kernel was created as a better command shell than the default Python shell. For interactive Python sessions in the command line, it is nicer and faster than plain Python with no downside. So we will use it for this course:\nmodule load ipython-kernel/3.11\nNow, let‚Äôs activate the virtual python environment:\nsource /project/60055/env/bin/activate\nFinally, we can launch IPython:\nipython\nThen let‚Äôs rerun our model architecture and initialization of the pytree of model parameters from last course:\nimport jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\n\n\nclass CNN(nn.Module):\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n        x = nn.relu(x)\n        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n        x = nn.relu(x)\n        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n        x = x.reshape((x.shape[0], -1))\n        x = nn.Dense(features=256)(x)\n        x = nn.relu(x)\n        x = nn.Dense(features=10)(x)\n        x = nn.log_softmax(x)\n        return x\n\n\ncnn = CNN()\n\n\ndef get_initial_params(key):\n    init_shape = jnp.ones((1, 28, 28, 1))\n    initial_params = cnn.init(key, init_shape)\n    return initial_params\n\n\nkey = jax.random.key(0)\nkey, model_key = jax.random.split(key)\n\nparams = get_initial_params(model_key)"
  },
  {
    "objectID": "ai/fl/fl_training.html#fundamental-functioning",
    "href": "ai/fl/fl_training.html#fundamental-functioning",
    "title": "Training the model",
    "section": "Fundamental functioning",
    "text": "Fundamental functioning\n\nCalculate predictions\nWe can create some random inputs:\nkey, x_key = jax.random.split(key)\n\nx = jax.random.normal(x_key, (1, 28, 28, 1))\nThe predictions of our model based on these inputs are obtained by:\ny = cnn.apply(params, x)\nprint(y)\n\n\nUpdate parameters\nOptax‚Äîanother library built on JAX‚Äîis a full toolkit for gradient processing and optimization. It contains all the classic optimizers and loss functions and makes it easy to create your own optimizers and optimizer schedulers. Flax initially used its own optimizers but has now fully adopted use of Optax.\nHere is the most basic case:\nimport optax\n\nlearning_rate = 1e-1\noptimiser = optax.sgd(learning_rate)\nprint(optimiser)\nThe optimizer is a gradient transformation. It is a tuple of an init and an update methods. Those are pure functions following the model of JAX and Flax. This means that they are stateless and that a state needs to be initialized and passed as input, exactly as we saw for Flax models.\nLet‚Äôs initialize the optimizer state:\noptimiser_state = optimiser.init(params)\nThe update method returns a gradient transformation (that we can later apply to the gradients) and an updated optimizer state.\nThe gradients are calculated by passing a loss function to jax.grad and passing the parameters, the inputs, and the predictions to this transformed function (the derivative):\ngrads = jax.grad(&lt;some-loss-function&gt;)(params, x, y)\nThe loss function can be built from a large array of Optax loss methods.\nHere is how to use optimizer.update:\nupdates, optimiser_state = optimiser.update(grads, optimiser_state, params)"
  },
  {
    "objectID": "ai/fl/fl_training.html#key-regularizations",
    "href": "ai/fl/fl_training.html#key-regularizations",
    "title": "Training the model",
    "section": "Key regularizations",
    "text": "Key regularizations\nFlax makes it easy to apply classic regularizations and optimization techniques.\nBatch normalization improves convergence speed and has been a classic regularization technique since the publication of Sergey Ioffe and Christian Szegedy‚Äôs key paper in 2015. You can use it by adding a flax.linen.BatchNorm layer to your model.\nSimilarly, dropout techniques are implemented with a flax.linen.Dropout layer."
  },
  {
    "objectID": "ai/fl/fl_training.html#getting-started",
    "href": "ai/fl/fl_training.html#getting-started",
    "title": "Training the model",
    "section": "Getting started",
    "text": "Getting started\nThe best way to get started building your own model is to go over the examples provided as template by Flax. They all follow the same format, making it easy to clone and modify them. You can even modify them directly in Google Colab for some of them, making experimentation easy without having to install anything.\n\nNote however that things are not as simple as the documentation makes it to appear and some of the examples will not run for various reasons (dependency problem, error in code, etc.)\n\nLet‚Äôs check this structure and look at a few models.\nThen let‚Äôs run the ogbg-molpcba example together in Google Colab to have access to a free GPU."
  },
  {
    "objectID": "ai/fl/fl_training.html#running-flax-examples-in-the-alliance-clusters",
    "href": "ai/fl/fl_training.html#running-flax-examples-in-the-alliance-clusters",
    "title": "Training the model",
    "section": "Running Flax examples in the Alliance clusters",
    "text": "Running Flax examples in the Alliance clusters\nInstead of running these examples in Google Colab, you might want to run them on the Alliance clusters, particularly as you start developing your own model (rather than just run examples to learn techniques).\nFirst, you need to get the model you are interested in to the cluster.\nThere are many ways you could go about it, but one option is to download the directory of that particular model to your machine as a zip file using one of several sites making this easy.\nFor the ogbg-molpcba example, you paste the link ‚Äúhttps://github.com/google/flax/tree/main/examples/ogbg_molpcba‚Äù in the site.\nYou can then copy it to the cluster with:\nscp &lt;path-to-zip-file-on-your-machine&gt; &lt;user-name&gt;@&lt;hostname&gt;:\nIt will look something like this (make sure to rename the zip file to remove the spaces or to quote the path):\nscp examples-ogbg_molpcba.zip userxx@xxx.c3.ca:\nThen you could run it using JupyterLab, but a more efficient method is to use sbatch.\nCreate a script:\n\n\n&lt;your_job&gt;.sh\n\n#!/bin/bash\n#SBATCH --account=def-&lt;your_account&gt;\n#SBATCH --time=xxx\n#SBATCH --mem-per-cpu=xxx\n#SBATCH --cpus-per-task=xxx\n#SBATCH --job-name=\"&lt;your_job&gt;\"\n\n# Setup\nmodule load python/3.11.5\nsource ~/env/bin/activate\npython -m pip install --upgrade pip --no-index\npython -m pip install -r requirements.txt --no-index\n\n# Run example\npython main.py --workdir=./ogbg_molpcba --config=configs/default.py\n\nAnd run the script:\nsbatch &lt;your_job&gt;.sh"
  },
  {
    "objectID": "ai/fl/fl_scale.html",
    "href": "ai/fl/fl_scale.html",
    "title": "Training at scale",
    "section": "",
    "text": "Using a JupyterHub to prototype code might be fine, but when you want to access more resources, it is much more resource-efficient to submit sbatch jobs to Slurm.\nThis section covers the workflow.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Training at scale"
    ]
  },
  {
    "objectID": "ai/fl/fl_scale.html#write-a-python-script",
    "href": "ai/fl/fl_scale.html#write-a-python-script",
    "title": "Training at scale",
    "section": "Write a Python script",
    "text": "Write a Python script\nThe first step is to put all your code in a Python script that you can evaluate during the job.\nLet‚Äôs call it main.py:\n\n\n\n\n\n\nNotemain.py\n\n\n\n\n\nfrom datasets import load_dataset\nimport numpy as np\nfrom torchvision.transforms import v2 as T\nimport grain.python as grain\nimport jax\nimport jax.numpy as jnp\nfrom flax import nnx\nfrom transformers import FlaxViTForImageClassification\nimport optax\nimport matplotlib.pyplot as plt\nfrom time import time\n\ntrain_size = 5 * 750\nval_size = 5 * 250\n\ntrain_dataset = load_dataset(\"food101\",\n                             split=f\"train[:{train_size}]\")\n\nval_dataset = load_dataset(\"food101\",\n                           split=f\"validation[:{val_size}]\")\n\nlabels_mapping = {}\nindex = 0\nfor i in range(0, len(val_dataset), 250):\n    label = val_dataset[i][\"label\"]\n    if label not in labels_mapping:\n        labels_mapping[label] = index\n        index += 1\n\ninv_labels_mapping = {v: k for k, v in labels_mapping.items()}\n\nimg_size = 224\n\ndef to_np_array(pil_image):\n  return np.asarray(pil_image.convert(\"RGB\"))\n\ndef normalize(image):\n    mean = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n    std = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n    image = image.astype(np.float32) / 255.0\n    return (image - mean) / std\n\ntv_train_transforms = T.Compose([\n    T.RandomResizedCrop((img_size, img_size), scale=(0.7, 1.0)),\n    T.RandomHorizontalFlip(),\n    T.ColorJitter(0.2, 0.2, 0.2),\n    T.Lambda(to_np_array),\n    T.Lambda(normalize),\n])\n\ntv_test_transforms = T.Compose([\n    T.Resize((img_size, img_size)),\n    T.Lambda(to_np_array),\n    T.Lambda(normalize),\n])\n\ndef get_transform(fn):\n    def wrapper(batch):\n        batch[\"image\"] = [\n            fn(pil_image) for pil_image in batch[\"image\"]\n        ]\n        batch[\"label\"] = [\n            labels_mapping[label] for label in batch[\"label\"]\n        ]\n        return batch\n    return wrapper\n\ntrain_transforms = get_transform(tv_train_transforms)\nval_transforms = get_transform(tv_test_transforms)\n\ntrain_dataset = train_dataset.with_transform(train_transforms)\nval_dataset = val_dataset.with_transform(val_transforms)\n\nseed = 12\ntrain_batch_size = 32\nval_batch_size = 2 * train_batch_size\n\ntrain_sampler = grain.IndexSampler(\n    len(train_dataset),\n    shuffle=True,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1,\n)\n\nval_sampler = grain.IndexSampler(\n    len(val_dataset),\n    shuffle=False,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1,\n)\n\ntrain_loader = grain.DataLoader(\n    data_source=train_dataset,\n    sampler=train_sampler,\n    worker_count=4,\n    worker_buffer_size=2,\n    operations=[\n        grain.Batch(train_batch_size, drop_remainder=True),\n    ]\n)\n\nval_loader = grain.DataLoader(\n    data_source=val_dataset,\n    sampler=val_sampler,\n    worker_count=4,\n    worker_buffer_size=2,\n    operations=[\n        grain.Batch(val_batch_size),\n    ]\n)\n\nclass VisionTransformer(nnx.Module):\n    def __init__(\n        self,\n        num_classes: int = 1000,\n        in_channels: int = 3,\n        img_size: int = 224,\n        patch_size: int = 16,\n        num_layers: int = 12,\n        num_heads: int = 12,\n        mlp_dim: int = 3072,\n        hidden_size: int = 768,\n        dropout_rate: float = 0.1,\n        *,\n        rngs: nnx.Rngs = nnx.Rngs(0),\n    ):\n        # Patch and position embedding\n        n_patches = (img_size // patch_size) ** 2\n        self.patch_embeddings = nnx.Conv(\n            in_channels,\n            hidden_size,\n            kernel_size=(patch_size, patch_size),\n            strides=(patch_size, patch_size),\n            padding=\"VALID\",\n            use_bias=True,\n            rngs=rngs,\n        )\n\n        initializer = jax.nn.initializers.truncated_normal(stddev=0.02)\n        self.position_embeddings = nnx.Param(\n            initializer(\n                rngs.params(),\n                (1, n_patches + 1, hidden_size),\n                jnp.float32\n            )\n        )\n        self.dropout = nnx.Dropout(dropout_rate, rngs=rngs)\n\n        self.cls_token = nnx.Param(jnp.zeros((1, 1, hidden_size)))\n\n        # Transformer Encoder blocks\n        self.encoder = nnx.Sequential(*[\n            TransformerEncoder(\n                hidden_size,\n                mlp_dim,\n                num_heads,\n                dropout_rate,\n                rngs=rngs\n            )\n            for i in range(num_layers)\n        ])\n        self.final_norm = nnx.LayerNorm(hidden_size, rngs=rngs)\n\n        # Classification head\n        self.classifier = nnx.Linear(hidden_size, num_classes, rngs=rngs)\n\n    def __call__(self, x: jax.Array) -&gt; jax.Array:\n        # Patch and position embedding\n        patches = self.patch_embeddings(x)\n        batch_size = patches.shape[0]\n        patches = patches.reshape(batch_size, -1, patches.shape[-1])\n\n        cls_token = jnp.tile(self.cls_token, [batch_size, 1, 1])\n        x = jnp.concat([cls_token, patches], axis=1)\n        embeddings = x + self.position_embeddings\n        embeddings = self.dropout(embeddings)\n\n        # Encoder blocks\n        x = self.encoder(embeddings)\n        x = self.final_norm(x)\n\n        # fetch the first token\n        x = x[:, 0]\n\n        # Classification\n        return self.classifier(x)\n\nclass TransformerEncoder(nnx.Module):\n    def __init__(\n        self,\n        hidden_size: int,\n        mlp_dim: int,\n        num_heads: int,\n        dropout_rate: float = 0.0,\n        *,\n        rngs: nnx.Rngs = nnx.Rngs(0),\n    ) -&gt; None:\n\n        self.norm1 = nnx.LayerNorm(hidden_size, rngs=rngs)\n        self.attn = nnx.MultiHeadAttention(\n            num_heads=num_heads,\n            in_features=hidden_size,\n            dropout_rate=dropout_rate,\n            broadcast_dropout=False,\n            decode=False,\n            deterministic=False,\n            rngs=rngs,\n        )\n        self.norm2 = nnx.LayerNorm(hidden_size, rngs=rngs)\n\n        self.mlp = nnx.Sequential(\n            nnx.Linear(hidden_size, mlp_dim, rngs=rngs),\n            nnx.gelu,\n            nnx.Dropout(dropout_rate, rngs=rngs),\n            nnx.Linear(mlp_dim, hidden_size, rngs=rngs),\n            nnx.Dropout(dropout_rate, rngs=rngs),\n        )\n\n    def __call__(self, x: jax.Array) -&gt; jax.Array:\n        x = x + self.attn(self.norm1(x))\n        x = x + self.mlp(self.norm2(x))\n        return x\n\nmodel = VisionTransformer(num_classes=1000)\n\ntf_model = FlaxViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n\ndef vit_inplace_copy_weights(*, src_model, dst_model):\n    assert isinstance(src_model, FlaxViTForImageClassification)\n    assert isinstance(dst_model, VisionTransformer)\n\n    tf_model_params = src_model.params\n    tf_model_params_fstate = nnx.traversals.flatten_mapping(tf_model_params)\n\n    flax_model_params = nnx.state(dst_model, nnx.Param)\n    flax_model_params_fstate = flax_model_params.flat_state()\n\n    params_name_mapping = {\n        (\"cls_token\",): (\"vit\", \"embeddings\", \"cls_token\"),\n        (\"position_embeddings\",): (\n            \"vit\",\n            \"embeddings\",\n            \"position_embeddings\"\n        ),\n        **{\n            (\"patch_embeddings\", x): (\n                \"vit\",\n                \"embeddings\",\n                \"patch_embeddings\",\n                \"projection\",\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n        },\n        **{\n            (\"encoder\", \"layers\", i, \"attn\", y, x): (\n                \"vit\",\n                \"encoder\",\n                \"layer\",\n                str(i),\n                \"attention\",\n                \"attention\",\n                y,\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n            for y in [\"key\", \"value\", \"query\"]\n            for i in range(12)\n        },\n        **{\n            (\"encoder\", \"layers\", i, \"attn\", \"out\", x): (\n                \"vit\",\n                \"encoder\",\n                \"layer\",\n                str(i),\n                \"attention\",\n                \"output\",\n                \"dense\",\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n            for i in range(12)\n        },\n        **{\n            (\"encoder\", \"layers\", i, \"mlp\", \"layers\", y1, x): (\n                \"vit\",\n                \"encoder\",\n                \"layer\",\n                str(i),\n                y2,\n                \"dense\",\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n            for y1, y2 in [(0, \"intermediate\"), (3, \"output\")]\n            for i in range(12)\n        },\n        **{\n            (\"encoder\", \"layers\", i, y1, x): (\n                \"vit\", \"encoder\", \"layer\", str(i), y2, x\n            )\n            for x in [\"scale\", \"bias\"]\n            for y1, y2 in [\n                    (\"norm1\", \"layernorm_before\"),\n                    (\"norm2\", \"layernorm_after\")\n            ]\n            for i in range(12)\n        },\n        **{\n            (\"final_norm\", x): (\"vit\", \"layernorm\", x)\n            for x in [\"scale\", \"bias\"]\n        },\n        **{\n            (\"classifier\", x): (\"classifier\", x)\n            for x in [\"kernel\", \"bias\"]\n        }\n    }\n\n    nonvisited = set(flax_model_params_fstate.keys())\n\n    for key1, key2 in params_name_mapping.items():\n        assert key1 in flax_model_params_fstate, key1\n        assert key2 in tf_model_params_fstate, (key1, key2)\n\n        nonvisited.remove(key1)\n\n        src_value = tf_model_params_fstate[key2]\n        if key2[-1] == \"kernel\" and key2[-2] in (\"key\", \"value\", \"query\"):\n            shape = src_value.shape\n            src_value = src_value.reshape((shape[0], 12, 64))\n\n        if key2[-1] == \"bias\" and key2[-2] in (\"key\", \"value\", \"query\"):\n            src_value = src_value.reshape((12, 64))\n\n        if key2[-4:] == (\"attention\", \"output\", \"dense\", \"kernel\"):\n            shape = src_value.shape\n            src_value = src_value.reshape((12, 64, shape[-1]))\n\n        dst_value = flax_model_params_fstate[key1]\n        assert src_value.shape == dst_value.value.shape, (\n            key2, src_value.shape, key1, dst_value.value.shape\n        )\n        dst_value.value = src_value.copy()\n        assert dst_value.value.mean() == src_value.mean(), (\n            dst_value.value, src_value.mean()\n        )\n\n    assert len(nonvisited) == 0, nonvisited\n\n    nnx.update(dst_model, nnx.State.from_flat_path(flax_model_params_fstate))\n\nvit_inplace_copy_weights(src_model=tf_model, dst_model=model)\n\nmodel.classifier = nnx.Linear(model.classifier.in_features, 5, rngs=nnx.Rngs(0))\n\nnum_epochs = 3\nlearning_rate = 0.001\nmomentum = 0.8\ntotal_steps = len(train_dataset) // train_batch_size\n\nlr_schedule = optax.linear_schedule(learning_rate, 0.0, num_epochs * total_steps)\n\noptimizer = nnx.Optimizer(model, optax.sgd(lr_schedule, momentum, nesterov=True))\n\ndef compute_losses_and_logits(model: nnx.Module, images: jax.Array, labels: jax.Array):\n    logits = model(images)\n\n    loss = optax.softmax_cross_entropy_with_integer_labels(\n        logits=logits, labels=labels\n    ).mean()\n    return loss, logits\n\n@nnx.jit\ndef train_step(\n    model: nnx.Module, optimizer: nnx.Optimizer, batch: dict[str, np.ndarray]\n):\n    # Convert np.ndarray to jax.Array on GPU\n    images = jnp.array(batch[\"image\"])\n    labels = jnp.array(batch[\"label\"], dtype=jnp.int32)\n\n    grad_fn = nnx.value_and_grad(compute_losses_and_logits, has_aux=True)\n    (loss, logits), grads = grad_fn(model, images, labels)\n\n    optimizer.update(grads)  # In-place updates.\n\n    return loss\n\n@nnx.jit\ndef eval_step(\n    model: nnx.Module, batch: dict[str, np.ndarray], eval_metrics: nnx.MultiMetric\n):\n    # Convert np.ndarray to jax.Array on GPU\n    images = jnp.array(batch[\"image\"])\n    labels = jnp.array(batch[\"label\"], dtype=jnp.int32)\n    loss, logits = compute_losses_and_logits(model, images, labels)\n\n    eval_metrics.update(\n        loss=loss,\n        logits=logits,\n        labels=labels,\n    )\n\neval_metrics = nnx.MultiMetric(\n    loss=nnx.metrics.Average('loss'),\n    accuracy=nnx.metrics.Accuracy(),\n)\n\ntrain_metrics_history = {\n    \"train_loss\": [],\n}\n\neval_metrics_history = {\n    \"val_loss\": [],\n    \"val_accuracy\": [],\n}\n\ndef train_one_epoch(epoch):\n    model.train()\n\ndef evaluate_model(epoch):\n    model.eval()\n\n    eval_metrics.reset()\n    for val_batch in val_loader:\n        eval_step(model, val_batch, eval_metrics)\n\n    for metric, value in eval_metrics.compute().items():\n        eval_metrics_history[f'val_{metric}'].append(value)\n\n    print(f\"[val] epoch: {epoch + 1}/{num_epochs}\")\n    print(f\"- total loss: {eval_metrics_history['val_loss'][-1]:0.4f}\")\n    print(f\"- Accuracy: {eval_metrics_history['val_accuracy'][-1]:0.4f}\")\n\nstart = time()\n\nfor epoch in range(num_epochs):\n    train_one_epoch(epoch)\n    evaluate_model(epoch)\n\nend = time()\n\nprint(f\"Training took {round((end - start) / 60, 1)} minutes\")\n\nplt.plot(train_metrics_history[\"train_loss\"], label=\"Loss value during the training\")\nplt.legend()\nplt.savefig('loss.png')\n\nfig, axs = plt.subplots(1, 2, figsize=(10, 10))\naxs[0].set_title(\"Loss value on validation set\")\naxs[0].plot(eval_metrics_history[\"val_loss\"])\naxs[1].set_title(\"Accuracy on validation set\")\naxs[1].plot(eval_metrics_history[\"val_accuracy\"])\nplt.savefig('validation.png')\n\n\n\n\nWe have to make a few changes to our code:\n\nStrip your code of anything unnecessary that you might have used during prototyping.\nIt doesn‚Äôt make sense to use tqdm anymore, so remove the corresponding code.\nWe can‚Äôt display the graphs anymore, so we save them to files with plt.savefig()\nWhen we aren‚Äôt using IPython (directly or via Jupyter), we don‚Äôt have access to the built-in magic commands such as %%time to time the execution of a cell. Instead, we use the following snippet:\n\nstart = time()\n\n&lt;Code to time&gt;\n\nend = time()\n\nprint(f\"Training took {round((end - start) / 60, 1)} minutes\")\nIn this case, since it is the training that we want to time:\nstart = time()\n\nfor epoch in range(num_epochs):\n    train_one_epoch(epoch)\n    evaluate_model(epoch)\n\nend = time()\n\nprint(f\"Training took {round((end - start) / 60, 1)} minutes\")",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Training at scale"
    ]
  },
  {
    "objectID": "ai/fl/fl_scale.html#write-a-slurm-script",
    "href": "ai/fl/fl_scale.html#write-a-slurm-script",
    "title": "Training at scale",
    "section": "Write a Slurm script",
    "text": "Write a Slurm script\nThen you need to write a Bash script for the Slurm scheduler.\nOur training cluster is made of 50 nodes of the c4-30gb flavour (each node contains 4 CPU and 30G, meaning 7500M per CPU).\nIf we want to train on a single CPU using the maximum amount of memory for that CPU, this is what our script looks like (let‚Äôs call it train.sh):\n\n\ntrain.sh\n\n#!/bin/bash\n#SBATCH --time=20\n#SBATCH --mem-per-cpu=7500M\n\nmodule load python/3.12.4 arrow/19.0.1\nsource /project/60055/env/bin/activate\n\npython main.py\n\nWhen I tested this earlier, training took 36.8 minutes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOur training cluster doesn‚Äôt require an account and it doesn‚Äôt have GPUs. It also doesn‚Äôt have huge amounts of memory. Moreover our code only contains 5 classes of foods to make training much faster. Finally, our Python virtual environment is in /project so that we can all access it while you normally would store it in your home.\nIf you were to train our model on an Alliance cluster at scale, the script would thus look something like this:\n\n\ntrain.sh\n\n#!/bin/bash\n#SBATCH --account=def-&lt;name&gt;\n#SBATCH --time=5:0:0\n#SBATCH --mem=50G\n#SBATCH --gpus-per-node=1\n\nmodule load python/3.12.4 arrow/19.0.1\nsource ~/env/bin/activate\n\npython main.py\n\n\nReplace &lt;name&gt; by your Alliance account name.\nThis assumes that you have a Python virtual environment in ~/env with all necessary packages installed.\nAlso note that if you are using the Alliance supercomputer Cedar, there is a policy for this cluster blocking you from running jobs in the /home filesystem, so you will have to copy your files to /scratch or your /project and run the job from there.\n\nNotice the following differences:\n\nwe provide an account name,\nwe ask for a lot more time (training at scale)‚Äîthis could even be days or weeks,\nwe ask for a lot more memory,\nwe ask for a GPU‚Äîsometimes you will need several GPUs (remember that the same JAX code can run on any device),\nwe source a virtual environment which is in our home.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Training at scale"
    ]
  },
  {
    "objectID": "ai/fl/fl_scale.html#run-the-script",
    "href": "ai/fl/fl_scale.html#run-the-script",
    "title": "Training at scale",
    "section": "Run the script",
    "text": "Run the script\nsbatch train.sh",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Training at scale"
    ]
  },
  {
    "objectID": "ai/fl/fl_scale.html#monitor-the-job",
    "href": "ai/fl/fl_scale.html#monitor-the-job",
    "title": "Training at scale",
    "section": "Monitor the job",
    "text": "Monitor the job\nTo see whether your job is still running and to get the job ID, you can use the Alliance alias:\nsq\n\n\nPD ‚ÄÉ‚ÄÉ‚ÄÉ¬†¬†‚ûî the job is pending\nR ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ¬†‚ûî the job is running\nNo output ¬†‚ûî the job is done\n\n\nWhile your job is running, you can monitor it by opening a new terminal and, from the login node, running:\nsrun --jobid=&lt;jobID&gt; --pty bash\n\nReplace &lt;jobID&gt; by the job ID you got by running sq.\n\nThen launch htop:\nalias htop='htop -u $USER -s PERCENT_CPU'\nhtop                     # monitor all your processes\nhtop --filter \"python\"   # filter processes by name\nCheck average memory usage with:\nsstat -j &lt;jobID&gt; --format=AveRSS\nOr maximum memory usage with:\nsstat -j &lt;jobID&gt; --format=MaxRSS",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Training at scale"
    ]
  },
  {
    "objectID": "ai/fl/fl_scale.html#get-the-results",
    "href": "ai/fl/fl_scale.html#get-the-results",
    "title": "Training at scale",
    "section": "Get the results",
    "text": "Get the results\nThe results will be in a file created by Slurm and called, by default, slurm-&lt;jobID&gt;.out (you can change the name of this file by adding an option in your Slurm script).\nYou can look at them with:\nbat slurm-&lt;jobID&gt;.out",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Training at scale"
    ]
  },
  {
    "objectID": "ai/fl/fl_scale.html#retrieve-files",
    "href": "ai/fl/fl_scale.html#retrieve-files",
    "title": "Training at scale",
    "section": "Retrieve files",
    "text": "Retrieve files\nWe created two images (loss.png and validation.png). To retrieve them, you can use scp from your computer:\nscp username@hostname:path/file path\nFor instance:\nscp userxx@hostname:loss.png ~/\n\nReplace hostname by the hostname for this cluster and ~/ by the path where you want to download your file.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Training at scale"
    ]
  },
  {
    "objectID": "ai/fl/fl_resources.html",
    "href": "ai/fl/fl_resources.html",
    "title": "Resources",
    "section": "",
    "text": "Here is a list of resources to get started with deep learning using JAX.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "ai/fl/fl_resources.html#jax",
    "href": "ai/fl/fl_resources.html#jax",
    "title": "Resources",
    "section": "JAX",
    "text": "JAX\n\nJAX GitHub repo\nOfficial documentation\n\n\nOther resources\n\nAwesome JAX list of resources\nJAX AI Stack tutorials\nProjects using the JAX AI Stack\n\n\n\nQ&A\n\nJAX GitHub Discussions\nStack Overflow [jax] tag",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "ai/fl/fl_resources.html#data-and-pre-trained-models",
    "href": "ai/fl/fl_resources.html#data-and-pre-trained-models",
    "title": "Resources",
    "section": "Data and pre-trained models",
    "text": "Data and pre-trained models\n\nData loaders\n\nHugging Face Datasets GitHub repo\nHugging Face Datasets documentation and tutorials\nGrain GitHub repo\nGrain official documentation\nTorchData GitHub repo\nTensorFlow Datasets GitHub repo\nTensorFlow Datasets official documentation\n\n\n\nData augmentation\n\nTorchVision official documentation\n\n\n\nModels and pre-trained weights\n\nHugging Face Transformers GitHub repo\nHugging Face Transformers official documentation\nTorchVision official documentation",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "ai/fl/fl_resources.html#flax",
    "href": "ai/fl/fl_resources.html#flax",
    "title": "Resources",
    "section": "Flax",
    "text": "Flax\n\nOfficial documentation\n\nFlax GitHub repo\nOfficial documentation\nFlax API\n\n\n\nOther resources\n\nProjects using Flax\n\n\n\nQ&A\n\nFlax GitHub Discussions\nStack Overflow [flax] tag\n\n\n\nAlliance\nThe Alliance wiki has a page on Flax.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "ai/fl/fl_resources.html#optax",
    "href": "ai/fl/fl_resources.html#optax",
    "title": "Resources",
    "section": "Optax",
    "text": "Optax\n\nOptax GitHub repo\nOfficial documentation\n\n\nQ&A\n\nOptax GitHub Discussions",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "ai/fl/fl_resources.html#orbax",
    "href": "ai/fl/fl_resources.html#orbax",
    "title": "Resources",
    "section": "Orbax",
    "text": "Orbax\n\nOrbax GitHub repo\nOfficial documentation\n\n\nQ&A\n\nOrbax GitHub Discussions",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "ai/fl/fl_resources.html#alliance-clusters",
    "href": "ai/fl/fl_resources.html#alliance-clusters",
    "title": "Resources",
    "section": "Alliance clusters",
    "text": "Alliance clusters\n\nAlliance Wiki\nRunning jobs\nUsing GPUs with Slurm\nTechnical support",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "ai/fl/fl_preprocess.html",
    "href": "ai/fl/fl_preprocess.html",
    "title": "Preprocessing data",
    "section": "",
    "text": "This section covers an example of the second step of a classic workflow: preprocessing the data.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Preprocessing data"
    ]
  },
  {
    "objectID": "ai/fl/fl_preprocess.html#context",
    "href": "ai/fl/fl_preprocess.html#context",
    "title": "Preprocessing data",
    "section": "Context",
    "text": "Context\nThere are many tools and options. In this example, we use TorchVision to transform and augment images and Grain to create data loaders.\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nproc\nProcess data\n\n\n\nload-&gt;proc\n\n\n\n\ntv\n\ntorchvision\n\n\n\n\nnn\nDefine architecture\n\n\n\nproc-&gt;nn\n\n\n\n\npretr\nPre-trained model\n\n\n\n\n\nopt\nHyperparameters\n\n\n\nnn-&gt;opt\n\n\n\n\npretr-&gt;nn\n\n\n\n\ntrain\nTrain\n\n\n\nopt-&gt;train\n\n\n\n\ncp\nCheckpoint\n\n\n\ntrain-&gt;cp\n\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\ngr\n\ngrain\n\n\n\n\ngr-&gt;proc\n\n\n\n\n\ntv-&gt;proc\n\n\n\n\n\ntr\n\ntransformers\n\n\n\n\ntr-&gt;pretr\n\n\n\n\n\nfl1\n\nflax\n\n\n\n\n\nfl1-&gt;nn\n\n\n\n\n\nfl2\n\nflax\n\n\n\nfl2-&gt;train\n\n\n\n\n\noa\n\noptax\n\n\n\noa-&gt;opt\n\n\n\n\n\njx\n\njax\n\n\n\njx-&gt;fl2\n\n\n\n\n\nob\n\norbax\n\n\n\nob-&gt;cp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteMinimal necessary code from previous section\n\n\n\n\n\n\nfrom datasets import load_dataset\nimport matplotlib.pyplot as plt\n\ntrain_size = 5 * 750\nval_size = 5 * 250\n\ntrain_dataset = load_dataset(\"food101\",\n                             split=f\"train[:{train_size}]\")\n\nval_dataset = load_dataset(\"food101\",\n                           split=f\"validation[:{val_size}]\")\n\nlabels_mapping = {}\nindex = 0\nfor i in range(0, len(val_dataset), 250):\n    label = val_dataset[i][\"label\"]\n    if label not in labels_mapping:\n        labels_mapping[label] = index\n        index += 1\n\ninv_labels_mapping = {v: k for k, v in labels_mapping.items()}\n\ndef display_datapoints(*datapoints, tag=\"\", names_map=None):\n    num_samples = len(datapoints)\n\n    fig, axs = plt.subplots(1, num_samples, figsize=(20, 10))\n    for i, datapoint in enumerate(datapoints):\n        if isinstance(datapoint, dict):\n            img, label = datapoint[\"image\"], datapoint[\"label\"]\n        else:\n            img, label = datapoint\n\n        if hasattr(img, \"dtype\") and img.dtype in (np.float32, ):\n            img = ((img - img.min()) / (img.max() - img.min()) * 255.0).astype(np.uint8)\n\n        label_str = f\" ({names_map[label]})\" if names_map is not None else \"\"\n        axs[i].set_title(f\"{tag} Label: {label}{label_str}\")\n        axs[i].imshow(img)",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Preprocessing data"
    ]
  },
  {
    "objectID": "ai/fl/fl_preprocess.html#load-packages",
    "href": "ai/fl/fl_preprocess.html#load-packages",
    "title": "Preprocessing data",
    "section": "Load packages",
    "text": "Load packages\nPackages necessary for this section:\n\n# general array manipulation\nimport numpy as np\n\n# for image transformation and augmentation\nfrom torchvision.transforms import v2 as T\n\n# to create data loaders\nimport grain.python as grain",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Preprocessing data"
    ]
  },
  {
    "objectID": "ai/fl/fl_preprocess.html#data-normalization-and-augmentation",
    "href": "ai/fl/fl_preprocess.html#data-normalization-and-augmentation",
    "title": "Preprocessing data",
    "section": "Data normalization and augmentation",
    "text": "Data normalization and augmentation\nLet‚Äôs preprocess our images to match the methods used in the vision transformer (ViT) introduced by Dosovitskiy A et al. [1] and implemented in JAX. This will be useful when we fine tune this model with the Food dataset in another section.\nThe preprocessing involves normalization and random augmentation (to prevent overfitting) with TorchVision:\n\nimg_size = 224\n\ndef to_np_array(pil_image):\n  return np.asarray(pil_image.convert(\"RGB\"))\n\ndef normalize(image):\n    mean = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n    std = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n    image = image.astype(np.float32) / 255.0\n    return (image - mean) / std\n\ntv_train_transforms = T.Compose([\n    T.RandomResizedCrop((img_size, img_size), scale=(0.7, 1.0)),\n    T.RandomHorizontalFlip(),\n    T.ColorJitter(0.2, 0.2, 0.2),\n    T.Lambda(to_np_array),\n    T.Lambda(normalize),\n])\n\ntv_test_transforms = T.Compose([\n    T.Resize((img_size, img_size)),\n    T.Lambda(to_np_array),\n    T.Lambda(normalize),\n])\n\ndef get_transform(fn):\n    def wrapper(batch):\n        batch[\"image\"] = [\n            fn(pil_image) for pil_image in batch[\"image\"]\n        ]\n        batch[\"label\"] = [\n            labels_mapping[label] for label in batch[\"label\"]\n        ]\n        return batch\n    return wrapper\n\ntrain_transforms = get_transform(tv_train_transforms)\nval_transforms = get_transform(tv_test_transforms)\n\ntrain_dataset = train_dataset.with_transform(train_transforms)\nval_dataset = val_dataset.with_transform(val_transforms)",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Preprocessing data"
    ]
  },
  {
    "objectID": "ai/fl/fl_preprocess.html#data-loaders",
    "href": "ai/fl/fl_preprocess.html#data-loaders",
    "title": "Preprocessing data",
    "section": "Data loaders",
    "text": "Data loaders\nWe use Grain to create efficient data loaders:\n\nseed = 12\ntrain_batch_size = 32\nval_batch_size = 2 * train_batch_size\n\ntrain_sampler = grain.IndexSampler(\n    len(train_dataset),\n    shuffle=True,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1,\n)\n\nval_sampler = grain.IndexSampler(\n    len(val_dataset),\n    shuffle=False,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1,\n)\n\ntrain_loader = grain.DataLoader(\n    data_source=train_dataset,\n    sampler=train_sampler,\n    worker_count=4,\n    worker_buffer_size=2,\n    operations=[\n        grain.Batch(train_batch_size, drop_remainder=True),\n    ]\n)\n\nval_loader = grain.DataLoader(\n    data_source=val_dataset,\n    sampler=val_sampler,\n    worker_count=4,\n    worker_buffer_size=2,\n    operations=[\n        grain.Batch(val_batch_size),\n    ]\n)",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Preprocessing data"
    ]
  },
  {
    "objectID": "ai/fl/fl_preprocess.html#inspect-batches",
    "href": "ai/fl/fl_preprocess.html#inspect-batches",
    "title": "Preprocessing data",
    "section": "Inspect batches",
    "text": "Inspect batches\n\ntrain_batch = next(iter(train_loader))\nval_batch = next(iter(val_loader))\n\nprint(\n    \"Training batch info:\",\n      train_batch[\"image\"].shape,\n      train_batch[\"image\"].dtype,\n      train_batch[\"label\"].shape,\n      train_batch[\"label\"].dtype\n)\n\nprint(\n    \"Validation batch info:\",\n      val_batch[\"image\"].shape,\n      val_batch[\"image\"].dtype,\n      val_batch[\"label\"].shape,\n      val_batch[\"label\"].dtype\n)\n\nTraining batch info: (32, 224, 224, 3) float32 (32,) int64\nValidation batch info: (64, 224, 224, 3) float32 (64,) int64\n\n\nDisplay the first three training and validation items:\n\ndisplay_datapoints(\n    *[(train_batch[\"image\"][i], train_batch[\"label\"][i]) for i in range(3)],\n    tag=\"(Training) \",\n    names_map={\n        k: train_dataset.features[\"label\"].names[v]\n               for k, v in inv_labels_mapping.items()\n    }\n)\n\ndisplay_datapoints(\n    *[(val_batch[\"image\"][i], val_batch[\"label\"][i]) for i in range(3)],\n    tag=\"(Validation) \",\n    names_map={\n        k: val_dataset.features[\"label\"].names[v]\n               for k, v in inv_labels_mapping.items()\n    }\n)",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Preprocessing data"
    ]
  },
  {
    "objectID": "ai/fl/fl_numpy.html",
    "href": "ai/fl/fl_numpy.html",
    "title": "Relation to NumPy",
    "section": "",
    "text": "NumPy is a popular Python scientific API at the core of many libraries. JAX uses a NumPy-inspired API. There are however important differences that we will explore in this section.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Relation to NumPy"
    ]
  },
  {
    "objectID": "ai/fl/fl_numpy.html#a-numpy-inspired-api",
    "href": "ai/fl/fl_numpy.html#a-numpy-inspired-api",
    "title": "Relation to NumPy",
    "section": "A NumPy-inspired API",
    "text": "A NumPy-inspired API\nNumPy being so popular, JAX comes with a convenient high-level wrapper to NumPy: jax.numpy.\n\nBeing familiar with NumPy is thus an advantage to get started with JAX. The NumPy quickstart is a useful resource.\n\n\nFor a more efficient usage, JAX also comes with a lower-level API: jax.lax.\n\n\nNumPyJAX NumPy\n\n\n\nimport numpy as np\n\n\nprint(np.array([(1, 2, 3), (4, 5, 6)]))\n\n[[1 2 3]\n [4 5 6]]\n\n\n\nprint(np.zeros((2, 3)))\n\n[[0. 0. 0.]\n [0. 0. 0.]]\n\n\n\nprint(np.ones((2, 3, 2)))\n\n[[[1. 1.]\n  [1. 1.]\n  [1. 1.]]\n\n [[1. 1.]\n  [1. 1.]\n  [1. 1.]]]\n\n\n\nprint(np.arange(24).reshape(2, 3, 4))\n\n[[[ 0  1  2  3]\n  [ 4  5  6  7]\n  [ 8  9 10 11]]\n\n [[12 13 14 15]\n  [16 17 18 19]\n  [20 21 22 23]]]\n\n\n\nprint(np.linspace(0, 2, 9))\n\n[0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ]\n\n\n\nprint(np.linspace(0, 2, 9)[::-1])\n\n[2.   1.75 1.5  1.25 1.   0.75 0.5  0.25 0.  ]\n\n\n\n\nimport jax.numpy as jnp\nprint(jnp.array([(1, 2, 3), (4, 5, 6)]))\n[[1 2 3]\n [4 5 6]]\nprint(jnp.zeros((2, 3)))\n[[0. 0. 0.]\n [0. 0. 0.]]\nprint(jnp.ones((2, 3, 2)))\n[[[1. 1.]\n  [1. 1.]\n  [1. 1.]]\n\n [[1. 1.]\n  [1. 1.]\n  [1. 1.]]]\nprint(jnp.arange(24).reshape(2, 3, 4))\n[[[ 0  1  2  3]\n  [ 4  5  6  7]\n  [ 8  9 10 11]]\n\n [[12 13 14 15]\n  [16 17 18 19]\n  [20 21 22 23]]]\nprint(jnp.linspace(0, 2, 9))\n[0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ]\nprint(jnp.linspace(0, 2, 9)[::-1])\n[2.   1.75 1.5  1.25 1.   0.75 0.5  0.25 0.  ]\n\n\n\nDespite the similarities, there are important differences between JAX and NumPy.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Relation to NumPy"
    ]
  },
  {
    "objectID": "ai/fl/fl_numpy.html#differences-with-numpy",
    "href": "ai/fl/fl_numpy.html#differences-with-numpy",
    "title": "Relation to NumPy",
    "section": "Differences with NumPy",
    "text": "Differences with NumPy\n\nDifferent types\ntype(np.zeros((2, 3))) == type(jnp.zeros((2, 3)))\nFalse\n\nNumpyJAX NumPy\n\n\n\ntype(np.zeros((2, 3)))\n\nnumpy.ndarray\n\n\n\n\ntype(jnp.zeros((2, 3)))\njaxlib.xla_extension.ArrayImpl\n\n\n\n\n\nDifferent default data types\n\nNumpyJAX NumPy\n\n\n\nnp.zeros((2, 3)).dtype\n\ndtype('float64')\n\n\n\n\njnp.zeros((2, 3)).dtype\ndtype('float32')\n\n\n\n\nLower numerical precision improves speed and reduces memory usage at no cost while training neural networks and is thus a net benefit. Having been built with deep learning in mind, JAX defaults align with that of other DL libraries (e.g.¬†PyTorch, TensorFlow).\n\n\n\nImmutable arrays\n\nNumpyJAX NumPy\n\n\nIn NumPy, you can modify ndarrays:\n\na = np.arange(5)\na[0] = 9\nprint(a)\n\n[9 1 2 3 4]\n\n\n\n\nJAX arrays are immutable:\na = jnp.arange(5)\na[0] = 9\nTypeError: '&lt;class 'jaxlib.xla_extension.ArrayImpl'&gt;' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html\nInstead, you need to create a copy of the array with the mutation. This is done with:\nb = a.at[0].set(9)\nprint(b)\n[9 1 2 3 4]\nOf course, you can overwrite a:\na = a.at[0].set(9)\n\n\n\n\n\nPseudorandom number generation\nProgramming languages usually come with automated pseudorandom number generator (PRNG) based on nondeterministic data from the operating system. They are extremely convenient, but slow, based on repeats, and problematic in parallel executions.\nJAX relies on an explicitly set random state called a key.\nfrom jax import random\n\nkey = random.key(18)\nprint(key)\n[ 0 18]\nEach time you call a random function, you need a subkey split from your key. Keys should only ever be used once in your code. The key is what makes your code reproducible, but you don‚Äôt want to reuse it within your code as it would create spurious correlations.\nHere is the workflow:\n\nyou split your key into a new key and one or multiple subkeys,\nyou discard the old key (because it was used to do the split‚Äîso its entropy budget, so to speak, has been used),\nyou use the subkey(s) to run your random function(s) and keep the new key for a future split.\n\n\nSubkeys are of the same nature as keys. This is just a terminology.\n\nTo make sure not to reuse the old key, you can overwrite it by the new one:\nkey, subkey = random.split(key)\nprint(key)\n[4197003906 1654466292]\n\nThat‚Äôs the value of our new key for future splits.\n\nprint(subkey)\n[1685972163 1654824463]\n\nThis is the value of the subkey that we can use to call a random function.\n\nLet‚Äôs use that subkey now:\nprint(random.normal(subkey))\n1.1437175\n\nTo split your key into more subkeys, pass an argument to random.split:\nkey, subkey1, subkey2, subkey3 = random.split(key, 4)\n\n\n\nStrict input control\n\nNumpyJAX NumPy\n\n\nNumPy‚Äôs fundamental object is the ndarray, but NumPy is very tolerant as to the type of input.\n\nnp.sum([1.0, 2.0])  # here we are using a list\n\nnp.float64(3.0)\n\n\n\nnp.sum((1.0, 2.0))  # here is a tuple\n\nnp.float64(3.0)\n\n\n\n\nTo avoid inefficiencies, JAX will only accept arrays.\njnp.sum([1.0, 2.0])\nTypeError: sum requires ndarray or scalar arguments, got &lt;class 'list'&gt; at position 0.\njnp.sum((1.0, 2.0))\nTypeError: sum requires ndarray or scalar arguments, got &lt;class 'tuple'&gt; at position 0.\n\n\n\n\n\nOut of bounds indexing\n\nNumpyJAX NumPy\n\n\nNumPy will warn you with an error message if you try to index out of bounds:\n\nprint(np.arange(5)[10])\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[13], line 1\n----&gt; 1 print(np.arange(5)[10])\n\nIndexError: index 10 is out of bounds for axis 0 with size 5\n\n\n\n\n\nBe aware that JAX will not raise an error. Instead, it will silently return the closest boundary:\nprint(jnp.arange(5)[10])\n4\n\n\n\n\n\nFunctionally pure functions\nMore importantly, only functionally pure functions‚Äîthat is, functions for which the outputs are only based on the inputs and which have no side effects‚Äîcan be used with JAX.\n\nOutputs only based on inputs\nConsider the function:\ndef f(x):\n    return a + x\nwhich uses the variable a from the global environment.\nThis function is not functionally pure because the outputs (the results of the function) do not solely depend on the arguments (the values given to x) passed to it. They also depend on the value of a.\nRemember how tracing works: new inputs with the same shape and dtype use the cached compiled program directly. If the value of a changes in the global environment, a new tracing is not triggered and the cached compiled program uses the old value of a (the one that was used during tracing).\nIt is only if the code is run on an input x with a different shape and/or dtype that tracing happens again and that the new value for a takes effect.\nfrom jax import jit\n\na = jnp.ones(3)\nprint(a)\n[1. 1. 1.]\ndef f(x):\n    return a + x\n\nprint(jit(f)(jnp.ones(3)))\n[2. 2. 2.]\n\nAll good here because this is the first run (tracing).\n\nNow, let‚Äôs change the value of a to an array of zeros:\na = jnp.zeros(3)\nprint(a)\n[0. 0. 0.]\nAnd rerun the same code:\nprint(jit(f)(jnp.ones(3)))\n[2. 2. 2.]\nWe should have an array of ones, but we get the same result we got earlier. Why? because we are running a cached program with the value that a had during tracing.\nThe new value for a will only take effect if we re-trigger tracing by changing the shape and/or dtype of x:\na = jnp.zeros(4)\nprint(a)\n[0. 0. 0. 0.]\nprint(jit(f)(jnp.ones(4)))\n[1. 1. 1. 1.]\nPassing an argument of a different shape to f forced recompilation. Using a different data type (e.g.¬†with jnp.arange(3)) would have done the same.\n\n\nNo side effects\nA function is said to have a side effect if it changes something outside of its local environment (if it does anything beside returning an output).\nExamples of side effects include:\n\nprinting to standard output/shell,\nreading from file/writing to file,\nmodifying a global variable.\n\nIn JAX, the side effects will happen during the first run (tracing), but will not happen on subsequent runs. You thus cannot rely on side effects in your code.\ndef f(a, b):\n    print(\"Calculating sum\")\n    return a + b\n\nprint(jit(f)(jnp.arange(3), jnp.arange(3)))\nCalculating sum\n[0 2 4]\n\nPrinting (the side effect) happened here because this is the first run.\n\nLet‚Äôs rerun the function:\nprint(jit(f)(jnp.arange(3), jnp.arange(3)))\n[0 2 4]\nThis time, no printing.\n\nUnderstanding jaxprs\nJaxprs are created by tracers wrapping the Python code during compilation (the first run). They contain information on the shape and data type of arrays as well as the operations performed on these arrays. Jaxprs do not however contain information on values: this allows the compiled program to be general enough to be rerun with any new arrays of the same shape and data type without having to rerun the slow Python code and recompile.\nJaxprs also do not contain any information on elements that are not part of the inputs such as external variables, nor do they contain information on side effects.\nJaxprs can be visualized with the jax.make_jaxpr function:\nimport jax\n\nx = jnp.array([1., 4., 3.])\ny = jnp.array([8., 1., 2.])\n\ndef f(x, y):\n    return 2 * x**2 + y\n\njax.make_jaxpr(f)(x, y) \n{ lambda ; a:f32[3] b:f32[3]. let\n    c:f32[3] = integer_pow[y=2] a\n    d:f32[3] = mul 2.0 c\n    e:f32[3] = add d b\n  in (e,) }\nLet‚Äôs add a print function to f:\ndef f(x, y):\n    print(\"This is a function with side-effect\")\n    return 2 * x**2 + y\n\njax.make_jaxpr(f)(x, y)\n{ lambda ; a:f32[3] b:f32[3]. let\n    c:f32[3] = integer_pow[y=2] a\n    d:f32[3] = mul 2.0 c\n    e:f32[3] = add d b\n  in (e,) }\nThe jaxpr is exactly the same. This is why printing will happen during tracing (when the Python code is run), but not afterwards (when the compiled code using the jaxpr is run).",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Relation to NumPy"
    ]
  },
  {
    "objectID": "ai/fl/fl_numpy.html#why-the-constraints",
    "href": "ai/fl/fl_numpy.html#why-the-constraints",
    "title": "Relation to NumPy",
    "section": "Why the constraints?",
    "text": "Why the constraints?\nThe more constraints you add to a programming language, the more optimization you can get from the compiler. Speed comes at the cost of convenience.\nFor instance, consider a Python list. It is an extremely convenient and flexible object: heterogeneous, mutable‚Ä¶ You can do anything with it. But computations on lists are extremely slow.\nNumPy‚Äôs ndarrays are more constrained (homogeneous), but the type constraint permits the creation of a much faster language (NumPy is written in C and Fortran as well as Python) with vectorization, optimizations, and a greatly improved performance.\nJAX takes it further: by using an intermediate representation and very strict constraints on type, pure functional programming, etc., yet more optimizations can be achieved and you can optimize your own functions with JIT compilation and the XLA. Ultimately, this is what makes JAX so fast.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Relation to NumPy"
    ]
  },
  {
    "objectID": "ai/fl/fl_numpy.html#the-good-news",
    "href": "ai/fl/fl_numpy.html#the-good-news",
    "title": "Relation to NumPy",
    "section": "The good news",
    "text": "The good news\nThe good news is that Flax used to rely on the Linen API which followed JAX closely. It was very elegant and respected JAX extremely closely: updating model parameters and optimizer state could not be done as a side-effect and the models were thus stateless. Stateless models frameworks follow a functional programming approach in which the parameters are separate from the model and passed as inputs to the forward pass along with the data. This is also the case of the Julia package Lux (a modern rewrite of Flux with explicit model parameters and a philosophy similar to JAX‚Äôs).\nElegant, yes, but nobody was using Flax because it was just too obscure. People were using libraries such as Equinox instead because they were a lot easier and more familiar to PyTorch users.\nFlax entirely changed its API. The new API (NNX) now deals with stateful models √† la PyTorch. JAX‚Äôs idiosyncrasies are mostly dealt with by Flax under the hood (you still need to be aware of them though to prevent you from making mistakes when dealing with jnp.array) and Flax code is now not so dissimilar from PyTorch while still making use of the great AD, JIT, XLA, and same code on all devices.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Relation to NumPy"
    ]
  },
  {
    "objectID": "ai/fl/fl_model.html",
    "href": "ai/fl/fl_model.html",
    "title": "Defining a model architecture",
    "section": "",
    "text": "Defining a model architecture in Flax is currently done with the flax.linen API and is quite straightforward."
  },
  {
    "objectID": "ai/fl/fl_model.html#the-linen-api",
    "href": "ai/fl/fl_model.html#the-linen-api",
    "title": "Defining a model architecture",
    "section": "The Linen API",
    "text": "The Linen API\nLinen is Flax‚Äôs current 1 NN API. Let‚Äôs load it, along with JAX and the JAX NumPy API:\nimport jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nTo define a model, we create a subclass of the nn.Module which inherits all the characteristics of that module, saving us from defining all the behaviours a neural network should have (exactly as in PyTorch).\nWhat we do need to define of course, is the architecture and the flow of data through it.\nLinen contains all the classic elements to define a NN model:\n\nmodules to define standard layers (e.g.¬†fully connected layer with Dense\nconvolution layer with Conv, pooling layers with max_pool or avg_pool)\na set of activation functions (e.g.¬†relu, softmax, sigmoid)\nJAX transformations (e.g.¬†jit, vmap, jvp, vjp)\n\nLinen makes use of JAX‚Äôs shape inference so there is no need for ‚Äúin‚Äù features (e.g.¬†nn.Dense only requires one argument: the ‚Äúout‚Äù feature; this is in contrast with PyTorch‚Äôs nn.Linear which requires both an ‚Äúin‚Äù and an ‚Äúout‚Äù features).\n\nExample\nAs we already saw, Linen provides two syntaxes:\n\na longer syntax using setup: more redundant, more PyTorch-like, allows to define multiple methods,\na compact one with the @nn.compact decorator that can only use a single method and avoids duplication between setup and call.\n\nLet‚Äôs use the latter here:\nclass CNN(nn.Module):\n    @nn.compact\n    def __call__(self, x):\n      x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n      x = nn.relu(x)\n      x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n      x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n      x = nn.relu(x)\n      x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n      x = x.reshape((x.shape[0], -1))\n      x = nn.Dense(features=256)(x)\n      x = nn.relu(x)\n      x = nn.Dense(features=10)(x)\n      x = nn.log_softmax(x)\n      return x\nNow we can create an instance of the model:\ncnn = CNN()\nRemember that in Linen the parameters are not part of the model: we need to initialize them as a method of the model by passing a random key and JAX array setting up their shape:\ndef get_initial_params(key):\n    init_shape = jnp.ones((1, 28, 28, 1))\n    initial_params = cnn.init(key, init_shape)\n    return initial_params\n\nkey = jax.random.key(0)\nkey, model_key = jax.random.split(key)\n\nparams = get_initial_params(model_key)"
  },
  {
    "objectID": "ai/fl/fl_model.html#model-inspection",
    "href": "ai/fl/fl_model.html#model-inspection",
    "title": "Defining a model architecture",
    "section": "Model inspection",
    "text": "Model inspection\nBefore using a model, it is a good idea to inspect it and make sure that everything is ok.\n\nInspect model layers\nThe tabulate method prints a summary table of each module (layer) in our model:\nprint(cnn.tabulate(\n    jax.random.key(0), \n    jnp.ones((1, 28, 28, 1)),\n    compute_flops=True, \n    compute_vjp_flops=True)\n      )\n                                                    CNN Summary\n‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ path    ‚îÉ module ‚îÉ inputs              ‚îÉ outputs             ‚îÉ flops   ‚îÉ vjp_flops ‚îÉ params                     ‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ         ‚îÇ CNN    ‚îÇ float32[1,28,28,1]  ‚îÇ float32[1,10]       ‚îÇ 8708144 ‚îÇ 26957634  ‚îÇ                            ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ Conv_0  ‚îÇ Conv   ‚îÇ float32[1,28,28,1]  ‚îÇ float32[1,28,28,32] ‚îÇ 455424  ‚îÇ 1341472   ‚îÇ bias: float32[32]          ‚îÇ\n‚îÇ         ‚îÇ        ‚îÇ                     ‚îÇ                     ‚îÇ         ‚îÇ           ‚îÇ kernel: float32[3,3,1,32]  ‚îÇ\n‚îÇ         ‚îÇ        ‚îÇ                     ‚îÇ                     ‚îÇ         ‚îÇ           ‚îÇ                            ‚îÇ\n‚îÇ         ‚îÇ        ‚îÇ                     ‚îÇ                     ‚îÇ         ‚îÇ           ‚îÇ 320 (1.3 KB)               ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ Conv_1  ‚îÇ Conv   ‚îÇ float32[1,14,14,32] ‚îÇ float32[1,14,14,64] ‚îÇ 6566144 ‚îÇ 19704320  ‚îÇ bias: float32[64]          ‚îÇ\n‚îÇ         ‚îÇ        ‚îÇ                     ‚îÇ                     ‚îÇ         ‚îÇ           ‚îÇ kernel: float32[3,3,32,64] ‚îÇ\n‚îÇ         ‚îÇ        ‚îÇ                     ‚îÇ                     ‚îÇ         ‚îÇ           ‚îÇ                            ‚îÇ\n‚îÇ         ‚îÇ        ‚îÇ                     ‚îÇ                     ‚îÇ         ‚îÇ           ‚îÇ 18,496 (74.0 KB)           ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ Dense_0 ‚îÇ Dense  ‚îÇ float32[1,3136]     ‚îÇ float32[1,256]      ‚îÇ 1605888 ‚îÇ 5620224   ‚îÇ bias: float32[256]         ‚îÇ\n‚îÇ         ‚îÇ        ‚îÇ                     ‚îÇ                     ‚îÇ         ‚îÇ           ‚îÇ kernel: float32[3136,256]  ‚îÇ\n‚îÇ         ‚îÇ        ‚îÇ                     ‚îÇ                     ‚îÇ         ‚îÇ           ‚îÇ                            ‚îÇ\n‚îÇ         ‚îÇ        ‚îÇ                     ‚îÇ                     ‚îÇ         ‚îÇ           ‚îÇ 803,072 (3.2 MB)           ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ Dense_1 ‚îÇ Dense  ‚îÇ float32[1,256]      ‚îÇ float32[1,10]       ‚îÇ 5130    ‚îÇ 17940     ‚îÇ bias: float32[10]          ‚îÇ\n‚îÇ         ‚îÇ        ‚îÇ                     ‚îÇ                     ‚îÇ         ‚îÇ           ‚îÇ kernel: float32[256,10]    ‚îÇ\n‚îÇ         ‚îÇ        ‚îÇ                     ‚îÇ                     ‚îÇ         ‚îÇ           ‚îÇ                            ‚îÇ\n‚îÇ         ‚îÇ        ‚îÇ                     ‚îÇ                     ‚îÇ         ‚îÇ           ‚îÇ 2,570 (10.3 KB)            ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ         ‚îÇ        ‚îÇ                     ‚îÇ                     ‚îÇ         ‚îÇ     Total ‚îÇ 824,458 (3.3 MB)           ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n                                        Total Parameters: 824,458 (3.3 MB)\n\n\nflops: estimated FLOPs (floating point operations per second) cost of forward pass\nvjp_flops: estimated FLOPs cost of backward pass (vjp stands for vector-Jacobian product)\n\n\n\n\nInspect initial parameters\n\n\nYour turn:\n\nThe summary table includes the shape of the parameters.\nBased on what we already learned, what is another way to get this information?\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\nPrinting the pytree of the initial parameters we created would make it fairly hard to get a sense of their structure, but we know that JAX can operate on pytrees thanks to the tree_util module, so let‚Äôs make use of this:\njax.tree.map(jnp.shape, params)\n{'Conv_0': {'bias': (32,), 'kernel': (3, 3, 1, 32)},\n 'Conv_1': {'bias': (64,), 'kernel': (3, 3, 32, 64)},\n 'Dense_0': {'bias': (256,), 'kernel': (3136, 256)},\n 'Dense_1': {'bias': (10,), 'kernel': (256, 10)}}"
  },
  {
    "objectID": "ai/fl/fl_model.html#footnotes",
    "href": "ai/fl/fl_model.html#footnotes",
    "title": "Defining a model architecture",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFlax had an initial flax.nn API, now retired. Linen made things easier and more PyTorch-like.\nA new API called NNX is being developed and may replace Linen in the future. It makes Flax even more similar to PyTorch by breaking with JAX‚Äôs functionally pure functions requirements and bringing the parameters back into the model.‚Ü©Ô∏é"
  },
  {
    "objectID": "ai/fl/fl_jaxdl.html",
    "href": "ai/fl/fl_jaxdl.html",
    "title": "Deep learning with JAX",
    "section": "",
    "text": "JAX is perfect for developing deep learning models:\n\nit deals with multi-dimensional arrays,\nit is extremely fast,\nit is optimized for accelerators,\nand it is capable of flexible automatic differentiation.\n\nJAX is however not a DL library. While it is possible to create neural networks directly in JAX, it makes more sense to use libraries built on JAX that provide the toolkit necessary to build and train neural networks.\nxxx info from https://github.com/jax-ml/jax-ai-stack?tab=readme-ov-file"
  },
  {
    "objectID": "ai/fl/fl_jaxdl.html#deep-learning-workflow",
    "href": "ai/fl/fl_jaxdl.html#deep-learning-workflow",
    "title": "Deep learning with JAX",
    "section": "Deep learning workflow",
    "text": "Deep learning workflow\nTraining a neural network from scratch requires a number of steps:\n\n\n\n\n\n\n\n\n\nLoad\\ndataset\n\nLoad\ndataset\n\n\n\nDefine\\narchitecture\n\nDefine\narchitecture\n\n\n\nLoad\\ndataset-&gt;Define\\narchitecture\n\n\n\n\n\nTrain\n\nTrain\n\n\n\nDefine\\narchitecture-&gt;Train\n\n\n\n\n\nTest\n\nTest\n\n\n\nTrain-&gt;Test\n\n\n\n\n\nSave\\nmodel\n\nSave\nmodel\n\n\n\nTest-&gt;Save\\nmodel\n\n\n\n\n\n\n\n\n\n\n Pretrained models can also be used for feature extraction or transfer learning."
  },
  {
    "objectID": "ai/fl/fl_jaxdl.html#deep-learning-ecosystem-for-jax",
    "href": "ai/fl/fl_jaxdl.html#deep-learning-ecosystem-for-jax",
    "title": "Deep learning with JAX",
    "section": "Deep learning ecosystem for JAX",
    "text": "Deep learning ecosystem for JAX\nHere is a classic ecosystem of libraries for deep learning with JAX:\n\nLoad datasets\nThere are already good tools to load datasets (e.g.¬†torchvision, TensorFlow datasets, Hugging Face datasets, Grain), so JAX did not worry about creating its own implementation.\nDefine network architecture\nNeural networks can be build in JAX from scratch, but a number of packages built on JAX provide the necessary toolkit. Flax is the option recommended by the JAX developers and the one we will use in this course.\nTrain\nThe package CLU (Common Loop Utils) is a set of helpers to write shorter training loops. Optax provides loss and optimization functions. Orbax brings checkpointing utilities.\nTest\nTesting a model is easy to do directly in JAX.\nSave model\nFlax provides methods to save a model.\n\n To sum up, here is an ecosystem of libraries to use JAX for neural networks:\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nnn\nDefine network\n\n\n\n\nPyTorch\n\nPyTorch\n\n\n\n\ntrain\nTrain\nOptimize\nCheckpoint\n\n\n\n\nflax1\n\nFlax\n\n\n\n\ntest\nTest\n\n\n\n\nsave\nSave model\n\n\n\n\nTensorFlow\n\nTensorFlow\n\n\n\n\nPyTorch-&gt;flax1\n\n\n\n\n\nHugging Face\n\nHugging Face\n\n\n\n\nTensorFlow-&gt;flax1\n\n\n\n\n\nGrain\n\nGrain\n\n\n\n\nHugging Face-&gt;flax1\n\n\n\n\n\nGrain-&gt;flax1\n\n\n\n\n\njax1\n\nJAX\nCLU\nOptax\nOrbax\n\n\n\nflax1-&gt;jax1\n\n\n\n\n\nflax2\n\nFlax\n\n\n\njax2\n\nJAX\n\n\n\njax1-&gt;jax2\n\n\n\n\n\njax2-&gt;flax2\n\n\n\n\n\n\n\n\n\n\n When working from pretrained models, Hugging Face also provides a great API to download from thousands of pretrained models."
  },
  {
    "objectID": "ai/fl/fl_jaxdl.html#how-to-get-started",
    "href": "ai/fl/fl_jaxdl.html#how-to-get-started",
    "title": "Deep learning with JAX",
    "section": "How to get started?",
    "text": "How to get started?\nA common approach is to start from one of the example projects and use it as a template."
  },
  {
    "objectID": "ai/fl/fl_jax_content.html",
    "href": "ai/fl/fl_jax_content.html",
    "title": "A brief intro to JAX",
    "section": "",
    "text": "Content from the intro slides for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Introduction: JAX",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/fl/fl_jax_content.html#what-is-jax",
    "href": "ai/fl/fl_jax_content.html#what-is-jax",
    "title": "A brief intro to JAX",
    "section": "What is JAX?",
    "text": "What is JAX?\n\nLibrary for Python developed by Google.\nKey data structure: Array.\nComposition, transformation, and differentiation of numerical programs.\nCompilation for CPUs, GPUs, and TPUs.\nNumPy-like and lower-level APIs.\nRequires strict functional programming.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Introduction: JAX",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/fl/fl_jax_content.html#why-jax",
    "href": "ai/fl/fl_jax_content.html#why-jax",
    "title": "A brief intro to JAX",
    "section": "Why JAX?",
    "text": "Why JAX?\n\nFast\n\nDefault data type suited for deep learning.\nLike PyTorch, uses float32 as default. This level of precision is suitable for deep learning and increases efficiency (by contrast, NumPy defaults to float64).\nJIT compilation.\nThe same code can run on CPUs or on accelerators (GPUs and TPUs).\nXLA (Accelerated Linear Algebra) optimization.\nAsynchronous dispatch.\nVectorization, data parallelism, and sharding.\nAll levels of shared and distributed memory parallelism are supported.\n\n\n\nGreat AD\n\n\n\n\n\n\n\n\n\n01\n\n\nAutodiff method\n\n\n\n1\nStatic graph\nand XLA\n\n\n\n\n02\n\n\nFramework\n\n\n\n\n2\nDynamic graph\n\n\n\n1-&gt;2\n\n\n\n\n\na\n\nTensorFlow\n\n\n\n\n4\nDynamic graph\nand XLA\n\n\n\n2-&gt;4\n\n\n\n\n\nb\n\nPyTorch\n\n\n\n\n5\nPseudo-dynamic\nand XLA\n\n\n\n4-&gt;5\n\n\n\n\n\nd\n\nTensorFlow2\n\n\n\n\ne\n\nJAX\n\n\n\n\n\n03\n\n\nAdvantage\n\n\n\n\n\n7\nMostly\noptimized AD\n\n\n\n\n\n8\nConvenient\n\n\n\n\n\n9\nConvenient\n\n\n\n\n10\nConvenient and\nmostly optimized AD\n\n\n\n\n\n04\n\n\nDisadvantage\n\n\n\n\n\nA\nManual writing of IR\n\n\n\n\n\nB\nLimited AD optimization\n\n\n\n\n\nD\nDisappointing speed\n\n\n\n\nE\nPure functions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummarized from a blog post by Chris Rackauckas\n\n\n\nClose to the math\nConsidering the function f:\nf = lambda x: x**3 + 2*x**2 - 3*x + 8\nWe can create a new function dfdx that computes the gradient of f w.r.t. x:\nfrom jax import grad\n\ndfdx = grad(f)\ndfdx returns the derivatives:\nprint(dfdx(1.))\n4.0\n\n\nForward and reverse modes\n\nreverse-mode vector-Jacobian products: jax.vjp\nforward-mode Jacobian-vector products: jax.jvp\n\n\n\nHigher-order differentiation\nWith a single variable, the grad function calls can be nested:\nd2fdx = grad(dfdx)   # function to compute 2nd order derivatives\nd3fdx = grad(d2fdx)  # function to compute 3rd order derivatives\n...\nWith several variables, you have to use the functions:\n\njax.jacfwd for forward-mode,\njax.jacrev for reverse-mode.\n\n\n\nHow does it work?\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\nTransformation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\n Transformations \n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\n Just-in-time \n(JIT)\ncompilation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\nVectorization\nParallelization\n ¬†¬†Differentiation ¬†\n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\njax.jit\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\njax.vmap\njax.pmap\njax.grad\n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla\n\n\n\n\n\n\n\n\n\n\n\nNot a deep learning library\n\n\n\n\n\n\n\n\n\njx\n\nJAX\n\n\n\ndl\nDeep learning\n\n\n\njx-&gt;dl\n\n\n\n\n\nop\nOptimizers\n\n\n\njx-&gt;op\n\n\n\n\n\npp\nProbabilistic\nprogramming\n\n\n\njx-&gt;pp\n\n\n\n\n\npm\nProbabilistic\nmodeling\n\n\n\njx-&gt;pm\n\n\n\n\n\nll\nLLMs\n\n\n\nll-&gt;jx\n\n\n\n\n\nso\nSolvers\n\n\n\nso-&gt;jx\n\n\n\n\n\nph\nPhysics\nsimulations\n\n\n\nph-&gt;jx\n\n\n\n\n\n\n\n\n\n\n\n\nIdeal for DL\nJAX is a Python sublanguage ideal for deep learning.\n\n\n\n\n\n\n\n\n\njx\n\nJAX\n\n\n\ndl\nDeep learning\n\n\n\njx-&gt;dl\n\n\n\n\n\nop\nOptimizers\n\n\n\njx-&gt;op\n\n\n\n\n\npp\nProbabilistic\nprogramming\n\n\n\njx-&gt;pp\n\n\n\n\n\npm\nProbabilistic\nmodeling\n\n\n\njx-&gt;pm\n\n\n\n\n\nll\nLLMs\n\n\n\nll-&gt;jx\n\n\n\n\n\nso\nSolvers\n\n\n\nso-&gt;jx\n\n\n\n\n\nph\nPhysics\nsimulations\n\n\n\nph-&gt;jx",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Introduction: JAX",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/fl/fl_jax_content.html#jax-for-deep-learning",
    "href": "ai/fl/fl_jax_content.html#jax-for-deep-learning",
    "title": "A brief intro to JAX",
    "section": "JAX for deep learning",
    "text": "JAX for deep learning\n\nDeep learning libraries\n\n\n\n\n\n\n\n\n\njx\n\nJAX\n\n\n\ndl\nDeep learning\n\n\n\njx-&gt;dl\n\n\n\n\n\nop\nOptimizers\n\n\n\njx-&gt;op\n\n\n\n\n\nfl\n\nFlax\n\n\n\ndl-&gt;fl\n\n\n\n\neq\n\nEquinox\n\n\n\ndl-&gt;eq\n\n\n\n\nke\n\nKeras\n\n\n\ndl-&gt;ke\n\n\n\n\noa\n\nOptax\n\n\n\nop-&gt;oa\n\n\n\n\noi\n\nOptimix\n\n\n\nop-&gt;oi\n\n\n\n\n\n\n\n\n\n\n\nThis course\n\n\n\n\n\n\n\n\n\njx\n\nJAX\n\n\n\ndl\nDeep learning\n\n\n\njx-&gt;dl\n\n\n\n\n\nop\nOptimizers\n\n\n\njx-&gt;op\n\n\n\n\n\nfl\n\nFlax\n\n\n\ndl-&gt;fl\n\n\n\n\neq\n\nEquinox\n\n\n\ndl-&gt;eq\n\n\n\n\nke\n\nKeras\n\n\n\ndl-&gt;ke\n\n\n\n\noa\n\nOptax\n\n\n\nop-&gt;oa\n\n\n\n\noi\n\nOptimix\n\n\n\nop-&gt;oi",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Introduction: JAX",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/fl/fl_jax_content.html#modular-approach",
    "href": "ai/fl/fl_jax_content.html#modular-approach",
    "title": "A brief intro to JAX",
    "section": "Modular approach",
    "text": "Modular approach\n\nData loaders\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\n\n\n\n\n\n\n\nData transformations\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nproc\nProcess data\n\n\n\nload-&gt;proc\n\n\n\n\ntv\n\ntorchvision\n\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\ngr\n\ngrain\n\n\n\n\ngr-&gt;proc\n\n\n\n\n\ntv-&gt;proc\n\n\n\n\n\n\n\n\n\n\n\n\nCore deep learning library\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nproc\nProcess data\n\n\n\nload-&gt;proc\n\n\n\n\ntv\n\ntorchvision\n\n\n\n\nnn\nDefine architecture\n\n\n\nproc-&gt;nn\n\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\ngr\n\ngrain\n\n\n\n\ngr-&gt;proc\n\n\n\n\n\ntv-&gt;proc\n\n\n\n\n\nfl\n\nflax\n\n\n\nfl-&gt;nn\n\n\n\n\n\n\n\n\n\n\n\n\nOptimizer and loss functions\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nproc\nProcess data\n\n\n\nload-&gt;proc\n\n\n\n\ntv\n\ntorchvision\n\n\n\n\nnn\nDefine architecture\n\n\n\nproc-&gt;nn\n\n\n\n\nopt\nHyperparameters\n\n\n\nnn-&gt;opt\n\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\ngr\n\ngrain\n\n\n\n\ngr-&gt;proc\n\n\n\n\n\ntv-&gt;proc\n\n\n\n\n\nfl\n\nflax\n\n\n\nfl-&gt;nn\n\n\n\n\n\noa\n\noptax\n\n\n\noa-&gt;opt\n\n\n\n\n\n\n\n\n\n\n\n\nTrain\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nproc\nProcess data\n\n\n\nload-&gt;proc\n\n\n\n\ntv\n\ntorchvision\n\n\n\n\nnn\nDefine architecture\n\n\n\nproc-&gt;nn\n\n\n\n\nopt\nHyperparameters\n\n\n\nnn-&gt;opt\n\n\n\n\ntrain\nTrain\n\n\n\nopt-&gt;train\n\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\ngr\n\ngrain\n\n\n\n\ngr-&gt;proc\n\n\n\n\n\ntv-&gt;proc\n\n\n\n\n\nfl1\n\nflax\n\n\n\nfl1-&gt;nn\n\n\n\n\n\nfl2\n\nflax\n\n\n\n\nfl2-&gt;train\n\n\n\n\n\noa\n\noptax\n\n\n\noa-&gt;opt\n\n\n\n\n\njx\n\njax\n\n\n\n\njx-&gt;fl2\n\n\n\n\n\n\n\n\n\n\n\n\nCheckpointing\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nproc\nProcess data\n\n\n\nload-&gt;proc\n\n\n\n\ntv\n\ntorchvision\n\n\n\n\nnn\nDefine architecture\n\n\n\nproc-&gt;nn\n\n\n\n\nopt\nHyperparameters\n\n\n\nnn-&gt;opt\n\n\n\n\ntrain\nTrain\n\n\n\nopt-&gt;train\n\n\n\n\ncp\nCheckpoint\n\n\n\ntrain-&gt;cp\n\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\ngr\n\ngrain\n\n\n\n\ngr-&gt;proc\n\n\n\n\n\ntv-&gt;proc\n\n\n\n\n\nfl1\n\nflax\n\n\n\nfl1-&gt;nn\n\n\n\n\n\nfl2\n\nflax\n\n\n\n\noa\n\noptax\n\n\n\noa-&gt;opt\n\n\n\n\n\njx\n\njax\n\n\n\n\njx-&gt;fl2\n\n\n\n\n\nob\n\norbax\n\n\n\nob-&gt;cp\n\n\n\n\n\n\n\n\n\n\n\n\nTransfer learning\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nproc\nProcess data\n\n\n\nload-&gt;proc\n\n\n\n\ntv\n\ntorchvision\n\n\n\n\nnn\nDefine architecture\n\n\n\nproc-&gt;nn\n\n\n\n\npretr\nPre-trained model\n\n\n\n\nopt\nHyperparameters\n\n\n\nnn-&gt;opt\n\n\n\n\npretr-&gt;nn\n\n\n\n\ntrain\nTrain\n\n\n\nopt-&gt;train\n\n\n\n\ncp\nCheckpoint\n\n\n\ntrain-&gt;cp\n\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\ngr\n\ngrain\n\n\n\n\ngr-&gt;proc\n\n\n\n\n\ntv-&gt;proc\n\n\n\n\n\ntr\n\ntransformers\n\n\n\n\ntr-&gt;pretr\n\n\n\n\n\nfl1\n\nflax\n\n\n\n\nfl1-&gt;nn\n\n\n\n\n\nfl2\n\nflax\n\n\n\n\nfl2-&gt;train\n\n\n\n\n\noa\n\noptax\n\n\n\noa-&gt;opt\n\n\n\n\n\njx\n\njax\n\n\n\n\njx-&gt;fl2\n\n\n\n\n\nob\n\norbax\n\n\n\nob-&gt;cp",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Introduction: JAX",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/fl/fl_jax_content.html#installation",
    "href": "ai/fl/fl_jax_content.html#installation",
    "title": "A brief intro to JAX",
    "section": "Installation",
    "text": "Installation\n\nInstalling JAX\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinux x86_64\nLinux aarch64\nMac x86_64\nMac aarch64\nWindows x86_64\nWindows WSL2 x86_64\n\n\n\n\nCPU\nyes\nyes\nyes\nyes\nyes\nyes\n\n\nNVIDIA GPU\nyes\nyes\nno\nn/a\nno\nexperimental\n\n\nGoogle TPU\nyes\nn/a\nn/a\nn/a\nn/a\nn/a\n\n\nAMD GPU\nyes\nno\nexperimental\nn/a\nno\nno\n\n\nApple GPU\nn/a\nno\nn/a\nexperimental\nn/a\nn/a\n\n\nIntel GPU\nexperimental\nn/a\nn/a\nn/a\nno\nno\n\n\n\n\nFrom JAX documentation\n\nIf you install packages which depend on JAX (e.g.¬†Flax), they will by default install the CPU version of JAX. If you want to run JAX on GPUs, make sure to first install jax[cuda12].\nYou can install the CPU version on your machine to prototype and use a GPU version on the clusters (we have wheels).\n\n\nComplementary libraries\nThe modular approach has the downside that several libraries are required and conflicts between dependencies can be a problem.\nThe meta-library jax-ai-stack makes this easier to manage (install jax[cuda12] first for GPU).\nNote that for now TensorFlow and packages which depend on it (e.g.¬†TFDS, grain) are still stuck at Python 3.12, so you can‚Äôt use a newer Python version if you want to use some of them.\n\nOn your machine (and your machine only), a great tool to manage Python versions and packages is uv (see our webinar). On the clusters, you have to use module to load the Python version you want and pip to install packages.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Introduction: JAX",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/fl/fl_install.html",
    "href": "ai/fl/fl_install.html",
    "title": "Installing packages",
    "section": "",
    "text": "For this course, we have already installed the packages, but this section is important for you when you will want to install packages on your machine or on the Alliance clusters.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Installing packages"
    ]
  },
  {
    "objectID": "ai/fl/fl_install.html#on-your-machine",
    "href": "ai/fl/fl_install.html#on-your-machine",
    "title": "Installing packages",
    "section": "On your machine",
    "text": "On your machine\nOn your machine (but not on the Alliance clusters), I recommend that you use uv to create a Python project with your chosen Python version and all the necessary packages. uv installs packages much faster than pip and it is able to resolve dependencies very well. It also manages Python versions.\n\nIf you want more information on this, I gave a webinar on uv in May 2025.\n\nCreate a Python project (let‚Äôs call it jaxdl) and cd into it:\nuv init --bare jaxdl\ncd jaxdl\n\n--bare creates a uv project without files that I am not interested in here such as a README and a main.py.\n\nInstall the packages:\nuv add \"jax[cuda13]\" jax-ai-stack datasets matplotlib penzai torchvision tqdm transformers\n\nQuick explanation of packages we are installing:\n- jax[cuda13]           ‚ûî only if you want to run JAX on GPUs\n- jax-ai-stack          ‚ûî installs JAX for the CPU (if not already installed for the GPU),\n                                   Flax‚Äîthe main NN library,\n                                   Optax‚Äîoptimizers & loss functions,\n                                   Orbax‚Äîfor checkpointing,\n                                   Grain‚Äîto build efficient dataloaders,\n                                   Chex‚Äîa library of utilities for JAX,\n                                   ml_dtypes‚ÄîNumPy dtype extensions for deep learning\n- datasets              ‚ûî from Hugging Face‚Äîto load data\n- matplotlib            ‚ûî to visualise samples\n- penzai                ‚ûî to have interactive model display\n- torchvision           ‚ûî to augment the data to prevent over-fitting\n- tqdm                  ‚ûî progress bar\n- transformers          ‚ûî from Hugging Face‚Äîto load pretrained weights\n\nYou will see that the dependencies have automatically populated a pyproject.toml file and that a virtual environment called .venv was created.\nAs long as you are within the project, you don‚Äôt need to activate that virtual environment. You can just launch Python (or IPython, ptpython, Jupyter‚Ä¶) and the packages will be available.\nAlternatively, if your required a tighter pip equivalent, you can activate it as you would any other Python virtual environment:\nsource .venv/bin/activate",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Installing packages"
    ]
  },
  {
    "objectID": "ai/fl/fl_install.html#on-an-alliance-cluster",
    "href": "ai/fl/fl_install.html#on-an-alliance-cluster",
    "title": "Installing packages",
    "section": "On an Alliance cluster",
    "text": "On an Alliance cluster\n\nI already installed all the necessary packages in the training cluster to save time and space. The instructions for today thus differ from what you would normally do and production cluster instructions in the second tab are for your future reference only.\n\n\nTodayProduction cluster\n\n\nLook for available Python modules:\nmodule spider python\nLoad the version of your choice:\nmodule load python/3.13.2\nThe Hugging Face Datasets package uses PyArrow for efficiency. In order to install it, we also need to load an Arrow module.\nLet‚Äôs see what versions are available:\nmodule spider arrow\nAny version should be fine. Let‚Äôs load the latest (as of April 2025):\nmodule load arrow/19.0.1\nI created a virtual Python environment with all necessary packages under /project. All you have to do today is activate it with:\nsource /project/60055/env/bin/activate\n\n\nLook for available Python modules:\nmodule spider python\nLoad the version of your choice:\nmodule load python/3.13.2\nThe Hugging Face Datasets package uses PyArrow for efficiency. In order to install it, we also need to load an Arrow module.\nLet‚Äôs see what versions are available:\nmodule spider arrow\nAny version should be fine. Let‚Äôs load the latest (as of April 2025):\nmodule load arrow/19.0.1\nCreate a Python virtual environment:\npython -m venv ~/env\nActivate it:\nsource ~/env/bin/activate\nUpdate pip from wheel:\npython -m pip install --upgrade pip --no-index\n\nWhenever a Python wheel for a package is available on the Alliance clusters, you should use it instead of downloading the package from PyPI. To do this, simply add the --no-index flag to the install command.\nYou can see whether a wheel is available with avail_wheels &lt;package&gt; or look at the list of available wheels.\nAdvantages of wheels:\n\ncompiled for the clusters hardware,\nensures no missing or conflicting dependencies,\nmuch faster installation.\n\n\nInstall libraries from wheel:\npython -m pip install --no-index \"jax[cuda]\" jax-ai-stack[grain] datasets matplotlib penzai torchvision tqdm transformers\n\nDon‚Äôt forget --no-index to install from wheels.\n\n\nQuick explanation of packages we are installing:\n- jax[cuda]             ‚ûî only if you want to run JAX on GPUs\n- jax-ai-stack[grain]   ‚ûî installs JAX for the CPU (if not already installed for the GPU),\n                                   Flax‚Äîthe main NN library,\n                                   Optax‚Äîoptimizers & loss functions,\n                                   Orbax‚Äîfor checkpointing,\n                                   Grain‚Äîto build efficient dataloaders,\n                                   ml_dtypes‚ÄîNumPy dtype extensions for deep learning\n- datasets              ‚ûî from Hugging Face‚Äîto load data\n- matplotlib            ‚ûî to visualise samples\n- penzai                ‚ûî to have interactive model display\n- torchvision           ‚ûî to augment the data to prevent over-fitting\n- tqdm                  ‚ûî progress bar\n- transformers          ‚ûî from Hugging Face‚Äîto load pretrained weights",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Installing packages"
    ]
  },
  {
    "objectID": "ai/fl/fl_finetune.html",
    "href": "ai/fl/fl_finetune.html",
    "title": "Fine-tuning the model",
    "section": "",
    "text": "In this section, we fine-tune our model with our sample (5 classes) of the Food-101 dataset [1].",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Fine-tuning the model"
    ]
  },
  {
    "objectID": "ai/fl/fl_finetune.html#context",
    "href": "ai/fl/fl_finetune.html#context",
    "title": "Fine-tuning the model",
    "section": "Context",
    "text": "Context\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nproc\nProcess data\n\n\n\nload-&gt;proc\n\n\n\n\ntv\n\ntorchvision\n\n\n\n\nnn\nDefine architecture\n\n\n\nproc-&gt;nn\n\n\n\n\npretr\nPre-trained model\n\n\n\n\n\nopt\nHyperparameters\n\n\n\nnn-&gt;opt\n\n\n\n\npretr-&gt;nn\n\n\n\n\ntrain\nTrain\n\n\n\nopt-&gt;train\n\n\n\n\ncp\nCheckpoint\n\n\n\ntrain-&gt;cp\n\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\ngr\n\ngrain\n\n\n\n\ngr-&gt;proc\n\n\n\n\n\ntv-&gt;proc\n\n\n\n\n\ntr\n\ntransformers\n\n\n\n\ntr-&gt;pretr\n\n\n\n\n\nfl1\n\nflax\n\n\n\n\n\nfl1-&gt;nn\n\n\n\n\n\nfl2\n\nflax\n\n\n\nfl2-&gt;train\n\n\n\n\n\noa\n\noptax\n\n\n\noa-&gt;opt\n\n\n\n\n\njx\n\nJAX\n\n\n\njx-&gt;fl2\n\n\n\n\n\nob\n\norbax\n\n\n\nob-&gt;cp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteMinimal necessary code from previous sections\n\n\n\n\n\nfrom datasets import load_dataset\nimport numpy as np\nfrom torchvision.transforms import v2 as T\nimport grain.python as grain\nimport jax\nimport jax.numpy as jnp\nfrom flax import nnx\nfrom transformers import FlaxViTForImageClassification\nimport optax\n\ntrain_size = 5 * 750\nval_size = 5 * 250\n\ntrain_dataset = load_dataset(\"food101\",\n                             split=f\"train[:{train_size}]\")\n\nval_dataset = load_dataset(\"food101\",\n                           split=f\"validation[:{val_size}]\")\n\nlabels_mapping = {}\nindex = 0\nfor i in range(0, len(val_dataset), 250):\n    label = val_dataset[i][\"label\"]\n    if label not in labels_mapping:\n        labels_mapping[label] = index\n        index += 1\n\ninv_labels_mapping = {v: k for k, v in labels_mapping.items()}\n\nimg_size = 224\n\ndef to_np_array(pil_image):\n  return np.asarray(pil_image.convert(\"RGB\"))\n\ndef normalize(image):\n    mean = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n    std = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n    image = image.astype(np.float32) / 255.0\n    return (image - mean) / std\n\ntv_train_transforms = T.Compose([\n    T.RandomResizedCrop((img_size, img_size), scale=(0.7, 1.0)),\n    T.RandomHorizontalFlip(),\n    T.ColorJitter(0.2, 0.2, 0.2),\n    T.Lambda(to_np_array),\n    T.Lambda(normalize),\n])\n\ntv_test_transforms = T.Compose([\n    T.Resize((img_size, img_size)),\n    T.Lambda(to_np_array),\n    T.Lambda(normalize),\n])\n\ndef get_transform(fn):\n    def wrapper(batch):\n        batch[\"image\"] = [\n            fn(pil_image) for pil_image in batch[\"image\"]\n        ]\n        batch[\"label\"] = [\n            labels_mapping[label] for label in batch[\"label\"]\n        ]\n        return batch\n    return wrapper\n\ntrain_transforms = get_transform(tv_train_transforms)\nval_transforms = get_transform(tv_test_transforms)\n\ntrain_dataset = train_dataset.with_transform(train_transforms)\nval_dataset = val_dataset.with_transform(val_transforms)\n\nseed = 12\ntrain_batch_size = 32\nval_batch_size = 2 * train_batch_size\n\ntrain_sampler = grain.IndexSampler(\n    len(train_dataset),\n    shuffle=True,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1,\n)\n\nval_sampler = grain.IndexSampler(\n    len(val_dataset),\n    shuffle=False,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1,\n)\n\ntrain_loader = grain.DataLoader(\n    data_source=train_dataset,\n    sampler=train_sampler,\n    worker_count=4,\n    worker_buffer_size=2,\n    operations=[\n        grain.Batch(train_batch_size, drop_remainder=True),\n    ]\n)\n\nval_loader = grain.DataLoader(\n    data_source=val_dataset,\n    sampler=val_sampler,\n    worker_count=4,\n    worker_buffer_size=2,\n    operations=[\n        grain.Batch(val_batch_size),\n    ]\n)\n\nclass VisionTransformer(nnx.Module):\n    def __init__(\n        self,\n        num_classes: int = 1000,\n        in_channels: int = 3,\n        img_size: int = 224,\n        patch_size: int = 16,\n        num_layers: int = 12,\n        num_heads: int = 12,\n        mlp_dim: int = 3072,\n        hidden_size: int = 768,\n        dropout_rate: float = 0.1,\n        *,\n        rngs: nnx.Rngs = nnx.Rngs(0),\n    ):\n        # Patch and position embedding\n        n_patches = (img_size // patch_size) ** 2\n        self.patch_embeddings = nnx.Conv(\n            in_channels,\n            hidden_size,\n            kernel_size=(patch_size, patch_size),\n            strides=(patch_size, patch_size),\n            padding=\"VALID\",\n            use_bias=True,\n            rngs=rngs,\n        )\n\n        initializer = jax.nn.initializers.truncated_normal(stddev=0.02)\n        self.position_embeddings = nnx.Param(\n            initializer(\n                rngs.params(),\n                (1, n_patches + 1, hidden_size),\n                jnp.float32\n            )\n        )\n        self.dropout = nnx.Dropout(dropout_rate, rngs=rngs)\n\n        self.cls_token = nnx.Param(jnp.zeros((1, 1, hidden_size)))\n\n        # Transformer Encoder blocks\n        self.encoder = nnx.Sequential(*[\n            TransformerEncoder(\n                hidden_size,\n                mlp_dim,\n                num_heads,\n                dropout_rate,\n                rngs=rngs\n            )\n            for i in range(num_layers)\n        ])\n        self.final_norm = nnx.LayerNorm(hidden_size, rngs=rngs)\n\n        # Classification head\n        self.classifier = nnx.Linear(hidden_size, num_classes, rngs=rngs)\n\n    def __call__(self, x: jax.Array) -&gt; jax.Array:\n        # Patch and position embedding\n        patches = self.patch_embeddings(x)\n        batch_size = patches.shape[0]\n        patches = patches.reshape(batch_size, -1, patches.shape[-1])\n\n        cls_token = jnp.tile(self.cls_token, [batch_size, 1, 1])\n        x = jnp.concat([cls_token, patches], axis=1)\n        embeddings = x + self.position_embeddings\n        embeddings = self.dropout(embeddings)\n\n        # Encoder blocks\n        x = self.encoder(embeddings)\n        x = self.final_norm(x)\n\n        # fetch the first token\n        x = x[:, 0]\n\n        # Classification\n        return self.classifier(x)\n\nclass TransformerEncoder(nnx.Module):\n    def __init__(\n        self,\n        hidden_size: int,\n        mlp_dim: int,\n        num_heads: int,\n        dropout_rate: float = 0.0,\n        *,\n        rngs: nnx.Rngs = nnx.Rngs(0),\n    ) -&gt; None:\n\n        self.norm1 = nnx.LayerNorm(hidden_size, rngs=rngs)\n        self.attn = nnx.MultiHeadAttention(\n            num_heads=num_heads,\n            in_features=hidden_size,\n            dropout_rate=dropout_rate,\n            broadcast_dropout=False,\n            decode=False,\n            deterministic=False,\n            rngs=rngs,\n        )\n        self.norm2 = nnx.LayerNorm(hidden_size, rngs=rngs)\n\n        self.mlp = nnx.Sequential(\n            nnx.Linear(hidden_size, mlp_dim, rngs=rngs),\n            nnx.gelu,\n            nnx.Dropout(dropout_rate, rngs=rngs),\n            nnx.Linear(mlp_dim, hidden_size, rngs=rngs),\n            nnx.Dropout(dropout_rate, rngs=rngs),\n        )\n\n    def __call__(self, x: jax.Array) -&gt; jax.Array:\n        x = x + self.attn(self.norm1(x))\n        x = x + self.mlp(self.norm2(x))\n        return x\n\nmodel = VisionTransformer(num_classes=1000)\n\ntf_model = FlaxViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n\ndef vit_inplace_copy_weights(*, src_model, dst_model):\n    assert isinstance(src_model, FlaxViTForImageClassification)\n    assert isinstance(dst_model, VisionTransformer)\n\n    tf_model_params = src_model.params\n    tf_model_params_fstate = nnx.traversals.flatten_mapping(tf_model_params)\n\n    flax_model_params = nnx.state(dst_model, nnx.Param)\n    flax_model_params_fstate = flax_model_params.flat_state()\n\n    params_name_mapping = {\n        (\"cls_token\",): (\"vit\", \"embeddings\", \"cls_token\"),\n        (\"position_embeddings\",): (\n            \"vit\",\n            \"embeddings\",\n            \"position_embeddings\"\n        ),\n        **{\n            (\"patch_embeddings\", x): (\n                \"vit\",\n                \"embeddings\",\n                \"patch_embeddings\",\n                \"projection\",\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n        },\n        **{\n            (\"encoder\", \"layers\", i, \"attn\", y, x): (\n                \"vit\",\n                \"encoder\",\n                \"layer\",\n                str(i),\n                \"attention\",\n                \"attention\",\n                y,\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n            for y in [\"key\", \"value\", \"query\"]\n            for i in range(12)\n        },\n        **{\n            (\"encoder\", \"layers\", i, \"attn\", \"out\", x): (\n                \"vit\",\n                \"encoder\",\n                \"layer\",\n                str(i),\n                \"attention\",\n                \"output\",\n                \"dense\",\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n            for i in range(12)\n        },\n        **{\n            (\"encoder\", \"layers\", i, \"mlp\", \"layers\", y1, x): (\n                \"vit\",\n                \"encoder\",\n                \"layer\",\n                str(i),\n                y2,\n                \"dense\",\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n            for y1, y2 in [(0, \"intermediate\"), (3, \"output\")]\n            for i in range(12)\n        },\n        **{\n            (\"encoder\", \"layers\", i, y1, x): (\n                \"vit\", \"encoder\", \"layer\", str(i), y2, x\n            )\n            for x in [\"scale\", \"bias\"]\n            for y1, y2 in [\n                    (\"norm1\", \"layernorm_before\"),\n                    (\"norm2\", \"layernorm_after\")\n            ]\n            for i in range(12)\n        },\n        **{\n            (\"final_norm\", x): (\"vit\", \"layernorm\", x)\n            for x in [\"scale\", \"bias\"]\n        },\n        **{\n            (\"classifier\", x): (\"classifier\", x)\n            for x in [\"kernel\", \"bias\"]\n        }\n    }\n\n    nonvisited = set(flax_model_params_fstate.keys())\n\n    for key1, key2 in params_name_mapping.items():\n        assert key1 in flax_model_params_fstate, key1\n        assert key2 in tf_model_params_fstate, (key1, key2)\n\n        nonvisited.remove(key1)\n\n        src_value = tf_model_params_fstate[key2]\n        if key2[-1] == \"kernel\" and key2[-2] in (\"key\", \"value\", \"query\"):\n            shape = src_value.shape\n            src_value = src_value.reshape((shape[0], 12, 64))\n\n        if key2[-1] == \"bias\" and key2[-2] in (\"key\", \"value\", \"query\"):\n            src_value = src_value.reshape((12, 64))\n\n        if key2[-4:] == (\"attention\", \"output\", \"dense\", \"kernel\"):\n            shape = src_value.shape\n            src_value = src_value.reshape((12, 64, shape[-1]))\n\n        dst_value = flax_model_params_fstate[key1]\n        assert src_value.shape == dst_value.value.shape, (\n            key2, src_value.shape, key1, dst_value.value.shape\n        )\n        dst_value.value = src_value.copy()\n        assert dst_value.value.mean() == src_value.mean(), (\n            dst_value.value, src_value.mean()\n        )\n\n    assert len(nonvisited) == 0, nonvisited\n\n    nnx.update(dst_model, nnx.State.from_flat_path(flax_model_params_fstate))\n\nvit_inplace_copy_weights(src_model=tf_model, dst_model=model)\n\nmodel.classifier = nnx.Linear(model.classifier.in_features, 5, rngs=nnx.Rngs(0))\n\nnum_epochs = 3\nlearning_rate = 0.001\nmomentum = 0.8\ntotal_steps = len(train_dataset) // train_batch_size\n\nlr_schedule = optax.linear_schedule(learning_rate, 0.0, num_epochs * total_steps)\n\noptimizer = nnx.Optimizer(model, optax.sgd(lr_schedule, momentum, nesterov=True))\n\ndef compute_losses_and_logits(model: nnx.Module, images: jax.Array, labels: jax.Array):\n    logits = model(images)\n\n    loss = optax.softmax_cross_entropy_with_integer_labels(\n        logits=logits, labels=labels\n    ).mean()\n    return loss, logits\n\n@nnx.jit\ndef train_step(\n    model: nnx.Module, optimizer: nnx.Optimizer, batch: dict[str, np.ndarray]\n):\n    # Convert np.ndarray to jax.Array on GPU\n    images = jnp.array(batch[\"image\"])\n    labels = jnp.array(batch[\"label\"], dtype=jnp.int32)\n\n    grad_fn = nnx.value_and_grad(compute_losses_and_logits, has_aux=True)\n    (loss, logits), grads = grad_fn(model, images, labels)\n\n    optimizer.update(grads)  # In-place updates.\n\n    return loss\n\n@nnx.jit\ndef eval_step(\n    model: nnx.Module, batch: dict[str, np.ndarray], eval_metrics: nnx.MultiMetric\n):\n    # Convert np.ndarray to jax.Array on GPU\n    images = jnp.array(batch[\"image\"])\n    labels = jnp.array(batch[\"label\"], dtype=jnp.int32)\n    loss, logits = compute_losses_and_logits(model, images, labels)\n\n    eval_metrics.update(\n        loss=loss,\n        logits=logits,\n        labels=labels,\n    )\n\neval_metrics = nnx.MultiMetric(\n    loss=nnx.metrics.Average('loss'),\n    accuracy=nnx.metrics.Accuracy(),\n)\n\ntrain_metrics_history = {\n    \"train_loss\": [],\n}\n\neval_metrics_history = {\n    \"val_loss\": [],\n    \"val_accuracy\": [],\n}",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Fine-tuning the model"
    ]
  },
  {
    "objectID": "ai/fl/fl_finetune.html#load-packages",
    "href": "ai/fl/fl_finetune.html#load-packages",
    "title": "Fine-tuning the model",
    "section": "Load packages",
    "text": "Load packages\n# to have a progress bar during training\nimport tqdm\n\n# to visualize evolution of loss and sample data\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Fine-tuning the model"
    ]
  },
  {
    "objectID": "ai/fl/fl_finetune.html#training-and-evaluation-functions",
    "href": "ai/fl/fl_finetune.html#training-and-evaluation-functions",
    "title": "Fine-tuning the model",
    "section": "Training and evaluation functions",
    "text": "Training and evaluation functions\nbar_format = \"{desc}[{n_fmt}/{total_fmt}]{postfix} [{elapsed}&lt;{remaining}]\"\n\ndef train_one_epoch(epoch):\n    model.train()\n    with tqdm.tqdm(\n        desc=f\"[train] epoch: {epoch}/{num_epochs}, \",\n        total=total_steps,\n        bar_format=bar_format,\n        leave=True,\n    ) as pbar:\n        for batch in train_loader:\n            loss = train_step(model, optimizer, batch)\n            train_metrics_history[\"train_loss\"].append(loss.item())\n            pbar.set_postfix({\"loss\": loss.item()})\n            pbar.update(1)\n\ndef evaluate_model(epoch):\n    model.eval()\n\n    eval_metrics.reset()\n    for val_batch in val_loader:\n        eval_step(model, val_batch, eval_metrics)\n\n    for metric, value in eval_metrics.compute().items():\n        eval_metrics_history[f'val_{metric}'].append(value)\n\n    print(f\"[val] epoch: {epoch + 1}/{num_epochs}\")\n    print(f\"- total loss: {eval_metrics_history['val_loss'][-1]:0.4f}\")\n    print(f\"- Accuracy: {eval_metrics_history['val_accuracy'][-1]:0.4f}\")",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Fine-tuning the model"
    ]
  },
  {
    "objectID": "ai/fl/fl_finetune.html#train-the-model",
    "href": "ai/fl/fl_finetune.html#train-the-model",
    "title": "Fine-tuning the model",
    "section": "Train the model",
    "text": "Train the model\n%%time\n\nfor epoch in range(num_epochs):\n    train_one_epoch(epoch)\n    evaluate_model(epoch)",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Fine-tuning the model"
    ]
  },
  {
    "objectID": "ai/fl/fl_finetune.html#oom-issues",
    "href": "ai/fl/fl_finetune.html#oom-issues",
    "title": "Fine-tuning the model",
    "section": "OOM issues",
    "text": "OOM issues\nI ran out of memory running this code on my machine.\nOut of memory (OOM) problems are common when trying to train a model with JAX on GPUs. See for instance this question on Stack Overflow and this issue in the JAX repo.\nAccording to the JAX documentation on GPU memory allocation, you can try the following:\nimport os\nos.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\nos.environ['XLA_PYTHON_CLIENT_ALLOCATOR'] = 'platform'\nos.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '0.5'\nor, if you use IPython (or Jupyter which runs IPython), you can use the equivalent syntax using the IPython built-in magic command to set environment variables %env:\n%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n%env XLA_PYTHON_CLIENT_ALLOCATOR=platform\n%env XLA_PYTHON_CLIENT_MEM_FRACTION=0.5\nNone of these solutions worked for me neither on my machine nor on Cedar and I am starting to suspect that there is a problem with this particular version of jaxlib.\nWithout GPUs (so on our training cluster), training will be much longer, but you won‚Äôt run into this problem.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Fine-tuning the model"
    ]
  },
  {
    "objectID": "ai/fl/fl_finetune.html#metrics-graphs",
    "href": "ai/fl/fl_finetune.html#metrics-graphs",
    "title": "Fine-tuning the model",
    "section": "Metrics graphs",
    "text": "Metrics graphs\nIf we hadn‚Äôt run out of memory, we could graph our metrics.\nEvolution of the loss during training:\nplt.plot(train_metrics_history[\"train_loss\"], label=\"Loss value during the training\")\nplt.legend()\nLoss and accuracy on the validation set:\nfig, axs = plt.subplots(1, 2, figsize=(10, 10))\naxs[0].set_title(\"Loss value on validation set\")\naxs[0].plot(eval_metrics_history[\"val_loss\"])\naxs[1].set_title(\"Accuracy on validation set\")\naxs[1].plot(eval_metrics_history[\"val_accuracy\"])",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Fine-tuning the model"
    ]
  },
  {
    "objectID": "ai/fl/fl_finetune.html#check-sample-data",
    "href": "ai/fl/fl_finetune.html#check-sample-data",
    "title": "Fine-tuning the model",
    "section": "Check sample data",
    "text": "Check sample data\nAnd we could look at the model predictions for 5 items:\ntest_indices = [1, 250, 500, 750, 1000]\n\ntest_images = jnp.array([val_dataset[i][\"image\"] for i in test_indices])\nexpected_labels = [val_dataset[i][\"label\"] for i in test_indices]\n\nmodel.eval()\npreds = model(test_images)\nnum_samples = len(test_indices)\nnames_map = train_dataset.features[\"label\"].names\n\nprobas = nnx.softmax(preds, axis=1)\npred_labels = probas.argmax(axis=1)\n\n\nfig, axs = plt.subplots(1, num_samples, figsize=(20, 10))\nfor i in range(num_samples):\n    img, expected_label = test_images[i], expected_labels[i]\n\n    pred_label = pred_labels[i].item()\n    proba = probas[i, pred_label].item()\n    if img.dtype in (np.float32, ):\n        img = ((img - img.min()) / (img.max() - img.min()) * 255.0).astype(np.uint8)\n\n    expected_label_str = names_map[inv_labels_mapping[expected_label]]\n    pred_label_str = names_map[inv_labels_mapping[pred_label]]\n    axs[i].set_title(f\"Expected: {expected_label_str} vs \\nPredicted: {pred_label_str}, P={proba:.2f}\")\n    axs[i].imshow(img)",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Fine-tuning the model"
    ]
  },
  {
    "objectID": "ai/fl/fl_cnn.html",
    "href": "ai/fl/fl_cnn.html",
    "title": "Defining model architecture",
    "section": "",
    "text": "In this section, we define a model with Flax‚Äôs new API called NNX."
  },
  {
    "objectID": "ai/fl/fl_cnn.html#context",
    "href": "ai/fl/fl_cnn.html#context",
    "title": "Defining model architecture",
    "section": "Context",
    "text": "Context\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nproc\nProcess data\n\n\n\nload-&gt;proc\n\n\n\n\ntv\n\ntorchvision\n\n\n\n\nnn\nDefine architecture\n\n\n\nproc-&gt;nn\n\n\n\n\npretr\nPre-trained model\n\n\n\n\nopt\nHyperparameters\n\n\n\nnn-&gt;opt\n\n\n\n\npretr-&gt;nn\n\n\n\n\ncp\nCheckpoint\n\n\n\nopt-&gt;cp\n\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\ngr\n\ngrain\n\n\n\n\ngr-&gt;proc\n\n\n\n\n\ntv-&gt;proc\n\n\n\n\n\ntr\n\ntransformers\n\n\n\ntr-&gt;pretr\n\n\n\n\n\nfl\n\nflax\n\n\n\n\nfl-&gt;nn\n\n\n\n\n\noa\n\noptax\n\n\n\noa-&gt;opt\n\n\n\n\n\nob\n\norbax\n\n\n\nob-&gt;cp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteMinimal necessary code from previous sections\n\n\n\n\n\nfrom datasets import load_dataset\nimport numpy as np\nfrom torchvision.transforms import v2 as T\nimport grain.python as grain\n\ntrain_size = 5 * 750\nval_size = 5 * 250\n\ntrain_dataset = load_dataset(\"food101\",\n                             split=f\"train[:{train_size}]\")\n\nval_dataset = load_dataset(\"food101\",\n                           split=f\"validation[:{val_size}]\")\n\nlabels_mapping = {}\nindex = 0\nfor i in range(0, len(val_dataset), 250):\n    label = val_dataset[i][\"label\"]\n    if label not in labels_mapping:\n        labels_mapping[label] = index\n        index += 1\n\ninv_labels_mapping = {v: k for k, v in labels_mapping.items()}\n\nimg_size = 224\n\ndef to_np_array(pil_image):\n  return np.asarray(pil_image.convert(\"RGB\"))\n\ndef normalize(image):\n    # Image preprocessing matches the one of pretrained ViT\n    mean = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n    std = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n    image = image.astype(np.float32) / 255.0\n    return (image - mean) / std\n\ntv_train_transforms = T.Compose([\n    T.RandomResizedCrop((img_size, img_size), scale=(0.7, 1.0)),\n    T.RandomHorizontalFlip(),\n    T.ColorJitter(0.2, 0.2, 0.2),\n    T.Lambda(to_np_array),\n    T.Lambda(normalize),\n])\n\ntv_test_transforms = T.Compose([\n    T.Resize((img_size, img_size)),\n    T.Lambda(to_np_array),\n    T.Lambda(normalize),\n])\n\ndef get_transform(fn):\n    def wrapper(batch):\n        batch[\"image\"] = [\n            fn(pil_image) for pil_image in batch[\"image\"]\n        ]\n        # map label index between 0 - 19\n        batch[\"label\"] = [\n            labels_mapping[label] for label in batch[\"label\"]\n        ]\n        return batch\n    return wrapper\n\ntrain_transforms = get_transform(tv_train_transforms)\nval_transforms = get_transform(tv_test_transforms)\n\ntrain_dataset = train_dataset.with_transform(train_transforms)\nval_dataset = val_dataset.with_transform(val_transforms)\n\nseed = 12\ntrain_batch_size = 32\nval_batch_size = 2 * train_batch_size\n\ntrain_sampler = grain.IndexSampler(\n    len(train_dataset),\n    shuffle=True,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1,\n)\n\nval_sampler = grain.IndexSampler(\n    len(val_dataset),\n    shuffle=False,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1,\n)\n\ntrain_loader = grain.DataLoader(\n    data_source=train_dataset,\n    sampler=train_sampler,\n    worker_count=4,\n    worker_buffer_size=2,\n    operations=[\n        grain.Batch(train_batch_size, drop_remainder=True),\n    ]\n)\n\nval_loader = grain.DataLoader(\n    data_source=val_dataset,\n    sampler=val_sampler,\n    worker_count=4,\n    worker_buffer_size=2,\n    operations=[\n        grain.Batch(val_batch_size),\n    ]\n)"
  },
  {
    "objectID": "ai/fl/fl_cnn.html#load-packages",
    "href": "ai/fl/fl_cnn.html#load-packages",
    "title": "Defining model architecture",
    "section": "Load packages",
    "text": "Load packages\nPackage and module necessary for this section:\n# to define the model architecture\nfrom flax import nnx\n\n# to get callables from functions with fewer arguments\nfrom functools import partial"
  },
  {
    "objectID": "ai/fl/fl_cnn.html#flax-api",
    "href": "ai/fl/fl_cnn.html#flax-api",
    "title": "Defining model architecture",
    "section": "Flax API",
    "text": "Flax API\nFlax went through several APIs.\nThe initial nn API‚Äînow retired‚Äîgot replaced in 2020 by the Linen API, still available with the Flax package. In 2024, they launched the NNX API.\nEach iteration has moved further from JAX and closer to Python, with a syntax increasingly similar to PyTorch.\nThe old Linen API is a stateless model framework similar to the Julia package Lux.jl. It follows a strict functional programming approach in which the parameters are separate from the model and are passed as inputs to the forward pass along with the data. This is much closer to the JAX sublanguage, more optimized, but restrictive and unpopular in the deep learning community and among Python users.\nBy contrast, the new NNX API is a stateful model framework similar to PyTorch and the older Julia package Flux.jl: model parameters and optimizer state are stored within the model instance. Flax handles a lot of JAX‚Äôs constraints under the hood, making the code more familiar to Python/PyTorch users, simpler, and more forgiving.\nWhile the Linen API still exists, new users are advised to learn the new NNX API."
  },
  {
    "objectID": "ai/fl/fl_cnn.html#simple-cnn",
    "href": "ai/fl/fl_cnn.html#simple-cnn",
    "title": "Defining model architecture",
    "section": "Simple CNN",
    "text": "Simple CNN\nWe will use LeNet-5 [1] model, initially used on the MNIST dataset by LeCun et al. [2]. We modify it to take three-channel images (RGB for colour images) instead of a single channel (black and white images as was the case in the MNIST) and have five categories as final output.\nThe architecture of this model is explained in details in this kaggle post.\nclass CNN(nnx.Module):\n  \"\"\"An adapted LeNet-5 model.\"\"\"\n\n  def __init__(self, *, rngs: nnx.Rngs):\n    self.conv1 = nnx.Conv(3, 6, kernel_size=(5, 5), rngs=rngs)\n    self.max_pool = partial(nnx.max_pool, window_shape=(2, 2), strides=(2, 2))\n    self.conv2 = nnx.Conv(6, 16, kernel_size=(5, 5), rngs=rngs)\n    self.linear1 = nnx.Linear(3136, 120, rngs=rngs)\n    self.linear2 = nnx.Linear(120, 84, rngs=rngs)\n    self.linear3 = nnx.Linear(84, 5, rngs=rngs)\n\n  def __call__(self, x):\n    x = self.max_pool(nnx.relu(self.conv1(x)))\n    x = self.max_pool(nnx.relu(self.conv2(x)))\n    x = x.reshape(x.shape[0], -1)  # flatten\n    x = nnx.relu(self.linear1(x))\n    x = nnx.relu(self.linear2(x))\n    x = self.linear3(x)\n    return x\n\n# Instantiate the model.\nmodel = CNN(rngs=nnx.Rngs(0))\n\n# Visualize it.\nnnx.display(model)\nimport jax.numpy as jnp  # JAX NumPy\n\ny = model(jnp.ones((4, 224, 224, 3)))\ny\nimport optax\n\nlearning_rate = 0.005\nmomentum = 0.9\n\noptimizer = nnx.Optimizer(model, optax.adamw(learning_rate, momentum))\nmetrics = nnx.MultiMetric(\n  accuracy=nnx.metrics.Accuracy(),\n  loss=nnx.metrics.Average('loss'),\n)\n\nnnx.display(optimizer)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About this site",
    "section": "",
    "text": "This site contains Marie-H√©l√®ne Burle‚Äôs latest content.\nHer older training material can be found on the archived sites:"
  },
  {
    "objectID": "about.html#main-training-website",
    "href": "about.html#main-training-website",
    "title": "About this site",
    "section": "Main training website",
    "text": "Main training website\nThis is the MINT (‚ÄúMint Is Not Training‚Äù) website.\nTo view all our training material, please visit the training website."
  },
  {
    "objectID": "about.html#other-websites",
    "href": "about.html#other-websites",
    "title": "About this site",
    "section": "Other websites",
    "text": "Other websites\nIn addition, here are a few of our websites for various training events:\n\nCoding Fundamentals for Humanists 2025 for the Digital Humanities Summer Institute\nSFU Summer School 2025\nCoding Fundamentals for Humanists 2024 for the Digital Humanities Summer Institute\nSFU Summer School 2024\nCoding Fundamentals for Humanists 2023 for the Digital Humanities Summer Institute\nUvic Summer School 2023\nSFU Summer School 2023\nHSS Winter Series 2023\nAutumn School 2022\nTraining Modules 2022\nHSS Winter Series 2022\nCoding Fundamentals for Humanists 2022 for the Digital Humanities Summer Institute\nTraining Modules 2021\nCoding Fundamentals for Humanists 2021 for the Digital Humanities Summer Institute\nSummer School 2020"
  },
  {
    "objectID": "ai/fl/fl_data.html",
    "href": "ai/fl/fl_data.html",
    "title": "Loading data",
    "section": "",
    "text": "In this section, we download the Food-101 dataset [1] that we will later use to train and fine-tune models.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Loading data"
    ]
  },
  {
    "objectID": "ai/fl/fl_data.html#context",
    "href": "ai/fl/fl_data.html#context",
    "title": "Loading data",
    "section": "Context",
    "text": "Context\nStep one of a classic deep learning workflow: getting the data. There are several options. In this example, we use Datasets from Hugging Face.\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nproc\nProcess data\n\n\n\nload-&gt;proc\n\n\n\n\ntv\n\ntorchvision\n\n\n\n\nnn\nDefine architecture\n\n\n\nproc-&gt;nn\n\n\n\n\npretr\nPre-trained model\n\n\n\n\n\nopt\nHyperparameters\n\n\n\nnn-&gt;opt\n\n\n\n\npretr-&gt;nn\n\n\n\n\ntrain\nTrain\n\n\n\nopt-&gt;train\n\n\n\n\ncp\nCheckpoint\n\n\n\ntrain-&gt;cp\n\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\ngr\n\ngrain\n\n\n\n\ngr-&gt;proc\n\n\n\n\n\ntv-&gt;proc\n\n\n\n\n\ntr\n\ntransformers\n\n\n\n\ntr-&gt;pretr\n\n\n\n\n\nfl1\n\nflax\n\n\n\n\n\nfl1-&gt;nn\n\n\n\n\n\nfl2\n\nflax\n\n\n\nfl2-&gt;train\n\n\n\n\n\noa\n\noptax\n\n\n\noa-&gt;opt\n\n\n\n\n\njx\n\njax\n\n\n\njx-&gt;fl2\n\n\n\n\n\nob\n\norbax\n\n\n\nob-&gt;cp",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Loading data"
    ]
  },
  {
    "objectID": "ai/fl/fl_data.html#load-packages",
    "href": "ai/fl/fl_data.html#load-packages",
    "title": "Loading data",
    "section": "Load packages",
    "text": "Load packages\nPackages necessary for this section:\n\n# to get information about a dataset before downloading it\nfrom datasets import load_dataset_builder\n\n# to load dataset from Hugging Face Hub\nfrom datasets import load_dataset\n\n# to display a few samples\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Loading data"
    ]
  },
  {
    "objectID": "ai/fl/fl_data.html#choosing-a-library",
    "href": "ai/fl/fl_data.html#choosing-a-library",
    "title": "Loading data",
    "section": "Choosing a library",
    "text": "Choosing a library\nData can be downloaded and processed manually, but many datasets are available via Hugging Face datasets, torchvision, and TensorFlow Datasets. Remember that JAX does not implement domain-specific utilities and is not a deep learning library. Flax is a deep learning library, but, because there are already so many good options to load and process data, they did not implement a method of their own.\nChoose the library you are the most familiar with, or the one for which you found code somewhere, or the one that seems the easiest to you, or provides the exact functionality that you want for your project.\nThe Food-101 dataset for instance can be accessed with torchvision.datasets.Food101 since it is one of TorchVision datasets or with tfds.image_classification.Food101 since it is also one of TFDS datasets.\nIt is also in the Hugging Face Hub and that‚Äôs the method that we will use here.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Loading data"
    ]
  },
  {
    "objectID": "ai/fl/fl_data.html#hugging-face-datasets",
    "href": "ai/fl/fl_data.html#hugging-face-datasets",
    "title": "Loading data",
    "section": "Hugging Face datasets",
    "text": "Hugging Face datasets\nThe Datasets library from Hugging Face is a lightweight, framework-agnostic, and easy to use API to download datasets from the Hugging Face Hub. It uses Apache Arrow‚Äôs efficient caching system, allowing large datasets to be used on machines with small memory [2].\n\nSearch dataset\nGo to the Hugging Face Hub and search through thousands of open source datasets provided by the community.\n\n\nInspect dataset\nYou can get information on a dataset before downloading it.\nLoad the dataset builder for the dataset you are interested in:\n\nds_builder = load_dataset_builder(\"food101\")\n\nGet a description of the dataset (if it exists‚Äîhere it doesn‚Äôt):\n\nds_builder.info.description\n\n''\n\n\nGet information on the features:\n\nds_builder.info.features\n\n{'image': Image(mode=None, decode=True),\n 'label': ClassLabel(names=['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli', 'caprese_salad', 'carrot_cake', 'ceviche', 'cheesecake', 'cheese_plate', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros', 'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel', 'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad', 'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque', 'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta', 'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad', 'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi', 'tacos', 'takoyaki', 'tiramisu', 'tuna_tartare', 'waffles'])}\n\n\n\n\nDownload dataset\nWe will only use the first 5 classes of food (instead of 101) to test our code. To prevent us from all downloading the data (by default in ~/.cache/huggingface), we will use a joint cache directory at /project/60055/data.\ntrain_size = 5 * 750\nval_size = 5 * 250\n\ntrain_dataset = load_dataset(\"food101\",\n                             split=f\"train[:{train_size}]\",\n                             cache_dir=\"/project/60055/data\")\n\nval_dataset = load_dataset(\"food101\",\n                           split=f\"validation[:{val_size}]\",\n                           cache_dir=\"/project/60055/data\")",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Loading data"
    ]
  },
  {
    "objectID": "ai/fl/fl_data.html#explore-data",
    "href": "ai/fl/fl_data.html#explore-data",
    "title": "Loading data",
    "section": "Explore data",
    "text": "Explore data\nLet‚Äôs inspect our data:\n\nprint(\"Training set size:\", len(train_dataset))\nprint(\"Validation set size:\", len(val_dataset))\nprint(\"Training set shape:\", train_dataset.shape)\nprint(\"Validation set shape:\", val_dataset.shape)\nprint(\"First item of training set:\", train_dataset[0])\nprint(\"Firt image of training set:\", train_dataset[0][\"image\"])\nprint(\"First label of training set:\", train_dataset[0][\"label\"])\n\nTraining set size: 3750\nValidation set size: 1250\nTraining set shape: (3750, 2)\nValidation set shape: (1250, 2)\nFirst item of training set: {'image': &lt;PIL.Image.Image image mode=RGB size=384x512 at 0x7F6CE1C26CF0&gt;, 'label': 6}\nFirt image of training set: &lt;PIL.Image.Image image mode=RGB size=384x512 at 0x7F6CE1748410&gt;\nFirst label of training set: 6\n\n\nHere is the beginning of the list of foods:\n\nprint(train_dataset.features[\"label\"].names[:5])\n\n['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare']\n\n\nAnd here is the food of the first item in the training set (label 6):\n\nprint(\"First food of training set:\", train_dataset.features[\"label\"].names[6])\n\nFirst food of training set: beignets\n\n\nTo make this simpler, we can create a mapping of the labels matching their order:\n\nlabels_mapping = {}\nindex = 0\nfor i in range(0, len(val_dataset), 250):\n    label = val_dataset[i][\"label\"]\n    if label not in labels_mapping:\n        labels_mapping[label] = index\n        index += 1\n\ninv_labels_mapping = {v: k for k, v in labels_mapping.items()}\n\nprint(inv_labels_mapping)\n\n{0: 6, 1: 79, 2: 81, 3: 53, 4: 10}\n\n\nAnd a mapping of the names:\n\nnames_map={k: train_dataset.features[\"label\"].names[v] for k, v in inv_labels_mapping.items()}\nprint(names_map)\n\n{0: 'beignets', 1: 'prime_rib', 2: 'ramen', 3: 'hamburger', 4: 'bruschetta'}\n\n\nNow, to get the food of the first item, we just have to do:\n\nprint(names_map[0])\n\nbeignets\n\n\nHere is a function to display some samples (their images, label, and food type):\n\ndef display_datapoints(*datapoints, tag=\"\", names_map=None):\n    num_samples = len(datapoints)\n\n    fig, axs = plt.subplots(1, num_samples, figsize=(20, 10))\n    for i, datapoint in enumerate(datapoints):\n        if isinstance(datapoint, dict):\n            img, label = datapoint[\"image\"], datapoint[\"label\"]\n        else:\n            img, label = datapoint\n\n        if hasattr(img, \"dtype\") and img.dtype in (np.float32, ):\n            img = ((img - img.min()) / (img.max() - img.min()) * 255.0).astype(np.uint8)\n\n        label_str = f\" ({names_map[label]})\" if names_map is not None else \"\"\n        axs[i].set_title(f\"{tag} Label: {label}{label_str}\")\n        axs[i].imshow(img)\n\nLet‚Äôs display the first 3 items (images and labels) of both the training and validation sets:\n\ndisplay_datapoints(\n    train_dataset[0],\n    train_dataset[1],\n    train_dataset[2],\n    tag=\"(Training)\",\n    names_map=train_dataset.features[\"label\"].names,\n)\n\ndisplay_datapoints(\n    val_dataset[0],\n    val_dataset[1],\n    val_dataset[2],\n    tag=\"(Validation)\",\n    names_map=val_dataset.features[\"label\"].names,\n)",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Loading data"
    ]
  },
  {
    "objectID": "ai/fl/fl_hyperparameters.html",
    "href": "ai/fl/fl_hyperparameters.html",
    "title": "Hyperparameters",
    "section": "",
    "text": "In this section, we set the hyperparameters that will be used during training: the optimizer, the loss function, the number of epochs, the momentum, the initial learning rate and a learning rate schedule, the training and evaluation steps, and the metrics to evaluate training.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Hyperparameters"
    ]
  },
  {
    "objectID": "ai/fl/fl_hyperparameters.html#context",
    "href": "ai/fl/fl_hyperparameters.html#context",
    "title": "Hyperparameters",
    "section": "Context",
    "text": "Context\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nproc\nProcess data\n\n\n\nload-&gt;proc\n\n\n\n\ntv\n\ntorchvision\n\n\n\n\nnn\nDefine architecture\n\n\n\nproc-&gt;nn\n\n\n\n\npretr\nPre-trained model\n\n\n\n\n\nopt\nHyperparameters\n\n\n\nnn-&gt;opt\n\n\n\n\npretr-&gt;nn\n\n\n\n\ntrain\nTrain\n\n\n\nopt-&gt;train\n\n\n\n\ncp\nCheckpoint\n\n\n\ntrain-&gt;cp\n\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\ngr\n\ngrain\n\n\n\n\ngr-&gt;proc\n\n\n\n\n\ntv-&gt;proc\n\n\n\n\n\ntr\n\ntransformers\n\n\n\n\ntr-&gt;pretr\n\n\n\n\n\nfl1\n\nflax\n\n\n\n\n\nfl1-&gt;nn\n\n\n\n\n\nfl2\n\nflax\n\n\n\nfl2-&gt;train\n\n\n\n\n\noa\n\noptax\n\n\n\noa-&gt;opt\n\n\n\n\n\njx\n\nJAX\n\n\n\njx-&gt;fl2\n\n\n\n\n\nob\n\norbax\n\n\n\nob-&gt;cp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteMinimal necessary code from previous sections\n\n\n\n\n\nfrom datasets import load_dataset\nimport numpy as np\nfrom torchvision.transforms import v2 as T\nimport grain.python as grain\nimport jax\nimport jax.numpy as jnp\nfrom flax import nnx\nfrom transformers import FlaxViTForImageClassification\n\ntrain_size = 5 * 750\nval_size = 5 * 250\n\ntrain_dataset = load_dataset(\"food101\",\n                             split=f\"train[:{train_size}]\")\n\nval_dataset = load_dataset(\"food101\",\n                           split=f\"validation[:{val_size}]\")\n\nlabels_mapping = {}\nindex = 0\nfor i in range(0, len(val_dataset), 250):\n    label = val_dataset[i][\"label\"]\n    if label not in labels_mapping:\n        labels_mapping[label] = index\n        index += 1\n\ninv_labels_mapping = {v: k for k, v in labels_mapping.items()}\n\nimg_size = 224\n\ndef to_np_array(pil_image):\n  return np.asarray(pil_image.convert(\"RGB\"))\n\ndef normalize(image):\n    mean = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n    std = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n    image = image.astype(np.float32) / 255.0\n    return (image - mean) / std\n\ntv_train_transforms = T.Compose([\n    T.RandomResizedCrop((img_size, img_size), scale=(0.7, 1.0)),\n    T.RandomHorizontalFlip(),\n    T.ColorJitter(0.2, 0.2, 0.2),\n    T.Lambda(to_np_array),\n    T.Lambda(normalize),\n])\n\ntv_test_transforms = T.Compose([\n    T.Resize((img_size, img_size)),\n    T.Lambda(to_np_array),\n    T.Lambda(normalize),\n])\n\ndef get_transform(fn):\n    def wrapper(batch):\n        batch[\"image\"] = [\n            fn(pil_image) for pil_image in batch[\"image\"]\n        ]\n        batch[\"label\"] = [\n            labels_mapping[label] for label in batch[\"label\"]\n        ]\n        return batch\n    return wrapper\n\ntrain_transforms = get_transform(tv_train_transforms)\nval_transforms = get_transform(tv_test_transforms)\n\ntrain_dataset = train_dataset.with_transform(train_transforms)\nval_dataset = val_dataset.with_transform(val_transforms)\n\nseed = 12\ntrain_batch_size = 32\nval_batch_size = 2 * train_batch_size\n\ntrain_sampler = grain.IndexSampler(\n    len(train_dataset),\n    shuffle=True,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1,\n)\n\nval_sampler = grain.IndexSampler(\n    len(val_dataset),\n    shuffle=False,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1,\n)\n\ntrain_loader = grain.DataLoader(\n    data_source=train_dataset,\n    sampler=train_sampler,\n    worker_count=4,\n    worker_buffer_size=2,\n    operations=[\n        grain.Batch(train_batch_size, drop_remainder=True),\n    ]\n)\n\nval_loader = grain.DataLoader(\n    data_source=val_dataset,\n    sampler=val_sampler,\n    worker_count=4,\n    worker_buffer_size=2,\n    operations=[\n        grain.Batch(val_batch_size),\n    ]\n)\n\nclass VisionTransformer(nnx.Module):\n    def __init__(\n        self,\n        num_classes: int = 1000,\n        in_channels: int = 3,\n        img_size: int = 224,\n        patch_size: int = 16,\n        num_layers: int = 12,\n        num_heads: int = 12,\n        mlp_dim: int = 3072,\n        hidden_size: int = 768,\n        dropout_rate: float = 0.1,\n        *,\n        rngs: nnx.Rngs = nnx.Rngs(0),\n    ):\n        # Patch and position embedding\n        n_patches = (img_size // patch_size) ** 2\n        self.patch_embeddings = nnx.Conv(\n            in_channels,\n            hidden_size,\n            kernel_size=(patch_size, patch_size),\n            strides=(patch_size, patch_size),\n            padding=\"VALID\",\n            use_bias=True,\n            rngs=rngs,\n        )\n\n        initializer = jax.nn.initializers.truncated_normal(stddev=0.02)\n        self.position_embeddings = nnx.Param(\n            initializer(\n                rngs.params(),\n                (1, n_patches + 1, hidden_size),\n                jnp.float32\n            )\n        )\n        self.dropout = nnx.Dropout(dropout_rate, rngs=rngs)\n\n        self.cls_token = nnx.Param(jnp.zeros((1, 1, hidden_size)))\n\n        # Transformer Encoder blocks\n        self.encoder = nnx.Sequential(*[\n            TransformerEncoder(\n                hidden_size,\n                mlp_dim,\n                num_heads,\n                dropout_rate,\n                rngs=rngs\n            )\n            for i in range(num_layers)\n        ])\n        self.final_norm = nnx.LayerNorm(hidden_size, rngs=rngs)\n\n        # Classification head\n        self.classifier = nnx.Linear(hidden_size, num_classes, rngs=rngs)\n\n    def __call__(self, x: jax.Array) -&gt; jax.Array:\n        # Patch and position embedding\n        patches = self.patch_embeddings(x)\n        batch_size = patches.shape[0]\n        patches = patches.reshape(batch_size, -1, patches.shape[-1])\n\n        cls_token = jnp.tile(self.cls_token, [batch_size, 1, 1])\n        x = jnp.concat([cls_token, patches], axis=1)\n        embeddings = x + self.position_embeddings\n        embeddings = self.dropout(embeddings)\n\n        # Encoder blocks\n        x = self.encoder(embeddings)\n        x = self.final_norm(x)\n\n        # fetch the first token\n        x = x[:, 0]\n\n        # Classification\n        return self.classifier(x)\n\nclass TransformerEncoder(nnx.Module):\n    def __init__(\n        self,\n        hidden_size: int,\n        mlp_dim: int,\n        num_heads: int,\n        dropout_rate: float = 0.0,\n        *,\n        rngs: nnx.Rngs = nnx.Rngs(0),\n    ) -&gt; None:\n\n        self.norm1 = nnx.LayerNorm(hidden_size, rngs=rngs)\n        self.attn = nnx.MultiHeadAttention(\n            num_heads=num_heads,\n            in_features=hidden_size,\n            dropout_rate=dropout_rate,\n            broadcast_dropout=False,\n            decode=False,\n            deterministic=False,\n            rngs=rngs,\n        )\n        self.norm2 = nnx.LayerNorm(hidden_size, rngs=rngs)\n\n        self.mlp = nnx.Sequential(\n            nnx.Linear(hidden_size, mlp_dim, rngs=rngs),\n            nnx.gelu,\n            nnx.Dropout(dropout_rate, rngs=rngs),\n            nnx.Linear(mlp_dim, hidden_size, rngs=rngs),\n            nnx.Dropout(dropout_rate, rngs=rngs),\n        )\n\n    def __call__(self, x: jax.Array) -&gt; jax.Array:\n        x = x + self.attn(self.norm1(x))\n        x = x + self.mlp(self.norm2(x))\n        return x\n\nmodel = VisionTransformer(num_classes=1000)\n\ntf_model = FlaxViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n\ndef vit_inplace_copy_weights(*, src_model, dst_model):\n    assert isinstance(src_model, FlaxViTForImageClassification)\n    assert isinstance(dst_model, VisionTransformer)\n\n    tf_model_params = src_model.params\n    tf_model_params_fstate = nnx.traversals.flatten_mapping(tf_model_params)\n\n    flax_model_params = nnx.state(dst_model, nnx.Param)\n    flax_model_params_fstate = flax_model_params.flat_state()\n\n    params_name_mapping = {\n        (\"cls_token\",): (\"vit\", \"embeddings\", \"cls_token\"),\n        (\"position_embeddings\",): (\n            \"vit\",\n            \"embeddings\",\n            \"position_embeddings\"\n        ),\n        **{\n            (\"patch_embeddings\", x): (\n                \"vit\",\n                \"embeddings\",\n                \"patch_embeddings\",\n                \"projection\",\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n        },\n        **{\n            (\"encoder\", \"layers\", i, \"attn\", y, x): (\n                \"vit\",\n                \"encoder\",\n                \"layer\",\n                str(i),\n                \"attention\",\n                \"attention\",\n                y,\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n            for y in [\"key\", \"value\", \"query\"]\n            for i in range(12)\n        },\n        **{\n            (\"encoder\", \"layers\", i, \"attn\", \"out\", x): (\n                \"vit\",\n                \"encoder\",\n                \"layer\",\n                str(i),\n                \"attention\",\n                \"output\",\n                \"dense\",\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n            for i in range(12)\n        },\n        **{\n            (\"encoder\", \"layers\", i, \"mlp\", \"layers\", y1, x): (\n                \"vit\",\n                \"encoder\",\n                \"layer\",\n                str(i),\n                y2,\n                \"dense\",\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n            for y1, y2 in [(0, \"intermediate\"), (3, \"output\")]\n            for i in range(12)\n        },\n        **{\n            (\"encoder\", \"layers\", i, y1, x): (\n                \"vit\", \"encoder\", \"layer\", str(i), y2, x\n            )\n            for x in [\"scale\", \"bias\"]\n            for y1, y2 in [\n                    (\"norm1\", \"layernorm_before\"),\n                    (\"norm2\", \"layernorm_after\")\n            ]\n            for i in range(12)\n        },\n        **{\n            (\"final_norm\", x): (\"vit\", \"layernorm\", x)\n            for x in [\"scale\", \"bias\"]\n        },\n        **{\n            (\"classifier\", x): (\"classifier\", x)\n            for x in [\"kernel\", \"bias\"]\n        }\n    }\n\n    nonvisited = set(flax_model_params_fstate.keys())\n\n    for key1, key2 in params_name_mapping.items():\n        assert key1 in flax_model_params_fstate, key1\n        assert key2 in tf_model_params_fstate, (key1, key2)\n\n        nonvisited.remove(key1)\n\n        src_value = tf_model_params_fstate[key2]\n        if key2[-1] == \"kernel\" and key2[-2] in (\"key\", \"value\", \"query\"):\n            shape = src_value.shape\n            src_value = src_value.reshape((shape[0], 12, 64))\n\n        if key2[-1] == \"bias\" and key2[-2] in (\"key\", \"value\", \"query\"):\n            src_value = src_value.reshape((12, 64))\n\n        if key2[-4:] == (\"attention\", \"output\", \"dense\", \"kernel\"):\n            shape = src_value.shape\n            src_value = src_value.reshape((12, 64, shape[-1]))\n\n        dst_value = flax_model_params_fstate[key1]\n        assert src_value.shape == dst_value.value.shape, (\n            key2, src_value.shape, key1, dst_value.value.shape\n        )\n        dst_value.value = src_value.copy()\n        assert dst_value.value.mean() == src_value.mean(), (\n            dst_value.value, src_value.mean()\n        )\n\n    assert len(nonvisited) == 0, nonvisited\n\n    nnx.update(dst_model, nnx.State.from_flat_path(flax_model_params_fstate))\n\nvit_inplace_copy_weights(src_model=tf_model, dst_model=model)\n\nmodel.classifier = nnx.Linear(model.classifier.in_features, 5, rngs=nnx.Rngs(0))",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Hyperparameters"
    ]
  },
  {
    "objectID": "ai/fl/fl_hyperparameters.html#load-packages",
    "href": "ai/fl/fl_hyperparameters.html#load-packages",
    "title": "Hyperparameters",
    "section": "Load packages",
    "text": "Load packages\nPackages and modules necessary for this section:\n# to set the learning rate and optimizer\nimport optax\n\n# to plot the evolution of learning rate\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Hyperparameters"
    ]
  },
  {
    "objectID": "ai/fl/fl_hyperparameters.html#optimizer-and-learning-rate-schedule",
    "href": "ai/fl/fl_hyperparameters.html#optimizer-and-learning-rate-schedule",
    "title": "Hyperparameters",
    "section": "Optimizer and learning rate schedule",
    "text": "Optimizer and learning rate schedule\nnum_epochs = 3\nlearning_rate = 0.001\nmomentum = 0.8\ntotal_steps = len(train_dataset) // train_batch_size\n\nlr_schedule = optax.linear_schedule(learning_rate, 0.0, num_epochs * total_steps)\n\niterate_subsample = np.linspace(0, num_epochs * total_steps, 100)\nplt.plot(\n    np.linspace(0, num_epochs, len(iterate_subsample)),\n    [lr_schedule(i) for i in iterate_subsample],\n    lw=3,\n)\nplt.title(\"Learning rate\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Learning rate\")\nplt.grid()\nplt.xlim((0, num_epochs))\nplt.show()\n\noptimizer = nnx.Optimizer(model, optax.sgd(lr_schedule, momentum, nesterov=True))",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Hyperparameters"
    ]
  },
  {
    "objectID": "ai/fl/fl_hyperparameters.html#loss-function",
    "href": "ai/fl/fl_hyperparameters.html#loss-function",
    "title": "Hyperparameters",
    "section": "Loss function",
    "text": "Loss function\ndef compute_losses_and_logits(model: nnx.Module, images: jax.Array, labels: jax.Array):\n    logits = model(images)\n\n    loss = optax.softmax_cross_entropy_with_integer_labels(\n        logits=logits, labels=labels\n    ).mean()\n    return loss, logits",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Hyperparameters"
    ]
  },
  {
    "objectID": "ai/fl/fl_hyperparameters.html#train-and-evaluation-steps",
    "href": "ai/fl/fl_hyperparameters.html#train-and-evaluation-steps",
    "title": "Hyperparameters",
    "section": "Train and evaluation steps",
    "text": "Train and evaluation steps\nThis is the part that is computationally intensive and where we want to use JAX and its efficiency. In particularly, we want to JIT-compile the functions that will do the training and evaluation.\nJAX requires a strictly functional programming version of Python. This is what allows its internal representations (the Jaxprs) to perform transformations (jax.jit, jax.vmap, jax.pmap, and jax.grad and the convenience decorators @jax.jit, @jax.vmap, @jax.pmap, and @jax.grad).\nFlax does not respect this anymore with the new NNX API. The JAX transformations can thus not be applied directly in Flax (as they were in the Linen API) and require adapted versions that handle objects‚Äô states under the hood. The NNX versions of these transformations are called nnx.jit, nnx.vmap, nnx.pmap, and nnx.grad (and the convenience decorators @nnx.jit, @nnx.vmap, @nnx.pmap, and @nnx.grad).\n@nnx.jit\ndef train_step(\n    model: nnx.Module, optimizer: nnx.Optimizer, batch: dict[str, np.ndarray]\n):\n    # Convert np.ndarray to jax.Array on GPU\n    images = jnp.array(batch[\"image\"])\n    labels = jnp.array(batch[\"label\"], dtype=jnp.int32)\n\n    grad_fn = nnx.value_and_grad(compute_losses_and_logits, has_aux=True)\n    (loss, logits), grads = grad_fn(model, images, labels)\n\n    optimizer.update(grads)  # In-place updates.\n\n    return loss\n\n@nnx.jit\ndef eval_step(\n    model: nnx.Module, batch: dict[str, np.ndarray], eval_metrics: nnx.MultiMetric\n):\n    # Convert np.ndarray to jax.Array on GPU\n    images = jnp.array(batch[\"image\"])\n    labels = jnp.array(batch[\"label\"], dtype=jnp.int32)\n    loss, logits = compute_losses_and_logits(model, images, labels)\n\n    eval_metrics.update(\n        loss=loss,\n        logits=logits,\n        labels=labels,\n    )",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Hyperparameters"
    ]
  },
  {
    "objectID": "ai/fl/fl_hyperparameters.html#training-metrics",
    "href": "ai/fl/fl_hyperparameters.html#training-metrics",
    "title": "Hyperparameters",
    "section": "Training metrics",
    "text": "Training metrics\neval_metrics = nnx.MultiMetric(\n    loss=nnx.metrics.Average('loss'),\n    accuracy=nnx.metrics.Accuracy(),\n)\n\ntrain_metrics_history = {\n    \"train_loss\": [],\n}\n\neval_metrics_history = {\n    \"val_loss\": [],\n    \"val_accuracy\": [],\n}",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Hyperparameters"
    ]
  },
  {
    "objectID": "ai/fl/fl_jax.html",
    "href": "ai/fl/fl_jax.html",
    "title": "Introduction: JAX",
    "section": "",
    "text": "A brief introduction to JAX and to the JAX deep learning stack.\n\nSlides (Click and wait: the presentation might take a few instants to load)\nSlides content for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Introduction: JAX"
    ]
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#what-is-jax",
    "href": "ai/fl/fl_jax_slides.html#what-is-jax",
    "title": "A brief intro to",
    "section": "What is JAX?",
    "text": "What is JAX?\n\nLibrary for Python developed by Google\n\n\nKey data structure: Array\n\n\nComposition, transformation, and differentiation of numerical programs\n\n\nCompilation for CPUs, GPUs, and TPUs\n\n\nNumPy-like and lower-level APIs\n\n\nRequires strict functional programming"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#fast",
    "href": "ai/fl/fl_jax_slides.html#fast",
    "title": "A brief intro to",
    "section": "Fast",
    "text": "Fast\n\nDefault data type suited for deep learning\nLike PyTorch, uses float32 as default. This level of precision is suitable for deep learning and increases efficiency (by contrast, NumPy defaults to float64)\nJIT compilation\nThe same code can run on CPUs or on accelerators (GPUs and TPUs)\nXLA (Accelerated Linear Algebra) optimization\nAsynchronous dispatch\nVectorization, data parallelism, and sharding\nAll levels of shared and distributed memory parallelism are supported"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#great-ad",
    "href": "ai/fl/fl_jax_slides.html#great-ad",
    "title": "A brief intro to",
    "section": "Great AD",
    "text": "Great AD\n\n\n\n\n\n\n\n\n\n01\n\n\nAutodiff method\n\n\n\n1\nStatic graph\nand XLA\n\n\n\n\n02\n\n\nFramework\n\n\n\n\n2\nDynamic graph\n\n\n\n1-&gt;2\n\n\n\n\n\na\n\nTensorFlow\n\n\n\n\n4\nDynamic graph\nand XLA\n\n\n\n2-&gt;4\n\n\n\n\n\nb\n\nPyTorch\n\n\n\n\n5\nPseudo-dynamic\nand XLA\n\n\n\n4-&gt;5\n\n\n\n\n\nd\n\nTensorFlow2\n\n\n\n\ne\n\nJAX\n\n\n\n\n\n03\n\n\nAdvantage\n\n\n\n\n\n7\nMostly\noptimized AD\n\n\n\n\n\n8\nConvenient\n\n\n\n\n\n9\nConvenient\n\n\n\n\n10\nConvenient and\nmostly optimized AD\n\n\n\n\n\n04\n\n\nDisadvantage\n\n\n\n\n\nA\nManual writing of IR\n\n\n\n\n\nB\nLimited AD optimization\n\n\n\n\n\nD\nDisappointing speed\n\n\n\n\nE\nPure functions\n\n\n\n\n\n\n\n\n\n\n\n\n\n‚ÄÉ‚ÄÉSummarized from a blog post by Chris Rackauckas"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#close-to-the-math",
    "href": "ai/fl/fl_jax_slides.html#close-to-the-math",
    "title": "A brief intro to",
    "section": "Close to the math",
    "text": "Close to the math\nConsidering the function f:\nf = lambda x: x**3 + 2*x**2 - 3*x + 8\nWe can create a new function dfdx that computes the gradient of f w.r.t. x:\nfrom jax import grad\n\ndfdx = grad(f)\ndfdx returns the derivatives:\nprint(dfdx(1.))\n4.0"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#forward-and-reverse-modes",
    "href": "ai/fl/fl_jax_slides.html#forward-and-reverse-modes",
    "title": "A brief intro to",
    "section": "Forward and reverse modes",
    "text": "Forward and reverse modes\n\nreverse-mode vector-Jacobian products: jax.vjp\nforward-mode Jacobian-vector products: jax.jvp"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#higher-order-differentiation",
    "href": "ai/fl/fl_jax_slides.html#higher-order-differentiation",
    "title": "A brief intro to",
    "section": "Higher-order differentiation",
    "text": "Higher-order differentiation\nWith a single variable, the grad function calls can be nested:\nd2fdx = grad(dfdx)   # function to compute 2nd order derivatives\nd3fdx = grad(d2fdx)  # function to compute 3rd order derivatives\n...\nWith several variables, you have to use the functions:\n\njax.jacfwd for forward-mode,\njax.jacrev for reverse-mode."
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#how-does-it-work",
    "href": "ai/fl/fl_jax_slides.html#how-does-it-work",
    "title": "A brief intro to",
    "section": "How does it work?",
    "text": "How does it work?\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\nTransformation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\n Transformations \n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#how-does-it-work-1",
    "href": "ai/fl/fl_jax_slides.html#how-does-it-work-1",
    "title": "A brief intro to",
    "section": "How does it work?",
    "text": "How does it work?\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\n Just-in-time \n(JIT)\ncompilation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\nVectorization\nParallelization\n ¬†¬†Differentiation ¬†\n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#how-does-it-work-2",
    "href": "ai/fl/fl_jax_slides.html#how-does-it-work-2",
    "title": "A brief intro to",
    "section": "How does it work?",
    "text": "How does it work?\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\njax.jit\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\njax.vmap\njax.pmap\njax.grad\n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#not-a-deep-learning-library",
    "href": "ai/fl/fl_jax_slides.html#not-a-deep-learning-library",
    "title": "A brief intro to",
    "section": "Not a deep learning library",
    "text": "Not a deep learning library\n\n\n\n\n\n\n\n\n\njx\n\nJAX\n\n\n\ndl\nDeep learning\n\n\n\njx-&gt;dl\n\n\n\n\n\nop\nOptimizers\n\n\n\njx-&gt;op\n\n\n\n\n\npp\nProbabilistic\nprogramming\n\n\n\njx-&gt;pp\n\n\n\n\n\npm\nProbabilistic\nmodeling\n\n\n\njx-&gt;pm\n\n\n\n\n\nll\nLLMs\n\n\n\nll-&gt;jx\n\n\n\n\n\nso\nSolvers\n\n\n\nso-&gt;jx\n\n\n\n\n\nph\nPhysics\nsimulations\n\n\n\nph-&gt;jx"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#a-python-sublanguage-ideal-for-deep-learning",
    "href": "ai/fl/fl_jax_slides.html#a-python-sublanguage-ideal-for-deep-learning",
    "title": "A brief intro to",
    "section": "A Python sublanguage ideal for deep learning",
    "text": "A Python sublanguage ideal for deep learning\n\n\n\n\n\n\n\n\n\njx\n\nJAX\n\n\n\ndl\nDeep learning\n\n\n\njx-&gt;dl\n\n\n\n\n\nop\nOptimizers\n\n\n\njx-&gt;op\n\n\n\n\n\npp\nProbabilistic\nprogramming\n\n\n\njx-&gt;pp\n\n\n\n\n\npm\nProbabilistic\nmodeling\n\n\n\njx-&gt;pm\n\n\n\n\n\nll\nLLMs\n\n\n\nll-&gt;jx\n\n\n\n\n\nso\nSolvers\n\n\n\nso-&gt;jx\n\n\n\n\n\nph\nPhysics\nsimulations\n\n\n\nph-&gt;jx"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#deep-learning-libraries",
    "href": "ai/fl/fl_jax_slides.html#deep-learning-libraries",
    "title": "A brief intro to",
    "section": "Deep learning libraries",
    "text": "Deep learning libraries\n\n\n\n\n\n\n\n\n\njx\n\nJAX\n\n\n\ndl\nDeep learning\n\n\n\njx-&gt;dl\n\n\n\n\n\nop\nOptimizers\n\n\n\njx-&gt;op\n\n\n\n\n\nfl\n\nFlax\n\n\n\ndl-&gt;fl\n\n\n\n\neq\n\nEquinox\n\n\n\ndl-&gt;eq\n\n\n\n\nke\n\nKeras\n\n\n\ndl-&gt;ke\n\n\n\n\noa\n\nOptax\n\n\n\nop-&gt;oa\n\n\n\n\noi\n\nOptimix\n\n\n\nop-&gt;oi"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#this-course",
    "href": "ai/fl/fl_jax_slides.html#this-course",
    "title": "A brief intro to",
    "section": "This course",
    "text": "This course\n\n\n\n\n\n\n\n\n\njx\n\nJAX\n\n\n\ndl\nDeep learning\n\n\n\njx-&gt;dl\n\n\n\n\n\nop\nOptimizers\n\n\n\njx-&gt;op\n\n\n\n\n\nfl\n\nFlax\n\n\n\ndl-&gt;fl\n\n\n\n\neq\n\nEquinox\n\n\n\ndl-&gt;eq\n\n\n\n\nke\n\nKeras\n\n\n\ndl-&gt;ke\n\n\n\n\noa\n\nOptax\n\n\n\nop-&gt;oa\n\n\n\n\noi\n\nOptimix\n\n\n\nop-&gt;oi"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#data-loaders",
    "href": "ai/fl/fl_jax_slides.html#data-loaders",
    "title": "A brief intro to",
    "section": "Data loaders",
    "text": "Data loaders\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#data-transformations",
    "href": "ai/fl/fl_jax_slides.html#data-transformations",
    "title": "A brief intro to",
    "section": "Data transformations",
    "text": "Data transformations\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nproc\nProcess data\n\n\n\nload-&gt;proc\n\n\n\n\ntv\n\ntorchvision\n\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\ngr\n\ngrain\n\n\n\n\ngr-&gt;proc\n\n\n\n\n\ntv-&gt;proc"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#core-deep-learning-library",
    "href": "ai/fl/fl_jax_slides.html#core-deep-learning-library",
    "title": "A brief intro to",
    "section": "Core deep learning library",
    "text": "Core deep learning library\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nproc\nProcess data\n\n\n\nload-&gt;proc\n\n\n\n\ntv\n\ntorchvision\n\n\n\n\nnn\nDefine architecture\n\n\n\nproc-&gt;nn\n\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\ngr\n\ngrain\n\n\n\n\ngr-&gt;proc\n\n\n\n\n\ntv-&gt;proc\n\n\n\n\n\nfl\n\nflax\n\n\n\nfl-&gt;nn"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#optimizer-and-loss-functions",
    "href": "ai/fl/fl_jax_slides.html#optimizer-and-loss-functions",
    "title": "A brief intro to",
    "section": "Optimizer and loss functions",
    "text": "Optimizer and loss functions\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nproc\nProcess data\n\n\n\nload-&gt;proc\n\n\n\n\ntv\n\ntorchvision\n\n\n\n\nnn\nDefine architecture\n\n\n\nproc-&gt;nn\n\n\n\n\nopt\nHyperparameters\n\n\n\nnn-&gt;opt\n\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\ngr\n\ngrain\n\n\n\n\ngr-&gt;proc\n\n\n\n\n\ntv-&gt;proc\n\n\n\n\n\nfl\n\nflax\n\n\n\nfl-&gt;nn\n\n\n\n\n\noa\n\noptax\n\n\n\noa-&gt;opt"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#train",
    "href": "ai/fl/fl_jax_slides.html#train",
    "title": "A brief intro to",
    "section": "Train",
    "text": "Train\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nproc\nProcess data\n\n\n\nload-&gt;proc\n\n\n\n\ntv\n\ntorchvision\n\n\n\n\nnn\nDefine architecture\n\n\n\nproc-&gt;nn\n\n\n\n\nopt\nHyperparameters\n\n\n\nnn-&gt;opt\n\n\n\n\ntrain\nTrain\n\n\n\nopt-&gt;train\n\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\ngr\n\ngrain\n\n\n\n\ngr-&gt;proc\n\n\n\n\n\ntv-&gt;proc\n\n\n\n\n\nfl1\n\nflax\n\n\n\nfl1-&gt;nn\n\n\n\n\n\nfl2\n\nflax\n\n\n\n\nfl2-&gt;train\n\n\n\n\n\noa\n\noptax\n\n\n\noa-&gt;opt\n\n\n\n\n\njx\n\njax\n\n\n\n\njx-&gt;fl2"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#checkpointing",
    "href": "ai/fl/fl_jax_slides.html#checkpointing",
    "title": "A brief intro to",
    "section": "Checkpointing",
    "text": "Checkpointing\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nproc\nProcess data\n\n\n\nload-&gt;proc\n\n\n\n\ntv\n\ntorchvision\n\n\n\n\nnn\nDefine architecture\n\n\n\nproc-&gt;nn\n\n\n\n\nopt\nHyperparameters\n\n\n\nnn-&gt;opt\n\n\n\n\ntrain\nTrain\n\n\n\nopt-&gt;train\n\n\n\n\ncp\nCheckpoint\n\n\n\ntrain-&gt;cp\n\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\ngr\n\ngrain\n\n\n\n\ngr-&gt;proc\n\n\n\n\n\ntv-&gt;proc\n\n\n\n\n\nfl1\n\nflax\n\n\n\nfl1-&gt;nn\n\n\n\n\n\nfl2\n\nflax\n\n\n\n\noa\n\noptax\n\n\n\noa-&gt;opt\n\n\n\n\n\njx\n\njax\n\n\n\n\njx-&gt;fl2\n\n\n\n\n\nob\n\norbax\n\n\n\nob-&gt;cp"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#transfer-learning",
    "href": "ai/fl/fl_jax_slides.html#transfer-learning",
    "title": "A brief intro to",
    "section": "Transfer learning",
    "text": "Transfer learning\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nproc\nProcess data\n\n\n\nload-&gt;proc\n\n\n\n\ntv\n\ntorchvision\n\n\n\n\nnn\nDefine architecture\n\n\n\nproc-&gt;nn\n\n\n\n\npretr\nPre-trained model\n\n\n\n\nopt\nHyperparameters\n\n\n\nnn-&gt;opt\n\n\n\n\npretr-&gt;nn\n\n\n\n\ntrain\nTrain\n\n\n\nopt-&gt;train\n\n\n\n\ncp\nCheckpoint\n\n\n\ntrain-&gt;cp\n\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\ngr\n\ngrain\n\n\n\n\ngr-&gt;proc\n\n\n\n\n\ntv-&gt;proc\n\n\n\n\n\ntr\n\ntransformers\n\n\n\n\ntr-&gt;pretr\n\n\n\n\n\nfl1\n\nflax\n\n\n\n\nfl1-&gt;nn\n\n\n\n\n\nfl2\n\nflax\n\n\n\n\nfl2-&gt;train\n\n\n\n\n\noa\n\noptax\n\n\n\noa-&gt;opt\n\n\n\n\n\njx\n\njax\n\n\n\n\njx-&gt;fl2\n\n\n\n\n\nob\n\norbax\n\n\n\nob-&gt;cp"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#installing-jax",
    "href": "ai/fl/fl_jax_slides.html#installing-jax",
    "title": "A brief intro to",
    "section": "Installing JAX",
    "text": "Installing JAX\n\n\n\n\n\n\n\n\n\n\n\n\nLinux x86_64\nLinux aarch64\nMac aarch64\nWindows x86_64\nWindows WSL2 x86_64\n\n\n\n\nCPU\nyes\nyes\nyes\nyes\nyes\n\n\nNVIDIA GPU\nyes\nyes\nn/a\nno\nexperimental\n\n\nGoogle TPU\nyes\nn/a\nn/a\nn/a\nn/a\n\n\nAMD GPU\nyes\nno\nn/a\nno\nexperimental\n\n\nApple GPU\nn/a\nno\nexperimental\nn/a\nn/a\n\n\nIntel GPU\nexperimental\nn/a\nn/a\nno\nno\n\n\n\nFrom JAX documentation"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#installing-jax-1",
    "href": "ai/fl/fl_jax_slides.html#installing-jax-1",
    "title": "A brief intro to",
    "section": "Installing JAX",
    "text": "Installing JAX\nIf you install packages which depend on JAX (e.g.¬†Flax), they will by default install the CPU version of JAX. If you want to run JAX on GPUs, make sure to first install jax[cuda13]\nYou can install the CPU version on your machine to prototype and use a GPU version on the clusters (we have wheels)"
  },
  {
    "objectID": "ai/fl/fl_jax_slides.html#installing-complementary-libraries",
    "href": "ai/fl/fl_jax_slides.html#installing-complementary-libraries",
    "title": "A brief intro to",
    "section": "Installing complementary libraries",
    "text": "Installing complementary libraries\nThe modular approach has the downside that several libraries are required and conflicts between dependencies can be a problem\nThe meta-library jax-ai-stack makes this easier to manage (install jax[cuda13] first for GPU)\n\nOn your machine (and your machine only), a great tool to manage Python versions and packages is uv (see our webinar). On the clusters, you have to use module to load the Python version you want and pip to install packages"
  },
  {
    "objectID": "ai/fl/fl_load_weights.html",
    "href": "ai/fl/fl_load_weights.html",
    "title": "Loading pre-trained weights",
    "section": "",
    "text": "In this section, we transfer weights from a pre-trained model into our ViT model.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Loading pre-trained weights"
    ]
  },
  {
    "objectID": "ai/fl/fl_load_weights.html#context",
    "href": "ai/fl/fl_load_weights.html#context",
    "title": "Loading pre-trained weights",
    "section": "Context",
    "text": "Context\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nproc\nProcess data\n\n\n\nload-&gt;proc\n\n\n\n\ntv\n\ntorchvision\n\n\n\n\nnn\nDefine architecture\n\n\n\nproc-&gt;nn\n\n\n\n\npretr\nPre-trained model\n\n\n\n\n\nopt\nHyperparameters\n\n\n\nnn-&gt;opt\n\n\n\n\npretr-&gt;nn\n\n\n\n\ntrain\nTrain\n\n\n\nopt-&gt;train\n\n\n\n\ncp\nCheckpoint\n\n\n\ntrain-&gt;cp\n\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\ngr\n\ngrain\n\n\n\n\ngr-&gt;proc\n\n\n\n\n\ntv-&gt;proc\n\n\n\n\n\ntr\n\ntransformers\n\n\n\n\ntr-&gt;pretr\n\n\n\n\n\nfl1\n\nflax\n\n\n\n\n\nfl1-&gt;nn\n\n\n\n\n\nfl2\n\nflax\n\n\n\nfl2-&gt;train\n\n\n\n\n\noa\n\noptax\n\n\n\noa-&gt;opt\n\n\n\n\n\njx\n\nJAX\n\n\n\njx-&gt;fl2\n\n\n\n\n\nob\n\norbax\n\n\n\nob-&gt;cp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteMinimal necessary code from previous sections\n\n\n\n\n\nimport jax\nimport jax.numpy as jnp\nfrom flax import nnx\n\nclass VisionTransformer(nnx.Module):\n    def __init__(\n        self,\n        num_classes: int = 1000,\n        in_channels: int = 3,\n        img_size: int = 224,\n        patch_size: int = 16,\n        num_layers: int = 12,\n        num_heads: int = 12,\n        mlp_dim: int = 3072,\n        hidden_size: int = 768,\n        dropout_rate: float = 0.1,\n        *,\n        rngs: nnx.Rngs = nnx.Rngs(0),\n    ):\n        # Patch and position embedding\n        n_patches = (img_size // patch_size) ** 2\n        self.patch_embeddings = nnx.Conv(\n            in_channels,\n            hidden_size,\n            kernel_size=(patch_size, patch_size),\n            strides=(patch_size, patch_size),\n            padding=\"VALID\",\n            use_bias=True,\n            rngs=rngs,\n        )\n\n        initializer = jax.nn.initializers.truncated_normal(stddev=0.02)\n        self.position_embeddings = nnx.Param(\n            initializer(\n                rngs.params(),\n                (1, n_patches + 1, hidden_size),\n                jnp.float32\n            )\n        )\n        self.dropout = nnx.Dropout(dropout_rate, rngs=rngs)\n\n        self.cls_token = nnx.Param(jnp.zeros((1, 1, hidden_size)))\n\n        # Transformer Encoder blocks\n        self.encoder = nnx.Sequential(*[\n            TransformerEncoder(\n                hidden_size,\n                mlp_dim,\n                num_heads,\n                dropout_rate,\n                rngs=rngs\n            )\n            for i in range(num_layers)\n        ])\n        self.final_norm = nnx.LayerNorm(hidden_size, rngs=rngs)\n\n        # Classification head\n        self.classifier = nnx.Linear(hidden_size, num_classes, rngs=rngs)\n\n    def __call__(self, x: jax.Array) -&gt; jax.Array:\n        # Patch and position embedding\n        patches = self.patch_embeddings(x)\n        batch_size = patches.shape[0]\n        patches = patches.reshape(batch_size, -1, patches.shape[-1])\n\n        cls_token = jnp.tile(self.cls_token, [batch_size, 1, 1])\n        x = jnp.concat([cls_token, patches], axis=1)\n        embeddings = x + self.position_embeddings\n        embeddings = self.dropout(embeddings)\n\n        # Encoder blocks\n        x = self.encoder(embeddings)\n        x = self.final_norm(x)\n\n        # fetch the first token\n        x = x[:, 0]\n\n        # Classification\n        return self.classifier(x)\n\nclass TransformerEncoder(nnx.Module):\n    def __init__(\n        self,\n        hidden_size: int,\n        mlp_dim: int,\n        num_heads: int,\n        dropout_rate: float = 0.0,\n        *,\n        rngs: nnx.Rngs = nnx.Rngs(0),\n    ) -&gt; None:\n\n        self.norm1 = nnx.LayerNorm(hidden_size, rngs=rngs)\n        self.attn = nnx.MultiHeadAttention(\n            num_heads=num_heads,\n            in_features=hidden_size,\n            dropout_rate=dropout_rate,\n            broadcast_dropout=False,\n            decode=False,\n            deterministic=False,\n            rngs=rngs,\n        )\n        self.norm2 = nnx.LayerNorm(hidden_size, rngs=rngs)\n\n        self.mlp = nnx.Sequential(\n            nnx.Linear(hidden_size, mlp_dim, rngs=rngs),\n            nnx.gelu,\n            nnx.Dropout(dropout_rate, rngs=rngs),\n            nnx.Linear(mlp_dim, hidden_size, rngs=rngs),\n            nnx.Dropout(dropout_rate, rngs=rngs),\n        )\n\n    def __call__(self, x: jax.Array) -&gt; jax.Array:\n        x = x + self.attn(self.norm1(x))\n        x = x + self.mlp(self.norm2(x))\n        return x\n\nmodel = VisionTransformer(num_classes=1000)",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Loading pre-trained weights"
    ]
  },
  {
    "objectID": "ai/fl/fl_load_weights.html#load-packages",
    "href": "ai/fl/fl_load_weights.html#load-packages",
    "title": "Loading pre-trained weights",
    "section": "Load packages",
    "text": "Load packages\nPackages and modules necessary for this section:\n# Hugging Face ViT Model transformer with image classification head\nfrom transformers import FlaxViTForImageClassification\n\n# Packages to test our model after weight transfer\nimport matplotlib.pyplot as plt\nfrom transformers import ViTImageProcessor\nfrom PIL import Image\nimport requests\nFlaxViTForImageClassification instantiates a pretrained Flax model with an image classification head from a pre-trained ViT model configuration.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Loading pre-trained weights"
    ]
  },
  {
    "objectID": "ai/fl/fl_load_weights.html#load-pre-trained-weights",
    "href": "ai/fl/fl_load_weights.html#load-pre-trained-weights",
    "title": "Loading pre-trained weights",
    "section": "Load pre-trained weights",
    "text": "Load pre-trained weights\nWe want to load the weights from Google‚Äôs ViT model pre-trained on ImageNet-21k at resolution 224x224 and fine-tuned on ImageNet 2012 at resolution 224x224 introduced by Dosovitskiy et al. [1] in our model.\nFor this, we use the from_pretrained method of FlaxViTForImageClassification and get the weights from Google‚Äôs model stored as google/vit-base-patch16-224 on the Hugging Face model Hub.\ntf_model = FlaxViTForImageClassification.from_pretrained('google/vit-base-patch16-224')",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Loading pre-trained weights"
    ]
  },
  {
    "objectID": "ai/fl/fl_load_weights.html#copy-weights-to-our-model",
    "href": "ai/fl/fl_load_weights.html#copy-weights-to-our-model",
    "title": "Loading pre-trained weights",
    "section": "Copy weights to our model",
    "text": "Copy weights to our model\ntf_model is a transformer ViT model with the pre-trained weights. We want to copy those weights to our ViT Flax model called model:\ndef vit_inplace_copy_weights(*, src_model, dst_model):\n    assert isinstance(src_model, FlaxViTForImageClassification)\n    assert isinstance(dst_model, VisionTransformer)\n\n    tf_model_params = src_model.params\n    tf_model_params_fstate = nnx.traversals.flatten_mapping(tf_model_params)\n\n    flax_model_params = nnx.state(dst_model, nnx.Param)\n    flax_model_params_fstate = flax_model_params.flat_state()\n\n    params_name_mapping = {\n        (\"cls_token\",): (\"vit\", \"embeddings\", \"cls_token\"),\n        (\"position_embeddings\",): (\n            \"vit\",\n            \"embeddings\",\n            \"position_embeddings\"\n        ),\n        **{\n            (\"patch_embeddings\", x): (\n                \"vit\",\n                \"embeddings\",\n                \"patch_embeddings\",\n                \"projection\",\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n        },\n        **{\n            (\"encoder\", \"layers\", i, \"attn\", y, x): (\n                \"vit\",\n                \"encoder\",\n                \"layer\",\n                str(i),\n                \"attention\",\n                \"attention\",\n                y,\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n            for y in [\"key\", \"value\", \"query\"]\n            for i in range(12)\n        },\n        **{\n            (\"encoder\", \"layers\", i, \"attn\", \"out\", x): (\n                \"vit\",\n                \"encoder\",\n                \"layer\",\n                str(i),\n                \"attention\",\n                \"output\",\n                \"dense\",\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n            for i in range(12)\n        },\n        **{\n            (\"encoder\", \"layers\", i, \"mlp\", \"layers\", y1, x): (\n                \"vit\",\n                \"encoder\",\n                \"layer\",\n                str(i),\n                y2,\n                \"dense\",\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n            for y1, y2 in [(0, \"intermediate\"), (3, \"output\")]\n            for i in range(12)\n        },\n        **{\n            (\"encoder\", \"layers\", i, y1, x): (\n                \"vit\", \"encoder\", \"layer\", str(i), y2, x\n            )\n            for x in [\"scale\", \"bias\"]\n            for y1, y2 in [\n                    (\"norm1\", \"layernorm_before\"),\n                    (\"norm2\", \"layernorm_after\")\n            ]\n            for i in range(12)\n        },\n        **{\n            (\"final_norm\", x): (\"vit\", \"layernorm\", x)\n            for x in [\"scale\", \"bias\"]\n        },\n        **{\n            (\"classifier\", x): (\"classifier\", x)\n            for x in [\"kernel\", \"bias\"]\n        }\n    }\n\n    nonvisited = set(flax_model_params_fstate.keys())\n\n    for key1, key2 in params_name_mapping.items():\n        assert key1 in flax_model_params_fstate, key1\n        assert key2 in tf_model_params_fstate, (key1, key2)\n\n        nonvisited.remove(key1)\n\n        src_value = tf_model_params_fstate[key2]\n        if key2[-1] == \"kernel\" and key2[-2] in (\"key\", \"value\", \"query\"):\n            shape = src_value.shape\n            src_value = src_value.reshape((shape[0], 12, 64))\n\n        if key2[-1] == \"bias\" and key2[-2] in (\"key\", \"value\", \"query\"):\n            src_value = src_value.reshape((12, 64))\n\n        if key2[-4:] == (\"attention\", \"output\", \"dense\", \"kernel\"):\n            shape = src_value.shape\n            src_value = src_value.reshape((12, 64, shape[-1]))\n\n        dst_value = flax_model_params_fstate[key1]\n        assert src_value.shape == dst_value.value.shape, (\n            key2, src_value.shape, key1, dst_value.value.shape\n        )\n        dst_value.value = src_value.copy()\n        assert dst_value.value.mean() == src_value.mean(), (\n            dst_value.value, src_value.mean()\n        )\n\n    assert len(nonvisited) == 0, nonvisited\n\n    nnx.update(dst_model, nnx.State.from_flat_path(flax_model_params_fstate))\n\nvit_inplace_copy_weights(src_model=tf_model, dst_model=model)",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Loading pre-trained weights"
    ]
  },
  {
    "objectID": "ai/fl/fl_load_weights.html#test-our-model",
    "href": "ai/fl/fl_load_weights.html#test-our-model",
    "title": "Loading pre-trained weights",
    "section": "Test our model",
    "text": "Test our model\nOur model should now be able to classify objects if they belong to the 1000 classes of ImageNet-1K.\nLet‚Äôs test it by passing the URL of the image of a Song Sparrow (Melospiza melodia):\nurl = \"https://www.allaboutbirds.org/guide/assets/photo/308771371-480px.jpg\"\nimage = Image.open(requests.get(url, stream=True).raw)\n\nprocessor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n\ninputs = processor(images=image, return_tensors=\"np\")\noutputs = tf_model(**inputs)\nlogits = outputs.logits\n\nmodel.eval()\nx = jnp.transpose(inputs[\"pixel_values\"], axes=(0, 2, 3, 1))\noutput = model(x)\n\n# Model predicts one of the 1000 ImageNet classes.\nref_class_idx = logits.argmax(-1).item()\npred_class_idx = output.argmax(-1).item()\nassert jnp.abs(logits[0, :] - output[0, :]).max() &lt; 0.1\n\nfig, axs = plt.subplots(1, 2, figsize=(12, 8))\naxs[0].set_title(\n    f\"Reference model:\\n{tf_model.config.id2label[ref_class_idx]}\\nP={nnx.softmax(logits, axis=-1)[0, ref_class_idx]:.3f}\"\n)\naxs[0].imshow(image)\naxs[1].set_title(\n    f\"Our model:\\n{tf_model.config.id2label[pred_class_idx]}\\nP={nnx.softmax(output, axis=-1)[0, pred_class_idx]:.3f}\"\n)\naxs[1].imshow(image)\nThe Song Sparrow is apparently not in the 1000 classes. But the good news is that our model with the transferred weights gave exactly the same result as the google/vit-base-patch16-224 model and with the same probability. Brambling‚Äîanother songbird‚Äîis probably the class the closest to a Song Sparrow. So all looks good.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Loading pre-trained weights"
    ]
  },
  {
    "objectID": "ai/fl/fl_load_weights.html#reduce-number-of-classes",
    "href": "ai/fl/fl_load_weights.html#reduce-number-of-classes",
    "title": "Loading pre-trained weights",
    "section": "Reduce number of classes",
    "text": "Reduce number of classes\nOur model now returns 1000 categories, but we want to fine-tune it on the Food-101 dataset [2] that we have reduced to only 5 classes. So we need to replace the model classifier with one returning 5 classes:\nmodel.classifier = nnx.Linear(model.classifier.in_features, 5, rngs=nnx.Rngs(0))\n\nx = jnp.ones((4, 224, 224, 3))\ny = model(x)\nprint(\"Predictions shape: \", y.shape)",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Loading pre-trained weights"
    ]
  },
  {
    "objectID": "ai/fl/fl_nn.html",
    "href": "ai/fl/fl_nn.html",
    "title": "Defining a model architecture",
    "section": "",
    "text": "In this section, we define a model with Flax‚Äôs new API called NNX.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Defining a model architecture"
    ]
  },
  {
    "objectID": "ai/fl/fl_nn.html#context",
    "href": "ai/fl/fl_nn.html#context",
    "title": "Defining a model architecture",
    "section": "Context",
    "text": "Context\n\n\n\n\n\n\n\n\n\nload\nLoad data\n\n\n\nproc\nProcess data\n\n\n\nload-&gt;proc\n\n\n\n\ntv\n\ntorchvision\n\n\n\n\nnn\nDefine architecture\n\n\n\nproc-&gt;nn\n\n\n\n\npretr\nPre-trained model\n\n\n\n\n\nopt\nHyperparameters\n\n\n\nnn-&gt;opt\n\n\n\n\npretr-&gt;nn\n\n\n\n\ntrain\nTrain\n\n\n\nopt-&gt;train\n\n\n\n\ncp\nCheckpoint\n\n\n\ntrain-&gt;cp\n\n\n\n\npt\n\ntorchdata\n\n\n\npt-&gt;load\n\n\n\n\n\ntfds\n\ntfds\n\n\n\ntfds-&gt;load\n\n\n\n\n\ndt\n\ndatasets\n\n\n\ndt-&gt;load\n\n\n\n\n\ngr\n\ngrain\n\n\n\n\ngr-&gt;proc\n\n\n\n\n\ntv-&gt;proc\n\n\n\n\n\ntr\n\ntransformers\n\n\n\n\ntr-&gt;pretr\n\n\n\n\n\nfl1\n\nflax\n\n\n\n\n\nfl1-&gt;nn\n\n\n\n\n\nfl2\n\nflax\n\n\n\nfl2-&gt;train\n\n\n\n\n\noa\n\noptax\n\n\n\noa-&gt;opt\n\n\n\n\n\njx\n\njax\n\n\n\njx-&gt;fl2\n\n\n\n\n\nob\n\norbax\n\n\n\nob-&gt;cp",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Defining a model architecture"
    ]
  },
  {
    "objectID": "ai/fl/fl_nn.html#load-packages",
    "href": "ai/fl/fl_nn.html#load-packages",
    "title": "Defining a model architecture",
    "section": "Load packages",
    "text": "Load packages\nPackage and module necessary for this section:\n\n# to define the jax.Array type\nimport jax\n\n# general JAX array manipulations\nimport jax.numpy as jnp\n\n# to define the model architecture\nfrom flax import nnx\n\n# to get callables from functions with fewer arguments\nfrom functools import partial",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Defining a model architecture"
    ]
  },
  {
    "objectID": "ai/fl/fl_nn.html#the-flax-nnx-api",
    "href": "ai/fl/fl_nn.html#the-flax-nnx-api",
    "title": "Defining a model architecture",
    "section": "The Flax NNX API",
    "text": "The Flax NNX API\nFlax went through several APIs.\nThe initial nn API‚Äînow retired‚Äîgot replaced in 2020 by the Linen API, still available with the Flax package. In 2024, they launched the NNX API.\nEach iteration has moved further from JAX and closer to Python, with a syntax increasingly similar to PyTorch.\nWhile the Linen API still exists, new users are advised to learn the new NNX API.\n\nStateful models\nThe old Linen API is a stateless model framework similar to the Julia package Lux.jl. It follows a strict functional programming approach in which the parameters are separate from the model and are passed as inputs to the forward pass along with the data. This is much closer to the JAX sublanguage, more optimized, but restrictive and unpopular in the deep learning community and among Python users.\nBy contrast, the new NNX API is a stateful model framework similar to PyTorch and the older Julia package Flux.jl: model parameters and optimizer state are stored within the model instance. Flax handles a lot of JAX‚Äôs constraints under the hood, making the code more familiar to Python/PyTorch users, simpler, and more forgiving.\nThe dynamic state handled by NNX is stored in nnx.Params and the static state (all types not handled by NNX) are stored directly as Python object attributes. This follows the classic Python object-oriented paradigm.\n\n\nNo shape inference\nAll model dimensions need to be explicitly stated.\n\n\nHandling of PRNG\nWe saw that JAX has a complex way to handle pseudo-random number generation. While the Linen API required PRNG to be done explicitly in JAX by the user, the new NNX API defines the random state as an object state stored in a variable and carried by the model.\n\n\nWhat this looks like\nDefine the model architecture:\n\nclass Linear(nnx.Module):\n  def __init__(self, din: int, dout: int, *, rngs: nnx.Rngs):\n    key = rngs.params()\n    self.w = nnx.Param(jax.random.uniform(key, (din, dout)))\n    self.b = nnx.Param(jnp.zeros((dout,)))\n    self.din, self.dout = din, dout\n\n  def __call__(self, x: jax.Array):\n    return x @ self.w + self.b\n\nInstantiate the model:\n\nmodel = Linear(2, 5, rngs=nnx.Rngs(params=0))\n\nDisplay the model structure:\n\nnnx.display(model)\n\n     \n\n\n   \n\n\n\nIf you have the penzai package installed, you will see an interactive display of the model.\n\n\ny = model(x=jnp.ones((1, 2)))\nprint(\"Predictions shape: \", y.shape)\n\nPredictions shape:  (1, 5)",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Defining a model architecture"
    ]
  },
  {
    "objectID": "ai/fl/fl_nn.html#example-mlp-with-flax-nnx",
    "href": "ai/fl/fl_nn.html#example-mlp-with-flax-nnx",
    "title": "Defining a model architecture",
    "section": "Example MLP with Flax NNX",
    "text": "Example MLP with Flax NNX\nMultilayer perceptrons (MLPs) are fully-connected feed-forward neural networks.\nHere is an example of MLP with a single hidden layer for the MNIST dataset by LeCun et al. [1]:\n\n\n\nImage source\n\n\nAnd here is the implementation in Flax NNX:\n\nclass MLP(nnx.Module):\n\n  def __init__(\n          self,\n          # 28x28 pixel images with 1 channel\n          n_features: int = 784,\n          n_hidden: int = 300,\n          # 10 digits\n          n_targets: int = 10,\n          *,\n          rngs: nnx.Rngs\n  ):\n    self.n_features = n_features\n    self.layer1 = nnx.Linear(n_features, n_hidden, rngs=rngs)\n    self.layer2 = nnx.Linear(n_hidden, n_hidden, rngs=rngs)\n    self.layer3 = nnx.Linear(n_hidden, n_targets, rngs=rngs)\n\n  def __call__(self, x):\n    x = x.reshape(x.shape[0], self.n_features) # flatten\n    x = nnx.selu(self.layer1(x))\n    x = nnx.selu(self.layer2(x))\n    x = self.layer3(x)\n    return x\n\n# instantiate the model\nmodel = MLP(rngs=nnx.Rngs(0))\n\n# visualize it\nnnx.display(model)\n\n     \n\n\n   \n\n\n\nNNX API references:\n\nflax.nnx.Linear layer class\nflax.nnx.selu SELU activation function",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Defining a model architecture"
    ]
  },
  {
    "objectID": "ai/fl/fl_nn.html#example-cnn-with-flax-nnx",
    "href": "ai/fl/fl_nn.html#example-cnn-with-flax-nnx",
    "title": "Defining a model architecture",
    "section": "Example CNN with Flax NNX",
    "text": "Example CNN with Flax NNX\nConvolutional neural networks (CNNs) take advantage of the spacial correlations that exist in images and allow to greatly reduce the number of neurons in vision networks.\nLeNet-5 [2] model, initially used on the MNIST dataset by LeCun et al. [1], is an early and simple CNN. The architecture of this model is explained in details in this kaggle post and here is a schematic:\n\n\n\nImage source: LeCun et al. [2]\n\n\nYou can find the keras code here and the PyTorch code (slightly modified) here for comparison.\n\nclass LeNet(nnx.Module):\n  \"\"\"An adapted LeNet-5 model.\"\"\"\n\n  def __init__(self, *, rngs: nnx.Rngs):\n    self.conv1 = nnx.Conv(1, 6, kernel_size=(5, 5), rngs=rngs)\n    self.max_pool = partial(nnx.max_pool, window_shape=(2, 2), strides=(2, 2))\n    self.conv2 = nnx.Conv(6, 16, kernel_size=(5, 5), rngs=rngs)\n    self.linear1 = nnx.Linear(16 * 4 * 4, 120, rngs=rngs)\n    self.linear2 = nnx.Linear(120, 84, rngs=rngs)\n    self.linear3 = nnx.Linear(84, 10, rngs=rngs)\n\n  def __call__(self, x):\n    x = self.max_pool(nnx.relu(self.conv1(x)))\n    x = self.max_pool(nnx.relu(self.conv2(x)))\n    x = x.reshape(x.shape[0], -1)  # flatten\n    x = nnx.relu(self.linear1(x))\n    x = nnx.relu(self.linear2(x))\n    x = self.linear3(x)\n    return x\n\n# instantiate the model\nmodel = LeNet(rngs=nnx.Rngs(0))\n\n# visualize it\nnnx.display(model)\n\n     \n\n\n   \n\n\n\nNNX API references:\n\nflax.nnx.Conv convolution module\nflax.nnx.Linear layer class\nflax.nnx.max_pool is missing in the API documentation as of April 2025\nflax.nnx.relu activation function",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Defining a model architecture"
    ]
  },
  {
    "objectID": "ai/fl/fl_nn.html#vit-with-flax-nnx",
    "href": "ai/fl/fl_nn.html#vit-with-flax-nnx",
    "title": "Defining a model architecture",
    "section": "ViT with Flax NNX",
    "text": "ViT with Flax NNX\nLeNet (various iterations until 1998) was followed by AlexNet in 2011 and many increasingly complex CNNs, until multi-head attention and transformers changed everything.\nTransformers are a complex neural network architecture developed by Google in 2017, after the seminal paper ‚ÄúAttention Is All You Need‚Äù [3]‚Äîcited 175,083 times as of April 2025 (!!!)‚Äîcame out. They were initially only used in natural language processing (NLP), but have since been applied to vision.\nTo classify our food dataset, we will use the vision transformer (ViT) introduced by Dosovitskiy et al. [4] (that we will fine-tune in a later section).\nHere is a schematic of the model:\n\n\n\nImage source: Dosovitskiy et al. [4]\n\n\nAnd here is the JAX implementation by Google Research:\n\nclass VisionTransformer(nnx.Module):\n    def __init__(\n        self,\n        num_classes: int = 1000,\n        in_channels: int = 3,\n        img_size: int = 224,\n        patch_size: int = 16,\n        num_layers: int = 12,\n        num_heads: int = 12,\n        mlp_dim: int = 3072,\n        hidden_size: int = 768,\n        dropout_rate: float = 0.1,\n        *,\n        rngs: nnx.Rngs = nnx.Rngs(0),\n    ):\n        # Patch and position embedding\n        n_patches = (img_size // patch_size) ** 2\n        self.patch_embeddings = nnx.Conv(\n            in_channels,\n            hidden_size,\n            kernel_size=(patch_size, patch_size),\n            strides=(patch_size, patch_size),\n            padding=\"VALID\",\n            use_bias=True,\n            rngs=rngs,\n        )\n\n        initializer = jax.nn.initializers.truncated_normal(stddev=0.02)\n        self.position_embeddings = nnx.Param(\n            initializer(\n                rngs.params(),\n                (1, n_patches + 1, hidden_size),\n                jnp.float32\n            )\n        )\n        self.dropout = nnx.Dropout(dropout_rate, rngs=rngs)\n\n        self.cls_token = nnx.Param(jnp.zeros((1, 1, hidden_size)))\n\n        # Transformer Encoder blocks\n        self.encoder = nnx.Sequential(*[\n            TransformerEncoder(\n                hidden_size,\n                mlp_dim,\n                num_heads,\n                dropout_rate,\n                rngs=rngs\n            )\n            for i in range(num_layers)\n        ])\n        self.final_norm = nnx.LayerNorm(hidden_size, rngs=rngs)\n\n        # Classification head\n        self.classifier = nnx.Linear(hidden_size, num_classes, rngs=rngs)\n\n    def __call__(self, x: jax.Array) -&gt; jax.Array:\n        # Patch and position embedding\n        patches = self.patch_embeddings(x)\n        batch_size = patches.shape[0]\n        patches = patches.reshape(batch_size, -1, patches.shape[-1])\n\n        cls_token = jnp.tile(self.cls_token, [batch_size, 1, 1])\n        x = jnp.concat([cls_token, patches], axis=1)\n        embeddings = x + self.position_embeddings\n        embeddings = self.dropout(embeddings)\n\n        # Encoder blocks\n        x = self.encoder(embeddings)\n        x = self.final_norm(x)\n\n        # fetch the first token\n        x = x[:, 0]\n\n        # Classification\n        return self.classifier(x)\n\nclass TransformerEncoder(nnx.Module):\n    def __init__(\n        self,\n        hidden_size: int,\n        mlp_dim: int,\n        num_heads: int,\n        dropout_rate: float = 0.0,\n        *,\n        rngs: nnx.Rngs = nnx.Rngs(0),\n    ) -&gt; None:\n\n        self.norm1 = nnx.LayerNorm(hidden_size, rngs=rngs)\n        self.attn = nnx.MultiHeadAttention(\n            num_heads=num_heads,\n            in_features=hidden_size,\n            dropout_rate=dropout_rate,\n            broadcast_dropout=False,\n            decode=False,\n            deterministic=False,\n            rngs=rngs,\n        )\n        self.norm2 = nnx.LayerNorm(hidden_size, rngs=rngs)\n\n        self.mlp = nnx.Sequential(\n            nnx.Linear(hidden_size, mlp_dim, rngs=rngs),\n            nnx.gelu,\n            nnx.Dropout(dropout_rate, rngs=rngs),\n            nnx.Linear(mlp_dim, hidden_size, rngs=rngs),\n            nnx.Dropout(dropout_rate, rngs=rngs),\n        )\n\n    def __call__(self, x: jax.Array) -&gt; jax.Array:\n        x = x + self.attn(self.norm1(x))\n        x = x + self.mlp(self.norm2(x))\n        return x\n\nx = jnp.ones((4, 224, 224, 3))\nmodel = VisionTransformer(num_classes=1000)\ny = model(x)\nprint(\"Predictions shape: \", y.shape)\n\nPredictions shape:  (4, 1000)\n\n\n\nNNX API references:\n\nflax.nnx.Conv convolution module\nflax.nnx.Dropout dropout class\nflax.nnx.LayerNorm layer normalization class\nflax.nnx.Linear linear layer class\nflax.nnx.MultiHeadAttention multi-head attention class\nflax.nnx.Param parameter class\nflax.nnx.Sequential helper class\nflax.nnx.gelu GELU activation function",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Defining a model architecture"
    ]
  },
  {
    "objectID": "ai/fl/fl_optimization.html#data-padding",
    "href": "ai/fl/fl_optimization.html#data-padding",
    "title": "Optimizations",
    "section": "Data padding",
    "text": "Data padding\n\nPrevent recompilation for the last batch that is smaller (different shape)."
  },
  {
    "objectID": "ai/fl/fl_optimization.html#learning-rate-scheduling",
    "href": "ai/fl/fl_optimization.html#learning-rate-scheduling",
    "title": "Optimizations",
    "section": "Learning rate scheduling",
    "text": "Learning rate scheduling"
  },
  {
    "objectID": "ai/fl/fl_optimization.html#using-multiple-accelerators",
    "href": "ai/fl/fl_optimization.html#using-multiple-accelerators",
    "title": "Optimizations",
    "section": "Using multiple accelerators",
    "text": "Using multiple accelerators\nParallel runs on multiple GPUs/TPUs"
  },
  {
    "objectID": "ai/fl/fl_regularization.html",
    "href": "ai/fl/fl_regularization.html",
    "title": "Regularization",
    "section": "",
    "text": "Regularization"
  },
  {
    "objectID": "ai/fl/fl_regularization.html#batch-normalization",
    "href": "ai/fl/fl_regularization.html#batch-normalization",
    "title": "Regularization",
    "section": "Batch normalization",
    "text": "Batch normalization\nBatch normalization"
  },
  {
    "objectID": "ai/fl/fl_regularization.html#dropout",
    "href": "ai/fl/fl_regularization.html#dropout",
    "title": "Regularization",
    "section": "Dropout",
    "text": "Dropout\nDropout"
  },
  {
    "objectID": "ai/fl/fl_run.html",
    "href": "ai/fl/fl_run.html",
    "title": "Running JAX",
    "section": "",
    "text": "This sections covers important considerations on how to use resources efficiently when training neural networks and instructions on how to run code during this course.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Running JAX"
    ]
  },
  {
    "objectID": "ai/fl/fl_run.html#resource-efficient-workflow",
    "href": "ai/fl/fl_run.html#resource-efficient-workflow",
    "title": "Running JAX",
    "section": "Resource efficient workflow",
    "text": "Resource efficient workflow\n\nCode prototyping\nPython being an interpreted language, it makes sense to prototype code in an interactive fashion. There are many options of this, including:\n\nlaunching the Python REPL (which finally saw a little refresh with Python 3.13 but still remains very austere)\nusing the much more powerful IPython shell,\nusing the even more powerful ptpython (prompt toolkit) shell,\nusing the previous two combined (ptpython integrates with IPython thanks to its ptipython executable),\nusing Emacs as a Python IDE,\nusing JupyterLab.\n\nTraining a model requires a lot of resources. You might need multiple GPUs or entire nodes. It would be silly to have so much resource sit idle for hours while you are typing in a Jupyter notebook or thinking about your code.\nThe answer is to prototype code in an interactive environment at a very small scale (e.g.¬†on a tiny subsample of data) until you have a program (a script) that works.\n\n\nScaling things up\nOnce you are confident that your code is good, you can scale it up on more hardware (not all at once, do multiple tests at increasingly larger scale so that you don‚Äôt wait for three weeks for results that don‚Äôt work).\nFor this part, it is best to SSH into a cluster and launch a batch Slurm job.\nOne of the great things about JAX is that the same code runs on any device so you can test the code on your machine on CPUs and then run it as is on a clusters on GPU.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Running JAX"
    ]
  },
  {
    "objectID": "ai/fl/fl_run.html#our-workflow-for-this-course",
    "href": "ai/fl/fl_run.html#our-workflow-for-this-course",
    "title": "Running JAX",
    "section": "Our workflow for this course",
    "text": "Our workflow for this course\nWe will mostly use a JupyterHub during this course to play with snippets of code. When we get to really trying to train a model, we will log in to our training cluster via SSH and submit jobs to the Slurm scheduler.\n\nAccessing our temporary JupyterHub\n\nGo to the etherpad shared during the course to claim a username,\ngo to the URL of the JupyterHub for this course,\nsign in with the username you claimed and the password we gave you,\nleave OTP blank,\nthe server options are good as they are unless you want to bump the time a little (e.g.¬†to 1.5h),\npress start,\nstart a Python notebook: click on the button Python 3 in the Notebook section (top row of buttons).\n\nThe packages for this course are already installed in the JupyterHub.\nIf you don‚Äôt need all the time you asked for after all, you should log out (the resources you are using on a cluster are shared amongst many people and when resources are allocated to you, they aren‚Äôt available to other people. So it is a good thing not to ask for unnecessary resources and have them sit idle when others could be using them).\nTo log out, click on File in the top menu and select Log out at the very bottom.\nIf you would like to make a change to the information you entered on the server option page after you have pressed start, log out in the same way, log back in, edit the server options, and press start again.\n\nNote that this JupyterHub will be destroyed at the end of the course.\n\n\n\nLogging in through SSH\n\nOpen a terminal emulator\nWindows users: ‚ÄÉInstall the free version of MobaXTerm and launch it.\nmacOS users: ‚ÄÉ‚ÄÉLaunch Terminal.\nLinux users: ‚ÄÉ‚ÄÉ‚ÄÇ¬†Open the terminal emulator of your choice.\n\n\nAccess the cluster through secure shell\n\nWindows users\nFollow the first 18% of this demo.\nFor Remote host, use the hostname we gave you.\nSelect the box Specify username and provide your username.\n\nNote that the password is entered through blind typing, meaning that you will not see anything happening as you type it. This is a Linux feature. While it is a little disturbing at first, do know that it is working. Make sure to type it slowly to avoid typos, then press the Enter key on your keyboard.\n\n\n\nmacOS and Linux users\nIn the terminal, run:\nssh &lt;username&gt;@&lt;hostname&gt;\n\nReplace the username and hostname by their values. For instance:\nssh user21@somecluster.c3.ca\n\nYou will be asked a question, answer ‚ÄúYes‚Äù.\nWhen prompted, type the password.\n\nNote that the password is entered through blind typing, meaning that you will not see anything happening as you type it. This is a Linux feature. While it is a little disturbing at first, do know that it is working. Make sure to type it slowly to avoid typos, then press the Enter key on your keyboard.\n\n\n\n\nTroubleshooting\nProblems logging in are almost always due to typos. If you cannot log in, retry slowly, entering your password carefully.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>",
      "Running JAX"
    ]
  },
  {
    "objectID": "ai/fl/fl_state.html",
    "href": "ai/fl/fl_state.html",
    "title": "Flax‚Äôs handling of model states",
    "section": "",
    "text": "Deep learning models can be split into two categories depending on the framework used to train them: stateful and stateless models. Flax‚Äîbeing built on top of JAX‚Äîfalls in the latter category.\nIn this section, we will see what all of this means and how Flax handles model states."
  },
  {
    "objectID": "ai/fl/fl_state.html#dealing-with-state-in-jax",
    "href": "ai/fl/fl_state.html#dealing-with-state-in-jax",
    "title": "Flax‚Äôs handling of model states",
    "section": "Dealing with state in JAX",
    "text": "Dealing with state in JAX\nJAX JIT compilation requires that functions be without side effects since side effects are only executed once, during tracing.\nUpdating model parameters and optimizer state thus cannot be done as a side-effect. The state cannot be part of the model instance‚Äîit needs to be explicit, that is, separated from the model. During instantiation, no memory is allocated for the parameters. During the forward pass, the parameters will be part of the inputs, along with the data. The model is thus stateless and the constrains of pure functional programming are met (inputs lead to outputs without external influence or side effects).\nLet‚Äôs see why a stateful approach doesn‚Äôt work with JAX1: instead of defining a neural network class, we will define a very simple Counter class, following the PyTorch approach, that just adds 1. This allows us to see right away what is going on.\nimport jax\nimport jax.numpy as jnp\n\nclass Counter:\n    def __init__(self):\n        self.n = 0\n      \n    def count(self) -&gt; int:\n        \"\"\"Adds one to the counter and returns the new value.\"\"\"\n        self.n += 1\n        return self.n\n  \n    def reset(self):\n        \"\"\"Resets the counter to zero.\"\"\"\n        self.n = 0\nNow we can create an instance called counter of the Counter class.\ncounter = Counter()\nWe can use the counter:\nfor _ in range(3):\n    print(counter.count())\n1\n2\n3\nNow, let‚Äôs try with a JIT compiled version of count():\ncount_jit = jax.jit(counter.count)\n\ncounter.reset()\n\nfor _ in range(3):\n    print(count_jit())\n1\n1\n1\nThis is because count is not a functionally pure function. The tracing happens for the first run of the function (first iteration of the loop). Thereafter, the compiled version will rerun without taking into account the modifications of the attributes of counter.\nFor this to work, we need to initialize an explicit state and pass it as an argument to the count function:\nState = int\n\nclass Counter:\n    def count(self, n: State) -&gt; tuple[int, State]:\n        return n+1, n+1\n    \n    def reset(self) -&gt; State:\n        return 0\n\ncounter = Counter()\nstate = counter.reset()\n\nfor _ in range(3):\n    value, state = counter.count(state)\n    print(value)\n1\n2\n3\ncount_jit = jax.jit(counter.count)\n\nstate = counter.reset()\n\nfor _ in range(3):\n    value, state = count_jit(state)\n    print(value)\n1\n2\n3\n\nAs explained in JAX‚Äôs documentation, we turned a function of the type:\nclass StatefulClass\n  state: State\n  def stateful_method(*args, **kwargs) -&gt; Output:\nInto:\nclass StatelessClass\n  def stateless_method(state: State, *args, **kwargs) -&gt; (Output, State):"
  },
  {
    "objectID": "ai/fl/fl_state.html#stateful-vs-stateless-models",
    "href": "ai/fl/fl_state.html#stateful-vs-stateless-models",
    "title": "Flax‚Äôs handling of model states",
    "section": "Stateful vs stateless models",
    "text": "Stateful vs stateless models\n\nStateful models\nIn frameworks such as PyTorch or the Julia package Flux, model parameters and optimizer state are stored within the model instance. Instantiating a PyTorch model allocates memory for the model parameters. The model can then be described as stateful.\n\n\nStateless models\nFrameworks based on JAX such as Flax but also the Julia package Lux (a modern rewrite of Flux with explicit model parameters and a philosophy similar to JAX‚Äôs) are stateless: they follow a functional programming approach in which the parameters are separate from the model and are passed as inputs to the forward pass along with the data.\n\n\nExample: PyTorch vs Flax\nFlax, being built on JAX, it requires functionally pure functions and thus stateless models.\nHere is a comparison of the approach taken by PyTorch (stateful) vs Flax (stateless) to define and initialize a model (simplified model and workflow to show the principle):\n\nPyTorchFlax\n\n\nThis is how PyTorch works:\nimport torch\nimport torch.nn as nn\n\n# we create a subclass of torch.nn.Module\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.dense1 = nn.Linear(4, 144)\n        self.dense2 = nn.Linear(144, 4)\n\n    def forward(self, x):\n        x = self.dense1(x)\n        x = F.relu(x)\n        x = self.dense2(x)\n        return x\n\n# Create model instance\nmodel = Net()\n\n# Random data and labels\ndata = torch.empty((4, 12, 12, 1))\nlabels = torch.randn((4, 12, 12, 1))\nDuring the forward pass, only the inputs are passed through the model, but of course the outputs depend on the inputs and on the state of the model.\n\n\nHere is the Flax approach:\nimport jax\nimport jax.numpy as jnp\nfrom jax import random\nfrom flax import linen as nn\nimport optax\n\nSetup syntaxCompact syntax\n\n\nFlax provides a setup syntax of model definition which will look more familiar to PyTorch users:\n# Create a subclass of torch.nn.Module\nclass Net(nn.Module):\n  def setup(self):\n    self.dense1 = nn.Dense(12)\n    self.dense2 = nn.Dense(1)\n\n  def __call__(self, x):\n    x = self.dense1(x)\n    x = nn.relu(x)\n    x = self.dense2(x)\n    return x\n\n\nFlax comes with a compact syntax of model definition which is equivalent to the setup syntax in all respect except style:\n# Create a subclass of torch.nn.Module\nclass Net(nn.Module):\n  @nn.compact\n  def __call__(self, x):\n    x = nn.Dense(12, name=\"dense1\")(x)\n    x = nn.relu(x)\n    x = nn.Dense(12, name=\"dense2\")(x)\n    return x\n\n\n\nThe parameters are not part of the model. You initialize them afterwards and create a parameter object:\n# Create model instance\nmodel = Net()\n\n# Random data and labels\nkey, subkey1, subkey2 = random.split(random.key(13), 3)\ndata = jnp.empty((4, 12, 12, 1))\nlabels = random.normal(subkey1, (4, 12, 12, 1))\n\n# Initialize model parameters\nparams = model.init(subkey2, data)\n\n\n\nSimilarly, here are the stateful and stateless approaches to train the model:\n\nPyTorchFlax\n\n\n# Forward pass\nlogits = model(data)\n\nloss = nn.CrossEntropyLoss(logits, labels)\n\n# Calculate gradients\nloss.backward()\n\n# Optimze parameters\noptimizer.step()\n\n\n# Forward pass\ndef loss_func(params, data):\n    logits = model.apply(params, data)\n    loss = optax.softmax_cross_entropy(logits, labels).mean()\n    return loss\n\n# Calculate gradients\ngrads = jax.grad(loss_func)(params)\n\n# Optimze parameters\nparams = state.apply_gradients(grads)\nThe parameters are passed as inputs, along with the data, during the forward pass."
  },
  {
    "objectID": "ai/fl/fl_state.html#flax-training-state",
    "href": "ai/fl/fl_state.html#flax-training-state",
    "title": "Flax‚Äôs handling of model states",
    "section": "Flax training state",
    "text": "Flax training state\nThe demo above is stripped of any complexity to show the principle, but it is not realistic.\nTo handle every changing state during training (training step, state of the parameters, state of the optimizer), you can create a Flax training state.\nFlax provides a dataclass that you can subclass to create a new training state class:\nfrom flax.training import train_state\n\nclass TrainState(train_state.TrainState):\n    batch_stats: flax.core.FrozenDict\nThen you can define the Flax training step with TrainState.create:\nstate = TrainState.create(\n    apply_fn = model.apply,\n    params = modulel.init(subkey2, data),\n    tx = optax.sgd(0.01),\n    batch_stats = params['batch_stats'],\n)"
  },
  {
    "objectID": "ai/fl/fl_state.html#nnx",
    "href": "ai/fl/fl_state.html#nnx",
    "title": "Flax‚Äôs handling of model states",
    "section": "NNX",
    "text": "NNX\nA new Flax API is under development and might replace Linen at some point.\nIt provides transformations similar to JAX‚Äôs but which work on non-pure functions. This would bring Flax much closer to PyTorch and turn it into a stateful NN library by re-adding the parameters inside the model."
  },
  {
    "objectID": "ai/fl/fl_state.html#footnotes",
    "href": "ai/fl/fl_state.html#footnotes",
    "title": "Flax‚Äôs handling of model states",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nModified from JAX‚Äôs documentation.‚Ü©Ô∏é"
  },
  {
    "objectID": "ai/index.html",
    "href": "ai/index.html",
    "title": "AI",
    "section": "",
    "text": "Getting started with ¬†\nAn intro course to DL with PyTorch\n\n\n\n\nFast computing with \nAn intro course to JAX\n\n\n\n\n\n\nJAX NN with \nA DL course with Flax\n\n\n\n\nDeep learning with ¬†\nTraining models with the JAX AI stack\n\n\n\n\n\n\nA brief overview of ¬†\nTraditional ML with scikit-learn\n\n\n\n\nWorkshops\nVarious DL topics\n\n\n\n\n\n\n60 min webinars\nVarious DL topics",
    "crumbs": [
      "AI",
      "<br>&nbsp;<em><b>AI</b></em><br><br>"
    ]
  },
  {
    "objectID": "ai/jx/jx_ad.html",
    "href": "ai/jx/jx_ad.html",
    "title": "Automatic differentiation",
    "section": "",
    "text": "One of the transformations that can be applied to array computations is the calculation of gradients which is crucial to the backpropagation through deep neural networks.\nConsidering the function f:\nWe can create a new function dfdx that computes the gradient of f w.r.t. x:\ndfdx returns the derivatives:",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Automatic differentiation"
    ]
  },
  {
    "objectID": "ai/jx/jx_ad.html#composing-transformations",
    "href": "ai/jx/jx_ad.html#composing-transformations",
    "title": "Automatic differentiation",
    "section": "Composing transformations",
    "text": "Composing transformations\nTransformations can be composed:\nprint(jit(grad(f))(1.))\n4.0\nprint(grad(jit(f))(1.))\n4.0",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Automatic differentiation"
    ]
  },
  {
    "objectID": "ai/jx/jx_ad.html#forward-and-reverse-modes",
    "href": "ai/jx/jx_ad.html#forward-and-reverse-modes",
    "title": "Automatic differentiation",
    "section": "Forward and reverse modes",
    "text": "Forward and reverse modes\nJAX offers other autodiff methods:\n\nreverse-mode vector-Jacobian products: jax.vjp,\nforward-mode Jacobian-vector products: jax.jvp.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Automatic differentiation"
    ]
  },
  {
    "objectID": "ai/jx/jx_ad.html#higher-order-differentiation",
    "href": "ai/jx/jx_ad.html#higher-order-differentiation",
    "title": "Automatic differentiation",
    "section": "Higher-order differentiation",
    "text": "Higher-order differentiation\nWith a single variable, the grad function calls can be nested:\nd2fdx = grad(dfdx)   # function to compute 2nd order derivatives\nd3fdx = grad(d2fdx)  # function to compute 3rd order derivatives\n...\nWith several variables, you have to use the functions:\n\njax.jacfwd for forward-mode,\njax.jacrev for reverse-mode.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Automatic differentiation"
    ]
  },
  {
    "objectID": "ai/jx/jx_install.html",
    "href": "ai/jx/jx_install.html",
    "title": "Installing JAX",
    "section": "",
    "text": "In this section, we will access a virtual training cluster through SSH and make JAX accessible.\nWe will also cover how to install JAX in the Alliance production clusters.\nUnless you aren‚Äôt planning to use accelerators, JAX relies on GPUs/TPUs dependencies determined by your OS and hardware (e.g.¬†CUDA and CUDNN). Making sure that the dependencies are installed, compatible, and working with JAX can be finicky, so it is a lot easier to install JAX from pip wheels.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Installation"
    ]
  },
  {
    "objectID": "ai/jx/jx_install.html#on-your-computer",
    "href": "ai/jx/jx_install.html#on-your-computer",
    "title": "Installing JAX",
    "section": "On your computer",
    "text": "On your computer\nOn your personal computer, use the wheel installation command from the official JAX site corresponding to your system.\n\nOn Windows, GPUs are only supported via Windows Subsystem for Linux 2.\n\nBecause JAX is designed for large array computations and machine learning, you will most likely want to use it on supercomputers. In this course, we will thus use a virtual Alliance cluster.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Installation"
    ]
  },
  {
    "objectID": "ai/jx/jx_install.html#on-an-alliance-cluster",
    "href": "ai/jx/jx_install.html#on-an-alliance-cluster",
    "title": "Installing JAX",
    "section": "On an Alliance cluster",
    "text": "On an Alliance cluster\n\nLogging in through SSH\n\nOpen a terminal emulator\nWindows users: ‚ÄÉInstall the free version of MobaXTerm and launch it.\nmacOS users: ‚ÄÉ‚ÄÉLaunch Terminal.\nLinux users: ‚ÄÉ‚ÄÉ‚ÄÇ¬†Open the terminal emulator of your choice.\n\n\nAccess the cluster through secure shell\n\nWindows users\nFollow the first 18% of this demo.\nFor ‚ÄúRemote host‚Äù, use the hostname we gave you.\nSelect the box ‚ÄúSpecify username‚Äù and provide your username.\n\nNote that the password is entered through blind typing, meaning that you will not see anything happening as you type it. This is a Linux feature. While it is a little disturbing at first, do know that it is working. Make sure to type it slowly to avoid typos, then press the ‚Äúenter‚Äù key on your keyboard.\n\n\n\nmacOS and Linux users\nIn the terminal, run:\nssh &lt;username&gt;@&lt;hostname&gt;\n\nReplace the username and hostname by their values. For instance:\nssh user21@somecluster.c3.ca\n\nYou will be asked a question, answer ‚ÄúYes‚Äù.\nWhen prompted, type the password.\n\nNote that the password is entered through blind typing, meaning that you will not see anything happening as you type it. This is a Linux feature. While it is a little disturbing at first, do know that it is working. Make sure to type it slowly to avoid typos, then press the ‚Äúenter‚Äù key on your keyboard.\n\n\n\n\nTroubleshooting\nProblems logging in are almost always due to typos. If you cannot log in, retry slowly, entering your password carefully.\n\n\n\nInstall JAX\n\nWe already created a Python virtual environment and installed JAX to save time. The instructions for today thus differ from what you would normally do, but I include the normal instructions in a separate tab for your future reference.\n\n\nTodayProduction cluster\n\n\nI already created a virtual Python environment under /project and installed JAX in it to save time and space. All you have to do is activate it:\nsource /project/60055/env/bin/activate\n\n\nLook for available Python modules:\nmodule spider python\nLoad the version of your choice:\nmodule load python/3.11.5\nCreate a Python virtual environment:\npython -m venv ~/env\nActivate it:\nsource ~/env/bin/activate\nUpdate pip from wheel:\npython -m pip install --upgrade pip --no-index\n\nWhenever a Python wheel for a package is available on the Alliance clusters, you should use it instead of downloading the package from PyPI. To do this, simply add the --no-index flag to the install command.\nYou can see whether a wheel is available with avail_wheels &lt;package&gt; or look at the list of available wheels.\nAdvantages of wheels:\n\ncompiled for the clusters hardware,\nensures no missing or conflicting dependencies,\nmuch faster installation.\n\n\nInstall JAX from wheel:\npython -m pip install jax --no-index\n\nDon‚Äôt forget the --no-index flag here: the wheel will save you from having to deal with the CUDA and CUDNN dependencies, making your life a lot easier.\n\n\nIf you want to install a particular version of JAX, you first need to see what wheel is available:\navail_wheels \"jax*\"\nThen load the wheel of your choice:\npython -m pip install jax==0.4.26 --no-index",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Installation"
    ]
  },
  {
    "objectID": "ai/jx/jx_jobs.html",
    "href": "ai/jx/jx_jobs.html",
    "title": "Running jobs",
    "section": "",
    "text": "This section is a quick review on how to submit jobs to the scheduler (Slurm) on the Alliance clusters. For more detailed information, please visit our wiki.\n\nThere are two types of jobs that can be launched on an Alliance cluster: interactive jobs and batch jobs.\n\nDon‚Äôt run computations on the login node: those are very small nodes not designed to handle anything heavy.\n\n\nInteractive jobs\nTo run Python interactively, you should launch an salloc session.\n\nExample:\n\nsalloc --time=xxx --mem-per-cpu=xxx --cpus-per-task=xxx\nThis takes you to a compute node where you can now launch Python (or even better IPython) to run computations:\nipython\n\nNote that while interactive jobs are great for code development, they are not resource efficient: all the resources that you requested are blocked for you while your job is running, whether you are making use of them (running heavy computations) or not (thinking, typing code, running computations that use only a fraction of the requested resources).\nBest to use this on sample data using few resources.\n\n\n\nScripts\nOnce you have a working and tested program, you should run a batch job on the resources you need to get your results. To run a Python script called &lt;your_script&gt;.py, you first need to write a job script:\n\nExample:\n\n\n&lt;your_job&gt;.sh\n\n#!/bin/bash\n#SBATCH --account=def-&lt;your_account&gt;\n#SBATCH --time=xxx\n#SBATCH --mem-per-cpu=xxx\n#SBATCH --cpus-per-task=xxx\n#SBATCH --job-name=\"&lt;your_job&gt;\"\n\nsource ~/env/bin/activate\npython &lt;your_script&gt;.py\n\n\nThen launch your job with:\nsbatch &lt;your_job&gt;.sh\nYou can monitor your job with sq (an alias for squeue -u $USER $@).\n\nBatch jobs are the best approach to run heavy computations requiring a lot of hardware.\nIt will save you lots of waiting time (Alliance clusters) or money (commercial clusters).",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Running jobs"
    ]
  },
  {
    "objectID": "ai/jx/jx_map.html",
    "href": "ai/jx/jx_map.html",
    "title": "How does it work?",
    "section": "",
    "text": "Before using JAX, it is critical to understand its functioning: JAX architecture is at the core of its efficiency and flexibility, but also the cause of a number of constraints.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "How does it work?"
    ]
  },
  {
    "objectID": "ai/jx/jx_map.html#map",
    "href": "ai/jx/jx_map.html#map",
    "title": "How does it work?",
    "section": "Map",
    "text": "Map\nHere is a schematic of JAX‚Äôs functioning:\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\n Just-in-time \n(JIT)\ncompilation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\n Transformations \n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "How does it work?"
    ]
  },
  {
    "objectID": "ai/jx/jx_map.html#tracing",
    "href": "ai/jx/jx_map.html#tracing",
    "title": "How does it work?",
    "section": "Tracing",
    "text": "Tracing\nTracing happens during the first call of a function. Tracer objects are wrapped around each argument and record all operations performed on them, creating a Jaxpr (JAX expression). It is this intermediate representation‚Äîrather than the Python code‚Äîthat JAX then uses.\nThe tracer objects used to create the Jaxpr contain information about the shape and dtype of the initial Python arguments, but not their values. This means that new inputs with the same shape and dtype will use the cached compiled program directly, skipping the Python code entirely. Inputs with new shape and/or dtype will trigger tracing again (so the Python function gets executed again).\nFunction side-effects are not recorded by the tracers, which means that they are not part of the Jaxprs. They will be executed once (during tracing), but are thereafter absent from the cached compiled program.\nFunctions which use values outside of their arguments (e.g.¬†values from the global environment) will not update the cache if such values change.\nFor these reasons, only functionally pure functions (functions without side effects and which do not rely on values outside their arguments) should be used with JAX.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "How does it work?"
    ]
  },
  {
    "objectID": "ai/jx/jx_map.html#transformations",
    "href": "ai/jx/jx_map.html#transformations",
    "title": "How does it work?",
    "section": "Transformations",
    "text": "Transformations\nJAX is essentially a functional programming framework. Transformations are higher-order functions transforming Jaxprs.\nTransformations are composable and include:\n\njax.grad(): creates a function that evaluates the gradient of the input function,\njax.vmap(): implementation of automatic vectorization,\njax.pmap(): implementation of data parallelism across processing units,\n\nand finally, once other necessary transformations have been performed:\n\njax.jit(): just-in-time compilation for the XLA.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "How does it work?"
    ]
  },
  {
    "objectID": "ai/jx/jx_map.html#xla",
    "href": "ai/jx/jx_map.html#xla",
    "title": "How does it work?",
    "section": "XLA",
    "text": "XLA\nThe XLA (Accelerated Linear Algebra) compiler takes JIT-compiled JAX programs and optimizes them for the available hardware (CPUs, GPUs, or TPUs).",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "How does it work?"
    ]
  },
  {
    "objectID": "ai/jx/jx_optimizations.html",
    "href": "ai/jx/jx_optimizations.html",
    "title": "Pushing optimizations further",
    "section": "",
    "text": "JAX feels lower level than other libraries (more constraints, more performance). This can be pushed further for additional speedups (but with additional code complexity).",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Pushing optimizations further"
    ]
  },
  {
    "objectID": "ai/jx/jx_optimizations.html#the-lax-api",
    "href": "ai/jx/jx_optimizations.html#the-lax-api",
    "title": "Pushing optimizations further",
    "section": "The lax API",
    "text": "The lax API\njax.numpy is a high-level NumPy-like API wrapped around jax.lax. jax.lax is a more efficient lower-level API itself wrapped around XLA. It is more powerful, but even stricter and requires many more lines of code.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Pushing optimizations further"
    ]
  },
  {
    "objectID": "ai/jx/jx_optimizations.html#pallas-extension-to-write-gpu-and-tpu-kernels",
    "href": "ai/jx/jx_optimizations.html#pallas-extension-to-write-gpu-and-tpu-kernels",
    "title": "Pushing optimizations further",
    "section": "Pallas: extension to write GPU and TPU kernels",
    "text": "Pallas: extension to write GPU and TPU kernels\nWith the success of Triton, JAX built the Pallas extension that allows JAX users to write GPU kernels.\nIt also allows to write kernels for the TPU with moisaic.\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\n Just-in-time \n(JIT)\ncompilation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\ntriton\n\nTriton\n\n\n\nGPU\n\nGPU\n\n\n\ntriton-&gt;GPU\n\n\n\n\n\nmosaic\n\nMosaic\n\n\n\nTPU\n\nTPU\n\n\n\nmosaic-&gt;TPU\n\n\n\n\n\ntransform\n\nVectorization\nParallelization\n ¬†¬†Differentiation ¬†\n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;triton\n\n\n\n\nhlo-&gt;mosaic",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Pushing optimizations further"
    ]
  },
  {
    "objectID": "ai/jx/jx_parallel.html",
    "href": "ai/jx/jx_parallel.html",
    "title": "Parallel computing",
    "section": "",
    "text": "JAX is designed for DNN and linear algebra at scale. Processing vast amounts of data in parallel is crucial to its goal. Two of JAX‚Äôs transformations allow to turn linear code into parallel code very easily.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Parallel computing"
    ]
  },
  {
    "objectID": "ai/jx/jx_parallel.html#vectorization",
    "href": "ai/jx/jx_parallel.html#vectorization",
    "title": "Parallel computing",
    "section": "Vectorization",
    "text": "Vectorization\nRemember how a number of transformations are applied to jaxprs. We already saw two of JAX‚Äôs main transformations: JIT compilation with jax.jit and automatic differentiation with jax.grad. Vectorization with jax.vmap is another one.\nIt automates the vectorization of complex functions (operations on arrays are naturally executed in a vectorized fashion‚Äîas is the case in R, in NumPy, etc.‚Äîbut more complex functions are not).\nHere is an example from JAX 101 commonly encountered in deep learning:\nimport jax\nimport jax.numpy as jnp\n\nx = jnp.arange(5)\nw = jnp.array([2., 3., 4.])\n\ndef convolve(x, w):\n    output = []\n    for i in range(1, len(x)-1):\n        output.append(jnp.dot(x[i-1:i+2], w))\n    return jnp.array(output)\n\nconvolve(x, w)\nArray([11., 20., 29.], dtype=float32)\n\nSee this great post for explanations of convolutions.\n\nYou will probably want to apply the function convolve() to a batch of weights w and vectors x.\nxs = jnp.stack([x, x, x])\nws = jnp.stack([w, w, w])\nWe apply the jax.vmap() transformation to the convolve() function and pass the batches to it:\nvconvolve = jax.vmap(convolve)\nvconvolve(xs, ws)\nArray([[11., 20., 29.],\n       [11., 20., 29.],\n       [11., 20., 29.]], dtype=float32)\n\nAs we already saw, transformations can be composed:\nvconvolve_jit = jax.jit(vconvolve)\nvconvolve_jit(xs, ws)\nArray([[11., 20., 29.],\n       [11., 20., 29.],\n       [11., 20., 29.]], dtype=float32)",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Parallel computing"
    ]
  },
  {
    "objectID": "ai/jx/jx_parallel.html#parallel-runs-across-devices",
    "href": "ai/jx/jx_parallel.html#parallel-runs-across-devices",
    "title": "Parallel computing",
    "section": "Parallel runs across devices",
    "text": "Parallel runs across devices\nThe jax.pmap transformation does the same thing but each computation runs on a different device (e.g.¬†a different GPU) on the same node, allowing to scale things up further:\njax.pmap(convolve)(xs, ws)\njax.pmap automatically JIT compiles the code, so it is unnecessary to pass this to jax.jit.\n\nJAX is also capable of running distributed arrays across multiple devices through sharding.\nJAX does not have the ability to scale things up to the level of multi-node clusters, but the mpi4jax extension provides multi-host communication for distributed parallelism.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Parallel computing"
    ]
  },
  {
    "objectID": "ai/jx/jx_resources.html",
    "href": "ai/jx/jx_resources.html",
    "title": "Resources",
    "section": "",
    "text": "Here is a list of resources to get started with JAX.\n\n\nOfficial documentation\n\nJAX GitHub repo\nOfficial documentation\nJAX API\n\n\n\nOther resources\nAwesome JAX is a great list of resources on JAX.\n\n\nQ&A\n\nJAX GitHub Discussions\nStack Overflow [jax] tag\n\n\n\nAlliance wiki\nThere is currently no page on JAX, but there is a page on Flax.",
    "crumbs": [
      "AI",
      "<b><em>The JAX library</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "ai/jx/wb_jax.html",
    "href": "ai/jx/wb_jax.html",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "",
    "text": "JAX is an open source Python library for high-performance array computing and flexible automatic differentiation.\nHigh-performance computing is achieved by asynchronous dispatch, just-in-time compilation, the XLA compiler for linear algebra, and full compatibility with accelerators (GPUs and TPUs).\nAutomatic differentiation uses Autograd and works with complex control flows (conditions, recursions), second and third-order derivatives, forward and reverse modes. This makes JAX ideal for machine learning and neural network libraries such as Flax are built on it.\nThis webinar will give an overview of JAX‚Äôs principles and functioning.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Accelerated array & AD"
    ]
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#what-is-jax",
    "href": "ai/jx/wb_jax_slides.html#what-is-jax",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "What is JAX?",
    "text": "What is JAX?\n\nLibrary for Python developed by Google\n\n\nKey data structure: Array\n\n\nComposition, transformation, and differentiation of numerical programs\n\n\nCompilation for CPUs, GPUs, and TPUs\n\n\nNumPy-like and lower-level APIs\n\n\nRequires strict functional programming"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#why-jax",
    "href": "ai/jx/wb_jax_slides.html#why-jax",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Why JAX?",
    "text": "Why JAX?\n\n\n\n\n\n\n\n\n\n01\n\n\nAutodiff method\n\n\n\n1\nStatic graph\nand XLA\n\n\n\n\n02\n\n\nFramework\n\n\n\n\n2\nDynamic graph\n\n\n\n1-&gt;2\n\n\n\n\n\na\n\nTensorFlow\n\n\n\n\n4\nDynamic graph\nand XLA\n\n\n\n2-&gt;4\n\n\n\n\n\nb\n\nPyTorch\n\n\n\n\n5\nPseudo-dynamic\nand XLA\n\n\n\n4-&gt;5\n\n\n\n\n\nd\n\nTensorFlow2\n\n\n\n\ne\n\nJAX\n\n\n\n\n\n03\n\n\nAdvantage\n\n\n\n\n\n7\nMostly\noptimized AD\n\n\n\n\n\n8\nConvenient\n\n\n\n\n\n9\nConvenient\n\n\n\n\n10\nConvenient and\nmostly optimized AD\n\n\n\n\n\n04\n\n\nDisadvantage\n\n\n\n\n\nA\nManual writing of IR\n\n\n\n\n\nB\nLimited AD optimization\n\n\n\n\n\nD\nDisappointing speed\n\n\n\n\nE\nPure functions\n\n\n\n\n\n\n\n\n\n\n\n\n\n‚ÄÉ‚ÄÉSummarized from a blog post by Chris Rackauckas"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#installation",
    "href": "ai/jx/wb_jax_slides.html#installation",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Installation",
    "text": "Installation\n Install from pip wheels:\n\nPersonal computer: use wheels installation commands from official site\nAlliance clusters: python -m pip install jax --no-index \n\n\nWindows: GPU support only via WSL"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#the-numpy-api",
    "href": "ai/jx/wb_jax_slides.html#the-numpy-api",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "The NumPy API",
    "text": "The NumPy API\n\nNumPyJAX NumPy\n\n\n\nimport numpy as np\n\nprint(np.array([(1, 2, 3), (4, 5, 6)]))\n\n[[1 2 3]\n [4 5 6]]\n\n\n\nprint(np.arange(5))\n\n[0 1 2 3 4]\n\n\n\nprint(np.zeros(2))\n\n[0. 0.]\n\n\n\nprint(np.linspace(0, 2, 9))\n\n[0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ]\n\n\n\n\nimport jax.numpy as jnp\n\nprint(jnp.array([(1, 2, 3), (4, 5, 6)]))\n[[1 2 3]\n [4 5 6]]\nprint(jnp.arange(5))\n[0 1 2 3 4]\nprint(jnp.zeros(2))\n[0. 0.]\nprint(jnp.linspace(0, 2, 9))\n[0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ]"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#different-types",
    "href": "ai/jx/wb_jax_slides.html#different-types",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Different types",
    "text": "Different types\n\nNumpyJAX NumPy\n\n\n\ntype(np.zeros((2, 3)))\n\nnumpy.ndarray\n\n\n\n\ntype(jnp.zeros((2, 3)))\njaxlib.xla_extension.ArrayImpl"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#different-default-data-types",
    "href": "ai/jx/wb_jax_slides.html#different-default-data-types",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Different default data types",
    "text": "Different default data types\n\nNumpyJAX NumPy\n\n\n\nnp.zeros((2, 3)).dtype\n\ndtype('float64')\n\n\n\n\njnp.zeros((2, 3)).dtype\ndtype('float32')\n\nStandard for DL and libraries built for accelerators\nFloat64 are very slow on GPUs and not supported on TPUs"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#immutable-arrays",
    "href": "ai/jx/wb_jax_slides.html#immutable-arrays",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Immutable arrays",
    "text": "Immutable arrays\n\nNumpyJAX NumPy\n\n\n\na = np.arange(5)\na[0] = 9\nprint(a)\n\n[9 1 2 3 4]\n\n\n\n\na = jnp.arange(5)\na[0] = 9\nTypeError: '&lt;class 'jaxlib.xla_extension.ArrayImpl'&gt;' object does not support item assignment. JAX arrays are immutable.\nb = a.at[0].set(9)\nprint(b)\n[9 1 2 3 4]"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#strict-input-control",
    "href": "ai/jx/wb_jax_slides.html#strict-input-control",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Strict input control",
    "text": "Strict input control\n\nNumpyJAX NumPy\n\n\nNumPy is easy-going:\n\nnp.sum([1.0, 2.0])  # argument is a list\n\nnp.float64(3.0)\n\n\n\nnp.sum((1.0, 2.0))  # argument is a tuple\n\nnp.float64(3.0)\n\n\n\n\nTo avoid inefficiencies, JAX will only accept arrays:\njnp.sum([1.0, 2.0])\nTypeError: sum requires ndarray or scalar arguments, got &lt;class 'list'&gt;\njnp.sum((1.0, 2.0))\nTypeError: sum requires ndarray or scalar arguments, got &lt;class 'tuple'&gt;"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#out-of-bounds-indexing",
    "href": "ai/jx/wb_jax_slides.html#out-of-bounds-indexing",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Out of bounds indexing",
    "text": "Out of bounds indexing\n\nNumpyJAX NumPy\n\n\nNumPy will error if you index out of bounds:\n\nprint(np.arange(5)[10])\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[10], line 1\n----&gt; 1 print(np.arange(5)[10])\n\nIndexError: index 10 is out of bounds for axis 0 with size 5\n\n\n\n\n\nJAX will silently return the closest boundary:\nprint(jnp.arange(5)[10])\n4"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#prng-key",
    "href": "ai/jx/wb_jax_slides.html#prng-key",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "PRNG key",
    "text": "PRNG key\nTraditional pseudorandom number generators are based on nondeterministic state of OS\nSlow and problematic for parallel executions\nJAX relies on explicitly-set random state called a key:\nfrom jax import random\n\ninitial_key = random.key(18)\nprint(initial_key)\n[ 0 18]"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#prng-key-1",
    "href": "ai/jx/wb_jax_slides.html#prng-key-1",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "PRNG key",
    "text": "PRNG key\nEach key can only be used for one random function, but it can be split into new keys:\nnew_key1, new_key2 = random.split(initial_key)\n\ninitial_key can‚Äôt be used anymore now\n\nprint(new_key1)\n[4197003906 1654466292]\nprint(new_key2)\n[1685972163 1654824463]\nWe need to keep one key to split whenever we need and we can use the other one"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#prng-key-2",
    "href": "ai/jx/wb_jax_slides.html#prng-key-2",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "PRNG key",
    "text": "PRNG key\nTo make sure we don‚Äôt reuse a key by accident, it is best to overwrite the initial key with one of the new ones\nHere are easier names:\nkey = random.key(18)\nkey, subkey = random.split(key)\nWe can now use subkey to generate a random array:\nx = random.normal(subkey, (3, 2))"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#benchmarking",
    "href": "ai/jx/wb_jax_slides.html#benchmarking",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Benchmarking",
    "text": "Benchmarking\nJAX uses asynchronous dispatch\nInstead of waiting for a computation to complete before control returns to Python, the computation is dispatched to an accelerator and a future is created\nTo get proper timings, we need to make sure the future is resolved by using the block_until_ready() method"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#jit-syntax",
    "href": "ai/jx/wb_jax_slides.html#jit-syntax",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "JIT syntax",
    "text": "JIT syntax\nfrom jax import jit\n\nkey = random.key(8)\nkey, subkey1, subkey2 = random.split(key, 3)\n\na = random.normal(subkey1, (500, 500))\nb = random.normal(subkey2, (500, 500))\n\ndef sum_squared_error(a, b):\n    return jnp.sum((a-b)**2)\nOur function could simply be used as:\nsse = sum_squared_error(a, b)"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#jit-syntax-1",
    "href": "ai/jx/wb_jax_slides.html#jit-syntax-1",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "JIT syntax",
    "text": "JIT syntax\nOur code will run faster if we create a JIT compiled version and use that instead:\nsum_squared_error_jit = jit(sum_squared_error)\n\nsse = sum_squared_error_jit(a, b)\nAlternatively, this can be written as:\nsse = jit(sum_squared_error)(a, b)\nOr with the @jit decorator:\n@jit\ndef sum_squared_error(a, b):\n    return jnp.sum((a - b) ** 2)\n\nsse = sum_squared_error(a, b)"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#static-vs-traced-variables",
    "href": "ai/jx/wb_jax_slides.html#static-vs-traced-variables",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Static vs traced variables",
    "text": "Static vs traced variables\n@jit\ndef cond_func(x):\n    if x &lt; 0.0:\n        return x ** 2.0\n    else:\n        return x ** 3.0\n\nprint(cond_func(1.0))\njax.errors.TracerBoolConversionError: Attempted boolean conversion of traced array with shape bool[]\nJIT compilation uses tracing of the code based on shape and dtype so that the same compiled code can be reused for new values with the same characteristics\nTracer objects are not real values but abstract representation that are more general\nHere, an abstract general value does not work as it wouldn‚Äôt know which branch to take"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#static-vs-traced-variables-1",
    "href": "ai/jx/wb_jax_slides.html#static-vs-traced-variables-1",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Static vs traced variables",
    "text": "Static vs traced variables\nOne solution is to tell jit() to exclude the problematic arguments from tracing\nwith arguments positions:\ndef cond_func(x):\n    if x &lt; 0.0:\n        return x ** 2.0\n    else:\n        return x ** 3.0\n\ncond_func_jit = jit(cond_func, static_argnums=(0,))\n\nprint(cond_func_jit(2.0))\nprint(cond_func_jit(-2.0))\n8.0\n4.0"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#static-vs-traced-variables-2",
    "href": "ai/jx/wb_jax_slides.html#static-vs-traced-variables-2",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Static vs traced variables",
    "text": "Static vs traced variables\nOne solution is to tell jit() to exclude the problematic arguments from tracing\nwith arguments names:\ndef cond_func(x):\n    if x &lt; 0.0:\n        return x ** 2.0\n    else:\n        return x ** 3.0\n\ncond_func_jit_alt = jit(cond_func, static_argnames=\"x\")\n\nprint(cond_func_jit_alt(2.0))\nprint(cond_func_jit_alt(-2.0))\n8.0\n4.0"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#control-flow-primitives",
    "href": "ai/jx/wb_jax_slides.html#control-flow-primitives",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Control flow primitives",
    "text": "Control flow primitives\nAnother solution, is to use one of the structured control flow primitives:\nfrom jax import lax\n\nlax.cond(False, lambda x: x ** 2.0, lambda x: x ** 3.0, jnp.array([2.]))\nArray([8.], dtype=float32)\nlax.cond(True, lambda x: x ** 2.0, lambda x: x ** 3.0, jnp.array([-2.]))\nArray([4.], dtype=float32)"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#control-flow-primitives-1",
    "href": "ai/jx/wb_jax_slides.html#control-flow-primitives-1",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Control flow primitives",
    "text": "Control flow primitives\nOther control flow primitives:\n\nlax.while_loop\nlax.fori_loop\nlax.scan\n\nOther pseudo dynamic control flow functions:\n\nlax.select (NumPy API jnp.where and jnp.select)\nlax.switch (NumPy API jnp.piecewise)"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#static-vs-traced-operations",
    "href": "ai/jx/wb_jax_slides.html#static-vs-traced-operations",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Static vs traced operations",
    "text": "Static vs traced operations\nSimilarly, you can mark problematic operations as static so that they don‚Äôt get traced during JIT compilation:\n@jit\ndef f(x):\n    return x.reshape(jnp.array(x.shape).prod())\n\nx = jnp.ones((2, 3))\nprint(f(x))\nTypeError: Shapes must be 1D sequences of concrete values of integer type, got [Traced&lt;ShapedArray(int32[])&gt;with&lt;DynamicJaxprTrace(level=1/0)&gt;]"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#static-vs-traced-operations-1",
    "href": "ai/jx/wb_jax_slides.html#static-vs-traced-operations-1",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Static vs traced operations",
    "text": "Static vs traced operations\nThe problem here is that the shape of the argument to prod() depends on the value of x which is unknown at compilation time\nOne solution is to use the NumPy version of prod():\nimport numpy as np\n\n@jit\ndef f(x):\n    return x.reshape((np.prod(x.shape)))\n\nprint(f(x))\n[1. 1. 1. 1. 1. 1.]"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#jaxprs",
    "href": "ai/jx/wb_jax_slides.html#jaxprs",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Jaxprs",
    "text": "Jaxprs\nimport jax\n\nx = jnp.array([1., 4., 3.])\ny = jnp.array([8., 1., 2.])\n\ndef f(x, y):\n    return 2 * x**2 + y\n\njax.make_jaxpr(f)(x, y) \n{ lambda ; a:f32[3] b:f32[3]. let\n    c:f32[3] = integer_pow[y=2] a\n    d:f32[3] = mul 2.0 c\n    e:f32[3] = add d b\n  in (e,) }"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#outputs-only-based-on-inputs",
    "href": "ai/jx/wb_jax_slides.html#outputs-only-based-on-inputs",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Outputs only based on inputs",
    "text": "Outputs only based on inputs\ndef f(x):\n    return a + x\nf uses the variable a from the global environment\nThe output does not solely depend on the inputs: not a pure function"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#outputs-only-based-on-inputs-1",
    "href": "ai/jx/wb_jax_slides.html#outputs-only-based-on-inputs-1",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Outputs only based on inputs",
    "text": "Outputs only based on inputs\na = jnp.ones(3)\nprint(a)\n[1. 1. 1.]\ndef f(x):\n    return a + x\n\nprint(jit(f)(jnp.ones(3)))\n[2. 2. 2.]\n\nThings seem ok here because this is the first run (tracing)"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#outputs-only-based-on-inputs-2",
    "href": "ai/jx/wb_jax_slides.html#outputs-only-based-on-inputs-2",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Outputs only based on inputs",
    "text": "Outputs only based on inputs\nNow, let‚Äôs change the value of a to an array of zeros:\na = jnp.zeros(3)\nprint(a)\n[0. 0. 0.]\nAnd rerun the same code:\nprint(jit(f)(jnp.ones(3)))\n[2. 2. 2.]\n\nOur cached compiled program is run and we get a wrong result"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#outputs-only-based-on-inputs-3",
    "href": "ai/jx/wb_jax_slides.html#outputs-only-based-on-inputs-3",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Outputs only based on inputs",
    "text": "Outputs only based on inputs\nThe new value for a will only take effect if we re-trigger tracing by changing the shape and/or dtype of x:\na = jnp.zeros(4)\nprint(a)\n[0. 0. 0. 0.]\nprint(jit(f)(jnp.ones(4)))\n[1. 1. 1. 1.]\nPassing to f() an argument of a different shape forced retracing"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#no-side-effects",
    "href": "ai/jx/wb_jax_slides.html#no-side-effects",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "No side effects",
    "text": "No side effects\nSide effects: anything beside returned output\nExamples:\n\nPrinting to standard output\nReading from file/writing to file\nModifying a global variable"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#no-side-effects-1",
    "href": "ai/jx/wb_jax_slides.html#no-side-effects-1",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "No side effects",
    "text": "No side effects\nThe side effects will happen during tracing, but not on subsequent runs. You cannot rely on side effects in your code\ndef f(a, b):\n    print(\"Calculating sum\")\n    return a + b\n\nprint(jit(f)(jnp.arange(3), jnp.arange(3)))\nCalculating sum\n[0 2 4]\n\nPrinting happened here because this is the first run"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#no-side-effects-2",
    "href": "ai/jx/wb_jax_slides.html#no-side-effects-2",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "No side effects",
    "text": "No side effects\nLet‚Äôs rerun the function:\nprint(jit(f)(jnp.arange(3), jnp.arange(3)))\n[0 2 4]\nThis time, no printing"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#automatic-differentiation",
    "href": "ai/jx/wb_jax_slides.html#automatic-differentiation",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Automatic differentiation",
    "text": "Automatic differentiation\nConsidering the function f:\nf = lambda x: x**3 + 2*x**2 - 3*x + 8\nWe can create a new function dfdx that computes the gradient of f w.r.t. x:\nfrom jax import grad\n\ndfdx = grad(f)\ndfdx returns the derivatives\nprint(dfdx(1.))\n4.0"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#composing-transformations",
    "href": "ai/jx/wb_jax_slides.html#composing-transformations",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Composing transformations",
    "text": "Composing transformations\nTransformations can be composed:\nprint(jit(grad(f))(1.))\n4.0\nprint(grad(jit(f))(1.))\n4.0"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#forward-and-reverse-modes",
    "href": "ai/jx/wb_jax_slides.html#forward-and-reverse-modes",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Forward and reverse modes",
    "text": "Forward and reverse modes\nOther autodiff methods:\n\nReverse-mode vector-Jacobian products: jax.vjp\nForward-mode Jacobian-vector products: jax.jvp"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#higher-order-differentiation",
    "href": "ai/jx/wb_jax_slides.html#higher-order-differentiation",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Higher-order differentiation",
    "text": "Higher-order differentiation\n With a single variable, the grad function calls can be nested:\nd2fdx = grad(dfdx)   # function to compute 2nd order derivatives\nd3fdx = grad(d2fdx)  # function to compute 3rd order derivatives\n...\n With several variables:\n\njax.jacfwd for forward-mode\njax.jacrev for reverse-mode"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#pytrees",
    "href": "ai/jx/wb_jax_slides.html#pytrees",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Pytrees",
    "text": "Pytrees\nJAX has a nested container structure: pytree extremely useful for DNN"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#vectorization-and-parallelization",
    "href": "ai/jx/wb_jax_slides.html#vectorization-and-parallelization",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Vectorization and parallelization",
    "text": "Vectorization and parallelization\nOther transformations for parallel run of computations across batches of arrays:\n\nAutomatic vectorization with jax.vmap\nParallelization across devices with jax.pmap"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#lax-api",
    "href": "ai/jx/wb_jax_slides.html#lax-api",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Lax API",
    "text": "Lax API\njax.numpy is a high-level NumPy-like API wrapped around jax.lax\njax.lax is a more efficient lower-level API itself wrapped around XLA"
  },
  {
    "objectID": "ai/jx/wb_jax_slides.html#pallas-extension-to-write-gpu-and-tpu-kernels",
    "href": "ai/jx/wb_jax_slides.html#pallas-extension-to-write-gpu-and-tpu-kernels",
    "title": "Accelerated array computing and flexible differentiation with",
    "section": "Pallas: extension to write GPU and TPU kernels",
    "text": "Pallas: extension to write GPU and TPU kernels\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\n Just-in-time \n(JIT)\ncompilation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\ntriton\n\nTriton\n\n\n\nGPU\n\nGPU\n\n\n\ntriton-&gt;GPU\n\n\n\n\n\nmosaic\n\nMosaic\n\n\n\nTPU\n\nTPU\n\n\n\nmosaic-&gt;TPU\n\n\n\n\n\ntransform\n\nVectorization\nParallelization\n ¬†¬†Differentiation ¬†\n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;triton\n\n\n\n\nhlo-&gt;mosaic"
  },
  {
    "objectID": "ai/jxai/jxai_augmentation.html",
    "href": "ai/jxai/jxai_augmentation.html",
    "title": "Data augmentation",
    "section": "",
    "text": "Key to deep learning is data augmentation. This section explains what it is and what techniques we should use in our example.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data augmentation"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_augmentation.html#what-is-data-augmentation",
    "href": "ai/jxai/jxai_augmentation.html#what-is-data-augmentation",
    "title": "Data augmentation",
    "section": "What is data augmentation?",
    "text": "What is data augmentation?\nTraining deep learning models requires vast amounts of labelled data. The more diverse and numerous the data, the better the models will perform on new, unseen data.\nA number of labelled datasets exist, but they are only so big. Moreover, for specific applications, you will need to fine-tune models on specific data for which there might not be any labelled data. And labelling data is costly and time-consuming. In some cases, it might even be impossible because little unlabelled data exist (think for instance of rare tumours).\nData augmentation is the artificial creation of new data by modifying the existing data in small ways. It is very powerful to avoid overfitting, particularly where datasets are small (if you were lucky enough to have a huge dataset, you wouldn‚Äôt need to bother with data augmentation which would actually create an additional computationally costly step with extremely little benefit).\nXu et al. performed a comprehensive survey of image augmentation techniques for deep learning in 2023 [1], but the field is evolving very fast with new techniques coming out all the time.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data augmentation"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_augmentation.html#augmentation-libraries",
    "href": "ai/jxai/jxai_augmentation.html#augmentation-libraries",
    "title": "Data augmentation",
    "section": "Augmentation libraries",
    "text": "Augmentation libraries\nData augmentation being such a classic technique, many libraries offer sets of augmentation tools. Among the very popular, we can list:\n\nAlbumentationsX,\nTorchVision transforms,\nskimage.transform from scikit-image.\n\nThere are others.\nAmar√π et al. created a curated repository of libraries for data augmentation in computer vision [2].\nIn this course, we will use PIX, a library built for JAX which provides low-level, JAX-native image processing primitives that can be directly jitted and vmapped.\nWe are shifting paradigm here and moving from the CPU to the GPU. This is where JAX comes in.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data augmentation"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_augmentation.html#augmentation-techniques",
    "href": "ai/jxai/jxai_augmentation.html#augmentation-techniques",
    "title": "Data augmentation",
    "section": "Augmentation techniques",
    "text": "Augmentation techniques\nThere are many techniques:\n\nGeometric transformations (flips, rotations, scaling, crops‚Ä¶).\nColor space transformations (brightness, contrast, gamma, hue, saturation, grayscale conversion, channel shuffling‚Ä¶).\nNoise transformations (Gaussian noise, blurring‚Ä¶).\nOcclusive transformations (erasing parts of the image).\nMixing images (various techniques mixing images and appropriately applying the same treatment to labels).",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data augmentation"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_augmentation.html#choosing-techniques",
    "href": "ai/jxai/jxai_augmentation.html#choosing-techniques",
    "title": "Data augmentation",
    "section": "Choosing techniques",
    "text": "Choosing techniques\n\nHow many to use?\nThe size of your dataset dictates how aggressively you should augment.\n\n\n\n\n\n\n\n\nDataset size\nStrategy\nRecommended count\n\n\n\n\nTiny (&lt;1k images)\nHeavy augmentation. You should be worried about overfitting, so you need to create more artificial data\n4-6 techniques\n\n\nMedium (1k - 100k)\nStandard augmentation. Balance variety with training speed\n3-4 techniques\n\n\nLarge (&gt;100K images)\nLight augmentation.\n1-2 techniques\n\n\nMassive (&gt;1M images)\nNo augmentation. The data itself provides enough diversity. Augmentation will only slow down training.\n0 technique\n\n\n\nOur dataset contains about 50K images (including the validation set). This puts us in the medium category and a standard approach with 3 or 4 techniques should be reasonable.\n\n\nWhich ones to use?\nThe choice depends on the problem.\nIn our case, we are dealing with fine-grained birds identification. Colours are critical for species differentiation, so we don‚Äôt want to mess with that. This means that playing with hue, solarization, color jitter, or gray scale could be a bad idea as it might invalidate the labels (making one species actually look like another). Transformations that do not preserve the aspect ratio (squashing, warping) could be bad too as they might change the shape of discriminant features.\nVertical flips or 90¬∞ rotations would not be very useful as they wouldn‚Äôt produce realistic data ‚Ä¶\nThere are a lot of more advanced techniques out there (CutMix, SnapMix, TransMix, Attention Drop), but let‚Äôs start with easier ones. For geometric techniques, let‚Äôs do random crops and random horizontal flips.\nWe can also do some photometric augmentation as long as they don‚Äôt invalidate the labels: brightness and contrast. If we want the model to be able to identify black and white pictures, we definitely need to remove the colour dependence by using a technique turning images to gray (with some probability and level of colour removal). If, on the other hand, we are only interested in having a model able to identify colour images, we want to stay away from this.\nLet‚Äôs consider for instance random gamma adjustments and random contrast. They simulate different exposure levels and will improve the model‚Äôs robustness and performance by making it less sensitive to variations in lighting conditions.\n\n\nChoosing the parameters\nPicking the right bounds for each type of data augmentation involves balancing dataset diversity against image realism. If the range is too narrow, you don‚Äôt get much benefit, if it‚Äôs too wide, you might destroy critical features or create unrealistic images that confuse the model.\n\nDefault range\nCheck the industry-standards (look at the literature, ask an LLM, etc.).\nFor random crops, we don‚Äôt want to go too hard or we will crop out the distinguishing features of the birds.\nFor gamma, for most computer vision tasks (natural images, object detection, classification), the industry-standard starting point is 0.8 to 1.2.\nThis range simulates subtle lighting variations‚Äîlike a cloud passing over the sun or a slight difference in camera exposure‚Äîwithout washing out the image or making it too dark to see details. This should be good for us.\n\n\nDomain specific ranges\nYou might want to adjust the values based on your specific data type.\nFor instance, you can increase the gamma range for OCR (document analysis) because scanned documents often have wildly varying contrast and because text usually remains legible even under extreme gamma.\nNone of this applies to our example.\n\n\nVisual sanity check\nNever set augmentation parameters blindly. Visualize some tests to ensure the data you are using to train is still reasonable (and to make sure that you aren‚Äôt messing something up and getting totally absurd results!).\nLet‚Äôs test various gamma values on the first 4 images in the training set:\n\nimport dm_pix as pix\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport jax.numpy as jnp\n\nLet‚Äôs write a helper function that applies PIX deterministic adjust_gamma function to a JAX array image, then covert it to an RGB image that we can display:\n\ndef apply_gamma(img, gamma):\n    \"\"\"\n    Apply gamma transformation to a JAX array image\n    then turn it back into an RGB image for display.\n    \"\"\"\n    new_img = pix.adjust_gamma(\n        image=img,\n        gamma=gamma\n    )\n    rgb_img = (new_img * 255.0).astype(np.uint8)\n    gamma = round(gamma, 1)\n    return rgb_img, gamma\n\nThis next function will take a NumPy image from our Dataset class, turn it to a JAX array, apply our helper function apply_gamma, and display the result:\n\ndef show_tests(img, gamma_range):\n    \"\"\"\n    Turn the image into a JAX array,\n    run our apply_gamma function on it\n    (apply gamma then turn back to RGB image),\n    plot the RGB image.\n    \"\"\"\n    jnp_img = jnp.array(img, dtype=jnp.float32) / 255.\n    pics = []\n    gammas = []\n\n    for i in gamma_range:\n        pics.append(apply_gamma(jnp_img, i)[0])\n        gammas.append(apply_gamma(jnp_img, i)[1])\n\n    fig, axes = plt.subplots(3, 4, figsize=(8, 6))\n    axes = axes.flatten()\n\n    for i, ax in enumerate(axes):\n        ax.imshow(pics[i])\n        ax.axis('off')\n        ax.set_title(f'Gamma = {gammas[i]}', fontsize=9)\n    plt.tight_layout()\n    plt.show()\n\nNow we can apply it to a few images to get an idea of the effect and ensure nothing weird is going on. This will help us catch a coding mistake that could ruin the whole training process:\n\nshow_tests(nabirds_train[0]['img'], np.linspace(0.1, 3, 12))\n\n\n\n\n\n\n\n\n0.6 to 1.2 seem ok.\n\nshow_tests(nabirds_train[1]['img'], np.linspace(0.1, 3, 12))\n\n\n\n\n\n\n\n\n0.6 to 2.2 seem reasonable for this image.\n\nshow_tests(nabirds_train[2]['img'], np.linspace(0.1, 3, 12))\n\n\n\n\n\n\n\n\n0.6 to 2.2 seem ok for this one.\n\nshow_tests(nabirds_train[3]['img'], np.linspace(0.1, 3, 12))\n\n\n\n\n\n\n\n\n0.6 to 1.4 seem reasonable here.\nFor training, we will use random gamma as one of our transformation (we don‚Äôt want the deterministic function here since we want different transformations randomly applied at each epoch) with the min and max values set a bit more broadly than what is standard as our images seem to handle it OK. Let‚Äôs go with a min and max of 0.6 and 1.2 respectively.\nYou need to do similar checks for all augmentations that might lead to unpredictable results: you don‚Äôt want to try to train a model on images that are all black, crippled by artifacts, or smeared beyond recognition!\n\n\nValidation check\nYou can adjust the probabilities and magnitudes of the various augmentation techniques you chose based on the validation performance you get during training.\nYou can train a small version of your model (or for fewer epochs) and check how the validation loss improves with various variations of your augmentation strategy.\nI recently gave a webinar on MLflow which would be the perfect tool for this kind of comparison.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data augmentation"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_augmentation.html#our-plan-for-the-train-set",
    "href": "ai/jxai/jxai_augmentation.html#our-plan-for-the-train-set",
    "title": "Data augmentation",
    "section": "Our plan for the train set",
    "text": "Our plan for the train set\n\nImage normalization\nBefore anything else, we need to normalize our images.\nOur images are currently stored as NumPy arrays of type integers ranging from 0 to 255 (the values of the pixels):\n\nprint(nabirds_train[0]['img'].dtype)\n\nuint8\n\n\nIt is a classic normalization technique to divide these pixel values by 255 to bring them in the 0-1 range. This improves performance and stability in training.\nTo ensure that all features contribute equally and improve performance, it is also a standard practice to turn the pictures into standard scores (z-scores) by subtracting each data point by the mean and dividing by the standard deviation.\nIn our case, we have to do it because the ViT model that we will eventually use was pretrained on images preprocessed this way and it is important to use the same normalization as was used for the pretrained model.\nLet‚Äôs create a first transformation that does exactly that:\n\nimport numpy as np\n\nclass Normalize(grain.MapTransform):\n    def map(self, element):\n        img = element['img']\n        # Image preprocessing matches the one of pretrained ViT\n        mean = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n        std = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n        img = img.astype(np.float32) / 255.0\n        img_norm = (img - mean) / std\n        element['img'] = img_norm\n        return element\n\n\n\n\n\n\n\nTipEquivalent using PyTorch\n\n\n\n\n\nTorchVision comes with many transformations, but custom Transforms can also be written in PyTorch. Here is an example for a simple normalization and casting of images:\nclass NormAndCastPyTorch(object):\n    \"\"\"Transform class to normalize and cast images to float32.\"\"\"\n    def __call__(self, element):\n        element['img'] = np.asarray(element['img'], dtype=np.float32) / 255.0\n        return element\nTo combine multiple Transforms, you use torchvision.transforms.Compose, one of the TorchVision Transforms (or you can use the newer transforms v2).\nIn PyTorch, you would apply the Transforms as you instantiate your Dataset class since the Dataset class has a transform argument in which to pass them:\nnabirds_norm_train_pytorch = NABirdsDataset(\n    metadata_train,\n    os.path.join(base_dir, img_dir),\n    transform=NormAndCastPyTorch()\n)\nWith Grain, you pass the combined Transforms as an argument of the DataLoader class, as we saw in the previous section.\n\n\n\n\n\nOur augmentation strategy\n\n\n\n\n\n\nNotePseudorandom numbers in JAX\n\n\n\n\n\nBecause we apply random transformations to our data, we need to talk about pseudorandom numbers in JAX.\nJAX has a mechanism to handle pseudorandom number generation (PRNG) that solves the problems that the PRNG mechanisms used by NumPy, Julia, R, and many other languages suffer from: parallelization and vectorization.\nIt is not based on an implicit global random state; instead, it tracks the state explicitly via a random key (an array with a special dtype). Random functions do not modify the key. This means that you can‚Äôt reuse a key (to avoid spurious correlations). But the key is splittable into as many new keys as you want. This is what allows the parallelization and vectorization of stochasticity.\nYou start by generating a key with:\nfrom jax import random\n\nkey = random.key(123)  # 123 can be replaced by any other number\n                       # reuse the same number for replicability\nYou then split the key with:\nkey, subkey = random.split(key)\nThis uses the initial key (the argument of the split method), so you can‚Äôt reuse it. But it creates two new keys (the two on the left of the equal sign). You can name these new keys however you want, but to ensure that we don‚Äôt reuse the initial key by accident, we re-assign its name to one of the new key.\nNow, you can use subkey in the next random function. And if later on you need another one, you split key (the new one) again in the same way.\nYou can also create multiple new keys at once:\nkey, subkey1, subkey2, subkey3 = random.split(key, num=4)\n\n\n\nRandom crop:\n\nfrom jax import random\nimport dm_pix as pix\n\nkey = random.key(31)\nkey, subkey = random.split(key)\n\nclass RandomCrop(grain.MapTransform):\n    def map(self, element):\n        element['img'] = pix.random_crop(\n            key=subkey,\n            image=element['img'],\n            crop_sizes=(224, 224, 3)\n        )\n        return element\n\nRandom flip:\n\nkey, subkey = random.split(key)\n\nclass RandomFlip(grain.MapTransform):\n    def map(self, element):\n        element['img'] = pix.random_flip_left_right(\n            key=subkey,\n            image=element['img']\n        )\n        return element\n\nRandom contrast:\n\nkey, subkey = random.split(key)\n\nclass RandomContrast(grain.MapTransform):\n    def map(self, element):\n        element['img'] = pix.random_contrast(\n            key=subkey,\n            image=element['img'],\n            lower=0.8,\n            upper=1.2\n        )\n        return element\n\nRandom gamma (using the bounds we tested earlier):\n\nkey, subkey = random.split(key)\n\nclass RandomGamma(grain.MapTransform):\n    def map(self, element):\n        element['img'] = pix.random_gamma(\n            key=subkey,\n            image=element['img'],\n            min_gamma=0.6,\n            max_gamma=1.2\n        )\n        return element\n\n\n\nPass to DataLoader\nWe can now pass the transformations to the DataLoader. We can combine Transforms together very easily with Grain (no need of a Compose class with Grain as with TorchVision):\n\nseed = 123\ntrain_batch_size = 32\n\n# Train set sampler:\ntrain_sampler = grain.IndexSampler(\n    num_records=len(nabirds_train),\n    shuffle=True,                      # We shuffle the training set\n    seed=seed,\n    shard_options=grain.NoSharding(),  # No sharding for a single-device setup\n    num_epochs=None                    # The default (infinite stream of data)\n)\n\n# Train set DataLoader:\ntrain_loader = grain.DataLoader(\n    data_source=nabirds_train,\n    sampler=train_sampler,\n    operations=[\n        Normalize(),\n        RandomCrop(),\n        RandomFlip(),\n        RandomContrast(),\n        RandomGamma(),\n        grain.Batch(train_batch_size, drop_remainder=True)\n    ]\n)\n\n\n\nThe importance of checks\nWe have our DataLoader for the training set and we could start training, potentially spending hours or days trying to train a model ‚Ä¶ with terrible results.\nBefore starting to train, it is crutial to check that your samples look the way you expect them to.\nLet‚Äôs get some info on a batch:\n\ntrain_batch = next(iter(train_loader))\n\nprint(f\"\"\"\ntraining batch info:\n- img shape is {train_batch['img'].shape} and data type is {train_batch['img'].dtype}\n- species_name shape is {train_batch['species_name'].shape} and data type is {train_batch['species_name'].dtype}\n- species_id shape is {train_batch['species_id'].shape} and data type is {train_batch['species_id'].dtype}\n- photographer shape is {train_batch['photographer'].shape} and data type is {train_batch['photographer'].dtype}\n\"\"\")\n\n\ntraining batch info:\n- img shape is (32, 224, 224, 3) and data type is float32\n- species_name shape is (32,) and data type is &lt;U26\n- species_id shape is (32,) and data type is int64\n- photographer shape is (32,) and data type is &lt;U34\n\n\n\nAll looks as expected.\nAnd let‚Äôs plot a few processed training images:\n\nfig = plt.figure(figsize=(8, 8))\n\nfor i in range(12):\n    ax = plt.subplot(3, 4, i + 1)\n    plt.tight_layout()\n    ax.set_title(\n        f\"\"\"\n        {train_batch['species_name'][i]}\n        Picture by {train_batch['photographer'][i]}\n        \"\"\",\n        fontsize=7,\n        linespacing=1.5\n    )\n    ax.axis('off')\n    rgb_img = (\n        (train_batch['img'][i] - train_batch['img'][i].min()) / (train_batch['img'][i].max() - train_batch['img'][i].min()) * 255.0\n    ).astype(np.uint8)\n\n    plt.imshow(rgb_img)\n\nplt.show()\n\n\n\n\n\n\n\n\nOh no!!!! What happened?\nWe checked carefully that our gamma adjustment bounds are reasonable and we chose very moderate brightness adjustment, so what happened?\nZ-score normalization creates negative values (roughly half the pixels will be negative). But dm-pix expects [0, 1] inputs, so by default, it clips all negative values to 0. This immediately turns half your image black.\nWhy does dm-pix do this clipping? Without this, the gamma math would fail: gamma correction uses exponentiation (pixel to the power of gamma) and you cannot raise negative numbers to a floating-point power.\nAs a result, all the pixels that were darker than average (negative z-scores) were forced to pure black (value of 0).\nWhat is the solution?\nWe could change the order of the transformations and move our Normalize class after the PIX augmentations. But this would also fail because PIX expects [0, 1] values and we have [0, 255] values.\nSo we have no choice but to break our normalization into 2 steps. Here is the order of transformations that we need to use:\n\nConvert the integers 0‚Äì255 images to floats 0‚Äì1 images.\nApply random gamma, brightness, etc. from the PIX library.\nApply the specific mean/std normalization expected by the model.\n\nNote that different augmentation libraries might have different behaviours, so you need to check carefully what inputs the augmentation library you use expects.\nSo let‚Äôs fix our problem.\nFirst, split our Normalize class into two steps.\nA first step to turn the RGB integers to 0‚Äì1 floats:\n\nclass ToFloat(grain.MapTransform):\n    def map(self, element):\n        element['img'] = element['img'].astype(np.float32) / 255.0\n        return element\n\nAnd a second step to create the z-scores:\n\nclass ZScore(grain.MapTransform):\n    def map(self, element):\n        img = element['img']\n        mean = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n        std = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n        img = (img - mean) / std\n        element['img'] = img\n        return element\n\nFinally, we apply the transformations in the proper order:\n\ntrain_loader = grain.DataLoader(\n    data_source=nabirds_train,\n    sampler=train_sampler,\n    operations=[\n        ToFloat(),\n        RandomCrop(),\n        RandomFlip(),\n        RandomContrast(),\n        RandomGamma(),\n        ZScore(),\n        grain.Batch(train_batch_size, drop_remainder=True)\n    ]\n)\n\nWe recreate a batch:\n\ntrain_batch = next(iter(train_loader))\n\nLet‚Äôs plot a sample again:\n\nfig = plt.figure(figsize=(8, 8))\n\nfor i in range(12):\n    ax = plt.subplot(3, 4, i + 1)\n    plt.tight_layout()\n    ax.set_title(\n        f\"\"\"\n        {train_batch['species_name'][i]}\n        Picture by {train_batch['photographer'][i]}\n        \"\"\",\n        fontsize=7,\n        linespacing=1.5\n    )\n    ax.axis('off')\n    rgb_img = (\n        (train_batch['img'][i] - train_batch['img'][i].min()) / (train_batch['img'][i].max() - train_batch['img'][i].min()) * 255.0\n    ).astype(np.uint8)\n\n    plt.imshow(rgb_img)\n\nplt.show()\n\n\n\n\n\n\n\n\nThis time, things look as expected. Phew!",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data augmentation"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_augmentation.html#what-about-the-validation-set",
    "href": "ai/jxai/jxai_augmentation.html#what-about-the-validation-set",
    "title": "Data augmentation",
    "section": "What about the validation set?",
    "text": "What about the validation set?\nYou don‚Äôt want to apply any augmentation to the evaluation set. However, these images must match the normalization of the training set. Here, it is ok to use our Normalize class that combines both normalizations.\n\nPass to DataLoader\nPass transformations to the DataLoader:\n\nval_batch_size = 2 * train_batch_size\n\n# Validation set sampler:\nval_sampler = grain.IndexSampler(\n    num_records=len(nabirds_val),\n    shuffle=False,                     # We don't shuffle the validation set\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1\n)\n\n# Validation set DataLoader:\nval_loader = grain.DataLoader(\n    data_source=nabirds_val,\n    sampler=val_sampler,\n    # worker_count=4,                 # If you have the resources (I don't)\n    # worker_buffer_size=2,\n    operations=[\n        Normalize(),\n        grain.Batch(val_batch_size)\n    ]\n)\n\n\n\nChecks\nHere again, we want to make sure all is fine by gathering some info on a batch:\n\nval_batch = next(iter(val_loader))\n\nprint(f\"\"\"\nValidation batch info:\n- img shape is {val_batch['img'].shape} and data type is {val_batch['img'].dtype}\n- species_name shape is {val_batch['species_name'].shape} and data type is {val_batch['species_name'].dtype}\n- species_id shape is {val_batch['species_id'].shape} and data type is {val_batch['species_id'].dtype}\n- photographer shape is {val_batch['photographer'].shape} and data type is {val_batch['photographer'].dtype}\n\"\"\")\n\n\nValidation batch info:\n- img shape is (64, 224, 224, 3) and data type is float32\n- species_name shape is (64,) and data type is &lt;U26\n- species_id shape is (64,) and data type is int64\n- photographer shape is (64,) and data type is &lt;U34\n\n\n\nAnd displaying some samples:\n\nfig = plt.figure(figsize=(8, 8))\n\nfor i in range(12):\n    ax = plt.subplot(3, 4, i + 1)\n    plt.tight_layout()\n    ax.set_title(\n        f\"\"\"\n        {val_batch['species_name'][i]}\n        Picture by {val_batch['photographer'][i]}\n        \"\"\",\n        fontsize=7,\n        linespacing=1.5\n    )\n    ax.axis('off')\n    rgb_img = (\n        (val_batch['img'][i] - val_batch['img'][i].min()) / (val_batch['img'][i].max() - val_batch['img'][i].min()) * 255.0\n    ).astype(np.uint8)\n\n    plt.imshow(rgb_img)\n\nplt.show()\n\n\n\n\n\n\n\n\nEverything looks good here. It is now time to talk about models.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Data augmentation"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_ex.html",
    "href": "ai/jxai/jxai_ex.html",
    "title": "Our deep learning example",
    "section": "",
    "text": "This course is structured around one concrete deep learning example which we introduce in this section.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Our deep learning example"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_ex.html#the-problem",
    "href": "ai/jxai/jxai_ex.html#the-problem",
    "title": "Our deep learning example",
    "section": "The problem",
    "text": "The problem\nWe want to train a model to perform a fine-grained vision classification task in which the distinguishing features between classes are subtle.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Our deep learning example"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_ex.html#the-data",
    "href": "ai/jxai/jxai_ex.html#the-data",
    "title": "Our deep learning example",
    "section": "The data",
    "text": "The data\nWe will use the NABirds dataset from the Cornell Lab of Ornithology [1].",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Our deep learning example"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_ex.html#our-strategy",
    "href": "ai/jxai/jxai_ex.html#our-strategy",
    "title": "Our deep learning example",
    "section": "Our strategy",
    "text": "Our strategy\nBefore embarking on a deep learning project, it is crucial to think about the overall strategy to follow for optimum performance.\nIn particular, it is important to consider what should run on CPUs vs GPUs and what is part of the preliminary work (sometimes called ‚Äúoffline‚Äù) and what constitutes the actual training (‚Äúonline‚Äù).\nHere is our plan (click on the image to enlarge):\n\nIt is a hybrid approach, split in 2 phases:\n\nPhase 1: preparation (CPU)\nWe will do the preliminary, deterministic cropping of images on CPUs because:\n\nDoing it as a transformation during the training loop (so a Transform on our DataLoader) would make no sense‚Äîthat work would be repeated at each epoch while we only need to do it once. We are much better off doing it once and writing the outputs to file.\nMoreover, this would force the computer to load and decode large files to then throw away a large portions of them each time it sees these files (thousands of times during training). Saving to file at this step reduces the I/O load significantly and will make our training epochs run a lot faster.\nWriting to file is actually a task done by CPUs, so sending the data to GPUs and back to save it to files is actually a very inefficient workflow.\n\nFor this first part, we don‚Äôt use JAX. Instead, we use classic NumPy arrays. Trying to use JAX, JIT-compilation, or GPUs for this initial step would actually be very inefficient.\n\n\nPhase 2: training (GPU)\nAfter that, we move to the GPUs for the training loop (which includes data augmentation transformations‚Äîthese are random and happening with some probability at each epoch, so they must be part of the loop. We aren‚Äôt saving any of the transformed images to file at that point.)\nFor that part, we use JAX and we JIT compile. This is where we use the heavy lifting of compilation, JAX, and GPUs.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Our deep learning example"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_install.html",
    "href": "ai/jxai/jxai_install.html",
    "title": "Installing packages",
    "section": "",
    "text": "For this course, we have already installed the required packages, but this section is important for you when you will want to install packages on your machine or on the Alliance clusters.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Installing packages"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_install.html#on-your-machine",
    "href": "ai/jxai/jxai_install.html#on-your-machine",
    "title": "Installing packages",
    "section": "On your machine",
    "text": "On your machine\n\n\n\n\n\n\nNoteSupported platforms for JAX\n\n\n\n\n\nBefore you install the stack, you need to check whether your machine is able to run JAX on GPU (all systems can run JAX on CPU).\n\n\n\n\n\n\n\n\n\n\n\n\nLinux x86_64\nLinux aarch64\nMac aarch64\nWindows x86_64\nWindows WSL2 x86_64\n\n\n\n\nCPU\nyes\nyes\nyes\nyes\nyes\n\n\nNVIDIA GPU\nyes\nyes\nn/a\nno\nexperimental\n\n\nGoogle TPU\nyes\nn/a\nn/a\nn/a\nn/a\n\n\nAMD GPU\nyes\nno\nn/a\nno\nexperimental\n\n\nApple GPU\nn/a\nno\nexperimental\nn/a\nn/a\n\n\nIntel GPU\nexperimental\nn/a\nn/a\nno\nno\n\n\n\nfrom the JAX documentation\n\n\n\nOn your machine (but not on the Alliance clusters), I recommend that you use uv to create a Python project with your chosen Python version and all the necessary packages. uv installs packages much faster than pip and it is able to resolve dependencies very well. It also manages Python versions.\n\nIf you want more information on this, I gave a webinar on uv in May 2025.\n\nCreate a Python project (let‚Äôs call it jaxai) and cd into it:\nuv init --bare jaxai\ncd jaxai\n\n--bare creates a uv project without files that I am not interested in here such as a README and a main.py.\n\nInstall the packages:\nuv add dm-pix imageio jax-ai-stack \"jax[cuda13]\" matplotlib orbax polars scikit-image tqdm \"transformers==4.57.3\"\n\nQuick explanation of packages we are installing:\n- dm-pix                ‚ûî for data augmentation\n- imageio               ‚ûî to load images into NumPy arrays\n- jax-ai-stack          ‚ûî installs JAX for the CPU (if not already installed for the GPU),\n                                   Flax‚Äîthe main NN library,\n                                   Optax‚Äîoptimizers & loss functions,\n                                   Orbax‚Äîfor checkpointing,\n                                   Grain‚Äîto build efficient dataloaders,\n                                   ml_dtypes‚ÄîNumPy dtype extensions for deep learning\n- jax[cuda13]           ‚ûî only if you want to run JAX on GPUs (use an appropriate version of Cuda)\n- matplotlib            ‚ûî to display samples\n- orbax                 ‚ûî checkpointing and saving model\n- polars                ‚ûî for DataFrames\n- scikit-image          ‚ûî image resizing\n- tqdm                  ‚ûî display progress bars\n- transformers          ‚ûî load model and pre-trained weights from Hugging Face model Hub\n                          We pin the version because v5 will not support JAX anymore\nIf you install packages which depend on JAX (e.g.¬†Flax), they will by default install the CPU version of JAX. If you want to run JAX on GPUs, make sure to install jax[cuda13] (or whatever Cuda version is suitable).\n\nYou will see that the dependencies have automatically populated a pyproject.toml file and that a virtual environment called .venv was created.\nAs long as you are within the project, you don‚Äôt need to activate that virtual environment. You can just launch Python (or IPython, ptpython, Jupyter‚Ä¶) and the packages will be available.\nAlternatively, if your required a tighter pip equivalent, you can activate it as you would any other Python virtual environment:\nsource .venv/bin/activate",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Installing packages"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_install.html#on-an-alliance-cluster",
    "href": "ai/jxai/jxai_install.html#on-an-alliance-cluster",
    "title": "Installing packages",
    "section": "On an Alliance cluster",
    "text": "On an Alliance cluster\n\nI already installed all the necessary packages in the training cluster to save time and space. The instructions for today thus differ from what you would normally do and production cluster instructions in the second tab are for your future reference only.\n\n\nTodayProduction cluster\n\n\nLook for available Python modules:\nmodule spider python\nLoad version 3.11.5:\nmodule load python/3.11.5\nI created a virtual Python environment with all necessary packages under /project. All you have to do today is activate it with:\nsource /project/def-sponsor00/nabirds_venv/bin/activate\n\n\nLook for available Python modules:\nmodule spider python\nLoad the version of your choice:\nmodule load python/3.13.2\nCreate a Python virtual environment:\npython -m venv ~/env\nActivate it:\nsource ~/env/bin/activate\nUpdate pip from wheel:\npython -m pip install --upgrade --no-index pip\n\nWhenever a Python wheel for a package is available on the Alliance clusters, you should use it instead of downloading the package from PyPI. To do this, simply add the --no-index flag to the install command.\nYou can see whether a wheel is available with avail_wheels &lt;package&gt; or look at the list of available wheels.\nAdvantages of wheels:\n\ncompiled for the clusters hardware,\nensures no missing or conflicting dependencies,\nmuch faster installation.\n\n\nInstall libraries from wheel:\npython -m pip install --no-index dm-pix imageio jax-ai-stack \"jax[cuda]\" matplotlib orbax polars scikit-image tqdm \"transformers==4.57.1\"\n\n\nDon‚Äôt forget --no-index to install from wheels.\nOn the cluster, we pin the transformers version to 4.57.1 because this is the highest v4 present.\n\n\n\nWe don‚Äôt have cuda13 on the Alliance clusters yet. If you follow JAX official installation instructions and try to install jax[cuda13], pip will default to installing jax (CPU only).\nMake sure to use jax[cuda] (or the equivalent jax[cuda12]) instead to have the GPU version installed.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Installing packages"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_jaxstack_content.html",
    "href": "ai/jxai/jxai_jaxstack_content.html",
    "title": "The JAX AI stack",
    "section": "",
    "text": "Content from the course slides for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "The JAX stack",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_jaxstack_content.html#what-is-jax",
    "href": "ai/jxai/jxai_jaxstack_content.html#what-is-jax",
    "title": "The JAX AI stack",
    "section": "What is JAX?",
    "text": "What is JAX?\nJAX is a high-performance accelerator-oriented array computing library for Python developed by Google. It allows composition, JIT-compilation, transformation, and automatic differentiation of numerical programs.\nIt provides NumPy-like and lower-level APIs.\nIt also requires strict functional programming.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "The JAX stack",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_jaxstack_content.html#why-jax",
    "href": "ai/jxai/jxai_jaxstack_content.html#why-jax",
    "title": "The JAX AI stack",
    "section": "Why JAX?",
    "text": "Why JAX?\n\nFast\n\nDefault data type suited for deep learning\nLike PyTorch, uses float32 as default. This level of precision is suitable for deep learning and increases efficiency (by contrast, NumPy defaults to float64).\nJIT compilation\nThe same code can run on CPUs or on accelerators (GPUs and TPUs)\nXLA (Accelerated Linear Algebra) optimization\nAsynchronous dispatch\nVectorization, data parallelism, and sharding\nAll levels of shared and distributed memory parallelism are supported.\n\n\n\nGreat AD\n\n\n\n\n\n\n\n\n\n01\n\n\nAutodiff method\n\n\n\n1\nStatic graph\nand XLA\n\n\n\n\n02\n\n\nFramework\n\n\n\n\n2\nDynamic graph\n\n\n\n1-&gt;2\n\n\n\n\n\na\n\nTensorFlow\n\n\n\n\n4\nDynamic graph\nand XLA\n\n\n\n2-&gt;4\n\n\n\n\n\nb\n\nPyTorch\n\n\n\n\n5\nPseudo-dynamic\nand XLA\n\n\n\n4-&gt;5\n\n\n\n\n\nd\n\nTensorFlow2\n\n\n\n\ne\n\nJAX\n\n\n\n\n\n03\n\n\nAdvantage\n\n\n\n\n\n7\nMostly\noptimized AD\n\n\n\n\n\n8\nConvenient\n\n\n\n\n\n9\nConvenient\n\n\n\n\n10\nConvenient and\nmostly optimized AD\n\n\n\n\n\n04\n\n\nDisadvantage\n\n\n\n\n\nA\nManual writing of IR\n\n\n\n\n\nB\nLimited AD optimization\n\n\n\n\n\nD\nDisappointing speed\n\n\n\n\nE\nPure functions only\n(subset of Python)\n\n\n\n\n\n\n\n\n\n\n\n\n\nsummarized from a blog post by Chris Rackauckas\n\n\nClose to the math\nConsidering the function f:\nf = lambda x: x**3 + 2*x**2 - 3*x + 8\nWe can create a new function dfdx that computes the gradient of f w.r.t. x:\nfrom jax import grad\n\ndfdx = grad(f)\ndfdx returns the derivatives:\nprint(dfdx(1.))\n4.0\n\n\nForward and reverse modes\n\nreverse-mode vector-Jacobian products: jax.vjp\nforward-mode Jacobian-vector products: jax.jvp\n\n\n\nHigher-order differentiation\nWith a single variable, the grad function calls can be nested:\nd2fdx = grad(dfdx)   # function to compute 2nd order derivatives\nd3fdx = grad(d2fdx)  # function to compute 3rd order derivatives\n...\nWith several variables, you have to use the functions:\n\njax.jacfwd for forward-mode,\njax.jacrev for reverse-mode.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "The JAX stack",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_jaxstack_content.html#how-does-it-work",
    "href": "ai/jxai/jxai_jaxstack_content.html#how-does-it-work",
    "title": "The JAX AI stack",
    "section": "How does it work?",
    "text": "How does it work?\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\nTransformation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\n Transformations \n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\n Just-in-time \n(JIT)\ncompilation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\nVectorization\nParallelization\n ¬†¬†Differentiation ¬†\n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\njax.jit\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\njax.vmap\njax.pmap\njax.grad\n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "The JAX stack",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_jaxstack_content.html#jax-for-ai",
    "href": "ai/jxai/jxai_jaxstack_content.html#jax-for-ai",
    "title": "The JAX AI stack",
    "section": "JAX for AI",
    "text": "JAX for AI\n\nNot itself a DL library\n\n\n\n\n\n\n\n\n\njx\n\nJAX\n\n\n\ndl\nDeep learning\n\n\n\njx-&gt;dl\n\n\n\n\n\nop\nOptimizers\n\n\n\njx-&gt;op\n\n\n\n\n\npp\nProbabilistic\nprogramming\n\n\n\njx-&gt;pp\n\n\n\n\n\npm\nProbabilistic\nmodeling\n\n\n\njx-&gt;pm\n\n\n\n\n\nll\nLLMs\n\n\n\nll-&gt;jx\n\n\n\n\n\nso\nSolvers\n\n\n\nso-&gt;jx\n\n\n\n\n\nph\nPhysics\nsimulations\n\n\n\nph-&gt;jx\n\n\n\n\n\n\n\n\n\n\n\n\nA sublanguage ideal for DL\n\n\n\n\n\n\n\n\n\njx\n\nJAX\n\n\n\ndl\nDeep learning\n\n\n\njx-&gt;dl\n\n\n\n\n\nop\nOptimizers\n\n\n\njx-&gt;op\n\n\n\n\n\npp\nProbabilistic\nprogramming\n\n\n\njx-&gt;pp\n\n\n\n\n\npm\nProbabilistic\nmodeling\n\n\n\njx-&gt;pm\n\n\n\n\n\nll\nLLMs\n\n\n\nll-&gt;jx\n\n\n\n\n\nso\nSolvers\n\n\n\nso-&gt;jx\n\n\n\n\n\nph\nPhysics\nsimulations\n\n\n\nph-&gt;jx",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "The JAX stack",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_jaxstack_content.html#the-jax-ai-stack",
    "href": "ai/jxai/jxai_jaxstack_content.html#the-jax-ai-stack",
    "title": "The JAX AI stack",
    "section": "The JAX AI stack",
    "text": "The JAX AI stack\nA modular approach:\n\n\n\nfrom the JAX AI Stack website",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "The JAX stack",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_jh.html",
    "href": "ai/jxai/jxai_jh.html",
    "title": "Temporary JupyterHub",
    "section": "",
    "text": "While using JupyterLab is not an efficient method (and certainly not something you want to use while training your model at scale), this is what we will use for the first part of this course so that we can visualize images easily.\nThis section explains how to log in to our temporary JupyterHub.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Temporary JupyterHub"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_jh.html#jupyter-on-clusters",
    "href": "ai/jxai/jxai_jh.html#jupyter-on-clusters",
    "title": "Temporary JupyterHub",
    "section": "Jupyter on clusters",
    "text": "Jupyter on clusters\nTo use JupyterLab on a cluster, you use what is called a JupyterHub: a set of tools that spawn and manage multiple instances of JupyterLab servers. Under the hood, they manage an interactive job used by your JupyterLab server.\nLet‚Äôs try it on our training cluster.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Temporary JupyterHub"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_jh.html#launch-jupyterlab",
    "href": "ai/jxai/jxai_jh.html#launch-jupyterlab",
    "title": "Temporary JupyterHub",
    "section": "Launch JupyterLab",
    "text": "Launch JupyterLab\n\nClaim a username\nGo to the etherpad that we will share during the course and claim a username by adding your first name or a pseudo next to a free username on the list.\nYour username is the name that was already on the list, NOT what you wrote next to it (which doesn‚Äôt matter at all and only serves at signalling that this username is now taken).\nYour username will look like userxx or userxxx ‚Äîxx and xxx being 2 or 3 digits respectively‚Äîwith no space and no capital letter.\n\n\nLog in\n\ngo to the URL we will give you during the course,\nsign in with your new username and a password that we will give you during the course,\nleave OTP blank,\nlog in.\n\n\n\nLaunch a job\nThis will take you to server options page:\n\n\nChange the time to a suitable value,\npress start.\n\n\nNote that, unlike other JupyterHubs you might have used (e.g.¬†Syzygy), this JupyterHub is not permanent and will be destroyed at the end of the course.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Temporary JupyterHub"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_jh.html#end-a-session",
    "href": "ai/jxai/jxai_jh.html#end-a-session",
    "title": "Temporary JupyterHub",
    "section": "End a session",
    "text": "End a session\nIf you don‚Äôt need all the time you asked for after all, it is a great thing to log out (the resources you are using on this cluster are shared amongst many people and when resources are allocated to you, they aren‚Äôt available to other people. So it is a good thing not to ask for unnecessary resources and have them sit idle when others could be using them).\nTo log out, click on File in the top menu and select Log out at the very bottom.\nIf you would like to make a change to the information you entered on the server option page after you have pressed start, log out, log back in, edit the server options, and press start again.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Temporary JupyterHub"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_jh.html#start-a-python-notebook",
    "href": "ai/jxai/jxai_jh.html#start-a-python-notebook",
    "title": "Temporary JupyterHub",
    "section": "Start a Python notebook",
    "text": "Start a Python notebook\nTo start a Jupyter notebook with the Python kernel, click on the button Python 3 in the Notebook section (top row of buttons).",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Temporary JupyterHub"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_jh.html#the-jupyter-interface",
    "href": "ai/jxai/jxai_jh.html#the-jupyter-interface",
    "title": "Temporary JupyterHub",
    "section": "The Jupyter interface",
    "text": "The Jupyter interface\nIn a fashion Vi users will be familiar with, Jupyter notebooks come with two modes: edit mode in which you can type text as usual and command mode in which many keys are shortcuts to specific actions.\nHere are some useful key bindings to navigate a Jupyter notebook:\n\nEnter            enter edit mode\nEsc              enter command mode\n\n# in edit mode\nTab              code completion\n\n# in command mode\nup               navigate up\ndown             navigate up\nShift+up         select multiple cells up\nShift+down       select multiple cells down\na                insert a new blank cell above\nb                insert a new blank cell below\nc                copy the current or selected cells\nx                cut the current or selected cells\nv                paste the copied or cut cells\nm                turn the cell into a markdown cell\ny                turn the cell into a code cell\nShift+m          merge selected cells\n\n# in either mode\nCtl+Enter        run the current cell\nShift+Enter      run the current cell and move to a new cell below",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Temporary JupyterHub"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_model.html",
    "href": "ai/jxai/jxai_model.html",
    "title": "Model and training strategy",
    "section": "",
    "text": "In this section, we think about what deep learning technique, what model architecture, what weights, what specific packages to use for our classification task.\nThen we create our model.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Model and training strategy"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_model.html#our-strategy",
    "href": "ai/jxai/jxai_model.html#our-strategy",
    "title": "Model and training strategy",
    "section": "Our strategy",
    "text": "Our strategy\n\nTechnique\nTraining a model from scratch (starting with random weights) is a loss of time and computing resources. The overall technique that we need to apply is transfer learning‚Äîthat is, starting from weights pre-trained on a task similar to ours.\n\n\nArchitecture\nOptions that would make sense for our example include ResNet, EfficientNet, and ViT.\n\nResNet\nResNet, or residual network, is a type of architecture in which the layers are reformulated as learning residual functions with reference to the layer inputs. This allows for deeper (and thus more performant) networks [1]. This is the oldest of the options that make sense for us, but it is also the most robust.\n\n\n\nfrom [1]\n\n\nResNet-50 is available from Hugging Face and has become a classic CNN for image classification.\n\n\nEfficientNet\nEfficientNet is a family of newer computer vision CNNs from Google that uses a compound coefficient to uniformly scale depth, width, and resolution of networks and achieves better accuracy with fewer parameters than other CNNs [2]. This makes them easier to train on fewer resources and can lead to better results. Tuning them is however harder than the more robust ResNet family.\n\n\n\nfrom [2]\n\n\nThere are variations for different image sizes sizes, all available in Hugging Face. For instance:\n\nEfficientNet b0 for images of size 224x224\nEfficientNet b2 for images 260x260\nEfficientNet b3 for images 300x300\nEfficientNet b7 for images 600x600\n\n\n\nViT\nWhile the other options were CNN, ViT, or vision transformer, is a transformer architecture (initially created for NLP tasks) applied to computer vision tasks [3]. This is a more recent technique that attains excellent results while training substantially fewer computational resources.\n\n\n\nfrom [3]\n\n\nViT is available in Hugging Face.\nWhich one to choose depends on the available hardware, libraries in the framework you want to use, and other practical considerations. If time permits, this is a good case of experiment tracking with MLflow.\nWe will go with the ViT option.\nBut we have a problem.\nFlax is the neural network library in the JAX AI stack. It comes with an older, challenging API called Linen and a more recent, easier, more Pythonic API called NNX. We want to use the latter.\nThe problem is that Hugging Face Transformers has a Flax ViT model with a classification head (transformers.FlaxViTForImageClassification) which is exactly what we want, but it was built with the old Flax Linen API and there is no pretrained model built with NNX. So we need to build a ViT model from scratch with the NNX API and transfer the weights from the Linen ViT.\nAfter that, we can fine-tune with our dataset.\n\n\n\nPre-trained weights\nWe are doing fine-grained specialized image classification. An obvious place to start are weights pretrained on some general image classification dataset. The classic such dataset is ImageNet[4].\n\n\nStrategy summary\nHere is our plan:\n\n\n\n\n\n\n\nCategory\nOur choice\n\n\n\n\nOverall technique\nTransfer learning\n\n\nArchitecture\nViT with Flax NNX\n\n\nPre-trained weights\nTrained on ImageNet-21k\n\n\nViT for which we can get the pre-trained weights\ntransformers.FlaxViTForImageClassification",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Model and training strategy"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_model.html#implementation",
    "href": "ai/jxai/jxai_model.html#implementation",
    "title": "Model and training strategy",
    "section": "Implementation",
    "text": "Implementation\nThis part of the course draws from the ViT for image classification tutorial.\n\nDefine the model with Flax NNX\nFirst we define a ViT architecture from scratch using the Flax NNX API. The tutorial we draw from here itself uses the original JAX-based implementation of the ViT as described in [3].\n\nimport jax\nimport jax.numpy as jnp\nfrom flax import nnx\n\n\nclass TransformerEncoder(nnx.Module):\n    \"\"\"\n    A single transformer encoder block in the ViT model, inheriting from `flax.nnx.Module`.\n\n    Args:\n        hidden_size (int): Input/output embedding dimensionality.\n        mlp_dim (int): Dimension of the feed-forward/MLP block hidden layer.\n        num_heads (int): Number of attention heads.\n        dropout_rate (float): Dropout rate. Defaults to 0.0.\n        rngs (flax.nnx.Rngs): A set of named `flax.nnx.RngStream` objects that generate a stream of JAX pseudo-random number generator (PRNG) keys. Defaults to `flax.nnx.Rngs(0)`.\n    \"\"\"\n    def __init__(\n        self,\n        hidden_size: int,\n        mlp_dim: int,\n        num_heads: int,\n        dropout_rate: float = 0.0,\n        *,\n        rngs: nnx.Rngs = nnx.Rngs(0),\n    ) -&gt; None:\n        # First layer normalization using `flax.nnx.LayerNorm`\n        # before we apply Multi-Head Attentn.\n        self.norm1 = nnx.LayerNorm(hidden_size, rngs=rngs)\n        # The Multi-Head Attention layer (using `flax.nnx.MultiHeadAttention`).\n        self.attn = nnx.MultiHeadAttention(\n            num_heads=num_heads,\n            in_features=hidden_size,\n            dropout_rate=dropout_rate,\n            broadcast_dropout=False,\n            decode=False,\n            deterministic=False,\n            rngs=rngs,\n        )\n        # Second layer normalization using `flax.nnx.LayerNorm`.\n        self.norm2 = nnx.LayerNorm(hidden_size, rngs=rngs)\n\n        # The MLP for point-wise feedforward (using `flax.nnx.Sequential`, `flax.nnx.Linear, flax.nnx.Dropout`)\n        # with the GeLU activation function (`flax.nnx.gelu`).\n        self.mlp = nnx.Sequential(\n            nnx.Linear(hidden_size, mlp_dim, rngs=rngs),\n            nnx.gelu,\n            nnx.Dropout(dropout_rate, rngs=rngs),\n            nnx.Linear(mlp_dim, hidden_size, rngs=rngs),\n            nnx.Dropout(dropout_rate, rngs=rngs),\n        )\n\n    # The forward pass through the transformer encoder block.\n    def __call__(self, x: jax.Array) -&gt; jax.Array:\n        # The Multi-Head Attention layer with layer normalization.\n        x = x + self.attn(self.norm1(x))\n        # The feed-forward network with layer normalization.\n        x = x + self.mlp(self.norm2(x))\n        return x\n\n\nclass VisionTransformer(nnx.Module):\n    \"\"\" Implements the ViT model, inheriting from `flax.nnx.Module`.\n\n    Args:\n        num_classes (int): Number of classes in the classification. Defaults to 1000.\n        in_channels (int): Number of input channels in the image (such as 3 for RGB). Defaults to 3.\n        img_size (int): Input image size. Defaults to 224.\n        patch_size (int): Size of the patches extracted from the image. Defaults to 16.\n        num_layers (int): Number of transformer encoder layers. Defaults to 12.\n        num_heads (int): Number of attention heads in each transformer layer. Defaults to 12.\n        mlp_dim (int): Dimension of the hidden layers in the feed-forward/MLP block. Defaults to 3072.\n        hidden_size (int): Dimensionality of the embedding vectors. Defaults to 3072.\n        dropout_rate (int): Dropout rate (for regularization). Defaults to 0.1.\n        rngs (flax.nnx.Rngs): A set of named `flax.nnx.RngStream` objects that generate a stream of JAX pseudo-random number generator (PRNG) keys. Defaults to `flax.nnx.Rngs(0)`.\n\n    \"\"\"\n    def __init__(\n        self,\n        num_classes: int = 1000,\n        in_channels: int = 3,\n        img_size: int = 224,\n        patch_size: int = 16,\n        num_layers: int = 12,\n        num_heads: int = 12,\n        mlp_dim: int = 3072,\n        hidden_size: int = 768,\n        dropout_rate: float = 0.1,\n        *,\n        rngs: nnx.Rngs = nnx.Rngs(0),\n    ):\n        # Calculate the number of patches generated from the image.\n        n_patches = (img_size // patch_size) ** 2\n        # Patch embeddings:\n        # - Extracts patches from the input image and maps them to embedding vectors\n        #   using `flax.nnx.Conv` (convolutional layer).\n        self.patch_embeddings = nnx.Conv(\n            in_channels,\n            hidden_size,\n            kernel_size=(patch_size, patch_size),\n            strides=(patch_size, patch_size),\n            padding='VALID',\n            use_bias=True,\n            rngs=rngs,\n        )\n\n        # Positional embeddings (add information about image patch positions):\n        # Set the truncated normal initializer (using `jax.nn.initializers.truncated_normal`).\n        initializer = jax.nn.initializers.truncated_normal(stddev=0.02)\n        # The learnable parameter for positional embeddings (using `flax.nnx.Param`).\n        self.position_embeddings = nnx.Param(\n            initializer(rngs.params(), (1, n_patches + 1, hidden_size), jnp.float32)\n        ) # Shape `(1, n_patches +1, hidden_size`)\n        # The dropout layer.\n        self.dropout = nnx.Dropout(dropout_rate, rngs=rngs)\n\n        # CLS token (a special token prepended to the sequence of patch embeddings)\n        # using `flax.nnx.Param`.\n        self.cls_token = nnx.Param(jnp.zeros((1, 1, hidden_size)))\n\n        # Transformer encoder (a sequence of encoder blocks for feature extraction).\n        # - Create multiple Transformer encoder blocks (with `nnx.Sequential`\n        # and `TransformerEncoder(nnx.Module)` which is defined later).\n        self.encoder = nnx.Sequential(*[\n            TransformerEncoder(hidden_size, mlp_dim, num_heads, dropout_rate, rngs=rngs)\n            for i in range(num_layers)\n        ])\n        # Layer normalization with `flax.nnx.LayerNorm`.\n        self.final_norm = nnx.LayerNorm(hidden_size, rngs=rngs)\n\n        # Classification head (maps the transformer encoder to class probabilities).\n        self.classifier = nnx.Linear(hidden_size, num_classes, rngs=rngs)\n\n    # The forward pass in the ViT model.\n    def __call__(self, x: jax.Array) -&gt; jax.Array:\n        # Image patch embeddings.\n        # Extract image patches and embed them.\n        patches = self.patch_embeddings(x)\n        # Get the batch size of image patches.\n        batch_size = patches.shape[0]\n        # Reshape the image patches.\n        patches = patches.reshape(batch_size, -1, patches.shape[-1])\n\n        # Replicate the CLS token for each image with `jax.numpy.tile`\n        # by constructing an array by repeating `cls_token` along `[batch_size, 1, 1]` dimensions.\n        cls_token = jnp.tile(self.cls_token, [batch_size, 1, 1])\n        # Concatenate the CLS token and image patch embeddings.\n        x = jnp.concat([cls_token, patches], axis=1)\n        # Create embedded patches by adding positional embeddings to the concatenated CLS token and image patch embeddings.\n        embeddings = x + self.position_embeddings\n        # Apply the dropout layer to embedded patches.\n        embeddings = self.dropout(embeddings)\n\n        # Transformer encoder blocks.\n        # Process the embedded patches through the transformer encoder layers.\n        x = self.encoder(embeddings)\n        # Apply layer normalization\n        x = self.final_norm(x)\n\n        # Extract the CLS token (first token), which represents the overall image embedding.\n        x = x[:, 0]\n\n        # Predict class probabilities based on the CLS token embedding.\n        return self.classifier(x)\n\nQuick test to make sure the predictions have an expected shape:\n\nx = jnp.ones((4, 224, 224, 3))\nmodel = VisionTransformer(num_classes=1000)\ny = model(x)\nprint('Predictions shape: ', y.shape)\n\nPredictions shape:  (4, 1000)\n\n\n\n\nLoad pretrained weights\nThe Hugging Face Transformers package allows to load models and pretrained weights from the Hugging Face Models Hub‚Äîthe largest repository of open-weights models.\nWe use it to import the ViT model built with the old Flax Linen API:\n\nfrom transformers import FlaxViTForImageClassification\n\nThen we load weights pretrained on ImageNet-21k at the 224x224 resolution from the Hugging Face Models Hub:\n\ntf_model = FlaxViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n\nTensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n\n\n\nNote the warning about Transformers stopping support for TensorFlow and JAX starting at version 5. This is why we pinned the package at version 4 when we installed it.\n\nNow we copy the weights to our ViT model, reshaping layers to match the new architecture:\n\ndef vit_inplace_copy_weights(*, src_model, dst_model):\n    assert isinstance(src_model, FlaxViTForImageClassification)\n    assert isinstance(dst_model, VisionTransformer)\n\n    tf_model_params = src_model.params\n    tf_model_params_fstate = nnx.traversals.flatten_mapping(tf_model_params)\n\n    # Notice the use of `flax.nnx.state`.\n    flax_model_params = nnx.state(dst_model, nnx.Param)\n    flax_model_params_fstate = dict(flax_model_params.flat_state())\n\n    # Mapping from Flax parameter names to TF parameter names.\n    params_name_mapping = {\n        ('cls_token',): ('vit', 'embeddings', 'cls_token'),\n        ('position_embeddings',): ('vit', 'embeddings', 'position_embeddings'),\n        **{\n            ('patch_embeddings', x): ('vit', 'embeddings', 'patch_embeddings', 'projection', x)\n            for x in ['kernel', 'bias']\n        },\n        **{\n            ('encoder', 'layers', i, 'attn', y, x): (\n                'vit', 'encoder', 'layer', str(i), 'attention', 'attention', y, x\n            )\n            for x in ['kernel', 'bias']\n            for y in ['key', 'value', 'query']\n            for i in range(12)\n        },\n        **{\n            ('encoder', 'layers', i, 'attn', 'out', x): (\n                'vit', 'encoder', 'layer', str(i), 'attention', 'output', 'dense', x\n            )\n            for x in ['kernel', 'bias']\n            for i in range(12)\n        },\n        **{\n            ('encoder', 'layers', i, 'mlp', 'layers', y1, x): (\n                'vit', 'encoder', 'layer', str(i), y2, 'dense', x\n            )\n            for x in ['kernel', 'bias']\n            for y1, y2 in [(0, 'intermediate'), (3, 'output')]\n            for i in range(12)\n        },\n        **{\n            ('encoder', 'layers', i, y1, x): (\n                'vit', 'encoder', 'layer', str(i), y2, x\n            )\n            for x in ['scale', 'bias']\n            for y1, y2 in [('norm1', 'layernorm_before'), ('norm2', 'layernorm_after')]\n            for i in range(12)\n        },\n        **{\n            ('final_norm', x): ('vit', 'layernorm', x)\n            for x in ['scale', 'bias']\n        },\n        **{\n            ('classifier', x): ('classifier', x)\n            for x in ['kernel', 'bias']\n        }\n    }\n\n    nonvisited = set(flax_model_params_fstate.keys())\n\n    for key1, key2 in params_name_mapping.items():\n        assert key1 in flax_model_params_fstate, key1\n        assert key2 in tf_model_params_fstate, (key1, key2)\n\n        nonvisited.remove(key1)\n\n        src_value = tf_model_params_fstate[key2]\n        if key2[-1] == 'kernel' and key2[-2] in ('key', 'value', 'query'):\n            shape = src_value.shape\n            src_value = src_value.reshape((shape[0], 12, 64))\n\n        if key2[-1] == 'bias' and key2[-2] in ('key', 'value', 'query'):\n            src_value = src_value.reshape((12, 64))\n\n        if key2[-4:] == ('attention', 'output', 'dense', 'kernel'):\n            shape = src_value.shape\n            src_value = src_value.reshape((12, 64, shape[-1]))\n\n        dst_value = flax_model_params_fstate[key1]\n        assert src_value.shape == dst_value.value.shape, (key2, src_value.shape, key1, dst_value.value.shape)\n        dst_value.value = src_value.copy()\n        assert dst_value.value.mean() == src_value.mean(), (dst_value.value, src_value.mean())\n\n    assert len(nonvisited) == 0, nonvisited\n    # Notice the use of `flax.nnx.update` and `flax.nnx.State`.\n    nnx.update(dst_model, nnx.State.from_flat_path(flax_model_params_fstate))\n\n\nvit_inplace_copy_weights(src_model=tf_model, dst_model=model)\n\n\n\nVerify weights transfer\nTo make sure the weights pretrained on ImageNet got transferred successfully to our ViT model, we perform inference on a single image (that I added to my website to make it easily available at a URL) using both the original model from Transformers and our model so that we can compare the two:\n\nimport matplotlib.pyplot as plt\nfrom transformers import ViTImageProcessor\nfrom PIL import Image\nimport requests\n\nurl = \"https://mint.westdri.ca/ai/jxai/img/polarbears.jpg\"\nimage = Image.open(requests.get(url, stream=True).raw)\n\nprocessor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n\ninputs = processor(images=image, return_tensors=\"np\")\noutputs = tf_model(**inputs)\nlogits = outputs.logits\n\n\nmodel.eval()\nx = jnp.transpose(inputs[\"pixel_values\"], axes=(0, 2, 3, 1))\noutput = model(x)\n\n# Model predicts one of the 1000 ImageNet classes.\nref_class_idx = logits.argmax(-1).item()\npred_class_idx = output.argmax(-1).item()\nassert jnp.abs(logits[0, :] - output[0, :]).max() &lt; 0.1\n\nfig, axs = plt.subplots(1, 2, figsize=(7, 9))\n\nfor ax in axs:\n    ax.axis('off')\n\nplt.tight_layout()\n\naxs[0].set_title(\n    f\"\"\"\n    Reference model:\n    {tf_model.config.id2label[ref_class_idx]}\n    p={nnx.softmax(logits, axis=-1)[0, ref_class_idx]:.3f}\n    \"\"\",\n    fontsize=8\n)\naxs[0].imshow(image)\n\naxs[1].set_title(\n    f\"\"\"\n    Our model:\n    {tf_model.config.id2label[pred_class_idx]}\n    p={nnx.softmax(output, axis=-1)[0, pred_class_idx]:.3f}\n    \"\"\",\n    fontsize=8\n)\naxs[1].imshow(image)\n\n\n\n\n\n\n\n\n\nPicture by Paul Zizka\n\nOur model gives similar results; the weights transfer worked.\n\n\nAdjust classifier\nWe do not have 1000 classes (the default for our ViT model), but 405 (the bird species in our dataset). So we replace the classifier with a fully-connected layer returning 405 classes:\n\nmodel.classifier = nnx.Linear(model.classifier.in_features, 405, rngs=nnx.Rngs(0))\n\n# Make sure the predictions shape with our tiny example got adjusted\nprint('Predictions shape: ', y.shape)\n\nPredictions shape:  (4, 1000)\n\n\n\n\nDisplay model\n\nnnx.display(model)",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Model and training strategy"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_resources.html",
    "href": "ai/jxai/jxai_resources.html",
    "title": "Resources",
    "section": "",
    "text": "Here is a list of resources to get started with deep learning using JAX.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_resources.html#jax",
    "href": "ai/jxai/jxai_resources.html#jax",
    "title": "Resources",
    "section": "JAX",
    "text": "JAX\n\nOfficial sites\n\nJAX GitHub repo\nOfficial documentation\n\n\n\nOther resources\n\nAwesome JAX list of resources\nJAX AI Stack tutorials\nProjects using the JAX AI Stack\n\n\n\nQ&A\n\nJAX GitHub Discussions\nStack Overflow [jax] tag",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_resources.html#data-and-pre-trained-models",
    "href": "ai/jxai/jxai_resources.html#data-and-pre-trained-models",
    "title": "Resources",
    "section": "Data and pre-trained models",
    "text": "Data and pre-trained models\n\nData loaders\n\nHugging Face Datasets GitHub repo\nHugging Face Datasets documentation and tutorials\nGrain GitHub repo\nGrain official documentation\nTorchData GitHub repo\nTensorFlow Datasets GitHub repo\nTensorFlow Datasets official documentation\n\n\n\nData augmentation\n\nTorchVision official documentation\nPIX\nAlbumentationsX\n\n\n\nModels and pre-trained weights\n\nHugging Face Transformers GitHub repo\nHugging Face Transformers official documentation\nTorchVision official documentation",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_resources.html#flax",
    "href": "ai/jxai/jxai_resources.html#flax",
    "title": "Resources",
    "section": "Flax",
    "text": "Flax\n\nOfficial documentation\n\nFlax GitHub repo\nOfficial documentation\nFlax API\n\n\n\nOther resources\n\nProjects using Flax\n\n\n\nQ&A\n\nFlax GitHub Discussions\nStack Overflow [flax] tag\n\n\n\nAlliance\nThe Alliance wiki has a page on Flax.",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_resources.html#optax",
    "href": "ai/jxai/jxai_resources.html#optax",
    "title": "Resources",
    "section": "Optax",
    "text": "Optax\n\nOptax GitHub repo\nOfficial documentation\n\n\nQ&A\n\nOptax GitHub Discussions",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_resources.html#orbax",
    "href": "ai/jxai/jxai_resources.html#orbax",
    "title": "Resources",
    "section": "Orbax",
    "text": "Orbax\n\nOrbax GitHub repo\nOfficial documentation\n\n\nQ&A\n\nOrbax GitHub Discussions",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "ai/jxai/jxai_resources.html#alliance-clusters",
    "href": "ai/jxai/jxai_resources.html#alliance-clusters",
    "title": "Resources",
    "section": "Alliance clusters",
    "text": "Alliance clusters\n\nAlliance Wiki\nRunning jobs\nUsing GPUs with Slurm\nTechnical support",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian.html",
    "href": "ai/jxbayesian/wb_bayesian.html",
    "title": "Bayesian inference in JAX",
    "section": "",
    "text": "Bayesian statistics is more intuitive to the way we (humans) think about the world and easier to interpret than the traditional frequentist approach. Moreover, it allows for the incorporation of prior information and diverse data, it provides a measure of uncertainty, and it is extremely valuable in difficult situations with little data. The downside is that it is computationally complex and intensive. In addition, the best performing algorithms require burdensome calculations of derivatives. This explains its initial limitations.\nWith the advent of increasingly performant probabilistic programming languages (PPLs), algorithms, compilers, automatic differentiation engines, and computer hardware, Bayesian approaches are now fast growing in popularity in many fields.\nJAX is a library for Python that makes use of the extremely performant XLA compiler, runs on accelerators (GPUs/TPUs), provides automatic differentiation, just-in-time compilation, batching, and parallelization. In short, it is a perfect tool for Bayesian statistics. Not surprisingly, many PPLs now use it as a backend and Stan users (and developers!) are turning to it.\nIn this webinar, I will give a brief and very high-level introduction to Bayesian inference and JAX, then talk about the various PPLs and samplers which use JAX.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Bayesian inference in JAX"
    ]
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#two-interpretations-of-probabilities",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#two-interpretations-of-probabilities",
    "title": "Bayesian inference in",
    "section": "Two interpretations of probabilities",
    "text": "Two interpretations of probabilities\n\n\n\n\nFrequentist\n\n\n\n\nImage source\n\n\n\n\n\n\n\nBayesian\n\n\n\n\nImage source"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#frequentist",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#frequentist",
    "title": "Bayesian inference in",
    "section": "Frequentist",
    "text": "Frequentist\nFrequentist approach to probabilities: assigns probabilities to the long-run frequency of events\nIt doesn‚Äôt assign probabilities to non-random variables such as hypotheses or parameters\nInstead, the probability is assigned to the limit of the relative frequencies of events in infinite trials and we can assign a probability to the fact that a new random sample would produce a confidence interval that contains the unknown parameter\nThis is not how we intuitively think and the results are hard to interpret. This approach is also often artificially constrained and limits the integration of various forms of information\nIt is however computationally simple and fast: samples are randomly selected from the sample space and it returns test statistics such as p-values and confidence intervals. This is why it was the dominant approach for a long time: we knew how to do it"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#bayesian",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#bayesian",
    "title": "Bayesian inference in",
    "section": "Bayesian",
    "text": "Bayesian\nBayesian approach: assigns probabilities to our beliefs about an event\nBased on Bayes‚Äô theorem of conditional probabilities which allows to calculate the probability of a cause given its effect:\n\\[ P(A \\vert X) = \\frac{P(X \\vert A) P(A)}{P(X)} \\]\nwhere:\n\n\\(P(A)\\) is the prior probability of \\(A\\)‚Äîour belief about event \\(A\\)\n\\(P(X)\\) is the marginal probability of event \\(X\\) (some observed data)\n\\(P(X \\vert A)\\) is the likelihood or conditional probability of observing \\(X\\) given \\(A\\)\n\\(P(A \\vert X)\\) is the posterior probability‚Äîour updated belief about \\(A\\) given the data"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#which-approach-to-choose",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#which-approach-to-choose",
    "title": "Bayesian inference in",
    "section": "Which approach to choose?",
    "text": "Which approach to choose?\nBayesian statistics:\n\nis more intuitive to the way we think about the world (easier to interpret)\nallows for the incorporation of prior information and diverse data\nis more informative as it provides a measure of uncertainty (returns probabilities)\nis extremely valuable when there is little data (the inference is unstable and frequentist estimates have large variance and confidence intervals)\n\nBut beyond extremely simple examples, Bayesian inference is mathematically extremely arduous\nIt is also much more computationally heavy and only became possible to apply widely with the advent of powerful computers and new algorithms such as Markov chain Monte Carlo (MCMC)"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#algorithms",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#algorithms",
    "title": "Bayesian inference in",
    "section": "Algorithms",
    "text": "Algorithms\nA Bayesian approach to statistics often leads to posterior probability distributions that are too complex or too highly dimensional to be studied by analytical techniques\nMarkov chain Monte Carlo (MCMC) is a class of sampling algorithms which explore such distributions\nDifferent algorithms move in different ways across the N-dimensional space of the parameters, accepting or rejecting each new position based on its adherence to the prior distribution and the data\nThe sequence of accepted positions constitute the traces"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#probabilistic-programming-language",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#probabilistic-programming-language",
    "title": "Bayesian inference in",
    "section": "Probabilistic Programming Language",
    "text": "Probabilistic Programming Language\nProbabilistic programming language (PPL), explained simply in this (a bit outdated) blog post, are computer languages specialized in creating probabilistic models and making inference\nModel components are first-class primitives\nThey can be based on a general programming language (e.g.¬†Python, Julia) or domain specific"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#first-bayesian-ppls",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#first-bayesian-ppls",
    "title": "Bayesian inference in",
    "section": "First Bayesian PPLs",
    "text": "First Bayesian PPLs\nRelied on Gibbs sampling:\n\nWinBUGS replaced by OpenBUGS, written in Component Pascal\nJAGS, written in C++\n\nBUGS = Bayesian inference Using Gibbs Sampling\nJAGS = Just Another Gibbs Sampler"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#stan",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#stan",
    "title": "Bayesian inference in",
    "section": "Stan",
    "text": "Stan\nStan (see also website and paper) is a domain-specific language\nStan scripts can be executed from R, Python, or the shell via RStan, PyStan, etc.\nAlso used as the backend for the R package brms which doesn‚Äôt require learning Stan but only works for simple models\nRelies on No-U-Turn sampler (NUTS), a variant of Hamiltonian Monte Carlo (HMC) (see also HMC paper)\nHMC and variants require burdensome calculations of derivatives. Stan solved that by creating its own reverse-mode automatic differentiation engine\nSuperior to Gibbs sampler ‚ûî made Stan a very popular PPL for years"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#ppls-based-on-deep-learning-frameworks",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#ppls-based-on-deep-learning-frameworks",
    "title": "Bayesian inference in",
    "section": "PPLs based on deep learning frameworks",
    "text": "PPLs based on deep learning frameworks\nSince HMC and NUTS require autodiff, many Python PPLs have emerged in recent years, following the explosion of deep learning\nExamples:\n\nPyro based on PyTorch\nEdward, then Edward2 as well as TensorFlow Probability based on TensorFlow"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#enters-jax",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#enters-jax",
    "title": "Bayesian inference in",
    "section": "Enters JAX",
    "text": "Enters JAX\n\n\nHad JAX existed when we started coding Stan in 2011, we would‚Äôve used that rather than rolling our own autodiff system.\n\n\nBob Carpenter, one of Stan‚Äôs creators, in a recent blog post"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#what-is-jax",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#what-is-jax",
    "title": "Bayesian inference in",
    "section": "What is JAX?",
    "text": "What is JAX?\nJAX is a library for Python that:\n\nmakes use of the extremely performant XLA compiler\nruns on accelerators (GPUs/TPUs)\nprovides automatic differentiation\nuses just-in-time compilation\nallows batching and parallelization\n\n\n‚áí perfect tool for Bayesian statistics\n\n See our introductory JAX course and webinar for more details"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#jax-idiosyncrasies",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#jax-idiosyncrasies",
    "title": "Bayesian inference in",
    "section": "JAX idiosyncrasies",
    "text": "JAX idiosyncrasies\nJAX is sublanguage of Python requiring pure functions instead of Python‚Äôs object-oriented style\nIt has other quirks\nThe only one you really need to understand for use in PPLs is the pseudorandom number generation"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#prng-keys",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#prng-keys",
    "title": "Bayesian inference in",
    "section": "PRNG keys",
    "text": "PRNG keys\nTraditional pseudorandom number generators are based on nondeterministic state of the OS. This is slow and problematic for parallel executions\nJAX relies on an explicitly-set random state called a key:\nfrom jax import random\nkey = random.key(18)\nEach key can only be used for one random function, but it can be split into new keys:\nkey, subkey = random.split(key)\n\nThe first key can‚Äôt be used anymore. We overwrote it with a new key to ensure we don‚Äôt accidentally reuse it\n\nWe can now use subkey in random functions in our code (and keep key to generate new subkeys as needed)"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#jax-use-cases",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#jax-use-cases",
    "title": "Bayesian inference in",
    "section": "JAX use cases",
    "text": "JAX use cases"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#new-jax-backends-added-to-many-ppls",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#new-jax-backends-added-to-many-ppls",
    "title": "Bayesian inference in",
    "section": "New JAX backends added to many PPLs",
    "text": "New JAX backends added to many PPLs\nEdward2 and TensorFlow Probability can now use JAX as backend\nPyMC relies on building a static graph. It is based on PyTensor which provides JAX compilation (PyTensor is a fork of aesara, itself a fork of Theano)"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#numpyro",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#numpyro",
    "title": "Bayesian inference in",
    "section": "NumPyro",
    "text": "NumPyro\nNumPyro is a library based on Pyro but using NumPy and JAX"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#blackjax",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#blackjax",
    "title": "Bayesian inference in",
    "section": "Blackjax",
    "text": "Blackjax\nNot a PPL but a library of MCMC samplers built on JAX\nCan be used directly if you want to define your own log-probability density functions or can be used with several PPLs to define your model (make sure to translate it to a log-probability function)\nAlso provides building blocks for experimentation with new algorithms"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#blackjax-1",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#blackjax-1",
    "title": "Bayesian inference in",
    "section": "Blackjax",
    "text": "Blackjax"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#example-blackjax-sampler-hmc",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#example-blackjax-sampler-hmc",
    "title": "Bayesian inference in",
    "section": "Example Blackjax sampler: HMC",
    "text": "Example Blackjax sampler: HMC"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#example-blackjax-sampler-nuts",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#example-blackjax-sampler-nuts",
    "title": "Bayesian inference in",
    "section": "Example Blackjax sampler: NUTS",
    "text": "Example Blackjax sampler: NUTS"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#which-tool-to-choose",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#which-tool-to-choose",
    "title": "Bayesian inference in",
    "section": "Which tool to choose?",
    "text": "Which tool to choose?\nAll these tools are in active development (JAX was released and started shaking the field in 2018). Things are fast evolving. Reading blogs of main developers, posts on Hacker News, discourse forums, etc. helps to keep an eye on evolutions in the field\nThis recent conversation between Bob Carpenter (Stan core developer) and Ricardo Vieira (PyMC core developer) in the PyMC discourse forum is interesting\nA lot of it also comes down to user preferences"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#how-to-get-started-with-bayesian-computing",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#how-to-get-started-with-bayesian-computing",
    "title": "Bayesian inference in",
    "section": "How to get started with Bayesian computing?",
    "text": "How to get started with Bayesian computing?\nThe book Probabilistic Programming & Bayesian Methods for Hackers by Cameron Davidson-Pilon provides a code-based (using PyMC) and math-free introduction to Bayesian methods for the real beginner\nSeveral resources on the PyMC website including intro Bayesian with PyMC\nNumPyro tutorials\nMore advanced: tutorials from Blackjax Sampling Book Project"
  },
  {
    "objectID": "ai/jxbayesian/wb_bayesian_slides.html#how-to-transition-from-stan-to-a-jax-based-ppl",
    "href": "ai/jxbayesian/wb_bayesian_slides.html#how-to-transition-from-stan-to-a-jax-based-ppl",
    "title": "Bayesian inference in",
    "section": "How to transition from Stan to a JAX-based PPL?",
    "text": "How to transition from Stan to a JAX-based PPL?\nThe code to the classic Bayesian textbook Statistical Rethinking by Richard McElreath got translated by various people to modern JAX-based PPLs:"
  },
  {
    "objectID": "ai/mlops/wb_mlflow_content.html",
    "href": "ai/mlops/wb_mlflow_content.html",
    "title": "Experiment tracking with MLflow",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "ML experiment tracking",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/mlops/wb_mlflow_content.html#experiment-tracking",
    "href": "ai/mlops/wb_mlflow_content.html#experiment-tracking",
    "title": "Experiment tracking with MLflow",
    "section": "Experiment tracking",
    "text": "Experiment tracking\n\nLots of moving parts\nAI experiments come with a lot of components:\n\nDatasets\nModel architectures\nHyperparameters\n\nWhile developing an efficient model, various datasets will be trained on various architectures tuned with various hyperparameters.\n\n\nChallenging tracking\n\n*hp = hyperparameter\n\n\n\n\n\n\n\n\n\n\ndata1\n\ndata1\n\n\n\nmodel1\n\nmodel1\n\n\n\ndata1-&gt;model1\n\n\n\n\n\nmodel2\n\nmodel2\n\n\n\ndata1-&gt;model2\n\n\n\n\n\nmodel3\n\nmodel3\n\n\n\ndata1-&gt;model3\n\n\n\n\n\ndata2\n\ndata2\n\n\n\ndata2-&gt;model1\n\n\n\n\n\ndata2-&gt;model2\n\n\n\n\n\ndata2-&gt;model3\n\n\n\n\n\ndata3\n\ndata3\n\n\n\ndata3-&gt;model1\n\n\n\n\n\ndata3-&gt;model2\n\n\n\n\n\ndata3-&gt;model3\n\n\n\n\n\nhp1\n\nhp1\n\n\n\nhp1-&gt;model1\n\n\n\n\n\nhp1-&gt;model2\n\n\n\n\n\nhp1-&gt;model3\n\n\n\n\n\nhp2\n\nhp2\n\n\n\nhp2-&gt;model1\n\n\n\n\n\nhp2-&gt;model2\n\n\n\n\n\nhp2-&gt;model3\n\n\n\n\n\nhp3\n\nhp3\n\n\n\nhp3-&gt;model1\n\n\n\n\n\nhp3-&gt;model2\n\n\n\n\n\nhp3-&gt;model3\n\n\n\n\n\nperformance\n\nperformance1 ... performance27\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\n\n\n\n\n\nHow did we get performance19 again? ü§Ø\n\n\nExperiment tracking tools\nThe solution to this complexity is to use an experiment tracking tool such as MLflow and, optionally, a data versioning tool such as DVC.\n\nSee our webinar on DVC.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "ML experiment tracking",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/mlops/wb_mlflow_content.html#mlflow-overview",
    "href": "ai/mlops/wb_mlflow_content.html#mlflow-overview",
    "title": "Experiment tracking with MLflow",
    "section": "MLflow overview",
    "text": "MLflow overview\n\nPlatform for AI life cycle\n\n\n\nfrom MLflow website\n\n\n\n\nUse cases\n\nCompare algorithms\nKeep track of pipelines\nGenerate SHAP plots (relative contributions of features to the prediction)\nTrack models at checkpoints\nCompare models with different datasets\nTrack hyperparameter tuning experiments\nVisualize plots of logged metrics in UI\nKeep models and model versions in a registry\n\n\n\nFOSS & compatible\n\nOpen-source\nWorks with any ML or DL framework\nVendor-neutral if you run a server on a commercial platform\nCan be combined with dvc for dataset versioning\nWorks with any hyperparameter tuning framework ¬†‚ûî ¬†e.g.¬†integration with Optuna\n‚ÄÇ¬†‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇ¬†integration with Ray Tune\n‚ÄÇ¬†‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇ¬†integration with hyperopt\n\n\n\nUsed by proprietary tools\nThe foundation of many proprietary no-code/low-code tuning platforms that just add a layer on top to interface with the user with text rather than code.\n\ne.g.¬†Microsoft Fabric, FLAML\n\n\n\nLimitations\n\nMessy documentation (code typos, circular, confusing, many ‚ÄúGetting started‚Äù sections)\nuv not fully integrated (not supported in MLflow projects)\nThe UI can be unstable and inconsistent\nServers are not very resilient to by bad workflows, deletion and recreation of files, etc.\nNested runs don‚Äôt get logged as children runs if the workflow is not followed carefully",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "ML experiment tracking",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/mlops/wb_mlflow_content.html#tracking-with-mlflow",
    "href": "ai/mlops/wb_mlflow_content.html#tracking-with-mlflow",
    "title": "Experiment tracking with MLflow",
    "section": "Tracking with MLflow",
    "text": "Tracking with MLflow\n\nInstall MLflow\n(With uv)\nCreate a uv project:\nuv init --bare\nInstall MLflow:\nuv add mlflow\n\nuv is an amazing Python projects/versions/virtual envs manager and I recommend using it on your machine. However, it is currently not supported on the Alliance clusters where you need to keep using pip or risk issues with undetected modules.\n\nWhile installing MLflow with uv works without issues, MLflow models artifacts contain a conda.yaml file which expects pip.\nTo prevent getting the annoying warning:\nWARNING mlflow.utils.environment: Failed to resolve installed pip version.\n``pip`` will be added to conda.yaml environment spec without a version specifier.\neach time you log a model, you can install pip even if you never use it (or you can just ignore the warnings):\nuv add pip\n\n\nDefinitions in MLflow context\nParent run:\nOne experiment (e.g.¬†optimization task) containing multiple children (nested) runs.\nChild run:\nIndividual execution of a model training event.\nModel signature:\nDescription of a model input and output data structure, data types, and features names.\nModel artifacts:\nOutputs of model training process: trained model, checkpoints, and associated metadata.\nModel Uniform Resource Identifier (URI):\nUnique sequence of characters that identifies a model artifacts.\n\n\nMLflow tracking workflow\n\nCreate an experiment\nLaunch an MLflow server\nOpen the user interface in a browser to visualize the logged data\nLog tracking data (e.g.¬†train or tune a model)\n\n\n\nMLflow tracking setup\nYou can setup MLflow tracking locally or on a remote server, using databases or not1.\nIn the next slides, I am breaking down the workflow for the various configurations.\n\nCreate an experiment\n\n\n\n\n\n\nLocal\nimport mlflow\n\nmlflow.set_experiment(\"&lt;experiment-name&gt;\")\nLogs get stored in an mlruns directory.\n\nThis method will be deprecated, so prefer the use of a database.\n\n\n\n\n\n\n\n\n\n\nLocal with database\nimport mlflow\n\nmlflow.set_tracking_uri(\n    \"sqlite:///&lt;database-name&gt;.db\"\n)\nmlflow.set_experiment(\"&lt;experiment-name&gt;\")\nLogs get stored in a &lt;database-name&gt;.db file.\n\nHere we use SQLite which works well for a local database.\n\n\n\n\n\n\n\n\n\n\nRemote tracking server\n\n(For team development)\n\nimport mlflow\n\nmlflow.set_tracking_uri(\"http://&lt;host&gt;:&lt;port&gt;\")\nmlflow.set_experiment(\"&lt;experiment-name&gt;\")\n\n\n\n\n\nLaunch MLflow server\n\n\n\n\n\n\nLocal\nmlflow server\nThe server listens on http://localhost:5000 by default.\n\nTo listen to another port (e.g.¬†8080):\nmlflow server --port 8080\n\n\n\n\n\n\n\n\n\n\nLocal with database\nmlflow server \\\n       --backend-store-uri \\\n       sqlite:///&lt;database-name&gt;.db\n\nDefault port is 5000. To use another port (e.g.¬†8080):\nmlflow server \\\n       --backend-store-uri \\\n       sqlite:///&lt;database-name&gt;.db \\\n       --port 8080\n\n\n\n\n\n\n\n\n\n\nRemote tracking server\nmlflow server \\\n       --host &lt;host&gt; \\\n       --backend-store-uri \\\n       postgresql+psycopg2://&lt;username&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/mlflowdb \\\n       --port &lt;port&gt;\n\nHere we use PostgreSQL which works well to manage a database in a collaborative remote client-server system.\n(Requires installing the psycopg2 package.)\n\n\n\n\n\nAlliance clusters\n\nLaunch the MLflow server in the background (with a trailing &) as part of your job.\nUse the local workflow with the additional argument --host 0.0.0.0.\n\n\nExample job:\n\n#!/bin/bash\n#SBATCH ...\n#SBATCH ...\n\nmlflow server \\\n       --backend-store-uri sqlite:///&lt;database-name&gt;.db --host 0.0.0.0 &\n\npython &lt;script&gt;.py\n\n\n\nAccess the UI\nOpen http://&lt;host&gt;:&lt;port&gt; in a browser to view logs in the UI.\n\nExample: for a local server on port 5000 (the default), open http://localhost:5000.\n\n\nAlliance clusters\nOnce the job is running, you need to create a connection between the compute node running the server and your computer.\nFirst, you need to find the hostname of the compute node running the server. This is the value under NODELIST for your job when you run sq.\nThen, from your computer, run the SSH tunnelling command:\nssh -N -f -L localhost:5000:&lt;node&gt;:5000 &lt;user&gt;@&lt;cluster&gt;.alliancecan.ca\n\nReplace &lt;node&gt; by the compute node you identified, &lt;user&gt; by your user name, and &lt;cluster&gt; by the name of the Alliance cluster (e.g.¬†fir).\n\nFinally, open a browser (on your computer) and go to http://localhost:5000.\n\n\n\nLog tracking data\nDefine and run the experiment you want to track.\n\nExamples:\nTrain a model,\nTune hyperparameters,\nRun a model with different datasets,\n‚Ä¶",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "ML experiment tracking",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/mlops/wb_mlflow_content.html#use-case-1-model-tracking",
    "href": "ai/mlops/wb_mlflow_content.html#use-case-1-model-tracking",
    "title": "Experiment tracking with MLflow",
    "section": "Use case 1: model tracking",
    "text": "Use case 1: model tracking\n\nBenefits of using MLflow\n\nMonitor model metrics (e.g.¬†loss, accuracy)\nMonitor system metrics (e.g.¬†GPU, memory)\nSave checkpoints with metrics\nRecord hyperparameters and optimizer settings\nSnapshot library versions for reproducibility\n\n\n\nWorkflow\n\nCreate an experiment\nLaunch an MLflow server\nOpen the user interface in a browser to visualize the logged data\nLog tracking data:\n\nPrepare data\nDefine model\nDefine training parameters and optimizer\nTrain\n\n\n\n\nModel demo\n\nmodified from MLflow website\n\nWe need several packages for this demo. I create a bare uv project:\nuv init --bare\nand install the packages in its virtual environment:\nuv add mlflow psutil torch torchvision\nI also install ptpython because I like to use it instead of the default Python shell, but this is not necessary to run the demo (which is why I am adding it in the dev group):\nuv add --dev ptpython\nI can now launch ptpython (or python) to run the code:\nuv run ptpython\n\nCreate an experiment\nimport mlflow\n\nmlflow.set_tracking_uri(\"sqlite:///demos.db\")\nmlflow.set_experiment(\"model_tracking_demo\")\n\nmlflow.config.enable_system_metrics_logging()\nmlflow.config.set_system_metrics_sampling_interval(1)\n\nYou can see that the database file demos.db gets created.\n\n\n\nLaunch MLflow server\nIn Bash (not Python):\nuv run mlflow server --backend-store-uri sqlite:///demos.db\n\n\nAccess the UI\nOpen http://localhost:5000 in a browser to view logs in the UI.\nYou can see our model_tracking_demo experiment.\nClick on it to see the interface where the runs will be logged as we train our model.\n\n\nLog tracking data\nIn this demo, we log a checkpoint and its metrics after each epoch, as well as the final model for the training of a basic PyTorch classification neural network on the classic Fashion-MNIST dataset.\n\nPrepare data\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\n# Define device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load and prepare data\ntransform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n)\ntrain_dataset = datasets.FashionMNIST(\n    \"data\", train=True, download=True, transform=transform\n)\ntest_dataset = datasets.FashionMNIST(\"data\", train=False, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=1000)\n\n\nDefine model\nimport torch.nn as nn\n\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28 * 28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10),\n        def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\nmodel = NeuralNetwork().to(device)\n\n\nSet training conditions\nimport torch.optim as optim\n\n# Training parameters\nparams = {\n    \"epochs\": 4,\n    \"learning_rate\": 1e-3,\n    \"batch_size\": 64,\n    \"optimizer\": \"SGD\",\n    \"model_type\": \"MLP\",\n    \"hidden_units\": [512, 512],\n}\n\n# Define optimizer and loss function\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=params[\"learning_rate\"])\n\n\nTrain\nwith mlflow.start_run(run_name=\"run_1\") as run:\n    # Log training parameters\n    mlflow.log_params(params)\n\n    for epoch in range(params[\"epochs\"]):\n        model.train()\n        train_loss, correct, total = 0, 0, 0\n\n        for batch_idx, (data, target) in enumerate(train_loader):\n            data, target = data.to(device), target.to(device)\n\n            # Forward pass\n            optimizer.zero_grad()\n            output = model(data)\n            loss = loss_fn(output, target)\n\n            # Backward pass\n            loss.backward()\n            optimizer.step()\n\n            # Calculate metrics\n            train_loss += loss.item()\n            _, predicted = output.max(1)\n            total += target.size(0)\n            correct += predicted.eq(target).sum().item()\n\n            # Log batch metrics (every 100 batches)\n            if batch_idx % 100 == 0:\n                batch_loss = train_loss / (batch_idx + 1)\n                batch_acc = 100.0 * correct / total\n                mlflow.log_metrics(\n                    {\"batch_loss\": batch_loss, \"batch_accuracy\": batch_acc},\n                    step=epoch * len(train_loader) + batch_idx,\n                    # Calculate epoch metrics\n        epoch_loss = train_loss / len(train_loader)\n        epoch_acc = 100.0 * correct / total\n\n        # Validation\n        model.eval()\n        val_loss, val_correct, val_total = 0, 0, 0\n        with torch.no_grad():\n            for data, target in test_loader:\n                data, target = data.to(device), target.to(device)\n                output = model(data)\n                loss = loss_fn(output, target)\n\n                val_loss += loss.item()\n                _, predicted = output.max(1)\n                val_total += target.size(0)\n                val_correct += predicted.eq(target).sum().item()\n\n        # Calculate and log epoch validation metrics\n        val_loss = val_loss / len(test_loader)\n        val_acc = 100.0 * val_correct / val_total\n\n        # Log epoch metrics\n        mlflow.log_metrics(\n            {\n                \"train_loss\": epoch_loss,\n                \"train_accuracy\": epoch_acc,\n                \"val_loss\": val_loss,\n                \"val_accuracy\": val_acc,\n            },\n            step=epoch,\n        )\n        # Log checkpoint at the end of each epoch\n        mlflow.pytorch.log_model(\n            model,\n            name=f\"fashionmnist_1_checkpoint_{epoch}\"\n            print(\n            f\"Epoch {epoch+1}/{params['epochs']}, \"\n            f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}%, \"\n            f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\"\n        # Log the final trained model\n    model_info = mlflow.pytorch.log_model(\n        model,\n        name=\"fashionmnist_1_trained\"\n    )\n\n\n\nVisualize metrics\nGo to the UI in the browser. If you haven‚Äôt done so yet, click on the experiment we called model_tracking_demo.\nThen click on the run we called run_1 (if you don‚Äôt name runs, they get automatically generated names).\nFinally go to the Model metrics tab to see the metrics logged in real time.\nThe System metrics tab allows you to monitor your resource usage.\nAlternatively, you can click on the experiment and click on  (Chart view button).\nThis is a great method if you want to compare multiple runs.\n\n\nCreate a new run\nWe can create new runs by training the model again:\nwith mlflow.start_run(run_name=\"run_2\") as run:\n    # Log training parameters\n    mlflow.log_params(params)\n\n    for epoch in range(params[\"epochs\"]):\n        model.train()\n        train_loss, correct, total = 0, 0, 0\n\n        for batch_idx, (data, target) in enumerate(train_loader):\n            data, target = data.to(device), target.to(device)\n\n            # Forward pass\n            optimizer.zero_grad()\n            output = model(data)\n            loss = loss_fn(output, target)\n\n            # Backward pass\n            loss.backward()\n            optimizer.step()\n\n            # Calculate metrics\n            train_loss += loss.item()\n            _, predicted = output.max(1)\n            total += target.size(0)\n            correct += predicted.eq(target).sum().item()\n\n            # Log batch metrics (every 100 batches)\n            if batch_idx % 100 == 0:\n                batch_loss = train_loss / (batch_idx + 1)\n                batch_acc = 100.0 * correct / total\n                mlflow.log_metrics(\n                    {\"batch_loss\": batch_loss, \"batch_accuracy\": batch_acc},\n                    step=epoch * len(train_loader) + batch_idx,\n                    # Calculate epoch metrics\n        epoch_loss = train_loss / len(train_loader)\n        epoch_acc = 100.0 * correct / total\n\n        # Validation\n        model.eval()\n        val_loss, val_correct, val_total = 0, 0, 0\n        with torch.no_grad():\n            for data, target in test_loader:\n                data, target = data.to(device), target.to(device)\n                output = model(data)\n                loss = loss_fn(output, target)\n\n                val_loss += loss.item()\n                _, predicted = output.max(1)\n                val_total += target.size(0)\n                val_correct += predicted.eq(target).sum().item()\n\n        # Calculate and log epoch validation metrics\n        val_loss = val_loss / len(test_loader)\n        val_acc = 100.0 * val_correct / val_total\n\n        # Log epoch metrics\n        mlflow.log_metrics(\n            {\n                \"train_loss\": epoch_loss,\n                \"train_accuracy\": epoch_acc,\n                \"val_loss\": val_loss,\n                \"val_accuracy\": val_acc,\n            },\n            step=epoch,\n        )\n        # Log checkpoint at the end of each epoch\n        mlflow.pytorch.log_model(\n            model,\n            name=f\"fashionmnist_2_checkpoint_{epoch}\"\n            print(\n            f\"Epoch {epoch+1}/{params['epochs']}, \"\n            f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}%, \"\n            f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\"\n        # Log the final trained model\n    model_info = mlflow.pytorch.log_model(\n        model,\n        name=\"fashionmnist_2_trained\"\n    )",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "ML experiment tracking",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/mlops/wb_mlflow_content.html#use-case-2-tuning",
    "href": "ai/mlops/wb_mlflow_content.html#use-case-2-tuning",
    "title": "Experiment tracking with MLflow",
    "section": "Use case 2: tuning",
    "text": "Use case 2: tuning\n\nHyperparameter tuning\nThe goal of hyperparameter tuning is to find the optimal set of hyperparameters that maximize a model‚Äôs predictive accuracy and performance.\n‚ûî Find the right balance between high bias (underfitting) and high variance (overfitting) to improve the model‚Äôs ability to generalize and perform well on new, unseen data.\n\n\nTuning frameworks\nHyperparameters optimization used to be done manually following a systematic grid pattern. This was extremely inefficient.\nNowadays, there are many frameworks that do it automatically, faster, and better.\n\nExample:\n\n\nOptuna\nHyperopt\nRay Tune\n\n\n\nWorkflow\n\nCreate an experiment\nLaunch an MLflow server\nOpen the user interface in a browser to visualize the logged data\nLog tracking data:\n\nPrepare data\nDefine an objective function\nRun an optimization task\n\n\n\n\nTuning demo\n\nmodified from MLflow website\n\nFor this demo, we will use optuna as the hyperparameter optimization framework, so we need to install it (in Bash, not Python):\nuv add optuna\n\nCreate an experiment\nimport mlflow\n\nmlflow.set_tracking_uri(\"sqlite:///demos.db\")\nmlflow.set_experiment(\"tuning_demo\")\n\nWe are using the same database, but you could of course create a new one.\n\n\n\nLaunch MLflow server\nIn Bash/zsh (not in Python!) at root of project.\nmlflow server --backend-store-uri sqlite:///demos.db\n\nIf you are using the same database as in the previous demo and you kept the server running, you don‚Äôt have to do anything.\n\n\n\nAccess the UI\nOpen http://localhost:5000 in a browser.\nSelect the experiment tuning_demo.\n\n\nLog tracking data\nIn this demo, we train a random forest regressor model on the classic scikit-learn California housing dataset and tune its hyperparameters (random forest max depth, number of estimators, and max features) by minimizing the mean squared error between the predicted and validation values using the hyperparameter optimization package optuna.\n\nPrepare data\nimport sklearn\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import fetch_california_housing\n\nX, y = fetch_california_housing(return_X_y=True)\nX_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n\n\nObjective function\nDefine an objective function:\ndef objective(trial):\n    # Setting nested=True will create a child run under the parent run.\n    with mlflow.start_run(\n            nested=True,\n            run_name=f\"trial_{trial.number}\"\n    ) as child_run:\n        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 2, 32)\n        rf_n_estimators = trial.suggest_int(\n            \"rf_n_estimators\",\n            50,\n            300,\n            step=10\n        )\n        rf_max_features = trial.suggest_float(\"rf_max_features\", 0.2, 1.0)\n        params = {\n            \"max_depth\": rf_max_depth,\n            \"n_estimators\": rf_n_estimators,\n            \"max_features\": rf_max_features,\n        }\n        # Log current trial's parameters\n        mlflow.log_params(params)\n\n        regressor_obj = sklearn.ensemble.RandomForestRegressor(**params)\n        regressor_obj.fit(X_train, y_train)\n\n        y_pred = regressor_obj.predict(X_val)\n        error = sklearn.metrics.mean_squared_error(y_val, y_pred)\n        # Log current trial's error metric\n        mlflow.log_metrics({\"error\": error})\n\n        # Log the model file\n        mlflow.sklearn.log_model(regressor_obj, name=\"calhousing_1\")\n        # Make it easy to retrieve the best-performing child run later\n        trial.set_user_attr(\"run_id\", child_run.info.run_id)\n        return error\n\n\nOptimization task\nThen run an optimization task:\nimport optuna\n\n# Create a parent run that contains all child runs for different trials\nwith mlflow.start_run(run_name=\"calhousing_1_optimization_1\") as run:\n    # Log the experiment settings\n    n_trials = 5\n    mlflow.log_param(\"n_trials\", n_trials)\n\n    study = optuna.create_study(direction=\"minimize\")\n    study.optimize(objective, n_trials=n_trials)\n\n    # Log the best trial and its run ID\n    mlflow.log_params(study.best_trial.params)\n    mlflow.log_metrics({\"best_error\": study.best_value})\n    if best_run_id := study.best_trial.user_attrs.get(\"run_id\"):\n        mlflow.log_param(\"best_child_run_id\", best_run_id)\n\n\n\nVisualize trials errors\nGo to the UI in the browser. If you haven‚Äôt done so yet, click on the experiment we called tuning_demo.\nThen click on the + sign next to our optimization experiment to expand it.\nFinally click on  (Chart view button) to compare the trials.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "ML experiment tracking",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/mlops/wb_mlflow_content.html#use-case-3-model-registry",
    "href": "ai/mlops/wb_mlflow_content.html#use-case-3-model-registry",
    "title": "Experiment tracking with MLflow",
    "section": "Use case 3: model registry",
    "text": "Use case 3: model registry\n\nBenefits\n\nTracks development pipelines of models\nTracks model versions\nCentral place for all models (local or remote for collaborations)\nAliases, tags, annotations, metadata associated with models\n\n\n\nRegister models\nWhenever you care about a model, you should add it to the model registry.\nYou can do so when you log it by adding a value to the registered_model_name argument of the log_model function.\nBut often, you will do so afterwards, once you have looked at the logs and decided that they look good.\n\nRegister models in the UI\n\n\n\nVersion 1\n\nClick on the experiment name containing the model\nClick on Models in the left menus\nClick on the model to register\nClick on the Register model button in top right corner\nIn drop-down menu click Create New Model\nEnter name of model\nClick Register\n\n\n\n\nVersions 2+\n\n\n\n\n\nIn drop-down menu select model for which you want to create a new version\nClick Register\n\n\n\n\n\n\nRegister programmatically\nYou can also register models programmatically.\nFrom model ID:\n\nClick on the experiment name containing the model\nClick on Models in the left menus\nClick on the model to register\n\nThen run:\nmlflow.register_model(\"models:/&lt;model-id&gt;\", \"&lt;name-of-registered-model&gt;\")\n\n\n&lt;model-id&gt; = the letters and digits after Model ID\n&lt;name-of-registered-model&gt; = the name you give to your registered model\n\n\nFrom run ID:\nNavigate to and click on the model to register.\nThen run:\nmlflow.register_model(\n    \"runs:/&lt;source-run-id&gt;/&lt;model-name&gt;\",\n    \"&lt;name-of-registered-model&gt;\"\n)\n\n\n&lt;source-run-id&gt; = the digits in top right corner after Source run ID\n&lt;model-name&gt; = the name of the model in top left corner (the model you just clicked on)\n&lt;name-of-registered-model&gt; = the name you give to your registered model\n\n\n\n\n\nLoad registered model\nYou can then load any of your registered models with:\nmlflow.&lt;flavour&gt;.load_model(\n    \"models:/&lt;your_registered_model_name&gt;/&lt;model_version&gt;\"\n)\n\n&lt;flavour&gt; = any ML/DL flavour such as pytorch, sklearn, or any other named flavour (predefined code for supported ML/DL frameworks), or a custom PyFunc for unsupported frameworks.\n\n\n\nModel registry demo\nIn the previous demos, we logged a number of models:\n\nthe checkpoints of both our FashionMNIST runs\nthe final models of those two runs\nthe trials (child runs) of the California housing tuning experiment\n\nLet‚Äôs register some of these models.\n\nRegister models in the UI\n\n\nFashionMNIST:\n\nClick on model_tracking_demo\nClick on Models in the left menus\nClick on fashionmnist_1_trained\nClick on the Register model button in top right corner\nIn drop-down menu click Create New Model\nEnter: ‚Äúfashionmnist_1‚Äù\nClick Register\n\n\nCalifornia housing:\n\nClick on tuning_demo\nClick on Models in the left menus\nClick on the calhousing_1 line corresponding to our best trial run\nClick on the Register model button in top right corner\nIn drop-down menu click Create New Model\nEnter: ‚Äúcalhousing_1_best‚Äù\nClick Register\n\n\n\n\n\nRegister models in Python\nIn the UI:\n\nClick on model_tracking_demo\nClick on Models in the left menus\nClick on fashionmnist_2_trained\n\nThen run:\nmlflow.register_model(\n    \"models:/m-a7a4cd35cc4c4fe4b2e3d839b1307b5d\",\n    \"fashionmnist_2\"\n)\nIn the UI:\n\nClick on model_tracking_demo\nClick on Models in the left menus\nClick on fashionmnist_2_trained\n\nAlternatively:\nmlflow.register_model(\n    \"runs:/1a2844d0125e40cfac528ae44c4ae76a/fashionmnist_2_trained\",\n    \"fashionmnist_2\"\n)\n\n\nLoad registered models\nYou can load back any registered model by its name and version number:\nfashionmnist_1 = mlflow.pytorch.load_model(\"models:/fashionmnist_1/1\")\ncalhousing_1_best = mlflow.sklearn.load_model(\"models:/calhousing_1_best/1\")\nLet‚Äôs print the fashionmnist_1 model:\nfashionmnist_1\nand the calhousing_1_best model:\ncalhousing_1_best",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "ML experiment tracking",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/mlops/wb_mlflow_content.html#models-signatures",
    "href": "ai/mlops/wb_mlflow_content.html#models-signatures",
    "title": "Experiment tracking with MLflow",
    "section": "Models signatures",
    "text": "Models signatures\nYou might have noticed that we got the following warning at each model we logged:\nWARNING mlflow.models.model: Model logged without a signature and input example.\nPlease set `input_example` parameter when logging the model to auto infer the model signature.\nLet‚Äôs dive into this.\n\nBenefits of models signatures\nModel signatures describe the schema of inputs and outputs.\nThey help in model understanding and define how the model should be used.\n\n\nInput examples\nInput examples illustrate the data type and format that should be used with models and ensures validation that the models work properly. MLflow can infer a model signature for a model from an input example.\nThe input example also provides a test for the model during logging. It thus a good practice to add an input example whenever a model is logged.\n\n\nExample\nLet‚Äôs go back to the objective function we defined in the tuning demo as an example and let‚Äôs add the first the first element of the X ndarray an input example.\nWhen we define an objective function, we had the following:\ndef objective(trial):\n    # Setting nested=True will create a child run under the parent run.\n    with mlflow.start_run(\n            nested=True,\n            run_name=f\"trial_{trial.number}\"\n    ) as child_run:\n        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 2, 32)\n        rf_n_estimators = trial.suggest_int(\n            \"rf_n_estimators\",\n            50,\n            300,\n            step=10\n        )\n        rf_max_features = trial.suggest_float(\"rf_max_features\", 0.2, 1.0)\n        params = {\n            \"max_depth\": rf_max_depth,\n            \"n_estimators\": rf_n_estimators,\n            \"max_features\": rf_max_features,\n        }\n        # Log current trial's parameters\n        mlflow.log_params(params)\n\n        regressor_obj = sklearn.ensemble.RandomForestRegressor(**params)\n        regressor_obj.fit(X_train, y_train)\n\n        y_pred = regressor_obj.predict(X_val)\n        error = sklearn.metrics.mean_squared_error(y_val, y_pred)\n        # Log current trial's error metric\n        mlflow.log_metrics({\"error\": error})\n\n        # Log the model file\n        mlflow.sklearn.log_model(regressor_obj, name=\"calhousing_1\")\n        # Make it easy to retrieve the best-performing child run later\n        trial.set_user_attr(\"run_id\", child_run.info.run_id)\n        return error\nLet‚Äôs add the additional input_example argument in:\nmlflow.sklearn.log_model(regressor_obj, name=\"calhousing_1\")\nAnd have it look like:\nmlflow.sklearn.log_model(\n    regressor_obj,\n    name=\"calhousing_1\",\n    input_example=X[[0]]\n)\ndef objective(trial):\n    # Setting nested=True will create a child run under the parent run.\n    with mlflow.start_run(\n            nested=True,\n            run_name=f\"trial_{trial.number}\"\n    ) as child_run:\n        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 2, 32)\n        rf_n_estimators = trial.suggest_int(\n            \"rf_n_estimators\",\n            50,\n            300,\n            step=10\n        )\n        rf_max_features = trial.suggest_float(\"rf_max_features\", 0.2, 1.0)\n        params = {\n            \"max_depth\": rf_max_depth,\n            \"n_estimators\": rf_n_estimators,\n            \"max_features\": rf_max_features,\n        }\n        # Log current trial's parameters\n        mlflow.log_params(params)\n\n        regressor_obj = sklearn.ensemble.RandomForestRegressor(**params)\n        regressor_obj.fit(X_train, y_train)\n\n        y_pred = regressor_obj.predict(X_val)\n        error = sklearn.metrics.mean_squared_error(y_val, y_pred)\n        # Log current trial's error metric\n        mlflow.log_metrics({\"error\": error})\n\n        # Log the model file\n        mlflow.sklearn.log_model(\n            regressor_obj,\n            name=\"calhousing_1\",\n            input_example=X[[0]]\n        )\n        # Make it easy to retrieve the best-performing child run later\n        trial.set_user_attr(\"run_id\", child_run.info.run_id)\n        return error\nIf we re-run our optimization task now, we don‚Äôt get any warnings about missing signatures anymore:\nimport optuna\n\n# Create a parent run that contains all child runs for different trials\nwith mlflow.start_run(run_name=\"calhousing_1_optimization_1\") as run:\n    # Log the experiment settings\n    n_trials = 5\n    mlflow.log_param(\"n_trials\", n_trials)\n\n    study = optuna.create_study(direction=\"minimize\")\n    study.optimize(objective, n_trials=n_trials)\n\n    # Log the best trial and its run ID\n    mlflow.log_params(study.best_trial.params)\n    mlflow.log_metrics({\"best_error\": study.best_value})\n    if best_run_id := study.best_trial.user_attrs.get(\"run_id\"):\n        mlflow.log_param(\"best_child_run_id\", best_run_id)\n\nSignature test\nYou can do a sanity check of your signature by running your input example in the model.\nFirst, register the model and load it (let‚Äôs use the model we already registered):\ncalhousing_1_best = mlflow.sklearn.load_model(\"models:/calhousing_1_best/1\")\nThen test the input example:\ntry:\n    result = calhousing_1_best.predict(X[[0]])\n    print(\"‚úÖ Signature validation passed\")\nexcept Exception as e:\n    print(f\"‚ùå Signature issue: {e}\")\n‚úÖ Signature validation passed\nIf you used a bad input sample, you will get some informative error:\ntry:\n    result = calhousing_1_best.predict(X[0])\n    print(\"‚úÖ Signature validation passed\")\nexcept Exception as e:\n    print(f\"‚ùå Signature issue: {e}\")\n‚ùå Signature issue: Expected 2D array, got 1D array instead:\narray=[   8.3252      41.           6.984127     1.0238096  322.\n    2.5555556   37.88      -122.23     ].\nReshape your data either using array.reshape(-1, 1) if your data has \na single feature or array.reshape(1, -1) if it contains a single sample.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "ML experiment tracking",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/mlops/wb_mlflow_content.html#use-case-4-datasets-tracking",
    "href": "ai/mlops/wb_mlflow_content.html#use-case-4-datasets-tracking",
    "title": "Experiment tracking with MLflow",
    "section": "Use case 4: datasets tracking",
    "text": "Use case 4: datasets tracking\n\nBenefits\n\nKeep data and models together for reproducibility\nKeep data versions for traceability\nRecord metadata and data sources\nShare data for collaborations (when using remote servers)\n\n\n\nSupported data types\n\nPandasDataset: Pandas DataFrames\nSparkDataset: Apache Spark DataFrames\nNumpyDataset: NumPy arrays\nPolarsDataset: Polars DataFrames\nHuggingFaceDataset: Hugging Face datasets\nTensorFlowDataset: TensorFlow datasets\nMetaDataset: metadata-only datasets (no actual data storage)\n\nNon supported data types (e.g.¬†torchvision datasets) need to be converted to supported types or logged via custom functions.\n\n\nExample\nimport polars as pl\n\ntrain_data = pl.DataFrame({\"X\": X_train, \"y\": y_train})\nval_data = pl.DataFrame({\"X\": X_val, \"y\": y_val})\n\ntrain_dataset = mlflow.data.from_polars(train_data, name=\"calhousing_train\")\nval_dataset = mlflow.data.from_polars(val_data, name=\"calhousing_val\")\n\nwith mlflow.start_run():\n    mlflow.log_input(train_dataset, context=\"training\")\n    mlflow.log_input(val_dataset, context=\"validation\")",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "ML experiment tracking",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/mlops/wb_mlflow_content.html#footnotes",
    "href": "ai/mlops/wb_mlflow_content.html#footnotes",
    "title": "Experiment tracking with MLflow",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nUsage without databases will be deprecated at some point and is not recommended.‚Ü©Ô∏é",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "ML experiment tracking",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/pt_autograd.html",
    "href": "ai/pt/pt_autograd.html",
    "title": "Automatic differentiation",
    "section": "",
    "text": "PyTorch has automatic differentiation capabilities‚Äîmeaning that it can track all the operations performed on tensors during the forward pass and compute all the gradients automatically for the backpropagation‚Äîthanks to its package torch.autograd.\nLet‚Äôs have a look at this.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Automatic differentiation"
    ]
  },
  {
    "objectID": "ai/pt/pt_autograd.html#some-definitions",
    "href": "ai/pt/pt_autograd.html#some-definitions",
    "title": "Automatic differentiation",
    "section": "Some definitions",
    "text": "Some definitions\nDerivative of a function:\nRate of change of a function with a single variable w.r.t. its variable.\nPartial derivative:\nRate of change of a function with multiple variables w.r.t. one variable while other variables are considered as constants.\nGradient:\nVector of partial derivatives of function with several variables.\nDifferentiation:\nCalculation of the derivatives of a function.\nChain rule:\nFormula to calculate the derivatives of composite functions.\nAutomatic differentiation:\nAutomatic computation of partial derivatives by algorithms.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Automatic differentiation"
    ]
  },
  {
    "objectID": "ai/pt/pt_autograd.html#backpropagation",
    "href": "ai/pt/pt_autograd.html#backpropagation",
    "title": "Automatic differentiation",
    "section": "Backpropagation",
    "text": "Backpropagation\nFirst, we need to talk about backpropagation: the backward pass following each forward pass and which adjusts the model‚Äôs parameters to minimize the output of the loss function.\nThe last 2 videos of 3Blue1Brown neural network series explains backpropagation and its manual calculation very well.\n\nWhat is backpropagation?\n14 min video.\n\n\nThere is one minor terminological error in this video: they call the use of mini-batches stochastic gradient descent. In fact, this is called mini-batch gradient descent. Stochastic gradient descent uses a single example at each iteration.\n\n\n\nHow does backpropagation work?\n10 min video.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Automatic differentiation"
    ]
  },
  {
    "objectID": "ai/pt/pt_autograd.html#automatic-differentiation",
    "href": "ai/pt/pt_autograd.html#automatic-differentiation",
    "title": "Automatic differentiation",
    "section": "Automatic differentiation",
    "text": "Automatic differentiation\nIf we had to do all this manually, it would be absolute hell. Thankfully, many tools‚Äîincluding PyTorch‚Äîcan do this automatically.\n\nTracking computations\nFor the automation of the calculation of all those derivatives through chain rules, PyTorch needs to track computations during the forward pass.\nPyTorch does not however track all the computations on all the tensors (this would be extremely memory intensive!). To start tracking computations on a vector, set the requires_grad attribute to True:\n\nimport torch\n\nx = torch.ones(2, 4, requires_grad=True)\nx\n\ntensor([[1., 1., 1., 1.],\n        [1., 1., 1., 1.]], requires_grad=True)\n\n\n\nThe grad_fun attribute\nWhenever a tensor is created by an operation involving a tracked tensor, it has a grad_fun attribute:\n\ny = x + 1\ny\n\ntensor([[2., 2., 2., 2.],\n        [2., 2., 2., 2.]], grad_fn=&lt;AddBackward0&gt;)\n\n\n\ny.grad_fn\n\n&lt;AddBackward0 at 0x7f8798091540&gt;\n\n\n\n\nJudicious tracking\nYou don‚Äôt want to track more than is necessary. There are multiple ways to avoid tracking what you don‚Äôt want.\nYou can stop tracking computations on a tensor with the method detach:\n\nx\n\ntensor([[1., 1., 1., 1.],\n        [1., 1., 1., 1.]], requires_grad=True)\n\n\n\nx.detach_()\n\ntensor([[1., 1., 1., 1.],\n        [1., 1., 1., 1.]])\n\n\nYou can change its requires_grad flag:\n\nx = torch.zeros(2, 3, requires_grad=True)\nx\n\ntensor([[0., 0., 0.],\n        [0., 0., 0.]], requires_grad=True)\n\n\n\nx.requires_grad_(False)\n\ntensor([[0., 0., 0.],\n        [0., 0., 0.]])\n\n\nAlternatively, you can wrap any code you don‚Äôt want to track under with torch.no_grad():\n\nx = torch.ones(2, 4, requires_grad=True)\n\nwith torch.no_grad():\n    y = x + 1\n\ny\n\ntensor([[2., 2., 2., 2.],\n        [2., 2., 2., 2.]])\n\n\n\nCompare this with what we just did above.\n\n\n\n\nCalculating gradients\nLet‚Äôs calculate gradients manually, then use autograd, in a very simple case: imagine that \\(x\\), \\(y\\), and \\(z\\) are tensors containing the parameters of a model and that the error \\(e\\) could be calculated with the equation:\n\\[e=2x^4-y^3+3z^2\\]\n\nManual derivative calculation\nLet‚Äôs see how we would do this manually.\nFirst, we need the model parameters tensors:\n\nx = torch.tensor([1., 2.])\ny = torch.tensor([3., 4.])\nz = torch.tensor([5., 6.])\n\nWe calculate \\(e\\) following the above equation:\n\ne = 2*x**4 - y**3 + 3*z**2\n\nThe gradients of the error \\(e\\) w.r.t. the parameters \\(x\\), \\(y\\), and \\(z\\) are:\n\\[\\frac{de}{dx}=8x^3\\] \\[\\frac{de}{dy}=-3y^2\\] \\[\\frac{de}{dz}=6z\\]\nWe can calculate them with:\n\ngradient_x = 8*x**3\ngradient_x\n\ntensor([ 8., 64.])\n\n\n\ngradient_y = -3*y**2\ngradient_y\n\ntensor([-27., -48.])\n\n\n\ngradient_z = 6*z\ngradient_z\n\ntensor([30., 36.])\n\n\n\n\nAutomatic derivative calculation\nFor this method, we need to define our model parameters with requires_grad set to True:\n\nx = torch.tensor([1., 2.], requires_grad=True)\ny = torch.tensor([3., 4.], requires_grad=True)\nz = torch.tensor([5., 6.], requires_grad=True)\n\n\\(e\\) is calculated in the same fashion (except that here, all the computations on \\(x\\), \\(y\\), and \\(z\\) are tracked):\n\ne = 2*x**4 - y**3 + 3*z**2\n\nThe backward propagation is done automatically with:\n\ne.backward(torch.tensor([1., 1.]))\n\nAnd we have our 3 partial derivatives:\n\nprint(x.grad)\nprint(y.grad)\nprint(z.grad)\n\ntensor([ 8., 64.])\ntensor([-27., -48.])\ntensor([30., 36.])\n\n\n\n\nComparison\nThe result is the same, as can be tested with:\n\n8*x**3 == x.grad\n\ntensor([True, True])\n\n\n\n-3*y**2 == y.grad\n\ntensor([True, True])\n\n\n\n6*z == z.grad\n\ntensor([True, True])\n\n\nOf course, calculating the gradients manually here was extremely easy, but imagine how tedious and lengthy it would be to write the chain rules to calculate the gradients of all the composite functions in a neural network manually‚Ä¶",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Automatic differentiation"
    ]
  },
  {
    "objectID": "ai/pt/pt_choosing_frameworks.html",
    "href": "ai/pt/pt_choosing_frameworks.html",
    "title": "Which framework to choose?",
    "section": "",
    "text": "With the growing popularity of machine learning, many frameworks have appeared in various languages. One of the questions you might be facing is: which tool should I choose?\nThe main focus here is on the downsides of proprietary tools.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Which framework to choose?"
    ]
  },
  {
    "objectID": "ai/pt/pt_choosing_frameworks.html#points-worth-considering",
    "href": "ai/pt/pt_choosing_frameworks.html#points-worth-considering",
    "title": "Which framework to choose?",
    "section": "Points worth considering",
    "text": "Points worth considering\nThere are a several points you might want to consider in making that choice. For instance, what tools do people use in your field? (what tools are used in the papers you read?) What tools are your colleagues and collaborators using?\nLooking a bit further into the future, whether you are considering staying in academia or working in industry could also influence your choice. If the former, paying attention to the literature is key, if the latter, it may be good to have a look at the trends in job postings.\nSome frameworks offer collections of already-made toolkits. They are thus easy to start using and do not require a lot of programming experience. On the other hand, they may feel like black boxes and they are not very customizable. Scikit-learn and Keras‚Äîusually run on top of TensorFlow‚Äîfall in that category. Lower level tools allow you full control and tuning of your models, but can come with a steeper learning curve.\nPyTorch, developed by Facebook‚Äôs AI Research lab, has seen a huge increase in popularity in research in recent years due to its highly pythonic syntax, very convenient tensors, just-in-time (JIT) compilation, dynamic computation graphs, and because it is free and open-source.\nSeveral libraries are now adding a higher level on top of PyTorch: fastai, which we will use in this course, PyTorch Lightning, and PyTorch Ignite. fastai, in addition to the convenience of being able to write a model in a few lines of code, allows to dive as low as you choose into the PyTorch code, thus making it unconstrained by the optional ease of use. It also adds countless functionality. The downside of using this added layer is that it can make it less straightforward to install on a machine or to tweak and customize.\nThe most popular machine learning library currently remains TensorFlow, developed by the Google Brain Team. While it has a Python API, its syntax can be more obscure.\nJulia‚Äôs syntax is well suited for the implementation of mathematical models, GPU kernels can be written directly in Julia, and Julia‚Äôs speed is attractive in computation hungry fields. So Julia has also seen the development of many ML packages such as Flux or Knet. The user base of Julia remains quite small however.\nMy main motivation in writing this section however is to raise awareness about one question that should really be considered: whether the tool you decide to learn and use in your research is open-source or proprietary.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Which framework to choose?"
    ]
  },
  {
    "objectID": "ai/pt/pt_choosing_frameworks.html#proprietary-tools-a-word-of-caution",
    "href": "ai/pt/pt_choosing_frameworks.html#proprietary-tools-a-word-of-caution",
    "title": "Which framework to choose?",
    "section": "Proprietary tools: a word of caution",
    "text": "Proprietary tools: a word of caution\nAs a student, it is tempting to have the following perspective:\n\nMy university pays for this very expensive license. I have free access to this very expensive tool. It would be foolish not to make use of it while I can!\n\nWhen there are no equivalent or better open-source tools, that might be true. But when superior open-source tools exist, these university licenses are more of a trap than a gift.\nHere are some of the reasons you should be wary of proprietary tools:\n\nClosed research\nResearchers who do not have access to the tool cannot reproduce your methods.\nLarge Canadian universities may offer a license for the tool, but grad students in other countries, independent researchers, researchers in small organizations, etc. may not have access to a free license (or tens of thousands of dollars to pay for it).\n\n\nNon-transferable skills\nOnce you graduate, you may not have access to the tool anymore.\nOnce you leave your Canadian institution, you may become one of those researchers who do not have access to that tool. This means that you will not be able to re-run your thesis analyses, re-use your methods, and apply the skills you learnt. The time you spent learning that expensive tool you could play with for free may feel a lot less like a gift then.\n\n\nUncertainty of access\nYour university may stop paying for a license.\nAs commercial tools fall behind successful open-source ones, some universities may decide to stop purchasing a license. It happened during my years at SFU with an expensive and clunky citation manager which, after having been promoted for years by the library through countless workshops, got abandoned in favour of a much better free and open-source one.\n\n\nLocked-in files\nTo switch to another tool is not easy.\nProprietary tools often come with proprietary formats and, depending on the tool, it may be painful (or impossible) to convert your work to another format. When that happens, you are locked-in.\n\n\nLack of transparency\nProprietary tools are black boxes.\nIt is impossible to see the source code of proprietary software, so you don‚Äôt know what it really does with your code.\n\n\nLong-term reproducibility issues\nReproducing old methods is likely to be impossible.\nIt is often very difficult to have access to old versions of proprietary tools (and this can be necessary to reproduce old studies). When companies disappear, the tools they produced usually disappear with them. open-source tools, particularly those who have their code under version control in repositories such as GitHub, remain fully accessible (including all stages of development), and if they get abandoned, their maintenance can be taken over or restarted by others.\n\n\nCause for license headaches\nThe licenses you have access to may be limiting and require jumping through hoops.\nFor instance, the Alliance does not have an unlimited number of MATLAB licenses. Since these licenses come with complex rules (one license needed for each node, additional licenses for each toolbox, additional licenses for newer tools, etc.), it can quickly become a nightmare to navigate through it all. You may want to have a look at some of the comments in this thread.\n\n\nLack of competitiveness\nProprietary tools fall behind popular open-source tools.\nEven large teams of software engineers cannot compete against an active community of researchers developing open-source tools. When open-source tools become really popular, the number of users contributing to their development vastly outnumbers what any company can provide. The testing, licensing, and production of proprietary tools are also too slow to keep up with quickly evolving fields of research. (Of course, open-source tools which do not take off and remain absolutely obscure do not see the benefit of a vast community.)\n\n\nMismatch for research\nProprietary tools often fail to address specialized edge cases needed in research.\nIt is not commercially sound to develop cutting-edge capabilities so specialized in a narrow subfield that they can only target a minuscule number of customers. But this is often what research needs. With open-source tools, researchers can develop the capabilities that fit their very specific needs. So while commercial tools are good and reliable for large audiences, they are often not the best in research. This explains the success of R over tools such as SASS or Stata in the past decade.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Which framework to choose?"
    ]
  },
  {
    "objectID": "ai/pt/pt_choosing_frameworks.html#conclusion",
    "href": "ai/pt/pt_choosing_frameworks.html#conclusion",
    "title": "Which framework to choose?",
    "section": "Conclusion",
    "text": "Conclusion\nAll that said, sometimes you don‚Äôt have a choice over the tool to use for your research as this may be dictated by the culture in your field or by your supervisor. But if you are free to choose and if superior or equal open-source alternatives exist and are popular, do not fall in the trap of thinking that because your university and the Alliance pay for a license, you should make use of it. It may be free for you‚Äîfor now‚Äîbut it can have hidden costs.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Which framework to choose?"
    ]
  },
  {
    "objectID": "ai/pt/pt_data.html",
    "href": "ai/pt/pt_data.html",
    "title": "Loading data",
    "section": "",
    "text": "import torch\nimport torchvision\nimport torchvision.transforms as transforms\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\nbatch_size = 4\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# functions to show an image\n\n\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(trainloader)\nimages, labels = next(dataiter)\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\n\n\n\n\n\n\n\n\nplane deer  horse plane"
  },
  {
    "objectID": "ai/pt/pt_data.html#creating-a-dataloader",
    "href": "ai/pt/pt_data.html#creating-a-dataloader",
    "title": "Loading data",
    "section": "Creating a DataLoader",
    "text": "Creating a DataLoader\nA DataLoader is an iterable feeding data to a model. When we train a model, we run it for each element of the DataLoader in a for loop:\nfor i in data_loader:\n    &lt;some model&gt;"
  },
  {
    "objectID": "ai/pt/pt_hpc.html",
    "href": "ai/pt/pt_hpc.html",
    "title": "Deep learning on production clusters",
    "section": "",
    "text": "This section is a summary of relevant information while using Python in an HPC context for deep learning.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "DL on production clusters"
    ]
  },
  {
    "objectID": "ai/pt/pt_hpc.html#run-code-in-a-job",
    "href": "ai/pt/pt_hpc.html#run-code-in-a-job",
    "title": "Deep learning on production clusters",
    "section": "Run code in a job",
    "text": "Run code in a job\nWhen you ssh into one of the Alliance clusters, you log into the login node.\nEverybody using a cluster uses that node to enter the cluster. Do not run anything computationally intensive on this node or you would make the entire cluster very slow for everyone. To run your code, you need to start an interactive job or submit a batch job to Slurm (the job scheduler used by the Alliance clusters).",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "DL on production clusters"
    ]
  },
  {
    "objectID": "ai/pt/pt_hpc.html#plots",
    "href": "ai/pt/pt_hpc.html#plots",
    "title": "Deep learning on production clusters",
    "section": "Plots",
    "text": "Plots\nDo not run code that displays plots on screen. Instead, have them written to files.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "DL on production clusters"
    ]
  },
  {
    "objectID": "ai/pt/pt_hpc.html#data",
    "href": "ai/pt/pt_hpc.html#data",
    "title": "Deep learning on production clusters",
    "section": "Data",
    "text": "Data\n\nCopy files to/from the cluster\n\nFew files\nIf you need to copy files to or from the cluster, you can use scp from your local machine.\nCopy file from your computer to the cluster:\n[local]$ scp &lt;/local/path/to/file&gt; &lt;user&gt;@&lt;hostname&gt;:&lt;path/in/cluster&gt;\n\nExpressions between the &lt; and &gt; signs need to be replaced by the relevant information (without those signs).\n\nCopy file from the cluster to your computer:\n[local]$ scp &lt;user&gt;@&lt;hostname&gt;:&lt;cluster/path/to/file&gt; &lt;/local/path&gt;\n\n\nLarge amount of data\nUse Globus for large data transfers.\n\nThe Alliance is starting to store classic ML datasets on its clusters. So if your research uses a common dataset, it may be worth inquiring whether it might be available before downloading a copy.\n\n\n\n\nLarge collections of files\nThe Alliance clusters are optimized for very large files and are slowed by large collections of small files. Datasets with many small files need to be turned into single-file archives with tar. Failing to do so will affect performance not just for you, but for all users of the cluster.\n$ tar cf &lt;data&gt;.tar &lt;path/to/dataset/directory&gt;/*\n\n\nIf you want to also compress the files, replace tar cf with tar czf\nAs a modern alternative to tar, you can use Dar",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "DL on production clusters"
    ]
  },
  {
    "objectID": "ai/pt/pt_hpc.html#interactive-jobs",
    "href": "ai/pt/pt_hpc.html#interactive-jobs",
    "title": "Deep learning on production clusters",
    "section": "Interactive jobs",
    "text": "Interactive jobs\nInteractive jobs are useful for code testing and development. They are not however the most efficient way to run code, so you should limit their use to testing and development.\nYou start an interactive job with:\n$ salloc --account=def-&lt;account&gt; --cpus-per-task=&lt;n&gt; --gres=gpu:&lt;n&gt; --mem=&lt;mem&gt; --time=&lt;time&gt;\nOur training cluster does not have GPUs, so for this workshop, do not use the --gres=gpu:&lt;n&gt; option.\nFor the workshop, you also don‚Äôt have to worry about the --account=def-&lt;account&gt; option (or, if you want, you can use --account=def-sponsor00).\nOur training cluster has a total of 60 CPUs on 5 compute nodes. Since there are many of you in this workshop, please be very mindful when running interactive jobs: if you request a lot of CPUs for a long time, the other workshop attendees won‚Äôt be able to use the cluster anymore until your interactive job requested time ends (even if you aren‚Äôt running any code).\nHere are my suggestions so that we don‚Äôt run into this problem:\n\nOnly start interactive jobs when you need to understand what Python is doing at every step, or to test, explore, and develop code (so where an interactive Python shell is really beneficial). Once you have a model, submit a batch job to Slurm instead\nWhen running interactive jobs on this training cluster, only request 1 CPU (so --cpus-per-task=1)\nOnly request the time that you will really use (e.g.¬†for the lesson on Python tensors, maybe 30 min to 1 hour seems reasonable)\nIf you don‚Äôt need your job allocation anymore before it runs out, you can relinquish it with Ctrl+d\n\n\nBe aware that, on Cedar, you are not allowed to submit jobs from ~/home. Instead, you have to submit jobs from ~/scratch or ~/project.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "DL on production clusters"
    ]
  },
  {
    "objectID": "ai/pt/pt_hpc.html#batch-jobs",
    "href": "ai/pt/pt_hpc.html#batch-jobs",
    "title": "Deep learning on production clusters",
    "section": "Batch jobs",
    "text": "Batch jobs\nAs soon as you have a working Python script, you want to submit a batch job instead of running an interactive job. To do that, you need to write an sbatch script.\n\nJob script\n\nHere is an example script:\n\n#!/bin/bash\n#SBATCH --job-name=&lt;name&gt;*            # job name\n#SBATCH --account=def-&lt;account&gt;\n#SBATCH --time=&lt;time&gt;                 # max walltime in D-HH:MM or HH:MM:SS\n#SBATCH --cpus-per-task=&lt;number&gt;      # number of cores\n#SBATCH --gres=gpu:&lt;type&gt;:&lt;number&gt;    # type and number of GPU(s) per node\n#SBATCH --mem=&lt;mem&gt;                   # max memory (default unit is MB) per node\n#SBATCH --output=%x_%j.out*           # file name for the output\n#SBATCH --error=%x_%j.err*            # file name for errors\n#SBATCH --mail-user=&lt;email_address&gt;*\n#SBATCH --mail-type=ALL*\n\n# Load modules\n# (Do not use this in our workshop since we aren't using GPUs)\n# (Note: loading the Python module is not necessary\n# when you activate a Python virtual environment)\n# module load cudacore/.10.1.243 cuda/10 cudnn/7.6.5\n\n# Create a variable with the directory for your ML project\nSOURCEDIR=~/&lt;path/project/dir&gt;\n\n# Activate your Python virtual environment\nsource ~/env/bin/activate\n\n# Transfer and extract data to a compute node\nmkdir $SLURM_TMPDIR/data\ntar xf ~/projects/def-&lt;user&gt;/&lt;data&gt;.tar -C $SLURM_TMPDIR/data\n\n# Run your Python script on the data\npython $SOURCEDIR/&lt;script&gt;.py $SLURM_TMPDIR/data\n\n\n%x will get replaced by the script name and %j by the job number\nIf you compressed your data with tar czf, you need to extract it with tar xzf\nSBATCH options marked with a * are optional\nThere are various other options for email notifications\n\n\nYou may wonder why we transferred data to a compute node. This makes any I/O operation involving your data a lot faster, so it will speed up your code. Here is how this works:\nFirst, we create a temporary data directory in $SLURM_TMPDIR:\n$ mkdir $SLURM_TMPDIR/data\n\nThe variable $SLURM_TMPDIR is created by Slurm on the compute node where a job is running. Its path is /localscratch/&lt;user&gt;.&lt;jobid&gt;.0. Anything in it gets deleted when the job is done.\n\nThen we extract the data into it:\n$ tar xf ~/projects/def-&lt;user&gt;/&lt;data&gt;.tar -C $SLURM_TMPDIR/data\nIf your data is not in a tar file, you can simply copy it to the compute node running your job:\n$ cp -r ~/projects/def-&lt;user&gt;/&lt;data&gt; $SLURM_TMPDIR/data\n\n\nJob handling\n\nSubmit a job\n$ cd &lt;/dir/containing/job&gt;\n$ sbatch &lt;jobscript&gt;.sh\n\n\nCheck the status of your job(s)\n$ sq\n\nPD = pending\nR = running\nCG = completing (Slurm is doing the closing processes)\nNo information = your job has finished running\n\n\n\nCancel a job\n$ scancel &lt;jobid&gt;\n\n\nEfficiency of completed job\n$ seff &lt;jobid&gt;",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "DL on production clusters"
    ]
  },
  {
    "objectID": "ai/pt/pt_hpc.html#gpus",
    "href": "ai/pt/pt_hpc.html#gpus",
    "title": "Deep learning on production clusters",
    "section": "GPU(s)",
    "text": "GPU(s)\n\nGPU types\nSeveral Alliance clusters have GPUs. Their numbers and types differ:\n\n\n\nfrom the Alliance Wiki\n\n\nThe default is 12G P100, but you can request another type with SBATCH --gres=gpu:&lt;type&gt;:&lt;number&gt; (example: --gres=gpu:p100l:1 to request a 16G P100 on Cedar). Please refer to the Alliance Wiki for more details.\n\n\nNumber of GPU(s)\nTry running your model on a single GPU first.\nIt is very likely that you do not need more than one GPU. Asking for more than you need will greatly increase your waiting time until your job is run. The lesson on distributed computing with PyTorch gives a few information as to when you might benefit from using several GPUs and provides some links to more resources. We will also offer workshops on distributed ML in the future. In any event, you should test your model before asking for several GPUs.\n\n\nCPU/GPU ratio\nHere are the Alliance recommendations:\nB√©luga:\nNo more than 10 CPU per GPU.\nCedar:\nP100 GPU: no more than 6 CPU per GPU.\nV100 GPU: no more than 8 CPU per GPU.\nGraham:\nNo more than 16 CPU per GPU.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "DL on production clusters"
    ]
  },
  {
    "objectID": "ai/pt/pt_hpc.html#code-testing",
    "href": "ai/pt/pt_hpc.html#code-testing",
    "title": "Deep learning on production clusters",
    "section": "Code testing",
    "text": "Code testing\nIt might be wise to test your code in an interactive job before submitting a really big batch job to Slurm.\n\nActivate your virtual environment\n$ source ~/env/bin/activate\n\n\nStart an interactive job\n\nExample:\n\n$ salloc --account=def-&lt;account&gt; --gres=gpu:1 --cpus-per-task=6 --mem=32000 --time=0:30:0\n\n\nPrepare the data\nCreate a temporary data directory in $SLURM_TMPDIR:\n(env) $ mkdir $SLURM_TMPDIR/data\n\nThe variable $SLURM_TMPDIR is created by Slurm on the compute node where a job is running. Its path is /localscratch/&lt;user&gt;.&lt;jobid&gt;.0. Anything in it gets deleted when the job is done.\n\nExtract the data into it:\n(env) $ tar xf ~/projects/def-&lt;user&gt;/&lt;data&gt;.tar -C $SLURM_TMPDIR/data\n\n\nTry to run your code\nPlay in Python to test your code:\n(env) $ python\n&gt;&gt;&gt; import torch\n&gt;&gt;&gt; ...\nTo exit the virtual environment, run:\n(env) $ deactivate",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "DL on production clusters"
    ]
  },
  {
    "objectID": "ai/pt/pt_hpc.html#checkpoints",
    "href": "ai/pt/pt_hpc.html#checkpoints",
    "title": "Deep learning on production clusters",
    "section": "Checkpoints",
    "text": "Checkpoints\nLong jobs should have a checkpoint at least every 24 hours. This ensures that an outage won‚Äôt lead to days of computation lost and it will help get the job started by the scheduler sooner.\nFor instance, you might want to have checkpoints every n epochs (choose n so that n epochs take less than 24 hours to run).\nIn PyTorch, you can create dictionaries with all the information necessary and save them as .tar files with torch.save(). You can then load them back with torch.load().\nThe information you want to save in each checkpoint includes the model‚Äôs state_dict, the optimizer‚Äôs state_dict, the epoch at which you stopped, the latest training loss, and anything else needed to restart training where you left off.\n\nFor example, saving a checkpoint during training could look something like this:\n\ntorch.save({\n    'epoch': &lt;last epoch run&gt;,\n    'model_state_dict': net.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'loss': &lt;latest loss&gt;,\n}, &lt;path/to/checkpoint-file.tar&gt;)\n\nTo restart, initialize the model and optimizer, load the dictionary, and resume training:\n\n# Initialize the model and optimizer\nmodel = &lt;your model&gt;\noptimizer = &lt;your optimizer&gt;\n\n# Load the dictionary\ncheckpoint = torch.load(&lt;path/to/checkpoint-file.tar&gt;)\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\n\n# Resume training\nmodel.train()",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "DL on production clusters"
    ]
  },
  {
    "objectID": "ai/pt/pt_hpc.html#tensorboard-on-the-cluster",
    "href": "ai/pt/pt_hpc.html#tensorboard-on-the-cluster",
    "title": "Deep learning on production clusters",
    "section": "TensorBoard on the cluster",
    "text": "TensorBoard on the cluster\nTensorBoard allows to visually track your model metrics (e.g.¬†loss, accuracy, model graph, etc.). It requires a lot of processing power however, so if you want to use it on an Alliance cluster, do not run it from the login node. Instead, run it as part of your job. This section guides you through the whole workflow.\n\nLaunch TensorBoard\nFirst, you need to launch TensorBoard in the background (with a trailing &) before running your Python script. To do so, ad to your sbatch script:\ntensorboard --logdir=/tmp/&lt;your log dir&gt; --host 0.0.0.0 &\n\nExample:\n\n#!/bin/bash\n#SBATCH ...\n...\n\ntensorboard --logdir=/tmp/&lt;your log dir&gt; --host 0.0.0.0 &\npython $SOURCEDIR/&lt;script&gt;.py $SLURM_TMPDIR/data\n\n\nConnection with your computer\nOnce the job is running, you need to create a connection between the compute node running TensorBoard and your computer.\nFirst, you need to find the hostname of the compute node running the Tensorboard server. This is the value under NODELIST for your job when you run:\n$ sq\nThen, from your computer, enter this ssh command:\n[local]$ ssh -N -f -L localhost:6006:&lt;node hostname&gt;:6006 &lt;user&gt;@&lt;cluster&gt;.computecanada.ca\n\nReplace &lt;node hostname&gt; by the compute node hostname you just identified, &lt;user&gt; by your user name, and &lt;cluster&gt; by the name of the Alliance cluster hostname‚Äîe.g.¬†beluga, cedar, graham.\n\n\n\nAccess TensorBoard\nYou can now open a browser (on your computer) and go to http://localhost:6006 to monitor your model running on a compute node in the cluster!",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "DL on production clusters"
    ]
  },
  {
    "objectID": "ai/pt/pt_hpc.html#running-several-similar-jobs",
    "href": "ai/pt/pt_hpc.html#running-several-similar-jobs",
    "title": "Deep learning on production clusters",
    "section": "Running several similar jobs",
    "text": "Running several similar jobs\nA number of ML tasks (e.g.¬†hyperparameter optimization) require running several instances of similar jobs. Grouping them into a single job with GLOST or GNU Parallel reduces the stress on the scheduler.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "DL on production clusters"
    ]
  },
  {
    "objectID": "ai/pt/pt_intro_content.html",
    "href": "ai/pt/pt_intro_content.html",
    "title": "Introduction to machine learning",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Introduction",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/pt_intro_content.html#definitions",
    "href": "ai/pt/pt_intro_content.html#definitions",
    "title": "Introduction to machine learning",
    "section": "Definitions",
    "text": "Definitions\n\nArtificial intelligence (AI)\nAny human-made system mimicking animal intelligence. This is a large and very diverse field.\n\n\nMachine learning (ML)\nA subfield of AI that can be defined as computer programs whose performance at a task improves with experience.\n\n\nDeep learning (DL)\nA subfield of ML using artificial neural networks with two or more hidden layers.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Introduction",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/pt_intro_content.html#why-has-ml-become-so-popular",
    "href": "ai/pt/pt_intro_content.html#why-has-ml-become-so-popular",
    "title": "Introduction to machine learning",
    "section": "Why has ML become so popular?",
    "text": "Why has ML become so popular?\n\nNew types of tasks\nMachine learning achieves previously impossible tasks.\n\nLet‚Äôs take the example of image recognition:\n\nIn typical computing, a programmer writes code that gives a computer detailed instructions of what to do.\nCoding all the possible ways‚Äîpixel by pixel‚Äîthat an image can represent, say, a dog is an impossibly large task: there are many breeds of dogs, the image can be a picture, a blurred picture, a drawing, a cartoon, the dog can be in all sorts of positions, wearing clothes, etc.\nThere just aren‚Äôt enough resources to make the traditional programming approach able to create a computer program that can identify a dog in images.\nBy feeding a very large number of dog images to a neural network however, we can train that network to recognize dogs in images that it has never seen (without explicitly programming how it does this!).\n\n\nOld concept ‚Ä¶\n‚Ä¶ new computing power.\nThe concept is everything but new: Arthur Samuel came up with it in 1949 and built a self-learning Checkers-playing program in 1959.\n\n\n\nMachine learning consists of feeding vast amounts of data to algorithms to strengthen pathways, so the excitement for the approach became somewhat dormant due to the lack of computing power and the lack of training data at the time.\n The advent of powerful computers, GPUs, and massive amounts of data have brought the old concept to the forefront.\n\n\n\n\n\n\nFrom xkcd.com",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Introduction",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/pt_intro_content.html#how-does-it-work",
    "href": "ai/pt/pt_intro_content.html#how-does-it-work",
    "title": "Introduction to machine learning",
    "section": "How does it work?",
    "text": "How does it work?\nIt depends on the type of learning.\n\nSupervised learning\n\nRegression is a form of supervised learning with continuous outputs.\nClassification is supervised learning with discrete outputs.\n\nSupervised learning uses training data in the form of example input/output pairs.\nGoal: find the relationship between inputs and outputs.\n\n\nUnsupervised learning\nClustering, social network analysis, market segmentation, PCA ‚Ä¶ are all forms of unsupervised learning.\nUnsupervised learning uses unlabelled data.\nGoal: find structure within the data.\n\n\nReinforcement learning\nThe algorithm explores by performing random actions and these actions are rewarded or punished (bonus points or penalties).\nThis is how algorithms learn to play games.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Introduction",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/pt_intro_content.html#the-case-of-supervised-learning",
    "href": "ai/pt/pt_intro_content.html#the-case-of-supervised-learning",
    "title": "Introduction to machine learning",
    "section": "The case of supervised learning",
    "text": "The case of supervised learning\n\nDecide on an architecture\n\nThe architecture won‚Äôt change during training.\nThe type of architecture you choose (e.g.¬†CNN, Transformer) depends on the type of data you have (e.g.¬†vision, textual). The depth and breadth of your network depend on the amount of data and computing resource you have.\n\n\nSet some initial parameters\n\nYou can initialize them randomly or get much better ones through transfer learning.\nWhile the parameters are also part of the model, those will change during training.\n\n\nGet some labelled data\n\nWhen we say that we need a lot of data for machine learning, we mean ‚Äúlots of labelled data‚Äù as this is what gets used for training models.\n\n\nMake sure to keep data for testing\n\nThose data won‚Äôt be used for training the model. Often people keep around 20% of their data for testing.\n\n\nPass data and parameters\n\nThe train data are the inputs and the process of calculating the outputs is the forward pass.\n\n\nThe outputs are predictions\n\n\n\nCompare predictions with labels\n\nSince our data was labelled, we know what the true outputs are.\n\n\nCalculate train loss\n\nThe deviation of our predictions from the true outputs gives us a measure of training loss.\n\n\nAdjust parameters\n\nThe parameters get automatically adjusted to reduce the training loss through the mechanism of backpropagation. This is the actual training part.\nThis process is repeated many times. Training models is pretty much a giant for loop.\n\n\nFrom model to program\n\nRemember that the model architecture is fixed, but that the parameters change at each iteration of the training process.\nWhile the labelled data are key to training, what we are really interested in is the combination of architecture + final parameters.\n\nWhen the training is over, the parameters become fixed. Which means that our model now behaves like a classic program.\n\n\n\nEvaluate the model\n\nWe can now use the testing set (which was never used to train the model) to evaluate our model: if we pass the test inputs through our program, we get some predictions that we can compare to the test labels (which are the true outputs).\nThis gives us the test loss: a measure of how well our model performs.\n\n\nUse the model\n\nNow that we have a program, we can use it on unlabelled inputs to get what people ultimately want: unknown outputs.\nThis is when we put our model to actual use to solve some problem.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Introduction",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/pt_mnist.html",
    "href": "ai/pt/pt_mnist.html",
    "title": "Example: classifying the MNIST dataset",
    "section": "",
    "text": "Here is an example you can try on your own after the workshop: the classification of the MNIST dataset‚Äîa classic of machine learning.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Example: the MNIST"
    ]
  },
  {
    "objectID": "ai/pt/pt_mnist.html#the-mnist-dataset",
    "href": "ai/pt/pt_mnist.html#the-mnist-dataset",
    "title": "Example: classifying the MNIST dataset",
    "section": "The MNIST dataset",
    "text": "The MNIST dataset\nThe MNIST is a classic dataset commonly used for testing machine learning systems. It consists of pairs of images of handwritten digits and their corresponding labels.\nThe images are composed of 28x28 pixels of greyscale RGB codes ranging from 0 to 255 and the labels are the digits from 0 to 9 that each image represents.\nThere are 60,000 training pairs and 10,000 testing pairs.\nThe goal is to build a neural network which can learn from the training set to properly identify the handwritten digits and which will perform well when presented with the testing set that it has never seen. This is a typical case of supervised learning.\n\nNow, let‚Äôs explore the MNIST with PyTorch.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Example: the MNIST"
    ]
  },
  {
    "objectID": "ai/pt/pt_mnist.html#prepare-data",
    "href": "ai/pt/pt_mnist.html#prepare-data",
    "title": "Example: classifying the MNIST dataset",
    "section": "Prepare data",
    "text": "Prepare data\nFirst we need to download, unzip, and transform the data.\n\nWhere to store data in clusters\nWe will all use the same data. It would make little sense to all download it in our home directory.\nOn the Alliance clusters, a good place to store data shared amongst members of a project is in the /project file system.\nYou usually belong to /project/def-&lt;group&gt;, where &lt;group&gt; is the name of your PI. You can access it from your home directory through the symbolic link ~/projects/def-&lt;group&gt;.\nIn our training cluster, we are all part of the group def-sponsor00, accessible through /project/def-sponsor00 (or the hyperlink ~/projects/def-sponsor00).\nWe will thus all access the MNIST data in ~/projects/def-sponsor00/data.\n\n\nHow to obtain the data?\nThe dataset can be downloaded directly from the MNIST website, but the PyTorch package TorchVision has tools to download and transform several classic vision datasets, including the MNIST.\nhelp(torchvision.datasets.MNIST)\nHelp on class MNIST in module torchvision.datasets.mnist:\n\nclass MNIST(torchvision.datasets.vision.VisionDataset)\n\n |  MNIST(root: str, train: bool = True, \n |    transform: Optional[Callable] = None,\n |    target_transform: Optional[Callable] = None, \n |    download: bool = False) -&gt; None\n |   \n |  Args:\n |    root (string): Root directory of dataset where \n |      MNIST/raw/train-images-idx3-ubyte and \n |      MNIST/raw/t10k-images-idx3-ubyte exists.\n |    train (bool, optional): If True, creates dataset from \n |      train-images-idx3-ubyte, otherwise from t10k-images-idx3-ubyte.\n |    download (bool, optional): If True, downloads the dataset from the \n |      internet and puts it in root directory. If dataset is already \n |      downloaded, it is not downloaded again.\n |    transform (callable, optional): A function/transform that takes in \n |      an PIL image and returns a transformed version.\n |      E.g, transforms.RandomCrop\n |    target_transform (callable, optional): A function/transform that \n |      takes in the target and transforms it.\nNote that here too, the root argument sets the location of the downloaded data and we will use /project/def-sponsor00/data/.\n\n\nPrepare the data\nFirst, let‚Äôs load the needed libraries:\n\nimport torch\nfrom torchvision import datasets, transforms\nfrom matplotlib import pyplot as plt\n\nThe MNIST dataset already consists of a training and a testing sets, so we don‚Äôt have to split the data manually. Instead, we can directly create 2 different objects with the same function (train=True selects the train set and train=False selects the test set).\nWe will transform the raw data to tensors and normalize them using the mean and standard deviation of the MNIST training set: 0.1307 and 0.3081 respectively (even though the mean and standard deviation of the test data are slightly different, it is important to normalize the test data with the values of the training data to apply the same treatment to both sets).\nSo we first need to define a transformation:\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\n\n\n\nWe can now create our data objects\n\nTraining data\n\nRemember that train=True selects the training set of the MNIST.\n\n\ntrain_data = datasets.MNIST(\n    '~/projects/def-sponsor00/data',\n    train=True, download=True, transform=transform)\n\n0.3%0.7%1.0%1.3%1.7%2.0%2.3%2.6%3.0%3.3%3.6%4.0%4.3%4.6%5.0%5.3%5.6%6.0%6.3%6.6%6.9%7.3%7.6%7.9%8.3%8.6%8.9%9.3%9.6%9.9%10.2%10.6%10.9%11.2%11.6%11.9%12.2%12.6%12.9%13.2%13.6%13.9%14.2%14.5%14.9%15.2%15.5%15.9%16.2%16.5%16.9%17.2%17.5%17.9%18.2%18.5%18.8%19.2%19.5%19.8%20.2%20.5%20.8%21.2%21.5%21.8%22.1%22.5%22.8%23.1%23.5%23.8%24.1%24.5%24.8%25.1%25.5%25.8%26.1%26.4%26.8%27.1%27.4%27.8%28.1%28.4%28.8%29.1%29.4%29.8%30.1%30.4%30.7%31.1%31.4%31.7%32.1%32.4%32.7%33.1%33.4%33.7%34.0%34.4%34.7%35.0%35.4%35.7%36.0%36.4%36.7%37.0%37.4%37.7%38.0%38.3%38.7%39.0%39.3%39.7%40.0%40.3%40.7%41.0%41.3%41.7%42.0%42.3%42.6%43.0%43.3%43.6%44.0%44.3%44.6%45.0%45.3%45.6%45.9%46.3%46.6%46.9%47.3%47.6%47.9%48.3%48.6%48.9%49.3%49.6%49.9%50.2%50.6%50.9%51.2%51.6%51.9%52.2%52.6%52.9%53.2%53.6%53.9%54.2%54.5%54.9%55.2%55.5%55.9%56.2%56.5%56.9%57.2%57.5%57.9%58.2%58.5%58.8%59.2%59.5%59.8%60.2%60.5%60.8%61.2%61.5%61.8%62.1%62.5%62.8%63.1%63.5%63.8%64.1%64.5%64.8%65.1%65.5%65.8%66.1%66.4%66.8%67.1%67.4%67.8%68.1%68.4%68.8%69.1%69.4%69.8%70.1%70.4%70.7%71.1%71.4%71.7%72.1%72.4%72.7%73.1%73.4%73.7%74.0%74.4%74.7%75.0%75.4%75.7%76.0%76.4%76.7%77.0%77.4%77.7%78.0%78.3%78.7%79.0%79.3%79.7%80.0%80.3%80.7%81.0%81.3%81.7%82.0%82.3%82.6%83.0%83.3%83.6%84.0%84.3%84.6%85.0%85.3%85.6%85.9%86.3%86.6%86.9%87.3%87.6%87.9%88.3%88.6%88.9%89.3%89.6%89.9%90.2%90.6%90.9%91.2%91.6%91.9%92.2%92.6%92.9%93.2%93.6%93.9%94.2%94.5%94.9%95.2%95.5%95.9%96.2%96.5%96.9%97.2%97.5%97.9%98.2%98.5%98.8%99.2%99.5%99.8%100.0%\n100.0%\n2.0%4.0%6.0%7.9%9.9%11.9%13.9%15.9%17.9%19.9%21.9%23.8%25.8%27.8%29.8%31.8%33.8%35.8%37.8%39.7%41.7%43.7%45.7%47.7%49.7%51.7%53.7%55.6%57.6%59.6%61.6%63.6%65.6%67.6%69.6%71.5%73.5%75.5%77.5%79.5%81.5%83.5%85.5%87.4%89.4%91.4%93.4%95.4%97.4%99.4%100.0%\n100.0%\n\n\n\n\nTest data\n\ntrain=False selects the test set.\n\n\ntest_data = datasets.MNIST(\n    '~/projects/def-sponsor00/data',\n    train=False, transform=transform)",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Example: the MNIST"
    ]
  },
  {
    "objectID": "ai/pt/pt_mnist.html#exploring-the-data",
    "href": "ai/pt/pt_mnist.html#exploring-the-data",
    "title": "Example: classifying the MNIST dataset",
    "section": "Exploring the data",
    "text": "Exploring the data\n\nData inspection\nFirst, let‚Äôs check the size of train_data:\n\nprint(len(train_data))\n\n60000\n\n\nThat makes sense since the MNIST‚Äôs training set has 60,000 pairs. train_data has 60,000 elements and we should expect each element to be of size 2 since it is a pair. Let‚Äôs double-check with the first element:\n\nprint(len(train_data[0]))\n\n2\n\n\nSo far, so good. We can print that first pair:\n\nprint(train_data[0])\n\n(tensor([[[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3860, -0.1951,\n          -0.1951, -0.1951,  1.1795,  1.3068,  1.8032, -0.0933,  1.6887,\n           2.8215,  2.7197,  1.1923, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.0424,  0.0340,  0.7722,  1.5359,  1.7396,  2.7960,\n           2.7960,  2.7960,  2.7960,  2.7960,  2.4396,  1.7650,  2.7960,\n           2.6560,  2.0578,  0.3904, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n           0.1995,  2.6051,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,\n           2.7960,  2.7960,  2.7960,  2.7706,  0.7595,  0.6195,  0.6195,\n           0.2886,  0.0722, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.1951,  2.3633,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,\n           2.0960,  1.8923,  2.7197,  2.6433, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242,  0.5940,  1.5614,  0.9377,  2.7960,  2.7960,  2.1851,\n          -0.2842, -0.4242,  0.1231,  1.5359, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.2460, -0.4115,  1.5359,  2.7960,  0.7213,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242,  1.3450,  2.7960,  1.9942,\n          -0.3988, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.2842,  1.9942,  2.7960,\n           0.4668, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.0213,  2.6433,\n           2.4396,  1.6123,  0.9504, -0.4115, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6068,\n           2.6306,  2.7960,  2.7960,  1.0904, -0.1060, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n           0.1486,  1.9432,  2.7960,  2.7960,  1.4850, -0.0806, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.2206,  0.7595,  2.7833,  2.7960,  1.9560, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242,  2.7451,  2.7960,  2.7451,  0.3904,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n           0.1613,  1.2305,  1.9051,  2.7960,  2.7960,  2.2105, -0.3988,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.0722,  1.4596,\n           2.4906,  2.7960,  2.7960,  2.7960,  2.7578,  1.8923, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.1187,  1.0268,  2.3887,  2.7960,\n           2.7960,  2.7960,  2.7960,  2.1342,  0.5686, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.1315,  0.4159,  2.2869,  2.7960,  2.7960,  2.7960,\n           2.7960,  2.0960,  0.6068, -0.3988, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.1951,\n           1.7523,  2.3633,  2.7960,  2.7960,  2.7960,  2.7960,  2.0578,\n           0.5940, -0.3097, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242,  0.2758,  1.7650,  2.4524,\n           2.7960,  2.7960,  2.7960,  2.7960,  2.6815,  1.2686, -0.2842,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242,  1.3068,  2.7960,  2.7960,\n           2.7960,  2.2742,  1.2941,  1.2559, -0.2206, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242]]]), 5)\n\n\nAnd you can see that it is a tuple with:\n\nprint(type(train_data[0]))\n\n&lt;class 'tuple'&gt;\n\n\nWhat is that tuple made of?\n\nprint(type(train_data[0][0]))\nprint(type(train_data[0][1]))\n\n&lt;class 'torch.Tensor'&gt;\n&lt;class 'int'&gt;\n\n\nIt is made of the tensor for the first image (remember that we transformed the images into tensors when we created the objects train_data and test_data) and the integer of the first label (which you can see is 5 when you print train_data[0][1]).\nSo since train_data[0][0] is the tensor representing the image of the first pair, let‚Äôs check its size:\n\nprint(train_data[0][0].size())\n\ntorch.Size([1, 28, 28])\n\n\nThat makes sense: a color image would have 3 layers of RGB values (so the size in the first dimension would be 3), but because the MNIST has black and white images, there is a single layer of values‚Äîthe values of each pixel on a gray scale‚Äîso the first dimension has a size of 1. The 2nd and 3rd dimensions correspond to the width and length of the image in pixels, hence 28 and 28.\n\n\nYour turn:\n\nRun the following:\nprint(train_data[0][0][0])\nprint(train_data[0][0][0][0])\nprint(train_data[0][0][0][0][0])\nAnd think about what each of them represents.\nThen explore the test_data object.\n\n\n\nPlotting an image\nFor this, we will use pyplot from matplotlib.\nFirst, we select the image of the first pair and we resize it from 3 to 2 dimensions by removing its dimension of size 1 with torch.squeeze:\nimg = torch.squeeze(train_data[0][0])\nThen, we plot it with pyplot, but since we are in a cluster, instead of showing it to screen with plt.show(), we save it to file:\nplt.imshow(img, cmap='gray')\nThis is what that first image looks like:\n\nAnd indeed, it matches the first label we explored earlier (train_data[0][1]).\n\n\nImage with pixel values\nWe can plot it with more details by showing the value of each pixel in the image. One little twist is that we need to pick a threshold value below which we print the pixel values in white otherwise they would not be visible (black on near black background). We also round the pixel values to one decimal digit so as not to clutter the result.\nimgplot = plt.figure(figsize = (12, 12))\nsub = imgplot.add_subplot(111)\nsub.imshow(img, cmap='gray')\nwidth, height = img.shape\nthresh = img.max() / 2.5\nfor x in range(width):\n    for y in range(height):\n        val = round(img[x][y].item(), 1)\n        sub.annotate(str(val), xy=(y, x),\n                     horizontalalignment='center',\n                     verticalalignment='center',\n                     color='white' if img[x][y].item() &lt; thresh else 'black')",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Example: the MNIST"
    ]
  },
  {
    "objectID": "ai/pt/pt_mnist.html#batch-processing",
    "href": "ai/pt/pt_mnist.html#batch-processing",
    "title": "Example: classifying the MNIST dataset",
    "section": "Batch processing",
    "text": "Batch processing\nPyTorch provides the torch.utils.data.DataLoader class which combines a dataset and an optional sampler and provides an iterable (while training or testing our neural network, we will iterate over that object). It allows, among many other things, to set the batch size and shuffle the data.\nSo our last step in preparing the data is to pass it through DataLoader.\n\nCreate DataLoaders\n\nTraining data\ntrain_loader = torch.utils.data.DataLoader(\n    train_data, batch_size=20, shuffle=True)\n\n\nTest data\ntest_loader = torch.utils.data.DataLoader(\n    test_data, batch_size=20, shuffle=False)\n\n\n\nPlot a batch of images with labels\nNow that we have passed our data through DataLoader, it is easy to select one batch from it. Let‚Äôs plot an entire batch of images with their labels.\nFirst, we need to get one batch of training images and their labels:\ndataiter = iter(train_loader)\nbatchimg, batchlabel = dataiter.next()\nThen, we can plot them:\nbatchplot = plt.figure(figsize=(20, 5))\nfor i in torch.arange(20):\n    sub = batchplot.add_subplot(2, 10, i+1, xticks=[], yticks=[])\n    sub.imshow(torch.squeeze(batchimg[i]), cmap='gray')\n    sub.set_title(str(batchlabel[i].item()), fontsize=25)",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Example: the MNIST"
    ]
  },
  {
    "objectID": "ai/pt/pt_mnist.html#nn-to-classify-the-mnist",
    "href": "ai/pt/pt_mnist.html#nn-to-classify-the-mnist",
    "title": "Example: classifying the MNIST dataset",
    "section": "NN to classify the MNIST",
    "text": "NN to classify the MNIST\nLet‚Äôs build a multi-layer perceptron (MLP): the simplest neural network. It is a feed-forward (i.e.¬†no loop), fully-connected (i.e.¬†each neuron of one layer is connected to all the neurons of the adjacent layers) neural network with a single hidden layer.\n\n\nLoad packages\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torchvision import datasets, transforms\nfrom torch.optim.lr_scheduler import StepLR\nThe torch.nn.functional module contains all the functions of the torch.nn package.\nThese functions include loss functions, activation functions, pooling functions‚Ä¶\n\n\nCreate SummaryWriter instance\nThis SummaryWritter instance will be used by TensorBoard.\nwriter = SummaryWriter()\n\n\nDefine network architecture\n# To build a model, create a subclass of torch.nn.Module:\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(784, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    # Method for the forward pass:\n    def forward(self, x):\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n        output = F.log_softmax(x, dim=1)\n        return output\nPython‚Äôs class inheritance gives our subclass all the functionality of torch.nn.Module while allowing us to customize it.\n\n\nDefine a training function\ndef train(model, device, train_loader, optimizer, epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()  # reset the gradients to 0\n        output = model(data)\n        loss = F.nll_loss(output, target)  # negative log likelihood\n        writer.add_scalar(\"Loss/train\", loss, epoch)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 10 == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n\n\nDefine a testing function\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            # Sum up batch loss:\n            test_loss += F.nll_loss(output, target, reduction='sum').item()\n            # Get the index of the max log-probability:\n            pred = output.argmax(dim=1, keepdim=True)\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n\n    # Print a summary\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\n\nDefine a function to run the network\ndef main():\n    epochs = 1\n    torch.manual_seed(1)\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.1307,), (0.3081,))\n    ])\n\n    train_data = datasets.MNIST(\n        '~/projects/def-sponsor00/data',\n        train=True, download=True, transform=transform)\n\n    test_data = datasets.MNIST(\n        '~/projects/def-sponsor00/data',\n        train=False, transform=transform)\n\n    train_loader = torch.utils.data.DataLoader(train_data, batch_size=64)\n    test_loader = torch.utils.data.DataLoader(test_data, batch_size=1000)\n    model = Net().to(device)  # create instance of our network and send it to device\n    optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n    scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n\n    for epoch in range(1, epochs + 1):\n        train(model, device, train_loader, optimizer, epoch)\n        test(model, device, test_loader)\n        scheduler.step()\n\n\nRun the network\nmain()\n\n\nClose TensorBoard\nNow we can write pending events to disk and close TensorBoard.\nwriter.flush()\nwriter.close()\nThe code is working. Time to actually train our model!\nJupyter is a fantastic tool. It has a major downside however: when you launch a Jupyter server, you are running a job on a compute node. If you want to play for 8 hours in Jupyter, you are requesting an 8 hour job. Now, most of the time you spend on Jupyter is spent typing, running bits and pieces of code, or doing nothing at all. If you ask for GPUs, many CPUs, and lots of RAM, all of it will remain idle almost all of the time. It is a really suboptimal use of the Alliance resources.\nIn addition, if you ask for lots of resources for a long time, you will have to wait a long time in the queue before they get allocated to you.\nLastly, you will go through your allocation quickly.\nA much better strategy is to develop and test your code (with very little data, few epochs, etc.) in an interactive job (with salloc) or in Jupyter, then, launch an sbatch job to actually train your model. This ensures that heavy duty resources such as GPU(s) are only allocated to you when you are actually needing and using them.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Example: the MNIST"
    ]
  },
  {
    "objectID": "ai/pt/pt_mnist.html#train-and-test-our-model",
    "href": "ai/pt/pt_mnist.html#train-and-test-our-model",
    "title": "Example: classifying the MNIST dataset",
    "section": "Train and test our model",
    "text": "Train and test our model\n\nLog in a cluster\nOpen a terminal and SSH to a cluster.\n\n\nLoad necessary modules\nFirst, we need to load the Python and CUDA modules. This is done with the Lmod tool through the module command. Here are some key Lmod commands:\n# Get help on the module command\n$ module help\n\n# List modules that are already loaded\n$ module list\n\n# See which modules are available for a tool\n$ module avail &lt;tool&gt;\n\n# Load a module\n$ module load &lt;module&gt;[/&lt;version&gt;]\nHere are the modules we need:\n$ module load nixpkgs/16.09 gcc/7.3.0 cuda/10.0.130 cudnn/7.6 python/3.8.2\n\n\nInstall Python packages\nYou also need the Python packages matplotlib, torch, torchvision, and tensorboard.\nOn the Alliance clusters, you need to create a virtual environment in which you install packages with pip, then activate that virtual environment.\n\nDo not use Anaconda.\nWhile Anaconda is a great tool on personal computers, it is not an appropriate tool when working on the Alliance clusters: binaries are unoptimized for those clusters and library paths are inconsistent with their architecture. Anaconda installs packages in $HOME where it creates a very large number of small files. It can also create conflicts by modifying .bashrc.\n\nCreate a virtual environment:\n$ virtualenv --no-download ~/env\nActivate the virtual environment:\n$ source ~/env/bin/activate\nUpdate pip:\n(env) $ pip install --no-index --upgrade pip\nInstall the packages you need in the virtual environment:\n(env) $ pip install --no-cache-dir --no-index matplotlib torch torchvision tensorboard\nIf you want to exit the virtual environment, you can press Ctrl-D or run:\n(env) $ deactivate\n\n\nWrite a Python script\nCreate a directory for this project and cd into it:\nmkdir mnist\ncd mnist\nStart a Python script with the text editor of your choice:\nnano nn.py\nIn it, copy-paste the code we played with in Jupyter, but this time have it run for 10 epochs:\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torchvision import datasets, transforms\nfrom torch.optim.lr_scheduler import StepLR\n\nwriter = SummaryWriter()\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(784, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n        output = F.log_softmax(x, dim=1)\n        return output\n\ndef train(model, device, train_loader, optimizer, epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        writer.add_scalar(\"Loss/train\", loss, epoch)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 10 == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, reduction='sum').item()\n            pred = output.argmax(dim=1, keepdim=True)\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\ndef main():\n    epochs = 10  # don't forget to change the number of epochs\n    torch.manual_seed(1)\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.1307,), (0.3081,))\n    ])\n\n    train_data = datasets.MNIST(\n        '~/projects/def-sponsor00/data',\n        train=True, download=True, transform=transform)\n\n    test_data = datasets.MNIST(\n        '~/projects/def-sponsor00/data',\n        train=False, transform=transform)\n\n    train_loader = torch.utils.data.DataLoader(train_data, batch_size=64)\n    test_loader = torch.utils.data.DataLoader(test_data, batch_size=1000)\n    model = Net().to(device)\n    optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n    scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n\n    for epoch in range(1, epochs + 1):\n        train(model, device, train_loader, optimizer, epoch)\n        test(model, device, test_loader)\n        scheduler.step()\n\nmain()\n\nwriter.flush()\nwriter.close()\n\n\nWrite a Slurm script\nWrite a shell script with the text editor of your choice:\nnano nn.sh\nThis is what you want in that script:\n#!/bin/bash\n#SBATCH --time=5:0\n#SBATCH --cpus-per-task=1\n#SBATCH --gres=gpu:1\n#SBATCH --mem=4G\n#SBATCH --output=%x_%j.out\n#SBATCH --error=%x_%j.err\n\npython ~/mnist/nn.py\n\n--time accepts these formats: ‚Äúmin‚Äù, ‚Äúmin:s‚Äù, ‚Äúh:min:s‚Äù, ‚Äúd-h‚Äù, ‚Äúd-h:min‚Äù & ‚Äúd-h:min:s‚Äù\n%x will get replaced by the script name & %j by the job number\n\n\n\nSubmit a job\nFinally, you need to submit your job to Slurm:\n$ sbatch ~/mnist/nn.sh\nYou can check the status of your job with:\n$ sq\n\nPD = pending\nR = running\nCG = completing (Slurm is doing the closing processes)\nNo information = your job has finished running\n\nYou can cancel it with:\n$ scancel &lt;jobid&gt;\nOnce your job has finished running, you can display efficiency measures with:\n$ seff &lt;jobid&gt;",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Example: the MNIST"
    ]
  },
  {
    "objectID": "ai/pt/pt_mnist.html#explore-model-metrics",
    "href": "ai/pt/pt_mnist.html#explore-model-metrics",
    "title": "Example: classifying the MNIST dataset",
    "section": "Explore model metrics",
    "text": "Explore model metrics\nTensorBoard is a web visualization toolkit developed by TensorFlow which can be used with PyTorch.\nBecause we have sent our model‚Äôs metrics logs to TensorBoard as part of our code, a directory called runs with those logs was created in our ~/mnist directory.\n\nLaunch TensorBoard\nTensorBoard requires too much processing power to be run on the login node. When you run long jobs, the best strategy is to launch it in the background as part of the job. This allows you to monitor your model as it is running (and cancel it if things don‚Äôt look right).\n\nExample:\n\n#!/bin/bash\n#SBATCH ...\n#SBATCH ...\n\ntensorboard --logdir=runs --host 0.0.0.0 &\npython ~/mnist/nn.py\nBecause we only have 1 GPU and are taking turns running our jobs, we need to keep our jobs very short here. So we will launch a separate job for TensorBoard. This time, we will launch an interactive job:\nsalloc --time=1:0:0 --mem=2000M\nTo launch TensorBoard, we need to activate our Python virtual environment (TensorBoard was installed by pip):\nsource ~/projects/def-sponsor00/env/bin/activate\nThen we can launch TensorBoard in the background:\ntensorboard --logdir=~/mnist/runs --host 0.0.0.0 &\nNow, we need to create a connection with SSH tunnelling between your computer and the compute note running your TensorBoard job.\n\n\nConnect to TensorBoard\nYou need to connect to TensorBoard from your computer to monitor the metrics.\nFrom a new terminal on your computer, run:\nssh -NfL localhost:6006:&lt;hostname&gt;:6006 userxxx@uu.c3.ca\n\nReplace &lt;hostname&gt; by the name of the compute node running your salloc job. You can find it by looking at your prompt (your prompt shows &lt;username&gt;@&lt;hostname&gt;).\nReplace &lt;userxxx&gt; by your user name.\n\nNow, you can open a browser on your computer and access TensorBoard at http://localhost:6006.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Example: the MNIST"
    ]
  },
  {
    "objectID": "ai/pt/pt_nn.html",
    "href": "ai/pt/pt_nn.html",
    "title": "Introduction to neural networks",
    "section": "",
    "text": "3Blue1Brown by Grant Sanderson has a series of 4 videos on neural networks which is easy to watch, fun, and does an excellent job at explaining the functioning of a simple neural network. In this section, we will watch the first 2 videos as an introduction to what neural networks are and how they learn.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Introduction to NN"
    ]
  },
  {
    "objectID": "ai/pt/pt_nn.html#what-are-nn",
    "href": "ai/pt/pt_nn.html#what-are-nn",
    "title": "Introduction to neural networks",
    "section": "What are NN?",
    "text": "What are NN?\n19 min video.\n\n\nAs you develop your own ML models, if you find that your mathematical background is shaky, 3blue1brown also has an excellent series of videos on linear algebra and an equally great one on calculus.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Introduction to NN"
    ]
  },
  {
    "objectID": "ai/pt/pt_nn.html#how-do-nn-learn",
    "href": "ai/pt/pt_nn.html#how-do-nn-learn",
    "title": "Introduction to neural networks",
    "section": "How do NN learn?",
    "text": "How do NN learn?\n21 min video.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Introduction to NN"
    ]
  },
  {
    "objectID": "ai/pt/pt_nn.html#types-of-nn",
    "href": "ai/pt/pt_nn.html#types-of-nn",
    "title": "Introduction to neural networks",
    "section": "Types of NN",
    "text": "Types of NN\nSlides (Click and wait: the presentation might take a few instants to load)\nSlides content for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Introduction to NN"
    ]
  },
  {
    "objectID": "ai/pt/pt_nn_slides.html#fully-connected-neural-networks",
    "href": "ai/pt/pt_nn_slides.html#fully-connected-neural-networks",
    "title": "NN vs biological neurons Types of NN",
    "section": "Fully connected neural networks",
    "text": "Fully connected neural networks\n\n\n\n\n\nfrom Glosser.ca, Wikipedia\n\n\n\nEach neuron receives inputs from every neuron of the previous layer and passes its output to every neuron of the next layer."
  },
  {
    "objectID": "ai/pt/pt_nn_slides.html#convolutional-neural-networks",
    "href": "ai/pt/pt_nn_slides.html#convolutional-neural-networks",
    "title": "NN vs biological neurons Types of NN",
    "section": "Convolutional neural networks",
    "text": "Convolutional neural networks\n\nfrom Programming Journeys by Rensu TheartConvolutional neural networks (CNN) are used for spatially structured data (e.g.¬†images).\nImages have huge input sizes and would require a very large number of neurons in a fully connected neural net. In convolutional layers, neurons receive input from a subarea (called local receptive field) of the previous layer. This greatly reduces the number of parameters. Optionally, pooling (combining the outputs of neurons in a subarea) reduces the data dimensions."
  },
  {
    "objectID": "ai/pt/pt_nn_slides.html#recurrent-neural-networks",
    "href": "ai/pt/pt_nn_slides.html#recurrent-neural-networks",
    "title": "NN vs biological neurons Types of NN",
    "section": "Recurrent neural networks",
    "text": "Recurrent neural networks\n\nfrom fdeloche, WikipediaRecurrent neural networks (RNN) such as Long Short-Term Memory (LSTM) are used for chain structured data (e.g.¬†text).\nThey are not feedforward networks (i.e.¬†networks for which the information moves only in the forward direction without any loop)."
  },
  {
    "objectID": "ai/pt/pt_nn_slides.html#transformers",
    "href": "ai/pt/pt_nn_slides.html#transformers",
    "title": "NN vs biological neurons Types of NN",
    "section": "Transformers",
    "text": "Transformers\nA combination of two RNNs (the encoder and the decoder) is used in sequence to sequence models for translation or picture captioning.\nIn 2014 the concept of attention (giving added weight to important words) was developed, greatly improving the ability of such models to process a lot of data.\nThe problem with recurrence is that it is not easily to parallelize (and thus to run fast on GPUs).\nIn 2017, a new model‚Äîthe transformer‚Äîwas proposed: by using only attention mechanisms and no recurrence, the transformer achieves better results in an easily parallelizable fashion.\nWith the addition of transfer learning, powerful transformers emerged in the field of NLP (e.g.¬†Bidirectional Encoder Representations from Transformers (BERT) from Google and Generative Pre-trained Transformer-3 (GPT-3) from OpenAI)."
  },
  {
    "objectID": "ai/pt/pt_resources.html",
    "href": "ai/pt/pt_resources.html",
    "title": "Resources",
    "section": "",
    "text": "This section contains a list of general machine learning resources, resources specific to PyTorch, as well as resources for Python and fastai.\n\n\nMachine learning\nAlliance wiki ML page\n\nOpen-access preprints\nArxiv Sanity Preserver by Andrej Karpathy\nML papers in the computer science category on arXiv\nML papers in the stats category on arXiv\nDistill ML research online journal\n\n\nAdvice and sources\nAdvice and sources from ML research student\n\n\nGetting help\nStack Overflow [machine-learning] tag\nStack Overflow [deep-learning] tag\nStack Overflow [supervised-learning] tag\nStack Overflow [unsupervised-learning] tag\nStack Overflow [semisupervised-learning] tag\nStack Overflow [reinforcement-learning] tag\nStack Overflow [transfer-learning] tag\nStack Overflow [machine-learning-model] tag\nStack Overflow [learning-rate] tag\nStack Overflow [bayesian-deep-learning] tag\n\n\nFree introductory courses\ndeeplearning.ai\nfast.ai\nGoogle\n\n\nLists of open datasets\nbenchmarks.ai\nAIBench\nkaggle\nWikipedia\n\n\n\nPyTorch\nAlliance wiki PyTorch page\n\n\nDocumentation\nPyTorch website\nPyTorch documentation\nPyTorch tutorials\nPyTorch online courses\nPyTorch examples\n\n\nGetting help\nPyTorch Discourse forum\nStack Overflow [pytorch] tag\nStack Overflow [pytorch-dataloader] tag\nStack Overflow [pytorch-ignite] tag\n\n\nPre-trained models\nPyTorch Hub\n\n\n\nPython\nAlliance wiki Python page\n\nIDE\nProject Jupyter\nList of IDEs with description\nComparison of IDEs\nEmacs Python IDE\n\n\nShell\nIPython\nbpython\nptpython\n\n\nGetting help\nStack Overflow [python] tag\n\n\n\nfastai\n\nDocumentation\nManual\nTutorials\nPeer-reviewed paper\n\n\nBook\nPaperback version\nFree MOOC version of part 1 of the book\nJupyter notebooks version of the book\n\n\nGetting help\nDiscourse forum",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "ai/pt/pt_tensors.html",
    "href": "ai/pt/pt_tensors.html",
    "title": "PyTorch tensors",
    "section": "",
    "text": "Before information can be processed by algorithms, it needs to be converted to floating point numbers. Indeed, you don‚Äôt pass a sentence or an image through a model; instead you input numbers representing a sequence of words or pixel values.\nAll these floating point numbers need to be stored in a data structure. The most suited structure is multidimensional (to hold several layers of information) and homogeneous‚Äîall data of the same type‚Äîfor efficiency.\nPython already has several multidimensional array structures (e.g.¬†NumPy‚Äôs ndarray) but the particularities of deep learning call for special characteristics such as the ability to run operations on GPUs and/or in a distributed fashion, the ability to keep track of computation graphs for automatic differentiation, and different defaults (lower precision for improved training performance).\nThe PyTorch tensor is a Python data structure with these characteristics that can easily be converted to/from NumPy‚Äôs ndarray and integrates well with other Python libraries such as Pandas.\nIn this section, we will explore the basics of PyTorch tensors.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "PyTorch tensors"
    ]
  },
  {
    "objectID": "ai/pt/pt_tensors.html#importing-pytorch",
    "href": "ai/pt/pt_tensors.html#importing-pytorch",
    "title": "PyTorch tensors",
    "section": "Importing PyTorch",
    "text": "Importing PyTorch\nFirst of all, we need to import the torch library:\n\nimport torch\n\nWe can check its version with:\n\ntorch.__version__\n\n'2.7.0+cu126'",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "PyTorch tensors"
    ]
  },
  {
    "objectID": "ai/pt/pt_tensors.html#creating-tensors",
    "href": "ai/pt/pt_tensors.html#creating-tensors",
    "title": "PyTorch tensors",
    "section": "Creating tensors",
    "text": "Creating tensors\nThere are many ways to create tensors:\n\ntorch.tensor: ‚ÄÉ‚ÄÉInput individual values\ntorch.arange: ‚ÄÉ‚ÄÉ1D tensor with a sequence of integers\ntorch.linspace: ‚ÄÉ1D linear scale tensor\ntorch.logspace: ‚ÄÉ1D log scale tensor\ntorch.rand: ‚ÄÉ‚ÄÉ‚ÄÉ¬†Random numbers from a uniform distribution on [0, 1)\ntorch.randn: ‚ÄÉ‚ÄÉ‚ÄÇ¬†Numbers from the standard normal distribution\ntorch.randperm: ‚ÄÉ¬†Random permutation of integers\ntorch.empty: ‚ÄÉ‚ÄÉ‚ÄÇ¬†Uninitialized tensor\ntorch.zeros: ‚ÄÉ‚ÄÉ‚ÄÇ¬†Tensor filled with 0\ntorch.ones: ‚ÄÉ‚ÄÉ‚ÄÉ¬†Tensor filled with 1\ntorch.eye: ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇ¬†¬†Identity matrix\n\n\nFrom input values\n\nt = torch.tensor(3)\n\n\n\nYour turn:\n\nWithout using the shape descriptor, try to get the shape of the following tensors:\ntorch.tensor([0.9704, 0.1339, 0.4841])\n\ntorch.tensor([[0.9524, 0.0354],\n        [0.9833, 0.2562],\n        [0.0607, 0.6420]])\n\ntorch.tensor([[[0.4604, 0.2699],\n         [0.8360, 0.0317],\n         [0.3289, 0.1171]]])\n\ntorch.tensor([[[[0.0730, 0.8737],\n          [0.2305, 0.4719],\n          [0.0796, 0.2745]]],\n\n        [[[0.1534, 0.9442],\n          [0.3287, 0.9040],\n          [0.0948, 0.1480]]]])\n\nLet‚Äôs create a random tensor with a single element:\n\nt = torch.rand(1)\nt\n\ntensor([0.1258])\n\n\nWe can extract the value from a tensor with one element:\n\nt.item()\n\n0.1257982850074768\n\n\nAll these tensors have a single element, but an increasing number of dimensions:\n\ntorch.rand(1)\n\ntensor([0.3900])\n\n\n\ntorch.rand(1, 1)\n\ntensor([[0.6882]])\n\n\n\ntorch.rand(1, 1, 1)\n\ntensor([[[0.0423]]])\n\n\n\ntorch.rand(1, 1, 1, 1)\n\ntensor([[[[0.3623]]]])\n\n\n\nYou can tell the number of dimensions of a tensor easily by counting the number of opening square brackets.\n\n\ntorch.rand(1, 1, 1, 1).dim()\n\n4\n\n\nTensors can have multiple elements in one dimension:\n\ntorch.rand(6)\n\ntensor([0.3194, 0.8324, 0.6842, 0.5462, 0.4335, 0.0477])\n\n\n\ntorch.rand(6).dim()\n\n1\n\n\nAnd multiple elements in multiple dimensions:\n\ntorch.rand(2, 3, 4, 5)\n\ntensor([[[[0.2751, 0.7491, 0.3606, 0.1847, 0.8210],\n          [0.8549, 0.7280, 0.6912, 0.3304, 0.3114],\n          [0.4724, 0.8165, 0.2218, 0.6130, 0.3458],\n          [0.6167, 0.2413, 0.8206, 0.5638, 0.0965]],\n\n         [[0.9852, 0.8703, 0.9640, 0.4937, 0.9714],\n          [0.9394, 0.5743, 0.9706, 0.0757, 0.7892],\n          [0.9826, 0.3664, 0.3062, 0.6258, 0.0423],\n          [0.0121, 0.7599, 0.6933, 0.6317, 0.8294]],\n\n         [[0.9104, 0.3898, 0.7956, 0.4905, 0.2473],\n          [0.0213, 0.9614, 0.4768, 0.8116, 0.2958],\n          [0.9169, 0.7930, 0.0436, 0.5157, 0.5013],\n          [0.4241, 0.3144, 0.1485, 0.6809, 0.7301]]],\n\n\n        [[[0.3292, 0.6150, 0.4489, 0.1435, 0.9072],\n          [0.5220, 0.7579, 0.6088, 0.5416, 0.7387],\n          [0.5016, 0.1188, 0.1102, 0.4963, 0.6499],\n          [0.4095, 0.9137, 0.9722, 0.5457, 0.5097]],\n\n         [[0.3042, 0.6062, 0.8467, 0.2048, 0.8266],\n          [0.0151, 0.9860, 0.2823, 0.8156, 0.0425],\n          [0.9102, 0.9277, 0.8388, 0.1567, 0.0447],\n          [0.6520, 0.5048, 0.7269, 0.2211, 0.4119]],\n\n         [[0.6430, 0.9144, 0.4872, 0.4569, 0.4097],\n          [0.5599, 0.1621, 0.3895, 0.4058, 0.1664],\n          [0.9839, 0.9917, 0.4786, 0.5395, 0.3695],\n          [0.9295, 0.4590, 0.2973, 0.9712, 0.3366]]]])\n\n\n\ntorch.rand(2, 3, 4, 5).dim()\n\n4\n\n\n\ntorch.rand(2, 3, 4, 5).numel()\n\n120\n\n\n\ntorch.ones(2, 4)\n\ntensor([[1., 1., 1., 1.],\n        [1., 1., 1., 1.]])\n\n\n\nt = torch.rand(2, 3)\ntorch.zeros_like(t)             # Matches the size of t\n\ntensor([[0., 0., 0.],\n        [0., 0., 0.]])\n\n\n\ntorch.ones_like(t)\n\ntensor([[1., 1., 1.],\n        [1., 1., 1.]])\n\n\n\ntorch.randn_like(t)\n\ntensor([[ 0.2893, -1.7632, -0.2417],\n        [-1.4069,  0.8735,  0.6806]])\n\n\n\ntorch.arange(2, 10, 3)    # From 2 to 10 in increments of 3\n\ntensor([2, 5, 8])\n\n\n\ntorch.linspace(2, 10, 3)  # 3 elements from 2 to 10 on the linear scale\n\ntensor([ 2.,  6., 10.])\n\n\n\ntorch.logspace(2, 10, 3)  # Same on the log scale\n\ntensor([1.0000e+02, 1.0000e+06, 1.0000e+10])\n\n\n\ntorch.randperm(3)\n\ntensor([2, 0, 1])\n\n\n\ntorch.eye(3)\n\ntensor([[1., 0., 0.],\n        [0., 1., 0.],\n        [0., 0., 1.]])",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "PyTorch tensors"
    ]
  },
  {
    "objectID": "ai/pt/pt_tensors.html#conversion-tofrom-numpy",
    "href": "ai/pt/pt_tensors.html#conversion-tofrom-numpy",
    "title": "PyTorch tensors",
    "section": "Conversion to/from NumPy",
    "text": "Conversion to/from NumPy\nPyTorch tensors can be converted to NumPy ndarrays and vice-versa in a very efficient manner as both objects share the same memory.\n\nFrom PyTorch tensor to NumPy ndarray\n\nt = torch.rand(2, 3)\nt\n\ntensor([[0.4518, 0.4918, 0.1410],\n        [0.9275, 0.2999, 0.2147]])\n\n\n\nt_np = t.numpy()\nt_np\n\narray([[0.45182675, 0.4917711 , 0.14095235],\n       [0.9274815 , 0.29993367, 0.2146874 ]], dtype=float32)\n\n\n\n\nFrom NumPy ndarray to PyTorch tensor\n\nimport numpy as np\na = np.random.rand(2, 3)\na\n\narray([[0.95829615, 0.14386425, 0.18845223],\n       [0.38030131, 0.26575602, 0.55428177]])\n\n\n\na_pt = torch.from_numpy(a)\na_pt\n\ntensor([[0.9583, 0.1439, 0.1885],\n        [0.3803, 0.2658, 0.5543]], dtype=torch.float64)\n\n\n\nNote the different default data types.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "PyTorch tensors"
    ]
  },
  {
    "objectID": "ai/pt/pt_tensors.html#indexing-tensors",
    "href": "ai/pt/pt_tensors.html#indexing-tensors",
    "title": "PyTorch tensors",
    "section": "Indexing tensors",
    "text": "Indexing tensors\n\nt = torch.rand(3, 4)\nt\n\ntensor([[0.0526, 0.0594, 0.8536, 0.7605],\n        [0.8433, 0.6671, 0.7284, 0.7912],\n        [0.1491, 0.4907, 0.3182, 0.5749]])\n\n\n\nt[:, 2]\n\ntensor([0.8536, 0.7284, 0.3182])\n\n\n\nt[1, :]\n\ntensor([0.8433, 0.6671, 0.7284, 0.7912])\n\n\n\nt[2, 3]\n\ntensor(0.5749)\n\n\n\nA word of caution about indexing\nWhile indexing elements of a tensor to extract some of the data as a final step of some computation is fine, you should not use indexing to run operations on tensor elements in a loop as this would be extremely inefficient.\nInstead, you want to use vectorized operations.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "PyTorch tensors"
    ]
  },
  {
    "objectID": "ai/pt/pt_tensors.html#vectorized-operations",
    "href": "ai/pt/pt_tensors.html#vectorized-operations",
    "title": "PyTorch tensors",
    "section": "Vectorized operations",
    "text": "Vectorized operations\nSince PyTorch tensors are homogeneous (i.e.¬†made of a single data type), as with NumPy‚Äôs ndarrays, operations are vectorized and thus fast.\nNumPy is mostly written in C, PyTorch in C++. With either library, when you run vectorized operations on arrays/tensors, you don‚Äôt use raw Python (slow) but compiled C/C++ code (much faster).\nHere is an excellent post explaining Python vectorization & why it makes such a big difference.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "PyTorch tensors"
    ]
  },
  {
    "objectID": "ai/pt/pt_tensors.html#data-types",
    "href": "ai/pt/pt_tensors.html#data-types",
    "title": "PyTorch tensors",
    "section": "Data types",
    "text": "Data types\n\nDefault data type\nSince PyTorch tensors were built with efficiency in mind for neural networks, the default data type is 32-bit floating points.\nThis is sufficient for accuracy and much faster than 64-bit floating points.\n\nBy contrast, NumPy ndarrays use 64-bit as their default.\n\n\nt = torch.rand(2, 4)\nt.dtype\n\ntorch.float32\n\n\n\n\nSetting data type at creation\nThe type can be set with the dtype argument:\n\nt = torch.rand(2, 4, dtype=torch.float64)\nt\n\ntensor([[0.0689, 0.1494, 0.6843, 0.0534],\n        [0.7135, 0.0026, 0.4056, 0.5815]], dtype=torch.float64)\n\n\n\nPrinted tensors display attributes with values ‚â† default values.\n\n\nt.dtype\n\ntorch.float64\n\n\n\n\nChanging data type\n\nt = torch.rand(2, 4)\nt.dtype\n\ntorch.float32\n\n\n\nt2 = t.type(torch.float64)\nt2.dtype\n\ntorch.float64\n\n\n\n\nList of data types\n\n\n\n\n\n\n\ndtype\nDescription\n\n\n\n\ntorch.float16 / torch.half\n16-bit / half-precision floating-point\n\n\ntorch.float32 / torch.float\n32-bit / single-precision floating-point\n\n\ntorch.float64 / torch.double\n64-bit / double-precision floating-point\n\n\ntorch.uint8\nunsigned 8-bit integers\n\n\ntorch.int8\nsigned 8-bit integers\n\n\ntorch.int16 / torch.short\nsigned 16-bit integers\n\n\ntorch.int32 / torch.int\nsigned 32-bit integers\n\n\ntorch.int64 / torch.long\nsigned 64-bit integers\n\n\ntorch.bool\nboolean",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "PyTorch tensors"
    ]
  },
  {
    "objectID": "ai/pt/pt_tensors.html#simple-operations",
    "href": "ai/pt/pt_tensors.html#simple-operations",
    "title": "PyTorch tensors",
    "section": "Simple operations",
    "text": "Simple operations\n\nt1 = torch.tensor([[1, 2], [3, 4]])\nt1\n\ntensor([[1, 2],\n        [3, 4]])\n\n\n\nt2 = torch.tensor([[1, 1], [0, 0]])\nt2\n\ntensor([[1, 1],\n        [0, 0]])\n\n\nOperation performed between elements at corresponding locations:\n\nt1 + t2\n\ntensor([[2, 3],\n        [3, 4]])\n\n\nOperation applied to each element of the tensor:\n\nt1 + 1\n\ntensor([[2, 3],\n        [4, 5]])\n\n\n\nReduction\n\nt = torch.ones(2, 3, 4);\nt\n\ntensor([[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]])\n\n\n\nt.sum()   # Reduction over all entries\n\ntensor(24.)\n\n\n\nOther reduction functions (e.g.¬†mean) behave the same way.\n\nReduction over a specific dimension:\n\nt.sum(0)\n\ntensor([[2., 2., 2., 2.],\n        [2., 2., 2., 2.],\n        [2., 2., 2., 2.]])\n\n\n\nt.sum(1)\n\ntensor([[3., 3., 3., 3.],\n        [3., 3., 3., 3.]])\n\n\n\nt.sum(2)\n\ntensor([[4., 4., 4.],\n        [4., 4., 4.]])\n\n\nReduction over multiple dimensions:\n\nt.sum((0, 1))\n\ntensor([6., 6., 6., 6.])\n\n\n\nt.sum((0, 2))\n\ntensor([8., 8., 8.])\n\n\n\nt.sum((1, 2))\n\ntensor([12., 12.])\n\n\n\n\nIn-place operations\nWith operators post-fixed with _:\n\nt1 = torch.tensor([1, 2])\nt1\n\ntensor([1, 2])\n\n\n\nt2 = torch.tensor([1, 1])\nt2\n\ntensor([1, 1])\n\n\n\nt1.add_(t2)\nt1\n\ntensor([2, 3])\n\n\n\nt1.zero_()\nt1\n\ntensor([0, 0])\n\n\n\nWhile reassignments will use new addresses in memory, in-place operations will use the same addresses.\n\n\n\nTensor views\nt = torch.tensor([[1, 2, 3], [4, 5, 6]]); print(t)\nt.size()\nt.view(6)\nt.view(3, 2)\nt.view(3, -1) # Same: with -1, the size is inferred from other dimensions\n\nNote the difference\n\nt1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\nt1\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\n\nt2 = t1.t()\nt2\n\ntensor([[1, 4],\n        [2, 5],\n        [3, 6]])\n\n\n\nt3 = t1.view(3, 2)\nt3\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\n\n\nLogical operations\n\nt1 = torch.randperm(5)\nt1\n\ntensor([2, 4, 0, 3, 1])\n\n\n\nt2 = torch.randperm(5)\nt2\n\ntensor([0, 3, 1, 2, 4])\n\n\nTest each element:\n\nt1 &gt; 3\n\ntensor([False,  True, False, False, False])\n\n\nTest corresponding pairs of elements:\n\nt1 &lt; t2\n\ntensor([False, False,  True, False,  True])",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "PyTorch tensors"
    ]
  },
  {
    "objectID": "ai/pt/pt_tensors.html#device-attribute",
    "href": "ai/pt/pt_tensors.html#device-attribute",
    "title": "PyTorch tensors",
    "section": "Device attribute",
    "text": "Device attribute\nTensor data can be placed in the memory of various processor types:\n\nthe RAM of CPU,\nthe RAM of a GPU with CUDA support,\nthe RAM of a GPU with AMD‚Äôs ROCm support,\nthe RAM of an XLA device (e.g.¬†Cloud TPU) with the torch_xla package.\n\nThe values for the device attributes are:\n\nCPU: ¬†'cpu',\nGPU (CUDA & AMD‚Äôs ROCm): ¬†'cuda',\nXLA: ¬†xm.xla_device().\n\nThis last option requires to load the torch_xla package first:\nimport torch_xla\nimport torch_xla.core.xla_model as xm\n\nCreating a tensor on a specific device\nBy default, tensors are created on the CPU.\nYou can create a tensor on an accelerator by specifying the device attribute (our current training cluster does not have GPUs, so don‚Äôt run this on it):\nt_gpu = torch.rand(2, device='cuda')\n\n\nCopying a tensor to a specific device\nYou can also make copies of a tensor on other devices:\n# Make a copy of t on the GPU\nt_gpu = t.to(device='cuda')\nt_gpu = t.cuda()             # Alternative syntax\n\n# Make a copy of t_gpu on the CPU\nt = t_gpu.to(device='cpu')\nt = t_gpu.cpu()              # Alternative syntax\n\n\nMultiple GPUs\nIf you have multiple GPUs, you can optionally specify which one a tensor should be created on or copied to:\nt1 = torch.rand(2, device='cuda:0')  # Create a tensor on 1st GPU\nt2 = t1.to(device='cuda:0')          # Make a copy of t1 on 1st GPU\nt3 = t1.to(device='cuda:1')          # Make a copy of t1 on 2nd GPU\nOr the equivalent short forms:\nt2 = t1.cuda(0)\nt3 = t1.cuda(1)",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "PyTorch tensors"
    ]
  },
  {
    "objectID": "ai/pt/pt_workflow.html",
    "href": "ai/pt/pt_workflow.html",
    "title": "Overall workflow",
    "section": "",
    "text": "This classic PyTorch tutorial goes over the entire workflow to create and train a simple image classifier.\nLet‚Äôs go over it step by step.",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Workflow"
    ]
  },
  {
    "objectID": "ai/pt/pt_workflow.html#the-data",
    "href": "ai/pt/pt_workflow.html#the-data",
    "title": "Overall workflow",
    "section": "The data",
    "text": "The data\nCIFAR-10 from the Canadian Institute for Advanced Research is a classic dataset of 60,000 color images falling into 10 classes (6,000 images in each class):\n\nairplane\nautomobile\nbird\ncat\ndeer\ndog\nfrog\nhorse\nship\ntruck\n\nThe images are of size 32x32 pixels (tiny!), which makes it very lightweight, quick to load and easy to play with.\n\nCreate a DataLoader\nA DataLoader is an iterable feeding data to a model at each iteration. The data loader transforms the data to the proper format, sets the batch size, whether the data is shuffled or not, and how the I/O is parallelized. You can create DataLoaders with the torch.utils.data.DataLoader class.\nLet‚Äôs create 2 DataLoaders: one for the train set and one for the test set.\n\nLoad packages\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\n\n\n\nCreate a transform object\nThe CIFAR-10 images in the TorchVision library are Image objects (from the PIL.Image module of the pillow package).\nWe need to normalize them and turn them into tensors:\n\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\n\n\nChoose a batch size\nRemember that the data move forward through the network (forward pass), outputting some estimates which are used to calculate some loss (or error) value. Then we get gradients through automatic differentiation and the model parameters are adjusted a little through gradient descent.\nYou do not have to have the entire training set go through this process each time: you can use batches.\nThe batch size is the number of items from the data that are processed before the model is updated. There is no hard rule to set good batch sizes and sizes tend to be picked through trial and error.\nHere are some rules to chose a batch size:\n\nmake sure that the batch fits in the CPU or GPU,\nsmall batches give faster results (each training iteration is very fast), but give less accuracy,\nlarge batches lead to slower training, but better accuracy.\n\nLet‚Äôs set the batch size to 4:\n\nbatch_size = 4\n\n\n\nPut it together into DataLoaders\n\ntrainset = torchvision.datasets.CIFAR10(root='./data',\n                                        train=True,\n                                        download=True,\n                                        transform=transform)\n\ntrainloader = torch.utils.data.DataLoader(trainset,\n                                          batch_size=batch_size,\n                                          shuffle=True,\n                                          num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='./data',\n                                       train=False,\n                                       download=True,\n                                       transform=transform)\n\ntestloader = torch.utils.data.DataLoader(testset,\n                                         batch_size=batch_size,\n                                         shuffle=False,\n                                         num_workers=2)\n\nWe will also need the classes:\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer',\n           'dog', 'frog', 'horse', 'ship', 'truck')\n\n\n\n\nVisualize a sample of the data\nThough not necessary, it can be useful to have a look at the data:\n\n# Load the packages for this\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define a function to display an image\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n# Get a batch of random training images\ndataiter = iter(trainloader)\nimages, labels = next(dataiter)\n\n# Display the images\nimshow(torchvision.utils.make_grid(images))\n\n# Print the labels\nprint(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\n\n\n\n\n\n\n\n\nship  ship  ship  ship",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Workflow"
    ]
  },
  {
    "objectID": "ai/pt/pt_workflow.html#the-model",
    "href": "ai/pt/pt_workflow.html#the-model",
    "title": "Overall workflow",
    "section": "The model",
    "text": "The model\n\nArchitecture\nFirst, we need to define the architecture of the network. There are many types of architectures. For images, CNN are well suited.\nIn Python, you can define a subclass of an existing class with:\nclass YourSubclass(BaseClass):\n    &lt;definition of your subclass&gt;        \nThe subclass is derived from the base class and inherits its properties. PyTorch contains the class torch.nn.Module which is used as the base class when defining a neural network.\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    # Define the architecture of the network\n    def __init__(self):\n        super().__init__()\n        # 3 input image channel (3 colour channels)\n        # 6 output channels,\n        # 5x5 square convolution kernel\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        # Max pooling over a (2, 2) window\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        # 5*5 from image dimension\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        # 10 is the size of the output layer\n        # since there are 10 classes\n        self.fc3 = nn.Linear(84, 10)\n\n    # Set the flow of data through the network for the forward pass\n    # x represents the data\n    def forward(self, x):\n        # F.relu is the rectified-linear activation function\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        # flatten all dimensions except the batch dimension\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nLet‚Äôs create an instance of Net and print its structure:\n\nnet = Net()\nprint(net)\n\nNet(\n  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)\n\n\n\n\nLoss function and optimizer\nWe need to chose a loss function that will be used to calculate the gradients through backpropagation as well as an optimizer to do the gradient descent.\nSGD with momentum has proved a very efficient optimizing technique and is widely used.\n\nimport torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Workflow"
    ]
  },
  {
    "objectID": "ai/pt/pt_workflow.html#training",
    "href": "ai/pt/pt_workflow.html#training",
    "title": "Overall workflow",
    "section": "Training",
    "text": "Training\nWe can now train the model:\n\nfor epoch in range(2):  # loop over the dataset twice\n\n    running_loss = 0.0\n\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n            running_loss = 0.0\n\nprint('Finished Training')\n\n[1,  2000] loss: 2.232\n[1,  4000] loss: 1.874\n[1,  6000] loss: 1.662\n[1,  8000] loss: 1.591\n[1, 10000] loss: 1.519\n[1, 12000] loss: 1.475\n[2,  2000] loss: 1.413\n[2,  4000] loss: 1.367\n[2,  6000] loss: 1.348\n[2,  8000] loss: 1.319\n[2, 10000] loss: 1.296\n[2, 12000] loss: 1.285\nFinished Training",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Workflow"
    ]
  },
  {
    "objectID": "ai/pt/pt_workflow.html#testing",
    "href": "ai/pt/pt_workflow.html#testing",
    "title": "Overall workflow",
    "section": "Testing",
    "text": "Testing\n\nLittle test on one batch for fun\nLet‚Äôs now test our model on one batch of testing data.\nFirst, let‚Äôs get a batch of random testing data:\n\ndataiter = iter(testloader)\nimages, labels = next(dataiter)\n\nLet‚Äôs display them and print their true labels:\n\nimshow(torchvision.utils.make_grid(images))\nprint('Real: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n\n\n\n\n\n\n\n\nReal:  cat   ship  ship  plane\n\n\nNow, let‚Äôs run the same batch of testing images through our model:\n\noutputs = net(images)\n\nLet‚Äôs get the best predictions for these:\n\n_, predicted = torch.max(outputs, 1)\n\nprint('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n                              for j in range(4)))\n\nPredicted:  frog  plane ship  ship \n\n\n\n\nMore serious testing\nThis was fun, but of course, with a sample of one, we can‚Äôt say anything about how good our model is. We need to test it on many more images from the test set.\nLet‚Äôs use the entire test set:\n\ncorrect = 0\ntotal = 0\n# since we're not training, we don't need to calculate the gradients for our outputs\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        # calculate outputs by running images through the network\n        outputs = net(images)\n        # the class with the highest energy is what we choose as prediction\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n\nAccuracy of the network on the 10000 test images: 54 %\n\n\n\n\nPer class testing\nWe could see whether the model seem to perform better for some classes than others:\n\n# prepare to count predictions for each class\ncorrect_pred = {classname: 0 for classname in classes}\ntotal_pred = {classname: 0 for classname in classes}\n\n# again no gradients needed\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predictions = torch.max(outputs, 1)\n        # collect the correct predictions for each class\n        for label, prediction in zip(labels, predictions):\n            if label == prediction:\n                correct_pred[classes[label]] += 1\n            total_pred[classes[label]] += 1\n\n\n# print accuracy for each class\nfor classname, correct_count in correct_pred.items():\n    accuracy = 100 * float(correct_count) / total_pred[classname]\n    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n\nAccuracy for class: plane is 51.0 %\nAccuracy for class: car   is 77.3 %\nAccuracy for class: bird  is 40.7 %\nAccuracy for class: cat   is 47.3 %\nAccuracy for class: deer  is 43.4 %\nAccuracy for class: dog   is 26.0 %\nAccuracy for class: frog  is 81.1 %\nAccuracy for class: horse is 50.0 %\nAccuracy for class: ship  is 62.2 %\nAccuracy for class: truck is 66.2 %",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with PyTorch</em></b>",
      "Workflow"
    ]
  },
  {
    "objectID": "ai/pt/wb_torchtensors.html",
    "href": "ai/pt/wb_torchtensors.html",
    "title": "Everything you wanted to know (and more) about PyTorch tensors",
    "section": "",
    "text": "Before information can be fed to artificial neural networks (ANNs), it needs to be converted to a form ANNs can process: floating point numbers. Indeed, you don‚Äôt pass a sentence or an image through an ANN; you input numbers representing a sequence of words or pixel values.\nAll these floating point numbers need to be stored in a data structure. The most suited structure is multidimensional (to hold several layers of information) and since all data is of the same type, it is an array.\nPython already has several multidimensional array structures‚Äîthe most popular of which being NumPy‚Äôs ndarray‚Äîbut the particularities of deep learning call for special characteristics: ability to run operations on GPUs and/or in a distributed fashion, as well as the ability to keep track of computation graphs for automatic differentiation.\nThe PyTorch tensor is a Python data structure with these characteristics that can also easily be converted to/from NumPy‚Äôs ndarray and integrates well with other Python libraries such as Pandas.\nIn this webinar, suitable for users of all levels, we will have a deep look at this data structure and go much beyond a basic introduction.\nIn particular, we will:\n\nsee how tensors are stored in memory,\nlook at the metadata which allows this efficient memory storage,\ncover the basics of working with tensors (indexing, vectorized operations‚Ä¶),\nmove tensors to/from GPUs,\nconvert tensors to/from NumPy ndarrays,\nsee how tensors work in distributed frameworks,\nsee how linear algebra can be done with PyTorch tensors.\n\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "PyTorch tensors in depth"
    ]
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#acknowledgements",
    "href": "ai/pt/wb_torchtensors_slides.html#acknowledgements",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMany drawings in this webinar come from the book:\n\nThe section on storage is also highly inspired by it"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#using-tensors-locally",
    "href": "ai/pt/wb_torchtensors_slides.html#using-tensors-locally",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Using tensors locally",
    "text": "Using tensors locally\nYou need to have Python and PyTorch installed\nAdditionally, you might want to use an IDE such as elpy if you are an Emacs user, JupyterLab, etc.\n\nNote that PyTorch does not yet support Python 3.10 except in some Linux distributions or on systems where a wheel has been built For the time being, you might have to use it with Python 3.9"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#using-tensors-on-cc-clusters",
    "href": "ai/pt/wb_torchtensors_slides.html#using-tensors-on-cc-clusters",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Using tensors on CC clusters",
    "text": "Using tensors on CC clusters\nList available wheels and compatible Python versions (in the terminal):\navail_wheels \"torch*\"\nList available Python versions:\nmodule avail python\nGet setup:\nmodule load python/3.9.6             # Load a sensible Python version\nvirtualenv --no-download env         # Create a virtual env\nsource env/bin/activate              # Activate the virtual env\npip install --no-index --upgrade pip # Update pip\npip install --no-index torch         # Install PyTorch\nYou can then launch jobs with sbatch or salloc\nLeave the virtual env with the command: deactivate"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#outline",
    "href": "ai/pt/wb_torchtensors_slides.html#outline",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Outline",
    "text": "Outline\n\nWhat is a PyTorch tensor?\nMemory storage\nData type (dtype)\nBasic operations\nWorking with NumPy\nLinear algebra\nHarvesting the power of GPUs\nDistributed operations"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#outline-1",
    "href": "ai/pt/wb_torchtensors_slides.html#outline-1",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Outline",
    "text": "Outline\n\nWhat is a PyTorch tensor?\nMemory storage\nData type (dtype)\nBasic operations\nWorking with NumPy\nLinear algebra\nHarvesting the power of GPUs\nDistributed operations"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#ann-do-not-process-information-directly",
    "href": "ai/pt/wb_torchtensors_slides.html#ann-do-not-process-information-directly",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "ANN do not process information directly",
    "text": "ANN do not process information directly\n\nModified from Stevens, E., Antiga, L., & Viehmann, T. (2020). Deep learning with PyTorch. Manning Publications"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#it-needs-to-be-converted-to-numbers",
    "href": "ai/pt/wb_torchtensors_slides.html#it-needs-to-be-converted-to-numbers",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "It needs to be converted to numbers",
    "text": "It needs to be converted to numbers\n\nModified from Stevens, E., Antiga, L., & Viehmann, T. (2020). Deep learning with PyTorch. Manning Publications"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#these-numbers-must-be-stored-in-a-data-structure",
    "href": "ai/pt/wb_torchtensors_slides.html#these-numbers-must-be-stored-in-a-data-structure",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "These numbers must be stored in a data structure",
    "text": "These numbers must be stored in a data structure\nPyTorch tensors are Python objects holding multidimensional arrays\n\nStevens, E., Antiga, L., & Viehmann, T. (2020). Deep learning with PyTorch. Manning Publications"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#why-a-new-object-when-numpy-already-exists",
    "href": "ai/pt/wb_torchtensors_slides.html#why-a-new-object-when-numpy-already-exists",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Why a new object when NumPy already exists?",
    "text": "Why a new object when NumPy already exists?\n\n\nCan run on accelerators (GPUs, TPUs‚Ä¶)\nKeep track of computation graphs, allowing automatic differentiation\nFuture plan for sharded tensors to run distributed computations"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#what-is-a-pytorch-tensor-2",
    "href": "ai/pt/wb_torchtensors_slides.html#what-is-a-pytorch-tensor-2",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "What is a PyTorch tensor?",
    "text": "What is a PyTorch tensor?\nPyTorch is foremost a deep learning library\nIn deep learning, the information contained in objects of interest (e.g.¬†images, texts, sounds) is converted to floating-point numbers (e.g.¬†pixel values, token values, frequencies)\nAs this information is complex, multiple dimensions are required (e.g.¬†two dimensions for the width and height of an image, plus one dimension for the RGB colour channels)\nAdditionally, items are grouped into batches to be processed together, adding yet another dimension\nMultidimensional arrays are thus particularly well suited for deep learning"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#what-is-a-pytorch-tensor-3",
    "href": "ai/pt/wb_torchtensors_slides.html#what-is-a-pytorch-tensor-3",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "What is a PyTorch tensor?",
    "text": "What is a PyTorch tensor?\nArtificial neurons perform basic computations on these tensors\nTheir number however is huge and computing efficiency is paramount\nGPUs/TPUs are particularly well suited to perform many simple operations in parallel\nThe very popular NumPy library has, at its core, a mature multidimensional array object well integrated into the scientific Python ecosystem\nBut the PyTorch tensor has additional efficiency characteristics ideal for machine learning and it can be converted to/from NumPy‚Äôs ndarray if needed"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#outline-2",
    "href": "ai/pt/wb_torchtensors_slides.html#outline-2",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Outline",
    "text": "Outline\n\nWhat is a PyTorch tensor?\nMemory storage\nData type (dtype)\nBasic operations\nWorking with NumPy\nLinear algebra\nHarvesting the power of GPUs\nDistributed operations"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#efficient-memory-storage",
    "href": "ai/pt/wb_torchtensors_slides.html#efficient-memory-storage",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Efficient memory storage",
    "text": "Efficient memory storage\nIn Python, collections (lists, tuples) are groupings of boxed Python objects\nPyTorch tensors and NumPy ndarrays are made of unboxed C numeric types\n\nStevens, E., Antiga, L., & Viehmann, T. (2020). Deep learning with PyTorch. Manning Publications"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#efficient-memory-storage-1",
    "href": "ai/pt/wb_torchtensors_slides.html#efficient-memory-storage-1",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Efficient memory storage",
    "text": "Efficient memory storage\nThey are usually contiguous memory blocks, but the main difference is that they are unboxed: floats will thus take 4 (32-bit) or 8 (64-bit) bytes each\nBoxed values take up more memory (memory for the pointer + memory for the primitive)\n\nStevens, E., Antiga, L., & Viehmann, T. (2020). Deep learning with PyTorch. Manning Publications"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#implementation",
    "href": "ai/pt/wb_torchtensors_slides.html#implementation",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Implementation",
    "text": "Implementation\nUnder the hood, the values of a PyTorch tensor are stored as a torch.Storage instance which is a one-dimensional array\n\nimport torch\nt = torch.arange(10.).view(2, 5); print(t) # Functions explained later\ntensor([[ 0.,  1.,  2., 3.,  4.],\n        [ 5.,  6.,  7.,  8.,  9.]])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#implementation-1",
    "href": "ai/pt/wb_torchtensors_slides.html#implementation-1",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Implementation",
    "text": "Implementation\nstorage = t.storage(); print(storage)\n 0.0\n 1.0\n 2.0\n 3.0\n 4.0\n 5.0\n 6.0\n 7.0\n 8.0\n 9.0\n[torch.FloatStorage of size 10]"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#implementation-2",
    "href": "ai/pt/wb_torchtensors_slides.html#implementation-2",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Implementation",
    "text": "Implementation\nThe storage can be indexed\nstorage[3]\n3.0"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#implementation-3",
    "href": "ai/pt/wb_torchtensors_slides.html#implementation-3",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Implementation",
    "text": "Implementation\nstorage[3] = 10.0; print(storage)\n 0.0\n 1.0\n 2.0\n 10.0\n 4.0\n 5.0\n 6.0\n 7.0\n 8.0\n 9.0\n[torch.FloatStorage of size 10]"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#implementation-4",
    "href": "ai/pt/wb_torchtensors_slides.html#implementation-4",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Implementation",
    "text": "Implementation\nTo view a multidimensional array from storage, we need metadata:\n\nthe size (shape in NumPy) sets the number of elements in each dimension\nthe offset indicates where the first element of the tensor is in the storage\nthe stride establishes the increment between each element"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#storage-metadata",
    "href": "ai/pt/wb_torchtensors_slides.html#storage-metadata",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Storage metadata",
    "text": "Storage metadata\n\nStevens, E., Antiga, L., & Viehmann, T. (2020). Deep learning with PyTorch. Manning Publications"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#storage-metadata-1",
    "href": "ai/pt/wb_torchtensors_slides.html#storage-metadata-1",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Storage metadata",
    "text": "Storage metadata\nt.size()\nt.storage_offset()\nt.stride()\ntorch.Size([2, 5])\n0\n(5, 1)"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#storage-metadata-2",
    "href": "ai/pt/wb_torchtensors_slides.html#storage-metadata-2",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Storage metadata",
    "text": "Storage metadata"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#sharing-storage",
    "href": "ai/pt/wb_torchtensors_slides.html#sharing-storage",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Sharing storage",
    "text": "Sharing storage\nMultiple tensors can use the same storage, saving a lot of memory since the metadata is a lot lighter than a whole new array\n\nStevens, E., Antiga, L., & Viehmann, T. (2020). Deep learning with PyTorch. Manning Publications"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#transposing-in-2-dimensions",
    "href": "ai/pt/wb_torchtensors_slides.html#transposing-in-2-dimensions",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Transposing in 2 dimensions",
    "text": "Transposing in 2 dimensions\nt = torch.tensor([[3, 1, 2], [4, 1, 7]]); print(t)\nt.size()\nt.t()\nt.t().size()\ntensor([[3, 1, 2],\n        [4, 1, 7]])\ntorch.Size([2, 3])\ntensor([[3, 4],\n        [1, 1],\n        [2, 7]])\ntorch.Size([3, 2])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#transposing-in-2-dimensions-1",
    "href": "ai/pt/wb_torchtensors_slides.html#transposing-in-2-dimensions-1",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Transposing in 2 dimensions",
    "text": "Transposing in 2 dimensions\nThis is the same as flipping the stride elements around\n\nStevens, E., Antiga, L., & Viehmann, T. (2020). Deep learning with PyTorch. Manning Publications"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#transposing-in-higher-dimensions",
    "href": "ai/pt/wb_torchtensors_slides.html#transposing-in-higher-dimensions",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Transposing in higher dimensions",
    "text": "Transposing in higher dimensions\ntorch.t() is a shorthand for torch.transpose(0, 1):\ntorch.equal(t.t(), t.transpose(0, 1))\nTrue\nWhile torch.t() only works for 2D tensors, torch.transpose() can be used to transpose 2 dimensions in tensors of any number of dimensions"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#transposing-in-higher-dimensions-1",
    "href": "ai/pt/wb_torchtensors_slides.html#transposing-in-higher-dimensions-1",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Transposing in higher dimensions",
    "text": "Transposing in higher dimensions\nt = torch.zeros(1, 2, 3); print(t)\n\nt.size()\nt.stride()\ntensor([[[0., 0., 0.],\n         [0., 0., 0.]]])\n\ntorch.Size([1, 2, 3])\n(6, 3, 1)"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#transposing-in-higher-dimensions-2",
    "href": "ai/pt/wb_torchtensors_slides.html#transposing-in-higher-dimensions-2",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Transposing in higher dimensions",
    "text": "Transposing in higher dimensions\nt.transpose(0, 1)\n\nt.transpose(0, 1).size()\nt.transpose(0, 1).stride()\ntensor([[[0., 0., 0.]],\n        [[0., 0., 0.]]])\n\ntorch.Size([2, 1, 3])\n(3, 6, 1)  # Notice how transposing flipped 2 elements of the stride"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#transposing-in-higher-dimensions-3",
    "href": "ai/pt/wb_torchtensors_slides.html#transposing-in-higher-dimensions-3",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Transposing in higher dimensions",
    "text": "Transposing in higher dimensions\nt.transpose(0, 2)\n\nt.transpose(0, 2).size()\nt.transpose(0, 2).stride()\ntensor([[[0.],\n         [0.]],\n        [[0.],\n         [0.]],\n        [[0.],\n         [0.]]])\n\ntorch.Size([3, 2, 1])\n(1, 3, 6)"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#transposing-in-higher-dimensions-4",
    "href": "ai/pt/wb_torchtensors_slides.html#transposing-in-higher-dimensions-4",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Transposing in higher dimensions",
    "text": "Transposing in higher dimensions\nt.transpose(1, 2)\n\nt.transpose(1, 2).size()\nt.transpose(1, 2).stride()\ntensor([[[0., 0.],\n         [0., 0.],\n         [0., 0.]]])\n\ntorch.Size([1, 3, 2])\n(6, 1, 3)"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#outline-3",
    "href": "ai/pt/wb_torchtensors_slides.html#outline-3",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Outline",
    "text": "Outline\n\nWhat is a PyTorch tensor?\nMemory storage\nData type (dtype)\nBasic operations\nWorking with NumPy\nLinear algebra\nHarvesting the power of GPUs\nDistributed operations"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#default-dtype",
    "href": "ai/pt/wb_torchtensors_slides.html#default-dtype",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Default dtype",
    "text": "Default dtype\nSince PyTorch tensors were built with utmost efficiency in mind for neural networks, the default data type is 32-bit floating points\nThis is sufficient for accuracy and much faster than 64-bit floating points\n\nNote that, by contrast, NumPy ndarrays use 64-bit as their default"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#list-of-pytorch-tensor-dtypes",
    "href": "ai/pt/wb_torchtensors_slides.html#list-of-pytorch-tensor-dtypes",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "List of PyTorch tensor dtypes",
    "text": "List of PyTorch tensor dtypes\n\n\n\ntorch.float16 / torch.half\n\n\n‚ÄÉ‚ÄÉ\n\n\n16-bit / half-precision floating-point\n\n\n\n\ntorch.float32 / torch.float\n\n\n\n\n32-bit / single-precision floating-point\n\n\n\n\ntorch.float64 / torch.double\n\n\n\n\n64-bit / double-precision floating-point\n\n\n\n\n\n\n\n\n\n\ntorch.uint8\n\n\n\n\nunsigned 8-bit integers\n\n\n\n\ntorch.int8\n\n\n\n\nsigned 8-bit integers\n\n\n\n\ntorch.int16 / torch.short\n\n\n\n\nsigned 16-bit integers\n\n\n\n\ntorch.int32 / torch.int\n\n\n\n\nsigned 32-bit integers\n\n\n\n\ntorch.int64 / torch.long\n\n\n\n\nsigned 64-bit integers\n\n\n\n\n\n\n\n\n\n\n\n\ntorch.bool\n\n\n\n\nboolean"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#checking-and-changing-dtype",
    "href": "ai/pt/wb_torchtensors_slides.html#checking-and-changing-dtype",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Checking and changing dtype",
    "text": "Checking and changing dtype\nt = torch.rand(2, 3)\nprint(t)\n\n# Remember that the default dtype for PyTorch tensors is float32\nt.dtype\n\n# If dtype ‚â† default, it is printed\nt2 = t.type(torch.float64)\nprint(t2)\n\nt2.dtype\ntensor([[0.8130, 0.3757, 0.7682],\n        [0.3482, 0.0516, 0.3772]])\n\ntorch.float32\n\ntensor([[0.8130, 0.3757, 0.7682],\n        [0.3482, 0.0516, 0.3772]], dtype=torch.float64)\n\ntorch.float64"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#outline-4",
    "href": "ai/pt/wb_torchtensors_slides.html#outline-4",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Outline",
    "text": "Outline\n\nWhat is a PyTorch tensor?\nMemory storage\nData type (dtype)\nBasic operations\nWorking with NumPy\nLinear algebra\nHarvesting the power of GPUs\nDistributed operations"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#creating-tensors",
    "href": "ai/pt/wb_torchtensors_slides.html#creating-tensors",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Creating tensors",
    "text": "Creating tensors\n\ntorch.tensor: ‚ÄÉ‚ÄÉ¬†Input individual values\ntorch.arange: ‚ÄÉ‚ÄÉ¬†Similar to range but creates a 1D tensor\ntorch.linspace: ‚ÄÉ¬†1D linear scale tensor\ntorch.logspace: ‚ÄÉ¬†1D log scale tensor\ntorch.rand: ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇRandom numbers from a uniform distribution on [0, 1)\ntorch.randn: ‚ÄÉ‚ÄÉ‚ÄÉNumbers from the standard normal distribution\ntorch.randperm: ‚ÄÉ¬†Random permutation of integers\ntorch.empty: ‚ÄÉ‚ÄÉ‚ÄÉUninitialized tensor\ntorch.zeros: ‚ÄÉ‚ÄÉ‚ÄÉTensor filled with 0\ntorch.ones: ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇTensor filled with 1\ntorch.eye: ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ¬†Identity matrix"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#creating-tensors-1",
    "href": "ai/pt/wb_torchtensors_slides.html#creating-tensors-1",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Creating tensors",
    "text": "Creating tensors\ntorch.manual_seed(0)  # If you want to reproduce the result\ntorch.rand(1)\n\ntorch.manual_seed(0)  # Run before each operation to get the same result\ntorch.rand(1).item()  # Extract the value from a tensor\ntensor([0.4963])\n\n0.49625658988952637"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#creating-tensors-2",
    "href": "ai/pt/wb_torchtensors_slides.html#creating-tensors-2",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Creating tensors",
    "text": "Creating tensors\ntorch.rand(1)\ntorch.rand(1, 1)\ntorch.rand(1, 1, 1)\ntorch.rand(1, 1, 1, 1)\ntensor([0.6984])\ntensor([[0.5675]])\ntensor([[[0.8352]]])\ntensor([[[[0.2056]]]])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#creating-tensors-3",
    "href": "ai/pt/wb_torchtensors_slides.html#creating-tensors-3",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Creating tensors",
    "text": "Creating tensors\ntorch.rand(2)\ntorch.rand(2, 2, 2, 2)\ntensor([0.5932, 0.1123])\ntensor([[[[0.1147, 0.3168],\n          [0.6965, 0.9143]],\n         [[0.9351, 0.9412],\n          [0.5995, 0.0652]]],\n        [[[0.5460, 0.1872],\n          [0.0340, 0.9442]],\n         [[0.8802, 0.0012],\n          [0.5936, 0.4158]]]])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#creating-tensors-4",
    "href": "ai/pt/wb_torchtensors_slides.html#creating-tensors-4",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Creating tensors",
    "text": "Creating tensors\ntorch.rand(2)\ntorch.rand(3)\ntorch.rand(1, 1)\ntorch.rand(1, 1, 1)\ntorch.rand(2, 6)\ntensor([0.7682, 0.0885])\ntensor([0.1320, 0.3074, 0.6341])\ntensor([[0.4901]])\ntensor([[[0.8964]]])\ntensor([[0.4556, 0.6323, 0.3489, 0.4017, 0.0223, 0.1689],\n        [0.2939, 0.5185, 0.6977, 0.8000, 0.1610, 0.2823]])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#creating-tensors-5",
    "href": "ai/pt/wb_torchtensors_slides.html#creating-tensors-5",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Creating tensors",
    "text": "Creating tensors\ntorch.rand(2, 4, dtype=torch.float64)  # You can set dtype\ntorch.ones(2, 1, 4, 5)\ntensor([[0.6650, 0.7849, 0.2104, 0.6767],\n        [0.1097, 0.5238, 0.2260, 0.5582]], dtype=torch.float64)\ntensor([[[[1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1.]]],\n        [[[1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1.]]]])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#creating-tensors-6",
    "href": "ai/pt/wb_torchtensors_slides.html#creating-tensors-6",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Creating tensors",
    "text": "Creating tensors\nt = torch.rand(2, 3); print(t)\ntorch.zeros_like(t)             # Matches the size of t\ntorch.ones_like(t)\ntorch.randn_like(t)\ntensor([[0.4051, 0.6394, 0.0871],\n        [0.4509, 0.5255, 0.5057]])\ntensor([[0., 0., 0.],\n        [0., 0., 0.]])\ntensor([[1., 1., 1.],\n        [1., 1., 1.]])\ntensor([[-0.3088, -0.0104,  1.0461],\n        [ 0.9233,  0.0236, -2.1217]])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#creating-tensors-7",
    "href": "ai/pt/wb_torchtensors_slides.html#creating-tensors-7",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Creating tensors",
    "text": "Creating tensors\ntorch.arange(2, 10, 4)    # From 2 to 10 in increments of 4\ntorch.linspace(2, 10, 4)  # 4 elements from 2 to 10 on the linear scale\ntorch.logspace(2, 10, 4)  # Same on the log scale\ntorch.randperm(4)\ntorch.eye(3)\ntensor([2, 6])\ntensor([2.0000,  4.6667,  7.3333, 10.0000])\ntensor([1.0000e+02, 4.6416e+04, 2.1544e+07, 1.0000e+10])\ntensor([1, 3, 2, 0])\ntensor([[1., 0., 0.],\n        [0., 1., 0.],\n        [0., 0., 1.]])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#tensor-information",
    "href": "ai/pt/wb_torchtensors_slides.html#tensor-information",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Tensor information",
    "text": "Tensor information\nt = torch.rand(2, 3); print(t)\nt.size()\nt.dim()\nt.numel()\ntensor([[0.5885, 0.7005, 0.1048],\n        [0.1115, 0.7526, 0.0658]])\ntorch.Size([2, 3])\n2\n6"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#tensor-indexing",
    "href": "ai/pt/wb_torchtensors_slides.html#tensor-indexing",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Tensor indexing",
    "text": "Tensor indexing\nx = torch.rand(3, 4)\nx[:]                 # With a range, the comma is implicit: same as x[:, ]\nx[:, 2]\nx[1, :]\nx[2, 3]\ntensor([[0.6575, 0.4017, 0.7391, 0.6268],\n        [0.2835, 0.0993, 0.7707, 0.1996],\n        [0.4447, 0.5684, 0.2090, 0.7724]])\ntensor([0.7391, 0.7707, 0.2090])\ntensor([0.2835, 0.0993, 0.7707, 0.1996])\ntensor(0.7724)"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#tensor-indexing-1",
    "href": "ai/pt/wb_torchtensors_slides.html#tensor-indexing-1",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Tensor indexing",
    "text": "Tensor indexing\nx[-1:]        # Last element (implicit comma, so all columns)\n\n# No range, no implicit comma\n# Indexing from a list of tensors, so the result is a one dimensional tensor\n# (Each dimension is a list of tensors of the previous dimension)\nx[-1]\n\nx[-1].size()  # Same number of dimensions than x (2 dimensions)\n\nx[-1:].size() # We dropped one dimension\ntensor([[0.8168, 0.0879, 0.2642, 0.3777]])\n\ntensor([0.8168, 0.0879, 0.2642, 0.3777])\n\ntorch.Size([4])\n\ntorch.Size([1, 4])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#tensor-indexing-2",
    "href": "ai/pt/wb_torchtensors_slides.html#tensor-indexing-2",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Tensor indexing",
    "text": "Tensor indexing\nx[0:1]     # Python ranges are inclusive to the left, not the right\nx[:-1]     # From start to one before last (and implicit comma)\nx[0:3:2]   # From 0th (included) to 3rd (excluded) in increment of 2\ntensor([[0.5873, 0.0225, 0.7234, 0.4538]])\ntensor([[0.5873, 0.0225, 0.7234, 0.4538],\n        [0.9525, 0.0111, 0.6421, 0.4647]])\ntensor([[0.5873, 0.0225, 0.7234, 0.4538],\n        [0.8168, 0.0879, 0.2642, 0.3777]])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#tensor-indexing-3",
    "href": "ai/pt/wb_torchtensors_slides.html#tensor-indexing-3",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Tensor indexing",
    "text": "Tensor indexing\nx[None]          # Adds a dimension of size one as the 1st dimension\nx.size()\nx[None].size()\ntensor([[[0.5873, 0.0225, 0.7234, 0.4538],\n         [0.9525, 0.0111, 0.6421, 0.4647],\n         [0.8168, 0.0879, 0.2642, 0.3777]]])\ntorch.Size([3, 4])\ntorch.Size([1, 3, 4])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#a-word-of-caution-about-indexing",
    "href": "ai/pt/wb_torchtensors_slides.html#a-word-of-caution-about-indexing",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "A word of caution about indexing",
    "text": "A word of caution about indexing\nWhile indexing elements of a tensor to extract some of the data as a final step of some computation is fine, you should not use indexing to run operations on tensor elements in a loop as this would be extremely inefficient\nInstead, you want to use vectorized operations"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#vectorized-operations",
    "href": "ai/pt/wb_torchtensors_slides.html#vectorized-operations",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Vectorized operations",
    "text": "Vectorized operations\nSince PyTorch tensors are homogeneous (i.e.¬†made of a single data type), as with NumPy‚Äôs ndarrays, operations are vectorized and thus staggeringly fast\nNumPy is mostly written in C and PyTorch in C++. With either library, when you run vectorized operations on arrays/tensors, you don‚Äôt use raw Python (slow) but compiled C/C++ code (much faster)\nHere is an excellent post explaining Python vectorization and why it makes such a big difference"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#vectorized-operations-comparison",
    "href": "ai/pt/wb_torchtensors_slides.html#vectorized-operations-comparison",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Vectorized operations: comparison",
    "text": "Vectorized operations: comparison\nRaw Python method\n# Create tensor. We use float64 here to avoid truncation errors\nt = torch.rand(10**6, dtype=torch.float64)\n\n# Initialize sum\nsum = 0\n\n# Run loop\nfor i in range(len(t)): sum += t[i]\n\n# Print result\nprint(sum)\nVectorized function\nt.sum()"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#vectorized-operations-comparison-1",
    "href": "ai/pt/wb_torchtensors_slides.html#vectorized-operations-comparison-1",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Vectorized operations: comparison",
    "text": "Vectorized operations: comparison\nBoth methods give the same result\n\nThis is why we used float64:\nWhile the accuracy remains excellent with float32 if we use the PyTorch function torch.sum(), the raw Python loop gives a fairly inaccurate result\n\ntensor(500023.0789, dtype=torch.float64)\ntensor(500023.0789, dtype=torch.float64)"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#vectorized-operations-timing",
    "href": "ai/pt/wb_torchtensors_slides.html#vectorized-operations-timing",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Vectorized operations: timing",
    "text": "Vectorized operations: timing\nLet‚Äôs compare the timing with PyTorch built-in benchmark utility\n# Load utility\nimport torch.utils.benchmark as benchmark\n\n# Create a function for our loop\ndef sum_loop(t, sum):\n    for i in range(len(t)): sum += t[i]"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#vectorized-operations-timing-1",
    "href": "ai/pt/wb_torchtensors_slides.html#vectorized-operations-timing-1",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Vectorized operations: timing",
    "text": "Vectorized operations: timing\nNow we can create the timers\nt0 = benchmark.Timer(\n    stmt='sum_loop(t, sum)',\n    setup='from __main__ import sum_loop',\n    globals={'t': t, 'sum': sum})\n\nt1 = benchmark.Timer(\n    stmt='t.sum()',\n    globals={'t': t})"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#vectorized-operations-timing-2",
    "href": "ai/pt/wb_torchtensors_slides.html#vectorized-operations-timing-2",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Vectorized operations: timing",
    "text": "Vectorized operations: timing\nLet‚Äôs time 100 runs to have a reliable benchmark\nprint(t0.timeit(100))\nprint(t1.timeit(100))\n\nI ran the code on my laptop with a dedicated GPU and 32GB RAM"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#vectorized-operations-timing-3",
    "href": "ai/pt/wb_torchtensors_slides.html#vectorized-operations-timing-3",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Vectorized operations: timing",
    "text": "Vectorized operations: timing\nTiming of raw Python loop\nsum_loop(t, sum)\nsetup: from __main__ import sum_loop\n  1.37 s\n  1 measurement, 100 runs , 1 thread\nTiming of vectorized function\nt.sum()\n  191.26 us\n  1 measurement, 100 runs , 1 thread"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#vectorized-operations-timing-4",
    "href": "ai/pt/wb_torchtensors_slides.html#vectorized-operations-timing-4",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Vectorized operations: timing",
    "text": "Vectorized operations: timing\nSpeedup:\n1.37/(191.26 * 10**-6) = 7163\n\nThe vectorized function runs more than 7,000 times faster!!!"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#even-more-important-on-gpus",
    "href": "ai/pt/wb_torchtensors_slides.html#even-more-important-on-gpus",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Even more important on GPUs",
    "text": "Even more important on GPUs\nWe will talk about GPUs in detail later\nTiming of raw Python loop on GPU (actually slower on GPU!)\nsum_loop(t, sum)\nsetup: from __main__ import sum_loop\n  4.54 s\n  1 measurement, 100 runs , 1 thread\nTiming of vectorized function on GPU (here we do get a speedup)\nt.sum()\n  50.62 us\n  1 measurement, 100 runs , 1 thread"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#even-more-important-on-gpus-1",
    "href": "ai/pt/wb_torchtensors_slides.html#even-more-important-on-gpus-1",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Even more important on GPUs",
    "text": "Even more important on GPUs\nSpeedup:\n4.54/(50.62 * 10**-6) = 89688\n\nOn GPUs, it is even more important not to index repeatedly from a tensor\n\n\nOn GPUs, the vectorized function runs almost 90,000 times faster!!!"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#simple-mathematical-operations",
    "href": "ai/pt/wb_torchtensors_slides.html#simple-mathematical-operations",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Simple mathematical operations",
    "text": "Simple mathematical operations\nt1 = torch.arange(1, 5).view(2, 2); print(t1)\nt2 = torch.tensor([[1, 1], [0, 0]]); print(t2)\n\nt1 + t2 # Operation performed between elements at corresponding locations\nt1 + 1  # Operation applied to each element of the tensor\ntensor([[1, 2],\n        [3, 4]])\ntensor([[1, 1],\n        [0, 0]])\n\ntensor([[2, 3],\n        [3, 4]])\ntensor([[2, 3],\n        [4, 5]])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#reduction",
    "href": "ai/pt/wb_torchtensors_slides.html#reduction",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Reduction",
    "text": "Reduction\nt = torch.ones(2, 3, 4); print(t)\nt.sum()   # Reduction over all entries\ntensor([[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]])\ntensor(24.)\n\nOther reduction functions (e.g.¬†mean) behave the same way"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#reduction-1",
    "href": "ai/pt/wb_torchtensors_slides.html#reduction-1",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Reduction",
    "text": "Reduction\n# Reduction over a specific dimension\nt.sum(0)\nt.sum(1)\nt.sum(2)\ntensor([[2., 2., 2., 2.],\n        [2., 2., 2., 2.],\n        [2., 2., 2., 2.]])\ntensor([[3., 3., 3., 3.],\n        [3., 3., 3., 3.]])\ntensor([[4., 4., 4.],\n        [4., 4., 4.]])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#reduction-2",
    "href": "ai/pt/wb_torchtensors_slides.html#reduction-2",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Reduction",
    "text": "Reduction\n# Reduction over multiple dimensions\nt.sum((0, 1))\nt.sum((0, 2))\nt.sum((1, 2))\ntensor([6., 6., 6., 6.])\ntensor([8., 8., 8.])\ntensor([12., 12.])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#in-place-operations",
    "href": "ai/pt/wb_torchtensors_slides.html#in-place-operations",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "In-place operations",
    "text": "In-place operations\nWith operators post-fixed with _:\nt1 = torch.tensor([1, 2]); print(t1)\nt2 = torch.tensor([1, 1]); print(t2)\nt1.add_(t2); print(t1)\nt1.zero_(); print(t1)\ntensor([1, 2])\ntensor([1, 1])\ntensor([2, 3])\ntensor([0, 0])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#in-place-operations-vs-reassignments",
    "href": "ai/pt/wb_torchtensors_slides.html#in-place-operations-vs-reassignments",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "In-place operations vs reassignments",
    "text": "In-place operations vs reassignments\nt1 = torch.ones(1); t1, hex(id(t1))\nt1.add_(1); t1, hex(id(t1))        # In-place operation: same address\nt1 = t1.add(1); t1, hex(id(t1))    # Reassignment: new address in memory\nt1 = t1 + 1; t1, hex(id(t1))       # Reassignment: new address in memory\n(tensor([1.]), '0x7fc61accc3b0')\n(tensor([2.]), '0x7fc61accc3b0')\n(tensor([3.]), '0x7fc61accc5e0')\n(tensor([4.]), '0x7fc61accc6d0')"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#tensor-views",
    "href": "ai/pt/wb_torchtensors_slides.html#tensor-views",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Tensor views",
    "text": "Tensor views\nt = torch.tensor([[1, 2, 3], [4, 5, 6]]); print(t)\nt.size()\nt.view(6)\nt.view(3, 2)\nt.view(3, -1) # Same: with -1, the size is inferred from other dimensions\ntensor([[1, 2, 3],\n        [4, 5, 6]])\ntorch.Size([2, 3])\ntensor([1, 2, 3, 4, 5, 6])\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#note-the-difference",
    "href": "ai/pt/wb_torchtensors_slides.html#note-the-difference",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Note the difference",
    "text": "Note the difference\nt1 = torch.tensor([[1, 2, 3], [4, 5, 6]]); print(t1)\nt2 = t1.t(); print(t2)\nt3 = t1.view(3, 2); print(t3)\ntensor([[1, 2, 3],\n        [4, 5, 6]])\ntensor([[1, 4],\n        [2, 5],\n        [3, 6]])\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#logical-operations",
    "href": "ai/pt/wb_torchtensors_slides.html#logical-operations",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Logical operations",
    "text": "Logical operations\nt1 = torch.randperm(5); print(t1)\nt2 = torch.randperm(5); print(t2)\nt1 &gt; 3                            # Test each element\nt1 &lt; t2                           # Test corresponding pairs of elements\ntensor([4, 1, 0, 2, 3])\ntensor([0, 4, 2, 1, 3])\ntensor([ True, False, False, False, False])\ntensor([False,  True,  True, False, False])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#outline-5",
    "href": "ai/pt/wb_torchtensors_slides.html#outline-5",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Outline",
    "text": "Outline\n\nWhat is a PyTorch tensor?\nMemory storage\nData type (dtype)\nBasic operations\nWorking with NumPy\nLinear algebra\nHarvesting the power of GPUs\nDistributed operations"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#conversion-without-copy",
    "href": "ai/pt/wb_torchtensors_slides.html#conversion-without-copy",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Conversion without copy",
    "text": "Conversion without copy\nPyTorch tensors can be converted to NumPy ndarrays and vice-versa in a very efficient manner as both objects share the same memory\nt = torch.rand(2, 3); print(t)     # PyTorch Tensor\nt_np = t.numpy(); print(t_np)      # NumPy ndarray\ntensor([[0.8434, 0.0876, 0.7507],\n        [0.1457, 0.3638, 0.0563]])   \n\n[[0.84344184 0.08764815 0.7506627 ]\n [0.14567494 0.36384273 0.05629885]]"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#mind-the-different-defaults",
    "href": "ai/pt/wb_torchtensors_slides.html#mind-the-different-defaults",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Mind the different defaults",
    "text": "Mind the different defaults\nt_np.dtype\ndtype('float32')\n\nRemember that PyTorch tensors use 32-bit floating points by default\n(because this is what you want in neural networks)\n\n\nBut NumPy defaults to 64-bit\nDepending on your workflow, you might have to change dtype"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#from-numpy-to-pytorch",
    "href": "ai/pt/wb_torchtensors_slides.html#from-numpy-to-pytorch",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "From NumPy to PyTorch",
    "text": "From NumPy to PyTorch\nimport numpy as np\na = np.random.rand(2, 3); print(a)\na_pt = torch.from_numpy(a); print(a_pt)    # From ndarray to tensor\n[[0.55892276 0.06026952 0.72496545]\n [0.65659463 0.27697739 0.29141587]]\n\ntensor([[0.5589, 0.0603, 0.7250],\n        [0.6566, 0.2770, 0.2914]], dtype=torch.float64)\n\nHere again, you might have to change dtype"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#notes-about-conversion-without-copy",
    "href": "ai/pt/wb_torchtensors_slides.html#notes-about-conversion-without-copy",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Notes about conversion without copy",
    "text": "Notes about conversion without copy\nt and t_np are objects of different Python types, so, as far as Python is concerned,\nthey have different addresses\nid(t) == id(t_np)\nFalse"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#notes-about-conversion-without-copy-1",
    "href": "ai/pt/wb_torchtensors_slides.html#notes-about-conversion-without-copy-1",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Notes about conversion without copy",
    "text": "Notes about conversion without copy\nHowever‚Äîthat‚Äôs quite confusing‚Äîthey share an underlying C array in memory and modifying one in-place also modifies the other\nt.zero_()\nprint(t_np)\ntensor([[0., 0., 0.],\n        [0., 0., 0.]])\n\n[[0. 0. 0.]\n [0. 0. 0.]]"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#notes-about-conversion-without-copy-2",
    "href": "ai/pt/wb_torchtensors_slides.html#notes-about-conversion-without-copy-2",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Notes about conversion without copy",
    "text": "Notes about conversion without copy\nLastly, as NumPy only works on CPU, to convert a PyTorch tensor allocated to the GPU, the content will have to be copied to the CPU first"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#outline-6",
    "href": "ai/pt/wb_torchtensors_slides.html#outline-6",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Outline",
    "text": "Outline\n\nWhat is a PyTorch tensor?\nMemory storage\nData type (dtype)\nBasic operations\nWorking with NumPy\nLinear algebra\nHarvesting the power of GPUs\nDistributed operations"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#torch.linalg-module",
    "href": "ai/pt/wb_torchtensors_slides.html#torch.linalg-module",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "torch.linalg module",
    "text": "torch.linalg module\nAll functions from numpy.linalg implemented (with accelerator and automatic differentiation support) + additional functions\n\nRequires torch &gt;= 1.9\nLinear algebra support was less developed before the introduction of this module"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#system-of-linear-equations-solver",
    "href": "ai/pt/wb_torchtensors_slides.html#system-of-linear-equations-solver",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "System of linear equations solver",
    "text": "System of linear equations solver\nLet‚Äôs have a look at an extremely basic example:\n2x + 3y - z = 5\nx - 2y + 8z = 21\n6x + y - 3z = -1\nWe are looking for the values of x, y, and z that would satisfy this system"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#system-of-linear-equations-solver-1",
    "href": "ai/pt/wb_torchtensors_slides.html#system-of-linear-equations-solver-1",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "System of linear equations solver",
    "text": "System of linear equations solver\nWe create a 2D tensor A of size (3, 3) with the coefficients of the equations\nand a 1D tensor b of size 3 with the right hand sides values of the equations\nA = torch.tensor([[2., 3., -1.], [1., -2., 8.], [6., 1., -3.]]); print(A)\nb = torch.tensor([5., 21., -1.]); print(b)\ntensor([[ 2.,  3., -1.],\n        [ 1., -2.,  8.],\n        [ 6.,  1., -3.]])\ntensor([ 5., 21., -1.])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#system-of-linear-equations-solver-2",
    "href": "ai/pt/wb_torchtensors_slides.html#system-of-linear-equations-solver-2",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "System of linear equations solver",
    "text": "System of linear equations solver\nSolving this system is as simple as running the torch.linalg.solve function:\nx = torch.linalg.solve(A, b); print(x)\ntensor([1., 2., 3.])\nOur solution is:\nx = 1\ny = 2\nz = 3"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#verify-our-result",
    "href": "ai/pt/wb_torchtensors_slides.html#verify-our-result",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Verify our result",
    "text": "Verify our result\ntorch.allclose(A @ x, b)\nTrue"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#system-of-linear-equations-solver-3",
    "href": "ai/pt/wb_torchtensors_slides.html#system-of-linear-equations-solver-3",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "System of linear equations solver",
    "text": "System of linear equations solver\nHere is another simple example:\n# Create a square normal random matrix\nA = torch.randn(4, 4); print(A)\n# Create a tensor of right hand side values\nb = torch.randn(4); print(b)\n\n# Solve the system\nx = torch.linalg.solve(A, b); print(x)\n\n# Verify\ntorch.allclose(A @ x, b)"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#system-of-linear-equations-solver-4",
    "href": "ai/pt/wb_torchtensors_slides.html#system-of-linear-equations-solver-4",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "System of linear equations solver",
    "text": "System of linear equations solver\n(Results)\nA (coefficients):\ntensor([[ 1.5091,  2.0820,  1.7067,  2.3804],\n        [-1.1256, -0.3170, -1.0925, -0.0852],\n        [ 0.3276, -0.7607, -1.5991,  0.0185],\n        [-0.7504,  0.1854,  0.6211,  0.6382]])\nb (right hand side values):\ntensor([-1.0886, -0.2666,  0.1894, -0.2190])\nx (our solution):\ntensor([ 0.1992, -0.7011,  0.2541, -0.1526])\nVerification:\nTrue"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#with-2-multidimensional-tensors",
    "href": "ai/pt/wb_torchtensors_slides.html#with-2-multidimensional-tensors",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "With 2 multidimensional tensors",
    "text": "With 2 multidimensional tensors\nA = torch.randn(2, 3, 3)              # Must be batches of square matrices\nB = torch.randn(2, 3, 5)              # Dimensions must be compatible\nX = torch.linalg.solve(A, B); print(X)\ntorch.allclose(A @ X, B)\ntensor([[[-0.0545, -0.1012,  0.7863, -0.0806, -0.0191],\n         [-0.9846, -0.0137, -1.7521, -0.4579, -0.8178],\n         [-1.9142, -0.6225, -1.9239, -0.6972,  0.7011]],\n        [[ 3.2094,  0.3432, -1.6604, -0.7885,  0.0088],\n         [ 7.9852,  1.4605, -1.7037, -0.7713,  2.7319],\n         [-4.1979,  0.0849,  1.0864,  0.3098, -1.0347]]])\nTrue"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#matrix-inversions",
    "href": "ai/pt/wb_torchtensors_slides.html#matrix-inversions",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Matrix inversions",
    "text": "Matrix inversions\n\n\nIt is faster and more numerically stable to solve a system of linear equations directly than to compute the inverse matrix first\n\n\n\nLimit matrix inversions to situations where it is truly necessary"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#matrix-inversions-1",
    "href": "ai/pt/wb_torchtensors_slides.html#matrix-inversions-1",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Matrix inversions",
    "text": "Matrix inversions\nA = torch.rand(2, 3, 3)      # Batch of square matrices\nA_inv = torch.linalg.inv(A)  # Batch of inverse matrices\nA @ A_inv                    # Batch of identity matrices\ntensor([[[ 1.0000e+00, -6.0486e-07,  1.3859e-06],\n         [ 5.5627e-08,  1.0000e+00,  1.0795e-06],\n         [-1.4133e-07,  7.9992e-08,  1.0000e+00]],\n        [[ 1.0000e+00,  4.3329e-08, -3.6741e-09],\n         [-7.4627e-08,  1.0000e+00,  1.4579e-07],\n         [-6.3580e-08,  8.2354e-08,  1.0000e+00]]])"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#other-linear-algebra-functions",
    "href": "ai/pt/wb_torchtensors_slides.html#other-linear-algebra-functions",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Other linear algebra functions",
    "text": "Other linear algebra functions\ntorch.linalg contains many more functions:\n\ntorch.tensordot which generalizes matrix products\ntorch.linalg.tensorsolve which computes the solution X to the system torch.tensordot(A, X) = B\ntorch.linalg.eigvals which computes the eigenvalues of a square matrix\n‚Ä¶"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#outline-7",
    "href": "ai/pt/wb_torchtensors_slides.html#outline-7",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Outline",
    "text": "Outline\n\nWhat is a PyTorch tensor?\nMemory storage\nData type (dtype)\nBasic operations\nWorking with NumPy\nLinear algebra\nHarvesting the power of GPUs\nDistributed operations"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#device-attribute",
    "href": "ai/pt/wb_torchtensors_slides.html#device-attribute",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Device attribute",
    "text": "Device attribute\nTensor data can be placed in the memory of various processor types:\n\nthe RAM of CPU\nthe RAM of a GPU with CUDA support\nthe RAM of a GPU with AMD‚Äôs ROCm support\nthe RAM of an XLA device (e.g.¬†Cloud TPU) with the torch_xla package"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#device-attribute-1",
    "href": "ai/pt/wb_torchtensors_slides.html#device-attribute-1",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Device attribute",
    "text": "Device attribute\nThe values for the device attributes are:\n\nCPU: ¬†'cpu'\nGPU (CUDA and AMD‚Äôs ROCm): ¬†'cuda'\nXLA: ¬†xm.xla_device()\n\nThis last option requires to load the torch_xla package first:\nimport torch_xla\nimport torch_xla.core.xla_model as xm"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#creating-a-tensor-on-a-specific-device",
    "href": "ai/pt/wb_torchtensors_slides.html#creating-a-tensor-on-a-specific-device",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Creating a tensor on a specific device",
    "text": "Creating a tensor on a specific device\nBy default, tensors are created on the CPU\nt1 = torch.rand(2); print(t1)\ntensor([0.1606, 0.9771])  # Implicit: device='cpu'\n\nPrinted tensors only display attributes with values ‚â† default values"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#creating-a-tensor-on-a-specific-device-1",
    "href": "ai/pt/wb_torchtensors_slides.html#creating-a-tensor-on-a-specific-device-1",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Creating a tensor on a specific device",
    "text": "Creating a tensor on a specific device\nYou can create a tensor on an accelerator by specifying the device attribute\nt2_gpu = torch.rand(2, device='cuda'); print(t2_gpu)\ntensor([0.0664, 0.7829], device='cuda:0')  # :0 means the 1st GPU"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#copying-a-tensor-to-a-specific-device",
    "href": "ai/pt/wb_torchtensors_slides.html#copying-a-tensor-to-a-specific-device",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Copying a tensor to a specific device",
    "text": "Copying a tensor to a specific device\nYou can also make copies of a tensor on other devices\n# Make a copy of t1 on the GPU\nt1_gpu = t1.to(device='cuda'); print(t1_gpu)\nt1_gpu = t1.cuda()  # Same as above written differently\n\n# Make a copy of t2_gpu on the CPU\nt2 = t2_gpu.to(device='cpu'); print(t2)\nt2 = t2_gpu.cpu()   # For the altenative form\ntensor([0.1606, 0.9771], device='cuda:0')\ntensor([0.0664, 0.7829]) # Implicit: device='cpu'"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#multiple-gpus",
    "href": "ai/pt/wb_torchtensors_slides.html#multiple-gpus",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Multiple GPUs",
    "text": "Multiple GPUs\nIf you have multiple GPUs, you can optionally specify which one a tensor should be created on or copied to\nt3_gpu = torch.rand(2, device='cuda:0')  # Create a tensor on 1st GPU\nt4_gpu = t1.to(device='cuda:0')          # Make a copy of t1 on 1st GPU\nt5_gpu = t1.to(device='cuda:1')          # Make a copy of t1 on 2nd GPU\n\nOr the equivalent short forms for the last two:\nt4_gpu = t1.cuda(0)\nt5_gpu = t1.cuda(1)"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#timing",
    "href": "ai/pt/wb_torchtensors_slides.html#timing",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Timing",
    "text": "Timing\nLet‚Äôs compare the timing of some matrix multiplications on CPU and GPU with PyTorch built-in benchmark utility\n# Load utility\nimport torch.utils.benchmark as benchmark\n# Define tensors on the CPU\nA = torch.randn(500, 500)\nB = torch.randn(500, 500)\n# Define tensors on the GPU\nA_gpu = torch.randn(500, 500, device='cuda')\nB_gpu = torch.randn(500, 500, device='cuda')\n\nI ran the code on my laptop with a dedicated GPU and 32GB RAM"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#timing-1",
    "href": "ai/pt/wb_torchtensors_slides.html#timing-1",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Timing",
    "text": "Timing\nLet‚Äôs time 100 runs to have a reliable benchmark\nt0 = benchmark.Timer(\n    stmt='A @ B',\n    globals={'A': A, 'B': B})\n\nt1 = benchmark.Timer(\n    stmt='A_gpu @ B_gpu',\n    globals={'A_gpu': A_gpu, 'B_gpu': B_gpu})\n\nprint(t0.timeit(100))\nprint(t1.timeit(100))"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#timing-2",
    "href": "ai/pt/wb_torchtensors_slides.html#timing-2",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Timing",
    "text": "Timing\nA @ B\n  2.29 ms\n  1 measurement, 100 runs , 1 thread\n\nA_gpu @ B_gpu\n  108.02 us\n  1 measurement, 100 runs , 1 thread\nSpeedup:\n(2.29 * 10**-3)/(108.02 * 10**-6) = 21\nThis computation was 21 times faster on my GPU than on CPU"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#timing-3",
    "href": "ai/pt/wb_torchtensors_slides.html#timing-3",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Timing",
    "text": "Timing\nBy replacing 500 with 5000, we get:\nA @ B\n  2.21 s\n  1 measurement, 100 runs , 1 thread\n\nA_gpu @ B_gpu\n  57.88 ms\n  1 measurement, 100 runs , 1 thread\nSpeedup:\n2.21/(57.88 * 10**-3) = 38\nThe larger the computation, the greater the benefit: now 38 times faster"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#outline-8",
    "href": "ai/pt/wb_torchtensors_slides.html#outline-8",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Outline",
    "text": "Outline\n\nWhat is a PyTorch tensor?\nMemory storage\nData type (dtype)\nBasic operations\nWorking with NumPy\nLinear algebra\nHarvesting the power of GPUs\nDistributed operations"
  },
  {
    "objectID": "ai/pt/wb_torchtensors_slides.html#parallel-tensor-operations",
    "href": "ai/pt/wb_torchtensors_slides.html#parallel-tensor-operations",
    "title": "Everything you wanted to know(and more!)about PyTorch tensors",
    "section": "Parallel tensor operations",
    "text": "Parallel tensor operations\nPyTorch already allows for distributed training of ML models\nThe implementation of distributed tensor operations‚Äîfor instance for linear algebra‚Äîis in the work through the use of a ShardedTensor primitive that can be sharded across nodes\nSee also this issue for more comments about upcoming developments on (among other things) tensor sharding"
  },
  {
    "objectID": "ai/pt/wb_upscaling_content.html",
    "href": "ai/pt/wb_upscaling_content.html",
    "title": "Super-resolution with PyTorch",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Image upscaling",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/wb_upscaling_content.html#definitions",
    "href": "ai/pt/wb_upscaling_content.html#definitions",
    "title": "Super-resolution with PyTorch",
    "section": "Definitions",
    "text": "Definitions\n\n\n\nLR\nHR\nSR\nSISR\n\n\nlow resolution\nhigh resolution\nsuper-resolution = reconstruction of HR images from LR images\nsingle-image super-resolution = SR using a single input image",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Image upscaling",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/wb_upscaling_content.html#history-of-super-resolution",
    "href": "ai/pt/wb_upscaling_content.html#history-of-super-resolution",
    "title": "Super-resolution with PyTorch",
    "section": "History of super-resolution",
    "text": "History of super-resolution\n\n2 main periods\n\nA rather slow history with various interpolation algorithms of increasing complexity before deep neural networks.\nAn incredibly fast evolution since the advent of deep learning (DL).\n\n\n\nSR history Pre-DL\nPixel-wise interpolation prior to DL.\nVarious methods ranging from simple (e.g.¬†nearest-neighbour, bicubic) to complex (e.g.¬†Gaussian process regression, iterative FIR Wiener filter) algorithms.\n\nNearest-neighbour interpolation\nSimplest method of interpolation.\nSimply uses the value of the nearest pixel.\n\n\nBicubic interpolation\nConsists of determining the 16 coefficients \\(a_{ij}\\) in:\n\\[p(x, y) = \\sum_{i=0}^3\\sum_{i=0}^3 a\\_{ij} x^i y^j\\]\n\n\n\nSR history with DL\nDeep learning has seen a fast evolution marked by the successive emergence of various frameworks and architectures over the past 10 years.\nSome key network architectures and frameworks:\n\nCNN\nGAN\nTransformers\n\nThese have all been applied to SR.\nSR using (amongst others):\n\nConvolutional Neural Networks (SRCNN) ‚Äì 2014\nRandom Forests ‚Äì 2015\nPerceptual loss ‚Äì 2016\nSub-pixel CNN ‚Äì 2016\nResNet (SRResNet) & Generative Adversarial Network (SRGAN) ‚Äì 2017\nEnhanced SRGAN (ESRGAN) ‚Äì 2018\nPredictive Filter Flow (PFF) ‚Äì 2018\nDensely Residual Laplacian attention Network (DRLN) ‚Äì 2019\nSecond-order Attention Network (SAN) ‚Äì 2019\nLearned downscaling with Content Adaptive Resampler (CAR) ‚Äì 2019\nHolistic Attention Network (HAN) ‚Äì 2020\nSwin Transformer ‚Äì 2021\n\n\nSRCNN\n\n\n\nDong, C., Loy, C. C., He, K., & Tang, X. (2015). Image super-resolution using deep convolutional networks. IEEE transactions on pattern analysis and machine intelligence, 38(2), 295-307\n\n\n\nGiven a low-resolution image Y, the first convolutional layer of the SRCNN extracts a set of feature maps. The second layer maps these feature maps nonlinearly to high-resolution patch representations. The last layer combines the predictions within a spatial neighbourhood to produce the final high-resolution image F(Y)\n\nCan use sparse-coding-based methods.\n\n\n\nDong, C., Loy, C. C., He, K., & Tang, X. (2015). Image super-resolution using deep convolutional networks. IEEE transactions on pattern analysis and machine intelligence, 38(2), 295-307\n\n\n\n\nSRGAN\nDo not provide the best PSNR, but can give more realistic results by providing more texture (less smoothing).\n\n\nGAN\n\n\n\nStevens E., Antiga L., & Viehmann T. (2020). Deep Learning with PyTorch\n\n\n\n\nSRGAN\n\n\n\nLedig, C., Theis, L., Husz√°r, F., Caballero, J., Cunningham, A., Acosta, A., ‚Ä¶ & Shi, W. (2017). Photo-realistic single image super-resolution using a generative adversarial network. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp.¬†4681-4690)\n\n\nFollowed by the ESRGAN and many other flavours of SRGANs.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Image upscaling",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/wb_upscaling_content.html#swinir",
    "href": "ai/pt/wb_upscaling_content.html#swinir",
    "title": "Super-resolution with PyTorch",
    "section": "SwinIR",
    "text": "SwinIR\n\nAttention\n\nMnih, V., Heess, N., & Graves, A. (2014). Recurrent models of visual attention. In Advances in neural information processing systems (pp.¬†2204-2212).\n\n(cited 2769 times)\n\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ‚Ä¶ & Polosukhin, I. (2017). Attention is all you need. In Advances in neural information processing systems (pp.¬†5998-6008)\n\n(cited 30999 times‚Ä¶)\n\n\nTransformers\n\n\n\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ‚Ä¶ & Polosukhin, I. (2017). Attention is all you need. In Advances in neural information processing systems (pp.¬†5998-6008)\n\n\nInitially used for NLP to replace RNN as they allow parallelization. Now entering the domain of vision and others. Very performant with relatively few parameters.\n\n\nSwin Transformer\nThe Swin Transformer improved the use of transformers to the vision domain.\nSwin = Shifted WINdows\nSwin transformer (left) vs transformer as initially applied to vision (right):\n\n\n\nLiu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., ‚Ä¶ & Guo, B. (2021). Swin transformer: Hierarchical vision transformer using shifted windows. arXiv preprint arXiv:2103.14030\n\n\n\n\nSwinIR\n\n\n\nLiang, J., Cao, J., Sun, G., Zhang, K., Van Gool, L., & Timofte, R. (2021). SwinIR: Image restoration using swin transformer. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp.¬†1833-1844)\n\n\n\n\nTraining sets used\nDIV2K, Flickr2K, and other datasets.\n\n\nModels assessment\n3 metrics commonly used:\nPeak sign-to-noise ratio (PSNR) measured in dB:\n\\(\\frac{\\text{Maximum possible power of signal}}{\\text{Power of noise (calculated as the mean squared error)}}\\)\nCalculated at the pixel level\n\\[PSNR = 10\\,\\cdot\\,log_{10}\\,\\left(\\frac{MAX_I^2}{MSE}\\right)\\]\nStructural similarity index measure (SSIM):\nPrediction of perceived image quality based on a ‚Äúperfect‚Äù reference image.\n\\[SSIM(x,y) = \\frac{(2\\mu_x\\mu_y + c_1) + (2 \\sigma _{xy} + c_2)}\n    {(\\mu_x^2 + \\mu_y^2+c_1) (\\sigma_x^2 + \\sigma_y^2+c_2)}\\]\nMean opinion score (MOS):\nMean of subjective quality ratings.\n\\[MOS = \\frac{\\sum_{n=1}^N R\\_n}{N}\\]\n\n\nMetrics implementation\n\nImplement them yourself (using torch.log10, etc.).\nUse some library that implements them (e.g.¬†kornia).\nUse code of open source project with good implementation (e.g.¬†SwinIR).\nUse some higher level library that provides them (e.g.¬†ignite).\nImplement them yourself (using torch.log10, etc.).\nUse some library that implements them (e.g.¬†kornia).\nUse code of open source project with good implementation (e.g.¬†SwinIR).\nUse some higher level library that provides them (e.g.¬†ignite).\n\nimport kornia\n\npsnr_value = kornia.metrics.psnr(input, target, max_val)\nssim_value = kornia.metrics.ssim(img1, img2, window_size, max_val=1.0, eps=1e-12)\nSee the Kornia documentation for more info on kornia.metrics.psnr and kornia.metrics.ssim.\n\n\nBenchmark datasets\nSet5:\n\nSet14:\n\nBSD100 (Berkeley Segmentation Dataset):\n\n\n\nThe Set5 dataset\nA dataset consisting of 5 images which has been used for at least 18 years to assess SR methods.\n\n\nHow to get the dataset?\nFrom the HuggingFace Datasets Hub with the HuggingFace datasets package:\nfrom datasets import load_dataset\n\nset5 = load_dataset('eugenesiow/Set5', 'bicubic_x4', split='validation')\n\n\nDataset exploration\nprint(set5)\nlen(set5)\nset5[0]\nset5.shape\nset5.column_names\nset5.features\nset5.set_format('torch', columns=['hr', 'lr'])\nset5.format\n\n\nBenchmarks\nA 2012 review of interpolation methods for SR gives the metrics for a series of interpolation methods (using other datasets).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpolation methods\n\n\n\n\n\n\nDL methods\nThe Papers with Code website lists available benchmarks on Set5:\n\n\n\nThe Papers with Code website\n\n\nPSNR vs number of parameters for different methods on Set5x4:\n\n\n\nLiang, J., Cao, J., Sun, G., Zhang, K., Van Gool, L., & Timofte, R. (2021). SwinIR: Image restoration using swin transformer. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp.¬†1833-1844)\n\n\nComparison between SwinIR & a representative CNN-based model (RCAN) on classical SR images x4:\n\n\n\nLiang, J., Cao, J., Sun, G., Zhang, K., Van Gool, L., & Timofte, R. (2021). SwinIR: Image restoration using swin transformer. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp.¬†1833-1844)\n\n\n\n\n\nLiang, J., Cao, J., Sun, G., Zhang, K., Van Gool, L., & Timofte, R. (2021). SwinIR: Image restoration using swin transformer. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp.¬†1833-1844)\n\n\n\n\n\nLiang, J., Cao, J., Sun, G., Zhang, K., Van Gool, L., & Timofte, R. (2021). SwinIR: Image restoration using swin transformer. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp.¬†1833-1844)\n\n\n\n\nLet‚Äôs use SwinIR\n# Get the model\ngit clone git@github.com:JingyunLiang/SwinIR.git\ncd SwinIR\n\n# Copy our test images in the repo\ncp -r &lt;some/path&gt;/my_tests /testsets/my_tests\n\n# Run the model on our images\npython main_test_swinir.py --tile 400 --task real_sr --scale 4 --large_model --model_path model_zoo/swinir/003_realSR_BSRGAN_DFOWMFC_s64w8_SwinIR-L_x4_GAN.pth --folder_lq testsets/my_tests\nRan in 9 min on my machine with one GPU and 32GB of RAM.\n\n\nResults\n\n\n\nInitial images:\n \n \n \n \n \n \n \n \n \n \n\n\nUpscaled images:\n \n \n \n \n \n \n \n \n \n \n\n\n\n\n\nMetrics\nWe could use the PSNR and SSIM implementations from SwinIR, but let‚Äôs try the Kornia functions we mentioned earlier:\n\nkornia.metrics.psnr\nkornia.metrics.ssim\n\nLet‚Äôs load the libraries we need:\nimport kornia\nfrom PIL import Image\nimport torch\nfrom torchvision import transforms\nThen, we load one pair images (LR and HR):\nberlin1_lr = Image.open(\"&lt;some/path&gt;/lr/berlin_1945_1.jpg\")\nberlin1_hr = Image.open(\"&lt;some/path&gt;/hr/berlin_1945_1.png\")\nWe can display these images with:\nberlin1_lr.show()\nberlin1_hr.show()\nNow, we need to resize them so that they have identical dimensions and turn them into tensors:\npreprocess = transforms.Compose([\n        transforms.Resize(256),\n        transforms.ToTensor()\n        ])\n\nberlin1_lr_t = preprocess(berlin1_lr)\nberlin1_hr_t = preprocess(berlin1_hr)\nberlin1_lr_t.shape\nberlin1_hr_t.shape\ntorch.Size([3, 267, 256])\ntorch.Size([3, 267, 256])\nWe now have tensors with 3 dimensions:\n\nthe channels (RGB),\nthe height of the image (in pixels),\nthe width of the image (in pixels).\n\nAs data processing is done in batch in ML, we need to add a 4th dimension: the batch size.\n(It will be equal to 1 since we have a batch size of a single image).\nbatch_berlin1_lr_t = torch.unsqueeze(berlin1_lr_t, 0)\nbatch_berlin1_hr_t = torch.unsqueeze(berlin1_hr_t, 0)\nOur new tensors are now ready:\nbatch_berlin1_lr_t.shape\nbatch_berlin1_hr_t.shape\ntorch.Size([1, 3, 267, 256])\ntorch.Size([1, 3, 267, 256])\n\n\nPSNR\npsnr_value = kornia.metrics.psnr(batch_berlin1_lr_t, batch_berlin1_hr_t, max_val=1.0)\npsnr_value.item()\n33.379642486572266\n\n\nSSIM\nssim_map = kornia.metrics.ssim(\n    batch_berlin1_lr_t, batch_berlin1_hr_t, window_size=5, max_val=1.0, eps=1e-12)\n\nssim_map.mean().item()\n0.9868119359016418",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Image upscaling",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/pt/ws_audio_dataloader.html",
    "href": "ai/pt/ws_audio_dataloader.html",
    "title": "Creating an audio DataLoader",
    "section": "",
    "text": "import torch\nimport torchaudio\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Audio DataLoader with PyTorch"
    ]
  },
  {
    "objectID": "ai/pt/ws_audio_dataloader.html#load-packages",
    "href": "ai/pt/ws_audio_dataloader.html#load-packages",
    "title": "Creating an audio DataLoader",
    "section": "",
    "text": "import torch\nimport torchaudio\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Audio DataLoader with PyTorch"
    ]
  },
  {
    "objectID": "ai/pt/ws_audio_dataloader.html#download-and-unzip-data",
    "href": "ai/pt/ws_audio_dataloader.html#download-and-unzip-data",
    "title": "Creating an audio DataLoader",
    "section": "Download and unzip data",
    "text": "Download and unzip data\nPyTorch comes with many classic datasets.\n\nExamples:\n\nlist of available datasets for vision\nlist of audio datasets\nlist of texts datasets\n\n\nThis is convenient to develop and test your model, or to compare its performance with existing models using these datasets.\nHere, we will use the YESNO dataset which can be accessed through the torchaudio.datasets.YESNO class:\nhelp(torchaudio.datasets.YESNO)\nHelp on class YESNO in module torchaudio.datasets.yesno:\n\nclass YESNO(torch.utils.data.dataset.Dataset)\n\n |  YESNO(root: Union[str, pathlib.Path], url: str =\n |    'http://www.openslr.org/resources/1/waves_yesno.tar.gz', \n |    folder_in_archive: str = 'waves_yesno', \n |    download: bool = False) -&gt; None\n |  \n |  Args:\n |    root (str or Path): Path to the directory where the dataset is found \n |      or downloaded.\n |    url (str, optional): The URL to download the dataset from.\n |      (default: \"http://www.openslr.org/resources/1/waves_yesno.tar.gz\")\n |    folder_in_archive (str, optional):\n |      The top-level directory of the dataset. (default: \"waves_yesno\")\n |    download (bool, optional):\n |      Whether to download the dataset if it is not found at root path. \n |      (default: False).\nThe root argument sets the location of the downloaded data.\n\nWhere to store this data in the cluster\nWe will all use the same data. It would make little sense to all download it in our home directory.\n\nIn the Alliance clusters, a good place to store data shared amongst members of a project is in the /project file system.\nYou usually belong to /project/def-&lt;group&gt;, where &lt;group&gt; is the name of your PI. You can access it from your home directory through the symbolic link ~/projects/def-&lt;group&gt;.\n\nIn our training cluster, we are all part of the group def-sponsor00, accessible through /project/def-sponsor00 (or the hyperlink ~/projects/def-sponsor00).\nWe will thus use ~/projects/def-sponsor00/data as the root argument for torchaudio.datasets.yesno):\nyesno_data = torchaudio.datasets.YESNO(\n    '~/projects/def-sponsor00/data/',\n    download=True)\n\n\n2.8%5.6%8.4%11.1%13.9%16.7%19.5%22.3%25.1%27.9%30.7%33.4%36.2%39.0%41.8%44.6%47.4%50.2%52.9%55.7%58.5%61.3%64.1%66.9%69.7%72.5%75.2%78.0%80.8%83.6%86.4%89.2%92.0%94.7%97.5%100.0%",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Audio DataLoader with PyTorch"
    ]
  },
  {
    "objectID": "ai/pt/ws_audio_dataloader.html#explore-the-data",
    "href": "ai/pt/ws_audio_dataloader.html#explore-the-data",
    "title": "Creating an audio DataLoader",
    "section": "Explore the data",
    "text": "Explore the data\nA data point in YESNO is a tuple of waveform, sample_rate, and labels (the labels are 1 for ‚Äúyes‚Äù and 0 for ‚Äúno‚Äù).\nLet‚Äôs have a look at the first data point:\n\nyesno_data[0]\n\n(tensor([[ 3.0518e-05,  6.1035e-05,  3.0518e-05,  ..., -1.8616e-03,\n          -2.2583e-03, -1.3733e-03]]),\n 8000,\n [0, 0, 0, 0, 1, 1, 1, 1])\n\n\nOr, more nicely:\n\nwaveform, sample_rate, labels = yesno_data[0]\nprint(\"Waveform: {}\\nSample rate: {}\\nLabels: {}\".format(waveform, sample_rate, labels))\n\nWaveform: tensor([[ 3.0518e-05,  6.1035e-05,  3.0518e-05,  ..., -1.8616e-03,\n         -2.2583e-03, -1.3733e-03]])\nSample rate: 8000\nLabels: [0, 0, 0, 0, 1, 1, 1, 1]\n\n\nYou can also plot the data. For this, we will use pyplot from matplotlib.\nLet‚Äôs look at the waveform:\n\nplt.figure()\nplt.plot(waveform.t().numpy())",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Audio DataLoader with PyTorch"
    ]
  },
  {
    "objectID": "ai/pt/ws_audio_dataloader.html#split-the-data-into-a-training-set-and-a-testing-set",
    "href": "ai/pt/ws_audio_dataloader.html#split-the-data-into-a-training-set-and-a-testing-set",
    "title": "Creating an audio DataLoader",
    "section": "Split the data into a training set and a testing set",
    "text": "Split the data into a training set and a testing set\n\ntrain_size = int(0.8 * len(yesno_data))\ntest_size = len(yesno_data) - train_size\ntrain_dataset, test_dataset = torch.utils.data.random_split(yesno_data, [train_size, test_size])",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Audio DataLoader with PyTorch"
    ]
  },
  {
    "objectID": "ai/pt/ws_audio_dataloader.html#create-training-and-testing-dataloaders",
    "href": "ai/pt/ws_audio_dataloader.html#create-training-and-testing-dataloaders",
    "title": "Creating an audio DataLoader",
    "section": "Create training and testing DataLoaders",
    "text": "Create training and testing DataLoaders\nDataLoaders are Python iterables created by the torch.utils.data.DataLoader class from a dataset and a sampler.\nWe already have a dataset (yesno_data). Now we need a sampler (or sampling strategy) to draw samples from it. The sampling strategy contains the batch size, whether the data get shuffled prior to sampling, the number of workers used if the data is loaded in parallel, etc.\nTo create a training DataLoader with shuffled data and batch size of 1 (the default), we run:\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True)\n\ndata_loader is an iterable of 0.8*60=48 elements (80% of the 60 samples in the YESNO dataset):\n\nlen(train_loader)\n\n48\n\n\nWe do the same to create the testing DataLoader:\n\ntest_loader = torch.utils.data.DataLoader(test_dataset, shuffle=True)",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Audio DataLoader with PyTorch"
    ]
  },
  {
    "objectID": "ai/sk_intro.html",
    "href": "ai/sk_intro.html",
    "title": "Introduction",
    "section": "",
    "text": "What is scikit-learn and how does it fit in the wide landscape of machine learning frameworks?",
    "crumbs": [
      "AI",
      "<b><em>ML with Scikit-learn</em></b>"
    ]
  },
  {
    "objectID": "ai/sk_intro.html#what-is-machine-learning",
    "href": "ai/sk_intro.html#what-is-machine-learning",
    "title": "Introduction",
    "section": "What is machine learning?",
    "text": "What is machine learning?\nMaybe we should start with some definitions:\n\nArtificial intelligence (AI) can be defined as any human-made system mimicking animal intelligence. This is a large and very diverse field.\nMachine learning (ML) is a subfield of AI that can be defined as computer programs whose performance at a task improves with experience. This learning can be split into three categories:\n\nSupervised learning\nRegression is a form of supervised learning with continuous outputs. Classification is supervised learning with discrete outputs.\nSupervised learning uses training data in the form of example input/output pairs.\nThe goal is to find the relationship between inputs and outputs.\nUnsupervised learning\nClustering, social network analysis, market segmentation, dimensionality reduction (e.g.¬†PCA), anomaly detection ‚Ä¶ are all forms of unsupervised learning.\nUnsupervised learning uses unlabelled data and the goal is to find patterns within the data.\nReinforcement learning\nThe algorithm explores by performing random actions and these actions are rewarded or punished (bonus points or penalties).\nThis is how algorithms learn to play games.\n\nDeep learning (DL) is itself a subfield of machine learning using deep artificial neural networks.",
    "crumbs": [
      "AI",
      "<b><em>ML with Scikit-learn</em></b>"
    ]
  },
  {
    "objectID": "ai/sk_intro.html#what-is-scikit-learn",
    "href": "ai/sk_intro.html#what-is-scikit-learn",
    "title": "Introduction",
    "section": "What is scikit-learn?",
    "text": "What is scikit-learn?\nScikit-learn (also called sklearn) is a free and open source set of libraries for Python built on top of SciPy (thus using NumPy‚Äôs ndarray as the main data structure) used for machine learning.\nSklearn is a rich toolkit characterized by a clean, consistent, and very simple API.\nIt is easy to learn and very well documented. You can think of it as a vast collection of routines that are easy to apply and require little computing power.\n\n\n\nfrom scikit-learn.org",
    "crumbs": [
      "AI",
      "<b><em>ML with Scikit-learn</em></b>"
    ]
  },
  {
    "objectID": "ai/sk_intro.html#scikit-learn-in-the-ml-landscape",
    "href": "ai/sk_intro.html#scikit-learn-in-the-ml-landscape",
    "title": "Introduction",
    "section": "Scikit-learn in the ML landscape",
    "text": "Scikit-learn in the ML landscape\nThere are many machine learning frameworks. While sklearn has many advantages (ease of use, wide range of tools), it has clear limitations: there is no GPU support and deep learning and reinforcement learning are out of its scope (the only neural network implemented is a multilayer perceptron (an historical, very basic, and terribly inefficient neural network).\nIf you want to access the power and flexibility that deep neural networks provide, you should turn towards tools such as PyTorch (wonderful tool both in academia, research, and industry) or the higher-level Keras (easy API, easy to learn, but less flexible).",
    "crumbs": [
      "AI",
      "<b><em>ML with Scikit-learn</em></b>"
    ]
  },
  {
    "objectID": "ai/top_fl.html",
    "href": "ai/top_fl.html",
    "title": "Deep learning with JAX",
    "section": "",
    "text": "JAX is a fast open source Python library for function transformations (including differentiation) and array computations on accelerators (GPUs/TPUs). These attributes make it ideal for deep learning, but JAX is not, in itself, a deep learning library: it provides a structural framework on which libraries can be built without providing domain-specific tooling.\nTo make full use of JAX‚Äôs flexible autodiff and enhanced efficiency for deep learning while maintaining a syntax familiar to PyTorch users, a solid approach consists of using TorchData, TensorFlow Datasets, Grain, or Hugging Face Datasets to load the data, Flax to build neural networks, Optax for optimization, and Orbax for checkpointing.\nThis introductory course does not require any prior knowledge.\n\n Start course ‚û§",
    "crumbs": [
      "AI",
      "<b><em>Intro DL with JAX</em></b>"
    ]
  },
  {
    "objectID": "ai/top_jxai.html",
    "href": "ai/top_jxai.html",
    "title": "Deep learning with the JAX AI stack",
    "section": "",
    "text": "This example-based course takes you through the initial steps necessary to go from your own data to a trained model.\nIt uses a computer vision classification problem as the study case and a modern and efficiency-oriented stack of libraries as the tools, including:\n\nPolars for faster DataFrames,\nImageIO for reading in images into ndarrays,\nGrain or PyTorch for datasets classes and dataloaders,\nPIX for data augmentation,\nJAX for JIT compilation, accelerators use, automatic vectorization, and automatic differentiation,\nFlax for neural networks building,\nOrbax for checkpointing,\nOptax for optimization.\n\nThe main objective is to help you get started with deep learning by explaining concepts such as dataset classes, dataloaders, data augmentation, training, etc. as we move along our study case.\nWhile deep learning concepts are relatively simple, it is often a frustrating affair to get anything to work and to adapt documentation or online tutorials to your own data. By walking through this together, we will hopefully make this part less challenging when you try it on your own.\nAlong the way, I will introduce core JAX concepts and get you started with this powerful library.\nThis course doesn‚Äôt have prerequisites, although some knowledge of Python, NumPy, and a basic understanding of neural networks help.\n\n Start course ‚û§",
    "crumbs": [
      "AI",
      "<b><em>DL with the JAX AI stack</em></b>"
    ]
  },
  {
    "objectID": "ai/top_wb.html",
    "href": "ai/top_wb.html",
    "title": "AI webinars",
    "section": "",
    "text": "Map of current ML frameworks\n\n\n\n\nModel version control with\n\n\n\n\nAccelerated array & autodiff with \n\n\n\n\nImage upscaling (super-resolution)\n\n\n\n\n\n\nAI-powered coding with ¬†\n\n\n\n\nEasier ¬†¬† with fastai\n\n\n\n\nDL in  with \n\n\n\n\n¬† tensors in depth\n\n\n\n\n\n\nBayesian inference in \n\n\n\n\nExperiment tracking with",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>"
    ]
  },
  {
    "objectID": "ai/wb_copilot.html",
    "href": "ai/wb_copilot.html",
    "title": "AI-powered programming with Copilot",
    "section": "",
    "text": "The recent advances in generative AI have brought about a number of code generators and code-completion assistants. This webinar will give an overview of the state of the field, briefly explain the functioning of various types of tools, then focus on GitHub Copilot.\nCopilot is developed by GitHub and OpenAI. It is a cloud-based service requiring a subscription, but students and teachers can apply for free access. It can be used directly in the command line or as an extension to text editors such as VS Code, Emacs, or Neovim.\nI will demo Copilot‚Äôs main features:\n\nprovide live code-completion,\nturn comments into code,\ntranslate from one programming language to another.\n\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "AI-powered coding"
    ]
  },
  {
    "objectID": "ai/wb_copilot_slides.html#codex",
    "href": "ai/wb_copilot_slides.html#codex",
    "title": "AI-powered programming with",
    "section": "Codex",
    "text": "Codex\nOpenAI Codex‚Äîbased on GPT-3‚Äîis the model behind GitHub Copilot\nAll the big corporate companies are rushing to launch a growing number of similar (and not free, not open source) productivity products (e.g.¬†tabnine, Microsoft Visual Studio IntelliCode, Amazon CodeWhisperer)\nThese products generate code in a narrow context (auto-completion or transformation of natural language to code or vise-versa)"
  },
  {
    "objectID": "ai/wb_copilot_slides.html#alphacode-2",
    "href": "ai/wb_copilot_slides.html#alphacode-2",
    "title": "AI-powered programming with",
    "section": "AlphaCode 2",
    "text": "AlphaCode 2\nGoogle DeepMind AlphaCode 2‚Äîbased on Gemini‚Äîstands out as a totally different (and for now totally unavailable) product generating code at the level of competitive programming (reaching the 85th percentile)\nThink of it as code evolution by ‚Äúnatural‚Äù selection:\n\na very large number of code samples are generated (think ‚Äúmutations‚Äù)\na filtering and scoring system selects for the best candidates (that‚Äôs the selection part)\n\nAlphaCode 2 is able to solve much more open-ended problems"
  },
  {
    "objectID": "ai/wb_copilot_slides.html#what-about-foss",
    "href": "ai/wb_copilot_slides.html#what-about-foss",
    "title": "AI-powered programming with",
    "section": "What about FOSS?",
    "text": "What about FOSS?\nFree\nThese models are large and most convenient to run on servers\n‚ÄÉ‚Üí Price of cloud service\nSome self-hosted options exist. A very promising one is Tabby. Not practical for everyone\nOpen source\nWhile these models feed from open source code, they are themselves not open source üôÅ\nThe open source community is trying to provide open source alternatives (e.g.¬†Tabby). Despite the much more limited resources, the performance of some of these alternatives is very good"
  },
  {
    "objectID": "ai/wb_copilot_slides.html#what-is-github-copilot",
    "href": "ai/wb_copilot_slides.html#what-is-github-copilot",
    "title": "AI-powered programming with",
    "section": "What is GitHub Copilot?",
    "text": "What is GitHub Copilot?\n\n¬†‚Üí Cloud-hosted AI programming assistant\n\n\nDeveloped by GitHub (Microsoft)\nRunning Codex, a model by OpenAI derived from the LLM GPT-3 and trained on open source code"
  },
  {
    "objectID": "ai/wb_copilot_slides.html#access",
    "href": "ai/wb_copilot_slides.html#access",
    "title": "AI-powered programming with",
    "section": "Access",
    "text": "Access\nIndividual or organization GitHub accounts\nRequires subscription\nStudents, teachers, and maintainers of popular open source projects can apply for free access"
  },
  {
    "objectID": "ai/wb_copilot_slides.html#safety",
    "href": "ai/wb_copilot_slides.html#safety",
    "title": "AI-powered programming with",
    "section": "Safety",
    "text": "Safety\nFilters are in place for offensive words, but‚Ä¶\nGenerated code comes with no guaranty of safety or quality\nA lawsuit is open against GitHub Copilot for licenses violation"
  },
  {
    "objectID": "ai/wb_copilot_slides.html#supported-languages",
    "href": "ai/wb_copilot_slides.html#supported-languages",
    "title": "AI-powered programming with",
    "section": "Supported languages",
    "text": "Supported languages\nAny language used in public repos\nQuality of suggestions is higher for languages with lots of data"
  },
  {
    "objectID": "ai/wb_copilot_slides.html#how-to-use-it",
    "href": "ai/wb_copilot_slides.html#how-to-use-it",
    "title": "AI-powered programming with",
    "section": "How to use it?",
    "text": "How to use it?\n\nStart typing code and get autocomplete suggestions\n\n\nWrite comments describing what the code should do and get code generation based on context\n\n\nIt is easy to:\n‚ÄÉ‚ÄÉ‚Üí accept suggestions word by word\n‚ÄÉ‚ÄÉ‚Üí line by line\n‚ÄÉ‚ÄÉ‚Üí for entire functions\n‚ÄÉ‚ÄÉ‚Üí cycle through different suggestions"
  },
  {
    "objectID": "ai/wb_copilot_slides.html#interface",
    "href": "ai/wb_copilot_slides.html#interface",
    "title": "AI-powered programming with",
    "section": "Interface",
    "text": "Interface\nExtensions to text editors:\n‚ÄÉ‚ÄÇ‚Üí Visual Studio Code/Visual Studio\n‚ÄÉ‚ÄÇ‚Üí Vim/Neovim/Emacs\n‚ÄÉ‚ÄÇ‚Üí JetBrains IDEs\n‚ÄÉ‚ÄÇ‚Üí Azure Data Studio"
  },
  {
    "objectID": "ai/wb_copilot_slides.html#get-a-subscription",
    "href": "ai/wb_copilot_slides.html#get-a-subscription",
    "title": "AI-powered programming with",
    "section": "Get a subscription",
    "text": "Get a subscription\nGo to your GitHub account page\n‚ÄÉ‚ÄÇ‚Üí Settings\n‚ÄÉ‚ÄÇ‚Üí Copilot\n‚ÄÉ‚ÄÇ‚Üí Enable\nProvide free access or payment method\nSet settings"
  },
  {
    "objectID": "ai/wb_copilot_slides.html#vs-code",
    "href": "ai/wb_copilot_slides.html#vs-code",
    "title": "AI-powered programming with",
    "section": "VS Code",
    "text": "VS Code\n\nInstall the GitHub Copilot extension\n\n\nNext suggestion: ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ¬†Alt+]\nPrevious suggestion: ‚ÄÉ‚ÄÉ‚ÄÉ¬†¬†Alt+[\nReject suggestion: ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇ¬†Esc\nAccept suggestion: ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇTab\nAccept next suggested word: Ctrl+‚Üí ¬†(Command+‚Üí ¬†for macOS)\nSet your own key binding for editor.action.inlineSuggest.acceptNextLine to accept next suggested line\nOpen new tab with options: ‚ÄÇCtrl+Enter\nYou can also hover over suggestions"
  },
  {
    "objectID": "ai/wb_copilot_slides.html#vimneovim",
    "href": "ai/wb_copilot_slides.html#vimneovim",
    "title": "AI-powered programming with",
    "section": "Vim/Neovim",
    "text": "Vim/Neovim\nInstall Node.js\nClone https://github.com/github/copilot.vim\nConfigure:\n:Copilot setup\nEnable:\n:Copilot enable\nGet help:\n:help copilot"
  },
  {
    "objectID": "ai/wb_copilot_slides.html#emacs",
    "href": "ai/wb_copilot_slides.html#emacs",
    "title": "AI-powered programming with",
    "section": "Emacs",
    "text": "Emacs\nInstall Node.js\nAssuming straight is installed:\n(straight-use-package 'editorconfig)                   ; Copilot dependency\n\n(use-package copilot\n    :straight (:host github\n                     :repo \"copilot-emacs/copilot.el\"\n                     :files (\"dist\" \"*.el\"))\n    :hook (prog-mode . copilot-mode)                   ; Settings up to you\n    :bind ((\"C-8\" . copilot-complete)\n           :map copilot-completion-map\n           (\"C-j\" . copilot-accept-completion)\n           (\"C-f\" . copilot-accept-completion-by-word)\n           (\"C-t\" . copilot-accept-completion-by-line)\n           (\"C-n\" . copilot-next-completion)\n           (\"C-p\" . copilot-previous-completion)))\nLogin to your GitHub account (only needs to be done once): M-x copilot-login"
  },
  {
    "objectID": "ai/wb_copilot_slides.html#what-is-copilot-in-the-cli",
    "href": "ai/wb_copilot_slides.html#what-is-copilot-in-the-cli",
    "title": "AI-powered programming with",
    "section": "What is Copilot in the CLI?",
    "text": "What is Copilot in the CLI?\nIn beta\nAn extension to GitHub CLI (GitHub operations from the CLI)\n‚ÄÉ‚Üí Generate commands from natural language\n‚ÄÉ‚Üí Generate natural language explanations from commands\nTrained on data up to 2021\nLower performance for natural languages ‚â† English\nBe very careful: the command line is powerful and you can delete your data or mess up your system if you don‚Äôt know what you are doing. Check commands carefully!"
  },
  {
    "objectID": "ai/wb_copilot_slides.html#setup-1",
    "href": "ai/wb_copilot_slides.html#setup-1",
    "title": "AI-powered programming with",
    "section": "Setup",
    "text": "Setup\n\nInstall GitHub CLI\nConnect to your GitHub account:\ngh auth login\n\n\n Install Copilot in the CLI:\ngh extension install github/gh-copilot\n\nUpdate with: gh extension upgrade gh-copilot"
  },
  {
    "objectID": "ai/wb_copilot_slides.html#usage",
    "href": "ai/wb_copilot_slides.html#usage",
    "title": "AI-powered programming with",
    "section": "Usage",
    "text": "Usage\nGet code explanations:\ngh copilot explain\n Get code from natural language:\ngh copilot suggest"
  },
  {
    "objectID": "ai/wb_copilot_slides.html#resources",
    "href": "ai/wb_copilot_slides.html#resources",
    "title": "AI-powered programming with",
    "section": "Resources",
    "text": "Resources\nGitHub support portal\nGitHub Copilot documentation\nStack Overflow [github-copilot] tag\ncopilot.el (unofficial Emacs plug-in)"
  },
  {
    "objectID": "ai/wb_dvc_content.html",
    "href": "ai/wb_dvc_content.html",
    "title": "Version control for data science & machine learning with DVC",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Data & model version control",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/wb_dvc_content.html#on-version-control",
    "href": "ai/wb_dvc_content.html#on-version-control",
    "title": "Version control for data science & machine learning with DVC",
    "section": "On version control",
    "text": "On version control\nI won‚Äôt introduce here the benefits of using a good version control system such as Git.\n\n\n\nOn the benefits of VCS\n\n\n\nExtending Git for data\nWhile Git is a wonderful tool for text files versioning (code, writings in markup formats), it isn‚Äôt a tool to manage changes to datasets.\nSeveral open source tools‚Äîeach with a different structure and functioning‚Äîextend Git capabilities to track data: Git LFS, git-annex, lakeFS, Dolt, DataLad.\n\n\nGit for models and experiments\nReproducible research and collaboration on data science and machine learning projects involve more than datasets management:\nExperiments and the models they produce also need to be tracked.\n\n\nMany moving parts\n\n*hp = hyperparameter\n\n\n\n\n\n\n\n\n\n\ndata1\n\ndata1\n\n\n\nmodel1\n\nmodel1\n\n\n\ndata1-&gt;model1\n\n\n\n\n\nmodel2\n\nmodel2\n\n\n\ndata1-&gt;model2\n\n\n\n\n\nmodel3\n\nmodel3\n\n\n\ndata1-&gt;model3\n\n\n\n\n\ndata2\n\ndata2\n\n\n\ndata2-&gt;model1\n\n\n\n\n\ndata2-&gt;model2\n\n\n\n\n\ndata2-&gt;model3\n\n\n\n\n\ndata3\n\ndata3\n\n\n\ndata3-&gt;model1\n\n\n\n\n\ndata3-&gt;model2\n\n\n\n\n\ndata3-&gt;model3\n\n\n\n\n\nhp1\n\nhp1\n\n\n\nhp1-&gt;model1\n\n\n\n\n\nhp1-&gt;model2\n\n\n\n\n\nhp1-&gt;model3\n\n\n\n\n\nhp2\n\nhp2\n\n\n\nhp2-&gt;model1\n\n\n\n\n\nhp2-&gt;model2\n\n\n\n\n\nhp2-&gt;model3\n\n\n\n\n\nhp3\n\nhp3\n\n\n\nhp3-&gt;model1\n\n\n\n\n\nhp3-&gt;model2\n\n\n\n\n\nhp3-&gt;model3\n\n\n\n\n\nperformance\n\nperformance1 ... performance27\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\n\n\n\n\n\nHow did we get performance17 again? ü§Ø",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Data & model version control",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/wb_dvc_content.html#enters-dvc",
    "href": "ai/wb_dvc_content.html#enters-dvc",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Enters DVC",
    "text": "Enters DVC\n\nDVC principles\n\nLarge files (datasets, models‚Ä¶) are kept outside Git.\nEach large file or directory put under DVC tracking has an associated .dvc file.\nGit only tracks the .dvc files (metadata).\n\nWorkflows can be tracked for collaboration and reproducibility.\nDVC functions as a Makefile and allows to only rerun what is necessary.\n\n\nInstallation\nFor Linux (other OSes, refer to the doc):\n\npip:\npip install dvc\nconda\npipx (if you want dvc available everywhere without having to activate virtual envs):\npipx install dvc\n\n\nOptional dependencies [s3], [gdrive], etc. for remote storage.\n\n\n\nHow to run\nMultiple options:\n\nTerminal:\ndvc ...\nVS Code extension\nPython library if installed via pip or conda:\nimport dvc.api\n\n\nIn this webinar, I will use DVC through the command line.\n\n\n\nAcknowledgements\nCode and data for this webinar modified from:\n\nReal Python\nDataLad handbook\nDVC documentation\n\n\n\nThe project\ntree -L 3\n‚îú‚îÄ‚îÄ LICENSE\n‚îú‚îÄ‚îÄ data\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ prepared\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ raw\n‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ train\n‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ val\n‚îú‚îÄ‚îÄ metrics\n‚îú‚îÄ‚îÄ model\n‚îú‚îÄ‚îÄ requirements.txt\n‚îî‚îÄ‚îÄ src\n    ‚îú‚îÄ‚îÄ evaluate.py\n    ‚îú‚îÄ‚îÄ prepare.py\n    ‚îî‚îÄ‚îÄ train.py\n\n\nInitialize Git repo\ngit init\nInitialized empty Git repository in dvc/.git/\nThis creates the .git directory.\ngit status\nOn branch main\n\nNo commits yet\n\nUntracked files:\n    LICENSE\n    data/\n    requirements.txt\n    src/\n\n\nInitialize DVC project\ndvc init\nInitialized DVC repository.\n\nYou can now commit the changes to git.\n\nYou will also see a note about usage analytics collection and info on how to opt out.\n\nA .dvc directory and a .dvcignore file got created.\n\n\nCommit DVC system files\nDVC automatically staged its system file for us:\ngit status\nOn branch main\n\nNo commits yet\n\nChanges to be committed:\n    new file:   .dvc/.gitignore\n    new file:   .dvc/config\n    new file:   .dvcignore\n\nUntracked files:\n    LICENSE\n    data/\n    requirements.txt\n    src/\nSo we can directly commit:\ngit commit -m \"Initialize DVC\"\n\n\nPrepare repo\nLet‚Äôs work in a virtual environment:\n# Create venv and add to .gitignore\npython -m venv venv && echo venv &gt; .gitignore\n\n# Activate venv\nsource venv/bin/activate\n\n# Update pip\npython -m pip install --upgrade pip\n\n# Install packages needed\npython -m pip install -r requirements.txt\n\n\nClean working tree\ngit add .gitignore LICENSE requirements.txt\ngit commit -m \"Add general files\"\ngit add src\ngit commit -m \"Add scripts\"\ngit status\nOn branch main\nUntracked files:\n    data/\n\nNow, it is time to deal with the data.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Data & model version control",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/wb_dvc_content.html#tracking-data-with-dvc",
    "href": "ai/wb_dvc_content.html#tracking-data-with-dvc",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Tracking data with DVC",
    "text": "Tracking data with DVC\n\nPut data under DVC tracking\nWe are still not tracking any data:\ndvc status\nThere are no data or pipelines tracked in this project yet.\nYou can choose what to track as a unit (i.e.¬†each picture individually, the whole data directory as a unit).\nLet‚Äôs break it down by set:\ndvc add data/raw/train\ndvc add data/raw/val\nThis adds data to .dvc/cache/files and created 3 files in data/raw:\n\n.gitignore\ntrain.dvc\nval.dvc\n\nThe .gitignore tells Git not to track the data:\ncat data/raw/.gitignore\n/train\n/val\nThe .dvc files contain the metadata for the cached directories.\n\n\nTracked data\nWe are all good:\ndvc status\nData and pipelines are up to date.\n\n\nData (de)duplication\nLink between checked-out version of a file/directory and the cache:\n\n\n\n\n\n\n\n\n\nDuplication\nEditable\n\n\n\n\nReflinks*\nOnly when needed\nYes\n\n\nHardlinks/Symlinks\nNo\nNo\n\n\nCopies\nYes\nYes\n\n\n\n\n*Reflinks only available for a few file systems (Btrfs, XFS, OCFS2, or APFS).\n\n\n\nCommit the metafiles\nThe metafiles should be put under Git version control.\n\nYou can configure DVC to automatically stage its newly created system files:\ndvc config [--system] [--global] core.autostage true\n\nYou can then commit directly:\ngit commit -m \"Initial version of data\"\ngit status\nOn branch main\nnothing to commit, working tree clean\n\n\nTrack changes to the data\nLet‚Äôs make some change to the data:\nrm data/raw/val/n03445777/ILSVRC2012_val*\nRemember that Git is not tracking the data:\ngit status\nOn branch main\nnothing to commit, working tree clean\nBut DVC is:\ndvc status\ndata/raw/val.dvc:\n    changed outs:\n            modified:           data/raw/val\n\n\nAdd changes to DVC\ndvc add data/raw/val\ndvc status\nData and pipelines are up to date.\nNow we need to commit the changes to the .dvc file to Git:\ngit status\nOn branch main\nChanges to be committed:\n    modified:   data/raw/val.dvc\n\nStaging happened automatically because I have set the autostage option to true on my system.\n\ngit commit -m \"Delete data/raw/val/n03445777/ILSVRC2012_val*\"\n\n\nCheck out older versions\nWhat if we want to go back to the 1st version of our data?\nFor this, we first use Git to checkout the proper commit, then run dvc checkout to have the data catch up to the .dvc file.\nTo avoid forgetting to run the commands that will make DVC catch up to Git, we can automate this process by installing Git hooks:\ndvc install\n\nNow, all we have to do is to checkout the commit we want:\ngit log --oneline\n94b520b (HEAD -&gt; main) Delete data/raw/val/n03445777/ILSVRC2012_val*\n92837a6 Initial version of data\ndd961c6 Add scripts\ndb9c14e Initialize repo\n7e08586 Initialize DVC\ngit checkout 92837a6\nThe version of the data in the working directory got automatically switched to match the .dvc file:\ndvc status\nData and pipelines are up to date.\nYou can look at your files to verify that the deleted files are back.\n\n\nGit workflows\ngit checkout is ok to have a look, but a detached HEAD is not a good place to create new commits.\nLet‚Äôs create a new branch and switch to it:\ngit switch -c alternative\nSwitched to a new branch 'alternative'\nGoing back and forth between both versions of our data is now as simple as switching branch:\ngit switch main\ngit switch alternative",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Data & model version control",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/wb_dvc_content.html#collaboration",
    "href": "ai/wb_dvc_content.html#collaboration",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Collaboration",
    "text": "Collaboration\n\nClassic workflow\nThe Git project (including .dvc files) go to a Git remote (GitHub/GitLab/Bitbucket/server).\nThe data go to a DVC remote (AWS/Azure/Google Drive/server/etc.).\n\n\nDVC remotes\nDVC can use many cloud storage or remote machines/server via SSH, WebDAV, etc.\nLet‚Äôs create a local remote here:\n# Create a directory outside the project\nmkdir ../remote\n\n# Setup default (-d) remote\ndvc remote add -d local_remote ../remote\nSetting 'local_remote' as a default remote.\ncat .dvc/config\n[core]\n    remote = local_remote\n['remote \"local_remote\"']\n    url = ../../remote\n\n\nCommit remote config\nThe new remote configuration should be committed:\ngit status\nOn branch alternative\n\nChanges not staged for commit:\n    modified:   .dvc/config\ngit add .\ngit commit -m \"Config remote\"\n\n\nPush to remotes\nLet‚Äôs push the data from the cache (.dvc/cache) to the remote:\ndvc push\n2702 files pushed\n\nWith Git hooks installed, dvc push is automatically run after git push.\n(But the data is pushed to the DVC remote while the files tracked by Git get pushed to the Git remote).\n\nBy default, the entire data cache gets pushed to the remote, but there are many options.\n\nExample: only push data corresponding to a certain .dvc files.\ndvc push data/raw/val.dvc\n\n\n\nPull from remotes\ndvc fetch downloads data from the remote into the cache. To have it update the working directory, follow by dvc checkout.\nYou can do these 2 commands at the same time with dvc pull.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Data & model version control",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/wb_dvc_content.html#tracking-experiments",
    "href": "ai/wb_dvc_content.html#tracking-experiments",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Tracking experiments",
    "text": "Tracking experiments\n\nDVC pipelines\nDVC pipelines create reproducible workflows and are functionally similar to Makefiles.\nEach step in a pipeline is created with dvc stage add and add an entry to a dvc.yaml file.\n\ndvc stage add options:\n-n: name of stage\n-d: dependency\n-o: output\n\nEach stage contains:\n\ncmd: the command executed\ndeps: the dependencies\nouts: the outputs\n\nThe file is then used to visualize the pipeline and run it.\n\n\nExample\nLet‚Äôs create a pipeline to run a classifier on our data.\nThe pipeline contains 3 steps:\n\nprepare\ntrain\nevaluate\n\n\n\nCreate a pipeline\n\n1st stage (data preparation)\ndvc stage add -n prepare -d src/prepare.py -d data/raw \\\n    -o data/prepared/train.csv -o data/prepared/test.csv \\\n    python src/prepare.py\nAdded stage 'prepare' in 'dvc.yaml'\n\n\n2nd stage (training)\ndvc stage add -n train -d src/train.py -d data/prepared/train.csv \\\n    -o model/model.joblib \\\n    python src/train.py\nAdded stage `train` in 'dvc.yaml'\n\n\n3rd stage (evaluation)\ndvc stage add -n evaluate -d src/evaluate.py -d model/model.joblib \\\n    -M metrics/accuracy.json \\\n    python src/evaluate.py\nAdded stage `evaluate` in 'dvc.yaml'\n\n\n\nCommit pipeline\ngit commit -m \"Define pipeline\"\nprepare:\n    changed deps:\n            modified:           data/raw\n            modified:           src/prepare.py\n    changed outs:\n            deleted:            data/prepared/test.csv\n            deleted:            data/prepared/train.csv\ntrain:\n    changed deps:\n            deleted:            data/prepared/train.csv\n            modified:           src/train.py\n    changed outs:\n            deleted:            model/model.joblib\nevaluate:\n    changed deps:\n            deleted:            model/model.joblib\n            modified:           src/evaluate.py\n    changed outs:\n            deleted:            metrics/accuracy.json\n[main 4aa331b] Define pipeline\n 3 files changed, 27 insertions(+)\n create mode 100644 data/prepared/.gitignore\n create mode 100644 dvc.yaml\n create mode 100644 model/.gitignore\n\n\nVisualize pipeline in a DAG\ndvc dag\n+--------------------+         +------------------+\n| data/raw/train.dvc |         | data/raw/val.dvc |\n+--------------------+         +------------------+\n                  ***           ***\n                     **       **\n                       **   **\n                    +---------+\n                    | prepare |\n                    +---------+\n                          *\n                          *\n                          *\n                      +-------+\n                      | train |\n                      +-------+\n                          *\n                          *\n                          *\n                    +----------+\n                    | evaluate |\n                    +----------+\n\n\nRun pipeline\ndvc repro\n'data/raw/train.dvc' didn't change, skipping\n'data/raw/val.dvc' didn't change, skipping\nRunning stage 'prepare':\n&gt; python src/prepare.py\nGenerating lock file 'dvc.lock'\nUpdating lock file 'dvc.lock'\n\nRunning stage 'train':\n&gt; python src/train.py\nUpdating lock file 'dvc.lock'\n\nRunning stage 'evaluate':\n&gt; python src/evaluate.py\nUpdating lock file 'dvc.lock'\nUse `dvc push` to send your updates to remote storage.\n\n\ndvc repro breakdown\n\ndvc repro runs the dvc.yaml file in a Makefile fashion.\nFirst, it looks at the dependencies: the data didn‚Äôt change.\nThen it ran the commands to produce the outputs (since it is our first run, we had no outputs).\nWhen the 1st stage is run, a dvc.lock is created with information on that part of the run.\nWhen the 2nd and 3rd stages are run, dvc.lock is updated. At the end of the run dvc.lock contains all the info about the run we just did (version of the data used, etc.).\nA new directory called runs is created in .dvc/cache with cached data for this run.\n\n\n\nResults of the run\n\nThe prepared data was created in data/prepared (with a .gitignore to exclude it from Git‚Äîyou don‚Äôt want to track results in Git, but the scripts that can reproduce them).\nA model was saved in model (with another .gitignore file).\nThe accuracy of this run was created in metrics.\n\n\n\nClean working tree\nNow, we definitely want to create a commit with the dvc.lock.\nWe could add the metrics resulting from this run in the same commit:\ngit add metrics\ngit commit -m \"First pipeline run and results\"\nOur working tree is now clean and our data/pipeline up to date:\ngit status\nOn branch alternative\nnothing to commit, working tree clean\ndvc status\nData and pipelines are up to date.\n\n\nModify pipeline\nFrom now on, if we edit one of the scripts, or one of the dependencies, dvc status will tell us what changed and dvc repro will only rerun the parts of the pipeline to update the result, pretty much as a Makefile would.\n\n\nGoing further ‚Ä¶ next time\nDVC is a sophisticated tool with many additional features:\n\nCreation of data registries\nDVCLive (Python library to log experiment metrics).\nVisualize the performance logs as plots.\nContinuous integration with CML (Continuous Machine Learning).",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Data & model version control",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/wb_flux.html",
    "href": "ai/wb_flux.html",
    "title": "Machine learning in Julia with Flux",
    "section": "",
    "text": "This webinar, aimed at users with no experience in machine learning, is an introduction to the basic concepts of neural networks, followed by a simple example‚Äîthe classic classification of the MNIST database of handwritten digits‚Äîusing the Julia package Flux.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "DL in Julia with Flux"
    ]
  },
  {
    "objectID": "ai/wb_frameworks_content.html",
    "href": "ai/wb_frameworks_content.html",
    "title": "A map of current ML frameworks",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Current ML frameworks",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/wb_frameworks_content.html#disclaimers",
    "href": "ai/wb_frameworks_content.html#disclaimers",
    "title": "A map of current ML frameworks",
    "section": "Disclaimers",
    "text": "Disclaimers\nKeeping up with the ever evolving field of machine learning is daunting. This webinar aims to bring a little help in this navigation and maybe inspire you to explore new tools. It is however flawed in several ways:\n\nit is not exhaustive and focuses on the most used frameworks accessible through 3 popular languages,\na lot of the content could be accused of being biased and subjective,\nit will be outdated quickly.\n\nUltimately, the best frameworks are the ones that work best for you and your needs. The only piece of advice I would give is to always use open source tools.\n\n\n\n\n\n\n\n\n\nTraditional machine learning\\n(ML)\\n‚Üí computational statistics\\n‚Üí predictive analytics\n\nTraditional machine learning\n(ML)\n‚Üí computational statistics\n‚Üí predictive analytics\n\n\n\n\n\nDeep learning\\n(DL)\\n‚Üí artificial neural networks\n\nDeep learning\n(DL)\n‚Üí artificial neural networks\n\n\n\n\n\nFields\nFields\n\n\n\nFields--Traditional machine learning\\n(ML)\\n‚Üí computational statistics\\n‚Üí predictive analytics\n\n\n\n\nFields--Deep learning\\n(DL)\\n‚Üí artificial neural networks\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nml\n\nTraditional machine learning\n(ML)\n‚Üí computational statistics\n‚Üí predictive analytics\n\n\n\n\n\n1\n- Clustering\n- Naives Bayes\n- Ensemble methods\n- Model selection\n- Decision trees\n\n\n\nml-&gt;1\n\n\n\n\n\ndl\n\nDeep learning\n(DL)\n ¬†¬†¬†‚Üí artificial neural networks\n\n\n\n\n\n2\n- Architecture building\n- NN operations\n- Automatic differentiation (AD)\n- Optimization functions\n\n\n\ndl-&gt;2\n\n\n\n\n\nFields\nFields\n\n\n\nFields-&gt;ml\n\n\n\n\nFields-&gt;dl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython\n\nPython\n\n\n\n\n\nJulia\n\nJulia\n\n\n\n\n\nR\n\nR\n\n\n\n\n\nLanguages\nLanguages\n\n\n\nLanguages--Python\n\n\n\n\nLanguages--Julia\n\n\n\n\nLanguages--R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMost popular frameworks\n\ncluster_ml\n\nTraditional machine learning\n\n\ncluster_dl\n\nDeep learning\n\n\n\nscikit-learn\n\n\nscikit-learn\n\n\n\n\n\nPython\n\n\nPython\n\n\n\n\n\nscikit-learn--Python\n\n\n\n\nJulia\n\n\nJulia\n\n\n\n\n\nscikit-learn--Julia\n\n\n\n\nR\n\n\nR\n\n\n\n\n\nscikit-learn--R\n\n\n\n\nSeveral Julia ML packages\n\nSeveral Julia ML packages\n\n\n\nSeveral Julia ML packages--Julia\n\n\n\n\nMany R ML packages\n\nMany R ML packages\n\n\n\nMany R ML packages--R\n\n\n\n\nTorch\n\n\nTorch\n\n\n\n\n\nTensorFlow\n\n\nTensorFlow\n\n\n\n\n\nJAX\n\n\nJAX\n\n\n\n\n\nKeras\n\n\nKeras\n\n\n\n\n\nSeveral Julia DL packages\n\nSeveral Julia DL packages\n\n\n\nSeveral R DL packages\n\nSeveral R DL packages\n\n\n\nPython--Torch\n\n\n\n\nPython--TensorFlow\n\n\n\n\nPython--JAX\n\n\n\n\nPython--Keras\n\n\n\n\nJulia--Torch\n\n\n\n\nJulia--TensorFlow\n\n\n\n\nJulia--Keras\n\n\n\n\nJulia--Several Julia DL packages\n\n\n\n\nR--Torch\n\n\n\n\nR--TensorFlow\n\n\n\n\nR--Keras\n\n\n\n\nR--Several R DL packages\n\n\n\n\n\n\n\n\n\n\nscikit-learn is a toolbox of ML algorithms.\n\nTensorFlow was a leading DL framework for years, but is now fading.\n\nPyTorch slowly took over TensorFlow, but is now starting to face competition.\n\n\n\n\n\n\n\n\nMost popular frameworks\n\ncluster_ml\n\nTraditional machine learning\n\n\ncluster_dl\n\nDeep learning\n\n\n\nscikit-learn\n\n\nscikit-learn\n\n\n\n\n\nPython\n\n\nPython\n\n\n\n\n\nscikit-learn--Python\n\n\n\n\nJulia\n\n\nJulia\n\n\n\n\n\nscikit-learn--Julia\n\n\n\n\nR\n\n\nR\n\n\n\n\n\nscikit-learn--R\n\n\n\n\nSeveral Julia ML packages\n\nSeveral Julia ML packages\n\n\n\nSeveral Julia ML packages--Julia\n\n\n\n\nMany R ML packages\n\nMany R ML packages\n\n\n\nMany R ML packages--R\n\n\n\n\nTorch\n\n\nTorch\n\n\n\n\n\nTensorFlow\n\n\nTensorFlow\n\n\n\n\n\nJAX\n\n\nJAX\n\n\n\n\n\nKeras\n\n\nKeras\n\n\n\n\n\nSeveral Julia DL packages\n\nSeveral Julia DL packages\n\n\n\nSeveral R DL packages\n\nSeveral R DL packages\n\n\n\nPython--Torch\n\n\n\n\nPython--TensorFlow\n\n\n\n\nPython--JAX\n\n\n\n\nPython--Keras\n\n\n\n\nJulia--Torch\n\n\n\n\nJulia--TensorFlow\n\n\n\n\nJulia--Keras\n\n\n\n\nJulia--Several Julia DL packages\n\n\n\n\nR--Torch\n\n\n\n\nR--TensorFlow\n\n\n\n\nR--Keras\n\n\n\n\nR--Several R DL packages\n\n\n\n\n\n\n\n\n\n\nJAX is a domain specific language of NumPy-like ‚Äúpure‚Äù functions with automatic differentiation and accelerated linear algebra‚Äîa domain-specific compiler.\n\nkeras is a high-level API for deep learning.\n\n\n\n\n\n\n\n\nMost popular frameworks\n\ncluster_ml\n\nTraditional machine learning\n\n\ncluster_dl\n\nDeep learning\n\n\n\nscikit-learn\n\n\nscikit-learn\n\n\n\n\n\nPython\n\n\nPython\n\n\n\n\n\nscikit-learn--Python\n\n\n\n\nJulia\n\n\nJulia\n\n\n\n\n\nscikit-learn--Julia\n\n\n\n\nR\n\n\nR\n\n\n\n\n\nscikit-learn--R\n\n\n\n\nSeveral Julia ML packages\n\nSeveral Julia ML packages\n\n\n\nSeveral Julia ML packages--Julia\n\n\n\n\nMany R ML packages\n\nMany R ML packages\n\n\n\nMany R ML packages--R\n\n\n\n\nTorch\n\n\nTorch\n\n\n\n\n\nTensorFlow\n\n\nTensorFlow\n\n\n\n\n\nJAX\n\n\nJAX\n\n\n\n\n\nKeras\n\n\nKeras\n\n\n\n\n\nSeveral Julia DL packages\n\nSeveral Julia DL packages\n\n\n\nSeveral R DL packages\n\nSeveral R DL packages\n\n\n\nPython--Torch\n\n\n\n\nPython--TensorFlow\n\n\n\n\nPython--JAX\n\n\n\n\nPython--Keras\n\n\n\n\nJulia--Torch\n\n\n\n\nJulia--TensorFlow\n\n\n\n\nJulia--Keras\n\n\n\n\nJulia--Several Julia DL packages\n\n\n\n\nR--Torch\n\n\n\n\nR--TensorFlow\n\n\n\n\nR--Keras\n\n\n\n\nR--Several R DL packages\n\n\n\n\n\n\n\n\n\nA fast evolving field:\n\nMXNET was just retired a few days ago.\ncaffe2 is now part of PyTorch.\nJAX is looking like a replacement for TensorFlow.\nkeras has been the high-level frontend for a shifting list of backends (currently TensorFlow, PyTorch, JAX).\n\n\n\n\n\n\n\n\nPython\n\ncluster_ml\n\nTraditional machine learning\n\n\ncluster_dl\n\nDeep learning\n\n\n\nscikit-learn\n\n\nscikit-learn\n\n\n\n\n\nPython\n\n\nPython\n\n\n\n\n\nscikit-learn--Python\n\n\n\n\nJulia\n\n\nJulia\n\n\n\n\n\nscikit-learn--Julia\n\n\n\n\nR\n\n\nR\n\n\n\n\n\nscikit-learn--R\n\n\n\n\nSeveral Julia ML packages\n\nSeveral Julia ML packages\n\n\n\nSeveral Julia ML packages--Julia\n\n\n\n\nMany R ML packages\n\nMany R ML packages\n\n\n\nMany R ML packages--R\n\n\n\n\nTorch\n\n\nTorch\n\n\n\n\n\nTensorFlow\n\n\nTensorFlow\n\n\n\n\n\nJAX\n\n\nJAX\n\n\n\n\n\nKeras\n\n\nKeras\n\n\n\n\n\nSeveral Julia DL packages\n\nSeveral Julia DL packages\n\n\n\nSeveral R DL packages\n\nSeveral R DL packages\n\n\n\nPython--Torch\n\n\n\n\nPython--TensorFlow\n\n\n\n\nPython--JAX\n\n\n\n\nPython--Keras\n\n\n\n\nJulia--Torch\n\n\n\n\nJulia--TensorFlow\n\n\n\n\nJulia--Keras\n\n\n\n\nJulia--Several Julia DL packages\n\n\n\n\nR--Torch\n\n\n\n\nR--TensorFlow\n\n\n\n\nR--Keras\n\n\n\n\nR--Several R DL packages\n\n\n\n\n\n\n\n\n\nSeveral popular packages written for Python, but not in Python (too slow)\n‚Üí written in Fortran, C, C++, or DSL.\n\n\n\n\n\n\n\nJulia\n\ncluster_ml\n\nTraditional machine learning\n\n\ncluster_dl\n\nDeep learning\n\n\n\nscikit-learn\n\n\nscikit-learn\n\n\n\n\n\nPython\n\n\nPython\n\n\n\n\n\nscikit-learn--Python\n\n\n\n\nJulia\n\n\nJulia\n\n\n\n\n\nscikit-learn--Julia\n\n\n\n\nR\n\n\nR\n\n\n\n\n\nscikit-learn--R\n\n\n\n\nSeveral Julia ML packages\n\nSeveral Julia ML packages\n\n\n\nSeveral Julia ML packages--Julia\n\n\n\n\nMany R ML packages\n\nMany R ML packages\n\n\n\nMany R ML packages--R\n\n\n\n\nTorch\n\n\nTorch\n\n\n\n\n\nTensorFlow\n\n\nTensorFlow\n\n\n\n\n\nJAX\n\nJAX\n\n\n\nKeras\n\n\nKeras\n\n\n\n\n\nSeveral Julia DL packages\n\nSeveral Julia DL packages\n\n\n\nSeveral R DL packages\n\nSeveral R DL packages\n\n\n\nPython--Torch\n\n\n\n\nPython--TensorFlow\n\n\n\n\nPython--JAX\n\n\n\n\nPython--Keras\n\n\n\n\nJulia--Torch\n\n\n\n\nJulia--TensorFlow\n\n\n\n\nJulia--Keras\n\n\n\n\nJulia--Several Julia DL packages\n\n\n\n\nR--Torch\n\n\n\n\nR--TensorFlow\n\n\n\n\nR--Keras\n\n\n\n\nR--Several R DL packages\n\n\n\n\n\n\n\n\n\nClassic Python packages available in Julia thanks to wrappers.\nIn addition many packages written in Julia (as the language is fast enough).\n\n\n\n\n\n\n\nJulia\n\ncluster_ml\n\nTraditional machine learning\n\n\ncluster_dl\n\nDeep learning\n\n\n\nscikit-learn\n\n\nscikit-learn\n\n\n\n\n\nPython\n\n\nPython\n\n\n\n\n\nscikit-learn--Python\n\n\n\n\nJulia\n\n\nJulia\n\n\n\n\n\nscikit-learn--Julia\n\n\n\n\nR\n\n\nR\n\n\n\n\n\nscikit-learn--R\n\n\n\n\nSeveral Julia ML packages\n\nSeveral Julia ML packages\n\n\n\nSeveral Julia ML packages--Julia\n\n\n\n\nMany R ML packages\n\nMany R ML packages\n\n\n\nMany R ML packages--R\n\n\n\n\nTorch\n\n\nTorch\n\n\n\n\n\nTensorFlow\n\n\nTensorFlow\n\n\n\n\n\nJAX\n\nJAX\n\n\n\nKeras\n\n\nKeras\n\n\n\n\n\nSeveral Julia DL packages\n\nSeveral Julia DL packages\n\n\n\nSeveral R DL packages\n\nSeveral R DL packages\n\n\n\nPython--Torch\n\n\n\n\nPython--TensorFlow\n\n\n\n\nPython--JAX\n\n\n\n\nPython--Keras\n\n\n\n\nJulia--Torch\n\n\n\n\nJulia--TensorFlow\n\n\n\n\nJulia--Keras\n\n\n\n\nJulia--Several Julia DL packages\n\n\n\n\nR--Torch\n\n\n\n\nR--TensorFlow\n\n\n\n\nR--Keras\n\n\n\n\nR--Several R DL packages\n\n\n\n\n\n\n\n\n\nLet‚Äôs have a look at the Julia specific packages.\n\n\n\n\n\n\n\nA rich ecocystem of packages\n\ncluster_ml\n\nTraditional machine learning\n\n\ncluster_dl\n\nDeep learning\n\n\n\nAugmentedGaussianProcesses\n\nAugmentedGaussianProcesses\n\n\n\nEvoTrees\n\nEvoTrees\n\n\n\n\nMachineLearning\n\nMachineLearning\n\n\n\nTSML\n\nTSML\n\n\n\nDecisionTree\n\nDecisionTree\n\n\n\nMLJ\n\n\nMLJ\n\n\n\n\n\n\nZigZagBoomerang\n\nZigZagBoomerang\n\n\n\nLightGBM\n\nLightGBM\n\n\n\nTuring\n\n\nTuring\n\n\n\n\n\nBayesianOptimization\n\nBayesianOptimization\n\n\n\nGLMNet\n\nGLMNet\n\n\n\nLIBSVM\n\nLIBSVM\n\n\n\nMLBase\n\nMLBase\n\n\n\nJulia\n\n\nJulia\n\n\n\n\n\nMLBase--Julia\n\n\n\n\nMLKernels\n\nMLKernels\n\n\n\nClustering\n\nClustering\n\n\n\nForneyLab\n\nForneyLab\n\n\n\nFlux\n\n\nFlux\n\n\n\n\n\nLux\n\n\nLux\n\n\n\n\n\nKnet\n\n\nKnet\n\n\n\n\n\nMerlin\n\nMerlin\n\n\n\nMLJFlux\n\nMLJFlux\n\n\n\nFluxTraining\n\nFluxTraining\n\n\n\nGraphNeuralNetworks\n\nGraphNeuralNetworks\n\n\n\nJulia--MLJFlux\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNot counting utility packages...\n\ncluster_ml\n\nTraditional machine learning\n\n\ncluster_dl\n\nDeep learning\n\n\ncluster_utilities\n\nUtilities:\n\n\n\nAugmentedGaussianProcesses\n\nAugmentedGaussianProcesses\n\n\n\nEvoTrees\n\nEvoTrees\n\n\n\n\nMachineLearning\n\nMachineLearning\n\n\n\nTSML\n\nTSML\n\n\n\nDecisionTree\n\nDecisionTree\n\n\n\nMLJ\n\n\nMLJ\n\n\n\n\n\n\nZigZagBoomerang\n\nZigZagBoomerang\n\n\n\nLightGBM\n\nLightGBM\n\n\n\nTuring\n\n\nTuring\n\n\n\n\n\nBayesianOptimization\n\nBayesianOptimization\n\n\n\nGLMNet\n\nGLMNet\n\n\n\nLIBSVM\n\nLIBSVM\n\n\n\nMLBase\n\nMLBase\n\n\n\nJulia\n\n\nJulia\n\n\n\n\n\nMLBase--Julia\n\n\n\n\nMLKernels\n\nMLKernels\n\n\n\nClustering\n\nClustering\n\n\n\nForneyLab\n\nForneyLab\n\n\n\nFlux\n\n\nFlux\n\n\n\n\n\nLux\n\n\nLux\n\n\n\n\n\nKnet\n\n\nKnet\n\n\n\n\n\nMerlin\n\nMerlin\n\n\n\nMLJFlux\n\nMLJFlux\n\n\n\nFluxTraining\n\nFluxTraining\n\n\n\nGraphNeuralNetworks\n\nGraphNeuralNetworks\n\n\n\nMetalhead\n\nMetalhead\n\n\n\n\nDataLoaders\n\nDataLoaders\n\n\n\nMLUtils\n\nMLUtils\n\n\n\nMLDataUtils\n\nMLDataUtils\n\n\n\nMLDatasets\n\nMLDatasets\n\n\n\nTensorBoardLogger\n\nTensorBoardLogger\n\n\n\nObjectDetector\n\nObjectDetector\n\n\n\nJulia--MLJFlux\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnd many AD implementations!\n\ncluster_ml\n\nTraditional machine learning\n\n\ncluster_dl\n\nDeep learning\n\n\ncluster_autodiff\n\nAutodiff:\n\n\ncluster_utilities\n\nUtilities:\n\n\n\nAugmentedGaussianProcesses\n\nAugmentedGaussianProcesses\n\n\n\nEvoTrees\n\nEvoTrees\n\n\n\n\nMachineLearning\n\nMachineLearning\n\n\n\nTSML\n\nTSML\n\n\n\nDecisionTree\n\nDecisionTree\n\n\n\nMLJ\n\n\nMLJ\n\n\n\n\n\n\nZigZagBoomerang\n\nZigZagBoomerang\n\n\n\nLightGBM\n\nLightGBM\n\n\n\nTuring\n\n\nTuring\n\n\n\n\n\nBayesianOptimization\n\nBayesianOptimization\n\n\n\nGLMNet\n\nGLMNet\n\n\n\nLIBSVM\n\nLIBSVM\n\n\n\nMLBase\n\nMLBase\n\n\n\nJulia\n\n\nJulia\n\n\n\n\n\nMLBase--Julia\n\n\n\n\nMLKernels\n\nMLKernels\n\n\n\nClustering\n\nClustering\n\n\n\nForneyLab\n\nForneyLab\n\n\n\nFlux\n\n\nFlux\n\n\n\n\n\nLux\n\n\nLux\n\n\n\n\n\nKnet\n\n\nKnet\n\n\n\n\n\nMerlin\n\nMerlin\n\n\n\nMLJFlux\n\nMLJFlux\n\n\n\nFluxTraining\n\nFluxTraining\n\n\n\nGraphNeuralNetworks\n\nGraphNeuralNetworks\n\n\n\nMetalhead\n\nMetalhead\n\n\n\n\nDataLoaders\n\nDataLoaders\n\n\n\nMLUtils\n\nMLUtils\n\n\n\nMLDataUtils\n\nMLDataUtils\n\n\n\nMLDatasets\n\nMLDatasets\n\n\n\nTensorBoardLogger\n\nTensorBoardLogger\n\n\n\nObjectDetector\n\nObjectDetector\n\n\n\nStochasticAD\n\n\nStochasticAD\n\n\n\n\n\n\nForwardDiff\n\n\nForwardDiff\n\n\n\n\n\nReverseDiff\n\n\nReverseDiff\n\n\n\n\n\nZygote\n\n\nZygote\n\n\n\n\n\nEnzyme\n\n\nEnzyme\n\n\n\n\n\nChainRules\n\n\nChainRules\n\n\n\n\n\nTaylorDiff\n\n\nTaylorDiff\n\n\n\n\n\nJulia--MLJFlux\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotable options\n\ncluster_ml\n\nTraditional machine learning\n\n\ncluster_dl\n\nDeep learning\n\n\ncluster_utilities\n\nUtilities:\n\n\ncluster_autodiff\n\nAutodiff:\n\n\n\nAugmentedGaussianProcesses\n\nAugmentedGaussianProcesses\n\n\n\nEvoTrees\n\nEvoTrees\n\n\n\n\nMachineLearning\n\nMachineLearning\n\n\n\nTSML\n\nTSML\n\n\n\nDecisionTree\n\nDecisionTree\n\n\n\nMLJ\n\n\nMLJ\n\n\n\n\n\n\nZigZagBoomerang\n\nZigZagBoomerang\n\n\n\nLightGBM\n\nLightGBM\n\n\n\nTuring\n\n\nTuring\n\n\n\n\n\nBayesianOptimization\n\nBayesianOptimization\n\n\n\nGLMNet\n\nGLMNet\n\n\n\nLIBSVM\n\nLIBSVM\n\n\n\nMLBase\n\nMLBase\n\n\n\nJulia\n\n\nJulia\n\n\n\n\n\nMLBase--Julia\n\n\n\n\nMLKernels\n\nMLKernels\n\n\n\nClustering\n\nClustering\n\n\n\nForneyLab\n\nForneyLab\n\n\n\nFlux\n\n\nFlux\n\n\n\n\n\nLux\n\n\nLux\n\n\n\n\n\nKnet\n\n\nKnet\n\n\n\n\n\nMerlin\n\nMerlin\n\n\n\nMLJFlux\n\nMLJFlux\n\n\n\nFluxTraining\n\nFluxTraining\n\n\n\nGraphNeuralNetworks\n\nGraphNeuralNetworks\n\n\n\nMetalhead\n\nMetalhead\n\n\n\n\nDataLoaders\n\nDataLoaders\n\n\n\nMLUtils\n\nMLUtils\n\n\n\nMLDataUtils\n\nMLDataUtils\n\n\n\nMLDatasets\n\nMLDatasets\n\n\n\nTensorBoardLogger\n\nTensorBoardLogger\n\n\n\nObjectDetector\n\nObjectDetector\n\n\n\nStochasticAD\n\n\nStochasticAD\n\n\n\n\n\n\nForwardDiff\n\n\nForwardDiff\n\n\n\n\n\nReverseDiff\n\n\nReverseDiff\n\n\n\n\n\nZygote\n\n\nZygote\n\n\n\n\n\nEnzyme\n\n\nEnzyme\n\n\n\n\n\nChainRules\n\n\nChainRules\n\n\n\n\n\nTaylorDiff\n\n\nTaylorDiff\n\n\n\n\n\nJulia--MLJFlux\n\n\n\n\n\n\n\n\n\nMachine learning:\nMLJ is a ML toolbox with Julia functions and wrappers to scikit-learn models.\n\n\n\n\n\n\n\nNotable options\n\ncluster_ml\n\nTraditional machine learning\n\n\ncluster_dl\n\nDeep learning\n\n\ncluster_utilities\n\nUtilities:\n\n\ncluster_autodiff\n\nAutodiff:\n\n\n\nAugmentedGaussianProcesses\n\nAugmentedGaussianProcesses\n\n\n\nEvoTrees\n\nEvoTrees\n\n\n\n\nMachineLearning\n\nMachineLearning\n\n\n\nTSML\n\nTSML\n\n\n\nDecisionTree\n\nDecisionTree\n\n\n\nMLJ\n\n\nMLJ\n\n\n\n\n\n\nZigZagBoomerang\n\nZigZagBoomerang\n\n\n\nLightGBM\n\nLightGBM\n\n\n\nTuring\n\n\nTuring\n\n\n\n\n\nBayesianOptimization\n\nBayesianOptimization\n\n\n\nGLMNet\n\nGLMNet\n\n\n\nLIBSVM\n\nLIBSVM\n\n\n\nMLBase\n\nMLBase\n\n\n\nJulia\n\n\nJulia\n\n\n\n\n\nMLBase--Julia\n\n\n\n\nMLKernels\n\nMLKernels\n\n\n\nClustering\n\nClustering\n\n\n\nForneyLab\n\nForneyLab\n\n\n\nFlux\n\n\nFlux\n\n\n\n\n\nLux\n\n\nLux\n\n\n\n\n\nKnet\n\n\nKnet\n\n\n\n\n\nMerlin\n\nMerlin\n\n\n\nMLJFlux\n\nMLJFlux\n\n\n\nFluxTraining\n\nFluxTraining\n\n\n\nGraphNeuralNetworks\n\nGraphNeuralNetworks\n\n\n\nMetalhead\n\nMetalhead\n\n\n\n\nDataLoaders\n\nDataLoaders\n\n\n\nMLUtils\n\nMLUtils\n\n\n\nMLDataUtils\n\nMLDataUtils\n\n\n\nMLDatasets\n\nMLDatasets\n\n\n\nTensorBoardLogger\n\nTensorBoardLogger\n\n\n\nObjectDetector\n\nObjectDetector\n\n\n\nStochasticAD\n\n\nStochasticAD\n\n\n\n\n\n\nForwardDiff\n\n\nForwardDiff\n\n\n\n\n\nReverseDiff\n\n\nReverseDiff\n\n\n\n\n\nZygote\n\n\nZygote\n\n\n\n\n\nEnzyme\n\n\nEnzyme\n\n\n\n\n\nChainRules\n\n\nChainRules\n\n\n\n\n\nTaylorDiff\n\n\nTaylorDiff\n\n\n\n\n\nJulia--MLJFlux\n\n\n\n\n\n\n\n\n\nNeural networks:\nFlux is a DL framework similar to PyTorch in pure Julia.\nLux is a rewrite of Flux keeping the trainable and non-trainable parameters decoupled.\n\n\n\n\n\n\n\nNotable options\n\ncluster_ml\n\nTraditional machine learning\n\n\ncluster_dl\n\nDeep learning\n\n\ncluster_utilities\n\nUtilities:\n\n\ncluster_autodiff\n\nAutodiff:\n\n\n\nAugmentedGaussianProcesses\n\nAugmentedGaussianProcesses\n\n\n\nEvoTrees\n\nEvoTrees\n\n\n\n\nMachineLearning\n\nMachineLearning\n\n\n\nTSML\n\nTSML\n\n\n\nDecisionTree\n\nDecisionTree\n\n\n\nMLJ\n\n\nMLJ\n\n\n\n\n\n\nZigZagBoomerang\n\nZigZagBoomerang\n\n\n\nLightGBM\n\nLightGBM\n\n\n\nTuring\n\n\nTuring\n\n\n\n\n\nBayesianOptimization\n\nBayesianOptimization\n\n\n\nGLMNet\n\nGLMNet\n\n\n\nLIBSVM\n\nLIBSVM\n\n\n\nMLBase\n\nMLBase\n\n\n\nJulia\n\n\nJulia\n\n\n\n\n\nMLBase--Julia\n\n\n\n\nMLKernels\n\nMLKernels\n\n\n\nClustering\n\nClustering\n\n\n\nForneyLab\n\nForneyLab\n\n\n\nFlux\n\n\nFlux\n\n\n\n\n\nLux\n\n\nLux\n\n\n\n\n\nKnet\n\n\nKnet\n\n\n\n\n\nMerlin\n\nMerlin\n\n\n\nMLJFlux\n\nMLJFlux\n\n\n\nFluxTraining\n\nFluxTraining\n\n\n\nGraphNeuralNetworks\n\nGraphNeuralNetworks\n\n\n\nMetalhead\n\nMetalhead\n\n\n\n\nDataLoaders\n\nDataLoaders\n\n\n\nMLUtils\n\nMLUtils\n\n\n\nMLDataUtils\n\nMLDataUtils\n\n\n\nMLDatasets\n\nMLDatasets\n\n\n\nTensorBoardLogger\n\nTensorBoardLogger\n\n\n\nObjectDetector\n\nObjectDetector\n\n\n\nStochasticAD\n\n\nStochasticAD\n\n\n\n\n\n\nForwardDiff\n\n\nForwardDiff\n\n\n\n\n\nReverseDiff\n\n\nReverseDiff\n\n\n\n\n\nZygote\n\n\nZygote\n\n\n\n\n\nEnzyme\n\n\nEnzyme\n\n\n\n\n\nChainRules\n\n\nChainRules\n\n\n\n\n\nTaylorDiff\n\n\nTaylorDiff\n\n\n\n\n\nJulia--MLJFlux\n\n\n\n\n\n\n\n\n\nAutodiff:\nZygote is the AD engine for Flux.\nEnzyme is a novel, more powerful AD tool for languages using the LLVM compiler (now being incorporated in Lux).\n\n\n\n\n\n\n\nR\n\ncluster_ml\n\nTraditional machine learning\n\n\ncluster_dl\n\nDeep learning\n\n\n\nscikit-learn\n\n\nscikit-learn\n\n\n\n\n\nPython\n\n\nPython\n\n\n\n\n\nscikit-learn--Python\n\n\n\n\nJulia\n\n\nJulia\n\n\n\n\n\nscikit-learn--Julia\n\n\n\n\nR\n\n\nR\n\n\n\n\n\nscikit-learn--R\n\n\n\n\nSeveral Julia ML packages\n\nSeveral Julia ML packages\n\n\n\nSeveral Julia ML packages--Julia\n\n\n\n\nMany R ML packages\n\nMany R ML packages\n\n\n\nMany R ML packages--R\n\n\n\n\nTorch\n\n\nTorch\n\n\n\n\n\nTensorFlow\n\n\nTensorFlow\n\n\n\n\n\nJAX\n\nJAX\n\n\n\nKeras\n\n\nKeras\n\n\n\n\n\nSeveral Julia DL packages\n\nSeveral Julia DL packages\n\n\n\nSeveral R DL packages\n\nSeveral R DL packages\n\n\n\nPython--Torch\n\n\n\n\nPython--TensorFlow\n\n\n\n\nPython--JAX\n\n\n\n\nPython--Keras\n\n\n\n\nJulia--Torch\n\n\n\n\nJulia--TensorFlow\n\n\n\n\nJulia--Keras\n\n\n\n\nJulia--Several Julia DL packages\n\n\n\n\nR--Torch\n\n\n\n\nR--TensorFlow\n\n\n\n\nR--Keras\n\n\n\n\nR--Several R DL packages\n\n\n\n\n\n\n\n\n\nClassic Python packages available in R thanks to wrappers.\nIn addition many packages written for R, but not in R (too slow)\n‚Üí written in Fortran, C, or C++.\n\n\n\n\n\n\n\nR\n\ncluster_ml\n\nTraditional machine learning\n\n\ncluster_dl\n\nDeep learning\n\n\n\nscikit-learn\n\n\nscikit-learn\n\n\n\n\n\nPython\n\n\nPython\n\n\n\n\n\nscikit-learn--Python\n\n\n\n\nJulia\n\n\nJulia\n\n\n\n\n\nscikit-learn--Julia\n\n\n\n\nR\n\n\nR\n\n\n\n\n\nscikit-learn--R\n\n\n\n\nSeveral Julia ML packages\n\nSeveral Julia ML packages\n\n\n\nSeveral Julia ML packages--Julia\n\n\n\n\nMany R ML packages\n\nMany R ML packages\n\n\n\nMany R ML packages--R\n\n\n\n\nTorch\n\n\nTorch\n\n\n\n\n\nTensorFlow\n\n\nTensorFlow\n\n\n\n\n\nJAX\n\nJAX\n\n\n\nKeras\n\n\nKeras\n\n\n\n\n\nSeveral Julia DL packages\n\nSeveral Julia DL packages\n\n\n\nSeveral R DL packages\n\nSeveral R DL packages\n\n\n\nPython--Torch\n\n\n\n\nPython--TensorFlow\n\n\n\n\nPython--JAX\n\n\n\n\nPython--Keras\n\n\n\n\nJulia--Torch\n\n\n\n\nJulia--TensorFlow\n\n\n\n\nJulia--Keras\n\n\n\n\nJulia--Several Julia DL packages\n\n\n\n\nR--Torch\n\n\n\n\nR--TensorFlow\n\n\n\n\nR--Keras\n\n\n\n\nR--Several R DL packages\n\n\n\n\n\n\n\n\n\nLet‚Äôs have a look at the R specific packages:\n\n\n\n\n\n\n\n\ncluster_dl\n\nDeep learning\n\n\ncluster_ml\n\nTraditional machine learning\n\n\n\ne1071\n\ne1071\n\n\n\nipred\n\nipred\n\n\n\n\nkernlab\n\nkernlab\n\n\n\nrpart\n\nrpart\n\n\n\nparty\n\n\nparty\n\n\n\n\n\ncaret\n\ncaret\n\n\n\ngmodels\n\n\ngmodels\n\n\n\n\n\nrandomForest\n\nrandomForest\n\n\n\nranger\n\nranger\n\n\n\ngbm\n\ngbm\n\n\n\nxgboost\n\nxgboost\n\n\n\nC50\n\nC50\n\n\n\ncluster\n\ncluster\n\n\n\nR\n\n\nR\n\n\n\n\n\ncluster--R\n\n\n\n\nclass\n\nclass\n\n\n\nmclust\n\nmclust\n\n\n\nnaivebayes\n\nnaivebayes\n\n\n\nglmnet\n\nglmnet\n\n\n\nRSNNS\n\nRSNNS\n\n\n\nh2o\n\nh2o\n\n\n\ndarch\n\ndarch\n\n\n\ndeepr\n\ndeepr\n\n\n\nRCNN4R\n\nRCNN4R\n\n\n\nrcppDL\n\nrcppDL\n\n\n\nrnn\n\nrnn\n\n\n\nneuralnet\n\nneuralnet\n\n\n\ndeepnet\n\ndeepnet\n\n\n\nR--RCNN4R\n\n\n\n\n\n\n\n\n\nA very large field, particularly when it comes to statistical machine learning.\nQuite a lot of DL packages, despite R‚Äôs slow speed.\nThe Machine Learning CRAN Task View is a good reference for many packages.",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Current ML frameworks",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/wb_frameworks_content.html#languages-summary",
    "href": "ai/wb_frameworks_content.html#languages-summary",
    "title": "A map of current ML frameworks",
    "section": "Languages summary",
    "text": "Languages summary\n\n\n\n\n\n\n\n\n\n1\n- Huge userbase\n- Mature frameworks\n- Smooth APIs\n- Easy to scale\n\n\n\n2\nNeeds other\nlanguages\nfor speed\n\n\n\n\n3\n\n- All in Julia\n- Tools at the\nedge of research\n- Great for developpers\n\n\n\n\n\n\n4\n- Small userbase\n- Not the smoothest\nfor end users\n\n\n\n\n\n5\n- Countless packages\n- Very user-friendly\n- Well documented\n\n\n\n\n6\n- Needs C for\nspeed\n- Slow\n- Too slow for DL\n- Hard to scale\n\n\n\n\n\nStrengths\n\n\nStrengths\n\n\n\n\nWeaknesses\n\n\nWeaknesses\n\n\n\n\nPython\n\n\nPython\n\n\n\n\n\n\nJulia\n\n\nJulia\n\n\n\n\n\n\nR\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nGood\n\n\n\n2\nGood\n\n\n\n\n3\nGood\n\n\n\n\n4\nGood\n\n\n\n\n\n5\nGood\n\n\n\n\n6\nVery limited\n\n\n\n\n\nMachine learning\nMachine learning\n\n\n\n\nDeep learning\nDeep learning\n\n\n\n\nPython\n\n\nPython\n\n\n\n\n\n\nJulia\n\n\nJulia\n\n\n\n\n\n\nR\n\n\nR",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Current ML frameworks",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/wb_frameworks_content.html#frameworks-picks",
    "href": "ai/wb_frameworks_content.html#frameworks-picks",
    "title": "A map of current ML frameworks",
    "section": "Frameworks picks",
    "text": "Frameworks picks\n\n\n\n\n\n\n\nMachine learning\n\n\n1\nscikit-learn\nor MLJ\n\n\n\n2\nJulia or R\nstats packages\n\n\n\n\n3\nToolboxes of\nclassic algorithms\n\n\n\n1-&gt;3\n\n\n\n\n\n4\nAdvanced and\nspecialized techniques\nWhich ones to use\ndepends on specific problems\n\n\n\n2-&gt;4\n\n\n\n\n\n\n\n\n\n\n\n\nMany other options are also excellent. This selection is based on great documentation, ease of use, and popularity. It is very subjective.\n\n\n\n\n\n\n\nDeep learning\n\n\n1\nPyTorch\n\n\n\n2\nJAX\n\n\n\n\n4\nOptional Keras\nat high-level\nOptional JIT\n\n\n\n1-&gt;4\n\n\n\n\n\n3\nLux with Enzyme\n\n\n\n\n2-&gt;4\n\n\n\n\n\n5\nSophisticated AD\nOptional packages\nfor ease of use\n(e.g. Equinox)\nDomain-specific language\n\n\n\n2-&gt;5\n\n\n\n\n\n6\nExplicit parameters\nHigh performance AD\nJIT (Julia)\n\n\n\n3-&gt;6\n\n\n\n\n\n\n\n\n\n\n\n\nHere, the selection is based on speed, which is crucial for DL.\n\n\n\n\n\n\n\nDeep learning\n\n\n1\nPyTorch\n\n\n\n2\nJAX\n\n\n\n\n4\nOptional Keras\nat high-level\nOptional JIT\n\n\n\n1-&gt;4\n\n\n\n\n\n3\nLux with Enzyme\n\n\n\n\n2-&gt;4\n\n\n\n\n\n5\nSophisticated AD\nOptional packages\nfor ease of use\n(e.g. Equinox, Flax)\n\n\n\n2-&gt;5\n\n\n\n\n\n6\nExplicit parameters\nHigh performance AD\nJIT (Julia)\n\n\n\n3-&gt;6\n\n\n\n\n\n7\nEasy\nAll in Python\nUnified framework\n\n\n\n4-&gt;7\n\n\n\n\n\n8\nFastest options at the moment\nMany optional moving parts\nRequires learning a DSL (JAX)\nor Julia (Lux)\n\n\n\n5-&gt;8\n\n\n\n\n\n6-&gt;8\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutomatic differentiation (AD)\n\n\n1\nStatic graph\nand XLA\n\n\n\n2\nDynamic tape-based\n\n\n\n1-&gt;2\n\n\n\n\n\na\n\nTensorFlow\n\n\n\n\n3\nDynamic tape-based\nand JIT\n\n\n\n2-&gt;3\n\n\n\n\n\nb\n\nPyTorch\n\n\n\n\n4\nEager graph\nand XLA\n\n\n\n3-&gt;4\n\n\n\n\n\nc\n\nPyTorch\n\n\n\n\n5\nNon-standard interpretation\nand XLA\n\n\n\n4-&gt;5\n\n\n\n\n\nd\n\nTensorFlow2\n\n\n\n\n6\nWorks at lower level\n\n\n\n5-&gt;6\n\n\n\n\n\ne\n\nJAX\n\n\n\n\n7\nWorks on LLVM itself\n\n\n\n6-&gt;7\n\n\n\n\n\nf\n\nZygote\n\n\n\n\ng\n\nEnzyme\n\n\n\n\n\nA\nInconvenient\n\n\n\n\n\nB\nHard to optimize\n\n\n\n\n\nC\nNot currently developped\n\n\n\n\n\nD\nDynamism doesn't\nplay well with XLA\n\n\n\n\n\nE\nOnly sublanguage\n\n\n\n\n\nF\nHarder implementation\n\n\n\n\nG\nVery hard to implement\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom a blog post by Christopher Rackauckas",
    "crumbs": [
      "AI",
      "<b><em>Webinars</em></b>",
      "Current ML frameworks",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_dl_nlp_llm.html",
    "href": "ai/ws_dl_nlp_llm.html",
    "title": "Intro to deep learning, NLP, and LLMs",
    "section": "",
    "text": "‚ó¶ How does deep learning really work?\n‚ó¶ What exactly are those large language models everybody talks about?\n‚ó¶ How can I build a neural network?\n‚ó¶ What is NLP?\nThis presentation will answer these questions in a non-technical manner to give you a high-level understanding of a discipline that has become crucial in all fields of research.\n\nSlides (Click and wait: the presentation might take a few instants to load) \n\n Slides content for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro to DL, NLP, and LLMs"
    ]
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#ml-allows-to-achieve-previously-impossible-tasks",
    "href": "ai/ws_dl_nlp_llm_slides.html#ml-allows-to-achieve-previously-impossible-tasks",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "ML allows to achieve previously impossible tasks",
    "text": "ML allows to achieve previously impossible tasks\n\nLet‚Äôs take the example of image recognition:\n\nIn typical computing, a programmer writes code that gives a computer detailed instructions of what to do\nCoding all the possible ways‚Äîpixel by pixel‚Äîthat an image can represent, say, a dog is an impossibly large task: there are many breeds of dogs, the image can be a picture, a blurred picture, a drawing, a cartoon, the dog can be in all sorts of positions, wearing clothes, etc.\nThere just aren‚Äôt enough resources to make the traditional programming approach able to create a computer program that can identify a dog in images\nBy feeding a very large number of dog images to a neural network however, we can train that network to recognize dogs in images that it has never seen (without explicitly programming how it does this!)"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#old-concept-new-computing-power",
    "href": "ai/ws_dl_nlp_llm_slides.html#old-concept-new-computing-power",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Old concept ‚Ä¶ new computing power",
    "text": "Old concept ‚Ä¶ new computing power\nThe concept is everything but new: Arthur Samuel came up with it in 1949 and built a self-learning Checkers-playing program in 1959\n\n\nMachine learning consists of feeding vast amounts of data to algorithms to strengthen pathways, so the excitement for the approach became somewhat dormant due to the lack of computing power and the lack of training data at the time\nThe advent of powerful computers, GPUs, and massive amounts of data have brought the old concept to the forefront\n\n\n\n\n\n\nfrom xkcd.com"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#supervised-learning",
    "href": "ai/ws_dl_nlp_llm_slides.html#supervised-learning",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Supervised learning",
    "text": "Supervised learning\n\nRegression is a form of supervised learning with continuous outputs\nClassification is supervised learning with discrete outputs\n\nSupervised learning uses training data in the form of example input/output pairs\nGoal\nFind the relationship between inputs and outputs"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#unsupervised-learning",
    "href": "ai/ws_dl_nlp_llm_slides.html#unsupervised-learning",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Unsupervised learning",
    "text": "Unsupervised learning\nClustering, social network analysis, market segmentation, PCA ‚Ä¶ are all forms of unsupervised learning\nUnsupervised learning uses unlabelled data\nGoal\nFind structure within the data"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#reinforcement-learning",
    "href": "ai/ws_dl_nlp_llm_slides.html#reinforcement-learning",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Reinforcement learning",
    "text": "Reinforcement learning\nThe algorithm explores by performing random actions and these actions are rewarded or punished (bonus points or penalties)\nThis is how algorithms learn to play games"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#decide-on-an-architecture",
    "href": "ai/ws_dl_nlp_llm_slides.html#decide-on-an-architecture",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Decide on an architecture",
    "text": "Decide on an architecture\n\nThe architecture won‚Äôt change during training\nThe type of architecture you choose (e.g.¬†CNN, Transformer) depends on the type of data you have (e.g.¬†vision, textual). The depth and breadth of your network depend on the amount of data and computing resource you have"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#set-some-initial-parameters",
    "href": "ai/ws_dl_nlp_llm_slides.html#set-some-initial-parameters",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Set some initial parameters",
    "text": "Set some initial parameters\n\nYou can initialize them randomly or get much better ones through transfer learning\nWhile the parameters are also part of the model, those will change during training"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#get-some-labelled-data",
    "href": "ai/ws_dl_nlp_llm_slides.html#get-some-labelled-data",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Get some labelled data",
    "text": "Get some labelled data\n\nWhen we say that we need a lot of data for machine learning, we mean ‚Äúlots of labelled data‚Äù as this is what gets used for training models"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#make-sure-to-keep-some-data-for-testing",
    "href": "ai/ws_dl_nlp_llm_slides.html#make-sure-to-keep-some-data-for-testing",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Make sure to keep some data for testing",
    "text": "Make sure to keep some data for testing\n\nThose data won‚Äôt be used for training the model. Often people keep around 20% of their data for testing"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#pass-data-and-parameters-through-the-architecture",
    "href": "ai/ws_dl_nlp_llm_slides.html#pass-data-and-parameters-through-the-architecture",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Pass data and parameters through the architecture",
    "text": "Pass data and parameters through the architecture\n\nThe train data are the inputs and the process of calculating the outputs is the forward pass"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#the-outputs-of-the-model-are-predictions",
    "href": "ai/ws_dl_nlp_llm_slides.html#the-outputs-of-the-model-are-predictions",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "The outputs of the model are predictions",
    "text": "The outputs of the model are predictions"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#compare-those-predictions-to-the-train-labels",
    "href": "ai/ws_dl_nlp_llm_slides.html#compare-those-predictions-to-the-train-labels",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Compare those predictions to the train labels",
    "text": "Compare those predictions to the train labels\n\nSince our data was labelled, we know what the true outputs are"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#calculate-train-loss",
    "href": "ai/ws_dl_nlp_llm_slides.html#calculate-train-loss",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Calculate train loss",
    "text": "Calculate train loss\n\nThe deviation of our predictions from the true outputs gives us a measure of training loss"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#adjust-parameters",
    "href": "ai/ws_dl_nlp_llm_slides.html#adjust-parameters",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Adjust parameters",
    "text": "Adjust parameters\n\nThe parameters get automatically adjusted to reduce the training loss through the mechanism of backpropagation. This is the actual training part\nThis process is repeated many times. Training models is pretty much a giant for loop"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#from-model-to-program",
    "href": "ai/ws_dl_nlp_llm_slides.html#from-model-to-program",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "From model to program",
    "text": "From model to program\n\nRemember that the model architecture is fixed, but that the parameters change at each iteration of the training process"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#section",
    "href": "ai/ws_dl_nlp_llm_slides.html#section",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "¬†",
    "text": "While the labelled data are key to training, what we are really interested in is the combination of architecture + final parameters"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#section-1",
    "href": "ai/ws_dl_nlp_llm_slides.html#section-1",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "¬†",
    "text": "When the training is over, the parameters become fixed. Which means that our model now behaves like a classic program"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#evaluate-the-model",
    "href": "ai/ws_dl_nlp_llm_slides.html#evaluate-the-model",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Evaluate the model",
    "text": "Evaluate the model\n\nWe can now use the testing set (which was never used to train the model) to evaluate our model: if we pass the test inputs through our program, we get some predictions that we can compare to the test labels (which are the true outputs)\nThis gives us the test loss: a measure of how well our model performs"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#use-the-model",
    "href": "ai/ws_dl_nlp_llm_slides.html#use-the-model",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Use the model",
    "text": "Use the model\n\nNow that we have a program, we can use it on unlabelled inputs to get what people ultimately want: unknown outputs\nThis is when we put our model to actual use to solve some problem"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#learning",
    "href": "ai/ws_dl_nlp_llm_slides.html#learning",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Learning",
    "text": "Learning\n\n\nThe process of learning in biological NN happens through neuron death or growth and the creation or loss of synaptic connections between neurons\n\n\n\nIn ANN, learning happens through optimization algorithms such as gradient descent which minimize cross entropy loss functions by adjusting the weights and biases connecting each layer of neurons over many iterations"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#fully-connected-neural-networks",
    "href": "ai/ws_dl_nlp_llm_slides.html#fully-connected-neural-networks",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Fully connected neural networks",
    "text": "Fully connected neural networks\n\n\n\n\n\nfrom Glosser.ca, Wikipedia\n\n\n\nEach neuron receives inputs from every neuron of the previous layer and passes its output to every neuron of the next layer"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#convolutional-neural-networks",
    "href": "ai/ws_dl_nlp_llm_slides.html#convolutional-neural-networks",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Convolutional neural networks",
    "text": "Convolutional neural networks\n\nfrom Programming Journeys by Rensu TheartConvolutional neural networks (CNN) are used for spatially structured data (e.g.¬†images)\nImages have huge input sizes and would require a very large number of neurons in a fully connected neural net. In convolutional layers, neurons receive input from a subarea (called local receptive field) of the previous layer. This greatly reduces the number of parameters. Optionally, pooling (combining the outputs of neurons in a subarea) reduces the data dimensions"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#recurrent-neural-networks",
    "href": "ai/ws_dl_nlp_llm_slides.html#recurrent-neural-networks",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Recurrent neural networks",
    "text": "Recurrent neural networks\n\nfrom fdeloche, WikipediaRecurrent neural networks (RNN) such as Long Short-Term Memory (LSTM) are used for chain structured data (e.g.¬†text)\nThey are not feedforward networks (i.e.¬†networks for which the information moves only in the forward direction without any loop)"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#transformers",
    "href": "ai/ws_dl_nlp_llm_slides.html#transformers",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Transformers",
    "text": "Transformers\nA combination of two RNNs (the encoder and the decoder) is used in sequence to sequence models for translation or picture captioning\nIn 2014 the concept of attention (giving added weight to important words) was developed, greatly improving the ability of such models to process a lot of data\nThe problem with recurrence is that it is not easily to parallelize (and thus to run fast on GPUs)\nIn 2017, a new model‚Äîthe transformer‚Äîwas proposed: by using only attention mechanisms and no recurrence, the transformer achieves better results in an easily parallelizable fashion\nWith the addition of transfer learning, powerful transformers emerged in the field of NLP (e.g.¬†Bidirectional Encoder Representations from Transformers (BERT) from Google and Generative Pre-trained Transformer-3 (GPT-3) from OpenAI)"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#data-bias",
    "href": "ai/ws_dl_nlp_llm_slides.html#data-bias",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Data bias",
    "text": "Data bias\nBias is always present in data\nDocument the limitations and scope of your data as best as possible\nProblems to watch for:\n\nOut of domain data: data used for training are not relevant to the model application\nDomain shift: model becoming inadapted as conditions evolve\nFeedback loop: initial bias exacerbated over the time"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#transformation-of-subjects",
    "href": "ai/ws_dl_nlp_llm_slides.html#transformation-of-subjects",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Transformation of subjects",
    "text": "Transformation of subjects\nAlgorithms are supposed to help us, not transform us (e.g.¬†YouTube recommendation algorithms)"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#bugs",
    "href": "ai/ws_dl_nlp_llm_slides.html#bugs",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Bugs",
    "text": "Bugs\nExample of bug with real life consequences"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#what-is-nlp",
    "href": "ai/ws_dl_nlp_llm_slides.html#what-is-nlp",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "What is NLP?",
    "text": "What is NLP?\nNatural language processing is simply the application of machine learning to human (natural) language"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#applications",
    "href": "ai/ws_dl_nlp_llm_slides.html#applications",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Applications",
    "text": "Applications\n\nSpam detection\nTranslation\nSentiment analysis\nPredictive text\nText classification\nSpeech recognition\nNatural language generation\nChatbots\nSearch results"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#data-processing",
    "href": "ai/ws_dl_nlp_llm_slides.html#data-processing",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Data processing",
    "text": "Data processing\n\nTokenization: split text into sentences (sentence tokenization) and words (word tokenization)\nRemove punctuation and stopwords (e.g.¬†‚Äúthe‚Äù, ‚Äúa‚Äù, ‚Äúand‚Äù, ‚Äúis‚Äù, ‚Äúare‚Äù)\nTurn all words to lower case\nKeep only the lemma of words (lemmatization)\n\n\nAn alternative and simpler method is stemming\n\n\nIdentify word collocations (groups of words that often occur together, such as the bigrams ‚ÄúUnited States‚Äù or ‚Äúopen source‚Äù)\nTagging\nModel training"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#many-options",
    "href": "ai/ws_dl_nlp_llm_slides.html#many-options",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Many options",
    "text": "Many options\nHere are just a few:\n\nscikit-learn: a Python ML library built on top of SciPy\nNatural Language Toolkit (NLTK): a suite of Python libraries geared towards teaching and research\nspaCy: Python library geared towards production\ntorchtext, part of the PyTorch project (and many options of added layers on top such as PyTorch-NLP): Python library\nGenSim: Python library\nStanford CoreNLP: Java library\nMany libraries in the Julia programming language"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#which-one-to-choose",
    "href": "ai/ws_dl_nlp_llm_slides.html#which-one-to-choose",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Which one to choose?",
    "text": "Which one to choose?\nChoose an open source tool (i.e.¬†stay away from proprietary software such as MATLAB)\n\nResearchers who do not have access to the tool cannot reproduce your methods (open tools = open equitable research)\nOnce you graduate, you may not have access to the tool anymore\nYour university may stop paying for a license\nYou may get locked-in\nProprietary tools are often black boxes\nLong-term access is not guaranty (problem to replicate studies)\nThe licenses you have access to may be limiting and a cause of headache\nProprietary tools fall behind popular open-source tools\nProprietary tools often fail to address specialized edge cases needed in research"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#neural-nets",
    "href": "ai/ws_dl_nlp_llm_slides.html#neural-nets",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Neural nets",
    "text": "Neural nets\n3Blue1Brown by Grant Sanderson has a series of 4 videos on neural networks which is easy to watch, fun, and does an excellent job at introducing the functioning of a simple neural network\n\nWhat are NN? (19 min)\nHow do NN learn? (21 min)\nWhat is backpropagation? (14 min)\nHow does backpropagation work? (10 min)\n\n\nAs you develop your own ML models, if you find that your mathematical background is shaky, 3blue1brown also has an excellent series of videos on linear algebra and an equally great one on calculus"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#open-access-preprints",
    "href": "ai/ws_dl_nlp_llm_slides.html#open-access-preprints",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Open-access preprints",
    "text": "Open-access preprints\n\nArxiv Sanity Preserver by Andrej Karpathy\nML papers in the computer science category on arXiv\nML papers in the stats category on arXiv\nDistill ML research online journal"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#advice-and-sources",
    "href": "ai/ws_dl_nlp_llm_slides.html#advice-and-sources",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Advice and sources",
    "text": "Advice and sources\n\nAdvice and sources from ML research student"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#getting-help",
    "href": "ai/ws_dl_nlp_llm_slides.html#getting-help",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Getting help",
    "text": "Getting help\nStack Overflow:\n\n[machine-learning] tag\n[deep-learning] tag\n[supervised-learning] tag\n[unsupervised-learning] tag\n[semisupervised-learning] tag\n[reinforcement-learning] tag\n[transfer-learning] tag\n[machine-learning-model] tag\n[learning-rate] tag"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#open-datasets",
    "href": "ai/ws_dl_nlp_llm_slides.html#open-datasets",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Open datasets",
    "text": "Open datasets\n\nbenchmarks.ai\nAIBench\nkaggle\nWikipedia"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#pytorch",
    "href": "ai/ws_dl_nlp_llm_slides.html#pytorch",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "PyTorch",
    "text": "PyTorch\n\nDocumentation\nTutorials\nExamples\n\nGetting help\n\nPyTorch Discourse forum\nStack Overflow [pytorch] tag\n\nPre-trained models\n\nPyTorch Hub"
  },
  {
    "objectID": "ai/ws_dl_nlp_llm_slides.html#python",
    "href": "ai/ws_dl_nlp_llm_slides.html#python",
    "title": "A quick introduction to deep learning, NLP, and LLMs ",
    "section": "Python",
    "text": "Python\nIDE\n\nProject Jupyter\nList of IDEs with description\nComparison of IDEs\nEmacs Python IDE\n\nGetting help\n\nStack Overflow [python] tag"
  },
  {
    "objectID": "ai/ws_hss_intro_content.html",
    "href": "ai/ws_hss_intro_content.html",
    "title": "Intro to ML for the humanities",
    "section": "",
    "text": "Content from the workshop slides for easier browsing.",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro ML for the humanities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_hss_intro_content.html#definitions",
    "href": "ai/ws_hss_intro_content.html#definitions",
    "title": "Intro to ML for the humanities",
    "section": "Definitions",
    "text": "Definitions\n\nArtificial intelligence (AI)\nAny human-made system mimicking animal intelligence. This is a large and very diverse field.\n\n\nMachine learning (ML)\nA subfield of AI that can be defined as computer programs whose performance at a task improves with experience. This includes statistical inference and deep learning.\n\n\nDeep learning (DL)\nA subfield of ML using artificial neural networks with two or more hidden layers.\n\n\nNatural language processing (NLP)\nA subfield of AI focused on human languages. It can use statistical inference or deep learning.",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro ML for the humanities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_hss_intro_content.html#why-has-ml-become-so-popular",
    "href": "ai/ws_hss_intro_content.html#why-has-ml-become-so-popular",
    "title": "Intro to ML for the humanities",
    "section": "Why has ML become so popular?",
    "text": "Why has ML become so popular?\n\nNew types of tasks\nML allows to achieve previously impossible tasks.\n\nLet‚Äôs take the example of image recognition:\n\nIn typical computing, a programmer writes code that gives a computer detailed instructions of what to do.\nCoding all the possible ways‚Äîpixel by pixel‚Äîthat an image can represent, say, a dog is an impossibly large task: there are many breeds of dogs, the image can be a picture, a blurred picture, a drawing, a cartoon, the dog can be in all sorts of positions, wearing clothes, etc.\nThere just aren‚Äôt enough resources to make the traditional programming approach able to create a computer program that can identify a dog in images.\nBy feeding a very large number of dog images to a neural network however, we can train that network to recognize dogs in images that it has never seen (without explicitly programming how it does this!).\n\n\nOld concept ‚Ä¶\n‚Ä¶ new computing power.\nThe concept is everything but new: Arthur Samuel came up with it in 1949 and built a self-learning Checkers-playing program in 1959.\n\n\n\nMachine learning consists of feeding vast amounts of data to algorithms to strengthen pathways, so the excitement for the approach became somewhat dormant due to the lack of computing power and the lack of training data at the time.\n The advent of powerful computers, GPUs, and massive amounts of data have brought the old concept to the forefront.\n\n\n\n\n\n\nFrom xkcd.com",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro ML for the humanities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_hss_intro_content.html#so-how-does-it-all-work",
    "href": "ai/ws_hss_intro_content.html#so-how-does-it-all-work",
    "title": "Intro to ML for the humanities",
    "section": "So how does it all work?",
    "text": "So how does it all work?\nIt depends on the type of learning.\n\nSupervised learning\n\nRegression is a form of supervised learning with continuous outputs.\nClassification is supervised learning with discrete outputs.\n\nSupervised learning uses training data in the form of example input/output pairs.\nGoal: find the relationship between inputs and outputs.\n\n\nUnsupervised learning\nClustering, social network analysis, market segmentation, PCA ‚Ä¶ are all forms of unsupervised learning.\nUnsupervised learning uses unlabelled data.\nGoal: find structure within the data.\n\n\nReinforcement learning\nThe algorithm explores by performing random actions and these actions are rewarded or punished (bonus points or penalties).\nThis is how algorithms learn to play games.",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro ML for the humanities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_hss_intro_content.html#the-case-of-supervised-learning",
    "href": "ai/ws_hss_intro_content.html#the-case-of-supervised-learning",
    "title": "Intro to ML for the humanities",
    "section": "The case of supervised learning",
    "text": "The case of supervised learning\n\nDecide on an architecture\n\nThe architecture won‚Äôt change during training.\nThe type of architecture you choose (e.g.¬†CNN, Transformer) depends on the type of data you have (e.g.¬†vision, textual). The depth and breadth of your network depend on the amount of data and computing resource you have.\n\n\nSet some initial parameters\n\nYou can initialize them randomly or get much better ones through transfer learning.\nWhile the parameters are also part of the model, those will change during training.\n\n\nGet some labelled data\n\nWhen we say that we need a lot of data for machine learning, we mean ‚Äúlots of labelled data‚Äù as this is what gets used for training models.\n\n\nMake sure to keep data for testing\n\nThose data won‚Äôt be used for training the model. Often people keep around 20% of their data for testing.\n\n\nPass data and parameters\n\nThe train data are the inputs and the process of calculating the outputs is the forward pass.\n\n\nThe outputs are predictions\n\n\n\nCompare predictions with labels\n\nSince our data was labelled, we know what the true outputs are.\n\n\nCalculate train loss\n\nThe deviation of our predictions from the true outputs gives us a measure of training loss.\n\n\nAdjust parameters\n\nThe parameters get automatically adjusted to reduce the training loss through the mechanism of backpropagation. This is the actual training part.\nThis process is repeated many times. Training models is pretty much a giant for loop.\n\n\nFrom model to program\n\nRemember that the model architecture is fixed, but that the parameters change at each iteration of the training process.\n\nWhile the labelled data are key to training, what we are really interested in is the combination of architecture + final parameters.\n\nWhen the training is over, the parameters become fixed. Which means that our model now behaves like a classic program.\n\n\nEvaluate the model\n\nWe can now use the testing set (which was never used to train the model) to evaluate our model: if we pass the test inputs through our program, we get some predictions that we can compare to the test labels (which are the true outputs).\nThis gives us the test loss: a measure of how well our model performs.\n\n\nUse the model\n\nNow that we have a program, we can use it on unlabelled inputs to get what people ultimately want: unknown outputs.\nThis is when we put our model to actual use to solve some problem.",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro ML for the humanities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_hss_intro_content.html#artificial-neural-networks",
    "href": "ai/ws_hss_intro_content.html#artificial-neural-networks",
    "title": "Intro to ML for the humanities",
    "section": "Artificial neural networks",
    "text": "Artificial neural networks\n\n\n\nIn biological networks, the information consists of action potentials (neuron membrane rapid depolarizations) propagating through the network. In artificial ones, the information consists of tensors (multidimensional arrays) of weights and biases: each unit passes a weighted sum of an input tensor with an additional‚Äîpossibly weighted‚Äîbias through an activation function before passing on the output tensor to the next layer of units.\n\n\n\n\nArtificial neural networks are a series of layered units mimicking the concept of biological neurons: inputs are received by every unit of a layer, computed, then transmitted to units of the next layer. In the process of learning, experience strengthens some connections between units and weakens others.\n\n\n\n\n\n\nSchematic of a biological neuron:\n\n\n\n\nFrom Dhp1080, Wikipedia\n\n\n\n\n\nSchematic of an artificial neuron:\n\n\n\n\nModified from O.C. Akgun & J. Mei 2019\n\n\n\n\nWhile biological neurons are connected in extremely intricate patterns, artificial ones follow a layered structure. Another difference in complexity is in the number of units: the human brain has 65‚Äì90 billion neurons. ANN have much fewer units.\n\n\n\n\nNeurons in mouse cortex:\n\n\n\n\nNeurons are in green, the dark branches are blood vessels. Image by Na Ji, UC Berkeley\n\n\n\n\n\nNeural network with 2 hidden layers:\n\n\n\n\nFrom The Maverick Meerkat\n\n\n\n\nThe information in biological neurons is an all-or-nothing electrochemical pulse or action potential. Greater stimuli don‚Äôt produce stronger signals but increase firing frequency. In contrast, artificial neurons pass the computation of their inputs through an activation function and the output can take any of the values possible with that function.\n\n\n\nThreshold potential in biological neurons:\n\n\n\n\nModified from Blacktc, Wikimedia\n\n\n\n\nSome common activation functions in ANNs:\n\n\n\n\nFrom Diganta Misra 2019\n\n\n\n\n\nLearning\n\n\nThe process of learning in biological NN happens through neuron death or growth and the creation or loss of synaptic connections between neurons.\n\n\n\nIn ANN, learning happens through optimization algorithms such as gradient descent which minimize cross entropy loss functions by adjusting the weights and biases connecting each layer of neurons over many iterations.",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro ML for the humanities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_hss_intro_content.html#types-of-ann",
    "href": "ai/ws_hss_intro_content.html#types-of-ann",
    "title": "Intro to ML for the humanities",
    "section": "Types of ANN",
    "text": "Types of ANN\n\nFully connected neural networks\n\n\n\n\n\nFrom Glosser.ca, Wikipedia\n\n\n\nEach neuron receives inputs from every neuron of the previous layer and passes its output to every neuron of the next layer.\n\n\n\n\nConvolutional neural networks\n\n\n\nFrom Programming Journeys by Rensu Theart\n\n\nConvolutional neural networks (CNN) are used for spatially structured data (e.g.¬†images).\nImages have huge input sizes and would require a very large number of neurons in a fully connected neural net. In convolutional layers, neurons receive input from a subarea (called local receptive field) of the previous layer. This greatly reduces the number of parameters. Optionally, pooling (combining the outputs of neurons in a subarea) reduces the data dimensions.\n\n\nRecurrent neural networks\n\n\n\nFrom fdeloche, Wikipedia\n\n\nRecurrent neural networks (RNN) such as Long Short-Term Memory (LSTM) are used for chain structured data (e.g.¬†text).\nThey are not feedforward networks (i.e.¬†networks for which the information moves only in the forward direction without any loop).\n\n\nTransformers\nA combination of two RNNs (the encoder and the decoder) is used in sequence to sequence models for translation or picture captioning.\nIn 2014 the concept of attention (giving added weight to important words) was developed, greatly improving the ability of such models to process a lot of data.\nThe problem with recurrence is that it is not easily to parallelize (and thus to run fast on GPUs).\nIn 2017, a new model‚Äîthe transformer‚Äîwas proposed: by using only attention mechanisms and no recurrence, the transformer achieves better results in an easily parallelizable fashion.\nWith the addition of transfer learning, powerful transformers emerged in the field of NLP (e.g.¬†Bidirectional Encoder Representations from Transformers (BERT) from Google and Generative Pre-trained Transformer-3 (GPT-3) from OpenAI).",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro ML for the humanities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_hss_intro_content.html#ml-limitations",
    "href": "ai/ws_hss_intro_content.html#ml-limitations",
    "title": "Intro to ML for the humanities",
    "section": "ML limitations",
    "text": "ML limitations\n\nData bias\nBias is always present in data.\nDocument the limitations and scope of your data as best as possible.\nProblems to watch for:\n\nOut of domain data: data used for training are not relevant to the model application.\nDomain shift: model becoming inadapted as conditions evolve.\nFeedback loop: initial bias exacerbated over the time.\n\n\n\nThe last one is particularly problematic whenever the model outputs the next round of data based on interactions of the current round of data with the real world.\nSolution: ensure there are human circuit breakers and oversight.\n\n\n\n\n\n\nFrom xkcd.com\n\n\n\n\n\n\nTransformation of subjects\nAlgorithms are supposed to help us, not transform us (e.g.¬†YouTube recommendation algorithms).\n\n\nBugs\nExample of bug with real life consequences",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro ML for the humanities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_hss_intro_content.html#tools",
    "href": "ai/ws_hss_intro_content.html#tools",
    "title": "Intro to ML for the humanities",
    "section": "Tools",
    "text": "Tools\n\nMany options\nHere are just a few:\n\nscikit-learn: a Python ML library built on top of SciPy.\nNatural Language Toolkit (NLTK): a suite of Python libraries geared towards teaching and research.\nspaCy: Python library geared towards production.\ntorchtext, part of the PyTorch project (and many options of added layers on top such as PyTorch-NLP): Python library.\nGenSim: Python library.\nStanford CoreNLP: Java library.\nMany libraries in the Julia programming language.\n\n\n\nWhich one to choose?\nChoose an open source tool (i.e.¬†stay away from proprietary software such as MATLAB).\n\nResearchers who do not have access to the tool cannot reproduce your methods (open tools = open equitable research).\nOnce you graduate, you may not have access to the tool anymore.\nYour university may stop paying for a license.\nYou may get locked-in.\nProprietary tools are often black boxes.\nLong-term access is not guaranty (problem to replicate studies).\nThe licenses you have access to may be limiting and a cause of headache.\nProprietary tools fall behind popular open-source tools.\nProprietary tools often fail to address specialized edge cases needed in research.",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro ML for the humanities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "ai/ws_hss_intro_content.html#resources",
    "href": "ai/ws_hss_intro_content.html#resources",
    "title": "Intro to ML for the humanities",
    "section": "Resources",
    "text": "Resources\n\nNeural nets\n3Blue1Brown by Grant Sanderson has a series of 4 videos on neural networks which is easy to watch, fun, and does an excellent job at introducing the functioning of a simple neural network:\n\nWhat are NN? (19 min)\nHow do NN learn? (21 min)\nWhat is backpropagation? (14 min)\nHow does backpropagation work? (10 min)\n\n\nAs you develop your own ML models, if you find that your mathematical background is shaky, 3blue1brown also has an excellent series of videos on linear algebra and an equally great one on calculus.\n\n\n\nOpen-access preprints\n\nArxiv Sanity Preserver by Andrej Karpathy\nML papers in the computer science category on arXiv\nML papers in the stats category on arXiv\nDistill ML research online journal\n\n\n\nAdvice and sources\n\nAdvice and sources from ML research student\n\n\n\nGetting help\nStack Overflow:\n\n[machine-learning] tag\n[deep-learning] tag\n[supervised-learning] tag\n[unsupervised-learning] tag\n[semisupervised-learning] tag\n[reinforcement-learning] tag\n[transfer-learning] tag\n[machine-learning-model] tag\n[learning-rate] tag\n\n\n\nOpen datasets\n\nbenchmarks.ai\nAIBench\nkaggle\nWikipedia\n\n\n\nPyTorch\n\nDocumentation\nTutorials\nExamples\n\n\nGetting help\n\nPyTorch Discourse forum\nStack Overflow [pytorch] tag\n\n\n\nPre-trained models\n\nPyTorch Hub\n\n\n\n\nPython\n\nIDE\n\nProject Jupyter\nList of IDEs with description\nComparison of IDEs\nEmacs Python IDE\n\n\n\nGetting help\n\nStack Overflow [python] tag",
    "crumbs": [
      "AI",
      "<b><em>Workshops</em></b>",
      "Intro ML for the humanities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "bash/index.html",
    "href": "bash/index.html",
    "title": "Unix shells",
    "section": "",
    "text": "Getting started with  and ¬†\nA course on Bash and Zsh\n\n\n\n\nWorkshops\nVarious Unix shell topics\n\n\n\n\n\n\n60 min webinars\nVarious Unix shell topics",
    "crumbs": [
      "Bash/Zsh",
      "<br>&nbsp;<img src=\"img/logo_bash.png\" class=\"img-fluid\" style=\"width:1.6em\" alt=\"noshadow\"> &nbsp;/ &nbsp;<img src=\"img/logo_zsh.svg\" class=\"img-fluid\" style=\"width:1.3em\" alt=\"noshadow\"><br><br>"
    ]
  },
  {
    "objectID": "bash/intro_bash.html",
    "href": "bash/intro_bash.html",
    "title": "Introduction",
    "section": "",
    "text": "What are Unix shells?\nDo I need to use them?\nWhich one should I use?\nHow can I use it?\nThis section answers these questions and covers how we are going to run a shell for this course.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Introduction"
    ]
  },
  {
    "objectID": "bash/intro_bash.html#unix-shells",
    "href": "bash/intro_bash.html#unix-shells",
    "title": "Introduction",
    "section": "Unix shells",
    "text": "Unix shells\nUnix shells are command line interpreters for Unix-like operating systems (OS)1.\nIn contrast to graphical user interfaces (GUIs), the user enters commands as text‚Äîinteractively in a terminal or via scripts (a text file with a number of commands)‚Äîand the shell passes them to the OS.\n\nTypes of Unix shells\nBash, the Bourne Again SHell, released in 1989 as part of the GNU Project, is the default Unix shell on most systems, including the Alliance clusters. The executable to use it is bash. It replaces the initial Bourne shell‚Äîexecutable: sh. We will mostly learn Bash in this course.\nA newer and very popular shell, almost fully backward compatible with Bash and extending its capabilities, is Z shell (or Zsh)‚Äîexecutable: zsh. macOS recently changed its default shell from Bash to Zsh. We will talk about it at the end of this course.\nBoth Bash and Zsh are POSIX compliant, meaning that they respect the Portable Operating System Interface standards, making them compatible between operating systems.\nThere are several other Unix shells, some of which are also POSIX compliant and with a very similar syntax such as KornShell (ksh), others with a more different syntax and not POSIX compliant such as fish or C shell (csh).\n\n\nWhy use a shell?\nGiving instructions to the OS via text has many advantages.\nWhile automating GUI operations is difficult (you need a software that turns your mouse actions into a script or an AI agent), it is easy to rerun a script. It is also very easy to apply the same command to any number of files. Unix shells thus allow the creation of reproducible workflows and the automation of repetitive tasks.\n\nImagine you had 1000 files in a directory and you wanted to rename them all.\nUsing Windows Explorer or macOS Finder, you could right click on every file one by one to rename it, but it would take hours. Using a Unix shell, this is done by a very simple command and takes an instant.\n\nShells are particularly powerful to launch tools, modify files, search text, or combine commands.\n\nBecause shells are powerful, you can easily make consequential mistakes (e.g.¬†delete a lot of files permanently at once). For this reason, it is a good idea to make backups of your data before you start experimenting with novel shell commands (it is a very good idea to make frequent backups of your computer anyway!).\n\nKnowing how to interact with a machine via shells allows you to use computers that do not have a windowing system installed or to use them very efficiently without launching the windowing system.\nFinally, shells make it easy to access remote machines and HPC clusters.\n\nThe main method to access the Alliance HPC systems requires knowledge of a shell.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Introduction"
    ]
  },
  {
    "objectID": "bash/intro_bash.html#running-bash",
    "href": "bash/intro_bash.html#running-bash",
    "title": "Introduction",
    "section": "Running Bash",
    "text": "Running Bash\nSince Bash is a Unix shell, you need a Unix or Unix-like OS. This means that people on Linux or macOS can use Bash directly on their machine.\nFor Windows users, there are various options:\n\nusing Windows Subsystem for Linux (WSL),\nusing a Bash emulator (e.g.¬†Git BASH), but those only have a subset of the usual Bash utilities,\nusing a Unix-like environment for Windows (e.g.¬†Cygwin),\nusing a Unix Virtual machine,\naccessing a remote Unix machine.\n\n\nHow we will use Bash today\nToday, we will connect to a remote HPC cluster (supercomputer) via SSH (secure shell). HPC systems always run Linux.\n\nNote that this cluster is virtual and temporary. It will only be available for the duration of this course.\n\nThose on Linux or macOS can use Bash directly on their machine if they prefer, but using our remote system will give you an opportunity to practice using SSH‚Äîsomething you will have to do if you ever want to use the Alliance supercomputers.\n\nOn macOS, the default is now Zsh (you can see that by launching the application called ‚ÄúTerminal‚Äù and typing echo $SHELL, then pressing Enter), but Zsh is almost fully compatible with Bash commands, so it is fine to use it instead. If you really want to use Bash, simply launch it by typing in ‚ÄúTerminal‚Äù: bash, then pressing Enter.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Introduction"
    ]
  },
  {
    "objectID": "bash/intro_bash.html#remote-connection-to-the-cluster",
    "href": "bash/intro_bash.html#remote-connection-to-the-cluster",
    "title": "Introduction",
    "section": "Remote connection to the cluster",
    "text": "Remote connection to the cluster\n\nStep 1: get the info\nDuring the course, we will give you 3 pieces of information:\n\na link to a list of usernames,\nthe hostname for our temporary training cluster,\nthe password to access that cluster.\n\n\n\nStep 2: claim a username\nAdd your first name or a pseudo next to a free username on the list to claim it.\nYour username is the name that was already on the list, NOT what you wrote next to it (which doesn‚Äôt matter at all and only serves at signalling that this username is now taken).\nYour username will look like userxx‚Äîxx being 2 digits‚Äîwith no space and no capital letter.\n\n\nStep 3: run the ssh command\n\n¬†‚Ä¢¬† Linux and macOS users\nLinux users: ‚ÄÇ‚ÄÇopen the terminal emulator of your choice.\nmacOS users: ¬†¬†open ‚ÄúTerminal‚Äù.\nThen type:\nssh userxx@hostname\nand press Enter.\n\n\nReplace userxx by your username (e.g.¬†user09).\nReplace hostname by the hostname we will give you the day of the workshop.\n\n\nWhen asked:\n\nAre you sure you want to continue connecting (yes/no/[fingerprint])?\n\nAnswer: ‚Äúyes‚Äù.\n\n\n¬†‚Ä¢¬† Windows users\nWe suggest using the free version of MobaXterm, a software that comes with a terminal emulator and a GUI interface for SSH sessions.\nHere is how to install MobaXterm:\n\ndownload the ‚ÄúInstaller edition‚Äù to your computer (green button to the right),\nunzip the file,\ndouble-click on the .msi file to launch the installation.\n\nHere is how to log in with MobaXterm:\n\nopen MobaXterm,\nclick on Session (top left corner),\nclick on SSH (top left corner),\nfill in the Remote host * box with the cluster hostname we gave you,\ntick the box Specify username,\nfill in the box with the username you selected (e.g.¬†user09),\npress OK,\nwhen asked Are you sure you want to continue connecting (yes/no/[fingerprint])?, answer: ‚Äúyes‚Äù.\n\n\nHere is a live demo.\n\n\n\n\nStep 4: enter the password\nWhen prompted, enter the password we gave you.\nYou will not see anything happen as you type the password. This is normal and it is working, so keep on typing the password.\n\nThis is called blind typing and is a Linux safety feature. It can be unsettling at first not to get any feed-back while typing as it really looks like it is not working. Type slowly and make sure not to make typos.\n\nThen press Enter.\nYou are now logged in and your prompt should look like the following (with your actual username):\n[userxx@login1 ~]$\n\n\nTroubleshooting\nProblems logging in are almost always due to typos. If you cannot log in, retry slowly, entering your password carefully.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Introduction"
    ]
  },
  {
    "objectID": "bash/intro_bash.html#footnotes",
    "href": "bash/intro_bash.html#footnotes",
    "title": "Introduction",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nUnix-like systems include Linux, macOS, and a few others.‚Ü©Ô∏é",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Introduction"
    ]
  },
  {
    "objectID": "bash/intro_control_flow.html",
    "href": "bash/intro_control_flow.html",
    "title": "Control flow",
    "section": "",
    "text": "By default, scripts get executed linearly from top to bottom. Often however, you want to control what gets executed when.\nThis section covers various ways to control the flow of execution through a script."
  },
  {
    "objectID": "bash/intro_control_flow.html#normal-execution-of-commands",
    "href": "bash/intro_control_flow.html#normal-execution-of-commands",
    "title": "Control flow",
    "section": "Normal execution of commands",
    "text": "Normal execution of commands\nCommands get executed from top to bottom and from left to right. Different commands are separated by a line break and/or a semi-colon.\n\nExample:\n\nLook at the following commands:\nunzip bash.zip\nrm bash.zip\nThis is equivalent to:\nunzip bash.zip;\nrm bash.zip\nand to:\nunzip bash.zip; rm bash.zip\nThis is what we did to get the data for the past few sessions.\nIn all three cases, both commands will try to run. Now, if for some reason, the unzipping fails, the zip file still gets deleted. That‚Äôs a bummer."
  },
  {
    "objectID": "bash/intro_control_flow.html#conditional-on-previous-command",
    "href": "bash/intro_control_flow.html#conditional-on-previous-command",
    "title": "Control flow",
    "section": "Conditional on previous command",
    "text": "Conditional on previous command\n\nExecution conditional on success\nCommands can be limited to running only if the previous command ran successfully thanks to the double-ampersand (&&).\n\nExample:\n\nunzip bash.zip &&\n    rm bash.zip\nThis is equivalent to:\nunzip bash.zip && rm bash.zip\nIf the unzipping works (if it returns a zero exit status), then the Zip file gets deleted. If however, the unzipping fails (if it returns a non-zero exit status), the script aborts and we haven‚Äôt lost our Zip file.\n\n\nExecution conditional on failure\nThe opposite of && is ||: the second command only gets executed if the first one failed.\n\nExample:\n\nunzip bash.zip || echo \"Unzipping failed\"\nThis can also be written as:\nunzip bash.zip ||\n    echo \"Unzipping failed\""
  },
  {
    "objectID": "bash/intro_control_flow.html#conditional-executions",
    "href": "bash/intro_control_flow.html#conditional-executions",
    "title": "Control flow",
    "section": "Conditional executions",
    "text": "Conditional executions\nCommands can be executed or not depending on some conditions. To achieve this, we first need to have expressions that define these conditions.\n\nPredicates\nPredicates are expressions that, when evaluated, return either true or false.\nHere are examples of predicates:\n[ $var == 'text' ] checks whether var is equal to 'text'.\n[ $var == number ] checks whether var is equal to number.\n[ -e name ] checks whether name exists.\n[ -d name ] checks whether name is a directory.\n[ -f name ] checks whether name is a file.\nMake sure to have spaces around each bracket.\n\n\nYour turn:\n\n\nCreate a directory d1 and a file f1.\n\n\n\n\n\n\nWrite the predicates that test whether:\nd1 exists,\nd1 is a file,\nd1 is a directory,\nf1 is a file,\nf1 is a directory.\n\n\n\n\nIf statements\n\nSyntax\nIn its simplest form, if statements look like:\nif [ predicate ]\nthen\n    command1\n    command2\n    ...\nfi\n\nThis can also be written as:\nif [ predicate ]; then command1; command2; ...; fi\n\nIf the condition is true, the commands are executed, if the condition is false, nothing happens.\n\n\nExamples\n\nvar=f1\n\nif [ -e $var ]\nthen\n    echo \"$var exists\"\nfi\n\n\nvar=f2\n\nif [ -e $var ]\nthen\n    echo \"$var exists\"\nfi\n\n\n\nYour turn:\n\nWrite a conditional expression that prints ‚Äúd1 is a directory‚Äù if d1 is a directory and test it.\n\n\n\n\nIf else statements\n\nSyntax\nIf you want a different set of commands to be executed when the condition is false, you add an else statement:\nif [ predicate ]\nthen\n    command1\n    command2\n    ...\nelse\n    command3\n    command4\n    ...\nfi\n\n\nExamples\n\nvar=f1\n\nif [ -e $var ]\nthen\n    echo \"$var exists\"\nelse\n    echo \"$var does not exist\"\nfi\n\nf1 does not exist\n\n\n\nvar=f2\n\nif [ -e $var ]\nthen\n    echo \"$var exists\"\nelse\n    echo \"$var does not exist\"\nfi\n\nf2 does not exist\n\n\n\n\n\nIf elif else statements\nOf course, you can have multiple conditions defining trees of if statements. In that case, you use elif (any number of times):\n\nSyntax\nif [ predicate1 ]\nthen\n    command1\n    command2\n    ...\nelif [ predicate2 ]\nthen\n    command3\n    command4\n    ...\nelse\n    command5\n    command6\n    ...\nfi\n\n\nExamples\n\nvar=4\n\nif (( $var &lt; 0 ))\nthen\n    echo \"$var is negative\"\nelif (( $var &gt; 0 ))\nthen\n    echo \"$var is positive\"\nelse\n    echo \"$var is equal to zero\"\nfi\n\n4 is positive\n\n\n\n\nYour turn:\n\nPlay with the value of var to test our if elif else statement."
  },
  {
    "objectID": "bash/intro_control_flow.html#conditionally-repeated-executions",
    "href": "bash/intro_control_flow.html#conditionally-repeated-executions",
    "title": "Control flow",
    "section": "Conditionally repeated executions",
    "text": "Conditionally repeated executions\nCommands can be executed as long as a condition returns True thanks to while loops.\n\nSyntax\nThe syntax of a while loop in Bash is:\nwhile [ predicate ]\ndo\n    command1\n    command2\n    ...\ndone\n\n\nExample\n\nvar=0\n\nwhile (($var&lt;10))\ndo\n    echo \"$var\"\n    ((var++))\ndone\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nBe careful that while loops can lead to infinite loops. Such loops need to be manually interrupted (by pressing &lt;Ctrl+C&gt;).\n\nExample of infinite loop:\n\nvar=1\n\nwhile (($var&gt;0))\ndo\n    echo \"$var (Press &lt;Ctrl+C&gt; to stop)\"\n    ((var++))\n    sleep 1\ndone"
  },
  {
    "objectID": "bash/intro_control_flow.html#executions-repeated-over-a-collection",
    "href": "bash/intro_control_flow.html#executions-repeated-over-a-collection",
    "title": "Control flow",
    "section": "Executions repeated over a collection",
    "text": "Executions repeated over a collection\nCommands can be repeated for each element of a list thanks to for loops.\n\nCollections\nFor loops run a set of commands for each item of a collection. How do you create those collections?\n\nListing items one by one\nThe least efficient method is to list all the items one by one:\n\nfor i in file1 file2 file3\ndo\n    echo $i\ndone\n\nfile1\nfile2\nfile3\n\n\n\n\nWildcards\n\nls *.pdb\n\nls: cannot access '*.pdb': No such file or directory\n\n\n\n\nBrace expansion\nCollections can also be created with brace expansion.\n\nExamples:\n\n\necho {1,2,5}\n\n1 2 5\n\n\n\nMake sure not to add a space after the commas.\n\n\necho {list,of,strings}\n\nlist of strings\n\n\n\necho {file1,file2}.sh\n\nfile1.sh file2.sh\n\n\n\nls {ethane,methane,pentane}.pdb\n\nls: cannot access 'ethane.pdb': No such file or directory\nls: cannot access 'methane.pdb': No such file or directory\nls: cannot access 'pentane.pdb': No such file or directory\n\n\n\necho {1..5}\n\n1 2 3 4 5\n\n\n\necho {01..10}\n\n01 02 03 04 05 06 07 08 09 10\n\n\n\necho {r..v}\n\nr s t u v\n\n\n\necho {v..r}\n\nv u t s r\n\n\n\necho {a..e}{1..3}\n\na1 a2 a3 b1 b2 b3 c1 c2 c3 d1 d2 d3 e1 e2 e3\n\n\n\necho {a..c}{a..c}\n\naa ab ac ba bb bc ca cb cc\n\n\n\necho {1..5}.txt\n\n1.txt 2.txt 3.txt 4.txt 5.txt\n\n\n\necho file{3..6}.sh\n\nfile3.sh file4.sh file5.sh file6.sh\n\n\n\n\nSequences\nCollections can also be sequences:\n\nseq 1 2 10\n\n1\n3\n5\n7\n9\n\n\n\nHere, 1 is the start of the sequence, 10 is the end, and 2 is the step.\n\n\n\n\nFor loops\n\nSyntax\nThe general structure of a for loop is as follows:\nfor iterable in collection\ndo\n    command1\n    command2\n    ...\ndone\n\n\nExamples\nThe molecules directory contains a number of .pdb files. We want to rename them by prepending ‚Äúgas_‚Äù to their current names.\nWe can do this by creating a collection with a wildcard and applying the command to each element of the collection with a for loop:\nfor file in *.pdb\ndo\n    mv $file gas_$file\ndone\n\nThis can also be written as:\nfor file in *.pdb; do mv $file gas_$file; done\n\nHere is a for loop using a collection created by a sequence:\n\nfor i in $(seq 1 2 10)\ndo\n    echo file$i.txt\ndone\n\nfile1.txt\nfile3.txt\nfile5.txt\nfile7.txt\nfile9.txt\n\n\n\n\n\n\n\n\n\n\n\nYour turn:\n\nIn a directory the command ls returns:\nfructose.dat  glucose.dat  sucrose.dat  maltose.txt\nWhat would be the output of the following loop?\nfor datafile in *.dat\ndo\n  cat $datafile &gt;&gt; sugar.dat\ndone\n\nAll of the text from fructose.dat, glucose.dat and sucrose.dat would be concatenated and saved to a file called sugar.dat.\nThe text from sucrose.dat will be saved to a file called sugar.dat.\nAll of the text from fructose.dat, glucose.dat, sucrose.dat, and maltose.txt would be concatenated and saved to a file called sugar.dat.\nAll of the text from fructose.dat, glucose.dat and sucrose.dat will be printed to the screen and saved into a file called sugar.dat.\n\n\n\n\n\n\nHere is a video of a previous version of this workshop."
  },
  {
    "objectID": "bash/intro_find.html",
    "href": "bash/intro_find.html",
    "title": "Finding files",
    "section": "",
    "text": "For this section, we will play with files created by The Carpentries.\nYou can download them into a zip file called data.zip with:\ncurl --output data.zip https://mint.westdri.ca/bash/data.zip\nYou can then unzip that file with:\nunzip data.zip\nYou should now have a data directory.\ncd into it:\ncd data"
  },
  {
    "objectID": "bash/intro_find.html#data-for-this-section-same-data-as-previous-section",
    "href": "bash/intro_find.html#data-for-this-section-same-data-as-previous-section",
    "title": "Finding files",
    "section": "",
    "text": "For this section, we will play with files created by The Carpentries.\nYou can download them into a zip file called data.zip with:\ncurl --output data.zip https://mint.westdri.ca/bash/data.zip\nYou can then unzip that file with:\nunzip data.zip\nYou should now have a data directory.\ncd into it:\ncd data"
  },
  {
    "objectID": "bash/intro_find.html#command-find",
    "href": "bash/intro_find.html#command-find",
    "title": "Finding files",
    "section": "Command find",
    "text": "Command find\nSearch for files inside the current working directory:\nfind . -type f\n./methane.pdb\n./pentane.pdb\n./sorted.txt\n./propane.pdb\n./lengths.txt\n./cubane.pdb\n./ethane.pdb\n./octane.pdb\nfind . -type d will instead search for directories inside the current working directory.\nHere are other examples:\nfind . -maxdepth 1 -type f     # depth 1 is the current directory\nfind . -mindepth 2 -type f     # current directory and one level down\nfind . -name haiku.txt      # finds specific file\nls data       # shows one.txt two.txt\nfind . -name *.txt      # still finds one file -- why? answer: expands *.txt to haiku.txt\nfind . -name '*.txt'    # finds all three files -- good!\nLet‚Äôs wrap the last command into $()‚Äîcalled command substitution‚Äîas if it were a variable:\necho $(find . -name '*.txt')   # will print ./data/one.txt ./data/two.txt ./haiku.txt\nls -l $(find . -name '*.txt')   # will expand to ls -l ./data/one.txt ./data/two.txt ./haiku.txt\nwc -l $(find . -name '*.txt')   # will expand to wc -l ./data/one.txt ./data/two.txt ./haiku.txt\ngrep elegant $(find . -name '*.txt')   # will look for 'elegant' inside all *.txt files\n\n\nYour turn:\n\ngrep‚Äôs -v flag inverts pattern matching, so that only lines that do not match the pattern are printed.\nGiven that, which of the following commands will find all files in /data whose names end in ose.dat (e.g.¬†sucrose.dat or maltose.dat), but do not contain the word temp?\n\nfind /data -name '*.dat' | grep ose | grep -v temp\nfind /data -name ose.dat | grep -v temp\ngrep -v temp $(find /data -name '*ose.dat')\nNone of the above\n\n\nHere is a video of a previous version of this workshop."
  },
  {
    "objectID": "bash/intro_find.html#running-a-command-on-the-results-of-find",
    "href": "bash/intro_find.html#running-a-command-on-the-results-of-find",
    "title": "Finding files",
    "section": "Running a command on the results of find",
    "text": "Running a command on the results of find\nLet‚Äôs say that you want to run a command on each of the files in the output of find. You can always do something using command substitution like this:\nfor f in $(find . -name \"*.txt\")\ndo\n    command on $f\ndone\nAlternatively, you can make it a one-liner:\nfind . -name \"*.txt\" -exec command {} \\;\nAnother‚Äîperhaps more elegant‚Äîone-line alternative is to use xargs. In its simplest usage, xargs command lets you construct a list of arguments:\nfind . -name \"*.txt\"                   # returns multiple lines\nfind . -name \"*.txt\" | xargs           # use those lines to construct a list\nfind . -name \"*.txt\" | xargs command   # pass this list as arguments to `command`\ncommand $(find . -name \"*.txt\")        # command substitution, achieving the same result (this is riskier!)\ncommand `(find . -name \"*.txt\")`       # alternative syntax for command substitution\nIn these examples, xargs achieves the same result as command substitution, but it is safer in terms of memory usage and the length of lists you can pass.\nWhen would you need to use this? A good example is with the command grep. grep takes a search stream (and not a list of files) as its standard input:\ncat filename | grep pattern\nTo pass a list of files to grep, you can use xargs that takes that list from its standard input and converts it into a list of arguments that is then passed to grep:\nfind . -name \"*.txt\" | xargs grep pattern   # search for `pattern` inside all those files (`grep` does not take a list of files as standard input)\n\n\nHere is a video of a previous version of this workshop."
  },
  {
    "objectID": "bash/intro_modern.html",
    "href": "bash/intro_modern.html",
    "title": "Modern utilities",
    "section": "",
    "text": "In recent years, a number of open-source utilities for the Unix shell have emerged. Some are meant as replacements for classic tools with improved performance, better defaults, or nicer-looking outputs; others add novel functionality. Several of them were recently installed on the Alliance clusters.\nIn this section we will cover a selection of tools that are very popular, well-maintained, and will improve your time on the command line.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Modern utilities"
    ]
  },
  {
    "objectID": "bash/intro_modern.html#how-to-choose-tools",
    "href": "bash/intro_modern.html#how-to-choose-tools",
    "title": "Modern utilities",
    "section": "How to choose tools?",
    "text": "How to choose tools?\nYou can install and experiment with any tool. A few things might help you decide whether or not a tool looks promising:\n\nHow popular is it? (GitHub stars)\nIs it maintained? (date of last commit)\nHow polished is the documentation?\nHow fast is it? (what language is it written in?)\n\nTools written in Shell or Python will be slower, while those written in compiled languages (Rust, C, Go) will be faster.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Modern utilities"
    ]
  },
  {
    "objectID": "bash/intro_modern.html#ls-in-colours-eza",
    "href": "bash/intro_modern.html#ls-in-colours-eza",
    "title": "Modern utilities",
    "section": "ls in colours: eza",
    "text": "ls in colours: eza\neza is a replacement for ls.\nFor the most part, it adds colours and uses the same options as ls, but it also adds a few features and has better default options.\n\nInstallation\n\nOn your own machine\nYou can find the installation instructions here.\n\n\nOn the Alliance clusters\neza is not installed on the Alliance clusters, so you will have to install it locally under your own user. This is easy to do because it is written in Rust and can be installed with the Rust package manager.\nFirst, you load a Rust module, then you install the package:\nmodule load rust/1.76.0\ncargo install eza\nFinally, make sure that ~/.cargo/bin is in your PATH as this is where the binary will get installed. So add to your .bashrc:\nexport PATH=$PATH:~/.cargo/bin\n\nYou only need to do this once in the production cluster you use. After eza has been installed, it will be accessible on subsequent sessions.\n\n\n\n\nUsage\neza\nprojects scratch\nYou now have different colours for different types of files. You can already see that the directory (projects) is in bold blue and the symlink (scratch) is in cyan (my website doesn‚Äôt render these colours but you will see them when you run the command in our training cluster).\nLet‚Äôs create some files quickly to see a bit more colours:\ntouch test.html test.md test.py test.R\neza\nprojects scratch test.html test.md test.py test.R\nNow you can see that the scripts are in bold yellow while the markup files are in gray.\nThe flags are similar to those of ls, but some defaults are slightly different:\neza -al\n.rw-------@ 2.8k user02 19 Dec 04:20 .bash_history\n.rw-------@   18 user02 13 Dec 00:55 .bash_logout\n.rw-r-----@  141 user02 19 Dec 04:20 .bash_profile\n.rw-r-----@ 7.3k user02 19 Dec 03:57 .bashrc\ndrwxr-x---@    - user02 19 Dec 03:57 .cargo\ndrwx------@    - user02 13 Dec 18:10 .ssh\ndrwxr-xr-x@    - root   13 Dec 00:57 projects\nlrwxrwxrwx@    - user02 13 Dec 00:55 scratch -&gt; /scratch/user02\n.rw-r-----@    0 user02 19 Dec 04:25 test.html\n.rw-r-----@    0 user02 19 Dec 04:25 test.md\n.rw-r-----@    0 user02 19 Dec 04:25 test.py\n.rw-r-----@    0 user02 19 Dec 04:29 test.R\n\nCompare with ls -al:\ntotal 60\ndrwx------.  12 user02 user02 4096 Dec 19 04:29 .\ndrwxr-xr-x. 101 root   root   4096 Dec 13 00:57 ..\n-rw-------.   1 user02 user02 2763 Dec 19 04:20 .bash_history\n-rw-------.   1 user02 user02   18 Dec 13 00:55 .bash_logout\n-rw-r-----.   1 user02 user02  141 Dec 19 04:20 .bash_profile\n-rw-r-----.   1 user02 user02 7320 Dec 19 03:57 .bashrc\ndrwxr-x---.   4 user02 user02  125 Dec 19 03:57 .cargo\ndrwx------.   2 user02 user02   48 Dec 13 18:10 .ssh\ndrwxr-xr-x.   2 root   user02   27 Dec 13 00:57 projects\nlrwxrwxrwx.   1 user02 user02   15 Dec 13 00:55 scratch -&gt; /scratch/user02\n-rw-r-----.   1 user02 user02    0 Dec 19 04:29 test.R\n-rw-r-----.   1 user02 user02    0 Dec 19 04:25 test.html\n-rw-r-----.   1 user02 user02    0 Dec 19 04:25 test.md\n-rw-r-----.   1 user02 user02    0 Dec 19 04:25 test.py\neza by default shows the output in a human readable format (-h flag with ls) and without the group (-G with ls).\n\nThere is also the additional -T flag which is equivalent to running the tree utility:\neza -T\n.\n‚îú‚îÄ‚îÄ projects\n‚îÇ   ‚îî‚îÄ‚îÄ def-sponsor00 -&gt; /project/def-sponsor00\n‚îú‚îÄ‚îÄ scratch -&gt; /scratch/user02\n‚îú‚îÄ‚îÄ test.html\n‚îú‚îÄ‚îÄ test.md\n‚îú‚îÄ‚îÄ test.py\n‚îî‚îÄ‚îÄ test.R\n\n\nAlias\nIf you want, you can alias it to ls by adding to your .bashrc file:\nalias ls=eza\nIf you ever want to use the true ls utility, you can do so with \\ls.\n\n\nAlternative\nIf you want a simpler and more lightweight way to add colours to your ls outputs, you can look at LS_COLORS. I did this for years until I found eza.\nTo install it locally in the Alliance clusters, you have to download and uncompress a script, and copy it to a proper location:\nmkdir ./LS_COLORS &&\n    curl -L https://api.github.com/repos/trapd00r/LS_COLORS/tarball/master | tar xzf - --directory=./LS_COLORS --strip=1 &&\n    mkdir -p ~/.local/share &&\n    cp ~/LS_COLORS/lscolors.sh ~/.local/share &&\n    rm -r ~/LS_COLORS\nThen you need to add the following to your .bashrc file to source the script and add a proper alias to ls:\nsource ~/.local/share/lscolors.sh\nalias ls='ls --color'",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Modern utilities"
    ]
  },
  {
    "objectID": "bash/intro_modern.html#a-cat-with-wings-bat",
    "href": "bash/intro_modern.html#a-cat-with-wings-bat",
    "title": "Modern utilities",
    "section": "A cat with wings: bat",
    "text": "A cat with wings: bat\nbat is a replacement for cat with syntax highlighting for most programming languages, line numbers, and pager-like search and navigation.\n\nInstallation\nbat is installed on the Alliance clusters. To install it on your machine, you can follow the instructions here.\n\n\nUsage\nUse bat as you would use cat:\nbat .bash_profile\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n       ‚îÇ File: .bash_profile\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   1   ‚îÇ # .bash_profile\n   2   ‚îÇ\n   3   ‚îÇ # Get the aliases and functions\n   4   ‚îÇ if [ -f ~/.bashrc ]; then\n   5   ‚îÇ     . ~/.bashrc\n   6   ‚îÇ fi\n   7   ‚îÇ\n   8   ‚îÇ # User specific environment and startup programs\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nThen you are in your default pager.\nAmong other options, you can disable the frame with -nand also remove the line numbers with -p.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Modern utilities"
    ]
  },
  {
    "objectID": "bash/intro_modern.html#faster-find-fd",
    "href": "bash/intro_modern.html#faster-find-fd",
    "title": "Modern utilities",
    "section": "Faster find: fd",
    "text": "Faster find: fd\nfd is a replacement for find with the following assets:\n\nwritten in Rust, automatic parallelism ‚ûî with vastly improved performance,\nmore friendly syntax,\nby default excludes binaries as well as hidden files and directories,\nby default excludes patterns from .gitignore or other .ignore files.\n\n\nInstallation\nfg is installed on the Alliance clusters. To install it on your machine, you can follow the instructions here.\n\n\nBasic usage\nSearch file names for a pattern recursively in current directory:\nfd te\ntest.R\ntest.html\ntest.md\ntest.py\n\nfd uses regexp by default, so you can use pattern symbols:\nfd jx.*txt\n\n Search file names recursively in another directory:\nfd top bash/\n\n\nPrint all files in some directory to stdout\nCurrent directory:\nfd\nAnother directory:\nfd . bash/\n\n\nOptions\nSearch for files with a particular file extension:\nfd -e txt\nUse a globbing pattern instead of regexp:\nfd -g wb* bash/\nMatch full path instead of simply file name:\nfd -p bash/wb\nExecute command for each result of fd in parallel:\nfd top bash/ -x rg layout\nExecute command once with all results of fd as arguments:\nfd top bash/ -X rg layout\n\n\nExcluded files and directories\nBy default, fd excludes hidden files/directories and patterns in .gitignore (you can disable this with -H and -I respectively).\nThis makes fd combined with tree sometimes more useful than tree alone:\nfd . bash/ | tree --fromfile\n\nYou can make this a function:\nft () { fd $@ | tree --fromfile }\n\nExclude additional directories or patterns:\nfd -E *.txt -E img/ . bash/\nI personally prefer to disable the default settings and exclude patterns based on a file I created:\nalias fd='fd -u --ignore-file /home/marie/.fdignore'\nThis file (which can have any name you want) uses the same syntax as .gitignore.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Modern utilities"
    ]
  },
  {
    "objectID": "bash/intro_modern.html#rip-grep-ripgrep",
    "href": "bash/intro_modern.html#rip-grep-ripgrep",
    "title": "Modern utilities",
    "section": "RIP grep: ripgrep",
    "text": "RIP grep: ripgrep\nripgrep provides the rg utility‚Äîa replacement for grep with the following assets:\n\nwritten in Rust, automatic parallelism ‚ûî with vastly improved performance,\nby default excludes patterns from .gitignore or other .ignore files,\nby default excludes binaries as well as hidden files and directories,\nby default doesn‚Äôt follow symlinks.\n\n\nInstallation\nrg is installed on the Alliance clusters. To install it on your machine, you can follow the instructions here.\n\n\nUsage\nSearch lines in a file matching a pattern:\nrg .bash .bash_profile\n1:# .bash_profile\n4:if [ -f ~/.bashrc ]; then\n5:  . ~/.bashrc\nSearch lines matching pattern in all files in current directory (recursively):\nrg .bash\nrg and fd follow the same principles:\n\nuse of regexp by default,\nuse of globbing pattern with -g,\nsearch recursively by default,\nsame excluded files.\n\nYou can find full details on the syntax here.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Modern utilities"
    ]
  },
  {
    "objectID": "bash/intro_modern.html#smart-cd-zoxide",
    "href": "bash/intro_modern.html#smart-cd-zoxide",
    "title": "Modern utilities",
    "section": "Smart cd: zoxide",
    "text": "Smart cd: zoxide\nzoxide allows to easily jump to any directory.\n\nInstallation\nInstructions to install zoxide on your machine can be found here. Note that fzf (see below) adds cool functionality to it, so you might want to install it as well.\nInstalling zoxide on the Alliance clusters is extremely easy.\n\nFirst, you have to run the command:\n\ncurl -sSfL https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh | sh\nThis will install the binary in ~/.local/bin.\n\nThen, you have to make sure that ~/.local/bin is in your PATH.\n\nAdd to your .bashrc:\nexport PATH=$PATH:~/.local/bin\n\nFinally, you need to add to your .bashrc file (if you want to use it in Bash):\n\neval \"$(zoxide init bash)\"\nOr, if you want to use it in Zsh, add to your .zshrc file:\neval \"$(zoxide init zsh)\"\n\nYou can change the z and zi commands (a bit hard to type) by whatever command you want. I personally changed them to j and ji (‚Äúj‚Äù for ‚Äújump‚Äù). To do this, replace the eval expression(s) above by:\neval \"$(zoxide init --cmd j bash)\"\nand/or\neval \"$(zoxide init --cmd j zsh)\"\n\n\n\nUsage\nNow, you can type z (or whatever command you chose‚Äîsee above) instead of a regular cd command.\nIn addition, you can simplify the path you want to get to to just a few characters and zoxide will take you there.\nIf there are multiple locations matching your entry, the matching algorithm will chose the highest ranking path based on your frequency of use and how recently you visited a path.\nThis means that you can visit your usual places extremely easily. For less frequent places, add a bit more info.\nFinally, if you want to choose amongst all possible options in a completion framework, use zi instead and zoxide will open fzf (see below).\n\n\nAlternative\nA tool that served me well until someone pointed the faster and better zoxide to me is autojump.\n\nInstallation\nautojump is installed on the Alliance clusters, but you need to source a script before you can use it. Since you need to do this at every session, you should add to your .bashrc file:\n[[ -s $EPREFIX/etc/profile.d/autojump.sh ]] && source $EPREFIX/etc/profile.d/autojump.sh\nTo install autojump on your machine, you can follow the instructions here.\n\n\nUsage\nSimilar to zoxide but you need to visit directories so that they get entered into autojump‚Äôs database before you can jump to them.\nj is a wrapper for autojump, jc jumps to subdirectories of the current directory.\nYou can find the full usage documentation here.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Modern utilities"
    ]
  },
  {
    "objectID": "bash/intro_modern.html#fuzzy-finder-fzf",
    "href": "bash/intro_modern.html#fuzzy-finder-fzf",
    "title": "Modern utilities",
    "section": "Fuzzy finder: fzf",
    "text": "Fuzzy finder: fzf\nfzf allows to find elements of any list through incremental completion and fuzzy matching. It can be paired with any number of commands.\n\nInstallation\nfzf is installed on the Alliance clusters.\nTo get fzf kbds and fuzzy completion in your shell, add to your .bashrc:\neval \"$(fzf --bash)\"\nand/or your .zshrc:\nsource &lt;(fzf --zsh)\nTo install it on your machine, you can follow the instructions here.\n\n\nDirect usage\nIf you run fzf directly, it will search the current directory recursively, do a narrowing selection, and print the result:\nfzf\nYou can make use of fd (or whatever command you want) to filter out unnecessary entries by setting the FZF_DEFAULT_COMMAND environment variable (in your .bashrc or .zshrc):\nexport FZF_DEFAULT_COMMAND='fd -u --ignore-file /home/marie/.fdignore'\nRunning fzf by itself will now be equivalent to running your command of choice that you put in the FZF_DEFAULT_COMMAND environment variable piped to fzf. For all other ways to use fzf (see below), this has no effect so you still have the full flexibility of the tool.\n\n\nfzf key bindings\nfzf ships with three default kbds:\n\nCtl+t ‚ûî paste the selection into the command\nCtl+r ‚ûî paste the selection from history into the command\nAlt+c ‚ûî cd into the selection\n\nThe one that I find particularly useful is the first one. It is extremely useful to start typing a command (e.g.¬†cp), then use Ctl+t to add the path to a file or directory you want to use as argument of the command before finishing to type your command. Try it out!\n\n\nPipe to fzf\nYou can pipe the output of any command that returns a list of elements into fzf to find any particular element easily through incremental completion.\nFor instance, you can pipe the output of ls into fzf:\nls | fzf\nTo look for a running process:\nalias proc='ps -ef | fzf --cycle -i -e +s --tac --reverse'\n\nproc\nTo kill a running process:\nproc_kill() {\n    local pid\n    pid=$(ps -ef |\n          sed 1d |\n          fzf --cycle --reverse -i -e -m --bind \"ctrl-o:toggle-all\" \\\n          --header \"Tab: toggle, C-o: toggle-all\" |\n          awk '{print $2}')\n    echo $pid | xargs kill -${1:-15}\n}\n\nproc_kill\nTo search your command history:\nhis() {\n    fc -ln 1 |\n    rg -v '^q$|^x$|^vs$|^ek .*$|^zoom$|^c$|^cca$|^rs ...$|^hobu$|^cd$|^kzo$|^ih.?$|^zre$|^j m$|^y$|^g$|^-$|^auradd$' |\n    fzf --cycle -i -e +s --tac --reverse |\n    sed 's/ *[0-9]* *//'\n}\n\nhis\nTo search your command history and run the selected entry:\nhis_run() {\n    $(fc -ln 1 |\n      rg -v '^q$|^x$|^vs$|^ek .*$|^zoom$|^c$|^cca$|^rs ...$|^hobu$|^cd$|^kzo$|^ih.?$|^zre$|^j m$|^y$|^g$|^-$|^auradd$' |\n      fzf --cycle -i -e +s --tac --reverse |\n      sed 's/ *[0-9]* *//')\n}\n\nhis_run\nfzf has many options to select the order of entries, the type of completion, whether or not to display a preview, etc. You can find the information in the documentation.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Modern utilities"
    ]
  },
  {
    "objectID": "bash/intro_modern.html#file-system-tuis",
    "href": "bash/intro_modern.html#file-system-tuis",
    "title": "Modern utilities",
    "section": "File system TUIs",
    "text": "File system TUIs\n\nWhat is a TUI?\nTerminal user interfaces (TUIs) are the predecessors to graphical user interfaces (GUIs) which are entirely text based and run in terminals.\nThey have remained very popular among command line aficionados because they are fast, efficient, powerful, and keyboard-driven, while being friendly and visual.\nFantastic modern ones keep being built for tasks as diverse as interfaces to Git, music players, games, emails, dashboards, and, for our purpose here, file system management.\n\n\nFormerly most popular file system TUIs\nThere are many file system TUIs and all of them are actually really good. The two most notable ones used to be:\n\nranger\n\nExtremely sophisticated, easy to customize, tons of features.\n\nBuilt in Python, it can be slow for operations in directories with thousands of files.\n\n\nnnn\n\nMinimalist and very fast (written in C).\n\nNot easy to customize (many customizations require compiling from source). Most functionalities rely on plugins that need to be installed. Not easy to get started with.\n\n\n\nThe new kid: yazi\nyazi is a brand new file system TUI that has quickly become the most popular out there.\nIt is extremely modern, very fast (written in Rust), very well documented, intuitive, easy to customize, and integrates with modern utilities such as fd, rg, zoxide, and fzf out of the box.\nOnly at version 0.4, it is not fully mature yet, but it has already more stars on GitHub than ranger and nnn because it combines ease of customization and sophistication with speed.\n\n\nAlternatives\nHere are other really good‚Äîjust not as fast or full-featured‚Äîfile system TUIs, in decreasing number of stars on GitHub:\n\nbroot\nsuperfile\nlf\nxplr\nfff (now archived)\nvifm\nmc",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Modern utilities"
    ]
  },
  {
    "objectID": "bash/intro_modern.html#webinar",
    "href": "bash/intro_modern.html#webinar",
    "title": "Modern utilities",
    "section": "Webinar",
    "text": "Webinar\nI gave a webinar on this topic that you can find here.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Modern utilities"
    ]
  },
  {
    "objectID": "bash/intro_redirections.html",
    "href": "bash/intro_redirections.html",
    "title": "Redirections & pipes",
    "section": "",
    "text": "By default, commands that produce an output print it to the terminal. This output can however be redirected to be printed elsewhere (e.g.¬†to a file) or to be passed as the argument of another command."
  },
  {
    "objectID": "bash/intro_redirections.html#redirections",
    "href": "bash/intro_redirections.html#redirections",
    "title": "Redirections & pipes",
    "section": "Redirections",
    "text": "Redirections\nBy default, commands that produce an output print it to standard output‚Äîthat is, the terminal. This is what we have been doing so far.\nThe output can however be redirected with the &gt; sign. For instance, it can be redirected to a file, which is very handy if you want to save the result.\n\nExample:\n\nLet‚Äôs print the number of lines in each .pdb file in the molecules directory:\n\nwc -l *.pdb\n\nwc: '*.pdb': No such file or directory\n\n\n\n\nYour turn:\n\n\nWhat does the wc command do?\nWhat does the -l flag for this command do?\nHow did you find out?\n\n\nTo save this result into a file called lengths.txt, we run:\n\nwc -l *.pdb &gt; lengths.txt\n\nwc: '*.pdb': No such file or directory\n\n\n\nNote that &gt; always creates a new file. If a file called lengths.txt already exists, it will be overwritten. Be careful not to lose data this way!\nIf you don‚Äôt want to lose the content of the old file, you can append the output to the existing file with &gt;&gt; (&gt;&gt; will create a file lengths.txt if it doesn‚Äôt exist yet, but if it exists, it will append the new content below the old one).\n\n\n\nYour turn:\n\nHow can you make sure that you did create a file called lengths.txt?\n\nLet‚Äôs print its content to the terminal:\n\ncat lengths.txt\n\nAs you can see, it contains the output of the command wc -l *.pdb.\nOf course, we can print the content of the file with modification. For instance, we can sort it:\n\nsort -n lengths.txt\n\nAnd we can redirect this new output to a new file:\n\nsort -n lengths.txt &gt; sorted.txt\n\nInstead of printing an entire file to the terminal, you can print only part of it.\nLet‚Äôs print the first line of the new file sorted.txt:\n\nhead -1 sorted.txt"
  },
  {
    "objectID": "bash/intro_redirections.html#pipes",
    "href": "bash/intro_redirections.html#pipes",
    "title": "Redirections & pipes",
    "section": "Pipes",
    "text": "Pipes\nAnother form of redirection is the Bash pipe. Instead of redirecting the output to a different stream for printing, the output is passed as an argument to another command. This is very convenient because it allows to chain multiple commands without having to create files or variables to save intermediate results.\nFor instance, we could run the three commands we ran previously at once, without the creation of the two intermediate files:\n\nwc -l *.pdb | sort -n | head -1\n\nwc: '*.pdb': No such file or directory\n\n\nIn each case, the output of the command on the left-hand side (LHS) is passed as the input of the command on the right-hand side (RHS).\n\n\nYour turn:\n\nIn a directory we want to find the 3 files that have the least number of lines. Which command would work for this?\n\nwc -l * &gt; sort -n &gt; head -3\nwc -l * | sort -n | head 1-3\nwc -l * | sort -n | head -3\nwc -l * | head -3 | sort -n\n\n\nHere is a video of a previous version of this workshop."
  },
  {
    "objectID": "bash/intro_resources.html",
    "href": "bash/intro_resources.html",
    "title": "Resources",
    "section": "",
    "text": "This section lists a few useful Bash resources.\n\nOne very useful (although very dense) resource is the Bash manual. This is the absolute reference.\nThere are countless sites with Bash courses and guides. Here are a few:\n\nBash Guide for Beginners\nLearn X in Y minutes for Bash\nLinux Bash Shell Scripting Tutorial\n\nYou can also get information on Bash from within Bash with:\ninfo bash\nand:\nman bash\nThere are also countless resources online and don‚Äôt forget to Google anything you don‚Äôt know how to do: you will almost certainly find the answer on StackOverflow or some Stack Exchange site.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "bash/intro_special_parameters.html",
    "href": "bash/intro_special_parameters.html",
    "title": "Special parameters",
    "section": "",
    "text": "A number of special parameters, all starting with $, get expanded by Bash.\n\n\n$1, $2, $3, ‚Ä¶ are positional special characters,\n$@ is an array-like construct referring of all positional parameters,\n$# expands to the number of arguments,\n$$ pid of the current shell,\n$! expands to the PID of the most recent background command,\n$0 expands to the name of the current shell or script.\n\n\n\n\nExample:\n\nfunction arguments {\n    echo First argument: $1\n    echo Second argument: $2\n    echo Third argument: $3\n    echo Number of arguments: $#\n    echo All arguments: $@\n}\n\narguments one two three four five\n\nFirst argument: one\nSecond argument: two\nThird argument: three\nNumber of arguments: 5\nAll arguments: one two three four five\n\n\nAdditionally, !! is replaced by the previous command.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Special parameters"
    ]
  },
  {
    "objectID": "bash/intro_text.html#searching-inside-files-with-grep",
    "href": "bash/intro_text.html#searching-inside-files-with-grep",
    "title": "Searching & manipulating text",
    "section": "Searching inside files with grep",
    "text": "Searching inside files with grep\ncd ~/Desktop/data-shell/writing\nmore haiku.txt\nFirst let‚Äôs search for text in files:\ngrep not haiku.txt     # let's find all lines that contain the word 'not'\ngrep day haiku.txt     # now search for word 'day'\ngrep -w day haiku.txt     # search for a separate word 'day' (not 'today', etc.)\ngrep -w today haiku.txt   # search for 'today'\ngrep -w Today haiku.txt   # search for 'Today'\ngrep -i -w today haiku.txt       # both upper and lower case 'today'\ngrep -n -i -w today haiku.txt    # -n prints out numbers the matching lines\ngrep -n -i -w -v the haiku.txt   # -v searches for lines that do not contain 'the'\nman grep\nMore than two arguments to grep:\ngrep pattern file1 file2 file3   # all argument after the first one are assumed to be filenames\ngrep pattern *.txt   # the last argument will expand to the list of *.txt files\n\nThe Tao that is seen\nIs not the true Tao, until\nYou bring fresh toner.\nWith searching comes loss\nand the presence of absence:\n\"My Thesis\" not found.\nYesterday it worked.\nToday it is not working.\nSoftware is like that.\nFrom the above text, contained in the file haiku.txt, which command would result in the following output:\nand the presence of absence:\n\ngrep of haiku.txt\ngrep -E of haiku.txt\ngrep -w of haiku.txt \n\nHere is a video on this topic."
  },
  {
    "objectID": "bash/intro_text.html#text-manipulation",
    "href": "bash/intro_text.html#text-manipulation",
    "title": "Searching & manipulating text",
    "section": "Text manipulation",
    "text": "Text manipulation\n(This example was kindly provided by John Simpson.)\nIn this section we‚Äôll use two tools for text manipulation: sed and tr. Our goal is to calculate the frequency of all dictionary words in the novel ‚ÄúThe Invisible Man‚Äù by Herbert Wells (public domain). First, let‚Äôs apply our knowledge of grep to this text:\ncd ~/Desktop/data-shell\nls   # shows wellsInvisibleMan.txt\nwc wellsInvisibleMan.txt                          # number of lines, words, characters\ngrep invisible wellsInvisibleMan.txt              # see the invisible man\ngrep invisible wellsInvisibleMan.txt | wc -l      # returns 60; adding -w gives the same count\ngrep -i invisible wellsInvisibleMan.txt | wc -l   # returns 176 (includes: invisible Invisible INVISIBLE)\nLet‚Äôs sidetrack for a second and see how we can use the ‚Äústream editor‚Äù sed:\nsed 's/[iI]nvisible/supervisible/g' wellsInvisibleMan.txt &gt; visibleMan.txt   # make him visible\ncat wellsInvisibleMan.txt | sed 's/[iI]nvisible/supervisible/g' &gt; visibleMan.txt   # this also works (standard input)\ngrep supervisible visibleMan.txt   # see what happened to the now visible man\ngrep -i invisible visibleMan.txt   # see what was not converted\nman sed\nNow let‚Äôs remove punctuation from the original file using ‚Äútr‚Äù (translate) command:\ncat wellsInvisibleMan.txt | tr -d \"[:punct:]\" &gt; invisibleNoPunct.txt    # tr only takes standard input\ntail wellsInvisibleMan.txt\ntail invisibleNoPunct.txt\nNext convert all upper case to lower case:\ncat invisibleNoPunct.txt | tr '[:upper:]' '[:lower:]' &gt; invisibleClean.txt\ntail invisibleClean.txt\nNext replace spaces with new lines:\ncat invisibleClean.txt | sed 's/ /\\'$'\\n/g' &gt; invisibleList.txt   # \\'$'\\n is a shortcut for a new line\nmore invisibleList.txt\nNext remove empty lines:\nsed '/^$/d' invisibleList.txt  &gt; invisibleCompact.txt\nNext sort the list alphabetically, count each word‚Äôs occurrence, and remove duplicate words:\ncat invisibleCompact.txt | sort | uniq -c &gt; invisibleWords.txt\nmore invisibleWords.txt\nNext sort the list into most frequent words:\ncat invisibleWords.txt | sort -gr &gt; invisibleFrequencyList.txt   # use 'man sort'\nmore invisibleFrequencyList.txt\n\n\n\n\n\n\nYou can watch a video for this topic after the workshop.\nQuick reference:\nsed 's/pattern1/pattern2/' filename    # replace pattern1 with pattern2, one per line\nsed 's/pattern1/pattern2/g' filename   # same but multiple per line\nsed 's|pattern1|pattern2|g' filename   # same\n\ncat wellsInvisibleMan.txt | tr -d \"[:punct:]\" &gt; invisibleNoPunct.txt       # remove punctuation; tr only takes standard input\ncat invisibleNoPunct.txt | tr '[:upper:]' '[:lower:]' &gt; invisibleClean.txt # convert all upper case to lower case:\ncat invisibleClean.txt | sed 's/ /\\'$'\\n/g' &gt; invisibleList.txt            # replace spaces with new lines;\n                                                                           # \\'$'\\n is a shortcut for a new line\nsed '/^$/d' invisibleList.txt  &gt; invisibleCompact.txt   # remove empty lines\ncat invisibleCompact.txt | sort | uniq -c &gt; invisibleWords.txt   # sort the list alphabetically, count each word's occurrence\ncat invisibleWords.txt | sort -gr &gt; invisibleFrequencyList.txt   # sort the list into most frequent words\n\nWrite a script that takes an English-language file and print the list of its 100 most common words, along with the word count. Hint: use the workflow from the text manipulation video. Finally, convert this script into a bash function. (no need to type any answer)"
  },
  {
    "objectID": "bash/intro_text.html#awk-scripting-language",
    "href": "bash/intro_text.html#awk-scripting-language",
    "title": "Searching & manipulating text",
    "section": "AWK scripting language",
    "text": "AWK scripting language\nAWK is a scripting language that can be used inside Bash which allows for column-based text manipulation.\ncd .../data-shell/writing\ncat haiku.txt   # 11 lines\nYou can define inline awk scripts with braces surrounded by single quotation:\nawk '{print $1}' haiku.txt       # $1 is the first field (word) in each line =&gt; processing columns\nawk '{print $0}' haiku.txt       # $0 is the whole line\nawk '{print}' haiku.txt          # the whole line is the default action\nawk -Fa '{print $1}' haiku.txt   # can specify another separator with -F (\"a\" in this case)\nYou can use multiple commands inside your awk script:\necho Hello Tom &gt; hello.txt\necho Hello John &gt;&gt; hello.txt\nawk '{$2=\"Adam\"; print $0}' hello.txt   # we replaced the second word in each line with \"Adam\"\nMost common awk usage is to postprocess output of other commands:\n/bin/ps aux    # display all running processes as multi-column output\n/bin/ps aux | awk '{print $2 \" \" $11}'   # print only the process number and the command\nAwk also takes patterns in addition to scripts:\nawk '/Yesterday|Today/' haiku.txt   # print the lines that contain the words Yesterday or Today\nAnd then you act on these patterns: if the pattern evaluates to True, then run the script:\nawk '/Yesterday|Today/{print $3}' haiku.txt\nawk '/Yesterday|Today/' haiku.txt | awk '{print $3}'   # same as previous line\nAwk has a number of built-in variables; the most commonly used is NR:\nawk 'NR&gt;1' haiku.txt    # if NumberRecord &gt;1 then print it (default action), i.e. skip the first line\nawk 'NR&gt;1{print $0}' haiku.txt   # last command expanded\nawk 'NR&gt;1 && NR &lt; 5' haiku.txt   # print lines 2-4\n\nExercise: write a awk script to process cities.csv to print only town/city names and their population and store it in a separate file populations.csv. Try to do everything in a single-line command.\n\nQuick reference:\nls -l | awk 'NR&gt;3 {print $5 \"  \" $9}'   # print 5th and 9th columns starting with line 4\nawk 'NR&gt;1 && NR &lt; 5' haiku.txt          # print lines 2-4\nawk '/Yesterday|Today/' haiku.txt       # print lines that contain Yesterday or Today\n\nWrite a one-line command that finds 5 largest files in the current directory and prints only their names and file sizes in the human-readable format (indicating bytes, kB, MB, GB, ‚Ä¶) in the decreasing file-size order. Hint: use find, xargs, and awk. \n\nLet‚Äôs study together these commands:\nsource ~/projects/def-sponsor00/shared/fzf/.fzf.bash\nkill -9 `/bin/ps aux | fzf | awk '{print $2}'`\n\nHere is a video on this topic."
  },
  {
    "objectID": "bash/intro_variables.html",
    "href": "bash/intro_variables.html",
    "title": "Variables",
    "section": "",
    "text": "You can assign values to names. These names and the values they hold are called ‚Äúvariables‚Äù.\nVariables are a convenient way to reuse values.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Variables"
    ]
  },
  {
    "objectID": "bash/intro_variables.html#declaring-variables",
    "href": "bash/intro_variables.html#declaring-variables",
    "title": "Variables",
    "section": "Declaring variables",
    "text": "Declaring variables\nYou declare a variable (i.e.¬†a name that holds a value) with the = sign:\nvar=value\n\nMake sure not to put spaces around the equal sign.\n\n\nExample:\n\n\nvar=5\n\nYou can delete a variable with the unset command:\n\nunset var",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Variables"
    ]
  },
  {
    "objectID": "bash/intro_variables.html#expanding-variables",
    "href": "bash/intro_variables.html#expanding-variables",
    "title": "Variables",
    "section": "Expanding variables",
    "text": "Expanding variables\nTo expand a variable (to access its value), you need to prepend its name with $.\n\nThis is not what we want:\n\n\nvar=value\necho var\n\nvar\n\n\n\nThis however works:\n\n\nvar=value\necho $var\n\nvalue",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Variables"
    ]
  },
  {
    "objectID": "bash/intro_variables.html#quotes",
    "href": "bash/intro_variables.html#quotes",
    "title": "Variables",
    "section": "Quotes",
    "text": "Quotes\n\nWhen declaring\nQuotes are necessary for values containing special characters such as spaces.\n\nThis doesn‚Äôt work:\n\n\nvar=string with spaces\necho $var\n\nbash: line 1: with: command not found\n\n\n\nThis works:\n\n\nvar=\"string with spaces\"\necho $var\n\nstring with spaces\n\n\n\nThis also works:\n\n\nvar='string with spaces'\necho $var\n\nstring with spaces\n\n\nWhen declaring variables, single and double quotes are equivalent. Which one should you use then? Use the one that is most convenient.\n\nThis is not good:\n\n\nvar='that's a string with spaces'\necho $var\n\nbash: -c: line 1: unexpected EOF while looking for matching `''\n\n\n\nThis works well:\n\n\nvar=\"that's a string with spaces\"\necho $var\n\nthat's a string with spaces\n\n\n\nAlternatively, single quotes can be escaped, but it is a little crazy: the first ' ends the first string, then the apostrophe needs to be escaped (\\'), finally, the third ' starts the second string.\n\nvar='that'\\''s a string with spaces'\necho $var\n\nthat's a string with spaces\n\n\n\n\nConversely, this is not good:\n\n\nvar=\"he said: \"string with spaces\"\"\necho $var\n\nbash: line 1: with: command not found\n\n\n\nWhile this works:\n\n\nvar='he said: \"string with spaces\"'\necho $var\n\nhe said: \"string with spaces\"\n\n\n\nDouble quotes as well can be escaped (simply by prepending them with \\):\n\nvar=\"he said: \\\"string with spaces\\\"\"\necho $var\n\nhe said: \"string with spaces\"\n\n\n\n\n\nWhen expanding\nWhile not necessary in many situations, it is safer to expand variables in double quotes, in case the expansion leads to problematic special characters. In the example above, this was not problematic and using $var or \"$var\" both work.\nIn the following example however, it is problematic:\nvar=\"string with spaces\"\ntouch $var\nThis creates 3 files called string, with, and spaces. Probably not what you wanted‚Ä¶\nThe following creates a single file called string with spaces:\nvar=\"string with spaces\"\ntouch \"$var\"\n\nTo be safe, it is thus a good habit to quote expanded variables.\n\nIt is important to note however that single quotes don‚Äôt expand variables (only double quotes do).\nThe following would thus create a file called $var:\nvar=\"string with spaces\"\ntouch '$var'",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Variables"
    ]
  },
  {
    "objectID": "bash/intro_variables.html#exporting-variables",
    "href": "bash/intro_variables.html#exporting-variables",
    "title": "Variables",
    "section": "Exporting variables",
    "text": "Exporting variables\nUsing export ensures that all inherited processes of the current shell also have access to this variable:\n\nExample:\n\nvar=3\nzsh           # Launch Zsh (another shell)\necho $var\nThis returns nothing: var is not defined in the Zsh process.\nexport var=3\nzsh\necho $var\nThis returns 3: var got exported into the Zsh process.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Variables"
    ]
  },
  {
    "objectID": "bash/intro_variables.html#string-manipulation",
    "href": "bash/intro_variables.html#string-manipulation",
    "title": "Variables",
    "section": "String manipulation",
    "text": "String manipulation\n\nGetting a subset\n\nvar=\"hello\"\necho ${var:2}      # Print from character 2\necho ${var:2:1}    # Print 1 character from character 2\n\nllo\nl\n\n\n\nBash indexes from 0.\n\n\n\nSearch and replace\n\nvar=\"hello\"\necho ${var/l/L}    # Replace the first match of l by L\necho ${var//l/L}   # Replace all matches of l by L\n\nheLlo\nheLLo\n\n\n\n\nString concatenation\nIf you want to concatenate the expanded variable with another string, you need to use curly braces or quotes.\n\nThis does not return anything because there is no variable called varshine:\n\n\nvar=sun\necho $varshine\n\n\nThese two syntaxes do work:\n\n\nvar=sun\necho ${var}shine\necho \"$var\"shine\n\nsunshine\nsunshine",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Variables"
    ]
  },
  {
    "objectID": "bash/intro_variables.html#environment-variables",
    "href": "bash/intro_variables.html#environment-variables",
    "title": "Variables",
    "section": "Environment variables",
    "text": "Environment variables\nEnvironment variables help control the behaviour of processes on a machine. You can think of them as customizations of your system.\nMany are set automatically.\n\nExample:\n\necho $HOME\n/home/user09\nThere are many other environment variables (e.g.¬†PATH, PWD, PS1). To see the list, you can run printenv or env.\nIf you want to add new environment variables, you can add them to your ~/.bashrc file which is sourced each time you start a new shell.\nHere is a video of a previous version of this workshop.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Variables"
    ]
  },
  {
    "objectID": "bash/intro_zsh.html",
    "href": "bash/intro_zsh.html",
    "title": "Z shell",
    "section": "",
    "text": "Z shell (or Zsh) is a more modern Unix shell, very similar to Bash but with more functionality and ease of use.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Z shell"
    ]
  },
  {
    "objectID": "bash/intro_zsh.html#installation",
    "href": "bash/intro_zsh.html#installation",
    "title": "Z shell",
    "section": "Installation",
    "text": "Installation\nzsh is installed on the Alliance clusters. It is now also the default shell on macOS. For Windows users, you will probably have to use WSL. Here is a suggested setup (Unix shells such as Bash and Zsh are built for Unix systems and Windows is not a Unix system).",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Z shell"
    ]
  },
  {
    "objectID": "bash/intro_zsh.html#first-launch",
    "href": "bash/intro_zsh.html#first-launch",
    "title": "Z shell",
    "section": "First launch",
    "text": "First launch\nWhen you launch zsh for the first time, a little program runs to help you create the Zsh config file .zshrc and set some options.\nYou will probably want to add to this file the aliases, functions, and sourcing that you normally have in your .bashrc file.\nOne thing that you do not have to copy over are the definitions of environment variables that you have defined in .bashrc with export because export ensures that the variables get exported into any shell launched from Bash (and that is what we are doing when we launch Zsh). If you have defined environment variables in .bashrc without exporting them and you want to use them in Zsh as well, you either need to export them in your .bashrc file or copy the variable definitions over to your .zshrc file.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Z shell"
    ]
  },
  {
    "objectID": "bash/intro_zsh.html#useful-plugins",
    "href": "bash/intro_zsh.html#useful-plugins",
    "title": "Z shell",
    "section": "Useful plugins",
    "text": "Useful plugins\nOut of the box, Zsh is nicer than Bash, but in addition, there are many additional niceties that have been built for it.\noh my zsh is a popular project and it contains many useful configurations and add-ons, but it also contain a lot of unnecessary things and is quite bloated.\nI personally prefer to keep things simpler and install 3 great plugins:\n\nsyntax highlighting,\nautosuggestions, and\nhistory substring search.\n\nThe syntax highlighting plug-in is installed on the Alliance clusters. To install the other two, you only have to clone the repos or scp the scripts themselves.\nClone the repos (you only need to do this once):\n# create a directory to store the scripts\nmkdir ~/.zsh_plugins\n\n# autosuggestions\ngit clone https://github.com/zsh-users/zsh-autosuggestions.git ~/.zsh_plugins/zsh-autosuggestions\n\n# history substring search\ngit clone https://github.com/zsh-users/zsh-history-substring-search.git ~/.zsh_plugins/zsh-history-substring-search\nThe you have to source the scripts (the one already installed on the Alliance clusters and the ones you just cloned under your own user).\nYou need to do this at each session, so you should add it to your .zshrc file:\nsource $EPREFIX/usr/share/zsh/site-functions/zsh-syntax-highlighting.zsh\nsource ~/.zsh_plugins/zsh-history-substring-search/zsh-history-substring-search.zsh\nsource ~/.zsh_plugins/zsh-autosuggestions/zsh-autosuggestions.zsh\nFor the scripts to become active in your current Zsh session, you also need to run these lines in your terminal or exit Zsh (with Ctl + d) and launch it back in (this sources the .zshrc file again and will thus source the scripts).\nNow paste the function we saw previously in zsh:\nproc_kill() {\n    local pid\n    pid=$(ps -ef |\n          sed 1d |\n          fzf --cycle --reverse -i -e -m --bind \"ctrl-o:toggle-all\" \\\n          --header \"Tab: toggle, C-o: toggle-all\" |\n          awk '{print $2}')\n    echo $pid | xargs kill -${1:-15}\n}\nand you will see the wonders of syntax highlighting in your shell inputs.\nTo use the history substring search, start typing some command then press Alt + p or Alt + n to cycle through all entries in your history that start with what you already typed.\nFinally, the autosuggestion will suggest commands based on your history and/or classic suggestions. You can accept the whole command with Ctl + e or accept a single word with Alt + f.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Z shell"
    ]
  },
  {
    "objectID": "bash/molecules/intro_find.html",
    "href": "bash/molecules/intro_find.html",
    "title": "Finding files",
    "section": "",
    "text": "For this section, we will play with files created by The Carpentries.\nYou can download them into a zip file called data.zip with:\ncurl --output data.zip https://mint.westdri.ca/bash/data.zip\nYou can then unzip that file with:\nunzip data.zip\nYou should now have a data directory.\ncd into it:\ncd data"
  },
  {
    "objectID": "bash/molecules/intro_find.html#data-for-this-section-same-data-as-previous-section",
    "href": "bash/molecules/intro_find.html#data-for-this-section-same-data-as-previous-section",
    "title": "Finding files",
    "section": "",
    "text": "For this section, we will play with files created by The Carpentries.\nYou can download them into a zip file called data.zip with:\ncurl --output data.zip https://mint.westdri.ca/bash/data.zip\nYou can then unzip that file with:\nunzip data.zip\nYou should now have a data directory.\ncd into it:\ncd data"
  },
  {
    "objectID": "bash/molecules/intro_find.html#command-find",
    "href": "bash/molecules/intro_find.html#command-find",
    "title": "Finding files",
    "section": "Command find",
    "text": "Command find\nSearch for files inside the current working directory:\nfind . -type f\n./methane.pdb\n./pentane.pdb\n./sorted.txt\n./propane.pdb\n./lengths.txt\n./cubane.pdb\n./ethane.pdb\n./octane.pdb\nfind . -type d will instead search for directories inside the current working directory.\nHere are other examples:\nfind . -maxdepth 1 -type f     # depth 1 is the current directory\nfind . -mindepth 2 -type f     # current directory and one level down\nfind . -name haiku.txt      # finds specific file\nls data       # shows one.txt two.txt\nfind . -name *.txt      # still finds one file -- why? answer: expands *.txt to haiku.txt\nfind . -name '*.txt'    # finds all three files -- good!\nLet‚Äôs wrap the last command into $()‚Äîcalled command substitution‚Äîas if it were a variable:\necho $(find . -name '*.txt')   # will print ./data/one.txt ./data/two.txt ./haiku.txt\nls -l $(find . -name '*.txt')   # will expand to ls -l ./data/one.txt ./data/two.txt ./haiku.txt\nwc -l $(find . -name '*.txt')   # will expand to wc -l ./data/one.txt ./data/two.txt ./haiku.txt\ngrep elegant $(find . -name '*.txt')   # will look for 'elegant' inside all *.txt files\n\n\nYour turn:\n\ngrep‚Äôs -v flag inverts pattern matching, so that only lines that do not match the pattern are printed.\nGiven that, which of the following commands will find all files in /data whose names end in ose.dat (e.g.¬†sucrose.dat or maltose.dat), but do not contain the word temp?\n\nfind /data -name '*.dat' | grep ose | grep -v temp\nfind /data -name ose.dat | grep -v temp\ngrep -v temp $(find /data -name '*ose.dat')\nNone of the above\n\n\nHere is a video of a previous version of this workshop."
  },
  {
    "objectID": "bash/molecules/intro_find.html#running-a-command-on-the-results-of-find",
    "href": "bash/molecules/intro_find.html#running-a-command-on-the-results-of-find",
    "title": "Finding files",
    "section": "Running a command on the results of find",
    "text": "Running a command on the results of find\nLet‚Äôs say that you want to run a command on each of the files in the output of find. You can always do something using command substitution like this:\nfor f in $(find . -name \"*.txt\")\ndo\n    command on $f\ndone\nAlternatively, you can make it a one-liner:\nfind . -name \"*.txt\" -exec command {} \\;\nAnother‚Äîperhaps more elegant‚Äîone-line alternative is to use xargs. In its simplest usage, xargs command lets you construct a list of arguments:\nfind . -name \"*.txt\"                   # returns multiple lines\nfind . -name \"*.txt\" | xargs           # use those lines to construct a list\nfind . -name \"*.txt\" | xargs command   # pass this list as arguments to `command`\ncommand $(find . -name \"*.txt\")        # command substitution, achieving the same result (this is riskier!)\ncommand `(find . -name \"*.txt\")`       # alternative syntax for command substitution\nIn these examples, xargs achieves the same result as command substitution, but it is safer in terms of memory usage and the length of lists you can pass.\nWhen would you need to use this? A good example is with the command grep. grep takes a search stream (and not a list of files) as its standard input:\ncat filename | grep pattern\nTo pass a list of files to grep, you can use xargs that takes that list from its standard input and converts it into a list of arguments that is then passed to grep:\nfind . -name \"*.txt\" | xargs grep pattern   # search for `pattern` inside all those files (`grep` does not take a list of files as standard input)\n\n\nHere is a video of a previous version of this workshop."
  },
  {
    "objectID": "bash/molecules/intro_script.html",
    "href": "bash/molecules/intro_script.html",
    "title": "Writing scripts",
    "section": "",
    "text": "There are series of commands that you need to run regularly. Instead of having to type them each time, you can write them in a text file (called a script) with a .sh extension and execute that file whenever you want to run that set of commands. This is a great way to automate work.\nThis section covers scripts syntax and execution.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Writing scripts"
    ]
  },
  {
    "objectID": "bash/molecules/intro_script.html#writing-and-executing-scripts",
    "href": "bash/molecules/intro_script.html#writing-and-executing-scripts",
    "title": "Writing scripts",
    "section": "Writing and executing scripts",
    "text": "Writing and executing scripts\n\nScripts as arguments to bash\nA shell script is simply a text file. You can create it with a text editor such as nano which is installed on most systems.\nLet‚Äôs try to create one that we will call test.sh:\nnano test.sh\nIn the file, write the command: echo This is my first script.\nThis is the content of our test.sh file:\n\n\ntest.sh\n\necho This is my first script\n\nNow, how do we run this?\nWe simply pass it as an argument to the bash command:\nbash test.sh\nThis is my first script\nAnd it worked!\n\n\nShebang\nThere is another way to write and execute scripts: we can use a shebang.\nA shebang consists of the characters #! followed by the path of an executable. Here, the executable we want is bash and its path is /bin/bash.\nSo our script becomes:\n\n\ntest.sh\n\n#!/bin/bash\n\necho This is my first script.\n\nNow, the cool thing about this is that we don‚Äôt need to pass the script as an argument of the bash command anymore since the information that this should be executed by Bash is already written in the shebang. Instead, we can execute it with ./test.sh.\nBut there is a little twist:\n./test.sh\nbash: ./test.sh: Permission denied\nWe first need to make the file executable by changing its permissions.\n\n\nUnix permissions\nUnix systems such as Linux use POSIX permissions.\nTo add an executable permission to a file, you need to run:\nchmod u+x test.sh\nNow that our script is executable, we can run:\n./test.sh\nThis is my first script\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere and here are two videos of a previous version of this workshop.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Writing scripts"
    ]
  },
  {
    "objectID": "bash/molecules/intro_script.html#comments",
    "href": "bash/molecules/intro_script.html#comments",
    "title": "Writing scripts",
    "section": "Comments",
    "text": "Comments\nAnything to the right of the symbol # is ignored by the interpreter and is for human consumption only.\n# You can write full-line comments\n\npwd       # You can also write comments after a command\nComments are used to document scripts. DO USE THEM: future you will thank you.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>",
      "Writing scripts"
    ]
  },
  {
    "objectID": "bash/top_intro.html",
    "href": "bash/top_intro.html",
    "title": "Getting started with Unix shells",
    "section": "",
    "text": "Unix shells such as Bash or Zsh are command line interpreters for Unix-like operating systems: the user enters commands as text‚Äîinteractively in a terminal or in scripts‚Äîand the shell passes them to the operating system.\nGiving instructions to the machine via text instead of using a graphical user interface (GUI) is very powerful:\n\nAutomating tasks performed via GUI interfaces is something that AI agents are now‚Äîtentatively‚Äîbecoming able to do, but for repetitive tasks that can be completed via the command line, automation has been easy to do for decades.\nCommands can be written to scripts which allows for the creation of reproducible workflows.\nFinally, Unix shells allow to securely access remote machines and supercomputers.\n\nThis course is a hands-on introduction to Bash and Zsh. It will teach you to log in to the Alliance supercomputers and covers common commands, loops, redirections, functions, wildcards, aliases, and scripting.\n\n Start course ‚û§",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Getting started</em></b>"
    ]
  },
  {
    "objectID": "bash/top_ws.html",
    "href": "bash/top_ws.html",
    "title": "Bash workshops",
    "section": "",
    "text": "Scripting for beginners",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Workshops</em></b>"
    ]
  },
  {
    "objectID": "bash/wb_tools2.html",
    "href": "bash/wb_tools2.html",
    "title": "A few more of our favourite tools",
    "section": "",
    "text": "In a previous webinar, we presented three of our favourite command line tools. Today, we will introduce other tools we find really useful in our daily workflow:\n\nlazygit: a wonderful terminal UI for Git,\nbat: a great syntax highlighter,\nripgrep: a fast alternative to grep,\nfd: a /really/ fast alternative to find,\npass: a command line password manager.\n\nAlong the way, I will use a few other neat command line tools such as hyperfine‚Äîfor sophisticated benchmarking‚Äîand diff-so-fancy‚Äîwhich makes your diffs a lot more readable.\nFor the Emacs users among you, we will finish the workshop with two Emacs utilities:\n\nTRAMP: a remote file access system,\nHelm: a ‚Äúframework for incremental completions and narrowing selections‚Äù.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Webinars</em></b>",
      "More fun tools for the CLI"
    ]
  },
  {
    "objectID": "bash/wb_tools3_content.html",
    "href": "bash/wb_tools3_content.html",
    "title": "Modern shell utilities",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "bash/wb_tools3_content.html#how-to-choose-tools",
    "href": "bash/wb_tools3_content.html#how-to-choose-tools",
    "title": "Modern shell utilities",
    "section": "How to choose tools?",
    "text": "How to choose tools?\n\nPopularity (GitHub stars)\nIs it maintained? (date of last commit)\nNumber of maintainers\nHow polished is the documentation?\nHow fast is it? (what language is it written in? Shell/Python will be slower, compiled languages (Rust, C, Go) will be faster.)",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "bash/wb_tools3_content.html#ls-in-colours-eza",
    "href": "bash/wb_tools3_content.html#ls-in-colours-eza",
    "title": "Modern shell utilities",
    "section": "ls in colours: eza",
    "text": "ls in colours: eza\n\nWhat is eza?\neza is a replacement for ls.\n\nAdds colours.\nBetter default options.\nAdd tree feature.\n\n\n\nInstallation\n\nOn your machine\nInstructions here.\n\n\nOn the Alliance clusters\neza is not installed on the Alliance clusters, so you have to install it locally under your own user. This is easy to do because it is written in Rust and can be installed with the Rust package manager.\nLoad a Rust module, install eza, and make sure ~/.cargo/bin is in your path:\nmodule load rust/1.76.0\ncargo install eza\n\nYou only need to do this once. Once installed, eza will be accessible on subsequent sessions.\n\n\n\n\nUsage\neza\n‚ûî Different colours for directories, symlinks, and different types of files and better defaults (compare ls -al with eza -al).\neza by default shows the output in a human readable format and without the group.\nThe flags are similar to those of ls with the additional -T, equivalent to running the tree utility:\neza -T python/\n\n\nAlias\nYou can alias it to ls by adding to your .bashrc or .zshrc file:\nalias ls=eza\nIf you ever want to use the true ls utility, you can do so with \\ls.\n\n\nAlternative\nIf you want a simpler and more lightweight way to add colours to your ls outputs, you can look at LS_COLORS (I did this for years until I found eza).\nTo install it locally in the Alliance clusters, you download and uncompress a script, and copy it to a proper location:\nmkdir ./LS_COLORS &&\n    curl -L https://api.github.com/repos/trapd00r/LS_COLORS/tarball/master |\n        tar xzf - --directory=./LS_COLORS --strip=1 &&\n    mkdir -p ~/.local/share &&\n    cp ~/LS_COLORS/lscolors.sh ~/.local/share &&\n    rm -r ~/LS_COLORS\nThen you add to your .bashrc/.zshrc file the sourcing of the script and an alias to ls:\nsource ~/.local/share/lscolors.sh\nalias ls='ls --color'",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "bash/wb_tools3_content.html#a-cat-with-wings-bat",
    "href": "bash/wb_tools3_content.html#a-cat-with-wings-bat",
    "title": "Modern shell utilities",
    "section": "A cat with wings: bat",
    "text": "A cat with wings: bat\n\nWhat is bat?\nbat is a replacement for cat.\n\nAdds syntax highlighting for most programming languages.\nAdds line numbers.\nAdds pager-like search.\nAdds pager-like navigation.\n\n\n\nInstallation\n\nOn your machine\nInstructions here.\n\n\nOn the Alliance clusters\nbat is already installed on the Alliance clusters.\n\n\n\nUsage\nUse bat as you would use cat:\nbat /home/marie/parvus/prog/progpy/pydoc/basics.py\nand you are in your default pager.\nAmong other options, you can disable the frame with -n and also remove the line numbers with -p.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "bash/wb_tools3_content.html#faster-find-fd",
    "href": "bash/wb_tools3_content.html#faster-find-fd",
    "title": "Modern shell utilities",
    "section": "Faster find: fd",
    "text": "Faster find: fd\n\nWhat is fd?\nfd is a replacement for find.\n\nWritten in Rust, automatic parallelism ‚ûî with vastly improved performance.\nMore friendly syntax.\nBy default excludes binaries as well as hidden files and directories.\nBy default excludes patterns from .gitignore or other .ignore files.\n\n\n\nInstallation\n\nOn your machine\nInstructions here.\n\n\nOn the Alliance clusters\nfd is already installed on the Alliance clusters.\n\n\n\nBasic usage\nSearch file names for a pattern recursively in current directory:\nfd jx\n\nfd uses regexp by default, so you can use pattern symbols:\nfd jx.*txt\n\nSearch file names recursively in another directory:\nfd top bash/\n\n\nPrint all files in some directory\nCurrent directory:\nfd\nAnother directory:\nfd . bash/\n\n\nOptions\nSearch for files with a particular file extension:\nfd -e txt\nUse a globbing pattern instead of regexp:\nfd -g wb* bash/\nExecute command for each result of fd in parallel:\nfd top bash/ -x rg layout\nExecute command once with all results of fd as arguments:\nfd top bash/ -X rg layout\n\n\nExcluded files and directories\nBy default, fd excludes hidden files/directories and patterns in .gitignore (you can disable this with -H and -I respectively).\nThis makes fd combined with tree sometimes more useful than tree alone.\nCompare tree bash/ with:\nfd . bash/ | tree --fromfile\n\nYou can make this a function:\nft () { fd $@ | tree --fromfile }\n\nExclude additional directories or patterns:\nfd -E *.txt -E img/ . bash/\n\n\nMy personal alias\nI prefer to disable the default settings and exclude patterns based on a file I created:\nalias fd='fd -u --ignore-file /home/marie/.fdignore'",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "bash/wb_tools3_content.html#rip-grep-ripgrep",
    "href": "bash/wb_tools3_content.html#rip-grep-ripgrep",
    "title": "Modern shell utilities",
    "section": "RIP grep: ripgrep",
    "text": "RIP grep: ripgrep\n\nWhat is ripgrep?\nripgrep provides the rg utility‚Äîa replacement for grep.\n\nWritten in Rust, automatic parallelism ‚ûî with vastly improved performance.\nBy default excludes patterns from .gitignore or other .ignore files.\nBy default excludes binaries as well as hidden files and directories.\nBy default doesn‚Äôt follow symlinks\n\n\n\nInstallation\n\nOn your machine\nInstructions here.\n\n\nOn the Alliance clusters\nrg is already installed on the Alliance clusters.\n\n\n\nUsage\nSearch lines in a file matching a pattern:\nrg colour /home/marie/parvus/prog/mint/bash/wb_tools3_slides.qmd\nSearch lines matching pattern in all files in current directory (recursively):\nrg colour\nrg and fd follow the same principles:\n\nUse regexp by default.\nUse globbing pattern instead with -g.\nSearch recursively by default.\nSame excluded files.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "bash/wb_tools3_content.html#smart-cd-zoxide",
    "href": "bash/wb_tools3_content.html#smart-cd-zoxide",
    "title": "Modern shell utilities",
    "section": "Smart cd: zoxide",
    "text": "Smart cd: zoxide\n\nWhat is zoxide?\nzoxide allows to easily jump to any directory.\n\n\nInstallation\n\nOn your machine\nInstructions here.\n\nfzf (see below) adds cool functionality to it, so you might want to install it as well.\n\n\n\nOn the Alliance clusters\nzoxide is not installed on the Alliance clusters, but local installation is easy.\n\nInstall the binary in ~/.local/bin with:\n\ncurl -sSfL https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh | sh\n\nAdd ~/.local/bin to your PATH by adding to your .bashrc:\n\nexport PATH=$PATH:~/.local/bin\n\nAdd to your .bashrc file (for Zsh, replace bash with zsh in .zshrc):\n\neval \"$(zoxide init bash)\"\n\n\n\nChoose a different command name\nUse this instead to use the command of your choice (e.g.¬†j and ji) instead of the default z and zi:\neval \"$(zoxide init --cmd j bash)\"\n\n\nUsage\nType z (or whatever command you chose) instead of cd.\nYou can simplify the path to just a few characters.\nIf there are multiple locations matching your entry, the algorithm will chose the highest ranking one based on your visit frequency and how recently you visited a path.\nThis means that you can visit your usual places with a few key strokes. For less frequent places, add more info.\nFinally, if you want to choose amongst all possible options in a completion framework, use zi instead and zoxide will open fzf.\n\n\nAlternative\nA tool that served me well until someone pointed zoxide to me is autojump.\n\nInstallation\nInstructions here for your machine.\nautojump is installed on the Alliance clusters, but you need add to your .bashrc or .zshrc:\n[[ -s $EPREFIX/etc/profile.d/autojump.sh ]] && source $EPREFIX/etc/profile.d/autojump.sh\n\n\nUsage\nSimilar to zoxide but you first need to visit directories so that they get entered in a database.\nj is a wrapper for autojump, jc jumps to subdirectories of current directory.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "bash/wb_tools3_content.html#fuzzy-finding-with-fzf",
    "href": "bash/wb_tools3_content.html#fuzzy-finding-with-fzf",
    "title": "Modern shell utilities",
    "section": "Fuzzy finding with fzf",
    "text": "Fuzzy finding with fzf\n\nWhat is fzf?\nfzf allows to find elements of any list through incremental completion and fuzzy matching. It can be paired with any number of commands.\n\n\nInstallation\n\nOn your machine\nInstructions here.\n\n\nOn the Alliance clusters\nfzf is already installed on the Alliance clusters.\nTo get fzf kbds and fuzzy completion in your shell, add to your .bashrc:\neval \"$(fzf --bash)\"\nand/or your .zshrc:\nsource &lt;(fzf --zsh)\n\n\n\nDirect usage\nIf you run fzf directly, it will search the current directory recursively, do a narrowing selection, and print the result:\nfzf\nYou can make use of fd to remove unnecessary entries:\nexport FZF_DEFAULT_COMMAND='fd -u --ignore-file /home/marie/.fdignore'\n\n\nfzf kbds\nThere are 3 default kbds:\n\nCtl+t ‚ûî paste selected file/dir into the command.\nCtl+r ‚ûî paste selected command from history into the command.\nAlt+c ‚ûî cd into selected dir.\n\n\n\nPipe to fzf\nYou can also pipe the output of any command that returns a list of elements into fzf.\nLook for a file/directory:\nls | fzf\nMany flags to select order of entries, type of completion, preview, case-sensitivity, and more.\nLook for a running process:\nps -ef | fzf --cycle -i -e +s --tac --reverse\nOf course, you can create aliases and functions using fzf.\nYou can put the previous command into an alias:\nalias proc='ps -ef | fzf --cycle -i -e +s --tac --reverse'\nOr write a function to kill a running process:\nproc_kill () {\n    local pid\n    pid=$(ps -ef |\n              sed 1d |\n              fzf --cycle --reverse -i -e -m --bind \"ctrl-o:toggle-all\" \\\n                  --header \"Tab: toggle, C-o: toggle-all\" |\n              awk '{print $2}')\n    echo $pid | xargs kill -${1:-15}\n}\nSearch your command history:\nhis () {\n    fc -ln 1 |\n        rg -v '^q$|^x$|^vs$|^ek .*$|^zoom$|^c$|^cca$|^rs ...$|^hobu$|^cd$|^kzo$|^ih.?$|^zre$|^j m$|^y$|^g$|^-$|^auradd$' |\n        fzf --cycle -i -e +s --tac --reverse |\n        sed 's/ *[0-9]* *//'\n}\nSearch your command history and run the selection:\nhis_run () {\n    $(fc -ln 1 |\n          rg -v '^q$|^x$|^vs$|^ek .*$|^zoom$|^c$|^cca$|^rs ...$|^hobu$|^cd$|^kzo$|^ih.?$|^zre$|^j m$|^y$|^g$|^-$|^auradd$' |\n          fzf --cycle -i -e +s --tac --reverse |\n          sed 's/ *[0-9]* *//')\n}\nAn example with preview to open the selection with emacsclient:\nie () {\n    emacsclient -c $(\n        fzf --cycle -i -e --reverse \\\n            --preview=\"source-highlight --failsafe -f esc256 -i {}\"\n                )\n}",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "bash/wb_tools3_content.html#file-system-tuis",
    "href": "bash/wb_tools3_content.html#file-system-tuis",
    "title": "Modern shell utilities",
    "section": "File system TUIs",
    "text": "File system TUIs\n\nWhat is a TUI?\nTerminal user interfaces (TUIs) are the predecessors to graphical user interfaces (GUIs) which are entirely text based and run in terminals.\nThey have remained very popular among command line aficionados because they are fast, efficient, powerful, and keyboard-driven, while being friendly and visual.\nFantastic modern ones keep being built for tasks as diverse as interfaces to Git, music players, games, emails, dashboards, and, for our purpose here, file system management.\n\n\nOlder popular file system TUIs\nThere are many file system TUIs and all of them are actually really good. The two most notable ones used to be:\n\nranger\n\nExtremely sophisticated, easy to customize, tons of features.\n\nBuilt in Python, it can be slow for operations in directories with thousands of files.\n\n\nnnn\n\nMinimalist and very fast (written in C).\n\nNot easy to customize (many customizations require compiling from source). Most functionalities rely on plugins that need to be installed. Not easy to get started with.\n\n\n\nThe new kid: yazi\nyazi is a brand new fs TUI that has quickly become the most popular.\nIt is extremely modern, very fast (written in Rust), very well documented, intuitive, easy to customize, and integrates with modern utilities such as fd, rg, zoxide, and fzf out of the box.\nOnly at version 0.4, it is not fully mature yet, but it has already more stars on GitHub than ranger and nnn because it combines ease of customization and sophistication with speed.\n\n\nAlternatives\nIn decreasing number of stars on GitHub:\n\nbroot\nsuperfile\nlf\nxplr\nfff (now archived)\nvifm\nmc",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "bash/wb_tools3_content.html#z-shell-plugins",
    "href": "bash/wb_tools3_content.html#z-shell-plugins",
    "title": "Modern shell utilities",
    "section": "Z shell plugins",
    "text": "Z shell plugins\n\nMy 3 favourite plugins\nThere are many plugins for Z shell and the (very bloated) Oh My Zsh, but I am sticking to 3 great plugins inspired or directly coming from the Fish shell:\n\nSyntax highlighting\nAutosuggestions\nHistory substring search\n\n\n\nInstallation\nAll plugins can be installed (info in their README) or simply Git cloned. zsh-syntax-highlighting is already installed on the Alliance clusters, so you only need to clone the other two:\n# create a directory to store the scripts\nmkdir ~/.zsh_plugins\n# autosuggestions\ngit clone https://github.com/zsh-users/zsh-autosuggestions.git ~/.zsh_plugins/zsh-autosuggestions\n# history substring search\ngit clone https://github.com/zsh-users/zsh-history-substring-search.git ~/.zsh_plugins/zsh-history-substring-search\nThen you need to source them (including zsh-syntax-highlighting), so add to your .zshrc file:\nsource $EPREFIX/usr/share/zsh/site-functions/zsh-syntax-highlighting.zsh\nsource ~/.zsh_plugins/zsh-history-substring-search/zsh-history-substring-search.zsh\nsource ~/.zsh_plugins/zsh-autosuggestions/zsh-autosuggestions.zsh\n\n\nUsage\nYou now have syntax highlighting in your shell inputs.\nTo use the history substring search, start typing some command then press Alt+p or Alt+n. It will cycle through all entries in your history that start that way\nFinally, the autosuggestion will suggest commands based on your history and/or classic suggestions. Accept the whole command with Ctl+e or a single word with Alt+f.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "bash/ws_scripting.html",
    "href": "bash/ws_scripting.html",
    "title": "Automation & scripting in bash for beginners",
    "section": "",
    "text": "This workshop will demystify the command line and get you started using Bash and Bash scripting.\nWarning: you might find that working in the command line is actually really fun and addictive!",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Workshops</em></b>",
      "Scripting for beginners"
    ]
  },
  {
    "objectID": "bash/ws_scripting.html#background",
    "href": "bash/ws_scripting.html#background",
    "title": "Automation & scripting in bash for beginners",
    "section": "Background",
    "text": "Background\n\nWhat are Unix shells?\nA Unix shell is a command line interpreter: the user enters commands as text, either interactively in the command line or in a script, and the shell passes them to the operating system.\n\nBash\nBash (Bourne Again SHell), released in 1989, is part of the GNU Project and is the default Unix shell on many systems (macOS recently changed its default to zsh).\n\n\nOther shells\nPrior to Bash, the default was the Bourne shell (sh).\nA new and popular shell (backward compatible with Bash) is zsh. It extends Bash‚Äôs capabilities.\nAnother shell in the same family is the KornShell (ksh).\nAll these shells are quite similar. The C shell (csh) however was modeled on the C programming language.\nBash is the most common shell and the one which makes the most sense to learn as a first Unix shell.\n\n\n\nWhy use a shell?\nWhile automating GUI operations is really difficult, it is easy to rerun a script (a file with a number of commands). Unix shells thus allow the creation of reproducible workflows and the automation of repetitive tasks.\nThey are powerful to launch tools, modify files, search text, or combine commands.\nThey also allow to work on remote machines and HPC systems.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Workshops</em></b>",
      "Scripting for beginners"
    ]
  },
  {
    "objectID": "bash/ws_scripting.html#how-we-will-use-bash-today",
    "href": "bash/ws_scripting.html#how-we-will-use-bash-today",
    "title": "Automation & scripting in bash for beginners",
    "section": "How we will use Bash today",
    "text": "How we will use Bash today\nBash is a Unix shell. You thus need a Unix or Unix-like operating system.\nWe will connect to a remote HPC system via SSH (secure shell). HPC systems always run Linux.\nThose on Linux or macOS can alternatively use Bash directly on their machine. On macOS, the default is now zsh (you can see that by typing echo $SHELL in Terminal), but zsh is fully compatible with Bash commands, so it is totally fine to use it instead. If you really want to use Bash, simply launch it by typing in Terminal: bash.\n\nRemote SSH connection\n\nUsernames and password\nWe will give you a link to an etherpad during the workshop. Add your name next to a free username to claim it.\nWe will also give you the password for our training cluster. When prompted, enter it.\n\nNote that you will not see any character as you type the password: this is called blind typing and is a Linux safety feature. Type slowly and make sure not to make typos. It can be unsettling at first not to get any feed-back while typing.\n\n\n\nLinux and macOS users\nLinux users: open the terminal emulator of your choice.\nmacOS users: open ‚ÄúTerminal‚Äù.\nThen type:\nssh userxx@bashworkshop.c3.ca  # Replace userxx by your username (e.g. user09)\n\n\nWindows users\nWe suggest using the free version of MobaXterm.\nMobaXterm comes with a terminal emulator and a GUI interface for SSH sessions.\nOpen MobaXterm, click on Session, then SSH, and fill in the Remote host name and your username. Here is a live demo.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Workshops</em></b>",
      "Scripting for beginners"
    ]
  },
  {
    "objectID": "bash/ws_scripting.html#bash-the-basics",
    "href": "bash/ws_scripting.html#bash-the-basics",
    "title": "Automation & scripting in bash for beginners",
    "section": "Bash: the basics",
    "text": "Bash: the basics\n\nThe prompt\nIn command-line interfaces, a command prompt is a sequence of characters indicating that the interpreter is ready to accept input. It can also provide some information (e.g.¬†time, error types, username and hostname, etc.)\nThe Bash prompt is customizable. By default, it often gives the username and the hostname, and it typically ends with $.\n\n\nHelp on commands\nMan pages:\nman &lt;command&gt;\n\nMan pages open in a pager (usually less).\nNavigate up/down with the space bar and the b key.\nQuit the pager with the q key.\n\nHelp pages:\n&lt;command&gt; --help\nInspect commands:\ncommand -V &lt;command&gt;\n\n\nExamples of commands\n\nPrint working directory: pwd\nChange directory: cd\nPrint: echo\nPrint content of a file: cat\nList: ls\nCopy: cp\nMove or rename: mv\nCreate a new directory: mkdir\nCreate a new file: touch\n\n\n\nKeybindings\nClear the terminal (command clear) with C-l (this means: press the Ctrl and L keys at the same time).\nNavigate command history with C-p and C-n (or up and down arrows).\nYou can auto-complete commands by pressing the tab key.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Workshops</em></b>",
      "Scripting for beginners"
    ]
  },
  {
    "objectID": "bash/ws_scripting.html#bash-scripting-the-basics",
    "href": "bash/ws_scripting.html#bash-scripting-the-basics",
    "title": "Automation & scripting in bash for beginners",
    "section": "Bash scripting: the basics",
    "text": "Bash scripting: the basics\nInstead of typing commands one at a time directly in a terminal, you can write them down, one per line, in a text file called a script.\nThey will be run in the order in which they are written when you execute the script.\nThis is a great way to automate tasks: to rerun this sequence of commands, you simply have to rerun the script.\n\nFile name\nShell scripts, including Bash scripts, are usually given the extension sh (e.g.¬†my_script.sh).\nYou can store scripts anywhere, but a common practice is to store them in a ~/bin directory.\n\n\nSyntax\n\nShebang\nScripts can be written for any interpreter (e.g.¬†Bash, Python, R, etc.) The way to tell the system which one to use is to use a shebang (#!) followed by the path of the interpreter on the first line of the script.\nTo use Bash, start your scripts with:\n#!/bin/bash\nYou may also encounter this notation:\n#!/usr/bin/env bash\nIf you are curious, you can read the answers to this Stack Overflow question for the differences between the two.\n\n\nComments\nAnything to the left of # is ignored by the interpreter and is for human consumption only.\n# You can write full-line comments\n\npwd       # You can also write comments after commands\n\n\n\nExecuting scripts\nThere are two ways to execute a script:\nbash my_script.sh\n./my_script.sh  # The dot represents the current directory\nIn the latter case, you need to make sure that your script is executable by first running:\nchmod u+x my_script.sh  # This makes the script executable by the user (i.e. you)\n\n\nOur first script\nOpen a text editor (e.g.¬†nano) and type:\n#!/bin/bash\n\necho \"This is our first script.\"\nSave and close the file.\n\n\nYour turn:\n\nNow run the script with one, then the other method.\nWhat does this script do?",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Workshops</em></b>",
      "Scripting for beginners"
    ]
  },
  {
    "objectID": "bash/ws_scripting.html#variables",
    "href": "bash/ws_scripting.html#variables",
    "title": "Automation & scripting in bash for beginners",
    "section": "Variables",
    "text": "Variables\n\nDeclaring variables\nYou can declare a variable (i.e.¬†a name that holds a value) with the = sign.\n!! Make sure not to put spaces around the equal sign.\nvariable=Test\n\n\nQuotes\nLet‚Äôs experiment with quotes:\n\nvariable=This string is the value of the variable\necho $variable\n\nbash: line 1: string: command not found\n\n\nOops‚Ä¶\n\nvariable=\"This string is the value of the variable\"\necho $variable\n\nThis string is the value of the variable\n\n\n\nvariable='This string is the value of the variable'\necho $variable\n\nThis string is the value of the variable\n\n\n\nvariable='This string's the value of the variable'\necho $variable\n\nbash: -c: line 1: unexpected EOF while looking for matching `''\n\n\nOops‚Ä¶\nOne solution to this is to use double quotes:\n\nvariable=\"This string's the value of the variable\"\necho $variable\n\nThis string's the value of the variable\n\n\nAlternatively, single quotes can be escaped:\n\nvariable='This string'\"'\"'s the value of the variable'\necho $variable\n\nThis string's the value of the variable\n\n\n\nAdmittedly, this last one is a little crazy. It is the way to escape single quotes in single-quoted strings.\nThe first ' ends the first string, both \" create a double-quoted string with ' (escaped) in it, then the last ' starts the second string.\nEscaping double quotes is a lot easier and simply requires \\\".\n\n\n\nExpanding a variable‚Äôs value\nTo expand a variable (to access its value), you need to prepend its name with $:\n\nvariable=Test\necho variable\n\nvariable\n\n\nMmmm‚Ä¶ not really want we want!\n\nvariable=Test\necho $variable\n\nTest\n\n\n\nvariable=Test; echo \"$variable\"\n\nTest\n\n\n!! Single quotes don‚Äôt expand variables.\n\nvariable=Test; echo '$variable'\n\n$variable\n\n\n\n\nPassing variables to a Bash script\nCreate a script called name.sh with the following content:\n#!/bin/bash\n\necho \"My name is $1.\"  # $1 refers to the first variable passed to the script\nYou can now pass a variable to this script with:\nbash name.sh Marie\nMy name is Marie.\nYou can pass several variables to a script. Copy name.sh to name2.sh and edit name2.sh to look like the following:\n#!/bin/bash\n\necho \"My name is $1 and I am $2 years old.\"\nbash name2.sh Marie 43\nMy name is Marie and I am 43 years old.\nYou can also pass any number of variables to a script:\n#!/bin/bash\n\necho $@\nbash script.sh argument1 argument2 argument3 argument4\nargument1 argument2 argument3 argument4\n\n\nBrace expansion\n\necho {1..5}\n\n1 2 3 4 5\n\n\n\necho {01..10}\n\n01 02 03 04 05 06 07 08 09 10\n\n\n\necho {1..5}.txt\n\n1.txt 2.txt 3.txt 4.txt 5.txt\n\n\n\necho {r..v}\n\nr s t u v\n\n\n\necho {file1,file2}.sh\n\nfile1.sh file2.sh\n\n\n!! Make sure not to add a space after the comma.\ntouch {file1,file2}.sh\ntouch file{3..6}.sh\n\necho {list,of,strings}\n\nlist of strings\n\n\n\n\nWildcards\nWildcards are really powerful to apply a command to all the elements having a common pattern.\nFor instance, we can delete all the files we created earlier (file1.sh, file2.sh, etc.) with a single command:\nrm file*.sh\n!! Be very careful that rm is irreversible. Deleted files do not go to the trash: they are gone.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Workshops</em></b>",
      "Scripting for beginners"
    ]
  },
  {
    "objectID": "bash/ws_scripting.html#loops",
    "href": "bash/ws_scripting.html#loops",
    "title": "Automation & scripting in bash for beginners",
    "section": "Loops",
    "text": "Loops\nTo apply a set of commands to all the elements of a list, you can use for loops. The general structure is as follows:\nfor &lt;iterable&gt; in &lt;list&gt;\ndo\n    &lt;statement1&gt;\n    &lt;statement2&gt;\n    ...\ndone\nLet‚Äôs create the script names.sh:\n#!/bin/bash\n\nfor name in $@\ndo\n    echo $name\ndone\nNow let‚Äôs run it with a list of arguments:\nbash names.sh Patrick Paul Marie Alex\nPatrick\nPaul\nMarie\nAlex\n\n\nYour turn:\n\nCompare the outputs of the following 2 scripts:\n\nscript1.sh:\n\n#!/bin/bash\n\necho $@\n\nscript2.sh:\n\n#!/bin/bash\n\nfor i in $@\ndo\n    echo $i\ndone\nHow do you explain the difference between running:\nbash script1.sh arg1 arg2 arg3\nand running:\nbash script2.sh arg1 arg2 arg3",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Workshops</em></b>",
      "Scripting for beginners"
    ]
  },
  {
    "objectID": "bash/ws_scripting.html#task-automation",
    "href": "bash/ws_scripting.html#task-automation",
    "title": "Automation & scripting in bash for beginners",
    "section": "Task automation",
    "text": "Task automation\nThis is a rather silly example, but bear with me and let‚Äôs imagine that it actually makes sense (of course, you don‚Äôt write that many thesis chapters so you would probably never automate these tasks‚Ä¶)\nSo‚Ä¶ let‚Äôs imagine that each time you write a thesis chapter, you do the same things:\n\nyou create a directory with the name of the chapter,\nyou create a number of subdirectories (for your source code, your manuscript, your data, and your results),\nyou create a Python script in the source code directory,\nyou create a markdown document in your manuscript directory,\nyou put the whole thing under version control with Git,\nyou create a .gitignore file in which you put the data subdirectory.\n\n\n\nYour turn:\n\nWrite a script that would do all this, then test the script.\nGive it a try on your own before looking at the solution below‚Ä¶\n\n\n\n\n\n\n\nWarningSolution\n\n\n\n\n\nHere is what the script looks like (let‚Äôs call it chapter.sh):\n#!/bin/bash\n\nmkdir $1\ncd $1\nmkdir src data results ms\ntouch src/$1.py ms/$1.md\ngit init\necho data/ &gt; .gitignore\nYou then run the script:\nbash chapter.sh chapter1\nYou can verify that all the files and directories got created with:\ntree chapter1\nchapter1/\n‚îú‚îÄ‚îÄ data\n‚îú‚îÄ‚îÄ ms\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ chapter1.md\n‚îú‚îÄ‚îÄ results\n‚îî‚îÄ‚îÄ src\n    ‚îî‚îÄ‚îÄ chapter1.py\nand:\nls -aF chapter1\n./  ../  data/  .git/  .gitignore  ms/  results/  src/\nYou can also verify the content of your .gitignore file with:\ncat chapter1/.gitignore\ndata/",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Workshops</em></b>",
      "Scripting for beginners"
    ]
  },
  {
    "objectID": "bash/ws_scripting.html#resources",
    "href": "bash/ws_scripting.html#resources",
    "title": "Automation & scripting in bash for beginners",
    "section": "Resources",
    "text": "Resources\nOne very useful (although very dense) resource is the Bash manual.\nYou can also get information on Bash from within Bash with:\ninfo bash\nand:\nman bash\nThere are also countless resources online and don‚Äôt forget to Google anything you don‚Äôt know how to do: you will almost certainly find the answer on StackOverflow or some Stack Exchange site.",
    "crumbs": [
      "Bash/Zsh",
      "<b><em>Workshops</em></b>",
      "Scripting for beginners"
    ]
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Please email us at: training at westdri dot ca."
  },
  {
    "objectID": "emacs/index.html",
    "href": "emacs/index.html",
    "title": "Emacs",
    "section": "",
    "text": "Getting started with ¬†\nAn intro course to Emacs\n\n\n\n\n60 min webinars\nVarious Emacs topics",
    "crumbs": [
      "Emacs",
      "<br>&nbsp;<img src=\"img/logo_emacs.png\" class=\"img-fluid\" style=\"width:1.75em\" alt=\"noshadow\"><br><br>"
    ]
  },
  {
    "objectID": "emacs/intro_backup.html",
    "href": "emacs/intro_backup.html",
    "title": "Backups and auto-saving",
    "section": "",
    "text": "By default, Emacs has two mechanisms helping to prevent data loss: backups and auto-saving.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Backups and auto-saving"
    ]
  },
  {
    "objectID": "emacs/intro_backup.html#backups",
    "href": "emacs/intro_backup.html#backups",
    "title": "Backups and auto-saving",
    "section": "Backups",
    "text": "Backups\nBy default, Emacs creates a single backup file for each file (although, of course, this can be changed). Each time you re-open a file and make changes, the version prior to this current editing session gets saved as the backup file.\nBackup files have names ending with ~.\n\n\nYour turn:\n\nCreate a file called file.txt and add the following content in it:\nThis is my file.\nSave it (C-x C-s).\nSend Emacs to the background (C-z) and run ls in the terminal. You should see a file called file.txt.\ncat file.txt shows you that it contains: This is my file.\nNow, close, then re-open the file and make the following changes:\nThis is my file, but I have re-edited it.\nSave it again.\nUsing ls and cat again (remember that you can also run Bash commands within Emacs with M-!), you should see that, in addition to your file file.txt with the content: This is my file, but I have re-edited it., there is now a backup file called file.txt~ with the content: This is my file.\nAs long as you don‚Äôt close the file, nothing happens to the backup file. But if you close it, re-open it, make new changes to it, and save it, the backup file.txt~ will now contain: This is my file, but I have re-edited it. (the version of the last editing session).\n\nBackup files preserve files prior to the current editing session. This is useful if you make terrible mistakes during an editing session.\n\nIf you don‚Äôt like having backup files next to your files, you can hide them out of the way thanks to the variable backup-directory-alist which allows you to store backup files in a directory of your choice.\nAlso, remember that in Dired, you can remove all backup files by typing ~.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Backups and auto-saving"
    ]
  },
  {
    "objectID": "emacs/intro_backup.html#auto-saving",
    "href": "emacs/intro_backup.html#auto-saving",
    "title": "Backups and auto-saving",
    "section": "Auto-saving",
    "text": "Auto-saving\nAuto-saving is a much more familiar concept as many software do this. This ensures that you don‚Äôt lose too much work if your computer crashes. By default, this happens every 300 keystrokes or after 30 seconds of idle time. Now, what is unusual is that Emacs saves the file in a separate file so as not to touch the file you are working on (this can be very useful if saving a file triggers some costly process such as re-rendering a website or if you don‚Äôt want to save temporary sensitive information).\nAuto-saved files are marked with # at the start and end of their names.\n\n\nYour turn:\n\nEdit file.txt and don‚Äôt save it for 300 keystrokes or idle for 30 seconds after some edits without saving. Now run ls and you will see that an auto-save file #file.txt# got created.\n\n\nIf you don‚Äôt like having auto-save files next to your files, you can hide them out of the way thanks to the variable auto-save-file-name-transforms which allows you to store backup files in a directory of your choice.\nAlso, remember that in Dired, you can remove all auto-save files by typing #.\n\n\nRecovering data\nIf you run M-x recover-this-file from within file.txt, its content will be replaced by the content of #file.txt#. You can also do this from outside the file with M-x recover-file and then entering the file name.\nIf your system crashes while you have unsaved changes in a file, Emacs will offer you to recover the content of your file from its auto-saved version next time you open it.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Backups and auto-saving"
    ]
  },
  {
    "objectID": "emacs/intro_customize.html",
    "href": "emacs/intro_customize.html",
    "title": "Customizing Emacs",
    "section": "",
    "text": "Customizing Emacs is obviously a very complex topic. This section only aims at getting you started using the easy customization interface.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Customizing Emacs"
    ]
  },
  {
    "objectID": "emacs/intro_customize.html#customizing-emacs",
    "href": "emacs/intro_customize.html#customizing-emacs",
    "title": "Customizing Emacs",
    "section": "Customizing Emacs",
    "text": "Customizing Emacs\nIn Emacs, everything is customizable.\nThere are two ways to customize Emacs (and you use both):\n\nyou can write Emacs Lisp code in your init file (the configuration file that gets loaded when Emacs launches),\nyou can use the easy customization interface which automatically adds code in your init file.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Customizing Emacs"
    ]
  },
  {
    "objectID": "emacs/intro_customize.html#the-init-file",
    "href": "emacs/intro_customize.html#the-init-file",
    "title": "Customizing Emacs",
    "section": "The init file",
    "text": "The init file\nIt is standard to call the init file .emacs and create it in your home (~/). Of course, like everything else, this too can be customized üôÇ\nThis file is read at startup and loads your Emacs configurations.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Customizing Emacs"
    ]
  },
  {
    "objectID": "emacs/intro_customize.html#easy-customization-interface",
    "href": "emacs/intro_customize.html#easy-customization-interface",
    "title": "Customizing Emacs",
    "section": "Easy customization interface",
    "text": "Easy customization interface\nThe easy customization interface can be accessed by running one of the customize commands, the most important of which are:\n\ncustomize-group for groups of variables,\ncustomize-variable for individual variable,\ncustomize-face for the appearance of one type of text.\n\n\n\nYour turn:\n\nType M-x customize-group python to enter the Python group and have a look at the various variables in that group.\nTry to change the default of the variable python-indent-offset. (You can select it from the group page, or you can access it directly with M-x customize-variable python-indent-offset).\nNow, try to customize the font-lock-keyword-face face. You can run M-x customize-face font-lock-keyword-face, but an easier way is to place the cursor on an element of that face and run M-x customize-face. The name of the face your cursor was on will appear as the default, so you can then simply press Return.\n\nThese will add customization at the top of your init file. If this file doesn‚Äôt exist, it will automatically create it.\nThe customization will be in the form:\n(custom-set-variables\n ;; custom-set-variables was added by Custom.\n ;; If you edit it by hand, you could mess it up, so be careful.\n ;; Your init file should contain only one such instance.\n ;; If there is more than one, they won't work right.\n(python-indent-offset 2))\n(custom-set-faces\n ;; custom-set-faces was added by Custom.\n ;; If you edit it by hand, you could mess it up, so be careful.\n ;; Your init file should contain only one such instance.\n ;; If there is more than one, they won't work right.\n (font-lock-keyword-face ((t (:foreground \"green\")))))",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Customizing Emacs"
    ]
  },
  {
    "objectID": "emacs/intro_install.html",
    "href": "emacs/intro_install.html",
    "title": "Installation and access",
    "section": "",
    "text": "In this section, we will make sure that you can access Emacs on our remote cluster.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Installation and access"
    ]
  },
  {
    "objectID": "emacs/intro_install.html#installing-emacs-on-your-machine",
    "href": "emacs/intro_install.html#installing-emacs-on-your-machine",
    "title": "Installation and access",
    "section": "Installing Emacs on your machine",
    "text": "Installing Emacs on your machine\nTo download and install Emacs on your computer, simply follow the instructions in the official documentation.\n\nIf you are on Linux, make sure to install the version of Emacs with native compilation and jansson support.\nNative compilation was added as an option to Emacs 28 and greatly speeds up Emacs, in particular startup time. You will need libgccjit installed on your system.\nJansson support was added as an option to Emacs 27 and speeds up anything that involves JSON files and makes lsp-mode and eglot in particular much faster.\nIf you don‚Äôt use Linux, you will have to install libgccjit and the version of jansson for your OS (could be called libjansson), then compile Emacs from source with the --with-native-compilation and --with-json flags.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Installation and access"
    ]
  },
  {
    "objectID": "emacs/intro_install.html#accessing-emacs-on-the-alliance-clusters",
    "href": "emacs/intro_install.html#accessing-emacs-on-the-alliance-clusters",
    "title": "Installation and access",
    "section": "Accessing Emacs on the Alliance clusters",
    "text": "Accessing Emacs on the Alliance clusters\nTo ensure that we are all working in the same environment, for this course, we will use Emacs in a training cluster. This will also prepare you for using it on the Alliance clusters.\nAll you need to do is to log in to our cluster through SSH. Emacs is then available without having to load any module.\n\nWindows users\nLaunch PowerShell and type ssh to see whether OpenSSH is installed and enabled on your system. If it is, follow the instructions for macOS and Linux users below.\nIf it is not, install the free version of MobaXTerm and launch it, then follow the first 18% of this demo.\nFor ‚ÄúRemote host‚Äù, use the hostname we gave you.\nSelect the box ‚ÄúSpecify username‚Äù and provide your username.\n\nNote that the password is entered through blind typing, meaning that you will not see anything happening as you type it. This is a Linux feature. While it is a little disturbing at first, do know that it is working. Make sure to type it slowly to avoid typos, then press the ‚Äúenter‚Äù key on your keyboard.\n\n\n\nmacOS and Linux users\nOpen a terminal emulator:\n\nmacOS users: ‚ÄÉ‚ÄÉLaunch Terminal.\nLinux users: ‚ÄÉ‚ÄÉ‚ÄÇ¬†Open the terminal emulator of your choice.\n\n(For Windows users with ssh available in PowerShell, use PowerShell as the terminal emulator).\nIn it, run:\nssh &lt;username&gt;@&lt;hostname&gt;\n\nReplace the username and hostname by their values. For instance:\nssh user021@somecluster.c3.ca\n\nYou will be asked a question, answer ‚ÄúYes‚Äù.\nWhen prompted, type the password.\n\nNote that the password is entered through blind typing, meaning that you will not see anything happening as you type it. This is a Linux feature. While it is a little disturbing at first, do know that it is working. Make sure to type it slowly to avoid typos, then press the ‚Äúenter‚Äù key on your keyboard.\n\n\n\nTroubleshooting\nProblems logging in are almost always due to typos. If you cannot log in, retry slowly, entering your password carefully.\nNow that you are logged in, in the next section, we will see how to launch Emacs.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Installation and access"
    ]
  },
  {
    "objectID": "emacs/intro_modes.html",
    "href": "emacs/intro_modes.html",
    "title": "Emacs modes",
    "section": "",
    "text": "At the core of Emacs functioning are modes. This section will explain what Emacs major and minor modes are.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Emacs modes"
    ]
  },
  {
    "objectID": "emacs/intro_modes.html#major-modes",
    "href": "emacs/intro_modes.html#major-modes",
    "title": "Emacs modes",
    "section": "Major modes",
    "text": "Major modes\nDifferent types of text require different behaviours, syntax highlighting, formatting, functions, variables, etc. Consequently, each type of buffer (e.g.¬†Python script, Markdown document, Julia REPL, Bash shell, directory editor, pdf) is associated with a different major mode.\nFile extensions, particular markers in the file, or other elements tell Emacs to automatically switch to the appropriate major mode.\nOnly one major mode is active at a time.\nSwitching to a different major mode is possible by running the corresponding major mode command (e.g.¬†M-x python-mode will switch to Python mode).\n\nFundamental mode\nfundamental-mode is the most basic major mode, with no particular feature. This is the mode enabled by default if Emacs cannot detect what specific major mode to enable.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Emacs modes"
    ]
  },
  {
    "objectID": "emacs/intro_modes.html#minor-modes",
    "href": "emacs/intro_modes.html#minor-modes",
    "title": "Emacs modes",
    "section": "Minor modes",
    "text": "Minor modes\nMinor modes provide additional and optional features that can be turned on or off (e.g.¬†spell checking, auto-completion, auto-indentation, fancy undo behaviour, fancy parenthesis matching highlighting).\nMinor modes can be turned on/off by running the corresponding minor mode commands (e.g.¬†M-x flyspell-mode will turn spell checking on/off).\nThe command consult-minor-mode-menu from the package consult makes this particularly easy (we will see in a later section how to install packages).\nEach mode comes with a set of commands. consult‚Äôs command consult-mode-command makes it easy to search for commands within each mode.\nAny number of minor modes can be active at the same time.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Emacs modes"
    ]
  },
  {
    "objectID": "emacs/intro_modes.html#list-of-enabled-modes",
    "href": "emacs/intro_modes.html#list-of-enabled-modes",
    "title": "Emacs modes",
    "section": "List of enabled modes",
    "text": "List of enabled modes\nBy default, C-h m or M-x describe-mode will open a list and description of the active modes.\nThe major mode can also be determined with C-h v major-mode (C-h v runs the command describe-variable).\nFinally, a list of minor modes can be viewed with C-h v minor-mode-list.\nHere too, the package consult makes this much nicer, thanks to the command consult-minor-mode-menu.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Emacs modes"
    ]
  },
  {
    "objectID": "emacs/intro_modes.html#the-mode-line",
    "href": "emacs/intro_modes.html#the-mode-line",
    "title": "Emacs modes",
    "section": "The mode line",
    "text": "The mode line\nAnother way to get information about enabled modes is the mode line.\nRemember that the mode line is that line near the bottom of the window with a series of information:",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Emacs modes"
    ]
  },
  {
    "objectID": "emacs/intro_modes.html#hooks",
    "href": "emacs/intro_modes.html#hooks",
    "title": "Emacs modes",
    "section": "Hooks",
    "text": "Hooks\nMinor modes can be automatically enabled when other modes (major or minor) are enabled thanks to hooks.\n\nFor example, to enable the aggressive indent minor mode whenever the ESS R major mode is enabled, you can add to your init file:\n\n(add-hook 'ess-r-mode-hook 'aggressive-indent-mode)\n\nOr, using use-package, now part of base Emacs:\n\n(use-package aggressive-indent\n    :hook (ess-r-mode . aggressive-indent-mode))\nWe will learn how to customize Emacs in a later section, so don‚Äôt worry if this doesn‚Äôt make much sense yet.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Emacs modes"
    ]
  },
  {
    "objectID": "emacs/intro_modes.html#modes-source-code",
    "href": "emacs/intro_modes.html#modes-source-code",
    "title": "Emacs modes",
    "section": "Modes source code",
    "text": "Modes source code\nTo see the source code of a mode, run C-h v (or M-x describe-variable) followed by the name of the mode map. This will open a help buffer with a link to the source code file.\n\nFor example C-h v text-mode-map will open a help buffer with a link to text-mode.el.\n\n\nThe help buffer opened by C-h m or M-x describe-mode also gives a link to the source code of the major mode.\n\nLooking at the source code of a mode is very useful to customize it.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Emacs modes"
    ]
  },
  {
    "objectID": "emacs/intro_modes.html#polymode",
    "href": "emacs/intro_modes.html#polymode",
    "title": "Emacs modes",
    "section": "Polymode",
    "text": "Polymode\nWhile it is normally impossible to associate multiple major modes with a single buffer, Polymode allows to insert sections of a major mode within another major mode.\nThis is extremely convenient for instance to embed sections of code within human text, or even to have code executed within human text (e.g.¬†R Markdown or its successor Quarto, Org Babel).\n\nFor example, here is the section of a markdown-mode buffer with snippets of julia-mode:\n\nJulia has \"assignment by operation\" operators:\n\n```{julia}\na = 2;\na += 7    # this is the same as a = a + 7\n```\n\nThere is a *left* division operator:\n\n```{julia}\n2\\8 == 8/2\n```\n\nIt can be rendered by Quarto into the following webpage:",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Emacs modes"
    ]
  },
  {
    "objectID": "emacs/intro_remote.html",
    "href": "emacs/intro_remote.html",
    "title": "Editing remote files",
    "section": "",
    "text": "Once you have installed a bunch of packages and configured Emacs to your liking, you will find it annoying to work without all these extra niceties.\nIf you use the Alliance clusters, it would be a pain to try to replicate your Emacs packages and configs there: first, the Emacs versions may differ, then it is difficult to keep all customizations in sync on your machine and on your cluster account, finally, it is simply a loss of time because there is a much better way to go about it: TRAMP.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Editing remote files"
    ]
  },
  {
    "objectID": "emacs/intro_remote.html#what-is-tramp",
    "href": "emacs/intro_remote.html#what-is-tramp",
    "title": "Editing remote files",
    "section": "What is TRAMP?",
    "text": "What is TRAMP?\nTRAMP (Transparent Remote file Access, Multiple Protocol) allows to edit remote files over SSH or files belonging to different users from your local Emacs instance. This is very convenient because it allows you to keep your usual Emacs environment with your local settings and packages.\nFor exhaustive information, you can look at the TRAMP manual.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Editing remote files"
    ]
  },
  {
    "objectID": "emacs/intro_remote.html#how-to-use-tramp",
    "href": "emacs/intro_remote.html#how-to-use-tramp",
    "title": "Editing remote files",
    "section": "How to use TRAMP?",
    "text": "How to use TRAMP?\nTRAMP is very easy to use, all you have to do is use the following syntax for the file name:\n/method:user@hostname:/path/to/file\n\nExample:\n\nThe remote name of the .bashrc file in your home directory on a remote machine would look something like this:\n/ssh:user026@somename.ca:.bashrc\n\nTo use TRAMP to access files as root (if you have root access), use /sudo::/path/to/file.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Editing remote files"
    ]
  },
  {
    "objectID": "emacs/intro_remote.html#using-tramp-with-mfa",
    "href": "emacs/intro_remote.html#using-tramp-with-mfa",
    "title": "Editing remote files",
    "section": "Using TRAMP with MFA",
    "text": "Using TRAMP with MFA\nRecently, the Alliance clusters started using MFA. Consequently, in order to use TRAMP to access files on a cluster, you will first have to enter your Alliance password, then the method you used for MFA.\nThe prompt for the password is self-explanatory (‚ÄúPassword:‚Äù). That for the MFA method is not: Emacs will prompt you with: ‚ÄúPasscode:‚Äù, after which you should do one of the following:\n\nType 1 and you will be prompted to approve the request on the Duo Mobile App on your phone (this is a bit confusing at first because the prompt is not as clear as when you join through SSH. Here, you have to know that you need to type 1).\nEnter one of your backup codes.\nPress the button on your YubiKey if you have one.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Editing remote files"
    ]
  },
  {
    "objectID": "emacs/intro_remote.html#safely-storing-passwords",
    "href": "emacs/intro_remote.html#safely-storing-passwords",
    "title": "Editing remote files",
    "section": "Safely storing passwords",
    "text": "Safely storing passwords\nThe auth-source library (part of Emacs) enables Emacs to automatically access passwords saved in a ~/.authoinfo or ~/.authoinfo.gpg file. For safety reasons, you definitely should encrypt it with gpg and make it a ~/.authoinfo.gpg file.\nOnce your Alliance account password is safely stored in this file, you won‚Äôt have to type it to access your files remotely anymore.\nYou will however still have to use Duo App or YubiKey. But here too, you can make things easier for yourself if you create an SSH config file and add for the Alliance cluster host you use some configuration to make your SSH logins persist for some amount of time (e.g.¬†60 min):\nHost HOSTNAME\n    ControlPath ~/.ssh/cm-%r@%h:%p\n    ControlMaster auto\n    ControlPersist 60m",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Editing remote files"
    ]
  },
  {
    "objectID": "emacs/intro_run.html",
    "href": "emacs/intro_run.html",
    "title": "Running Emacs",
    "section": "",
    "text": "There are several ways to run Emacs (as a GUI or in the terminal, with or without config file(s), as a server‚Ä¶). In this section, we will have a look at some very useful options.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Running Emacs"
    ]
  },
  {
    "objectID": "emacs/intro_run.html#list-of-options",
    "href": "emacs/intro_run.html#list-of-options",
    "title": "Running Emacs",
    "section": "List of options",
    "text": "List of options\nOn your computer, you can launch Emacs the way you launch any application (double-clicking on the icon, looking for it in your usual software launcher, etc.). On the cluster, you launch Emacs with the command emacs.\nLet‚Äôs try it:\nemacs\nTo close it, type C-x C-c. That brings you back to the terminal.\nEmacs, like most Linux commands, comes with a number of flags. To learn about them, you can open the manual page for Emacs:\nman emacs\n\nMan pages open in a pager (usually less).\nUseful keybindings when you are in the pager:\nSPACE      scroll one screen down\nb          backa one screen\nq          quit the pager\ng          go to the top of the document\n7g         go to line 7 from the top\nG          go to the bottom of the document\n/          search for a term\n           n will take you to the next result\n           N to the previous result",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Running Emacs"
    ]
  },
  {
    "objectID": "emacs/intro_run.html#windowterminal",
    "href": "emacs/intro_run.html#windowterminal",
    "title": "Running Emacs",
    "section": "Window/terminal",
    "text": "Window/terminal\nWhen we launched Emacs earlier, it launched directly in the terminal. This is because we are accessing the remote machine without X11 forwarding, so we cannot use graphical applications there.\nIf we had enabled X11 forwarding (by having an X11 server running on our machine and using ssh -Y), or if we were launching Emacs from a terminal on our machine, the command emacs would have launched the GUI version of Emacs with clickable menu, etc. In those cases, if we still wanted to launch Emacs in the terminal, we would have to use the -nw flag (for no window).",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Running Emacs"
    ]
  },
  {
    "objectID": "emacs/intro_run.html#initialization-file",
    "href": "emacs/intro_run.html#initialization-file",
    "title": "Running Emacs",
    "section": "Initialization file",
    "text": "Initialization file\nRight now, we do not have any initialization file (the user-written configuration file for Emacs). Later on however, we will create one and such file gets loaded automatically when Emacs starts. There are flags to prevent loading such file or to load a different configuration file.\nWe can also prevent the Emacs startup page with the --no-splash flag:\nemacs --no-splash",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Running Emacs"
    ]
  },
  {
    "objectID": "emacs/intro_run.html#emacs-server",
    "href": "emacs/intro_run.html#emacs-server",
    "title": "Running Emacs",
    "section": "Emacs server",
    "text": "Emacs server\nYou might have noticed that it takes a little time for Emacs to launch. This wouldn‚Äôt happen on a local machine, particularly with the latest version of Emacs (Emacs has gotten much faster in recent years, but our cluster still has an older version of Emacs installed). Still, Emacs being so powerful, it can be a bit slow to launch once you customize it with countless packages.\nIt is annoying to have to wait each time you need to edit a file! But there is a nice solution: you can launch an Emacs server with emacs --daemon, then, each time you need to use Emacs, you connect to the running server with the emacsclient command. That way, you wait for Emacs to start only once (when you launch the server, but not afterwards.\nYou will get this warning when you launch the server, but you can ignore it:\n\nWarning: due to a long standing Gtk+ bug https://gitlab.gnome.org/GNOME/gtk/issues/221 Emacs might crash when run in daemon mode and the X11 connection is unexpectedly lost. Using an Emacs configured with ‚Äìwith-x-toolkit=lucid does not have this problem.\n\nIf the warning bothers you, you can redirect to /dev/null by running `emacs ‚Äìdaemon 2&gt; /dev/null‚Äô instead.\nYou can also create an alias in your .bashrc file:\nalias es='emacs --daemon 2&gt; /dev/null'  # start Emacs server\nAnd you could even create an alias for emacsclient to make it easier to type since you will use it so often:\nalias ec='emacsclient'\nNow, to open a file called test.py you only have to run ec test.py.\nThe server keeps running even after you log out of your session. This can be convenient, but you probably shouldn‚Äôt let it run if you don‚Äôt plan on logging back in soon.\nTo kill the server, you can run the command kill-emacs from within Emacs (we will see how to run commands in a following section), or by running from the command line:\nemacsclient -e \"(kill-emacs)\"\nYou can create an alias for this too by adding something like this in your .bashrc:\nalias ek='emacsclient -e \"(kill-emacs)\"'  # kill Emacs server",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Running Emacs"
    ]
  },
  {
    "objectID": "emacs/intro_ui.html",
    "href": "emacs/intro_ui.html",
    "title": "User interface",
    "section": "",
    "text": "To understand the documentation, it is important to learn a little bit of Emacs terminology. Here, we will see what are Emacs windows, buffers, and other parts of the user interface.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "User interface"
    ]
  },
  {
    "objectID": "emacs/intro_ui.html#emacs-frames",
    "href": "emacs/intro_ui.html#emacs-frames",
    "title": "User interface",
    "section": "Emacs frames",
    "text": "Emacs frames\nWhen Emacs is run in a GUI fashion, what the OS usually calls a window is actually called in Emacs terminology a frame. It is possible to launch several Emacs frames. Right now, because we are running Emacs directly in the terminal, we can only have one Emacs frame.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "User interface"
    ]
  },
  {
    "objectID": "emacs/intro_ui.html#emacs-windows",
    "href": "emacs/intro_ui.html#emacs-windows",
    "title": "User interface",
    "section": "Emacs windows",
    "text": "Emacs windows\nA frame can contain one or several windows.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "User interface"
    ]
  },
  {
    "objectID": "emacs/intro_ui.html#buffers",
    "href": "emacs/intro_ui.html#buffers",
    "title": "User interface",
    "section": "Buffers",
    "text": "Buffers\nThe part of the window that contains the text to edit is called a buffer.\n\nBuffers can hold the content of a file, a running process (e.g.¬†REPL, shell), an image, a pdf‚Ä¶",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "User interface"
    ]
  },
  {
    "objectID": "emacs/intro_ui.html#echo-area",
    "href": "emacs/intro_ui.html#echo-area",
    "title": "User interface",
    "section": "Echo area",
    "text": "Echo area\nAt the bottom of each window is an echo area. This is where Emacs prints outputs.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "User interface"
    ]
  },
  {
    "objectID": "emacs/intro_ui.html#minibuffer",
    "href": "emacs/intro_ui.html#minibuffer",
    "title": "User interface",
    "section": "Minibuffer",
    "text": "Minibuffer\nThe minibuffer is a small buffer that appears in the echo area with a prompt and a cursor whenever Emacs expects some input from you.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "User interface"
    ]
  },
  {
    "objectID": "emacs/intro_ui.html#mode-line",
    "href": "emacs/intro_ui.html#mode-line",
    "title": "User interface",
    "section": "Mode line",
    "text": "Mode line\nBetween the buffer and the echo area is the mode line, an area that gives information on running modes, file name and path, place of the cursor in the buffer, whether the document has been modified, etc.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "User interface"
    ]
  },
  {
    "objectID": "emacs/intro_why.html",
    "href": "emacs/intro_why.html",
    "title": "Why Emacs?",
    "section": "",
    "text": "A good text editor is one of the most important tools a scientific programmer needs to choose and master.\nEmacs is a free, open source, and incredibly powerful text editor that can be turned into a complete IDE for writing and running code, and so much more.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Why Emacs?"
    ]
  },
  {
    "objectID": "emacs/intro_why.html#a-brief-history-of-emacs",
    "href": "emacs/intro_why.html#a-brief-history-of-emacs",
    "title": "Why Emacs?",
    "section": "A brief history of Emacs",
    "text": "A brief history of Emacs\nGNU Emacs is the most popular version of the Emacs text-editor family.\nThe first EMACS was written in 1976 by Davd A. Moon and Guy L. Steele Jr. at the MIT AI Lab. The development of GNU Emacs was started in 1984 by Richard Stallman‚Äîa free software movement activist and father of the copyleft concept. It is amongst the oldest free and open source software still under development. Despite its age, development actually remains very active with modern and powerful optimizations implemented constantly.\nGNU Emacs remains a symbol of the hacker culture of the 70s and 80s, particularly in its rivalry with vi as part of the editor war.\nIts editing functionalities are written in Emacs Lisp‚Äîa dialect of the Lisp programming language (the rest and the interpreter are written in C).\nThe official GNU Emacs website can be found here.",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Why Emacs?"
    ]
  },
  {
    "objectID": "emacs/intro_why.html#why-use-emacs",
    "href": "emacs/intro_why.html#why-use-emacs",
    "title": "Why Emacs?",
    "section": "Why use Emacs?",
    "text": "Why use Emacs?\nTo brag. Obviously.\n\nBut there are other reasons:\n\nFree and open source\nEndlessly customizable\nAmazing diff\nEasy macros and automation\nText and file searching\nBookmarks\nGreat programming IDE\nLossless and endless undo/redo\nPowerful integration with Git\nEmail, Slack, Telegram, calendar, IRC‚Ä¶\nFile manager\nUnified set of shortcuts, search functionality, and environment for any tasks (easier than learning new IDEs and GUIs all the time!)\nTetris! and other games\nCalculator, calendar‚Ä¶\nX windows manager\nFun!\n‚Ä¶\n\nEmacs can do just about anything (except the laundry).\n\nNow ‚Ä¶ getting started can be daunting ‚Ä¶\n\n‚Ä¶ and it doesn‚Äôt necessarily get easier.\n\nBut it is worth it!",
    "crumbs": [
      "Emacs",
      "<em><b>Getting started</b></em>",
      "Why Emacs?"
    ]
  },
  {
    "objectID": "emacs/top_wb.html",
    "href": "emacs/top_wb.html",
    "title": "Emacs webinars",
    "section": "",
    "text": "Emacs as a programming IDE\n\n\n\n\nModern, faster & better Emacs\n\n\n\n\nUnderstanding Emacs modes\n\n\n\n\nUsing LLMs in Emacs\n\n\n\n\n\n\nFull Python IDE in Emacs",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>"
    ]
  },
  {
    "objectID": "emacs/wb_ide_content.html",
    "href": "emacs/wb_ide_content.html",
    "title": "Emacs as a programming IDE",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.\nI am not trying to start an editor war here.\nParticularly as there are now excellent IDEs for Python, Julia, and R without Emacs learning curve (think VS Code, RStudio, or JupyterLab).",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "Emacs as a programming IDE",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_ide_content.html#why-i-still-use-and-love-emacs",
    "href": "emacs/wb_ide_content.html#why-i-still-use-and-love-emacs",
    "title": "Emacs as a programming IDE",
    "section": "Why I still use (and love) Emacs",
    "text": "Why I still use (and love) Emacs\n\nBookmarking\nFully customizable\nKbd for everything\nOrg mode (org tables!)\nOrganization of windows\nSearch and replace with regexp\nEdiff\nMacros\nEmacs everywhere (emails, Slack, Telegram with mu4e, emacs-slack, telega)\n\n\nHelm\n\nSearching in buffer\nNavigating open buffers and recent files\nNavigating file sections\nSelecting from kill ring\nMoving in mark ring\nLooking at active modes\n\n\n\nCompletion\n\ncompany-mode\nyasnippet\nDynamic abbrev expansion\n\n\n\nUndoing/redoing with undo-tree\n\nClassic undo/redo\nThe classic undo/redo in the vast majority of software follows a linear systems:\n\n\n\n\n\nflowchart TD\n   1((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nHave some file.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nMake some edits.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nMake more edits.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \"))---4((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nMake more edits.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \")):::current---4((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nCan undo.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \")):::current---3((\" \"))---4((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nUndo some more.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \")):::current---4((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px\n\n\n\n\n\n\n\nCan redo.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \"))-.-4((\" \")):::lost\n   3((\" \"))---5((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px\n   classDef lost stroke-dasharray: 3 4\n\n\n\n\n\n\n\nMake new edits.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \")):::current-.-4((\" \")):::lost\n   3((\" \"))---5((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px\n   classDef lost stroke-dasharray: 3 4\n\n\n\n\n\n\n\nCan still undo.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \")):::current---3((\" \"))-.-4((\" \")):::lost\n   3((\" \"))---5((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px\n   classDef lost stroke-dasharray: 3 4\n\n\n\n\n\n\n\nCan still undo.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \")):::current-.-4((\" \")):::lost\n   3((\" \"))---5((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px\n   classDef lost stroke-dasharray: 3 4\n\n\n\n\n\n\n\nAnd can redo.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \"))-.-4((\" \")):::lost\n   3((\" \"))---5((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px\n   classDef lost stroke-dasharray: 3 4\n\n\n\n\n\n\n\nBut some edits are forever lost.\n\n This system is basic, unsophisticated, and frustrating each time you loose edits.\n\n\nEmacs undo/undo\nEmacs offers a very interesting approach: while still a linear system, no edits are ever lost because Emacs does not have any redo. To redo, you undo the undo.\n\n\n\n\n\n---\nconfig:\n  themeVariables:\n    fontSize: 10\n  rankSpacing: 10\n---\nflowchart TD\n   1((1)):::current\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n\nHave some file.\n\n\n\n\n\n\n---\nconfig:\n  rankSpacing: 10\n---\nflowchart TD\n   1((1))---2((2)):::current\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n\nMake some edits.\n\n\n\n\n\n\n---\nconfig:\n  rankSpacing: 10\n---\nflowchart TD\n   1((1))---2((2))---3((3)):::current\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n\nMake more edits.\n\n\n\n\n\n\n---\nconfig:\n  rankSpacing: 10\n---\nflowchart TD\n   1((1))---2((2))---3((3))---4((4)):::current\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n\nMake more edits.\n\n\n\n\n\n\n---\nconfig:\n  rankSpacing: 10\n---\nflowchart TD\n   1((1))---2((2))---3((3))---4((4))---5((3)):::current\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n\nThe first undo adds a new point to the chain of edits.\n\n\n\n\n\n\n---\nconfig:\n  rankSpacing: 10\n---\nflowchart TD\n   1((1))---2((2))---3((3))---4((4))---5((3))---6((2)):::current\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n\nMore undoing keeps adding points to the chain.\n\n\n\n\n\n\n---\nconfig:\n  rankSpacing: 10\n---\nflowchart TD\n   1((1))---2((2))---3((3))---4((4))---5((3))---6((2))---7((3)):::current\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n\nThere is no redo: you stop undoing, then start again to undo the undo.\n\n\n\n\n\n\n---\nconfig:\n  rankSpacing: 10\n---\nflowchart TD\n   1((1))---2((2))---3((3))---4((4))---5((3))---6((2))---7((3))---8((5)):::current\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n\nYou can make new edits.\n\n\nNothing ever gets lost, but you might get headaches.\n\n\nExample: let‚Äôs go back to the starting point.\n\n\n\n\n\n\n---\nconfig:\n  rankSpacing: 10\n---\nflowchart TD\n   1((1))---2((2))---3((3))---4((4))---5((3))---6((2))---7((3))---8((5))---9((3))---10((2))---11((3))---12((4))---13((3))---14((2))---15((1)):::current\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n While this works, it quickly becomes an absolute hell not to get lost in the growing chain of undos, undo the undos, undo the undos of the undos‚Ä¶ not to mention that if you enter any non-undo command in the chain, you break it and you will have to do it all over again (plus the new undos you did before breaking the chain ü§Ø).\n\n\nUndo-tree\nThe obvious solution is to use a non-linear system, that is a tree system.\n\n\n\n\n\nflowchart TD\n   1((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n\nHave some file.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n\nMake some edits.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n\nMake some edits.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \"))---4((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n\nMake some edits.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \")):::current---4((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n\nUndo.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \")):::current---3((\" \"))---4((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n\nUndo.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \")):::current---4((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n\nRedo.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \"))---4((\" \"))\n   3((\" \"))---5((\" \")):::current\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n\nMake new edits.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \"))---4((\" \"))\n   3((\" \")):::current---5((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n\nUndo.\n\n\n\n\n\n\nflowchart TD\n   1((\" \"))---2((\" \"))---3((\" \"))---4((\" \")):::current\n   3((\" \"))---5((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n\nSwitch branch and redo the old version.\n\n\n\n\n\n\nflowchart TD\n   1((\" \")):::current---2((\" \"))---3((\" \"))---4((\" \"))\n   3((\" \"))---5((\" \"))\n   classDef current stroke: #f96, stroke-width: 2px, color: #f96\n\n\n\n\n\n\n\nNothing gets lost and it is more sane to navigate the history.\n\n This is truly great (undo-tree was actually first implemented in Vim, but ü§´).",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "Emacs as a programming IDE",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_ide_content.html#emacs-with-python",
    "href": "emacs/wb_ide_content.html#emacs-with-python",
    "title": "Emacs as a programming IDE",
    "section": "Emacs with Python",
    "text": "Emacs with Python\nEmacs comes with a Python mode that provides syntax highlighting. For a full IDE experience, there are multiple options, the most popular of which being the elpy package:\n\n\n\nCode from matplotlib",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "Emacs as a programming IDE",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_ide_content.html#emacs-with-r",
    "href": "emacs/wb_ide_content.html#emacs-with-r",
    "title": "Emacs as a programming IDE",
    "section": "Emacs with R",
    "text": "Emacs with R\nR is‚Äîas Emacs‚ÄîGNU software and has been integrated with Emacs via the ESS (Emacs Speaks Statistics) package for a very long time:",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "Emacs as a programming IDE",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_ide_content.html#emacs-with-julia",
    "href": "emacs/wb_ide_content.html#emacs-with-julia",
    "title": "Emacs as a programming IDE",
    "section": "Emacs with Julia",
    "text": "Emacs with Julia\nThe julia-mode package provides syntax highlighting and the julia-repl package implements a fully functional Julia REPL, optionally with the emacs-libvterm package:\n\n\n\nCode from Beautiful Makie\n\n\nESS also provides an IDE for Julia, but it does not allow for the funky Julia-specific REPL.\nAnother sophisticated option is to use julia-mode with the julia-snail package.",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "Emacs as a programming IDE",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_llms.html",
    "href": "emacs/wb_llms.html",
    "title": "AI pair programming & LLMs chats in Emacs",
    "section": "",
    "text": "Large language models (LLMs) have become powerful tools for coding, writing, and research. Not surprisingly, they are increasingly becoming integrated into many software, including text editors.\nEmacs is no exception and a number of packages have recently been developed to access models smoothly and directly. Of particular notice:\n\ncopilot.el brings GitHub Copilot‚Äôs code completion to Emacs,\ncopilot-chat.el allows to chat, write tests, explain, document, review, correct, and optimize code with GitHub Copilot in Emacs,\ngptel allows access to LLMs from any buffer,\nchatgpt-shell provides an Emacs shell to chat with LLMs,\nmcp.el provides an Emacs client for MCP,\naidermacs brings aider to Emacs (so forget about Cursor üôÇ).\n\nIn this webinar, I will demo these packages and show you how to install them and set things up.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.)\n\nInfo on mcp.el and its integration with gptel and copilot-chat.el was added after the webinar, so it is in the slides, but not in the video.\n\n\n Slides content for easier browsing.",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "AI pair programming in Emacs"
    ]
  },
  {
    "objectID": "emacs/wb_llms_slides.html#warning-about-my-setup",
    "href": "emacs/wb_llms_slides.html#warning-about-my-setup",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "Warning about my setup",
    "text": "Warning about my setup\nI normally don‚Äôt share my Emacs init code because it relies on a remapping of the semi-colon as a ring-map which makes my keybindings absurd on another machine. I also use straight.el for packages installations and it itself requires to be installed first\nBut I keep being asked for my code after each webinar. So this time, I am sharing it\nDon‚Äôt copy-paste it in your init file: it would break your Emacs. Instead, use it to inspire your potential setup or, better still, go to the packages READMEs. They provide a much better place to start\nYou have been warned‚Ä¶ üôÇ"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#privacy-warning",
    "href": "emacs/wb_llms_slides.html#privacy-warning",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "Privacy warning",
    "text": "Privacy warning\nMost companies offer a free tier. These may come with lower speed, limited tokens, older models\nThe free tier always come with a lack of privacy: your LLM usage is used for model training\nPaid services normally come with more privacy protections, but the landscape is fast evolving and accidents happen\nBe mindful of what you type when you interact with LLMs. Do not type sensitive information in your prompt"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#safe-api-key-storage",
    "href": "emacs/wb_llms_slides.html#safe-api-key-storage",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "Safe API key storage",
    "text": "Safe API key storage\nYour LLMs API keys, login credentials, or passwords should never appear as plain text in your init file\nSome packages provide mechanisms for safe storing or logging\nOthers don‚Äôt. In that case, there are multiple options. My favourites are based on auth-source and GPG"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#safe-api-key-storage-authinfo.gpg",
    "href": "emacs/wb_llms_slides.html#safe-api-key-storage-authinfo.gpg",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "Safe API key storage: authinfo.gpg",
    "text": "Safe API key storage: authinfo.gpg\nCreate a ~/.authinfo.gpg file with your keys in the format:\nmachine &lt;hostname&gt; login &lt;username&gt; password &lt;password&gt;\nIf you need a function to retrieve your key, use:\n(lambda ()\n  (auth-source-pick-first-password\n    :host \"&lt;hostname&gt;\"\n    :user \"&lt;username&gt;\"))\nIf you need a string, simply use:\n(auth-source-pick-first-password\n  :host \"&lt;hostname&gt;\"\n  :user \"&lt;username&gt;\")"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#safe-api-key-storage-pass",
    "href": "emacs/wb_llms_slides.html#safe-api-key-storage-pass",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "Safe API key storage: pass",
    "text": "Safe API key storage: pass\nUse the standard Unix password manager to store your API key by running in a Unix shell:\npass insert &lt;key-name&gt;\n# enter your API key twice when prompted\nFunction:\n(lambda ()\n  (auth-source-pass-get 'secret \"&lt;key-name&gt;\"))\nString:\n(auth-source-pass-get 'secret \"&lt;key-name&gt;\")"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#requirements",
    "href": "emacs/wb_llms_slides.html#requirements",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "Requirements",
    "text": "Requirements\nAccess to GitHub copilot\n\nFree tier available to everybody\nPro available free for students, teachers, maintainers of popular open-source projects\nPaid subscriptions for Pro and Pro+\n\nEmacs ‚â• 27\nNode.js ‚â• 22"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#installation",
    "href": "emacs/wb_llms_slides.html#installation",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "Installation",
    "text": "Installation\nInstall and load the package and dependency with your favourite method\nInstall the copilot server with M-x copilot-install-server\nLogin to Copilot with M-x copilot-login and follow the instructions\n\nYou can test the setup with M-x copilot-diagnose"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#my-setup-see-warning",
    "href": "emacs/wb_llms_slides.html#my-setup-see-warning",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "My setup (see warning)",
    "text": "My setup (see warning)\n;; dependency\n(straight-use-package 'editorconfig)\n\n(use-package copilot\n    :straight (:host github\n               :repo \"copilot-emacs/copilot.el\"\n               :files (\"dist\" \"*.el\"))\n    :bind ((\"C-8\" . copilot-complete)\n           (\"; j c\" . copilot-mode)\n           :map copilot-completion-map\n           (\"C-j\" . copilot-accept-completion)\n           (\"C-f\" . copilot-accept-completion-by-word)\n           (\"C-t\" . copilot-accept-completion-by-line)\n           (\"M-n\" . copilot-next-completion)\n           (\"M-p\" . copilot-previous-completion)))"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#requirements-1",
    "href": "emacs/wb_llms_slides.html#requirements-1",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "Requirements",
    "text": "Requirements\nAccess to GitHub copilot"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#functionality",
    "href": "emacs/wb_llms_slides.html#functionality",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "Functionality",
    "text": "Functionality\nChat with a model\n\nMarkdown or Org markup\nChats can be saved and restored\nBuffers can be added or removed as context\nCan choose model\n\nAI pair programming\n\nWrite tests\nExplain code/function at point/symbol at point\nReview code\nDocument code\nFix code\nOptimize code\nModify code\nCustomize prompts\n\nGenerate commit messages"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#my-setup-see-warning-1",
    "href": "emacs/wb_llms_slides.html#my-setup-see-warning-1",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "My setup (see warning)",
    "text": "My setup (see warning)\n;; dependency\n(straight-use-package 'magit)\n\n(use-package copilot-chat\n  :straight (:host github:repo \"chep/copilot-chat.el\" :files (\"*.el\"))\n  :after (org markdown-mode)\n  :bind ((\"; c c\" . copilot-chat)\n         (\"; c y\" . copilot-chat-yank)\n         (\"; c m\" . copilot-chat-set-model)\n         :map prog-mode-map\n         ;; explain symbol under point\n         (\"; c e s\" . copilot-chat-explain-symbol-at-line)\n         ;; explain function under point\n         (\"; c e f\" . copilot-chat-explain-defun)\n         ;; explain selected code\n         (\"; c e c\" . copilot-chat-explain)\n         ;; review selected code\n         (\"; c r c\" . copilot-chat-review)\n         ;; review current buffer\n         (\"; c r b\" . copilot-chat-review-whole-buffer)\n         ;; document selected code\n         (\"; c d\" . copilot-chat-doc)\n         ;; fix selected code\n         (\"; c f c\" . copilot-chat-fix)\n         ;; optimize selected code\n         (\"; c o\" . copilot-chat-optimize)\n         ;; write tests for selected code\n         (\"; c t\" . copilot-chat-test)\n         ;; apply a custom prompt to the function body under point\n         ;; (instruct on how to refactor the function)\n         (\"; c f f\" . copilot-chat-custom-prompt-function)\n         :map copilot-chat-org-prompt-mode-map\n         (\"C-&lt;return&gt;\" . copilot-chat-prompt-send)\n         :map org-mode-map\n         (\"; c g\" . copilot-chat-prompt-split-and-list)))"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#requirements-2",
    "href": "emacs/wb_llms_slides.html#requirements-2",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "Requirements",
    "text": "Requirements\nAPI key(s) for model(s), GitHub copilot, or model(s) running locally"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#functionality-1",
    "href": "emacs/wb_llms_slides.html#functionality-1",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "Functionality",
    "text": "Functionality\nChat in dedicated buffer or from any buffer\n\nMarkdown or Org markup\nChoose model\nAdd/remove context (including media)\nSet temperature\n\nA number of packages are built on top of gptel"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#my-setup-see-warning-2",
    "href": "emacs/wb_llms_slides.html#my-setup-see-warning-2",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "My setup (see warning)",
    "text": "My setup (see warning)\n(use-package gptel\n  :config\n  (setq\n   gptel-model 'gemini-2.5-pro\n   gptel-backend (gptel-make-gemini \"Gemini\"\n                   :key #'gptel-api-key-from-auth-source\n                   :stream t))\n  :bind ((\"; g g\" . gptel)\n         (\"; g s\" . gptel-send)\n         (\"; g m\" . gptel-menu)))"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#functionality-2",
    "href": "emacs/wb_llms_slides.html#functionality-2",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "Functionality",
    "text": "Functionality\nmcp.el integrates easily with gptel and copilot-chat.el\nThe LLMs you use can then access any MCP server you setup"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#my-setup-see-warning-3",
    "href": "emacs/wb_llms_slides.html#my-setup-see-warning-3",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "My setup (see warning)",
    "text": "My setup (see warning)\n\nI use the Context7 MCP server\n\n(use-package mcp\n  :after (:any gptel copilot-chat)\n  :custom (mcp-hub-servers\n           `((\"context7\" . (:command \"npx\"\n                :args (\"-y\" \"@upstash/context7-mcp@latest\" \"--api-key\" ,(auth-source-pick-first-password\n                                                                         :host \"context7_api_key\"\n                                                                         :user \"secret\"))))))\n  :config (require 'mcp-hub)\n  :hook (after-init . mcp-hub-start-all-server))"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#integration-with-gptel",
    "href": "emacs/wb_llms_slides.html#integration-with-gptel",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "Integration with gptel",
    "text": "Integration with gptel\nTo have gptel integrate with mcp.el and automatically use the servers you have set, add to the gptel :config declaration:\n(require 'gptel-integrations) ; always needed\n(gptel-mcp-connect)           ; to connect automatically\n\nAlternatively, you can call gptel-mcp-connect and gptel-mcp-disconnect to enable/disable servers manually"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#integration-with-copilot-chat.el",
    "href": "emacs/wb_llms_slides.html#integration-with-copilot-chat.el",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "Integration with copilot-chat.el",
    "text": "Integration with copilot-chat.el\nUse copilot-chat-set-mcp-servers to enable or disable servers"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#requirements-3",
    "href": "emacs/wb_llms_slides.html#requirements-3",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "Requirements",
    "text": "Requirements\nAPI key(s) for model(s) or local model(s)"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#functionality-3",
    "href": "emacs/wb_llms_slides.html#functionality-3",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "Functionality",
    "text": "Functionality\nChat in an Emacs shell\n\nChoose and swap models\nDescribe code\nProofread text\nWrite commits messages\nSave/restore transcripts"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#my-setup-see-warning-4",
    "href": "emacs/wb_llms_slides.html#my-setup-see-warning-4",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "My setup (see warning)",
    "text": "My setup (see warning)\n;; dependency\n(use-package shell-maker\n  :straight (:type git :host github :repo \"xenodium/shell-maker\"))\n\n(use-package chatgpt-shell\n  :straight (:type git :host github\n             :repo \"xenodium/chatgpt-shell\"\n             :files (\"chatgpt-shell*.el\"))\n  :init\n  (setq chatgpt-shell-google-key\n    (lambda ()\n      (auth-source-pick-first-password\n       :host \"google_api_key\" :user \"secret\")))\n  :bind (\"; c s\" . chatgpt-shell))"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#requirements-4",
    "href": "emacs/wb_llms_slides.html#requirements-4",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "Requirements",
    "text": "Requirements\nAPI key(s) for model(s) or local model(s)\nEmacs ‚â• 26.1\naider\ntransient"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#functionality-4",
    "href": "emacs/wb_llms_slides.html#functionality-4",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "Functionality",
    "text": "Functionality\nEdiff of AI-generated changes\nCustom prompts\nCode/chat/help/architect modes\nIntegrates with vterm\nAuto-detects project root\nVoice commands\nRetrieves web content\nWrites tests\nDebugs code\nWeak model for fast easy tasks\nTRAMP support\nEasy passing of aider options"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#my-setup-see-warning-5",
    "href": "emacs/wb_llms_slides.html#my-setup-see-warning-5",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "My setup (see warning)",
    "text": "My setup (see warning)\n(use-package aidermacs\n  :bind ((\"; c a\" . aidermacs-transient-menu))\n  :config\n  (setenv \"GOOGLE_API_KEY\" (auth-source-pick-first-password\n                :host \"google_api_key\"\n                :user \"secret\"))\n  :custom\n  (aidermacs-default-chat-mode 'architect)\n  (aidermacs-default-model \"gemini\"))"
  },
  {
    "objectID": "emacs/wb_llms_slides.html#alternative-aider.el",
    "href": "emacs/wb_llms_slides.html#alternative-aider.el",
    "title": "AI pair programming &LLMs chats in Emacs",
    "section": "Alternative: aider.el",
    "text": "Alternative: aider.el\naider.el is the initial project aidermacs was forked from\n\naider.el is closer to aider (the original CLI tool)\naidermacs integrates more into Emacs"
  },
  {
    "objectID": "emacs/wb_modes_content.html",
    "href": "emacs/wb_modes_content.html",
    "title": "Understanding Emacs modes",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "Understanding Emacs modes",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_modes_content.html#why-use-emacs",
    "href": "emacs/wb_modes_content.html#why-use-emacs",
    "title": "Understanding Emacs modes",
    "section": "Why use Emacs?",
    "text": "Why use Emacs?\n\n\n To brag.  Obviously.\n\n\n\n\n\n\nBut there are other reasons:\n\nFree and open source\nEndlessly customizable\nAmazing diff\nMacros\nText and file searching\nGreat programming IDE\nLossless and endless undo/redo\nFun!\n‚Ä¶",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "Understanding Emacs modes",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_modes_content.html#getting-started-can-be-daunting",
    "href": "emacs/wb_modes_content.html#getting-started-can-be-daunting",
    "title": "Understanding Emacs modes",
    "section": "Getting started can be daunting",
    "text": "Getting started can be daunting\n\n\n\n\n\nAnd it doesn‚Äôt necessarily get easier.\n\n\n\n\n\nBut it‚Äôs all worth it!",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "Understanding Emacs modes",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_modes_content.html#a-few-emacs-concepts",
    "href": "emacs/wb_modes_content.html#a-few-emacs-concepts",
    "title": "Understanding Emacs modes",
    "section": "A few Emacs concepts",
    "text": "A few Emacs concepts\n\nEmacs Lisp\nEmacs Lisp is a dialect of the Lisp programming language developed especially to write the editing functionality of the Emacs text editor (the rest of Emacs and its interpreter are written in C).\nEmacs is endlessly customizable to anyone with a basic knowledge of Emacs Lisp. In particular, variables and functions setting the behaviour and appearance of the text editor can be created or modified.\nThe language is well documented.\n\n\nGraphical display\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKeybindings (kbd)\n\n\n\nFrom Ecol LG #134 by Javier Malonda\n\n\n\n\nKbd notations\nC-c means press the Control key and the C key together.\nM-x means press the Alt (Windows) or Option (macOS) key and the X key together.\nC-c m means press the Control key and the C key together, then press the M key.\nC-c C-x m means press Ctl+C, then Ctl+X, then M.\nC-x C-c M-w C-m M-v M-t M-u means that you probably should choose another kbd.\n\n\nCommand execution\nA useful way to execute a command interactively, when it is not bound to a kbd, is to type M-x (this brings up the minibuffer, a place in which to type inputs) followed by the command name.\n\nFor example, M-x count-words will output the number of lines, sentences, words, and characters of the current buffer in the echo area.",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "Understanding Emacs modes",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_modes_content.html#time-to-talk-about-emacs-modes",
    "href": "emacs/wb_modes_content.html#time-to-talk-about-emacs-modes",
    "title": "Understanding Emacs modes",
    "section": "Time to talk about Emacs modes",
    "text": "Time to talk about Emacs modes\n\nMajor modes\nDifferent types of text require different behaviours, syntax highlighting, formatting, functions, variables, etc.\nEach type of buffer (e.g.¬†Python script, Markdown document, Julia REPL, Bash shell, directory editor, pdf) is associated with a different major mode.\nFile extensions, particular markers in the file, or other elements tell Emacs to automatically switch to the appropriate major mode.\nOnly one major mode is active at a time.\nSwitching to a different major mode is possible by running the corresponding major mode command (e.g.¬†M-x python-mode will switch to Python mode).\n\n\nFundamental mode\nfundamental-mode is the most basic major mode, with no particular feature.\nThis is the mode enabled by default if Emacs cannot detect what specific major mode to enable.\n\n\nMinor modes\nMinor modes provide additional and optional features that can be turned on or off (e.g.¬†spell checking, auto-completion, auto-indentation, fancy undo behaviour, fancy parenthesis matching highlighting).\nMinor modes can be turned on/off by running the corresponding minor mode commands (e.g.¬†M-x flyspell-mode will turn spell checking on/off). The command consult-minor-mode-menu from the package consult makes this particularly easy.\nEach mode comes with a set of commands. consult‚Äôs command consult-mode-command makes it easy to search for commands within each mode.\nAny number of minor modes can be active at the same time.\n\n\nList of enabled modes\nBy default, &lt;f1&gt; m or M-x describe-mode will open a list and description of the active modes.\nThe major mode can also be determined with &lt;f1&gt; v major-mode (&lt;f1&gt; v runs the command describe-variable).\nA list of minor modes can also be viewed with &lt;f1&gt; v minor-mode-list.\nAgain, consult‚Äôs consult-minor-mode-menu makes all this much nicer.\n\n\nThe mode line\nAnother way to get information about enabled modes is the mode line:\n\n\n\n\n\n\n\nHooks\nMinor modes can be automatically enabled when other modes (major or minor) are enabled thanks to hooks.\n\nFor example, to enable the aggressive indent minor mode whenever the ESS R major mode is enabled, you can add to your init file:\n\n(add-hook 'ess-r-mode-hook 'aggressive-indent-mode)\n\nOr, using use-package, now part of base Emacs:\n\n(use-package aggressive-indent\n:hook (ess-r-mode . aggressive-indent-mode))\n\n\nModes source code\nTo see the source code of a mode, run &lt;f1&gt; v (or M-x describe-variable) followed by the name of the mode map.\nThis will open a help buffer with a link to the source code file.\n\nFor example &lt;f1&gt; v text-mode-map will open a help buffer with a link to text-mode.el.\n\n\nThe help buffer opened by &lt;f1&gt; m or M-x describe-mode also gives a link to the source code of the major mode.\n\nLooking at the source code of a mode is very useful to customize it.\n\n\nCustomizing modes\nIn Emacs, everything is customizable.\nTo customize modes, you can write Emacs Lisp code in your init file (the configuration file that gets loaded when Emacs launches) or you can use the easy customization interface.\n\nFor example, to customize the Markdown major mode, you would run M-x customize-group markdown.\n\n\n\nEvaluation order\nIf you write your own Emacs code, be careful that functions and variables take the value of their last loaded version. The order in which Emacs code is evaluated thus matters.\nYou want to evaluate as little as possible when you launch Emacs to speed up start-up time (lazy evaluation): you don‚Äôt want to load every single package that you have installed.\nThis means that if you overwrite a function or variable of a mode in your init file, the init file is read at start-up, but when that mode is launched, the default function/variable will overwrite the custom one you wrote in your init file.\nTo by-pass this problem, you can use eval-after-load.\n\nExample:\n(eval-after-load\n \"markdown\"\n '(defun markdown-demote ()\n    ...))\n\n\nuse-package has the :init and :config keyword symbols that ensure that the following expressions are evaluated respectively before or after the loading of a package.\n\n\n\nCustomizing kbd\nMost modes come with specific keymaps: sets of kbd only active when the mode is enabled. These kbd of course can be customized.\n\nFor example, to modify the kbd for the function markdown-outline-previous in the markdown-mode-map:\n\n(define-key markdown-mode-map (kbd \"M-p\") 'markdown-outline-previous)\n\nOr, using use-package:\n\n(use-package markdown-mode\n    :bind (:map markdown-mode-map\n                (\"M-p\" . markdown-outline-previous)))\n\n\nPolymode\nWhile it is normally impossible to associate multiple major modes with a single buffer, Polymode allows to insert sections of a major mode within another major mode.\nThis is extremely convenient for instance to embed sections of code within human text, or even to have code executed within human text (e.g.¬†R Markdown or its successor Quarto, Org Babel).\nmarkdown-mode with snippets of julia-mode:\nJulia has \"assignment by operation\" operators:\n\n```{julia}\na = 2;\na += 7    # this is the same as a = a + 7\n```\n\nThere is a *left* division operator:\n\n```{julia}\n2\\8 == 8/2\n```\nRendered by Quarto into:",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "Understanding Emacs modes",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "emacs/wb_new_tools.html",
    "href": "emacs/wb_new_tools.html",
    "title": "Modern Emacs",
    "section": "",
    "text": "Emacs might have been created in the 70s, but development is alive and well:\n\n10 years ago version 24 brought huge speedups with lexical binding.\nIn 2022, version 28 added‚Äîamong other things‚Äîjust-in-time native compilation for elisp code for improved performance.\nVersion 29 last year brought countless exciting new additions such as official tree-sitter support and built-in Eglot and use-package.\nIn addition to Emacs itself, a profusion of modern packages have emerged over the past few years (e.g.¬†the vertico/consult/orderless/marginalia/embark completion system; corfu and cape for at point completion) bringing great speed and sleekness to the user experience.\n\nAll these features are optional however and you need to learn about them to take advantage of their huge benefits. This webinar intends to get you started making Emacs really fast.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "Emacs",
      "<b><em>Webinars</em></b>",
      "Modern, faster & better Emacs"
    ]
  },
  {
    "objectID": "emacs/wb_new_tools_slides.html#lexical-binding",
    "href": "emacs/wb_new_tools_slides.html#lexical-binding",
    "title": "Modern Emacs",
    "section": "Lexical binding",
    "text": "Lexical binding\nIntroduced in version 24\nLexical binding can be used instead of dynamic binding for Emacs Lisp code\nSet as a file local variable\n\nDynamic binding\nName resolution depends on program state (runtime context), determined at run time\nGlobal environment for all variables\nMakes modifying behaviour easy\n\n\nLexical binding\nName resolution depends on lexical context (static context), determined at compile time\nLocal environments of functions and let, defconst, defvar, etc. expressions\nMakes compiler optimization much easier ‚Üí faster Elisp code = faster Emacs"
  },
  {
    "objectID": "emacs/wb_new_tools_slides.html#jit-native-compilation",
    "href": "emacs/wb_new_tools_slides.html#jit-native-compilation",
    "title": "Modern Emacs",
    "section": "JIT native compilation",
    "text": "JIT native compilation\nIntroduced in version 28\nRequires libgccjit\nBuild Emacs --with-native-compilation\nPackages can also be compiled natively (automatic with straight)\n\nFaster startup\nSpeedup of 2.5 to 5 compared to corresponding byte-compiled code"
  },
  {
    "objectID": "emacs/wb_new_tools_slides.html#lazy-loading",
    "href": "emacs/wb_new_tools_slides.html#lazy-loading",
    "title": "Modern Emacs",
    "section": "Lazy loading",
    "text": "Lazy loading\nBuilt-in since version 29\nFine-tuned loading of packages with use-package\nIntegrates nicely with straight\n\nFaster startup time\nMore organized init file\nEasier to reload configurations for single package"
  },
  {
    "objectID": "emacs/wb_new_tools_slides.html#accurate-syntax-tree",
    "href": "emacs/wb_new_tools_slides.html#accurate-syntax-tree",
    "title": "Modern Emacs",
    "section": "Accurate syntax tree",
    "text": "Accurate syntax tree\nBuilt-in since version 29\nTree-sitter for Emacs\nCode is parsed accurately instead of using regexp\n\nPerfect syntax highlighting, indentation, and navigation\nFaster\n\nSimplest setup with treesit-auto:\n(use-package treesit-auto\n  :config\n  (treesit-auto-add-to-auto-mode-alist 'all))"
  },
  {
    "objectID": "emacs/wb_new_tools_slides.html#history-of-code-completion-in-emacs-ido",
    "href": "emacs/wb_new_tools_slides.html#history-of-code-completion-in-emacs-ido",
    "title": "Modern Emacs",
    "section": "History of code completion in Emacs: IDO",
    "text": "History of code completion in Emacs: IDO\n\n\n\nFrom Xah Emacs Blog"
  },
  {
    "objectID": "emacs/wb_new_tools_slides.html#history-of-code-completion-in-emacs-ido-vertical",
    "href": "emacs/wb_new_tools_slides.html#history-of-code-completion-in-emacs-ido-vertical",
    "title": "Modern Emacs",
    "section": "History of code completion in Emacs: IDO vertical",
    "text": "History of code completion in Emacs: IDO vertical\n\n\n\nFrom oremacs"
  },
  {
    "objectID": "emacs/wb_new_tools_slides.html#history-of-code-completion-in-emacs-helm",
    "href": "emacs/wb_new_tools_slides.html#history-of-code-completion-in-emacs-helm",
    "title": "Modern Emacs",
    "section": "History of code completion in Emacs: HELM",
    "text": "History of code completion in Emacs: HELM\n\n\n\nFrom oracleyue"
  },
  {
    "objectID": "emacs/wb_new_tools_slides.html#history-of-code-completion-in-emacs-ivy",
    "href": "emacs/wb_new_tools_slides.html#history-of-code-completion-in-emacs-ivy",
    "title": "Modern Emacs",
    "section": "History of code completion in Emacs: Ivy",
    "text": "History of code completion in Emacs: Ivy\nWith optional Counsel & Swiper\n\n\n\nFrom abo-abo/swiper"
  },
  {
    "objectID": "emacs/wb_new_tools_slides.html#new-framework",
    "href": "emacs/wb_new_tools_slides.html#new-framework",
    "title": "Modern Emacs",
    "section": "New framework",
    "text": "New framework\nExternal packages\nUse default Emacs functions (less code)\nFaster, flexible, customizable with discrete units"
  },
  {
    "objectID": "emacs/wb_new_tools_slides.html#packages",
    "href": "emacs/wb_new_tools_slides.html#packages",
    "title": "Modern Emacs",
    "section": "Packages",
    "text": "Packages\n\n\nMinibuffer\n\nvertico ‚ÄÉ‚ÄÉ¬†frontend completion UI\norderless ‚ÄÉbackend completion style\nconsult ‚ÄÉ‚ÄÉbackend completion functions\nmarginalia ‚ÄÇannotations\nembark ‚ÄÉ¬†¬†¬†actions on completion buffer\n\n\nIn buffer\n\ncorfu ‚ÄÉ‚ÄÉ¬†frontend completion UI\norderless ¬†backend completion style\ncape ‚ÄÉ‚ÄÉ‚ÄÇbackend completion functions\neglot ‚ÄÉ‚ÄÉ¬†¬†backend LSP client"
  },
  {
    "objectID": "emacs/wb_new_tools_slides.html#compared-to-previous-frameworks",
    "href": "emacs/wb_new_tools_slides.html#compared-to-previous-frameworks",
    "title": "Modern Emacs",
    "section": "Compared to previous frameworks",
    "text": "Compared to previous frameworks\n\nIntegrates beautifully with internal Emacs functions\nEasy jump back & forth between buffer and completion buffer\nMuch faster than HELM\nLightning fast previews with auto-closing buffers\nEasy customization"
  },
  {
    "objectID": "emacs/wb_new_tools_slides.html#example-configuration",
    "href": "emacs/wb_new_tools_slides.html#example-configuration",
    "title": "Modern Emacs",
    "section": "Example configuration",
    "text": "Example configuration\nVertico (frontend for completion in minibuffer)\n(use-package vertico\n  :init\n  (vertico-mode 1)\n  (vertico-multiform-mode 1)\n  :config\n  (setq vertico-multiform-commands\n    '((consult-line buffer)\n      (consult-line-thing-at-point buffer)\n      (consult-recent-file buffer)\n      (consult-mode-command buffer)\n      (consult-complex-command buffer)\n      (embark-bindings buffer)\n      (consult-locate buffer)\n      (consult-project-buffer buffer)\n      (consult-ripgrep buffer)\n      (consult-fd buffer)))\n  :bind (:map vertico-map\n          (\"C-k\" . kill-whole-line)\n          (\"C-u\" . kill-whole-line)\n          (\"C-o\" . vertico-next-group)\n          (\"&lt;tab&gt;\" . minibuffer-complete)\n          (\"M-&lt;return&gt;\" . minibuffer-force-complete-and-exit)))\n\n;; save search history\n(use-package savehist\n  :init\n  (savehist-mode 1))"
  },
  {
    "objectID": "emacs/wb_new_tools_slides.html#language-server-protocol-client",
    "href": "emacs/wb_new_tools_slides.html#language-server-protocol-client",
    "title": "Modern Emacs",
    "section": "Language Server Protocol client",
    "text": "Language Server Protocol client\nBuilt-in since version 29\nEglot (Emacs Polyglot) allows to connect to a programming language server\nExample: Julia\nNeed to install an LSP for Julia:\n(straight-use-package 'eglot-jl)\nThen run eglot-jl-init\nNow eglot in a Julia buffer connects to the server\n\nSimilarly, you can install an LSP for R or Python or any language and use Eglot with R, Python, or whatever language"
  },
  {
    "objectID": "emacs/wb_new_tools_slides.html#to-all-emacs-developers-and-maintainers",
    "href": "emacs/wb_new_tools_slides.html#to-all-emacs-developers-and-maintainers",
    "title": "Modern Emacs",
    "section": "‚ù§ to all Emacs developers and maintainers",
    "text": "‚ù§ to all Emacs developers and maintainers\nIn particular,\ndevelopers, maintainers, and contributors to Emacs core,\ndevelopers and maintainers to some of the mentioned packages:\nDaniel Mendler\nOmar Antol√≠n Camarena\nJo√£o T√°vora\nRobb Enzmann\nJohn Wiegley\nAdam B\nand all their contributors"
  },
  {
    "objectID": "git/col_pr.html",
    "href": "git/col_pr.html",
    "title": "Working without write access",
    "section": "",
    "text": "There are two situations in which you do not have write access to projects:\n\nyou are an outsider (i.e.¬†you are contributing to open source projects you are using, but you are not part of the team),\nyou are part of the team, but the person in charge wants a workflow via pull requests (PRs)‚Äîthis is often the case in large teams with a more top-down organization.\n\nThis section shows you how you can contribute to such projects.",
    "crumbs": [
      "Git",
      "<b><em>Collaborating on GitHub</em></b>",
      "Working without write access"
    ]
  },
  {
    "objectID": "git/col_pr.html#opening-issues",
    "href": "git/col_pr.html#opening-issues",
    "title": "Working without write access",
    "section": "Opening issues",
    "text": "Opening issues\nThe easiest thing to do is to open an issue.\nThis is a way to bring the attention of the maintainer(s) of the project to a particular question without attempting to directly address the problem.\nYou might open an issue for instance if:\n\nyou are having problems with an open source tool you are using,\nyou found a bug,\nyou want to suggest a new feature,\n(more applicable to the research collaboration framework) you want your team to address some question relevant to the project‚Äîan issue is a way to keep something in the mind of everyone involved until it is resolved and closed.\n\n\nIf enabled by the maintainer of a project, the Discussions tab is the place where you want to ask for help or discuss topics less directly pertinent to improving the project.",
    "crumbs": [
      "Git",
      "<b><em>Collaborating on GitHub</em></b>",
      "Working without write access"
    ]
  },
  {
    "objectID": "git/col_pr.html#submitting-changes",
    "href": "git/col_pr.html#submitting-changes",
    "title": "Working without write access",
    "section": "Submitting changes",
    "text": "Submitting changes\nIf you want to actually edit the content of a project you don‚Äôt have write-access to, you have to create a pull request (PR).\n\nIn GitLab, pull requests are called merge requests (MR), but the concepts are exactly the same.\n\n\nWorkflow summary\nThis is a multi-step process. Here is a summary that we will break down step by step below:\n\n\n\n\n\nflowchart TD\n  subgraph gh[\"&lt;b&gt;GitHub&lt;/b&gt;\"]\n    subgraph project[\"&lt;b&gt;Project&lt;/b&gt;\"]\n      upstream/main[\"&lt;b&gt;upstream/main&lt;/b&gt;\"]\n      upstream/dev[\"&lt;b&gt;upstream/dev&lt;/b&gt;\"]\n    end\n    subgraph fork[\"&lt;b&gt;Your fork&lt;/b&gt;\"]\n      origin/main[\"&lt;b&gt;origin/main&lt;/b&gt;\"]\n      origin/dev[\"&lt;b&gt;origin/dev&lt;/b&gt;\"]\n    end\n  end\n  subgraph local[\"&lt;b&gt;Your machine&lt;/b&gt;\"]\n    subgraph clone[\"&lt;b&gt;Your clone&lt;/b&gt;\"]\n      main[\"&lt;b&gt;main&lt;/b&gt;\"]\n      dev[\"&lt;b&gt;dev&lt;/b&gt;\"]\n    end\n  end\n\n  classDef location fill:#bfbfbf, color:#000;\n  class gh location;\n  class local location;\n  classDef repo fill:#85adad, color:#000;\n  class project repo;\n  class fork repo;\n  class clone repo;\n\n  upstream/main == GitHub Fork ==&gt;  origin/main\n  origin/main == git clone ==&gt; main\n  upstream/main == git pull upstream main ==&gt; main\n  main -- git push origin main --&gt; origin/main\n  main == git switch -c dev ==&gt; dev\n  dev == git push origin dev ==&gt; origin/dev\n  origin/dev == GitHub PR ==&gt; upstream/dev\n  upstream/dev -. PR merged by maintainer .-&gt; upstream/main\n\n  linkStyle 0 stroke:YellowGreen;\n  linkStyle 1 stroke:YellowGreen, color:magenta;\n  linkStyle 2 stroke:goldenrod, color:magenta;\n  linkStyle 3 stroke:sienna, color:magenta;\n  linkStyle 4 stroke:goldenrod, color:magenta;\n  linkStyle 5 stroke:goldenrod, color:magenta;\n  linkStyle 6 stroke:goldenrod;\n  linkStyle 7 stroke:CornflowerBlue, stroke-width:4px;\n\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n  subgraph legend[\"&lt;b&gt;Legend&lt;/b&gt;\"]\n    direction LR\n    start1[ ] ===&gt;|To do before first PR| stop1[ ]\n    style start1 height:0px;\n    style stop1 height:0px;\n    start2[ ] ===&gt;|To do for each PR| stop2[ ]\n    style start2 height:0px;\n    style stop2 height:0px;\n    start3[ ] ---&gt;|\"(Optional) If you want to keep your fork up to date\"| stop3[ ]\n    style start3 height:0px;\n    style stop3 height:0px;\n\n    style legend fill:#fff, color:grey;\n\n    linkStyle 0 stroke:YellowGreen, color:grey;\n    linkStyle 1 stroke:goldenrod, color:grey;\n    linkStyle 2 stroke:sienna, color:grey;\n  end\n\n\n The pull request workflow‚ÄÇ \n\n\n\n\n‚ÄúProject‚Äù = the project you want to contribute to\n‚ÄúYour fork‚Äù = your fork of the project\n‚ÄúYour clone‚Äù = your local clone of the project (cloned from origin)\n‚Äúdev‚Äù = a new branch you create and switch to before committing changes\n‚Äúupstream‚Äù = the name of the remote corresponding to the original project\n‚Äúorigin‚Äù = the name of the remote you can push to (your fork)\n\n\n\nWorkflow step by step\n\nSetup\nBefore you can submit PRs, there are two steps that you need to do to set things up.\n\nFork the project\nFirst, create a fork of the project. This will make a copy of the repository into your GitHub account: go to GitHub and fork the project by clicking on the Fork button in the top right corner:\n\n\n\n\n\nflowchart TD\n  subgraph gh[\"&lt;b&gt;GitHub&lt;/b&gt;\"]\n    subgraph project[\"&lt;b&gt;Project&lt;/b&gt;\"]\n      upstream/main[\"&lt;b&gt;upstream/main&lt;/b&gt;\"]\n      upstream/dev[\"&lt;b&gt;upstream/dev&lt;/b&gt;\"]\n    end\n    subgraph fork[\"&lt;b&gt;Your fork&lt;/b&gt;\"]\n      origin/main[\"&lt;b&gt;origin/main&lt;/b&gt;\"]\n      origin/dev[\"&lt;b&gt;origin/dev&lt;/b&gt;\"]\n    end\n  end\n  subgraph local[\"&lt;b&gt;Your machine&lt;/b&gt;\"]\n    subgraph clone[\"&lt;b&gt;Your clone&lt;/b&gt;\"]\n      main[\"&lt;b&gt;main&lt;/b&gt;\"]\n      dev[\"&lt;b&gt;dev&lt;/b&gt;\"]\n    end\n  end\n\n  classDef location fill:#bfbfbf, color:#000;\n  class gh location;\n  class local location;\n  classDef repo fill:#85adad, color:#000;\n  class project repo;\n  class fork repo;\n  class clone repo;\n\n  upstream/main == GitHub Fork ==&gt;  origin/main\n  origin/main ~~~ main\n  upstream/main ~~~ main\n  main ~~~ origin/main\n  main ~~~ dev\n  dev ~~~ origin/dev\n  origin/dev ~~~ upstream/dev\n  upstream/dev ~~~ upstream/main\n\n  linkStyle 0 stroke:YellowGreen;\n  linkStyle 1 stroke:YellowGreen, color:magenta;\n  linkStyle 2 stroke:goldenrod, color:magenta;\n  linkStyle 3 stroke:sienna, color:magenta;\n  linkStyle 4 stroke:goldenrod, color:magenta;\n  linkStyle 5 stroke:goldenrod, color:magenta;\n  linkStyle 6 stroke:goldenrod;\n\n\n\n\n\n\n\nIf you want to develop your own version of the project, you can keep working on your fork and develop it in a direction different from that of the initial project. You have all privileges on the forked project: your fork is your repo. This means that you can make any changes you want. You can clone it to your machine, create commits and push them back to your fork.\nHere however, we want to submit changes to the original project.\n\n\n\nClone your fork\nThen clone your fork to your machine to have a local copy of the project. This will automatically set your fork on GitHub as a remote called origin.\nSince origin is your fork, you can freely pull from and push to it.\n# If you have set SSH for your GitHub account\ngit clone git@github.com:&lt;user&gt;/&lt;repo&gt;.git &lt;name&gt;\n\n# If you haven't set SSH\ngit clone https://github.com/&lt;user&gt;/&lt;repo&gt;.git &lt;name&gt;\n\n\n\n\n\nflowchart TD\n  subgraph gh[\"&lt;b&gt;GitHub&lt;/b&gt;\"]\n    subgraph project[\"&lt;b&gt;Project&lt;/b&gt;\"]\n      upstream/main[\"&lt;b&gt;upstream/main&lt;/b&gt;\"]\n      upstream/dev[\"&lt;b&gt;upstream/dev&lt;/b&gt;\"]\n    end\n    subgraph fork[\"&lt;b&gt;Your fork&lt;/b&gt;\"]\n      origin/main[\"&lt;b&gt;origin/main&lt;/b&gt;\"]\n      origin/dev[\"&lt;b&gt;origin/dev&lt;/b&gt;\"]\n    end\n  end\n  subgraph local[\"&lt;b&gt;Your machine&lt;/b&gt;\"]\n    subgraph clone[\"&lt;b&gt;Your clone&lt;/b&gt;\"]\n      main[\"&lt;b&gt;main&lt;/b&gt;\"]\n      dev[\"&lt;b&gt;dev&lt;/b&gt;\"]\n    end\n  end\n\n  classDef location fill:#bfbfbf, color:#000;\n  class gh location;\n  class local location;\n  classDef repo fill:#85adad, color:#000;\n  class project repo;\n  class fork repo;\n  class clone repo;\n\n  upstream/main ~~~  origin/main\n  origin/main == git clone ==&gt; main\n  upstream/main ~~~ main\n  main ~~~ origin/main\n  main ~~~ dev\n  dev ~~~ origin/dev\n  origin/dev ~~~ upstream/dev\n  upstream/dev ~~~ upstream/main\n\n  linkStyle 0 stroke:YellowGreen;\n  linkStyle 1 stroke:YellowGreen, color:magenta;\n  linkStyle 2 stroke:goldenrod, color:magenta;\n  linkStyle 3 stroke:sienna, color:magenta;\n  linkStyle 4 stroke:goldenrod, color:magenta;\n  linkStyle 5 stroke:goldenrod, color:magenta;\n  linkStyle 6 stroke:goldenrod;\n\n\n\n\n\n\n\n\n\nCreate a PR\nCreating a PR is a four-step process.\n\n1. Update your local repo\nYou need to make sure that your local copy of the repo is up to date by pulling from upstream.\n\nAdd upstream\nAdd a second remote, this one pointing to the initial project. It is usual to call this remote upstream:\n# If you have set SSH for your GitHub account\ngit remote add upstream git@github.com:&lt;user&gt;/&lt;repo&gt;.git\n\n# If you haven't set SSH\ngit remote add upstream https://github.com/&lt;user&gt;/&lt;repo&gt;.git\n\n\nPull from upstream\nYou can now pull from upstream to keep your local repo up to date:\ngit pull upstream main\n\n\n\n\n\nflowchart TD\n  subgraph gh[\"&lt;b&gt;GitHub&lt;/b&gt;\"]\n    subgraph project[\"&lt;b&gt;Project&lt;/b&gt;\"]\n      upstream/main[\"&lt;b&gt;upstream/main&lt;/b&gt;\"]\n      upstream/dev[\"&lt;b&gt;upstream/dev&lt;/b&gt;\"]\n    end\n    subgraph fork[\"&lt;b&gt;Your fork&lt;/b&gt;\"]\n      origin/main[\"&lt;b&gt;origin/main&lt;/b&gt;\"]\n      origin/dev[\"&lt;b&gt;origin/dev&lt;/b&gt;\"]\n    end\n  end\n  subgraph local[\"&lt;b&gt;Your machine&lt;/b&gt;\"]\n    subgraph clone[\"&lt;b&gt;Your clone&lt;/b&gt;\"]\n      main[\"&lt;b&gt;main&lt;/b&gt;\"]\n      dev[\"&lt;b&gt;dev&lt;/b&gt;\"]\n    end\n  end\n\n  classDef location fill:#bfbfbf, color:#000;\n  class gh location;\n  class local location;\n  classDef repo fill:#85adad, color:#000;\n  class project repo;\n  class fork repo;\n  class clone repo;\n\n  upstream/main ~~~  origin/main\n  origin/main ~~~ main\n  upstream/main == git pull upstream main ==&gt; main\n  main ~~~ origin/main\n  main ~~~ dev\n  dev ~~~ origin/dev\n  origin/dev ~~~ upstream/dev\n  upstream/dev ~~~ upstream/main\n\n  linkStyle 0 stroke:YellowGreen;\n  linkStyle 1 stroke:YellowGreen, color:magenta;\n  linkStyle 2 stroke:goldenrod, color:magenta;\n  linkStyle 3 stroke:sienna, color:magenta;\n  linkStyle 4 stroke:goldenrod, color:magenta;\n  linkStyle 5 stroke:goldenrod, color:magenta;\n  linkStyle 6 stroke:goldenrod;\n\n\n\n\n\n\n\nOf course, if your local copy and the initial project have diverged in places, this will lead to conflicts that you will have to resolve as you merge the pulls from upstream.\n\nNote that, while you can pull freely from upstream, you can‚Äôt push changes back to it directly since you don‚Äôt have write access to the initial project (if anybody could push to any project, that would be utter chaos).\n\n\n\n2. Switch to new branch\nYou don‚Äôt want to create the changes for your PR on main: if the PR is rejected by the maintainer of the project or if they are taking time to accept it, you would then be stuck not knowing how to add new changes to your project.\nIt is much better to create a new branch for the changes you want to submit to the project as a PR (don‚Äôt forget to switch to that branch before committing the changes):\n\n\n\n\n\nflowchart TD\n  subgraph gh[\"&lt;b&gt;GitHub&lt;/b&gt;\"]\n    subgraph project[\"&lt;b&gt;Project&lt;/b&gt;\"]\n      upstream/main[\"&lt;b&gt;upstream/main&lt;/b&gt;\"]\n      upstream/dev[\"&lt;b&gt;upstream/dev&lt;/b&gt;\"]\n    end\n    subgraph fork[\"&lt;b&gt;Your fork&lt;/b&gt;\"]\n      origin/main[\"&lt;b&gt;origin/main&lt;/b&gt;\"]\n      origin/dev[\"&lt;b&gt;origin/dev&lt;/b&gt;\"]\n    end\n  end\n  subgraph local[\"&lt;b&gt;Your machine&lt;/b&gt;\"]\n    subgraph clone[\"&lt;b&gt;Your clone&lt;/b&gt;\"]\n      main[\"&lt;b&gt;main&lt;/b&gt;\"]\n      dev[\"&lt;b&gt;dev&lt;/b&gt;\"]\n    end\n  end\n\n  classDef location fill:#bfbfbf, color:#000;\n  class gh location;\n  class local location;\n  classDef repo fill:#85adad, color:#000;\n  class project repo;\n  class fork repo;\n  class clone repo;\n\n  upstream/main ~~~  origin/main\n  origin/main ~~~ main\n  upstream/main ~~~ main\n  main ~~~ origin/main\n  main == git switch -c dev ==&gt; dev\n  dev ~~~ origin/dev\n  origin/dev ~~~ upstream/dev\n  upstream/dev ~~~ upstream/main\n\n  linkStyle 0 stroke:YellowGreen;\n  linkStyle 1 stroke:YellowGreen, color:magenta;\n  linkStyle 2 stroke:goldenrod, color:magenta;\n  linkStyle 3 stroke:sienna, color:magenta;\n  linkStyle 4 stroke:goldenrod, color:magenta;\n  linkStyle 5 stroke:goldenrod, color:magenta;\n  linkStyle 6 stroke:goldenrod;\n\n\n\n\n\n\n\n\n3. Push changes to origin\nMake your changes, commit, then push your branch to origin:\n\n\n\n\n\nflowchart TD\n  subgraph gh[\"&lt;b&gt;GitHub&lt;/b&gt;\"]\n    subgraph project[\"&lt;b&gt;Project&lt;/b&gt;\"]\n      upstream/main[\"&lt;b&gt;upstream/main&lt;/b&gt;\"]\n      upstream/dev[\"&lt;b&gt;upstream/dev&lt;/b&gt;\"]\n    end\n    subgraph fork[\"&lt;b&gt;Your fork&lt;/b&gt;\"]\n      origin/main[\"&lt;b&gt;origin/main&lt;/b&gt;\"]\n      origin/dev[\"&lt;b&gt;origin/dev&lt;/b&gt;\"]\n    end\n  end\n  subgraph local[\"&lt;b&gt;Your machine&lt;/b&gt;\"]\n    subgraph clone[\"&lt;b&gt;Your clone&lt;/b&gt;\"]\n      main[\"&lt;b&gt;main&lt;/b&gt;\"]\n      dev[\"&lt;b&gt;dev&lt;/b&gt;\"]\n    end\n  end\n\n  classDef location fill:#bfbfbf, color:#000;\n  class gh location;\n  class local location;\n  classDef repo fill:#85adad, color:#000;\n  class project repo;\n  class fork repo;\n  class clone repo;\n\n  upstream/main ~~~  origin/main\n  origin/main ~~~ main\n  upstream/main ~~~ main\n  main ~~~ origin/main\n  main ~~~ dev\n  dev == git push origin dev ==&gt; origin/dev\n  origin/dev ~~~ upstream/dev\n  upstream/dev ~~~ upstream/main\n\n  linkStyle 0 stroke:YellowGreen;\n  linkStyle 1 stroke:YellowGreen, color:magenta;\n  linkStyle 2 stroke:goldenrod, color:magenta;\n  linkStyle 3 stroke:sienna, color:magenta;\n  linkStyle 4 stroke:goldenrod, color:magenta;\n  linkStyle 5 stroke:goldenrod, color:magenta;\n  linkStyle 6 stroke:goldenrod;\n\n\n\n\n\n\n\n\n4. Submit a PR\nAfter you have pushed your branch to origin, go to your fork on GitHub: GitHub will automatically offer to submit a PR in a pop-up and you can just follow the instructions:\n\n\n\n\n\nflowchart TD\n  subgraph gh[\"&lt;b&gt;GitHub&lt;/b&gt;\"]\n    subgraph project[\"&lt;b&gt;Project&lt;/b&gt;\"]\n      upstream/main[\"&lt;b&gt;upstream/main&lt;/b&gt;\"]\n      upstream/dev[\"&lt;b&gt;upstream/dev&lt;/b&gt;\"]\n    end\n    subgraph fork[\"&lt;b&gt;Your fork&lt;/b&gt;\"]\n      origin/main[\"&lt;b&gt;origin/main&lt;/b&gt;\"]\n      origin/dev[\"&lt;b&gt;origin/dev&lt;/b&gt;\"]\n    end\n  end\n  subgraph local[\"&lt;b&gt;Your machine&lt;/b&gt;\"]\n    subgraph clone[\"&lt;b&gt;Your clone&lt;/b&gt;\"]\n      main[\"&lt;b&gt;main&lt;/b&gt;\"]\n      dev[\"&lt;b&gt;dev&lt;/b&gt;\"]\n    end\n  end\n\n  classDef location fill:#bfbfbf, color:#000;\n  class gh location;\n  class local location;\n  classDef repo fill:#85adad, color:#000;\n  class project repo;\n  class fork repo;\n  class clone repo;\n\n  upstream/main ~~~  origin/main\n  origin/main ~~~ main\n  upstream/main ~~~ main\n  main ~~~ origin/main\n  main ~~~ dev\n  dev ~~~ origin/dev\n  origin/dev == GitHub PR ==&gt; upstream/dev\n  upstream/dev ~~~ upstream/main\n\n  linkStyle 0 stroke:YellowGreen;\n  linkStyle 1 stroke:YellowGreen, color:magenta;\n  linkStyle 2 stroke:goldenrod, color:magenta;\n  linkStyle 3 stroke:sienna, color:magenta;\n  linkStyle 4 stroke:goldenrod, color:magenta;\n  linkStyle 5 stroke:goldenrod, color:magenta;\n  linkStyle 6 stroke:goldenrod;\n\n\n\n\n\n\nThe maintainer of the initial project may accept or decline the PR. They may also make comments and ask you to make changes. If so, make new changes and push additional commits to that branch until they are happy with the change.\nOnce/if the maintainer accepts the PR, they merge it to the main branch in the project:\n\n\n\n\n\nflowchart TD\n  subgraph gh[\"&lt;b&gt;GitHub&lt;/b&gt;\"]\n    subgraph project[\"&lt;b&gt;Project&lt;/b&gt;\"]\n      upstream/main[\"&lt;b&gt;upstream/main&lt;/b&gt;\"]\n      upstream/dev[\"&lt;b&gt;upstream/dev&lt;/b&gt;\"]\n    end\n    subgraph fork[\"&lt;b&gt;Your fork&lt;/b&gt;\"]\n      origin/main[\"&lt;b&gt;origin/main&lt;/b&gt;\"]\n      origin/dev[\"&lt;b&gt;origin/dev&lt;/b&gt;\"]\n    end\n  end\n  subgraph local[\"&lt;b&gt;Your machine&lt;/b&gt;\"]\n    subgraph clone[\"&lt;b&gt;Your clone&lt;/b&gt;\"]\n      main[\"&lt;b&gt;main&lt;/b&gt;\"]\n      dev[\"&lt;b&gt;dev&lt;/b&gt;\"]\n    end\n  end\n\n  classDef location fill:#bfbfbf, color:#000;\n  class gh location;\n  class local location;\n  classDef repo fill:#85adad, color:#000;\n  class project repo;\n  class fork repo;\n  class clone repo;\n\n  upstream/main ~~~  origin/main\n  origin/main ~~~ main\n  upstream/main ~~~ main\n  main ~~~ origin/main\n  main ~~~ dev\n  dev ~~~ origin/dev\n  origin/dev ~~~ upstream/dev\n  upstream/dev -. PR merged by maintainer .-&gt; upstream/main\n\n  linkStyle 0 stroke:YellowGreen;\n  linkStyle 1 stroke:YellowGreen, color:magenta;\n  linkStyle 2 stroke:goldenrod, color:magenta;\n  linkStyle 3 stroke:sienna, color:magenta;\n  linkStyle 4 stroke:goldenrod, color:magenta;\n  linkStyle 5 stroke:goldenrod, color:magenta;\n  linkStyle 6 stroke:goldenrod;\n  linkStyle 7 stroke:CornflowerBlue, stroke-width:4px;\n\n\n\n\n\n\nCongratulations: you have successfully contributed changes to the project. üôÇ\nYou can now delete the branch you created for this PR (GitHub will offer you to do so on your fork with a pop-up). You can also delete it on your local repo with:\ngit branch -d dev  # use the name you chose for your branch\n\n\n\n(Optional) Update your fork\nOptionally, if you want to keep your fork up to date, you should pull from upstream to integrate the new changes to your local repo:\n\n\n\n\n\nflowchart TD\n  subgraph gh[\"&lt;b&gt;GitHub&lt;/b&gt;\"]\n    subgraph project[\"&lt;b&gt;Project&lt;/b&gt;\"]\n      upstream/main[\"&lt;b&gt;upstream/main&lt;/b&gt;\"]\n      upstream/dev[\"&lt;b&gt;upstream/dev&lt;/b&gt;\"]\n    end\n    subgraph fork[\"&lt;b&gt;Your fork&lt;/b&gt;\"]\n      origin/main[\"&lt;b&gt;origin/main&lt;/b&gt;\"]\n      origin/dev[\"&lt;b&gt;origin/dev&lt;/b&gt;\"]\n    end\n  end\n  subgraph local[\"&lt;b&gt;Your machine&lt;/b&gt;\"]\n    subgraph clone[\"&lt;b&gt;Your clone&lt;/b&gt;\"]\n      main[\"&lt;b&gt;main&lt;/b&gt;\"]\n      dev[\"&lt;b&gt;dev&lt;/b&gt;\"]\n    end\n  end\n\n  classDef location fill:#bfbfbf, color:#000;\n  class gh location;\n  class local location;\n  classDef repo fill:#85adad, color:#000;\n  class project repo;\n  class fork repo;\n  class clone repo;\n\n  upstream/main ~~~  origin/main\n  origin/main ~~~ main\n  upstream/main -- git pull upstream main --&gt; main\n  main ~~~ origin/main\n  main ~~~ dev\n  dev ~~~ origin/dev\n  origin/dev ~~~ upstream/dev\n  upstream/dev ~~~ upstream/main\n\n  linkStyle 0 stroke:YellowGreen;\n  linkStyle 1 stroke:YellowGreen, color:magenta;\n  linkStyle 2 stroke:sienna, color:magenta;\n  linkStyle 3 stroke:sienna, color:magenta;\n  linkStyle 4 stroke:goldenrod, color:magenta;\n  linkStyle 5 stroke:goldenrod, color:magenta;\n  linkStyle 6 stroke:goldenrod;\n\n\n\n\n\n\nThen you should push those changes back to your fork:\n\n\n\n\n\nflowchart TD\n  subgraph gh[\"&lt;b&gt;GitHub&lt;/b&gt;\"]\n    subgraph project[\"&lt;b&gt;Project&lt;/b&gt;\"]\n      upstream/main[\"&lt;b&gt;upstream/main&lt;/b&gt;\"]\n      upstream/dev[\"&lt;b&gt;upstream/dev&lt;/b&gt;\"]\n    end\n    subgraph fork[\"&lt;b&gt;Your fork&lt;/b&gt;\"]\n      origin/main[\"&lt;b&gt;origin/main&lt;/b&gt;\"]\n      origin/dev[\"&lt;b&gt;origin/dev&lt;/b&gt;\"]\n    end\n  end\n  subgraph local[\"&lt;b&gt;Your machine&lt;/b&gt;\"]\n    subgraph clone[\"&lt;b&gt;Your clone&lt;/b&gt;\"]\n      main[\"&lt;b&gt;main&lt;/b&gt;\"]\n      dev[\"&lt;b&gt;dev&lt;/b&gt;\"]\n    end\n  end\n\n  classDef location fill:#bfbfbf, color:#000;\n  class gh location;\n  class local location;\n  classDef repo fill:#85adad, color:#000;\n  class project repo;\n  class fork repo;\n  class clone repo;\n\n  upstream/main ~~~  origin/main\n  origin/main ~~~ main\n  upstream/main ~~~ main\n  main -- git push origin main --&gt; origin/main\n  main ~~~ dev\n  dev ~~~ origin/dev\n  origin/dev ~~~ upstream/dev\n  upstream/dev ~~~ upstream/main\n\n  linkStyle 0 stroke:YellowGreen;\n  linkStyle 1 stroke:YellowGreen, color:magenta;\n  linkStyle 2 stroke:goldenrod, color:magenta;\n  linkStyle 3 stroke:sienna, color:magenta;\n  linkStyle 4 stroke:goldenrod, color:magenta;\n  linkStyle 5 stroke:goldenrod, color:magenta;\n  linkStyle 6 stroke:goldenrod;",
    "crumbs": [
      "Git",
      "<b><em>Collaborating on GitHub</em></b>",
      "Working without write access"
    ]
  },
  {
    "objectID": "git/index.html",
    "href": "git/index.html",
    "title": "Git",
    "section": "",
    "text": "Getting started with ¬†\nA course on version control\n\n\n\n\nCollaborating on ¬†\nA course on collaborative workflows\n\n\n\n\n\n\nWorkshops\nVarious Git topics\n\n\n\n\n60 min webinars\nVarious Git topics",
    "crumbs": [
      "Git",
      "<br>&nbsp;<img src=\"img/logo_git.png\" class=\"img-fluid\" style=\"width:1.5em\" alt=\"noshadow\"><br><br>"
    ]
  },
  {
    "objectID": "git/intro_branches.html",
    "href": "git/intro_branches.html",
    "title": "Branches",
    "section": "",
    "text": "One of the reasons Git has become so popular is its branching system: unlike in other version control tools in which creating branches is a lengthy and expensive process involving heavy copies, a branch in Git is just a lightweight pointer to a commit. This makes creating branches extremely quick and cheap.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Branches"
    ]
  },
  {
    "objectID": "git/intro_branches.html#what-is-a-branch",
    "href": "git/intro_branches.html#what-is-a-branch",
    "title": "Branches",
    "section": "What is a branch?",
    "text": "What is a branch?\nA branch is a pointer to a commit (under the hood, it is a small file containing the 40 character hash checksum of the commit it points to).\nRemember that little pointer called main? That‚Äôs our main branch: the one Git creates automatically when we create our first commit.\nWhen you run git status and get ‚ÄúOn branch main‚Äù in the output, or when you run git log and see ‚Äú(HEAD -&gt; main)‚Äù in the log, it means that the HEAD pointer (your position in the Git history) points to the branch main (which itself points to a commit).\n\nI know that is a lot of pointers ‚Ä¶ but this is really what makes Git so nimble, powerful, and fantastic. Because these pointers are very cheap (tiny files) and so useful.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Branches"
    ]
  },
  {
    "objectID": "git/intro_branches.html#why-use-multiple-branches",
    "href": "git/intro_branches.html#why-use-multiple-branches",
    "title": "Branches",
    "section": "Why use multiple branches?",
    "text": "Why use multiple branches?\nBranches are useful in so many situations:\n\nIf your changes break code, you still have a fully functional branch to go back to if needed.\nIf you develop a tool being used, this allows you to experiment with new features until they are ready without messing up with the working project.\nYou can create a branch for each alternative approach. This allows you to jump back and forth between various alternatives.\nYou can work on different aspects of the project on different branches. This prevents having messy incomplete work all over the place on the same branch.\nIf you want to revisit an old commit, you can create a branch there and switch to it instead of moving HEAD (creating a detached HEAD situation). This way, if you decide to create new commits from that old one, you don‚Äôt risk loosing them.\nBranches are great for collaboration: each person can work on their own branch and merge it back to the main branch when they are done with one section of a project.\n\nAnd since branches are so cheap to create, there is no downside to their creation.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Branches"
    ]
  },
  {
    "objectID": "git/intro_branches.html#creating-branches-and-switching-between-branches",
    "href": "git/intro_branches.html#creating-branches-and-switching-between-branches",
    "title": "Branches",
    "section": "Creating branches and switching between branches",
    "text": "Creating branches and switching between branches\nYou can create a new branch with:\ngit branch &lt;new-branch-name&gt;\n\nExample:\n\ngit branch test\n\nand you can then switch to it with:\ngit switch &lt;new-branch-name&gt;\n\nExample:\n\ngit switch test\n\nAlternatively, you can do both at once with the convenient:\ngit switch -c &lt;new-branch-name&gt;\n\n-c flag for ‚Äúcreate‚Äù. So you create a branch and switch to it directly.\n\nI find this last command most useful as it is all too easy otherwise to create a new branch, forget to switch to it, and create commits on the wrong branch ‚Ä¶",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Branches"
    ]
  },
  {
    "objectID": "git/intro_branches.html#listing-branches",
    "href": "git/intro_branches.html#listing-branches",
    "title": "Branches",
    "section": "Listing branches",
    "text": "Listing branches\ngit branch\n  main\n* test\nThe * shows the branch you are currently on (i.e.¬†the branch to which HEAD points to). In our example, the project has two branches and we are on the branch test.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Branches"
    ]
  },
  {
    "objectID": "git/intro_branches.html#comparing-branches",
    "href": "git/intro_branches.html#comparing-branches",
    "title": "Branches",
    "section": "Comparing branches",
    "text": "Comparing branches\nYou can use git diff to compare branches:\ngit diff main test\nThis shows all the lines that have been modified (added or deleted) between the commits both branches point to.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Branches"
    ]
  },
  {
    "objectID": "git/intro_branches.html#merging-branches",
    "href": "git/intro_branches.html#merging-branches",
    "title": "Branches",
    "section": "Merging branches",
    "text": "Merging branches\nWhen you are happy with the changes you made on your test branch, you can merge it into main.\n\nFast-forward merge\nIf you have only created new commits on the branch test, the merge is called a ‚Äúfast-forward merge‚Äù because main and test have not diverged: it is simply a question of having main catch up to test.\n\nFirst, you switch to main:\ngit switch main\n\nThen you do the fast-forward merge:\ngit merge test\n\nThen, usually, you delete the branch test as it has served its purpose:\ngit branch -d test\n\nAlternatively, you can switch back to test and do the next bit of experimental work on it. This allows to keep main free of mishaps and bad developments.\n\n\nThree-way merge\nIf the branches have diverged (you created commits on both branches), the merge requires the creation of an additional commit called a ‚Äúmerge commit‚Äù.\nLet‚Äôs go back to our situation before we created the branch test:\n\nThis time, you create a branch called test2:\n\nand you switch to it:\n\nThen you create some commits:\n\n\nNow you switch back to main:\n\nAnd you create commits from main too:\n\n\nTo merge your branch test2 into main, a new commit is now required. Git will create this new commit automatically. As long as there is no conflict, it is just as easy as a fast-forward merge:\ngit merge test2\n\nAfter which, you can delete the (now useless) test branch (with git branch -d test2):",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Branches"
    ]
  },
  {
    "objectID": "git/intro_branches.html#resolving-conflicts",
    "href": "git/intro_branches.html#resolving-conflicts",
    "title": "Branches",
    "section": "Resolving conflicts",
    "text": "Resolving conflicts\nGit works line by line. As long as you aren‚Äôt working on the same line(s) of the same file(s) on different branches, there will not be any merging difficulty. If however you modified one or more of the same line(s) of the same file(s) on different branches, Git has no way to decide which version should be kept and will thus not be able to complete the merge. It will then ask you to resolve the conflict(s). Conveniently, it will list the file(s) containing the conflict(s).\nThere are fancy tools to resolve conflicts, but you can do it in any text editor: simply open the file(s) listed by Git as having conflicts and look for the following markers:\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nThis is your version.\n=======\nThis is the alternative version of the same section of the file.\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; alternative version\nIn our case, it could look something like:\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nGreat sentence.\n=======\nGreat sentence with some variations.\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; test2\nThese markers are added by Git to signal the areas of conflict. It is up to you to choose between the two versions (or create a third one) and remove the conflict markers. After that, you can stage the file(s) which contained the conflicts to finish the merge (and then you can commit).",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Branches"
    ]
  },
  {
    "objectID": "git/intro_documentation.html",
    "href": "git/intro_documentation.html",
    "title": "Documentation",
    "section": "",
    "text": "Git comes with internal documentation. This section covers how to access it.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Documentation"
    ]
  },
  {
    "objectID": "git/intro_documentation.html#manual-pages",
    "href": "git/intro_documentation.html#manual-pages",
    "title": "Documentation",
    "section": "Manual pages",
    "text": "Manual pages\nThe manual page for any Git command can be open with:\ngit help &lt;command&gt;\n\nExample:\n\ngit help commit\nOn Unix systems (Linux and macOS), you can alternatively use the man command this way:\nman git-&lt;command&gt;\n\nExample:\n\nman git-commit\nFinally, many commands come with an help flag:\ngit &lt;command&gt; --help\n\nExample:\n\ngit commit --help\nAll these methods lead to the same thing: the manual page corresponding to the command will open in a pager (usually less). A pager is a program which makes it easier to read documents in the command line.\n\nUseful keybindings when you are in the pager:\nSPACE      scroll one screen down\nb          backa one screen\nq          quit the pager\ng          go to the top of the document\n7g         go to line 7 from the top\nG          go to the bottom of the document\n/          search for a term\n           n will take you to the next result\n           N to the previous result",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Documentation"
    ]
  },
  {
    "objectID": "git/intro_documentation.html#command-options",
    "href": "git/intro_documentation.html#command-options",
    "title": "Documentation",
    "section": "Command options",
    "text": "Command options\nInstead of opening the full manual in the pager, if you want to simply output the various flags (options) for a command directly in the terminal, you can use:\ngit &lt;command&gt; -h\n\nExample:\n\ngit commit -h",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Documentation"
    ]
  },
  {
    "objectID": "git/intro_git.html",
    "href": "git/intro_git.html",
    "title": "What is Git?",
    "section": "",
    "text": "Git is a free and open source version control system‚Äîa software that tracks changes to your files, allowing you to revisit or revert to older versions.\n\nSlides (Click and wait: the presentation might take a few instants to load)\n Slides content for easier browsing.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "What is Git?"
    ]
  },
  {
    "objectID": "git/intro_install.html",
    "href": "git/intro_install.html",
    "title": "Installation and setup",
    "section": "",
    "text": "In this section, we will learn how to install and configure Git.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Installation and setup"
    ]
  },
  {
    "objectID": "git/intro_install.html#installing-git-on-your-machine",
    "href": "git/intro_install.html#installing-git-on-your-machine",
    "title": "Installation and setup",
    "section": "Installing Git on your machine",
    "text": "Installing Git on your machine\n\nYou don‚Äôt have to install Git locally for this course if you plan on using our training cluster.\n\n\nmacOS/Linux users\nInstall Git from the official website.\n\n\nWindows users\nInstall Git for Windows. This will also install Git Bash, a Bash emulator.\n\nGit is built for Unix-like systems (Linux and macOS). In order to use Git from the command line on Windows, you need a Unix shell such as Bash. To make this very easy, Git for Windows comes with its Bash emulator.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Installation and setup"
    ]
  },
  {
    "objectID": "git/intro_install.html#git-in-the-alliance-clusters",
    "href": "git/intro_install.html#git-in-the-alliance-clusters",
    "title": "Installation and setup",
    "section": "Git in the Alliance clusters",
    "text": "Git in the Alliance clusters\nOn the Alliance clusters, Git is not only already installed, but it gets automatically loaded at each session, so you don‚Äôt have to load a module for it (as you do for most software). This is because Git is an integral part of any good workflow.\n\nLogging in our training cluster\n\nA username, hostname, and password will be given to you during the workshop.\n\n\nNote that this temporary cluster will only be available for the duration of this course.\n\n\nOpen a terminal emulator\nWindows users: ‚ÄÉInstall the free version of MobaXTerm and launch it.\nmacOS users: ‚ÄÉ‚ÄÉLaunch Terminal.\nLinux users: ‚ÄÉ‚ÄÉ‚ÄÇ¬†Open the terminal emulator of your choice.\n\n\nAccess the cluster\n\nWindows users\nFollow the first 18% of this demo.\nFor ‚ÄúRemote host‚Äù, use the hostname we gave you.\nSelect the box ‚ÄúSpecify username‚Äù and provide your username.\n\nNote that the password is entered through blind typing, meaning that you will not see anything happening as you type it. This is a Linux feature. While it is a little disturbing at first, do know that it is working. Make sure to type it slowly to avoid typos, then press the ‚Äúenter‚Äù key on your keyboard.\n\n\n\nmacOS and Linux users\nIn the terminal, run:\nssh &lt;username&gt;@&lt;hostname&gt;\n\nReplace the username and hostname by their values. For instance:\nssh user21@somecluster.c3.ca\n\nYou will be asked a question, answer ‚ÄúYes‚Äù.\nWhen prompted, type the password.\n\nNote that the password is entered through blind typing, meaning that you will not see anything happening as you type it. This is a Linux feature. While it is a little disturbing at first, do know that it is working. Make sure to type it slowly to avoid typos, then press the ‚Äúenter‚Äù key on your keyboard.\n\n\n\n\nTroubleshooting\nProblems logging in are almost always due to typos. If you cannot log in, retry slowly, entering your password carefully.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Installation and setup"
    ]
  },
  {
    "objectID": "git/intro_install.html#using-git",
    "href": "git/intro_install.html#using-git",
    "title": "Installation and setup",
    "section": "Using Git",
    "text": "Using Git\nWe will use Git from the command line throughout this workshop. Why? There are very friendly GUIs (graphical user interfaces) software for Git, but there are many good reasons to learn how to use Git from the command line:\n\nGUI software tend to be buggy,\nthey are limited to simple operations and you can‚Äôt use Git to its full potential with them,\nwhen you work on a remote machine (e.g.¬†on the Alliance clusters), using Git from the command line is so much more convenient,\nthere will be situations in your life when you will not have access to your favourite Git GUI software and you will have to use the command line, so you need to know how to use it, even if this is not what you will do in your every day workflow.\n\nAnother (and great!) way to use Git is with the TUI called lazygit which I will describe in a later section.\n\nIf you work on your machine\nmacOS users: ‚ÄÇ‚ÄÇ‚ÄÇ‚ÄÇ¬†Open Terminal.\nWindows users: ‚ÄÉ¬†¬†Open Git Bash.\nLinux users: ‚ÄÉ‚ÄÉ‚ÄÉOpen the terminal emulator of your choice.\n\n\nIf you work on our training cluster\nYou are already set: as mentioned above, Git is available at every session without loading any module.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Installation and setup"
    ]
  },
  {
    "objectID": "git/intro_install.html#configuring-git",
    "href": "git/intro_install.html#configuring-git",
    "title": "Installation and setup",
    "section": "Configuring Git",
    "text": "Configuring Git\nBefore you can use Git, you need to set some basic configuration. You will do this in the terminal you just opened.\n\nList settings\ngit config --list\n\n\nUser identity\ngit config --global user.name \"&lt;Your Name&gt;\"\ngit config --global user.email \"&lt;your@email&gt;\"\n\nExample:\n\ngit config --global user.name \"John Doe\"\ngit config --global user.email \"john.doe@gmail.com\"\n\nIt is recommended to use your real name and real email address: when you will collaborate on projects, you will probably want this information to be attached to your commits rather than a weird pseudo.\n\n\n\nText editor\ngit config --global core.editor \"&lt;text-editor&gt;\"\n\nExample for nano:\n\ngit config --global core.editor \"nano\"\n\n\nLine ending\n\nmacOS, Linux, or WSL\ngit config --global core.autocrlf input\n\n\nWindows\ngit config --global core.autocrlf true\n\n\n\nData integration method\nWhen you pull from a remote that was changed by a collaborator, their changes need to be integrated into yours. There are two ways to do this: with and without rebase.\nTo save you from having to pass the --rebase or --no-rebase flag each time you run git pull, you can set our preference in the configuration file.\nTo use the non-rebase method (which used to be the default in older versions of Git), run:\ngit config --global pull.rebase false\nThis will integrate changes from remote branches into your local branches by creating merge commits.\nIf you want to use rebase instead, run the above line with true.\nIn that case, the commits from the remote branch would be inserted before your local commits, thus creating a linear history and preventing the creating of merge commits.\nYou can look at this blog post for a good summary of the pros and cons of each method.\n\n\nProject-specific configuration\nYou can also set project-specific configurations (e.g.¬†maybe you want to use a different email address for a certain project).\nIn that case, navigate to your project and run the command without the --global flag.\n\nExample:\n\ncd /path/to/project\ngit config user.email \"your_other@email\"",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Installation and setup"
    ]
  },
  {
    "objectID": "git/intro_remotes.html",
    "href": "git/intro_remotes.html",
    "title": "Remotes",
    "section": "",
    "text": "Remotes are copies of a project and its history.\nThey can be located anywhere, including on external drive or on the same machine as the project, although they are often on a different machine to serve as backup, or on a network (e.g.¬†internet) to serve as a syncing hub for collaborations.\nPopular online Git repository managers & hosting services:\n\nGitHub\nGitLab\nBitbucket\n\nLet‚Äôs see how to create and manage remotes.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Remotes"
    ]
  },
  {
    "objectID": "git/intro_remotes.html#creating-a-remote-on-github",
    "href": "git/intro_remotes.html#creating-a-remote-on-github",
    "title": "Remotes",
    "section": "Creating a remote on GitHub",
    "text": "Creating a remote on GitHub\n\nCreate a free GitHub account\nIf you don‚Äôt already have one, sign up for a free GitHub account.\n\n\nConnect to GitHub\nThe 2 main ways to push data to GitHub are:\n\nusing a token,\nusing SSH.\n\nWe will use a token here.\n\nThere are alternative methods but you will have to look for information on your own:\n\nIf you use Edge, there is an integration with GitHub since they are both owned by Microsoft.\n\nThe GitHub Desktop application gives additional options to connect.\n\nIf you use the GitHub app, it also gives authentication methods.\n\n\n\nFor information on how to use SSH with GitHub, you can look at this section of our course on collaborating with GitHub.\n\nA token can be generated in GitHub settings.\nHere is the workflow:\n\nIn the upper-right corner of any page on GitHub, click your profile photo, then click Settings.\nIn the left sidebar, click Developer settings.\nIn the left sidebar, under Personal access tokens, click Fine-grained tokens.\nClick Generate new token.\nUnder Token name, enter a name for the token.\nUnder Repository access, select which repositories you want the token to access.\nUnder Permissions, select which permissions to grant the token.\nClick Generate token.\nMake sure to copy the token and save it to your computer.\n\nWhen you push to GitHub, you will be asked for your username and password. Your username is your GitHub username and the password is your token.\n\n\nCreate a repository on GitHub\n\nGo to the GitHub website, login, and go to your home page.\nLook for the Repositories tab & click the green New button.\nEnter the name you want for your repo, without spaces.\nMake the repository public or private.\n\n\n\nLink remote repo to local repo\nClick on the Code green drop-down button, select SSH if you have set SSH for your GitHub account or HTTPS and copy the address.\nIn the command line, cd inside your project, and add the remote:\ngit remote add &lt;remote-name&gt; &lt;remote-address&gt;\nremote-name is a convenience name to identify that remote. You can choose any name, but since Git automatically call the remote origin when you clone a repo, it is common practice to use origin as the name for the first remote.\n\nExample (using an SSH address):\n\ngit remote add origin git@github.com:&lt;user&gt;/&lt;repo&gt;.git\n\nExample (using an HTTPS address):\n\ngit remote add origin https://github.com/&lt;user&gt;/&lt;repo&gt;.git",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Remotes"
    ]
  },
  {
    "objectID": "git/intro_remotes.html#getting-information-on-remotes",
    "href": "git/intro_remotes.html#getting-information-on-remotes",
    "title": "Remotes",
    "section": "Getting information on remotes",
    "text": "Getting information on remotes\nList remotes:\ngit remote\nList remotes with their addresses:\ngit remote -v\nGet more information on a remote:\ngit remote show &lt;remote-name&gt;\n\nExample:\n\ngit remote show origin",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Remotes"
    ]
  },
  {
    "objectID": "git/intro_remotes.html#managing-remotes",
    "href": "git/intro_remotes.html#managing-remotes",
    "title": "Remotes",
    "section": "Managing remotes",
    "text": "Managing remotes\nRename a remote:\ngit remote rename &lt;old-remote-name&gt; &lt;new-remote-name&gt;\nDelete a remote:\ngit remote remove &lt;remote-name&gt;\nChange the address of a remote:\ngit remote set-url &lt;remote-name&gt; &lt;new-url&gt; [&lt;old-url&gt;]",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Remotes"
    ]
  },
  {
    "objectID": "git/intro_remotes.html#getting-data-from-a-remote",
    "href": "git/intro_remotes.html#getting-data-from-a-remote",
    "title": "Remotes",
    "section": "Getting data from a remote",
    "text": "Getting data from a remote\nIf you collaborate on a project, you have to get the data added by your teammates to keep your local project up to date.\nTo download new data from a remote, you have 2 options:\n\ngit fetch\ngit pull\n\n\nFetching changes\nFetching downloads the data from a remote that you don‚Äôt already have in your local version of the project:\ngit fetch &lt;remote-name&gt;\nThe branches on the remote are now accessible locally as &lt;remote-name&gt;/&lt;branch&gt;. You can inspect them or you can merge them into your local branches.\n\nExample:\n\ngit fetch origin\n\n\nPulling changes\nPulling fetches the changes & merges them onto your local branches:\ngit pull &lt;remote-name&gt; &lt;branch&gt;\n\nExample:\n\ngit pull origin main\nIf your branch is already tracking a remote branch, you can omit the arguments:\ngit pull",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Remotes"
    ]
  },
  {
    "objectID": "git/intro_remotes.html#pushing-to-a-remote",
    "href": "git/intro_remotes.html#pushing-to-a-remote",
    "title": "Remotes",
    "section": "Pushing to a remote",
    "text": "Pushing to a remote\nUploading data to the remote is called pushing:\ngit push &lt;remote-name&gt; &lt;branch-name&gt;\n\nExample:\n\ngit push origin main\nYou can set an upstream branch to track a local branch with the -u flag:\ngit push -u &lt;remote-name&gt; &lt;branch-name&gt;\n\nExample:\n\ngit push -u origin main\nFrom now on, all you have to run when you are on main is:\ngit push\n\n\n\nby jscript",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Remotes"
    ]
  },
  {
    "objectID": "git/intro_stash.html",
    "href": "git/intro_stash.html",
    "title": "Stashing",
    "section": "",
    "text": "Stashing is a way to put changes aside for some time. Changes can be reapplied later (and/or applied on other branches).\nWhy would you want to do that? And how?",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Stashing"
    ]
  },
  {
    "objectID": "git/intro_stash.html#what-are-git-stashes",
    "href": "git/intro_stash.html#what-are-git-stashes",
    "title": "Stashing",
    "section": "What are Git stashes?",
    "text": "What are Git stashes?\nHaving a clean working tree is necessary for many Git operations and recommended for others. If you have changes from an unfinished piece of work getting in the way, you could do an ugly commit to get rid of them. But if you care about having an organized history with meaningful commits (or if you don‚Äôt want others to see your messy drafts), stashing is a much better alternative.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Stashing"
    ]
  },
  {
    "objectID": "git/intro_stash.html#creating-a-stash",
    "href": "git/intro_stash.html#creating-a-stash",
    "title": "Stashing",
    "section": "Creating a stash",
    "text": "Creating a stash\nYou can stash the changes in your modified files with:\ngit stash\nTo also include new (untracked) files, you have to use the -u flag:\ngit stash -u",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Stashing"
    ]
  },
  {
    "objectID": "git/intro_stash.html#listing-stashes",
    "href": "git/intro_stash.html#listing-stashes",
    "title": "Stashing",
    "section": "Listing stashes",
    "text": "Listing stashes\nOf course, you don‚Äôt want to lose or forget about your stashes.\nYou can list them with:\ngit stash list\nStashes are also shown when you run git log (with any of its variations) with the --all flag.\n\nExample:\n\ngit log --graph --oneline --all",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Stashing"
    ]
  },
  {
    "objectID": "git/intro_stash.html#re-applying-changes-from-a-stash",
    "href": "git/intro_stash.html#re-applying-changes-from-a-stash",
    "title": "Stashing",
    "section": "Re-applying changes from a stash",
    "text": "Re-applying changes from a stash\nTo re-apply the changes (or apply them on another branch), you run:\ngit stash apply\nIf you had staged changes, you can also restore the state of the index by running instead:\ngit stash apply --index\nIf you created multiple stashes, this will apply the last one you created. If this is not what you want, you have to specify which stash you want to use with the reflog syntax:\n\nstash@{0} is the last stash (so you can omit it)\n\nstash@{1} is the one before it\n\nstash@{2} the one before that\n\netc.\n\n\nTo apply the stash before last:\n\ngit stash apply stash@{1}",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Stashing"
    ]
  },
  {
    "objectID": "git/intro_stash.html#deleting-a-stash",
    "href": "git/intro_stash.html#deleting-a-stash",
    "title": "Stashing",
    "section": "Deleting a stash",
    "text": "Deleting a stash\nYou delete the last (or the only) stash with:\ngit stash drop\nHere again, if you want to delete another stash, specify it with its reflog index.\n\nTo delete the antepenultimate stash:\n\ngit stash drop stash@{2}\nYou can apply and delete a stash at the same time with:\ngit stash pop\nThis is convenient, but less flexible.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Stashing"
    ]
  },
  {
    "objectID": "git/intro_three_trees.html",
    "href": "git/intro_three_trees.html",
    "title": "The three trees of Git",
    "section": "",
    "text": "One useful mental representation of the functioning of Git is to imagine three file trees."
  },
  {
    "objectID": "git/intro_three_trees.html#the-three-trees-of-git",
    "href": "git/intro_three_trees.html#the-three-trees-of-git",
    "title": "The three trees of Git",
    "section": "The three trees of Git",
    "text": "The three trees of Git\n\nWorking directory\nLet‚Äôs imagine that you are starting to work on a project.\nFirst, you create a directory.\nIn it, you create several sub-directories.\nIn those, you create a number of files.\nYou can open these files, read them, edit them, etc. This is something you are very familiar with.\nIn the Git world, this is the working directory or working tree of the project.\nThat is: an uncompressed version of your files that you can access and edit.\nYou can think of it as a sandbox because this is where you can experiment with the project. This is where the project gets developed.\nNow, Git has two other important pieces in its architecture.\n\n\nIndex\nIf you want the project history to be useful to future you, it has to be nice and tidy. You don‚Äôt want to record snapshots haphazardly or you will never be able to find anything back.\nBefore you record a snapshot, you carefully select the elements of the project as it is now that would be useful to write to the project history together. The index or staging area is what allows to do that: it contains the suggested future snapshot.\n\n\nHEAD\nFinally, the last tree in Git architecture is one snapshot in the project history that serves as a reference version of the project: if you want to see what you have been experimenting on in your ‚Äúsandbox‚Äù, you need to compare the state of the working directory with some snapshot.\nRemember that HEAD is a pointer pointing at a branch, that a branch is itself a pointer pointing at a commit, and finally that a commit is a Git object pointing at a snapshot. When the HEAD pointer moves around, whatever snapshot it points to populates the HEAD tree.\nAs we saw earlier, when you create a commit, HEAD automatically points to the new commit. So the HEAD tree is often filled with the last snapshot you created. But‚Äîas we will see later‚Äîwe can move the HEAD pointer around through other ways. So the HEAD tree can be populated by any snapshot in your project history."
  },
  {
    "objectID": "git/intro_three_trees.html#status-of-the-three-trees",
    "href": "git/intro_three_trees.html#status-of-the-three-trees",
    "title": "The three trees of Git",
    "section": "Status of the three trees",
    "text": "Status of the three trees\nTo display the status of these trees, you run:\ngit status"
  },
  {
    "objectID": "git/intro_three_trees.html#three-trees-in-action",
    "href": "git/intro_three_trees.html#three-trees-in-action",
    "title": "The three trees of Git",
    "section": "Three trees in action",
    "text": "Three trees in action\n\nClean working tree\nWe say that the working tree is ‚Äúclean‚Äù when all changes tracked by Git were staged and committed:\n\nHere is an example for a project with a single file called File at version v1.\n\n\n\n\nMaking changes to the working tree\nWhen you edit files in your project, you make changes in the working directory or working tree.\n\nFor instance, you make changes to File. Let‚Äôs say that it is now at version v2:\n\n\nThe other two trees remain at version v1.\nIf you run git status, this is what you get:\nOn branch main\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n        modified:   File\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\n\nStaging changes\nYou stage that file (meaning that you will include the changes of that file in the next commit) with:\ngit add File\nAfter which, your Git trees look like this:\n\nNow, the index also has File at version v2 and git status returns:\nOn branch main\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n        modified:   File\n\n\nCommitting changes\nFinally, you create a snapshot and the commit pointing to it‚Äîrecording the staged changes to history‚Äîwith:\ngit commit -m \"Added File\"\n-m is a flag that allows to provide the commit message directly in the command line. If you don‚Äôt use it, Git will open a text editor so that you can type the message. Without a message, there can be no commit.\nNow your trees look like this:\n\nOur working tree is clean again and git status returns:\nOn branch main\nnothing to commit, working tree clean\nThis means that there are no uncommitted changes in the working tree or the staging area: all the changes have been written to history.\n\nYou don‚Äôt have to stage all the changes in the working directory before making a commit; that is actually the whole point of the staging area.\nThis means that the working directory is not necessarily clean after you have created a new commit."
  },
  {
    "objectID": "git/intro_tools.html",
    "href": "git/intro_tools.html",
    "title": "Tools for a friendlier Git",
    "section": "",
    "text": "Two great open-source tools to work with Git in a nice visual manner while remaining in the command line.",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Tools for a friendlier Git"
    ]
  },
  {
    "objectID": "git/intro_tools.html#lazygit",
    "href": "git/intro_tools.html#lazygit",
    "title": "Tools for a friendlier Git",
    "section": "lazygit",
    "text": "lazygit\nlazygit is an excellent multi-platform terminal user interface for Git. It is my favourite Git interface and I use it all the time. You can find the installation instructions here.\nI recently gave a webinar on it that you can find here. Below is the video from the webinar:",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Tools for a friendlier Git"
    ]
  },
  {
    "objectID": "git/intro_tools.html#fzf",
    "href": "git/intro_tools.html#fzf",
    "title": "Tools for a friendlier Git",
    "section": "fzf",
    "text": "fzf\nfzf is a fantastic multi-platform command line fuzzy finder with a huge versatility.\nIt is easy to install on your machine and can also be installed on the Alliance clusters with:\ngit clone --depth 1 https://github.com/junegunn/fzf.git ~/.fzf &&\n    ~/.fzf/install\n\n# then answer y, y, n to the 3 questions\n\nIn this video, I demo quickly how it can be used with Git:",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>",
      "Tools for a friendlier Git"
    ]
  },
  {
    "objectID": "git/practice_repo/ws_search.html",
    "href": "git/practice_repo/ws_search.html",
    "title": "Searching a version-controlled project",
    "section": "",
    "text": "What is the point of creating all these commits if you are unable to make use of them because you can‚Äôt find the information you need in them?\nIn this workshop, we will learn how to search:\n\nyour files (at any of their versions) and\nyour commit logs.\n\nBy the end of the workshop, you should be able to retrieve anything you need from your versioned project.",
    "crumbs": [
      "Git",
      "<b><em>Workshops</em></b>",
      "Searching a Git project"
    ]
  },
  {
    "objectID": "git/practice_repo/ws_search.html#installation",
    "href": "git/practice_repo/ws_search.html#installation",
    "title": "Searching a version-controlled project",
    "section": "Installation",
    "text": "Installation\nmacOS & Linux users:\nInstall Git from the official website.\nWindows users:\nInstall Git for Windows. This will also install ‚ÄúGit Bash‚Äù, a Bash emulator.",
    "crumbs": [
      "Git",
      "<b><em>Workshops</em></b>",
      "Searching a Git project"
    ]
  },
  {
    "objectID": "git/practice_repo/ws_search.html#using-git",
    "href": "git/practice_repo/ws_search.html#using-git",
    "title": "Searching a version-controlled project",
    "section": "Using Git",
    "text": "Using Git\nWe will use Git from the command line throughout this workshop.\nmacOS users: ‚ÄÉ‚ÄÉ‚ÄÇopen ‚ÄúTerminal‚Äù.\nWindows users: ‚ÄÉ‚ÄÇopen ‚ÄúGit Bash‚Äù.\nLinux users: ‚ÄÉ‚ÄÉ‚ÄÉopen the terminal emulator of your choice.",
    "crumbs": [
      "Git",
      "<b><em>Workshops</em></b>",
      "Searching a Git project"
    ]
  },
  {
    "objectID": "git/practice_repo/ws_search.html#practice-repo",
    "href": "git/practice_repo/ws_search.html#practice-repo",
    "title": "Searching a version-controlled project",
    "section": "Practice repo",
    "text": "Practice repo\n\nGet a repo\nYou are welcome to use a repository of yours to follow this workshop. Alternatively, you can clone a practice repo I have on GitHub:\n\nNavigate to an appropriate location:\n\ncd /path/to/appropriate/location\n\nClone the repo:\n\n# If you have set SSH for your GitHub account\ngit clone git@github.com:prosoitos/practice_repo.git\n# If you haven't set SSH\ngit clone https://github.com/prosoitos/practice_repo.git\n\nEnter the repo:\n\ncd practice_repo",
    "crumbs": [
      "Git",
      "<b><em>Workshops</em></b>",
      "Searching a Git project"
    ]
  },
  {
    "objectID": "git/practice_repo/ws_search.html#searching-files",
    "href": "git/practice_repo/ws_search.html#searching-files",
    "title": "Searching a version-controlled project",
    "section": "Searching files",
    "text": "Searching files\nThe first thing that can happen is that you are looking for a certain pattern somewhere in your project (for instance a certain function or a certain word).\n\ngit grep\nThe main command to look through versioned files is git grep.\nYou might be familiar with the command-line utility grep which allows to search for lines matching a certain pattern in files. git grep does a similar job with these differences:\n\nit is much faster since all files under version control are already indexed by Git,\nyou can easily search any commit without having to check it out,\nit has features lacking in grep such as, for instance, pattern arithmetic or tree search using globs.\n\n\n\nLet‚Äôs try it\nBy default, git grep searches recursively through the tracked files in the working directory (that is, the current version of the tracked files).\nFirst, let‚Äôs look for the word test in the current version of the tracked files in the test repo:\n\ngit grep test\n\nadrian.txt:Adrian's test text file.\nformerlyadrian.txt:Adrian's test text file.\nms/protocol.md:This is my test.\nms/smabraha.txt:This is a test file that I wanted to make, then push it somehow\nredone17.txt:this is a test file from redone17\nsrc/test_manuel.py:def test(model, device, test_loader):\nsrc/test_manuel.py:    test_loss = 0\nsrc/test_manuel.py:        for data, target in test_loader:\nsrc/test_manuel.py:            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\nsrc/test_manuel.py:    test_loss /= len(test_loader.dataset)\nsrc/test_manuel.py:        test_loss, correct, len(test_loader.dataset),\nsrc/test_manuel.py:        100. * correct / len(test_loader.dataset)))\nsrc/test_manuel.py:    test_data = datasets.MNIST(\nsrc/test_manuel.py:    test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\nsrc/test_manuel.py:        test(model, device, test_loader)\ntestAV1.txt:This is a test\ntext-collab.txt:This is the collaboration testing\n\n\nLet‚Äôs add blank lines between the results of each file for better readability:\n\ngit grep --break test\n\nadrian.txt:Adrian's test text file.\n\nformerlyadrian.txt:Adrian's test text file.\n\nms/protocol.md:This is my test.\n\nms/smabraha.txt:This is a test file that I wanted to make, then push it somehow\n\nredone17.txt:this is a test file from redone17\n\nsrc/test_manuel.py:def test(model, device, test_loader):\nsrc/test_manuel.py:    test_loss = 0\nsrc/test_manuel.py:        for data, target in test_loader:\nsrc/test_manuel.py:            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\nsrc/test_manuel.py:    test_loss /= len(test_loader.dataset)\nsrc/test_manuel.py:        test_loss, correct, len(test_loader.dataset),\nsrc/test_manuel.py:        100. * correct / len(test_loader.dataset)))\nsrc/test_manuel.py:    test_data = datasets.MNIST(\nsrc/test_manuel.py:    test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\nsrc/test_manuel.py:        test(model, device, test_loader)\n\ntestAV1.txt:This is a test\n\ntext-collab.txt:This is the collaboration testing\n\n\nLet‚Äôs also put the file names on separate lines:\n\ngit grep --break --heading test\n\nadrian.txt\nAdrian's test text file.\n\nformerlyadrian.txt\nAdrian's test text file.\n\nms/protocol.md\nThis is my test.\n\nms/smabraha.txt\nThis is a test file that I wanted to make, then push it somehow\n\nredone17.txt\nthis is a test file from redone17\n\nsrc/test_manuel.py\ndef test(model, device, test_loader):\n    test_loss = 0\n        for data, target in test_loader:\n            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n    test_loss /= len(test_loader.dataset)\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    test_data = datasets.MNIST(\n    test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\n        test(model, device, test_loader)\n\ntestAV1.txt\nThis is a test\n\ntext-collab.txt\nThis is the collaboration testing\n\n\nWe can display the line numbers for the results with the -n flag:\n\ngit grep --break --heading -n test\n\nadrian.txt\n1:Adrian's test text file.\n\nformerlyadrian.txt\n1:Adrian's test text file.\n\nms/protocol.md\n9:This is my test.\n\nms/smabraha.txt\n1:This is a test file that I wanted to make, then push it somehow\n\nredone17.txt\n1:this is a test file from redone17\n\nsrc/test_manuel.py\n50:def test(model, device, test_loader):\n52:    test_loss = 0\n55:        for data, target in test_loader:\n58:            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n62:    test_loss /= len(test_loader.dataset)\n65:        test_loss, correct, len(test_loader.dataset),\n66:        100. * correct / len(test_loader.dataset)))\n84:    test_data = datasets.MNIST(\n90:    test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\n97:        test(model, device, test_loader)\n\ntestAV1.txt\n1:This is a test\n\ntext-collab.txt\n1:This is the collaboration testing\n\n\nNotice how the results for the file src/test_manuel.py involve functions. It would be very convenient to have the names of the functions in which test appears.\nWe can do this with the -p flag:\n\ngit grep --break --heading -p test src/test_manuel.py\n\nsrc/test_manuel.py\ndef train(model, device, train_loader, optimizer, epoch):\ndef test(model, device, test_loader):\n    test_loss = 0\n        for data, target in test_loader:\n            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n    test_loss /= len(test_loader.dataset)\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\ndef main():\n    test_data = datasets.MNIST(\n    test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\n        test(model, device, test_loader)\n\n\n\nWe added the argument src/test_manuel.py to limit the search to that file.\n\nWe can now see that the word test appears in the functions test and main.\nNow, instead of printing all the matching lines, let‚Äôs print the number of matches per file:\n\ngit grep -c test\n\nadrian.txt:1\nformerlyadrian.txt:1\nms/protocol.md:1\nms/smabraha.txt:1\nredone17.txt:1\nsrc/test_manuel.py:10\ntestAV1.txt:1\ntext-collab.txt:1\n\n\n\n\nMore complex patterns\ngit grep in fact searches for regular expressions. test is a regular expression matching test, but we can look for more complex patterns.\nLet‚Äôs look for image:\n\ngit grep image\n\n\nNo output means that the search is not returning any result.\n\nLet‚Äôs make this search case insensitive:\n\ngit grep -i image\n\nsrc/new_file.py:from PIL import Image\nsrc/new_file.py:berlin1_lr = Image.open(\"/home/marie/parvus/pwg/wtm/slides/static/img/upscaling/lr/berlin_1945_1.jpg\")\nsrc/new_file.py:berlin1_hr = Image.open(\"/home/marie/parvus/pwg/wtm/slides/static/img/upscaling/hr/berlin_1945_1.png\")\n\n\nWe are now getting some results as Image was present in three lines of the file src/new_file.py.\nLet‚Äôs now search for data:\n\ngit grep data\n\n.gitignore:data/\nms/protocol.md:Collected and analyzed amazing data\nsrc/new_file.py:from datasets import load_dataset\nsrc/new_file.py:set5 = load_dataset('eugenesiow/Set5', 'bicubic_x4', split='validation')\nsrc/test_manuel.py:from torchvision import datasets, transforms\nsrc/test_manuel.py:    for batch_idx, (data, target) in enumerate(train_loader):\nsrc/test_manuel.py:        data, target = data.to(device), target.to(device)\nsrc/test_manuel.py:        output = model(data)\nsrc/test_manuel.py:                epoch, batch_idx * len(data), len(train_loader.dataset),\nsrc/test_manuel.py:        for data, target in test_loader:\nsrc/test_manuel.py:            data, target = data.to(device), target.to(device)\nsrc/test_manuel.py:            output = model(data)\nsrc/test_manuel.py:    test_loss /= len(test_loader.dataset)\nsrc/test_manuel.py:        test_loss, correct, len(test_loader.dataset),\nsrc/test_manuel.py:        100. * correct / len(test_loader.dataset)))\nsrc/test_manuel.py:    train_data = datasets.MNIST(\nsrc/test_manuel.py:        '~/parvus/pwg/wtm/tml/data',\nsrc/test_manuel.py:        # '~/projects/def-sponsor00/data',\nsrc/test_manuel.py:    test_data = datasets.MNIST(\nsrc/test_manuel.py:        '~/parvus/pwg/wtm/tml/data',\nsrc/test_manuel.py:        # '~/projects/def-sponsor00/data',\nsrc/test_manuel.py:    train_loader = torch.utils.data.DataLoader(train_data, batch_size=50)\nsrc/test_manuel.py:    test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\n\n\nWe are getting results for the word data, but also for the pattern data in longer expressions such as train_data or dataset. If we only want results for the word data, we can use the -w flag:\n\ngit grep -w data\n\n.gitignore:data/\nms/protocol.md:Collected and analyzed amazing data\nsrc/test_manuel.py:    for batch_idx, (data, target) in enumerate(train_loader):\nsrc/test_manuel.py:        data, target = data.to(device), target.to(device)\nsrc/test_manuel.py:        output = model(data)\nsrc/test_manuel.py:                epoch, batch_idx * len(data), len(train_loader.dataset),\nsrc/test_manuel.py:        for data, target in test_loader:\nsrc/test_manuel.py:            data, target = data.to(device), target.to(device)\nsrc/test_manuel.py:            output = model(data)\nsrc/test_manuel.py:        '~/parvus/pwg/wtm/tml/data',\nsrc/test_manuel.py:        # '~/projects/def-sponsor00/data',\nsrc/test_manuel.py:        '~/parvus/pwg/wtm/tml/data',\nsrc/test_manuel.py:        # '~/projects/def-sponsor00/data',\nsrc/test_manuel.py:    train_loader = torch.utils.data.DataLoader(train_data, batch_size=50)\nsrc/test_manuel.py:    test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\n\n\nNow, let‚Äôs use a more complex regular expression. We want the counts for the pattern \".*_.*\" (i.e.¬†any name with a snail case such as train_loader):\n\ngit grep -c \".*_.*\"\n\n.gitignore:4\nsrc/new_file.py:22\nsrc/test_manuel.py:29\n\n\nLet‚Äôs print the first 3 results per file:\n\ngit grep -m 3 \".*_.*\"\n\n.gitignore:hidden_file\n.gitignore:search_cache/\n.gitignore:ws_search_cache/html\nsrc/new_file.py:from datasets import load_dataset\nsrc/new_file.py:set5 = load_dataset('eugenesiow/Set5', 'bicubic_x4', split='validation')\nsrc/new_file.py:set5.column_names\nsrc/test_manuel.py:from torch.optim.lr_scheduler import StepLR\nsrc/test_manuel.py:    def __init__(self):\nsrc/test_manuel.py:        super(Net, self).__init__()\n\n\nAs you can see, our results also include __init__ which is not what we were looking for. So let‚Äôs exclude __:\n\ngit grep -m 3 -e \".*_.*\" --and --not -e \"__\"\n\n.gitignore:hidden_file\n.gitignore:search_cache/\n.gitignore:ws_search_cache/html\nsrc/new_file.py:from datasets import load_dataset\nsrc/new_file.py:set5 = load_dataset('eugenesiow/Set5', 'bicubic_x4', split='validation')\nsrc/new_file.py:set5.column_names\nsrc/test_manuel.py:from torch.optim.lr_scheduler import StepLR\nsrc/test_manuel.py:        x = F.max_pool2d(x, 2)\nsrc/test_manuel.py:        output = F.log_softmax(x, dim=1)\n\n\n\nFor simple searches, you don‚Äôt have to use the -e flag before the pattern you are searching for. Here however, our command has gotten complex enough that we have to use it before each pattern.\n\nLet‚Äôs make sure this worked as expected:\n\ngit grep -c \".*_.*\"\necho \"---\"\ngit grep -c \"__\"\necho \"---\"\ngit grep -ce \".*_.*\" --and --not -e \"__\"\n\n.gitignore:4\nsrc/new_file.py:22\nsrc/test_manuel.py:29\n---\nsrc/test_manuel.py:2\n---\n.gitignore:4\nsrc/new_file.py:22\nsrc/test_manuel.py:27\n\n\nThere were 2 lines matching __ in src/test_manuel.py and we have indeed excluded them from our search.\nExtended regular expressions are also covered with the flag -E.\n\n\nSearching other trees\nSo far, we have searched the current version of tracked files, but we can just as easily search files at any commit.\nLet‚Äôs search for test in the tracked files 20 commits ago:\n\ngit grep test HEAD~20\n\nHEAD~20:adrian.txt:Adrian's test text file.\nHEAD~20:formerlyadrian.txt:Adrian's test text file.\nHEAD~20:ms/protocol.md:This is my test.\nHEAD~20:ms/smabraha.txt:This is a test file that I wanted to make, then push it somehow\nHEAD~20:redone17.txt:this is a test file from redone17\nHEAD~20:testAV1.txt:This is a test\nHEAD~20:text-collab.txt:This is the collaboration testing\n\n\n\nAs you can see, the file src/test_manuel.py is not in the results. Either it didn‚Äôt exist or it didn‚Äôt have the word test at that commit.\n\nIf you want to search tracked files AND untracked files, you need to use the --untracked flag.\nLet‚Äôs create a new (thus untracked) file with some content including the word test:\n\necho \"This is a test\" &gt; newfile\n\nNow compare the following:\n\ngit grep -c test\n\nadrian.txt:1\nformerlyadrian.txt:1\nms/protocol.md:1\nms/smabraha.txt:1\nredone17.txt:1\nsrc/test_manuel.py:10\ntestAV1.txt:1\ntext-collab.txt:1\n\n\nwith:\n\ngit grep -c --untracked test\n\nadrian.txt:1\nformerlyadrian.txt:1\nms/protocol.md:1\nms/smabraha.txt:1\nredone17.txt:1\nsrc/test_manuel.py:10\ntestAV1.txt:1\ntext-collab.txt:1\nws_search.rmarkdown:41\n\n\n\nThis last result also returned our untracked file newfile.\n\nIf you want to search untracked and ignored files (meaning all your files), use the flags --untracked --no-exclude-standard.\nLet‚Äôs see what the .gitignore file contains:\n\ncat .gitignore\n\ndata/\noutput/\nhidden_file\nsearch_cache/\nsearch.qmd\nnewfile\nimg\nws_search_cache/html\nws_search.qmd\n\n\nThe directory data is in .gitignore. This means that it is not under version control and it thus doesn‚Äôt exist in our repo (since we cloned our repo, we only have the version-controlled files). Let‚Äôs create it:\nmkdir data\nNow, let‚Äôs create a file in it that contains test:\n\necho \"And another test\" &gt; data/file\n\nWe can rerun our previous two searches to verify that files excluded from version control are not searched:\n\ngit grep -c test\n\nadrian.txt:1\nformerlyadrian.txt:1\nms/protocol.md:1\nms/smabraha.txt:1\nredone17.txt:1\nsrc/test_manuel.py:10\ntestAV1.txt:1\ntext-collab.txt:1\n\n\n\ngit grep -c --untracked test\n\nadrian.txt:1\nformerlyadrian.txt:1\nms/protocol.md:1\nms/smabraha.txt:1\nredone17.txt:1\nsrc/test_manuel.py:10\ntestAV1.txt:1\ntext-collab.txt:1\nws_search.rmarkdown:41\n\n\nAnd now, let‚Äôs try:\n\ngit grep -c --untracked --no-exclude-standard test\n\nadrian.txt:1\ndata/file:1\nformerlyadrian.txt:1\nms/protocol.md:1\nms/smabraha.txt:1\nnewfile:1\nredone17.txt:1\nsrc/test_manuel.py:10\ntestAV1.txt:1\ntext-collab.txt:1\nws_search.qmd:41\nws_search.rmarkdown:41\n\n\n\ndata/file, despite being excluded from version control, is also searched.\n\n\n\nSearching all commits\nWe saw that git grep &lt;pattern&gt; &lt;commit&gt; can search a pattern in any commit. Now, what if we all to search all commits for a pattern?\nFor this, we pass the expression $(git rev-list --all) in lieu of &lt;commit&gt;.\ngit rev-list --all creates a list of all the commits in a way that can be used as an argument to other functions. The $() allows to run the expression inside it and pass the result as and argument.\nTo search for test in all the commits, we thus run:\ngit grep \"test\" $(git rev-list --all)\nI am not running this command has it has a huge output. Instead, I will limit the search to the last two commits:\n\ngit grep \"test\" $(git rev-list --all -2)\n\n388fdc13de66537cac2169253cb385dfd409e710:adrian.txt:Adrian's test text file.\n388fdc13de66537cac2169253cb385dfd409e710:formerlyadrian.txt:Adrian's test text file.\n388fdc13de66537cac2169253cb385dfd409e710:ms/protocol.md:This is my test.\n388fdc13de66537cac2169253cb385dfd409e710:ms/smabraha.txt:This is a test file that I wanted to make, then push it somehow\n388fdc13de66537cac2169253cb385dfd409e710:redone17.txt:this is a test file from redone17\n388fdc13de66537cac2169253cb385dfd409e710:src/test_manuel.py:def test(model, device, test_loader):\n388fdc13de66537cac2169253cb385dfd409e710:src/test_manuel.py:    test_loss = 0\n388fdc13de66537cac2169253cb385dfd409e710:src/test_manuel.py:        for data, target in test_loader:\n388fdc13de66537cac2169253cb385dfd409e710:src/test_manuel.py:            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n388fdc13de66537cac2169253cb385dfd409e710:src/test_manuel.py:    test_loss /= len(test_loader.dataset)\n388fdc13de66537cac2169253cb385dfd409e710:src/test_manuel.py:        test_loss, correct, len(test_loader.dataset),\n388fdc13de66537cac2169253cb385dfd409e710:src/test_manuel.py:        100. * correct / len(test_loader.dataset)))\n388fdc13de66537cac2169253cb385dfd409e710:src/test_manuel.py:    test_data = datasets.MNIST(\n388fdc13de66537cac2169253cb385dfd409e710:src/test_manuel.py:    test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\n388fdc13de66537cac2169253cb385dfd409e710:src/test_manuel.py:        test(model, device, test_loader)\n388fdc13de66537cac2169253cb385dfd409e710:testAV1.txt:This is a test\n388fdc13de66537cac2169253cb385dfd409e710:text-collab.txt:This is the collaboration testing\n423f454765d45e21e0ae401da0b3dec2d84113ce:adrian.txt:Adrian's test text file.\n423f454765d45e21e0ae401da0b3dec2d84113ce:formerlyadrian.txt:Adrian's test text file.\n423f454765d45e21e0ae401da0b3dec2d84113ce:ms/protocol.md:This is my test.\n423f454765d45e21e0ae401da0b3dec2d84113ce:ms/smabraha.txt:This is a test file that I wanted to make, then push it somehow\n423f454765d45e21e0ae401da0b3dec2d84113ce:redone17.txt:this is a test file from redone17\n423f454765d45e21e0ae401da0b3dec2d84113ce:src/test_manuel.py:def test(model, device, test_loader):\n423f454765d45e21e0ae401da0b3dec2d84113ce:src/test_manuel.py:    test_loss = 0\n423f454765d45e21e0ae401da0b3dec2d84113ce:src/test_manuel.py:        for data, target in test_loader:\n423f454765d45e21e0ae401da0b3dec2d84113ce:src/test_manuel.py:            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n423f454765d45e21e0ae401da0b3dec2d84113ce:src/test_manuel.py:    test_loss /= len(test_loader.dataset)\n423f454765d45e21e0ae401da0b3dec2d84113ce:src/test_manuel.py:        test_loss, correct, len(test_loader.dataset),\n423f454765d45e21e0ae401da0b3dec2d84113ce:src/test_manuel.py:        100. * correct / len(test_loader.dataset)))\n423f454765d45e21e0ae401da0b3dec2d84113ce:src/test_manuel.py:    test_data = datasets.MNIST(\n423f454765d45e21e0ae401da0b3dec2d84113ce:src/test_manuel.py:    test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\n423f454765d45e21e0ae401da0b3dec2d84113ce:src/test_manuel.py:        test(model, device, test_loader)\n423f454765d45e21e0ae401da0b3dec2d84113ce:testAV1.txt:This is a test\n423f454765d45e21e0ae401da0b3dec2d84113ce:text-collab.txt:This is the collaboration testing\n\n\n\nIn combination with the fuzzy finder tool fzf, this can make finding a particular commit extremely easy.\nFor instance, the code below allows you to dynamically search in the result through incremental completion:\ngit grep \"test\" $(git rev-list --all) | fzf --cycle -i -e\nOr even better, you can automatically copy the short form of the hash of the selected commit to clipboard so that you can use it with git show, git checkout, etc.:\ngit grep \"test\" $(git rev-list --all) |\n    fzf --cycle -i -e |\n    cut -c 1-7 |\n    xclip -r -selection clipboard\n\nHere, I am using xclip to copy to the clipboard as I am on Linux. Depending on your OS you might need to use a different tool.\n\nOf course, you can create a function in your .bashrc file with such code so that you wouldn‚Äôt have to type it each time:\ngrep_all_commits () {\n    git grep \"$1\" $(git rev-list --all) |\n        fzf --cycle -i -e |\n        cut -c 1-7 |\n        xclip -r -selection clipboard\n}\nAlternatively, you can pass the result directly into whatever git command you want to use that commit for.\nHere is an example with git show:\ngit grep \"test\" $(git rev-list --all) |\n    fzf --cycle -i -e |\n    cut -c 1-7 |\n    git show\nAnd if you wanted to get really fancy, you could go with:\ngit grep \"test\" $(git rev-list --all) |\n    fzf --cycle -i -e --no-multi \\\n        --ansi --preview=\"$_viewGitLogLine\" \\\n        --header \"enter: view, C-c: copy hash\" \\\n        --bind \"enter:execute:$_viewGitLogLine | less -R\" \\\n        --bind \"ctrl-c:execute:$_gitLogLineToHash |\n        xclip -r -selection clipboard\"\nWrapped in a function:\ngrep_all_commits_preview () {\n    git grep \"$1\" $(git rev-list --all) |\n        fzf --cycle -i -e --no-multi \\\n            --ansi --preview=\"$_viewGitLogLine\" \\\n            --header \"enter: view, C-c: copy hash\" \\\n            --bind \"enter:execute:$_viewGitLogLine |\n              less -R\" \\\n            --bind \"ctrl-c:execute:$_gitLogLineToHash |\n        xclip -r -selection clipboard\"\n}\nThis last function allows you to search through all the results in an incremental fashion while displaying a preview of the selected diff (the changes made at that particular commit). If you want to see more of the diff than the preview displays, press &lt;enter&gt; (then q to quit the pager), if you want to copy the hash of a commit, press C-c (Control + c).\nWith this function, you can now instantly get a preview of the changes made to any line containing an expression for any file, at any commit, and copy the hash of the selected commit. This is really powerful.\n\n\n\nAliases\nIf you don‚Äôt want to type a series of flags all the time, you can configure aliases for Git. For instance, Alex Razoumov uses the alias git search for git grep --break --heading -n -i.\nLet‚Äôs add to it the -p flag. Here is how you would set this alias:\ngit config --global alias.search 'grep --break --heading -n -i -p'\n\nThis setting gets added to your main Git configuration file (on Linux, by default, at ~/.gitconfig).\n\nFrom there on, you can use your alias with:\n\ngit search test\n\ngit: 'search' is not a git command. See 'git --help'.",
    "crumbs": [
      "Git",
      "<b><em>Workshops</em></b>",
      "Searching a Git project"
    ]
  },
  {
    "objectID": "git/practice_repo/ws_search.html#searching-logs",
    "href": "git/practice_repo/ws_search.html#searching-logs",
    "title": "Searching a version-controlled project",
    "section": "Searching logs",
    "text": "Searching logs\nThe second thing that can happen is that you are looking for some pattern in your version control logs.\n\ngit log\ngit log allows to get information on commit logs.\nBy default, it outputs all the commits of the current branch.\nLet‚Äôs show the logs of the last 3 commits:\n\ngit log -3\n\ncommit 388fdc13de66537cac2169253cb385dfd409e710\nAuthor: Marie-Helene Burle &lt;marie.burle@westdri.ca&gt;\nDate:   Thu Dec 14 20:55:30 2023 -0800\n\n    update gitignore\n\ncommit 423f454765d45e21e0ae401da0b3dec2d84113ce\nMerge: 7342af5 818c32a\nAuthor: Marie-Helene Burle &lt;marie.burle@westdri.ca&gt;\nDate:   Tue Dec 12 17:30:07 2023 -0800\n\n    Merge branch 'main' of github.com:prosoitos/practice_repo\n\ncommit 7342af5dfff53dc51dfaf99da1e29448fd253e03\nAuthor: Marie-Helene Burle &lt;marie.burle@westdri.ca&gt;\nDate:   Tue Dec 12 17:29:59 2023 -0800\n\n    update gitignore\n\n\nThe output can be customized thanks to a plethora of options.\nFor instance, here are the logs of the last 15 commits, in a graph, with one line per commit:\n\ngit log --graph --oneline -n 15\n\n* 388fdc1 update gitignore\n*   423f454 Merge branch 'main' of github.com:prosoitos/practice_repo\n|\\  \n| * 818c32a Delete ml_models directory\n| * b3c2414 Created using Colaboratory\n* | 7342af5 update gitignore\n|/  \n* e3cfb2e Update gitignore with Quarto files\n* 15fdec6 Update README.org\n* 15d4ee9 change values training\n* 06efa34 add lots of code\n* 1457143 remove stupid line\n* 711e1dc add real py content to test_manual.py\n* 90016aa adding new python file\n*   2c0f612 Merge branch 'main' of github.com:prosoitos/git_workshop_collab\n|\\  \n| *   6f7d03d Merge branch 'main' of https://github.com/prosoitos/git_workshop_collab into main\n| |\\  \n| * \\   3c53269 Merge branch 'main' of https://github.com/prosoitos/git_workshop_collab into main\n| |\\ \\  \n\n\nBut git log has also flags that allow to search for patterns.\n\n\nSearching commit messages\nOne of the reasons it is so important to write informative commit messages is that they are key to finding commits later on.\nTo look for a pattern in all your commit messages, use git log --grep=&lt;pattern&gt;.\nLet‚Äôs look for test in the commit messages and limit the output to 3 commits:\n\ngit log --grep=test -3\n\ncommit 711e1dc53011e5071b17dc7c35b516f6e066f396\nAuthor: Marie-Helene Burle &lt;marie.burle@westgrid.ca&gt;\nDate:   Tue Mar 15 11:52:48 2022 -0700\n\n    add real py content to test_manual.py\n\ncommit a55ca0d60d82578c94bd49fc4ca987727b851216\nAuthor: Manuelhrokr &lt;zl.manuel@protonmail.com&gt;\nDate:   Thu Feb 17 15:19:42 2022 -0700\n\n    new comment add just as test\n\ncommit ea74e46f487fba09c31524a110fdf060796e3cf8\nAuthor: mpkin &lt;mikin@physics.ubc.ca&gt;\nDate:   Thu Sep 23 14:51:24 2021 -0700\n\n    Add test_mk.txt\n\n\nFor a more compact output:\n\ngit log --grep=\"test\" -3 --oneline\n\n711e1dc add real py content to test_manual.py\na55ca0d new comment add just as test\nea74e46 Add test_mk.txt\n\n\n\nHere too you can use this in combination to fzf with for instance:\ngit log --grep=\"test\" | fzf --cycle -i -e\nOr:\ngit log --grep=\"test\" --oneline |\n    fzf --cycle -i -e --no-multi \\\n        --ansi --preview=\"$_viewGitLogLine\" \\\n        --header \"enter: view, C-c: copy hash\" \\\n        --bind \"enter:execute:$_viewGitLogLine | less -R\" \\\n        --bind \"ctrl-c:execute:$_gitLogLineToHash |\n        xclip -r -selection clipboard\"\n\n\n\nChanges made to a pattern\nRemember that test was present in the file src/test_manuel.py. If we want to see when the pattern was first created and then each time it was modified, we use the -L flag in this fashion:\ngit log -L :&lt;pattern&gt;:file\nIn our case:\n\ngit log -L :test:src/test_manuel.py\n\ncommit 711e1dc53011e5071b17dc7c35b516f6e066f396\nAuthor: Marie-Helene Burle &lt;marie.burle@westgrid.ca&gt;\nDate:   Tue Mar 15 11:52:48 2022 -0700\n\n    add real py content to test_manual.py\n\ndiff --git a/src/test_manuel.py b/src/test_manuel.py\n--- a/src/test_manuel.py\n+++ b/src/test_manuel.py\n@@ -1,1 +50,19 @@\n-test\n+def test(model, device, test_loader):\n+    model.eval()\n+    test_loss = 0\n+    correct = 0\n+    with torch.no_grad():\n+        for data, target in test_loader:\n+            data, target = data.to(device), target.to(device)\n+            output = model(data)\n+            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n+            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n+            correct += pred.eq(target.view_as(pred)).sum().item()\n+\n+    test_loss /= len(test_loader.dataset)\n+\n+    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n+        test_loss, correct, len(test_loader.dataset),\n+        100. * correct / len(test_loader.dataset)))\n+\n+\n\ncommit 90016aa3ed3a6cf71e206392bbf10adfe1a14c17\nAuthor: Manuelhrokr &lt;zl.manuel@protonmail.com&gt;\nDate:   Thu Feb 17 15:33:03 2022 -0700\n\n    adding new python file\n\ndiff --git a/src/test_manuel.py b/src/test_manuel.py\n--- /dev/null\n+++ b/src/test_manuel.py\n@@ -0,0 +1,1 @@\n+test\n\n\nThis is very useful if you want to see, for instance, changes made to a function in a script.\n\n\nChanges in number of occurrences\nNow, if we want to list all commits that created a change in the number of occurrences of test in our project, we run:\n\ngit log -S test --oneline\n\n818c32a Delete ml_models directory\nb3c2414 Created using Colaboratory\n711e1dc add real py content to test_manual.py\n90016aa adding new python file\n652faa5 delete my file\nb684eac Deleted file\n6717236 For collab\nca1845d delete alex.txt\n6b56198 editing adrians text file\n01a7358 test dtrad\ne44a454 Create testAV1.txt\n5ee88e6 For collab\ncf3d4ea Collab-test\n13faa1e test, test\n0366115 Adrian's test file\n9ebd3ce This is my test\n6dfefa8 create redone17.txt\ne43163c added alex.txt\n\n\nThis can be useful to identify the commit you need.",
    "crumbs": [
      "Git",
      "<b><em>Workshops</em></b>",
      "Searching a Git project"
    ]
  },
  {
    "objectID": "git/practice_repo/ws_search.html#tldr",
    "href": "git/practice_repo/ws_search.html#tldr",
    "title": "Searching a version-controlled project",
    "section": "TL;DR",
    "text": "TL;DR\nHere are the search functions you are the most likely to use:\n\nSearch for a pattern in the current version of your tracked files:\n\ngit grep &lt;pattern&gt;\n\nSearch for a pattern in your files at a certain commit:\n\ngit grep &lt;pattern&gt; &lt;commit&gt;\n\nSearch for a pattern in your files in all the commits:\n\ngit grep &lt;pattern&gt; $(git rev-list --all)\n\nSearch for a pattern in your commit messages:\n\ngit log --grep=&lt;pattern&gt;\nNow you should be able to find pretty much anything in your projects and their histories.",
    "crumbs": [
      "Git",
      "<b><em>Workshops</em></b>",
      "Searching a Git project"
    ]
  },
  {
    "objectID": "git/top_intro.html",
    "href": "git/top_intro.html",
    "title": "Getting started with Git",
    "section": "",
    "text": "A version control system allows you to track changes to your text files and save important versions of your projects that you can revisit or revert to later. It is a critical aspect to any serious workflow while prototyping code, building a website, developing software, or writing documents such as a thesis or papers in markdown or LaTeX.\nGit‚Äîa free and open source software‚Äîhas become the standard tool for version control.\nIn this hands-on course, you will learn how Git works and how to get started putting your projects under version control.\n\n Start course ‚û§",
    "crumbs": [
      "Git",
      "<b><em>Getting started with Git</em></b>"
    ]
  },
  {
    "objectID": "git/top_ws.html",
    "href": "git/top_ws.html",
    "title": "Git workshops",
    "section": "",
    "text": "Searching a Git project\n\n\n\n\nCollaborating through Git\n\n\n\n\nContributing to projects",
    "crumbs": [
      "Git",
      "<b><em>Workshops</em></b>"
    ]
  },
  {
    "objectID": "git/wb_dvc_content.html",
    "href": "git/wb_dvc_content.html",
    "title": "Version control for data science & machine learning with DVC",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "Git",
      "<b><em>Webinars</em></b>",
      "Data version control with DVC",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "git/wb_dvc_content.html#on-version-control",
    "href": "git/wb_dvc_content.html#on-version-control",
    "title": "Version control for data science & machine learning with DVC",
    "section": "On version control",
    "text": "On version control\nI won‚Äôt introduce here the benefits of using a good version control system such as Git.\n\n\n\nOn the benefits of VCS\n\n\n\nExtending Git for data\nWhile Git is a wonderful tool for text files versioning (code, writings in markup formats), it isn‚Äôt a tool to manage changes to datasets.\nSeveral open source tools‚Äîeach with a different structure and functioning‚Äîextend Git capabilities to track data: Git LFS, git-annex, lakeFS, Dolt, DataLad.\n\n\nGit for models and experiments\nReproducible research and collaboration on data science and machine learning projects involve more than datasets management:\nExperiments and the models they produce also need to be tracked.\n\n\nMany moving parts\n\n*hp = hyperparameter\n\n\n\n\n\n\n\n\n\n\ndata1\n\ndata1\n\n\n\nmodel1\n\nmodel1\n\n\n\ndata1-&gt;model1\n\n\n\n\n\nmodel2\n\nmodel2\n\n\n\ndata1-&gt;model2\n\n\n\n\n\nmodel3\n\nmodel3\n\n\n\ndata1-&gt;model3\n\n\n\n\n\ndata2\n\ndata2\n\n\n\ndata2-&gt;model1\n\n\n\n\n\ndata2-&gt;model2\n\n\n\n\n\ndata2-&gt;model3\n\n\n\n\n\ndata3\n\ndata3\n\n\n\ndata3-&gt;model1\n\n\n\n\n\ndata3-&gt;model2\n\n\n\n\n\ndata3-&gt;model3\n\n\n\n\n\nhp1\n\nhp1\n\n\n\nhp1-&gt;model1\n\n\n\n\n\nhp1-&gt;model2\n\n\n\n\n\nhp1-&gt;model3\n\n\n\n\n\nhp2\n\nhp2\n\n\n\nhp2-&gt;model1\n\n\n\n\n\nhp2-&gt;model2\n\n\n\n\n\nhp2-&gt;model3\n\n\n\n\n\nhp3\n\nhp3\n\n\n\nhp3-&gt;model1\n\n\n\n\n\nhp3-&gt;model2\n\n\n\n\n\nhp3-&gt;model3\n\n\n\n\n\nperformance\n\nperformance1 ... performance27\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\n\n\n\n\n\nHow did we get performance17 again? ü§Ø",
    "crumbs": [
      "Git",
      "<b><em>Webinars</em></b>",
      "Data version control with DVC",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "git/wb_dvc_content.html#enters-dvc",
    "href": "git/wb_dvc_content.html#enters-dvc",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Enters DVC",
    "text": "Enters DVC\n\nDVC principles\n\nLarge files (datasets, models‚Ä¶) are kept outside Git.\nEach large file or directory put under DVC tracking has an associated .dvc file.\nGit only tracks the .dvc files (metadata).\n\nWorkflows can be tracked for collaboration and reproducibility.\nDVC functions as a Makefile and allows to only rerun what is necessary.\n\n\nInstallation\nFor Linux (other OSes, refer to the doc):\n\npip:\npip install dvc\nconda\npipx (if you want dvc available everywhere without having to activate virtual envs):\npipx install dvc\n\n\nOptional dependencies [s3], [gdrive], etc. for remote storage.\n\n\n\nHow to run\nMultiple options:\n\nTerminal:\ndvc ...\nVS Code extension\nPython library if installed via pip or conda:\nimport dvc.api\n\n\nIn this webinar, I will use DVC through the command line.\n\n\n\nAcknowledgements\nCode and data for this webinar modified from:\n\nReal Python\nDataLad handbook\nDVC documentation\n\n\n\nThe project\ntree -L 3\n‚îú‚îÄ‚îÄ LICENSE\n‚îú‚îÄ‚îÄ data\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ prepared\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ raw\n‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ train\n‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ val\n‚îú‚îÄ‚îÄ metrics\n‚îú‚îÄ‚îÄ model\n‚îú‚îÄ‚îÄ requirements.txt\n‚îî‚îÄ‚îÄ src\n    ‚îú‚îÄ‚îÄ evaluate.py\n    ‚îú‚îÄ‚îÄ prepare.py\n    ‚îî‚îÄ‚îÄ train.py\n\n\nInitialize Git repo\ngit init\nInitialized empty Git repository in dvc/.git/\nThis creates the .git directory.\ngit status\nOn branch main\n\nNo commits yet\n\nUntracked files:\n    LICENSE\n    data/\n    requirements.txt\n    src/\n\n\nInitialize DVC project\ndvc init\nInitialized DVC repository.\n\nYou can now commit the changes to git.\n\nYou will also see a note about usage analytics collection and info on how to opt out.\n\nA .dvc directory and a .dvcignore file got created.\n\n\nCommit DVC system files\nDVC automatically staged its system file for us:\ngit status\nOn branch main\n\nNo commits yet\n\nChanges to be committed:\n    new file:   .dvc/.gitignore\n    new file:   .dvc/config\n    new file:   .dvcignore\n\nUntracked files:\n    LICENSE\n    data/\n    requirements.txt\n    src/\nSo we can directly commit:\ngit commit -m \"Initialize DVC\"\n\n\nPrepare repo\nLet‚Äôs work in a virtual environment:\n# Create venv and add to .gitignore\npython -m venv venv && echo venv &gt; .gitignore\n\n# Activate venv\nsource venv/bin/activate\n\n# Update pip\npython -m pip install --upgrade pip\n\n# Install packages needed\npython -m pip install -r requirements.txt\n\n\nClean working tree\ngit add .gitignore LICENSE requirements.txt\ngit commit -m \"Add general files\"\ngit add src\ngit commit -m \"Add scripts\"\ngit status\nOn branch main\nUntracked files:\n    data/\n\nNow, it is time to deal with the data.",
    "crumbs": [
      "Git",
      "<b><em>Webinars</em></b>",
      "Data version control with DVC",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "git/wb_dvc_content.html#tracking-data-with-dvc",
    "href": "git/wb_dvc_content.html#tracking-data-with-dvc",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Tracking data with DVC",
    "text": "Tracking data with DVC\n\nPut data under DVC tracking\nWe are still not tracking any data:\ndvc status\nThere are no data or pipelines tracked in this project yet.\nYou can choose what to track as a unit (i.e.¬†each picture individually, the whole data directory as a unit).\nLet‚Äôs break it down by set:\ndvc add data/raw/train\ndvc add data/raw/val\nThis adds data to .dvc/cache/files and created 3 files in data/raw:\n\n.gitignore\ntrain.dvc\nval.dvc\n\nThe .gitignore tells Git not to track the data:\ncat data/raw/.gitignore\n/train\n/val\nThe .dvc files contain the metadata for the cached directories.\n\n\nTracked data\nWe are all good:\ndvc status\nData and pipelines are up to date.\n\n\nData (de)duplication\nLink between checked-out version of a file/directory and the cache:\n\n\n\n\n\n\n\n\n\nDuplication\nEditable\n\n\n\n\nReflinks*\nOnly when needed\nYes\n\n\nHardlinks/Symlinks\nNo\nNo\n\n\nCopies\nYes\nYes\n\n\n\n\n*Reflinks only available for a few file systems (Btrfs, XFS, OCFS2, or APFS).\n\n\n\nCommit the metafiles\nThe metafiles should be put under Git version control.\n\nYou can configure DVC to automatically stage its newly created system files:\ndvc config [--system] [--global] core.autostage true\n\nYou can then commit directly:\ngit commit -m \"Initial version of data\"\ngit status\nOn branch main\nnothing to commit, working tree clean\n\n\nTrack changes to the data\nLet‚Äôs make some change to the data:\nrm data/raw/val/n03445777/ILSVRC2012_val*\nRemember that Git is not tracking the data:\ngit status\nOn branch main\nnothing to commit, working tree clean\nBut DVC is:\ndvc status\ndata/raw/val.dvc:\n    changed outs:\n            modified:           data/raw/val\n\n\nAdd changes to DVC\ndvc add data/raw/val\ndvc status\nData and pipelines are up to date.\nNow we need to commit the changes to the .dvc file to Git:\ngit status\nOn branch main\nChanges to be committed:\n    modified:   data/raw/val.dvc\n\nStaging happened automatically because I have set the autostage option to true on my system.\n\ngit commit -m \"Delete data/raw/val/n03445777/ILSVRC2012_val*\"\n\n\nCheck out older versions\nWhat if we want to go back to the 1st version of our data?\nFor this, we first use Git to checkout the proper commit, then run dvc checkout to have the data catch up to the .dvc file.\nTo avoid forgetting to run the commands that will make DVC catch up to Git, we can automate this process by installing Git hooks:\ndvc install\n\nNow, all we have to do is to checkout the commit we want:\ngit log --oneline\n94b520b (HEAD -&gt; main) Delete data/raw/val/n03445777/ILSVRC2012_val*\n92837a6 Initial version of data\ndd961c6 Add scripts\ndb9c14e Initialize repo\n7e08586 Initialize DVC\ngit checkout 92837a6\nThe version of the data in the working directory got automatically switched to match the .dvc file:\ndvc status\nData and pipelines are up to date.\nYou can look at your files to verify that the deleted files are back.\n\n\nGit workflows\ngit checkout is ok to have a look, but a detached HEAD is not a good place to create new commits.\nLet‚Äôs create a new branch and switch to it:\ngit switch -c alternative\nSwitched to a new branch 'alternative'\nGoing back and forth between both versions of our data is now as simple as switching branch:\ngit switch main\ngit switch alternative",
    "crumbs": [
      "Git",
      "<b><em>Webinars</em></b>",
      "Data version control with DVC",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "git/wb_dvc_content.html#collaboration",
    "href": "git/wb_dvc_content.html#collaboration",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Collaboration",
    "text": "Collaboration\n\nClassic workflow\nThe Git project (including .dvc files) go to a Git remote (GitHub/GitLab/Bitbucket/server).\nThe data go to a DVC remote (AWS/Azure/Google Drive/server/etc.).\n\n\nDVC remotes\nDVC can use many cloud storage or remote machines/server via SSH, WebDAV, etc.\nLet‚Äôs create a local remote here:\n# Create a directory outside the project\nmkdir ../remote\n\n# Setup default (-d) remote\ndvc remote add -d local_remote ../remote\nSetting 'local_remote' as a default remote.\ncat .dvc/config\n[core]\n    remote = local_remote\n['remote \"local_remote\"']\n    url = ../../remote\n\n\nCommit remote config\nThe new remote configuration should be committed:\ngit status\nOn branch alternative\n\nChanges not staged for commit:\n    modified:   .dvc/config\ngit add .\ngit commit -m \"Config remote\"\n\n\nPush to remotes\nLet‚Äôs push the data from the cache (.dvc/cache) to the remote:\ndvc push\n2702 files pushed\n\nWith Git hooks installed, dvc push is automatically run after git push.\n(But the data is pushed to the DVC remote while the files tracked by Git get pushed to the Git remote).\n\nBy default, the entire data cache gets pushed to the remote, but there are many options.\n\nExample: only push data corresponding to a certain .dvc files.\ndvc push data/raw/val.dvc\n\n\n\nPull from remotes\ndvc fetch downloads data from the remote into the cache. To have it update the working directory, follow by dvc checkout.\nYou can do these 2 commands at the same time with dvc pull.",
    "crumbs": [
      "Git",
      "<b><em>Webinars</em></b>",
      "Data version control with DVC",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "git/wb_dvc_content.html#tracking-experiments",
    "href": "git/wb_dvc_content.html#tracking-experiments",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Tracking experiments",
    "text": "Tracking experiments\n\nDVC pipelines\nDVC pipelines create reproducible workflows and are functionally similar to Makefiles.\nEach step in a pipeline is created with dvc stage add and add an entry to a dvc.yaml file.\n\ndvc stage add options:\n-n: name of stage\n-d: dependency\n-o: output\n\nEach stage contains:\n\ncmd: the command executed\ndeps: the dependencies\nouts: the outputs\n\nThe file is then used to visualize the pipeline and run it.\n\n\nExample\nLet‚Äôs create a pipeline to run a classifier on our data.\nThe pipeline contains 3 steps:\n\nprepare\ntrain\nevaluate\n\n\n\nCreate a pipeline\n\n1st stage (data preparation)\ndvc stage add -n prepare -d src/prepare.py -d data/raw \\\n    -o data/prepared/train.csv -o data/prepared/test.csv \\\n    python src/prepare.py\nAdded stage 'prepare' in 'dvc.yaml'\n\n\n2nd stage (training)\ndvc stage add -n train -d src/train.py -d data/prepared/train.csv \\\n    -o model/model.joblib \\\n    python src/train.py\nAdded stage `train` in 'dvc.yaml'\n\n\n3rd stage (evaluation)\ndvc stage add -n evaluate -d src/evaluate.py -d model/model.joblib \\\n    -M metrics/accuracy.json \\\n    python src/evaluate.py\nAdded stage `evaluate` in 'dvc.yaml'\n\n\n\nCommit pipeline\ngit commit -m \"Define pipeline\"\nprepare:\n    changed deps:\n            modified:           data/raw\n            modified:           src/prepare.py\n    changed outs:\n            deleted:            data/prepared/test.csv\n            deleted:            data/prepared/train.csv\ntrain:\n    changed deps:\n            deleted:            data/prepared/train.csv\n            modified:           src/train.py\n    changed outs:\n            deleted:            model/model.joblib\nevaluate:\n    changed deps:\n            deleted:            model/model.joblib\n            modified:           src/evaluate.py\n    changed outs:\n            deleted:            metrics/accuracy.json\n[main 4aa331b] Define pipeline\n 3 files changed, 27 insertions(+)\n create mode 100644 data/prepared/.gitignore\n create mode 100644 dvc.yaml\n create mode 100644 model/.gitignore\n\n\nVisualize pipeline in a DAG\ndvc dag\n+--------------------+         +------------------+\n| data/raw/train.dvc |         | data/raw/val.dvc |\n+--------------------+         +------------------+\n                  ***           ***\n                     **       **\n                       **   **\n                    +---------+\n                    | prepare |\n                    +---------+\n                          *\n                          *\n                          *\n                      +-------+\n                      | train |\n                      +-------+\n                          *\n                          *\n                          *\n                    +----------+\n                    | evaluate |\n                    +----------+\n\n\nRun pipeline\ndvc repro\n'data/raw/train.dvc' didn't change, skipping\n'data/raw/val.dvc' didn't change, skipping\nRunning stage 'prepare':\n&gt; python src/prepare.py\nGenerating lock file 'dvc.lock'\nUpdating lock file 'dvc.lock'\n\nRunning stage 'train':\n&gt; python src/train.py\nUpdating lock file 'dvc.lock'\n\nRunning stage 'evaluate':\n&gt; python src/evaluate.py\nUpdating lock file 'dvc.lock'\nUse `dvc push` to send your updates to remote storage.\n\n\ndvc repro breakdown\n\ndvc repro runs the dvc.yaml file in a Makefile fashion.\nFirst, it looks at the dependencies: the data didn‚Äôt change.\nThen it ran the commands to produce the outputs (since it is our first run, we had no outputs).\nWhen the 1st stage is run, a dvc.lock is created with information on that part of the run.\nWhen the 2nd and 3rd stages are run, dvc.lock is updated. At the end of the run dvc.lock contains all the info about the run we just did (version of the data used, etc.).\nA new directory called runs is created in .dvc/cache with cached data for this run.\n\n\n\nResults of the run\n\nThe prepared data was created in data/prepared (with a .gitignore to exclude it from Git‚Äîyou don‚Äôt want to track results in Git, but the scripts that can reproduce them).\nA model was saved in model (with another .gitignore file).\nThe accuracy of this run was created in metrics.\n\n\n\nClean working tree\nNow, we definitely want to create a commit with the dvc.lock.\nWe could add the metrics resulting from this run in the same commit:\ngit add metrics\ngit commit -m \"First pipeline run and results\"\nOur working tree is now clean and our data/pipeline up to date:\ngit status\nOn branch alternative\nnothing to commit, working tree clean\ndvc status\nData and pipelines are up to date.\n\n\nModify pipeline\nFrom now on, if we edit one of the scripts, or one of the dependencies, dvc status will tell us what changed and dvc repro will only rerun the parts of the pipeline to update the result, pretty much as a Makefile would.\n\n\nGoing further ‚Ä¶ next time\nDVC is a sophisticated tool with many additional features:\n\nCreation of data registries\nDVCLive (Python library to log experiment metrics).\nVisualize the performance logs as plots.\nContinuous integration with CML (Continuous Machine Learning).",
    "crumbs": [
      "Git",
      "<b><em>Webinars</em></b>",
      "Data version control with DVC",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "git/wb_lazygit.html",
    "href": "git/wb_lazygit.html",
    "title": "A great Git TUI: lazygit",
    "section": "",
    "text": "While it is important to know how to use Git from the command line, this makes for an austere experience: a series of commands are required to gather information on the state of the working tree, see changes to files, or get a schematic of the commit history. Committing sections of files interactively and other operations are just awkward affairs. On the other hand, the many graphic interfaces for Git are often buggy, slow, and limiting.\nOne option is to write exciting functions with tools such as fzf to make things more friendly and visual. A simpler and more polished option is to use an already built user interface for Git that runs directly in the command line. lazygit is one such open source tool. After years of development, it is a mature, beautiful tool that allows to perform any Git operation in the command line in a convenient, fast, and visual fashion.\nIn this webinar, I will demo how I use lazygit in my daily workflow to run routine as well as more complex Git commands.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "Git",
      "<b><em>Webinars</em></b>",
      "A great Git TUI: lazygit"
    ]
  },
  {
    "objectID": "git/wb_lazygit_slides.html#git-interfaces",
    "href": "git/wb_lazygit_slides.html#git-interfaces",
    "title": "A great Git TUI: lazygit",
    "section": "Git interfaces",
    "text": "Git interfaces\nThere are 3 main ways to use Git:\n\nThrough a Git GUI\nFrom the command line\nIntegrated within IDE"
  },
  {
    "objectID": "git/wb_lazygit_slides.html#git-interfaces-1",
    "href": "git/wb_lazygit_slides.html#git-interfaces-1",
    "title": "A great Git TUI: lazygit",
    "section": "Git interfaces",
    "text": "Git interfaces\nThey all have downsides:\n\nThrough a Git GUI ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇ¬†‚ûî ‚ÄÇSlow and buggy\nFrom the command line ‚ÄÇ‚ÄÇ‚ûî ‚ÄÇAustere and unintuitive\nIntegrated within IDE ‚ÄÉ‚ÄÉ¬†¬†‚ûî ‚ÄÇLimited"
  },
  {
    "objectID": "git/wb_lazygit_slides.html#on-the-beauty-of-tuis",
    "href": "git/wb_lazygit_slides.html#on-the-beauty-of-tuis",
    "title": "A great Git TUI: lazygit",
    "section": "On the beauty of TUIs",
    "text": "On the beauty of TUIs\nTerminal user interfaces (TUIs) were precursors to graphical user interfaces (GUIs), but they did not disappear\nPeople continue to build TUIs because they uniquely provide the speed of the command line and the easy of use of GUIs\nGitHub is full of sleek, modern, open source TUIs for all sorts of applications\nSeveral of them provide an interface to Git\nMy personal TUIs of choice are ranger as file manager and lazygit for Git"
  },
  {
    "objectID": "git/wb_lazygit_slides.html#lazygit",
    "href": "git/wb_lazygit_slides.html#lazygit",
    "title": "A great Git TUI: lazygit",
    "section": "lazygit",
    "text": "lazygit\nWith over 52k stars on GitHub, lazygit, created and maintained by Jesse Duffield is probably the most polished Git TUI\nI followed it as it grew and developed over the past 5 years. It was great from the start, but by now, it is a truly beautiful mature tool\nIt is cross-platform. You can find installation instructions in the README"
  },
  {
    "objectID": "git/wb_lazygit_slides.html#lazygit-1",
    "href": "git/wb_lazygit_slides.html#lazygit-1",
    "title": "A great Git TUI: lazygit",
    "section": "lazygit",
    "text": "lazygit\nGet command options:\nlazygit -h\nPrint default configurations with:\nlazygit -c\n\nlazygit is fully customizable"
  },
  {
    "objectID": "git/wb_lazygit_slides.html#resources",
    "href": "git/wb_lazygit_slides.html#resources",
    "title": "A great Git TUI: lazygit",
    "section": "Resources",
    "text": "Resources\n\nRepo\nDefault kbds\nConfiguration options"
  },
  {
    "objectID": "git/wb_lazygit_slides.html#time-for-a-demo",
    "href": "git/wb_lazygit_slides.html#time-for-a-demo",
    "title": "A great Git TUI: lazygit",
    "section": "Time for a demo!",
    "text": "Time for a demo!\nI will spend the rest of this webinar showing you how to use Git through lazygit"
  },
  {
    "objectID": "git/ws_contrib.html",
    "href": "git/ws_contrib.html",
    "title": "Collaborating to projects on GitHub",
    "section": "",
    "text": "There are countless free and open source tools on GitHub and if you use one such tool and find a problem or think that you can improve the project, or if you would like to request a novel feature, how do you go about it?\nIn this workshop, we will learn how to contribute to open source projects hosted on GitHub by opening issues and submitting pull requests.",
    "crumbs": [
      "Git",
      "<b><em>Workshops</em></b>",
      "Contributing to projects"
    ]
  },
  {
    "objectID": "git/ws_contrib.html#opening-issues",
    "href": "git/ws_contrib.html#opening-issues",
    "title": "Collaborating to projects on GitHub",
    "section": "Opening issues",
    "text": "Opening issues\nThe easiest thing to do, if for instance, you are having problems with the tool, found a bug, or want to submit a feature request, is to open an issue.\nGitHub has also now implemented the ability to open Discussions. If enabled by the maintainer of a project, this is the place where you want to ask for help.",
    "crumbs": [
      "Git",
      "<b><em>Workshops</em></b>",
      "Contributing to projects"
    ]
  },
  {
    "objectID": "git/ws_contrib.html#forking-a-project",
    "href": "git/ws_contrib.html#forking-a-project",
    "title": "Collaborating to projects on GitHub",
    "section": "Forking a project",
    "text": "Forking a project\nNow, a more advanced approach is to actually make changes to the code of the project.\nIf you want to develop your own version of the project, you can fork the GitHub repository: go to GitHub and fork the project by clicking on the Fork button in the top right corner.\nYou have all privileges on the forked project. So you can make any change you want there. You can clone it to your machine and develop the fork. But your fork does not get updated to the improvements made to the initial project. It is an independent project of its own.",
    "crumbs": [
      "Git",
      "<b><em>Workshops</em></b>",
      "Contributing to projects"
    ]
  },
  {
    "objectID": "git/ws_contrib.html#keeping-a-fork-up-to-date",
    "href": "git/ws_contrib.html#keeping-a-fork-up-to-date",
    "title": "Collaborating to projects on GitHub",
    "section": "Keeping a fork up to date",
    "text": "Keeping a fork up to date\nIf you want to keep your fork up to date with the initial project, you need to:\n\n1. Clone your fork on your machine\nThis will automatically set your fork on GitHub as the remote called origin:\n# If you have set SSH for your GitHub account\ngit clone git@github.com:&lt;user&gt;/&lt;repo&gt;.git &lt;name&gt;\n\n# If you haven't set SSH\ngit clone https://github.com/&lt;user&gt;/&lt;repo&gt;.git &lt;name&gt;\n\n\n2. Add upstream\nAdd a second remote, this one pointing to the initial project. It is usual to call this remote upstream:\n# If you have set SSH for your GitHub account\ngit remote add upstream git@github.com:&lt;user&gt;/&lt;repo&gt;.git\n\n# If you haven't set SSH\ngit remote add upstream https://github.com/&lt;user&gt;/&lt;repo&gt;.git\n\n\n3. Pull from upstream\nYou can now pull from upstream to keep your fork up to date.\nFrom there on, you can pull from and push to origin (your fork) and you can pull from upstream (the initial repo).\nOf course, if your project and the initial one diverge in places, this will lead to conflicts that you will have to resolve as you merge the pulls from upstream.\nMost of the time however, you don‚Äôt want to develop your own version of the project. Instead, you want to make the initial project better by contributing to it. But you can‚Äôt push changes to upstream directly since you are not part of that project. You don‚Äôt have write access to that repository. If anybody could push to any project, that would be utter chaos.\nSo how do you contribute code to someone else‚Äôs project?",
    "crumbs": [
      "Git",
      "<b><em>Workshops</em></b>",
      "Contributing to projects"
    ]
  },
  {
    "objectID": "git/ws_contrib.html#creating-pull-requests",
    "href": "git/ws_contrib.html#creating-pull-requests",
    "title": "Collaborating to projects on GitHub",
    "section": "Creating pull requests",
    "text": "Creating pull requests\nHere is the workflow as described in the Git manual:\n\nPull from upstream to make sure that your contributions are made on an up-to-date version of the project\nCreate and checkout a new branch\nMake and commit your changes on that branch\nPush that branch to your fork (i.e.¬†origin‚Äîremember that you do not have write access on upstream)\nGo to the original project GitHub‚Äôs page and open a pull request from your fork. Note that after you have pushed your branch to origin, GitHub will automatically offer you to do so.\n\nThe maintainer of the initial project may accept or decline the PR. They may also make comments and ask you to make changes. If so, make new changes and push additional commits to that branch until they are happy with the change.\nOnce the PR is merged by the maintainer, you can delete the branch on your fork and pull from upstream to update your local fork with the recently accepted changes.",
    "crumbs": [
      "Git",
      "<b><em>Workshops</em></b>",
      "Contributing to projects"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Training in Research Computing",
    "section": "",
    "text": "AI\nDeep learning frameworks\n\n\n\n\nR\nStatistical programming\n\n\n\n\nPython\nScientific programming\n\n\n\n\nJulia\nJIT-compiled programming\n\n\n\n\n\n\nGit\nVersion control & collaboration\n\n\n\n\nBash/Zsh\nCommand line & Unix shell scripting\n\n\n\n\nEmacs\nPower editor & programming IDE\n\n\n\n\nTools\nTools for research computing\n\n\n\n\n\n¬†\n\n\n\n\n\nLogging in to our training clusters\nInstructions on how to log in to the temporary training clusters that we use in a lot of our courses\n\n\n\n\n\nOur training websites\nThis is the MINT (‚ÄúMint Is Not Training‚Äù) website. It contains courses, webinars, and workshops by Marie-H√©l√®ne Burle.\nTo view all our training material, please visit the training website."
  },
  {
    "objectID": "julia/hpc_intro.html",
    "href": "julia/hpc_intro.html",
    "title": "Introduction to high performance research computing in Julia",
    "section": "",
    "text": "When you launch a Jupyter session from a JupyterHub, you are running a Slurm job on a compute node. If you want to play for 8 hours in Jupyter, you are requesting an 8 hour job. Now, most of the time you spend on Jupyter is spent typing, running bits and pieces of code, or doing nothing at all. If you ask for GPUs, many CPUs, and lots of RAM, all of it will remain idle most of the time. This is a suboptimal use of resources.\nIn addition, if you ask for lots of resources for a long time, you will have to wait for a while before they get allocated to you.\nLastly, you will go through your allocations quickly.\nAll of this applies equally for interactive sessions launched from an SSH session with salloc.",
    "crumbs": [
      "Julia",
      "<b><em>High-performance Julia</em></b>",
      "Intro to HPC in Julia"
    ]
  },
  {
    "objectID": "julia/hpc_intro.html#interactive-sessions-for-high-performance-computing",
    "href": "julia/hpc_intro.html#interactive-sessions-for-high-performance-computing",
    "title": "Introduction to high performance research computing in Julia",
    "section": "",
    "text": "When you launch a Jupyter session from a JupyterHub, you are running a Slurm job on a compute node. If you want to play for 8 hours in Jupyter, you are requesting an 8 hour job. Now, most of the time you spend on Jupyter is spent typing, running bits and pieces of code, or doing nothing at all. If you ask for GPUs, many CPUs, and lots of RAM, all of it will remain idle most of the time. This is a suboptimal use of resources.\nIn addition, if you ask for lots of resources for a long time, you will have to wait for a while before they get allocated to you.\nLastly, you will go through your allocations quickly.\nAll of this applies equally for interactive sessions launched from an SSH session with salloc.",
    "crumbs": [
      "Julia",
      "<b><em>High-performance Julia</em></b>",
      "Intro to HPC in Julia"
    ]
  },
  {
    "objectID": "julia/hpc_intro.html#a-better-approach",
    "href": "julia/hpc_intro.html#a-better-approach",
    "title": "Introduction to high performance research computing in Julia",
    "section": "A better approach",
    "text": "A better approach\nA more efficient strategy is to develop and test your code with small samples, few iterations, etc. in an interactive job (from an SSH session in the cluster with salloc), on your own computer, or in Jupyter. Once you are confident that your code works, launch an sbatch job from an SSH session in the cluster to run the code as a script on all your data. This ensures that heavy duty resources that you requested are actually put to use to run your heavy calculations and not seating idle while you are thinking, typing, etc.",
    "crumbs": [
      "Julia",
      "<b><em>High-performance Julia</em></b>",
      "Intro to HPC in Julia"
    ]
  },
  {
    "objectID": "julia/hpc_intro.html#logging-on-to-the-cluster",
    "href": "julia/hpc_intro.html#logging-on-to-the-cluster",
    "title": "Introduction to high performance research computing in Julia",
    "section": "Logging on to the cluster",
    "text": "Logging on to the cluster\nOpen a terminal emulator:\nWindows users: ‚ÄÉlaunch MobaXTerm.\nmacOS users: ‚ÄÉ‚ÄÉlaunch Terminal.\nLinux users: ‚ÄÉ‚ÄÉ‚ÄÇ¬†launch xterm or the terminal emulator of your choice.\nThen access the cluster through secure shell:\n$ ssh &lt;username&gt;@&lt;hostname&gt;    # enter password",
    "crumbs": [
      "Julia",
      "<b><em>High-performance Julia</em></b>",
      "Intro to HPC in Julia"
    ]
  },
  {
    "objectID": "julia/hpc_intro.html#accessing-julia",
    "href": "julia/hpc_intro.html#accessing-julia",
    "title": "Introduction to high performance research computing in Julia",
    "section": "Accessing Julia",
    "text": "Accessing Julia\nThis is done with the Lmod tool through the module command. You can find the full documentation here and below are the subcommands you will need:\n# get help on the module command\n$ module help\n$ module --help\n$ module -h\n\n# list modules that are already loaded\n$ module list\n\n# see which modules are available for Julia\n$ module spider julia\n\n# see how to load julia 1.3\n$ module spider julia/1.3.0\n\n# load julia 1.3 with the required gcc module first\n# (the order is important)\n$ module load gcc/7.3.0 julia/1.3.0\n\n# you can see that we now have Julia loaded\n$ module list",
    "crumbs": [
      "Julia",
      "<b><em>High-performance Julia</em></b>",
      "Intro to HPC in Julia"
    ]
  },
  {
    "objectID": "julia/hpc_intro.html#copying-files-to-the-cluster",
    "href": "julia/hpc_intro.html#copying-files-to-the-cluster",
    "title": "Introduction to high performance research computing in Julia",
    "section": "Copying files to the cluster",
    "text": "Copying files to the cluster\nWe will create a julia_workshop directory in ~/scratch, then copy our julia script in it.\n$ mkdir ~/scratch/julia_job\nOpen a new terminal window and from your local terminal (make sure that you are not on the remote terminal by looking at the bash prompt) run:\n$ scp /local/path/to/sort.jl &lt;username&gt;@&lt;hostname&gt;:scratch/julia_job\n$ scp /local/path/to/psort.jl &lt;username&gt;@&lt;hostname&gt;:scratch/julia_job\n\n# enter password",
    "crumbs": [
      "Julia",
      "<b><em>High-performance Julia</em></b>",
      "Intro to HPC in Julia"
    ]
  },
  {
    "objectID": "julia/hpc_intro.html#job-scripts",
    "href": "julia/hpc_intro.html#job-scripts",
    "title": "Introduction to high performance research computing in Julia",
    "section": "Job scripts",
    "text": "Job scripts\nWe will not run an interactive session with Julia on the cluster: we already have julia scripts ready to run. All we need to do is to write job scripts to submit to Slurm, the job scheduler used by the Alliance clusters.\nWe will create 2 scripts: one to run Julia on one core and one on as many cores as are available.\n\n\nYour turn:\n\nHow many processors are there on our training cluster?\n\nWe can run Julia with multiple threads by running:\n$ JULIA_NUM_THREADS=2 julia\nor:\n$ julia -t 2\nOnce in Julia, you can double check that Julia does indeed have access to 2 threads by running:\nThreads.nthreads()\nSave your job scripts in the files ~/scratch/julia_job/job_julia1c.sh and job_julia2c.sh for one and two cores respectively.\nHere is what our single core Slurm script looks like:\n#!/bin/bash\n#SBATCH --job-name=julia1c          # job name\n#SBATCH --time=00:01:00             # max walltime 1 min\n#SBATCH --cpus-per-task=1           # number of cores\n#SBATCH --mem=1000                  # max memory (default unit is megabytes)\n#SBATCH --output=julia1c%j.out      # file name for the output\n#SBATCH --error=julia1c%j.err       # file name for errors\n# %j gets replaced with the job number\n\necho Running NON parallel script\njulia sort.jl\necho Running parallel script on $SLURM_CPUS_PER_TASK core\njulia -t $SLURM_CPUS_PER_TASK psort.jl\n\n\nYour turn:\n\nWrite the script for 2 cores.\n\nNow, we can submit our jobs to the cluster:\n$ cd ~/scratch/julia_job\n$ sbatch job_julia1c.sh\n$ sbatch job_julia2c.sh\nAnd we can check their status with:\n$ sq      # This is an Alliance alias for `squeue -u $USER $@`\n\nPD stands for pending\nR stands for running",
    "crumbs": [
      "Julia",
      "<b><em>High-performance Julia</em></b>",
      "Intro to HPC in Julia"
    ]
  },
  {
    "objectID": "julia/hpc_performance.html",
    "href": "julia/hpc_performance.html",
    "title": "Performance",
    "section": "",
    "text": "If there is one thing you need to remember from this lesson, it is to avoid global variables (that is, avoid variables defined in the global environment).",
    "crumbs": [
      "Julia",
      "<b><em>High-performance Julia</em></b>",
      "Performance"
    ]
  },
  {
    "objectID": "julia/hpc_performance.html#definitions",
    "href": "julia/hpc_performance.html#definitions",
    "title": "Performance",
    "section": "Definitions",
    "text": "Definitions\nScope of variables: ‚ÄÉ¬†Environment within which a variables exist\nGlobal scope: ‚ÄÉ‚ÄÉ‚ÄÉ¬†¬†Global environment of a module\nLocal scope: ‚ÄÇ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇEnvironment within a function, a loop, a struct, a macro, etc.",
    "crumbs": [
      "Julia",
      "<b><em>High-performance Julia</em></b>",
      "Performance"
    ]
  },
  {
    "objectID": "julia/hpc_performance.html#why-avoid-global-variables",
    "href": "julia/hpc_performance.html#why-avoid-global-variables",
    "title": "Performance",
    "section": "Why avoid global variables?",
    "text": "Why avoid global variables?\nThe Julia compiler is not good at optimizing code using global variables. Part of the reason is that their type can change.\n\nExample\nWe will use the @time macro to time a loop:\n\nIn the global environment:\n\n\ntotal = 0\nn = 1e6\n\n@time for i in 1:n\n    global total += i\nend\n\n  0.258970 seconds (4.15 M allocations: 83.561 MiB, 5.19% gc time, 47.93% compilation time)\n\n\n\nNote the garbage collection (gc) time: 14% of total time.\nGarbage collection time is a sign of poor code.\n\n\nIn a local environment (a function):\n\n\nfunction local_loop(total, n)\n    total = total\n    @time for i in 1:n\n        global total += i\n    end\nend\n\nlocal_loop(0, 1e6)\n\n  0.025520 seconds (2.00 M allocations: 30.518 MiB)\n\n\n\nWe get a 7.5 speedup.\nThe memory allocation also decreased by more than half.\n\nFor more accurate performance measurements, you should use the @btime macro from the BenchmarkTools package which excludes compilation time from the timing, averages metrics over multiple runs, and is highly customizable.",
    "crumbs": [
      "Julia",
      "<b><em>High-performance Julia</em></b>",
      "Performance"
    ]
  },
  {
    "objectID": "julia/intro_basics.html",
    "href": "julia/intro_basics.html",
    "title": "Basics of the Julia language",
    "section": "",
    "text": "Comments do not get evaluated by Julia and are for humans only.\n\n# Comments in Julia are identified by hastags\n\n\n#=\nComments can also spread over multiple lines\nif you enclose them with this syntax\n=#\n\n\nx = 2          # Comments can be added at the end of lines\n\n2",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Basics of the Julia language"
    ]
  },
  {
    "objectID": "julia/intro_basics.html#comments",
    "href": "julia/intro_basics.html#comments",
    "title": "Basics of the Julia language",
    "section": "",
    "text": "Comments do not get evaluated by Julia and are for humans only.\n\n# Comments in Julia are identified by hastags\n\n\n#=\nComments can also spread over multiple lines\nif you enclose them with this syntax\n=#\n\n\nx = 2          # Comments can be added at the end of lines\n\n2",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Basics of the Julia language"
    ]
  },
  {
    "objectID": "julia/intro_basics.html#basic-operations",
    "href": "julia/intro_basics.html#basic-operations",
    "title": "Basics of the Julia language",
    "section": "Basic operations",
    "text": "Basic operations\n\n# By default, Julia returns the output\n2 + 3\n\n5\n\n\n\n# Trailing semi-colons suppress the output\n3 + 7;\n\n\n# Alternative syntax that can be used with operators\n+(2, 5)\n\n7\n\n\n\n# Updating operators\na = 3\na += 8    # this is the same as a = a + 8\n\n11\n\n\n\n# Operator precedence follows standard rules\n3 + 2 ^ 3 * 10\n\n83\n\n\n\nMore exotic operators\n\n# Usual division\n6 / 2\n\n3.0\n\n\n\n# Inverse division\n2 \\ 6\n\n3.0\n\n\n\n# Integer division (division truncated to an integer)\n7 √∑ 2\n\n3\n\n\n\n# Remainder\n7 % 2        # equivalent to rem(7, 2)\n\n1\n\n\n\n# Fraction\n4//8\n\n1//2\n\n\n\n# Julia supports fraction operations\n1//2 + 3//4\n\n5//4",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Basics of the Julia language"
    ]
  },
  {
    "objectID": "julia/intro_basics.html#variables",
    "href": "julia/intro_basics.html#variables",
    "title": "Basics of the Julia language",
    "section": "Variables",
    "text": "Variables\n\n\n\nfrom xkcd.com\n\n\nA variable is a name bound to a value:\n\na = 3;\n\nIt can be called:\n\na\n\n3\n\n\nOr used in expressions:\n\na + 2\n\n5\n\n\n\nAssignment\nYou can re-assign new values to variables:\n\na = 3;\na = -8.2;\na\n\n-8.2\n\n\nEven values of a different type:\n\na = \"a is now a string\"\n\n\"a is now a string\"\n\n\nYou can define multiple variables at once:\n\na, b, c = 1, 2, 3\nb\n\n2\n\n\n\n\nVariable names\nThese names are extremely flexible and can use Unicode character:\n\\omega       # press TAB\n\\sum         # press TAB\n\\sqrt        # press TAB\n\\in          # press TAB\n\\:phone:     # press TAB\n\nŒ¥ = 8.5;\nüêå = 3;\nŒ¥ + üêå\n\n11.5\n\n\nAdmittedly, using emojis doesn‚Äôt seem very useful, but using Greek letters to write equations really makes Julia a great mathematical language:\n\nœÉ = 3\nŒ¥ = œÄ\nœï = 8\n\n(5œÉ + 3Œ¥) / œï\n\n3.0530972450961724\n\n\n\nNote how the multiplication operator can be omitted when this does not lead to confusion. Also note how the mathematical constant œÄ is available in Julia without having to load any module.\n\nIf you want to know how to type a symbol, ask Julia: type ? and paste it in the REPL.\nThe only hard rules for variable names are:\n\nThey must begin with a letter or an underscore,\nThey cannot take the names of built-in keywords such as if, do, try, else,\nThey cannot take the names of built-in constants (e.g.¬†œÄ) and keywords in use in a session.\n\n\nWe thus get an error here:\n\n\nfalse = 3\n\n\nsyntax: invalid assignment location \"false\" around /home/marie/parvus/prog/mint/julia/intro_basics.qmd:182\nStacktrace:\n [1] top-level scope\n   @ ~/parvus/prog/mint/julia/intro_basics.qmd:182\n\n\n\nIn addition, the Julia Style Guide recommends to follow these conventions:\n\nUse lower case,\nWord separation can be indicated by underscores, but better not to use them if the names can be read easily enough without them.\n\n\n\nThe ans variable\nThe keyword ans is a variable which, in the REPL, takes the value of the last computation:\na = 3 ^ 2;\nans + 1\n10\n\n\nPrinting\nTo print the value of a variable in an interactive session, you only need to call it:\n\na = 3;\na\n\n3\n\n\nIn non interactive sessions, you have to use the println function:\n\nprintln(a)\n\n3",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Basics of the Julia language"
    ]
  },
  {
    "objectID": "julia/intro_basics.html#quotes",
    "href": "julia/intro_basics.html#quotes",
    "title": "Basics of the Julia language",
    "section": "Quotes",
    "text": "Quotes\nNote the difference between single and double quotes:\n\ntypeof(\"a\")\n\nString\n\n\n\ntypeof('a')\n\nChar\n\n\n\n\"This is a string\"\n\n\"This is a string\"\n\n\n\n'This is not a sring'\n\n\nParseError:\n# Error @ ]8;;file:///home/marie/parvus/prog/mint/julia/intro_basics.qmd#235:2\\/home/marie/parvus/prog/mint/julia/intro_basics.qmd:235:2]8;;\\\n'This is not a sring'\n#‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÄ‚îÄ character literal contains multiple characters\nStacktrace:\n [1] top-level scope\n   @ ~/parvus/prog/mint/julia/intro_basics.qmd:235\n\n\n\n\nWe got an error here since ' is used for the character type and can thus only contain a single character.\n\n\n'a'\n\n'a': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Basics of the Julia language"
    ]
  },
  {
    "objectID": "julia/intro_control_flow.html",
    "href": "julia/intro_control_flow.html",
    "title": "Control flow",
    "section": "",
    "text": "Control flow statements alter the linear execution of code, allowing for one or another section of code to be executed, or for one section of code to be executed multiple times.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Control flow"
    ]
  },
  {
    "objectID": "julia/intro_control_flow.html#conditional-statements",
    "href": "julia/intro_control_flow.html#conditional-statements",
    "title": "Control flow",
    "section": "Conditional statements",
    "text": "Conditional statements\nConditional statements allow to run instructions based on predicates: different sets of instructions will be executed depending on whether the predicates return true or false.\n\nPredicates\n\nHere are a few examples of predicates with classic operators:\n\noccursin(\"that\", \"this and that\")\n4 &lt; 3\na == b\na != b\n2 in 1:3\n3 &lt;= 4 && 4 &gt; 5\n3 &lt;= 4 || 4 &gt; 5\nIn addition, Julia possesses more exotic operators that can be used in predicates:\n\nThe inexact equality comparator, useful to compare floating-point numbers despite computer rounding.\n\n\nThe function isapprox or the equivalent binary operator ‚âà (typed with \\approx&lt;tab&gt;) can be used:\n\n0.1 + 0.2 == 0.3\n\nfalse\n\n\n\n0.1 + 0.2 ‚âà 0.3\n\ntrue\n\n\n\nisapprox(0.1 + 0.2, 0.3)\n\ntrue\n\n\nThe negatives are the function !isapprox and ‚ââ (typed with \\napprox&lt;tab&gt;).\n\n\nThe equivalent or triple equal operator compares objects in deeper ways (address in memory for mutable objects and content at the bit level for immutable objects).\n\n\n=== or ‚â° (typed with \\equiv&lt;tab&gt;) can be used:\n\na = [1, 2]; b = [1, 2];\n\n\na == b\n\ntrue\n\n\n\na ‚â° b     # This can also be written `a === b`\n\nfalse\n\n\n\na ‚â° a\n\ntrue\n\n\n\n\n\nIf statements\nif &lt;predicate&gt;\n    &lt;some action&gt;\nend\n\nIf &lt;predicate&gt; evaluates to true, the body of the if statement gets evaluated (&lt;some action&gt; is run),\nIf &lt;predicate&gt; evaluates to false, nothing happens.\n\n\nExample:\n\n\nfunction testsign1(x)\n    if x &gt;= 0\n        println(\"x is positive\")\n    end\nend\n\ntestsign1 (generic function with 1 method)\n\n\n\ntestsign1(3)\n\nx is positive\n\n\n\ntestsign1(-2)\n\n\nNothing gets returned since the predicate returned false.\n\n\n\nIf else statements\nif &lt;predicate&gt;\n    &lt;some action&gt;\nelse\n    &lt;some other action&gt;\nend\n\nIf &lt;predicate&gt; evaluates to true, &lt;some action&gt; is done,\nIf &lt;predicate&gt; evaluates to false, &lt;some other action&gt; is done.\n\n\nExample:\n\n\nfunction testsign2(x)\n    if x &gt;= 0\n        println(\"x is positive\")\n    else\n        println(\"x is negative\")\n    end\nend\n\ntestsign2 (generic function with 1 method)\n\n\n\ntestsign2(3)\n\nx is positive\n\n\n\ntestsign2(-2)\n\nx is negative\n\n\nIf else statements can be written in a terse format using the ternary operator:\n&lt;predicate&gt; ? &lt;some action&gt; : &lt;some other action&gt;\n\nHere is our function testsign2 written in terse format:\n\n\nfunction testsign2(x)\n    x &gt;= 0 ? println(\"x is positive\") : println(\"x is negative\")\nend\n\ntestsign2(-2)\n\nx is negative\n\n\n\nHere is another example:\n\na = 2\nb = 2.0\n\nif a == b\n    println(\"It's true\")\nelse\n    println(\"It's false\")\nend\nAnd in terse format:\n\na == b ? println(\"It's true\") : println(\"It's false\")\n\nIt's true\n\n\n\n\nIf elseif else statements\nif &lt;predicate1&gt;\n    &lt;some action&gt;\nelseif &lt;predicate2&gt;\n    &lt;some other action&gt;\nelse\n    &lt;yet some other action&gt;\nend\n\nExample:\n\n\nfunction testsign3(x)\n    if x &gt; 0\n        println(\"x is positive\")\n    elseif x == 0\n        println(\"x is zero\")\n    else\n        println(\"x is negative\")\n    end\nend\n\ntestsign3 (generic function with 1 method)\n\n\n\ntestsign3(3)\n\nx is positive\n\n\n\ntestsign3(0)\n\nx is zero\n\n\n\ntestsign3(-2)\n\nx is negative",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Control flow"
    ]
  },
  {
    "objectID": "julia/intro_control_flow.html#loops",
    "href": "julia/intro_control_flow.html#loops",
    "title": "Control flow",
    "section": "Loops",
    "text": "Loops\n\nFor loops\nFor loops run a set of instructions for each element of an iterable:\nfor &lt;iterable&gt;\n    &lt;some action&gt;\nend\n\nExamples:\n\n\nfor name = [\"Paul\", \"Lucie\", \"Sophie\"]\n    println(\"Hello $name\")\nend\n\nHello Paul\nHello Lucie\nHello Sophie\n\n\n\nfor i = 1:3, j = 3:5\n    println(i + j)\nend\n\n4\n5\n6\n5\n6\n7\n6\n7\n8\n\n\n\n\nWhile loops\nWhile loops run as long as a condition remains true:\nwhile &lt;predicate&gt;\n    &lt;some action&gt;\nend\n\nExample:\n\n\ni = 0\n\nwhile i &lt;= 10\n    println(i)\n    i += 1\nend\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Control flow"
    ]
  },
  {
    "objectID": "julia/intro_julia.html",
    "href": "julia/intro_julia.html",
    "title": "Introduction to Julia",
    "section": "",
    "text": "Why would I want to learn a new language? I already know R/python.\n\nR and python are interpreted languages: the code is executed directly, without prior-compilation. This is extremely convenient: it is what allows you to run code in an interactive shell. The price to pay is low performance: R and python are simply not good at handling large amounts of data. To overcome this limitation, users often turn to C or C++ for the most computation-intensive parts of their analyses. These are compiled‚Äîand extremely efficient‚Äîlanguages, but the need to use multiple languages and the non-interactive nature of compiled languages make this approach tedious.\nJulia uses just-in-time (JIT) compilation: the code is compiled at run time. This combines the interactive advantage of interpreted languages with the efficiency of compiled ones. Basically, it feels like running R or python, while it is almost as fast as C. This makes Julia particularly well suited for big data analyses, machine learning, or heavy modelling.\nIn addition, multiple dispatch (generic functions with multiple methods depending on the types of all the arguments) is at the very core of Julia. This is extremly convenient, cutting on conditionals and repetitions, and allowing for easy extensibility without having to rewrite code.\nFinally, Julia shines by its extremely clean and concise syntax. This last feature makes it easy to learn and really enjoyable to use.\nIn this workshop, which does not require any prior experience in Julia (experience in another language‚Äîe.g.¬†R or python‚Äîwould be best), we will go over the basics of Julia‚Äôs syntax and package system; then we will push the performance aspect further by looking at how Julia can make use of clusters for large scale parallel computing.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Introduction to Julia"
    ]
  },
  {
    "objectID": "julia/intro_julia.html#introducing-julia",
    "href": "julia/intro_julia.html#introducing-julia",
    "title": "Introduction to Julia",
    "section": "Introducing Julia",
    "text": "Introducing Julia\n\nBrief history\nStarted in 2009 by Jeff Bezanson, Stefan Karpinski, Viral B. Shah, and Alan Edelman, the general-purpose programming language Julia was launched in 2012 as free and open source software. Version 1.0 was released in 2018.\nRust developer Graydon Hoare wrote an interesting post which places Julia in a historical context of programming languages.\n\n\nWhy another language?\n\nJIT\nComputer languages mostly fall into two categories: compiled languages and interpreted languages.\n\nCompiled languages\nCompiled languages require two steps:\n\nin a first step the code you write in a human-readable format (the source code, usually in plain text) gets compiled into machine code\nit is then this machine code that is used to process your data\n\nSo you write a script, compile it, then use it.\n\nBecause machine code is a lot easier to process by computers, compiled languages are fast. The two step process however makes prototyping new code less practical, these languages are hard to learn, and debugging compilation errors can be challenging.\n\nExamples of compiled languages include C, C++, Fortran, Go, and Haskell.\n\n\n\nInterpreted languages\nInterpreted languages are executed directly which has many advantages such as dynamic typing and direct feed-back from the code and they are easy to learn, but this comes at the cost of efficiency. The source code can facultatively be bytecompiled into non human-readable, more compact, lower level bytecode which is read by the interpreter more efficiently.\n\n\nExamples of interpreted languages include R, Python, Perl, and JavaScript.\n\n\n\nA common workflow\nSo, with this, what do researchers do?\nA common workflow, with the constraints of either type of languages, consists of:\n\nexploring the data and developing code using a sample of the data or reasonably light computations in an interpreted language,\ntranslating the code into a compiled language,\nfinally throwing the full data and all the heavy duty computation at that optimized code.\n\nThis works and it works well.\nBut, as you can imagine, this roundabout approach is tedious, not to mention the fact that it involves mastering 2 languages.\n\n\nJIT compiled languages\nJulia uses just-in-time compilation or JIT based on LLVM: the source code is compiled at run time. This combines the flexibility of interpretation with the speed of compilation, bringing speed to an interactive language. It also allows for dynamic recompilation, continuous weighing of gains and costs of the compilation of parts of the code, and other on the fly optimizations.\nOf course, there are costs here too. They come in the form of overhead time to compile code the first time it is run and increased memory usage.\n\n\n\nMultiple dispatch\nIn languages with multiple dispatch, functions apply different methods at run time based on the type of the operands. This brings great type stability and improves speed.\nJulia is extremely flexible: type declaration is not required. Out of convenience, you can forego the feature if you want. Specifying types however will greatly optimize your code.\nHere is a good post on type stability, multiple dispatch, and Julia efficiency.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Introduction to Julia"
    ]
  },
  {
    "objectID": "julia/intro_julia.html#how-to-run-julia",
    "href": "julia/intro_julia.html#how-to-run-julia",
    "title": "Introduction to Julia",
    "section": "How to run Julia?",
    "text": "How to run Julia?\nThere are several ways to run Julia interactively:\n\ndirectly in the REPL (read‚Äìeval‚Äìprint loop: the interactive Julia shell),\nin interactive notebooks (e.g.¬†Jupyter, Pluto),\nin an editor able to run Julia interactively (e.g.¬†Emacs, VS Code, Vim).\n\nLet‚Äôs have a look at these interfaces.\n\nThe Julia REPL\nYou can launch the REPL from a terminal directly by typing the julia command.\n\nREPL keybindings\nIn the REPL, you can use standard command line keybindings (Emacs kbd):\nC-c     cancel\nC-d     quit\nC-l     clear console\n\nC-u     kill from the start of line\nC-k     kill until the end of line\n\nC-a     go to start of line\nC-e     go to end of line\n\nC-f     move forward one character\nC-b     move backward one character\n\nM-f     move forward one word\nM-b     move backward one word\n\nC-d     delete forward one character\nC-h     delete backward one character\n\nM-d     delete forward one word\nM-Backspace delete backward one word\n\nC-p     previous command\nC-n     next command\n\nC-r     backward search\nC-s     forward search\n\n\nREPL modes\nThe Julia REPL is unique in that it has four distinct modes:\njulia&gt; ‚ÄÉ‚ÄÉ¬† The main mode in which you will be running your code.\nhelp?&gt; ‚ÄÉ‚ÄÉ¬† A mode to easily access documentation.\nshell&gt; ‚ÄÉ‚ÄÉ¬† A mode in which you can run bash commands from within Julia.\n(env) pkg&gt; ¬†¬†¬†¬†A mode to easily perform actions on packages with Julia package manager.\n\nenv is the name of your current project environment.\nProject environments are similar to Python‚Äôs virtual environments and allow you, for instance, to have different package versions for different projects. By default, it is the current Julia version. So what you will see is (@v1.12) pkg&gt;.\n\nEnter the various modes by typing ?, ;, and ]. Go back to the regular mode with the Backspace key.\n\n\n\n\n\n\nNoteShort video showing the REPL in action\n\n\n\n\n\n\n\n\n\n\n\n\nText editors\n\nVS Code\nJulia for Visual Studio Code has become the main Julia IDE.\n\n\nEmacs\nThere are various ways to use Julia in Emacs:\n\nvia the julia-emacs and julia-repl packages,\nvia the ESS package,\nvia the Emacs IPython Notebook package if you want to access Jupyter notebooks in Emacs.\n\n\n\nVim\nThanks to the julia-vim package.\n\n\n\nInteractive notebooks\n\nJupyter\nProject Jupyter allows to create interactive programming documents through its web-based JupyterLab environment and its Jupyter Notebook.\n\n\nPluto\nThe Julia package Juno is a reactive notebook for Julia.\n\n\n\nQuarto\nQuarto builds interactive documents with code and runs Julia through Jupyter.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Introduction to Julia"
    ]
  },
  {
    "objectID": "julia/intro_julia.html#startup-options",
    "href": "julia/intro_julia.html#startup-options",
    "title": "Introduction to Julia",
    "section": "Startup options",
    "text": "Startup options\nYou can configure Julia by creating the file ~/.julia/config/startup.jl.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Introduction to Julia"
    ]
  },
  {
    "objectID": "julia/intro_julia.html#help-and-documentation",
    "href": "julia/intro_julia.html#help-and-documentation",
    "title": "Introduction to Julia",
    "section": "Help and documentation",
    "text": "Help and documentation\nAs we already saw, you can type ? to enter the help mode:\n?sum\nsearch: sum sum! summary cumsum cumsum! isnumeric VersionNumber issubnormal \nget_zero_subnormals set_zero_subnormals\n\n  sum(f, itr; [init])\n\n  Sum the results of calling function f on each element of itr.\n\n  The return type is Int for signed integers of less than system word size, \n  and UInt for unsigned integers of less than system word size. For all other \n  arguments a common return type is found to which all arguments are promoted.\n\n  The value returned for empty itr can be specified by init. It must be the \n  additive identity (i.e. zero) as it is unspecified whether init is used for \n  non-empty collections.\n\nI truncated this output as the documentation also contains many examples.\n\nTo print the list of functions containing a certain word in their description, you can use apropos().\n\nExample:\n\n\napropos(\"truncate\")\n\nBase.div\nBase.IOContext\nBase.ctruncate\nCore.String\nBase.trunc\nBase.ltruncate\nBase.dump\nBase.rtruncate\nBase.open\nBase.open_flags\nBase.truncate\nBase.IOBuffer\nBase.Broadcast.newindex\nLinearAlgebra.eigen\nDates.format\nDates.Date\nBase.trunc\nNetworkOptions\nArgTools\nDownloads.Curl\nQuartoNotebookWorker.Packages.IOCapture.capture",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Introduction to Julia"
    ]
  },
  {
    "objectID": "julia/intro_julia.html#version-information",
    "href": "julia/intro_julia.html#version-information",
    "title": "Introduction to Julia",
    "section": "Version information",
    "text": "Version information\nJulia version only:\n\nversioninfo()\n\nJulia Version 1.12.0\nCommit b907bd0600f (2025-10-07 15:42 UTC)\nBuild Info:\n  Official https://julialang.org release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 16 √ó Intel(R) Core(TM) i7-10875H CPU @ 2.30GHz\n  WORD_SIZE: 64\n  LLVM: libLLVM-18.1.7 (ORCJIT, skylake)\n  GC: Built with stock GC\nThreads: 1 default, 1 interactive, 1 GC (on 16 virtual cores)\nEnvironment:\n  JULIA_PROJECT = @.\n  JULIA_LOAD_PATH = @:@stdlib\n\n\nMore information, including commit, OS, CPU, and compiler:\n\nVERSION\n\nv\"1.12.0\"",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Introduction to Julia"
    ]
  },
  {
    "objectID": "julia/intro_julia.html#lets-try-a-few-commands",
    "href": "julia/intro_julia.html#lets-try-a-few-commands",
    "title": "Introduction to Julia",
    "section": "Let‚Äôs try a few commands",
    "text": "Let‚Äôs try a few commands\nx = 10\nx\nx = 2;\nx\ny = x;\ny\nans\nans + 3\n\na, b, c = 1, 2, 3\nb\n\n3 + 2\n+(3, 2)\n\na = 3\n2a\na += 7\na\n\n2\\8\n\na = [1 2; 3 4]\nb = a\na[1, 1] = 0\nb\n\n[1, 2, 3, 4]\n[1 2; 3 4]\n[1 2 3 4]\n[1 2 3 4]'\ncollect(1:4)\ncollect(1:1:4)\n1:4\na = 1:4\ncollect(a)\n\n[1, 2, 3] .* [1, 2, 3]\n\n4//8\n8//1\n1//2 + 3//4\n\na = true\nb = false\na + b\n\n\nYour turn:\n\nWhat does ; at the end of a command do?\nWhat is surprising about 2a?\nWhat does += do?\nWhat does .*do?\n\na = [3, 1, 2]\n\nsort(a)\nprintln(a)\n\nsort!(a)\nprintln(a)\n\n\nYour turn:\n\nWhat does ! at the end of a function name do?",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Introduction to Julia"
    ]
  },
  {
    "objectID": "julia/intro_non_interactive.html",
    "href": "julia/intro_non_interactive.html",
    "title": "Non interactive execution",
    "section": "",
    "text": "Julia scripts have a .jl extension.\nThe include function sources a Julia script (in a REPL session or in another script):\ninclude(\"file.jl\")\nThe code contained in file.jl is thus run non interactively.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Non interactive execution"
    ]
  },
  {
    "objectID": "julia/intro_non_interactive.html#sourcing-a-file",
    "href": "julia/intro_non_interactive.html#sourcing-a-file",
    "title": "Non interactive execution",
    "section": "",
    "text": "Julia scripts have a .jl extension.\nThe include function sources a Julia script (in a REPL session or in another script):\ninclude(\"file.jl\")\nThe code contained in file.jl is thus run non interactively.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Non interactive execution"
    ]
  },
  {
    "objectID": "julia/intro_non_interactive.html#running-code-from-the-command-line",
    "href": "julia/intro_non_interactive.html#running-code-from-the-command-line",
    "title": "Non interactive execution",
    "section": "Running code from the command line",
    "text": "Running code from the command line\nYou can run scripts by passing them to the julia command on the command line:\n$ julia script.jl\n\nThis code is run in a terminal, not in Julia, as is indicated by the $ prompt.\n\nYou can also evaluate single expressions in Julia from the command line by using the flag -e:\n$ julia -e 'println(2 + 3)'\n5\n\nPassing arguments\n\nTo the julia command itself\nIf you want to pass arguments to the julia command itself, you need to add them before the script or the Julia expression.\n\nExample:\n\n$ julia -O script.jl\n\n\nTo the script/Julia expression\nTo pass arguments to the script (or Julia expression if you use -e), you add them after the script or expression:\n$ julia script.jl arg1 arg2 arg3\narg1, arg2, arg3 will be passed in the global constant ARGS and interpreted as arguments to the script.\n\nExample passing arguments to an expression:\n\n$ julia -e 'for x in ARGS; println(x); end' 2 3\n2\n3\n\n\nTo both\nTo pass arguments both to the julia command and to the script/expression, you need to add the -- delimiter before the script/expression:\n$ julia [switches] -- [programfile] [args...]\n\nExample:\n\n$ julia -O -- script.jl arg1 arg2",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Non interactive execution"
    ]
  },
  {
    "objectID": "julia/intro_plotting.html",
    "href": "julia/intro_plotting.html",
    "title": "Plotting",
    "section": "",
    "text": "It can be convenient to plot directly in the REPL (for instance when using SSH).\n\nusing UnicodePlots\nhistogram(randn(1000), nbins=40)\n\n\nPrecompiling UnicodePlots\n\n  ‚úì Crayons\n\n  ‚úì MarchingCubes\n\n  ‚úì UnicodePlots\n\n  3 dependencies successfully precompiled in 35 seconds. 41 already precompiled.\n\nPrecompiling IntervalSetsExt\n\n  ‚úì UnicodePlots ‚Üí IntervalSetsExt\n\n  1 dependency successfully precompiled in 1 seconds. 46 already precompiled.\n\nPrecompiling FreeTypeExt\n\n  ‚úì UnicodePlots ‚Üí FreeTypeExt\n\n  1 dependency successfully precompiled in 1 seconds. 53 already precompiled.\n\n\n\n\n\n                ‚îå                                        ‚îê \n   [-3.0, -2.8) ‚î§‚ñà‚ñä 4                                      \n   [-2.8, -2.6) ‚î§‚ñå 1                                       \n   [-2.6, -2.4) ‚î§‚ñå 1                                       \n   [-2.4, -2.2) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 11                                 \n   [-2.2, -2.0) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä 15                                \n   [-2.0, -1.8) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå 12                                 \n   [-1.8, -1.6) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 11                                 \n   [-1.6, -1.4) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå 23                            \n   [-1.4, -1.2) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä 37                      \n   [-1.2, -1.0) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ 57             \n   [-1.0, -0.8) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé 53              \n   [-0.8, -0.6) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå 47                 \n   [-0.6, -0.4) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç 73     \n   [-0.4, -0.2) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ 68        \n   [-0.2, -0.0) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä 72      \n   [-0.0,  0.2) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ 68        \n   [ 0.2,  0.4) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  79  \n   [ 0.4,  0.6) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä 72      \n   [ 0.6,  0.8) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç 62          \n   [ 0.8,  1.0) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç 49                \n   [ 1.0,  1.2) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã 41                    \n   [ 1.2,  1.4) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç 49                \n   [ 1.4,  1.6) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå 32                        \n   [ 1.6,  1.8) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå 21                             \n   [ 1.8,  2.0) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ 13                                 \n   [ 2.0,  2.2) ‚î§‚ñà‚ñà‚ñà‚ñà‚ñå 10                                  \n   [ 2.2,  2.4) ‚î§‚ñà‚ñà‚ñã 6                                     \n   [ 2.4,  2.6) ‚î§‚ñà‚ñç 3                                      \n   [ 2.6,  2.8) ‚î§‚ñà‚ñà‚ñã 6                                     \n   [ 2.8,  3.0) ‚î§‚ñà‚ñç 3                                      \n   [ 3.0,  3.2) ‚î§‚ñå 1                                       \n                ‚îî                                        ‚îò \n                                 Frequency                 \n\n\n\nMost of the time however, you will want to make nicer looking graphs. There are many options to plot in Julia.\nPlots is a convenient Julia package which allows to use the same code with several graphing backends such as the GR framework (great for speed), Plotly.js (allows interaction with your graphs in a browser), or PyPlot. The default backend is the GR framework.\nStatsPlots is an enhanced version with added stats functionality.\n\nExample:\n\n\n# First run takes time as the package needs to compile\nusing StatsPlots\nStatsPlots.histogram(randn(1000), bins=40)\n\n\nPrecompiling StatsPlots\n\n  ‚úì Arpack_jll\n\n  ‚úì Distances\n\n  ‚úì Widgets\n\n  ‚úì Arpack\n\n  ‚úì SentinelArrays\n\n  ‚úì Distances ‚Üí DistancesSparseArraysExt\n\n  ‚úì TableOperations\n\n  ‚úì Distances ‚Üí DistancesChainRulesCoreExt\n\n  ‚úì MultivariateStats\n\n  ‚úì NearestNeighbors\n\n  ‚úì Clustering\n\n  ‚úì StatsPlots\n\n  12 dependencies successfully precompiled in 8 seconds. 225 already precompiled.\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere, we need to explicitly run StatsPlots.histogram rather than histogram to prevent a conflict with the function of the same name from the package UnicodePlots.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Plotting"
    ]
  },
  {
    "objectID": "julia/intro_tabular.html",
    "href": "julia/intro_tabular.html",
    "title": "Working with tabular data:",
    "section": "",
    "text": "Requirements:\n1 - The current Julia stable release\nInstallation instructions can be found here.\n2 - The packages: CSV, DataFrames, TimeSeries, Plots\nPackages can be installed with ] add &lt;package&gt;.\n3 - Covid-19 data from the Johns Hopkins University CSSE repository\nClone (git clone &lt;repo url&gt;) or download and unzip the repository.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Working with tabular data"
    ]
  },
  {
    "objectID": "julia/intro_tabular.html#load-packages",
    "href": "julia/intro_tabular.html#load-packages",
    "title": "Working with tabular data:",
    "section": "Load packages",
    "text": "Load packages\nusing CSV\nusing DataFrames\nusing Dates          # From the standard Julia library\nusing TimeSeries\nusing NamedArrays\nusing Plots\n\nWe will use the GR framework as a backend for Plots.",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Working with tabular data"
    ]
  },
  {
    "objectID": "julia/intro_tabular.html#data-until-march-22-2020",
    "href": "julia/intro_tabular.html#data-until-march-22-2020",
    "title": "Working with tabular data:",
    "section": "Data until March 22, 2020",
    "text": "Data until March 22, 2020\n\n\n\nfrom xkcd.com\n\n\nThe files in the Johns Hopkins University CSSE repository have changed over time.\nIn this workshop, we will use 2 sets of files:\n\na first set from January 22, 2020 until March 22, 2020\na second set from January 22, 2020 to the present\n\nBoth sets contain data on confirmed and dead cases for world countries and in some cases their subregions (provinces, states, etc. which I will globally here call ‚Äúprovinces‚Äù).\nThe first set also contains numbers of recovered cases which allow to calculate numbers of currently ill persons (of course, keep in mind that all these data represent various degrees of underestimation and are flawed in many ways, amongst which are varying levels of testing efforts both geographically and over time, under-reporting, etc).\nThe second set does not contain recovered cases (many overwhelmed countries stopped monitoring this at some point).\nWe will play with the first set together and you will then try to play with the second set on your own.\n\nLoad the data\nIf you did not clone or download and unzip the Covid-19 data repository in your working directory, adapt the path consequently.\n#= create a variable with the path we are interested in;\nthis makes the code below a bit shorter =#\ndir = \"COVID-19/csse_covid_19_data/csse_covid_19_time_series\"\n\n# create a list of the full paths of all the files in dir\nlist = joinpath.(relpath(dir), readdir(dir))\n\n#= read in the 3 csv files with confirmed, dead, and recovered numbers\ncorresponding to the first set of data (until March 22, 2020) =#\ndat = DataFrame.(CSV.File.(list[collect(2:4)]))\nWe now have a one-dimensional array of 3 DataFrames called dat.\n\n\nTransform data into long format\n# rename some variables to easier names\nDataFrames.rename!.(dat, Dict.(1 =&gt; Symbol(\"province\"),\n                               2 =&gt; Symbol(\"country\")))\n\n# create a one-dimensional array of strings\nvar = [\"total\", \"dead\", \"recovered\"]\n\n#= transform the data into long format in a vectorized fashion\nusing both our one-dimensional arrays of 3 elements =#\ndatlong = map((x, y) -&gt; stack(x, Not(collect(1:4)),\n                              variable_name = Symbol(\"date\"),\n                              value_name = Symbol(\"$y\")),\n              dat, var)\nWe now have a one-dimensional array of 3 DataFrames in long format called datlong.\n# join all elements of this array into a single DataFrame\nall = join(datlong[1], datlong[2], datlong[3],\n           on = [:date, :country, :province, :Lat, :Long])\n\n# get rid of \"Lat\" and \"Long\" and re-order the columns\nselect!(all, [4, 3, 1, 2, 7, 8])\n\n#= turn the year from 2 digits to 4 digits using regular expression\n(in a vectorised fashion by braodcasting with the dot notation);\nthen turn these values into strings, and finally into dates =#\nall.date = Date.(replace.(string.(all[:, 3]),\n                          r\"(.*)(..)$\" =&gt; s\"\\g&lt;1&gt;20\\2\"), \"m/dd/yy\");\n\n#= replace the missing values by the string \"NA\"\n(these are not real missing values, but rather non applicable ones) =#\nreplace!(all.province, missing =&gt; \"NA\");\nWe now have a single DataFrame called all, in long format, with the variables confirmed, dead, recovered, and ill.\nCalculate the number of currently ill individuals (again, in a vectorized fashion, by broadcasting with the dot notation):\nall.current = all.total .- all.dead .- all.recovered;\n\n\nWorld summary\nTo make a single plot with world totals of confirmed, dead, recovered, and ill cases, we want the sums of these variables for each day. We do this by grouping the data by date:\nworld = by(all, :date,\n           total = :total =&gt; sum,\n           dead = :dead =&gt; sum,\n           recovered = :recovered =&gt; sum,\n           current = :current =&gt; sum)\nNow we can plot our new variable world.\nAs our data is a time series, we need to transform it to a TimeArray thanks to the TimeArray() function from the TimeSeries package.\nplot(TimeArray(world, timestamp = :date),\n     title = \"World\",\n     legend = :outertopright,\n     widen = :false)\n\n\n\nData until March 22, 2020\n\n\n\n\nCountries/provinces summaries\nNow, we want to group the data by country:\ncountries = groupby(all, :country)\nWe also need to know how the authors of the dataset decided to label the various countries and their subregions.\nFor example, if you want to see what the data looks like for France, Canada, and India, you can run:\ncountries[findall(x -&gt; \"France\" in x, keys(countries))]\ncountries[findall(x -&gt; \"Canada\" in x, keys(countries))]\ncountries[findall(x -&gt; \"India\" in x, keys(countries))]\nThen you need to subset the data for the countries or provinces you are interested in.\nHere are some examples:\n# countries for which there are data for several provinces\ncanada = all[all[:, :country] .== \"Canada\", :]\nus = all[all[:, :country] .== \"US\", :]\nchina = all[all[:, :country] .== \"China\", :]\n\n# countries with no province data\nskorea = all[all[:, :country] .== \"Korea, South\", :]\ntaiwan = all[all[:, :country] .== \"Taiwan*\", :]\nsingapore = all[all[:, :country] .== \"Singapore\", :]\nitaly = all[all[:, :country] .== \"Italy\", :]\nspain = all[all[:, :country] .== \"Spain\", :]\n\n#= countries wich have subregions spread widely in the world;\nhere, I took the arbitrary decision to only look at the main subregions =#\nfrance = all[all[:, :province] .== \"France\", :]\nuk = all[all[:, :province] .== \"United Kingdom\", :]\n\n# provinces\nbc = all[all[:, :province] .== \"British Columbia\", :]\nny = all[all[:, :province] .== \"New York\", :]\nCalculate the totals for Canada, US, and China which all have data for subregions:\ncanada, us, china = by.([canada, us, china], :date,\n                        total = :total =&gt; sum,\n                        dead = :dead =&gt; sum,\n                        recovered = :recovered =&gt; sum,\n                        current = :current =&gt; sum)\nloclist1 = [canada, us, china]\nloctitles1 = [\"Canada\", \"US\", \"China\"]\n\npcanada, pus, pchina =\n    map((x, y) -&gt; plot(TimeArray(x, timestamp = :date),\n                       title = \"$y\", legend = :outertopright,\n                       widen = :false, dpi = :300),\n        loclist1, loctitles1)\nloclist2 = [france, bc, ny, taiwan, skorea, singapore, spain, italy, uk]\nloctitles2 = [\"France\", \"BC\", \"NY\", \"Taiwan\", \"South Korea\",\n              \"Singapore\", \"Spain\", \"Italy\", \"UK\"]\n\npfrance, pbc, pny, ptaiwan, pskorea,\npsingapore, pspain, pitaly, puk =\n    map((x, y) -&gt; plot(TimeArray(select(x, Not([:country, :province])),\n                                 timestamp = :date),\n                       title = \"$y\", legend = :outertopright,\n                       widen = :false, dpi = :300),\n        loclist2, loctitles2)\nNow, let‚Äôs plot a few countries/provinces:\n\nNorth America\nplot(pcanada, pbc, pus, pny,\n     legend = false, titlefontsize = 7, tickfontsize = 6)\n\n\n\nData until March 22, 2020\n\n\n\n\nAsia\nplot(pchina, ptaiwan, pskorea, psingapore,\n     legend = false, titlefontsize = 7, tickfontsize = 6)\n\n\n\nData until March 22, 2020\n\n\n\n\nEurope\nplot(pfrance, pspain, pitaly, puk,\n     legend = false, titlefontsize = 7, tickfontsize = 6)\n\n\n\nData until March 22, 2020",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Working with tabular data"
    ]
  },
  {
    "objectID": "julia/intro_tabular.html#data-up-to-the-present",
    "href": "julia/intro_tabular.html#data-up-to-the-present",
    "title": "Working with tabular data:",
    "section": "Data up to the present",
    "text": "Data up to the present\n\nSummary graphs\n\n\nYour turn:\n\nWrite the code to create an up-to-date graph for the world using the files: time_series_covid19_confirmed_global.csv and time_series_covid19_deaths_global.csv.\n\nHere is the result:\n\n\n\nData until March 25, 2020\n\n\n\n\nYour turn:\n\nCreate up-to-date graphs for the countries and/or provinces of your choice.\n\nHere are a few possible results:\n\n\n\nData until March 25, 2020\n\n\n\n\nCountries comparison\nOur side by side graphs don‚Äôt make comparisons very easy since they vary greatly in their axes scales.\nOf course, we could constrain them to have the same axes, but then, why not plot multiple countries or provinces in the same graph?\ncanada[!, :loc] .= \"Canada\";\nchina[!, :loc] .= \"China\";\n\nall = join(all, canada, china, on = [:date, :total, :dead, :loc],\n           kind = :outer)\n\nconfirmed = unstack(all[:, collect(3:5)], :loc, :total)\n\nconf_sel = select(confirmed,\n                  [:date, :Italy, :Spain, :China, :Iran,\n                   :France, :US, Symbol(\"South Korea\"), :Canada])\n\nplot(TimeArray(conf_sel, timestamp = :date),\n     title = \"Confirmed across a few countries\",\n     legend = :outertopright, widen = :false)\n\n\n\nData until March 25, 2020\n\n\n\n\nYour turn:\n\nWrite the code to make a similar graph with the number of deaths in a few countries of your choice.\n\nHere is a possible result:\n\n\n\nData until March 25, 2020",
    "crumbs": [
      "Julia",
      "<b><em>Getting started</em></b>",
      "Working with tabular data"
    ]
  },
  {
    "objectID": "julia/top_wb.html",
    "href": "julia/top_wb.html",
    "title": "Julia webinars",
    "section": "",
    "text": "Visualization with \n\n\n\n\nFirst gentle dab at ¬†\n\n\n\n\nDeep learning with",
    "crumbs": [
      "Julia",
      "<b><em>Webinars</em></b>"
    ]
  },
  {
    "objectID": "julia/wb_flux.html",
    "href": "julia/wb_flux.html",
    "title": "Machine learning in Julia with Flux",
    "section": "",
    "text": "This webinar, aimed at users with no experience in machine learning, is an introduction to the basic concepts of neural networks, followed by a simple example‚Äîthe classic classification of the MNIST database of handwritten digits‚Äîusing the Julia package Flux.",
    "crumbs": [
      "Julia",
      "<b><em>Webinars</em></b>",
      "Deep learning with Flux"
    ]
  },
  {
    "objectID": "julia/wb_makie_content.html",
    "href": "julia/wb_makie_content.html",
    "title": "Makie",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "Julia",
      "<b><em>Webinars</em></b>",
      "Data visualization with Makie",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "julia/wb_makie_content.html#plotting-in-julia",
    "href": "julia/wb_makie_content.html#plotting-in-julia",
    "title": "Makie",
    "section": "Plotting in Julia",
    "text": "Plotting in Julia\nThere are many options to create plots in Julia. Some of the most popular ones are:\n\nPlots.jl: high-level API for working with different back-ends (GR, Pyplot, Plotly‚Ä¶),\nPyPlot.jl: Julia interface to Matplotlib‚Äôs matplotlib.pyplot,\nPlotlyJS.jl: Julia interface to plotly.js,\nPlotlyLight.jl: the fastest plotting option in Julia by far, but limited features,\nGadfly.jl: following the grammar of graphics popularized by Hadley Wickham in R,\nVegaLite.jl: grammar of interactive graphics,\nPGFPlotsX.jl: Julia interface to the PGFPlots LaTeX package,\nUnicodePlots.jl: plots in the terminal üôÇ,\nMakie.jl: powerful plotting ecosystem: animation, 3D, GPU optimization.\n\nThis webinar focuses on Makie.jl.",
    "crumbs": [
      "Julia",
      "<b><em>Webinars</em></b>",
      "Data visualization with Makie",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "julia/wb_makie_content.html#the-makie-ecosystem",
    "href": "julia/wb_makie_content.html#the-makie-ecosystem",
    "title": "Makie",
    "section": "The Makie ecosystem",
    "text": "The Makie ecosystem\nMakie consists of a core package (Makie), with the plots functionalities.\nIn addition to this, a backend is needed to render plots into images or vector graphics. Three backends are available:\n\nCairoMakie: vector graphics or high-quality 2D plots. Creates, but does not display plots (you need an IDE that does or you can use ElectronDisplay.jl),\nGLMakie: based on OpenGL; 3D rendering and interactivity in GLFW window (no vector graphics),\nWGLMakie: web version of GLMakie (plots rendered in a browser instead of a window).",
    "crumbs": [
      "Julia",
      "<b><em>Webinars</em></b>",
      "Data visualization with Makie",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "julia/wb_makie_content.html#resources",
    "href": "julia/wb_makie_content.html#resources",
    "title": "Makie",
    "section": "Resources",
    "text": "Resources\nHere are some links and resources useful to get started with the Makie ecosystem:\n\nthe official Makie documentation,\nJulia Data Science book, chapter 5,\nthe project Beautiful Makie contains many great plot examples,\ncheatsheets:\n\nfor 2D plotting:\n\n\n\nFrom: Storopoli, Huijzer and Alonso (2021). Julia Data Science. https://juliadatascience.io. ISBN: 97984898\n\n\nfor 3D plotting:\n\n\n\nFrom: Storopoli, Huijzer and Alonso (2021). Julia Data Science. https://juliadatascience.io. ISBN: 97984898",
    "crumbs": [
      "Julia",
      "<b><em>Webinars</em></b>",
      "Data visualization with Makie",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "julia/wb_makie_content.html#troubleshooting",
    "href": "julia/wb_makie_content.html#troubleshooting",
    "title": "Makie",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nCairoMakie and WGLMakie should install without issues. Installing GLMakie however can be challenging. This page may lead you towards a solution.",
    "crumbs": [
      "Julia",
      "<b><em>Webinars</em></b>",
      "Data visualization with Makie",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "julia/wb_makie_content.html#extensions",
    "href": "julia/wb_makie_content.html#extensions",
    "title": "Makie",
    "section": "Extensions",
    "text": "Extensions\nA number of extensions have been built on top of Makie:\n\nGeoMakie.jl add geographical plotting utilities to Makie,\nAlgebraOfGraphics.jl turns plotting into a simple algebra of building blocks,\nGraphMakie.jl to create network graphs.",
    "crumbs": [
      "Julia",
      "<b><em>Webinars</em></b>",
      "Data visualization with Makie",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "julia/wb_makie_content.html#fundamental-functioning",
    "href": "julia/wb_makie_content.html#fundamental-functioning",
    "title": "Makie",
    "section": "Fundamental functioning",
    "text": "Fundamental functioning\n\nFigure\nLoad the package (here, we are using CairoMakie):\n\nusing CairoMakie                        # no need to import Makie itself\n\nCreate a Figure (container object):\n\nfig = Figure()\n\n\n\n\n\ntypeof(fig)\n\nFigure\n\n\nYou can customize a Figure:\n\nfig2 = Figure(backgroundcolor=:grey22, size=(300, 300))\n\n\n\n\nMakie uses the Colors.jl package as a dependency. You can find a list of all named colours here.\nTo use CSS specification (e.g.¬†hex), you need to install Colors explicitly and use its color parsing capabilities:\n\nusing Colors\nfig3 = Figure(backgroundcolor=colorant\"#adc2eb\")\n\n\n\n\n\n\nAxis\nThen, you can create an Axis:\n\nax = Axis(Figure()[1, 1])\n\nAxis with 0 plots:\n\n\n\ntypeof(ax)\n\nAxis\n\n\n\nAxis(fig3[1, 1])  # fig3[1, 1] sets the subplot layout: fig[row, col]\nfig3\n\n\n\n\n\nAxis(fig[2, 3])  # This is what happens if we change the layout\nfig\n\n\n\n\n\nAxis(fig3[2, 3])  # We can add another axis on fig3\nfig3\n\n\n\n\nAxes are customizable:\n\nfig4 = Figure()\nAxis(fig4[1, 1],\n     xlabel=\"x label\",\n     ylabel=\"y label\",\n     title=\"Title of the plot\")\nfig4\n\n\n\n\n\n\nPlot\nFinally, you can add a plot:\n\nfig = Figure()\nax = Axis(fig[1, 1])\nx = LinRange(-10, 10, 20)\ny = x\nscatter!(ax, x, y)  # Functions with ! transform their arguments\nfig\n\n\n\n\nOf course, there are many plotting functions, e.g.¬†scatterlines!:\n\nfig = Figure()\nax = Axis(fig[1, 1])\nx = LinRange(-10, 10, 20)\ny = x\nscatterlines!(ax, x, y)  # Functions with ! transform their arguments\nfig\n\n\n\n\nWe can also use lines!:\n\nfig = Figure()\nax = Axis(fig[1, 1])\nx = LinRange(-10, 10, 20)\ny = sin.(x)  # The . means that the function is broadcast to each element of x\nlines!(ax, x, y)\nfig\n\n\n\n\nLet‚Äôs add points to get a smoother line:\n\nfig = Figure()\nax = Axis(fig[1, 1])\nx = LinRange(-10, 10, 1000)\ny = sin.(x)  # The . means that the function is broadcast to each element of x\nlines!(ax, x, y)\nfig\n\n\n\n\nNow, you don‚Äôt have to create the Figure, Axis, and plot one at a time. You can create them at the same time with, for instance lines:\n\nx = LinRange(-10, 10, 1000)\ny = sin.(x)\nlines(x, y)  # Note the use of lines instead of lines!\n\n\n\n\nOr even more simply:\n\nx = LinRange(-10, 10, 1000)\nlines(x, sin)\n\n\n\n\nThis is a lot simpler, but it is important to understand the concepts of the Figure and Axis objects as you will need it to customize them:\n\nx = LinRange(-10, 10, 1000)\ny = cos.(x)\nlines(x, y;\n      figure=(; backgroundcolor=:green),\n      axis=(; title=\"Cosinus function\", xlabel=\"x label\", ylabel=\"y label\"))\n\n\n\n\nWhen you create the Figure, Axis, and plot at the same time, you create a FigureAxisPlot object:\n\nx = LinRange(-10, 10, 1000)\ny = cos.(x)\nobj = lines(x, y;\n            figure=(; backgroundcolor=:green),\n            axis=(; title=\"Cosinus function\",\n                  xlabel=\"x label\",\n                  ylabel=\"y label\"));\ntypeof(obj)\n\nMakie.FigureAxisPlot\n\n\n\nNote the ; in the figure and axis value. This is because these are one-element NamedTuples.\n\nThe mutating functions (with !) can be used to add plots to an existing figure, but first, you need to decompose the FigureAxisPlot object:\n\nfig, ax, plot = lines(x, sin)\nlines!(ax, x, cos)  # Remember that we are transforming the Axis object\nfig                 # Now we can plot the transformed Figure\n\n\n\n\nOr we can add several plots on different Axis in the same Figure:\n\nfig, ax1, plot = lines(x, sin)\nax2 = Axis(fig[1, 2])\nlines!(ax2, x, cos)\nfig",
    "crumbs": [
      "Julia",
      "<b><em>Webinars</em></b>",
      "Data visualization with Makie",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "julia/wb_makie_content.html#examples",
    "href": "julia/wb_makie_content.html#examples",
    "title": "Makie",
    "section": "Examples",
    "text": "Examples\n\n2D\n\nusing CairoMakie\nusing StatsBase, LinearAlgebra\nusing Interpolations, OnlineStats\nusing Distributions\nCairoMakie.activate!(type = \"png\")\n\nfunction eq_hist(matrix; nbins = 256 * 256)\n    h_eq = fit(Histogram, vec(matrix), nbins = nbins)\n    h_eq = normalize(h_eq, mode = :density)\n    cdf = cumsum(h_eq.weights)\n    cdf = cdf / cdf[end]\n    edg = h_eq.edges[1]\n    interp_linear = LinearInterpolation(edg, [cdf..., cdf[end]])\n    out = reshape(interp_linear(vec(matrix)), size(matrix))\n    return out\nend\n\nfunction getcounts!(h, fn; n = 100)\n    for _ in 1:n\n        vals = eigvals(fn())\n        x0 = real.(vals)\n        y0 = imag.(vals)\n        fit!(h, zip(x0,y0))\n    end\nend\n\nm(;a=10rand()-5, b=10rand()-5) = [0 0 0 a; -1 -1 1 0; b 0 0 0; -1 -1 -1 -1]\n\nh = HeatMap(range(-3.5,3.5,length=1200), range(-3.5,3.5, length=1200))\ngetcounts!(h, m; n=2_000_000)\n\nwith_theme(theme_black()) do\n    fig = Figure(figure_padding=0,size=(600,600))\n    ax = Axis(fig[1,1]; aspect = DataAspect())\n    heatmap!(ax,-3.5..3.5, -3.5..3.5, eq_hist(h.counts); colormap = :bone_1)\n    hidedecorations!(ax)\n    hidespines!(ax)\n    fig\nend\n\n\n\n\n\n\n3D\nusing GLMakie, Random\nGLMakie.activate!()\n\nRandom.seed!(13)\nx = -6:0.5:6\ny = -6:0.5:6\nz = 6exp.( -(x.^2 .+ y' .^ 2)./4)\n\nbox = Rect3(Point3f(-0.5), Vec3f(1))\nn = 100\ng(x) = x^(1/10)\nalphas = [g(x) for x in range(0,1,length=n)]\ncmap_alpha = resample_cmap(:linear_worb_100_25_c53_n256, n, alpha = alphas)\n\nwith_theme(theme_dark()) do\n    fig, ax, = meshscatter(x, y, z;\n                           marker=box,\n                           markersize = 0.5,\n                           color = vec(z),\n                           colormap = cmap_alpha,\n                           colorrange = (0,6),\n                           axis = (;\n                                   type = Axis3,\n                                   aspect = :data,\n                                   azimuth = 7.3,\n                                   elevation = 0.189,\n                                   perspectiveness = 0.5),\n                           figure = (;\n                                     size=(1200,800)))\n    meshscatter!(ax, x .+ 7, y, z./2;\n                 markersize = 0.25,\n                 color = vec(z./2),\n                 colormap = cmap_alpha,\n                 colorrange = (0, 6),\n                 ambient = Vec3f(0.85, 0.85, 0.85),\n                 backlight = 1.5f0)\n    xlims!(-5.5,10)\n    ylims!(-5.5,5.5)\n    hidedecorations!(ax; grid = false)\n    hidespines!(ax)\n    fig\nend\n\n\nFor more examples, have a look at Beautiful Makie.",
    "crumbs": [
      "Julia",
      "<b><em>Webinars</em></b>",
      "Data visualization with Makie",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "julia/wb_makie_content.html#using-the-alliance-clusters",
    "href": "julia/wb_makie_content.html#using-the-alliance-clusters",
    "title": "Makie",
    "section": "Using the Alliance clusters",
    "text": "Using the Alliance clusters\n\nCairoMakie\nCairoMakie will run without problem on the Alliance clusters. It is not designed for interactivity, so saving to file is what makes the most sense.\n\nExample:\n\nsave(\"graph.png\", fig)\n\nRemember however that CairoMakie is 2D only (for now).\n\n\n\nGLMakie\nGLMakie relies on GLFW to create windows with OpenGL. GLFW doesn‚Äôt support creating contexts without an associated window. The dependency GLFW.jl will thus not install in the clusters‚Äîeven with X11 forwarding‚Äîunless you use VDI nodes, VNC, or Virtual GL.\n\n\nWGLMakie\nYou can setup a server with JSServe.jl as per the documentation. However, this method is intended for the creation of interactive widgets, e.g.¬†for a website. While this is really cool, it isn‚Äôt optimized for performance. There might also be a way to create an SSH tunnel to your local browser, although there is no documentation on this.\nThe best solution probably is to save your plot to a file.\n\nConclusion about the Makie ecosystem on production clusters:\n\n2D plots: use CairoMakie and save to file,\n3D plots: use WGLMakie and save to file.",
    "crumbs": [
      "Julia",
      "<b><em>Webinars</em></b>",
      "Data visualization with Makie",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "login.html",
    "href": "login.html",
    "title": "Logging in to our temporary training clusters",
    "section": "",
    "text": "To ensure that everybody uses the same environment, we often build temporary training clusters in which we pre-install the necessary packages for our courses and workshops. This eliminates endless trouble-shooting that inevitably happens when attendees install software and packages on their own machines, as well as the complications that arise when people use different software and package versions in different environments.\nThese virtual clusters mimic the Alliance production clusters, but they have limited resources and only run for the duration of the event.\nThis section provides instruction on how to log in to those clusters."
  },
  {
    "objectID": "login.html#step-1-get-the-info",
    "href": "login.html#step-1-get-the-info",
    "title": "Logging in to our temporary training clusters",
    "section": "Step 1: get the info",
    "text": "Step 1: get the info\nDuring the course or workshop, we will give you 3 pieces of information:\n\na link to a list of usernames,\nthe hostname for our temporary training cluster,\nthe password to access that cluster."
  },
  {
    "objectID": "login.html#step-2-claim-a-username",
    "href": "login.html#step-2-claim-a-username",
    "title": "Logging in to our temporary training clusters",
    "section": "Step 2: claim a username",
    "text": "Step 2: claim a username\nAdd your first name or a pseudo next to a free username on the list to claim it.\nYour username is the name that was already on the list, NOT what you wrote next to it (which doesn‚Äôt matter at all and only serves at signalling that this username is now taken).\nYour username will look like userxx‚Äîxx being 2 digits‚Äîwith no space and no capital letter."
  },
  {
    "objectID": "login.html#step-3-run-the-ssh-command",
    "href": "login.html#step-3-run-the-ssh-command",
    "title": "Logging in to our temporary training clusters",
    "section": "Step 3: run the ssh command",
    "text": "Step 3: run the ssh command\n\n¬†‚Ä¢¬† Linux and macOS users\nLinux users: ‚ÄÇ‚ÄÇopen the terminal emulator of your choice.\nmacOS users: ¬†¬†open ‚ÄúTerminal‚Äù.\nThen type:\nssh userxx@hostname\nand press Enter.\n\n\nReplace userxx by your username (e.g.¬†user09).\nReplace hostname by the hostname we will give you the day of the workshop.\n\n\nWhen asked:\n\nAre you sure you want to continue connecting (yes/no/[fingerprint])?\n\nAnswer: ‚Äúyes‚Äù.\n\n\n¬†‚Ä¢¬† Windows users\nWe suggest using the free version of MobaXterm, a software that comes with a terminal emulator and a GUI interface for SSH sessions.\nHere is how to install MobaXterm:\n\ndownload the ‚ÄúInstaller edition‚Äù to your computer (green button to the right),\nunzip the file,\ndouble-click on the .msi file to launch the installation.\n\nHere is how to log in with MobaXterm:\n\nopen MobaXterm,\nclick on Session (top left corner),\nclick on SSH (top left corner),\nfill in the Remote host * box with the cluster hostname we gave you,\ntick the box Specify username,\nfill in the box with the username you selected (e.g.¬†user09),\npress OK,\nwhen asked Are you sure you want to continue connecting (yes/no/[fingerprint])?, answer: ‚Äúyes‚Äù.\n\n\nHere is a live demo."
  },
  {
    "objectID": "login.html#step-4-enter-the-password",
    "href": "login.html#step-4-enter-the-password",
    "title": "Logging in to our temporary training clusters",
    "section": "Step 4: enter the password",
    "text": "Step 4: enter the password\nWhen prompted, enter the password we gave you.\nYou will not see anything happen as you type the password. This is normal and it is working, so keep on typing the password.\n\nThis is called blind typing and is a Linux safety feature. It can be unsettling at first not to get any feed-back while typing as it really looks like it is not working. Type slowly and make sure not to make typos.\n\nThen press Enter."
  },
  {
    "objectID": "login.html#am-i-logged-in",
    "href": "login.html#am-i-logged-in",
    "title": "Logging in to our temporary training clusters",
    "section": "Am I logged in?",
    "text": "Am I logged in?\nTo know whether or not you are logged in, look at your prompt: it should look like the following (with your actual username):\n[userxx@login1 ~]$"
  },
  {
    "objectID": "login.html#troubleshooting",
    "href": "login.html#troubleshooting",
    "title": "Logging in to our temporary training clusters",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nProblems logging in are almost always due to typos. If you cannot log in, retry slowly, entering your password carefully."
  },
  {
    "objectID": "login.html#how-do-i-log-out",
    "href": "login.html#how-do-i-log-out",
    "title": "Logging in to our temporary training clusters",
    "section": "How do I log out?",
    "text": "How do I log out?\nYou can log out by pressing Ctl+d."
  },
  {
    "objectID": "login.html#video",
    "href": "login.html#video",
    "title": "Logging in to our temporary training clusters",
    "section": "Video",
    "text": "Video\nHere is a video covering this material slowly:"
  },
  {
    "objectID": "python/hpc_gpu.html",
    "href": "python/hpc_gpu.html",
    "title": "GPU-accelerated Python",
    "section": "",
    "text": "Coming up in spring 2026.",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "GPU-accelerated Python"
    ]
  },
  {
    "objectID": "python/hpc_polars.html",
    "href": "python/hpc_polars.html",
    "title": "Polars data frames",
    "section": "",
    "text": "Polars is a modern open source and very fast data frame framework for Python, Rust, JS, R, and Ruby. In this course, we will cover Polars for Python.\nMulti-threaded queries, SIMD vectorization, automatic parallelization, columnar Apache Arrow memory format, and lazy evaluation make Polars much faster than pandas. Polars is superior to pandas in other ways as well such as proper support for missing data and an ability to work with more data than can fit in memory. The API is intuitive and Polars integrates well with other Python libraries from the scientific programming toolbox.\n\n Start course ‚û§",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames"
    ]
  },
  {
    "objectID": "python/intro_collections.html",
    "href": "python/intro_collections.html",
    "title": "Collections",
    "section": "",
    "text": "Values can be stored in collections. This section introduces tuples, dictionaries, sets, and arrays in Python.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Collections"
    ]
  },
  {
    "objectID": "python/intro_collections.html#lists",
    "href": "python/intro_collections.html#lists",
    "title": "Collections",
    "section": "Lists",
    "text": "Lists\nLists are declared in square brackets:\n\nl = [2, 1, 3]\n\n\ntype(l)\n\nlist\n\n\nThey are ordered:\n\n['b', 'a'] == ['a', 'b']\n\nFalse\n\n\nThey can have repeat values:\n\n['a', 'a', 'a', 't']\n\n['a', 'a', 'a', 't']\n\n\nThey can be homogeneous:\n\n['b', 'a', 'x', 'e']\n\n['b', 'a', 'x', 'e']\n\n\n\ntype('b') == type('a') == type('x') == type('e')\n\nTrue\n\n\nor heterogeneous:\n\n[3, 'some string', 2.9, 'z']\n\n[3, 'some string', 2.9, 'z']\n\n\n\ntype(3) == type('some string') == type(2.9) == type('z')\n\nFalse\n\n\nThey can even be nested:\n\n[3, ['b', 'e', 3.9, ['some string', 9.9]], 8]\n\n[3, ['b', 'e', 3.9, ['some string', 9.9]], 8]\n\n\nThe length of a list is the number of items it contains and can be obtained with the function len:\n\nlen([3, ['b', 'e', 3.9, ['some string', 9.9]], 8])\n\n3\n\n\n\n\nYour turn:\n\nWhat are the 3 elements of this list?\nWhat are their respective types?\n\nTo extract an item from a list, you index it:\n\n[3, ['b', 'e', 3.9, ['some string', 9.9]], 8][0]\n\n3\n\n\n\nPython starts indexing at 0, so what we tend to think of as the ‚Äúfirst‚Äù element of a list is for Python the ‚Äúzeroth‚Äù element.\n\n\n[3, ['b', 'e', 3.9, ['some string', 9.9]], 8][1]\n\n['b', 'e', 3.9, ['some string', 9.9]]\n\n\n\n[3, ['b', 'e', 3.9, ['some string', 9.9]], 8][2]\n\n8\n\n\nOf course you can‚Äôt extract items that don‚Äôt exist:\n\n[3, ['b', 'e', 3.9, ['some string', 9.9]], 8][3]\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[342], line 1\n----&gt; 1 [3, ['b', 'e', 3.9, ['some string', 9.9]], 8][3]\n\nIndexError: list index out of range\n\n\n\nYou can index from the end of the list with negative values (here you start at -1 for the last element):\n\n[3, ['b', 'e', 3.9, ['some string', 9.9]], 8][-1]\n\n8\n\n\n\n\nYour turn:\n\nHow could you extract the string 'some string' from the list:\n[3, ['b', 'e', 3.9, ['some string', 9.9]], 8]\n\nYou can also slice a list:\n\n[3, ['b', 'e', 3.9, ['some string', 9.9]], 8][0:1]\n\n[3]\n\n\n\nNotice how slicing returns a list.\nNotice also how the left index is included but the right index excluded.\n\nIf you omit the first index, the slice starts at the beginning of the list:\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9][:6]\n\n[1, 2, 3, 4, 5, 6]\n\n\nIf you omit the second index, the slice goes to the end of the list:\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9][6:]\n\n[7, 8, 9]\n\n\n\n\nYour turn:\n\nFrom the list:\nl = [1, 2, 3, 4, 5, 6, 7, 8, 9]\nExtract the list [4, 5, 6].\n\nWhen slicing, you can specify the stride (the step size):\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9][2:7:2]\n\n[3, 5, 7]\n\n\n\nThe default stride is 1:\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9][2:7] == [1, 2, 3, 4, 5, 6, 7, 8, 9][2:7:1]\n\nTrue\n\n\n\nYou can reverse the order of a list with a -1 stride applied on the whole list:\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9][::-1]\n\n[9, 8, 7, 6, 5, 4, 3, 2, 1]\n\n\nYou can test whether an item is in a list:\n\n3 in [3, ['b', 'e', 3.9, ['some string', 9.9]], 8]\n\nTrue\n\n\n\n9 in [3, ['b', 'e', 3.9, ['some string', 9.9]], 8]\n\nFalse\n\n\nor not in a list:\n\n3 not in [3, ['b', 'e', 3.9, ['some string', 9.9]], 8]\n\nFalse\n\n\nYou can get the index (position) of an item inside a list:\n\n[3, ['b', 'e', 3.9, ['some string', 9.9]], 8].index(3)\n\n0\n\n\n\nNote that this only returns the index of the first occurrence:\n\n[3, 3, ['b', 'e', 3.9, ['some string', 9.9]], 8].index(3)\n\n0\n\n\n\nLists are mutable (they can be modified), so you can replace items in a list by other items:\n\nL = [3, ['b', 'e', 3.9, ['some string', 9.9]], 8]\n\n\nL[1] = 2\nprint(L)\n\n[3, 2, 8]\n\n\nYou can delete items from a list using their indices with list.pop:\n\nL.pop(2)\nprint(L)\n\n[3, 2]\n\n\n\n\nYour turn:\n\nWhy is 2 still in the list after using L.pop(2)?\n\nor with del:\n\ndel L[0]\nprint(L)\n\n[2]\n\n\n\nNotice how a list can have a single item:\n\nlen(L)\n\n1\n\n\nIt is then called a ‚Äúsingleton list‚Äù.\n\nYou can also delete items from a list using their values with list.remove:\n\nL.remove(2)\nL\n\n[]\n\n\n\nHere, because we are using list.remove, 2 represents the value 2, not the index.\n\n\nNotice how a list can even be empty:\n\nlen(L)\n\n0\n\n\nYou can actually initialise empty lists:\n\nM = []\ntype(M)\n\nlist\n\n\n\nYou can add items to a list. One at a time as we saw at the top of this page:\n\nL.append(7)\nprint(L)\n\n[7]\n\n\nAnd if you want to add multiple items at once?\n\n# This doesn't work...\nL.append(3, 6, 9)\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[364], line 2\n      1 # This doesn't work...\n----&gt; 2 L.append(3, 6, 9)\n\nTypeError: list.append() takes exactly one argument (3 given)\n\n\n\n\n# This doesn't work either (that's not what we wanted)\nL.append([3, 6, 9])\nprint(L)\n\n[7, [3, 6, 9]]\n\n\n\n\nYour turn:\n\nFix this mistake we just made and delete the nested list [3, 6, 9].\n\nTo add multiple values to a list (and not a nested list), you need to use list.extend:\n\nL.extend([3, 6, 9])\nprint(L)\n\n[7, [3, 6, 9], 3, 6, 9]\n\n\nIf you don‚Äôt want to add an item at the end of a list, you can use list.insert(&lt;index&gt;, &lt;object&gt;).\n\n\nYour turn:\n\nBetween which elements will 'test' be inserted?\n\nYou can sort homogeneous lists:\n\nL = [3, 9, 10, 0]\nL.sort()\nprint(L)\n\n[0, 3, 9, 10]\n\n\n\nL = ['some string', 'b', 'a']\nL.sort()\nprint(L)\n\n['a', 'b', 'some string']\n\n\n\nHeterogeneous lists cannot be sorted:\n\nL = [3, ['b', 'e', 3.9, ['some string', 9.9]], 8]\nL.sort()\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[369], line 2\n      1 L = [3, ['b', 'e', 3.9, ['some string', 9.9]], 8]\n----&gt; 2 L.sort()\n\nTypeError: '&lt;' not supported between instances of 'list' and 'int'\n\n\n\n\nYou can also get the min and max value of homogeneous lists:\n\nmin([3, 9, 10, 0])\n\n0\n\n\n\nmax(['some string', 'b', 'a'])\n\n'some string'\n\n\n\nFor heterogeneous lists, this also doesn‚Äôt work:\n\nmin([3, ['b', 'e', 3.9, ['some string', 9.9]], 8])\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[372], line 1\n----&gt; 1 min([3, ['b', 'e', 3.9, ['some string', 9.9]], 8])\n\nTypeError: '&lt;' not supported between instances of 'list' and 'int'\n\n\n\n\nLists can be concatenated with +:\n\nL + [3, 6, 9]\n\n[3, ['b', 'e', 3.9, ['some string', 9.9]], 8, 3, 6, 9]\n\n\nor repeated with *:\n\nL * 3\n\n[3,\n ['b', 'e', 3.9, ['some string', 9.9]],\n 8,\n 3,\n ['b', 'e', 3.9, ['some string', 9.9]],\n 8,\n 3,\n ['b', 'e', 3.9, ['some string', 9.9]],\n 8]\n\n\n\n\nYour turn:\n\nDo you remember this exercise from an earlier section?\n\na = 1\nb = a\na = 2\nWhat do you think the value of b is now?\n\nHere is a new exercise for you:\na = [0, 1, 2]\nb = a\na.append(3)\nWhat do you think the value of b is now?\n\n\n\n\n\n\n\nNoteExplanation\n\n\n\n\n\nWait, what? üòµ\nThis is because, in Python, a scalar (an object with a single value) is immutable, meaning that you can‚Äôt change its value.\nSo in the first example, when we run a = 2, we are creating a new object (because the value of the initial object cannot be changed).\nLists however are mutable. So when we run a.append(3), we are not creating a new object. Instead we are modifying the existing object. Since both a and b point to that object, if the object changes, the value of both a and b changes.\nIn this case, if you want to create a copy, you have to use the copy function from the copy module (we will talk about modules later in the course):\n\nimport copy\n\na = [0, 1, 2]\nb = a.copy()\na.append(3)\n\nprint(b)\n\n[0, 1, 2]\n\n\n\n\n\n\nTo sum up, lists are declared in square brackets. They are mutable, ordered (thus indexable), and possibly heterogeneous collections of values.\n\n\nList comprehensions\nList comprehensions allow to create lists by applying a function to or testing a condition on each element of iterables.\n\nExamples:\n\nCreate a new list by applying a function to each element of a first list:\n\nl = [-3, 5, -2, 0, 9]\nl2 = [x**2 for x in l]\nprint(l2)\n\n[9, 25, 4, 0, 81]\n\n\nCreate a new list by testing a condition on each element of a first list:\n\nl3 = [x for x in l if x&lt;=0]\nprint(l3)\n\n[-3, -2, 0]\n\n\nCreate a new list by applying a function to each element of a first list matching a condition:\n\nl4 = [x**2 for x in l if x&lt;=0]\nprint(l4)\n\n[9, 4, 0]\n\n\nFlatten a list with two for statements:\n\nnested_l = [[1, 2], [3], [4, 5, 6]]\nflat_l = [x for y in nested_l for x in y]\nprint(flat_l)\n\n[1, 2, 3, 4, 5, 6]\n\n\nBy adding more for statements, you can flatten more deeply nested lists:\n\nl = [[[3, 4], [4]]]\n[x for y in l for z in y for x in z]\n\n[3, 4, 4]\n\n\n\n\nStrings\nStrings behave (a little) like lists of characters in that they have a length (the number of characters):\n\nS = 'This is a string.'\nlen(S)\n\n17\n\n\nThey have a min and a max:\n\nmin(S)\n\n' '\n\n\n\nmax(S)\n\n't'\n\n\nYou can index them:\n\nS[3]\n\n's'\n\n\nSlice them:\n\nS[10:16]\n\n'string'\n\n\n\n\nYour turn:\n\nReverse the order of the string S.\n\nThey can also be concatenated with +:\n\nT = 'This is another string.'\nprint(S + ' ' + T)\n\nThis is a string. This is another string.\n\n\nor repeated with *:\n\nprint(S * 3)\n\nThis is a string.This is a string.This is a string.\n\n\n\n\nYour turn:\n\nModify the last expression to have spaces after the periods.\n\nThis is where the similarities stop however: methods such as list.sort, list.append, etc. will not work on strings.\n\nS.append('This will fail.')\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[388], line 1\n----&gt; 1 S.append('This will fail.')\n\nAttributeError: 'str' object has no attribute 'append'",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Collections"
    ]
  },
  {
    "objectID": "python/intro_collections.html#arrays",
    "href": "python/intro_collections.html#arrays",
    "title": "Collections",
    "section": "Arrays",
    "text": "Arrays\nPython comes with a built-in array module. When you need arrays for storing and retrieving data, this module is perfectly suitable and extremely lightweight. This tutorial covers the syntax in detail.\nWhenever you plan on performing calculations on your data however (which is the vast majority of cases), you should instead use the NumPy package. We will talk about NumPy briefly in another section.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Collections"
    ]
  },
  {
    "objectID": "python/intro_collections.html#tuples",
    "href": "python/intro_collections.html#tuples",
    "title": "Collections",
    "section": "Tuples",
    "text": "Tuples\nTuples are defined with parentheses:\n\nt = (3, 1, 4, 2)\n\n\ntype(t)\n\ntuple\n\n\nThey are ordered:\n\n(2, 3) == (3, 2)\n\nFalse\n\n\nThis means that they are indexable and sliceable:\n\n(2, 4, 6)[2]\n\n6\n\n\n\n(2, 4, 6)[::-1]\n\n(6, 4, 2)\n\n\nThey can be nested:\n\ntype((3, 1, (0, 2)))\n\ntuple\n\n\n\nlen((3, 1, (0, 2)))\n\n3\n\n\n\nmax((3, 1, 2))\n\n3\n\n\nThey can be heterogeneous:\n\ntype(('string', 2, True))\n\ntuple\n\n\nYou can create empty tuples:\n\ntype(())\n\ntuple\n\n\nYou can also create singleton tuples, but the syntax is a bit odd:\n\n# This is not a tuple...\ntype((1))\n\nint\n\n\n\n# This is the weird way to define a singleton tuple\ntype((1,))\n\ntuple\n\n\nHowever, the big difference with lists is that tuples are immutable:\n\nT = (2, 5)\nT[0] = 8\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[401], line 2\n      1 T = (2, 5)\n----&gt; 2 T[0] = 8\n\nTypeError: 'tuple' object does not support item assignment\n\n\n\nTuples are quite fascinating:\n\na, b = 1, 2\nprint(a, b)\n\n1 2\n\n\n\na, b = b, a\nprint(a, b)\n\n2 1\n\n\n\nTuples are declared in parentheses. They are immutable, ordered (thus indexable), and possibly heterogeneous collections of values.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Collections"
    ]
  },
  {
    "objectID": "python/intro_collections.html#sets",
    "href": "python/intro_collections.html#sets",
    "title": "Collections",
    "section": "Sets",
    "text": "Sets\nSets are declared in curly braces:\n\ns = {3, 2, 5}\n\n\ntype(s)\n\nset\n\n\nThey are unordered:\n\n{2, 4, 1} == {4, 2, 1}\n\nTrue\n\n\nConsequently, it makes no sense to index a set:\n\ns[0]\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[407], line 1\n----&gt; 1 s[0]\n\nTypeError: 'set' object is not subscriptable\n\n\n\nSets can be heterogeneous:\n\nS = {2, 'a', 'string'}\nisinstance(S, set)\n\nTrue\n\n\n\ntype(2) == type('a') == type('string')\n\nFalse\n\n\nThere are no duplicates in a set:\n\n{2, 2, 'a', 2, 'string', 'a'}\n\n{2, 'a', 'string'}\n\n\nYou can define an empty set, but only with the set function (because empty curly braces define a dictionary as we will see below):\n\nt = set()\n\n\nlen(t)\n\n0\n\n\n\ntype(t)\n\nset\n\n\nSince strings an iterables, you can use set to get a set of the unique characters:\n\nset('abba')\n\n{'a', 'b'}\n\n\n\n\nYour turn:\n\nHow could you create a set with the single element 'abba' in it?\n\n\nSets are declared in curly brackets. They are mutable, unordered (thus non indexable), possibly heterogeneous collections of unique values.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Collections"
    ]
  },
  {
    "objectID": "python/intro_collections.html#dictionaries",
    "href": "python/intro_collections.html#dictionaries",
    "title": "Collections",
    "section": "Dictionaries",
    "text": "Dictionaries\nDictionaries are also declared in curly braces. They associate values to keys:\n\nd = {'key1': 'value1', 'key2': 'value2'}\n\n\ntype(d)\n\ndict\n\n\nThe key/value pairs are unique:\n\n{'key1': 'value1', 'key2': 'value2', 'key1': 'value1'}\n\n{'key1': 'value1', 'key2': 'value2'}\n\n\nThey are unordered:\n\n{'a': 1, 'b': 2} == {'b': 2, 'a': 1}\n\nTrue\n\n\nConsequently, the pairs themselves cannot be indexed:\n\nd[0]\n\n\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nCell In[419], line 1\n----&gt; 1 d[0]\n\nKeyError: 0\n\n\n\nHowever, you can access values from their keys:\n\nD = {'c': 1, 'a': 3, 'b': 2}\nD['b']\n\n2\n\n\nor:\n\nD.get('b')\n\n2\n\n\nThere are methods to get the items (the pairs), the values, or the keys:\n\nD.items()\n\ndict_items([('c', 1), ('a', 3), ('b', 2)])\n\n\n\nD.values()\n\ndict_values([1, 3, 2])\n\n\n\nD.keys()\n\ndict_keys(['c', 'a', 'b'])\n\n\nTo return a sorted list of keys:\n\nsorted(D)\n\n['a', 'b', 'c']\n\n\nYou can create empty dictionaries:\n\nE = {}\ntype(E)\n\ndict\n\n\nDictionaries are mutable, so you can add, remove, or replace items.\nLet‚Äôs add an item to our empty dictionary E:\n\nE['author'] = 'Proust'\nprint(E)\n\n{'author': 'Proust'}\n\n\nWe can add another one:\n\nE['title'] = 'In search of lost time'\nprint(E)\n\n{'author': 'Proust', 'title': 'In search of lost time'}\n\n\nWe can modify one:\n\nE['author'] = 'Marcel Proust'\nE\n\n{'author': 'Marcel Proust', 'title': 'In search of lost time'}\n\n\n\n\nYour turn:\n\nAdd a third item to E with the number of volumes.\n\nWe can also remove items:\n\nE.pop('author')\nprint(E)\n\n{'title': 'In search of lost time'}\n\n\nor:\n\ndel E['title']\nprint(E)\n\n{}\n\n\n\nDictionaries are declared in curly braces. They are mutable and unordered collections of unique key/value pairs. They play the role of an associative array.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Collections"
    ]
  },
  {
    "objectID": "python/intro_collections.html#conversion-between-collections",
    "href": "python/intro_collections.html#conversion-between-collections",
    "title": "Collections",
    "section": "Conversion between collections",
    "text": "Conversion between collections\nFrom tuple to list:\n\nlist((3, 8, 1))\n\n[3, 8, 1]\n\n\nFrom tuple to set:\n\nset((3, 2, 3, 3))\n\n{2, 3}\n\n\nFrom list to tuple:\n\ntuple([3, 1, 4])\n\n(3, 1, 4)\n\n\nFrom list to set:\n\nset(['a', 2, 4])\n\n{2, 4, 'a'}\n\n\nFrom set to tuple:\n\ntuple({2, 3})\n\n(2, 3)\n\n\nFrom set to list:\n\nlist({2, 3})\n\n[2, 3]",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Collections"
    ]
  },
  {
    "objectID": "python/intro_collections.html#collections-module",
    "href": "python/intro_collections.html#collections-module",
    "title": "Collections",
    "section": "Collections module",
    "text": "Collections module\nPython has a built-in collections module providing the additional much more niche data structures: deque, defaultdict, namedtuple, OrderedDict, Counter, ChainMap, UserDict, UserList, and UserList.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Collections"
    ]
  },
  {
    "objectID": "python/intro_doc.html",
    "href": "python/intro_doc.html",
    "title": "Help and documentation",
    "section": "",
    "text": "This section shows you how to access help and documentation from within Python.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Help and documentation"
    ]
  },
  {
    "objectID": "python/intro_doc.html#module",
    "href": "python/intro_doc.html#module",
    "title": "Help and documentation",
    "section": "Module",
    "text": "Module\nYou can get help on a module (we will discuss modules later in the course) thanks to the help function, but only after you have loaded that module into your session:\nimport os\nhelp(os)\nHelp on module os:\n\nNAME\n    os - OS routines for NT or Posix depending on what system we're on.\n\nMODULE REFERENCE\n    https://docs.python.org/3.13/library/os.html\n\n    The following documentation is automatically generated from the Python\n    source files.  It may be incomplete, incorrect or include features that\n    are considered implementation detail and may vary between Python\n    implementations.  When in doubt, consult the module reference at the\n    location listed above.\n\n...",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Help and documentation"
    ]
  },
  {
    "objectID": "python/intro_doc.html#functions",
    "href": "python/intro_doc.html#functions",
    "title": "Help and documentation",
    "section": "Functions",
    "text": "Functions\nYou can also access the internal Python documentation on a function with help:\n\nhelp(max)\n\nHelp on built-in function max in module builtins:\n\nmax(...)\n    max(iterable, *[, default=obj, key=func]) -&gt; value\n    max(arg1, arg2, *args, *[, key=func]) -&gt; value\n\n    With a single iterable argument, return its biggest item. The\n    default keyword-only argument specifies an object to return if\n    the provided iterable is empty.\n    With two or more positional arguments, return the largest argument.\n\n\n\nAlternatively, you can print the __doc__ method of the function:\n\nprint(max.__doc__)\n\nmax(iterable, *[, default=obj, key=func]) -&gt; value\nmax(arg1, arg2, *args, *[, key=func]) -&gt; value\n\nWith a single iterable argument, return its biggest item. The\ndefault keyword-only argument specifies an object to return if\nthe provided iterable is empty.\nWith two or more positional arguments, return the largest argument.\n\n\n\n\nYour turn:\n\nTell me what the function str does?",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Help and documentation"
    ]
  },
  {
    "objectID": "python/intro_doc.html#methods-of-object-types",
    "href": "python/intro_doc.html#methods-of-object-types",
    "title": "Help and documentation",
    "section": "Methods of object types",
    "text": "Methods of object types\nSome methods belong to specific objects types (e.g.¬†lists have a method called append).\nIn those cases, help(&lt;method&gt;) won‚Äôt work.\n\nExample:\n\n\nhelp(append)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 help(append)\n\nNameError: name 'append' is not defined\n\n\n\nWhat you need to run instead is help(&lt;object&gt;.&lt;method&gt;).\n\nExample:\n\n\nhelp(list.append)\n\nHelp on method_descriptor:\n\nappend(self, object, /) unbound builtins.list method\n    Append object to the end of the list.\n\n\n\n\n\nYour turn:\n\nWhat does the popitem method of dictionaries (dict) does?",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Help and documentation"
    ]
  },
  {
    "objectID": "python/intro_doc.html#help-while-using-ipython-or-jupyter",
    "href": "python/intro_doc.html#help-while-using-ipython-or-jupyter",
    "title": "Help and documentation",
    "section": "Help while using IPython or Jupyter",
    "text": "Help while using IPython or Jupyter\nWhen using IPython (which means also when using Jupyter Lab or Jupyter notebooks since they run IPython), you can access help by using ?.\n\nExample:\n\n?sum\n# sum? also works\nSignature: sum(iterable, /, start=0)\nDocstring:\nReturn the sum of a 'start' value (default: 0) plus an iterable of numbers\n\nWhen the iterable is empty, return the start value.\nThis function is intended specifically for use with numeric values and may\nreject non-numeric types.\nType:      builtin_function_or_method\n\nNote that, for modules, the help you get this way only contains the description. If you want to get the full documentation (including classes, functions, and data), you need to use the help function instead.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Help and documentation"
    ]
  },
  {
    "objectID": "python/intro_hpc.html",
    "href": "python/intro_hpc.html",
    "title": "Python at scale",
    "section": "",
    "text": "This section gives a brief introduction on how to use Python efficiently at scale on the Digital Research Alliance of Canada supercomputers.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Python at scale"
    ]
  },
  {
    "objectID": "python/intro_hpc.html#the-problem-with-jupyter",
    "href": "python/intro_hpc.html#the-problem-with-jupyter",
    "title": "Python at scale",
    "section": "The problem with Jupyter",
    "text": "The problem with Jupyter\nWhen you launch a Jupyter session from a JupyterHub, you are running a Slurm job on compute nodes. If you want to play for 8 hours in Jupyter, you are requesting an 8 hour job. Now, most of the time you spend on Jupyter is spent typing, thinking, running bits and pieces of code, or doing nothing at all. If you ask for GPUs, many CPUs, and lots of RAM, all of it will remain idle most of the time. This is a suboptimal use of resources.\nIn addition, if you ask for lots of resources for a long time, you will have to wait for a while before they get allocated to you.\nLastly, you will go through your allocations quickly.\nAll of this applies equally for interactive sessions launched from an SSH session with salloc.\nIdeally, you want to ensure that heavy duty resources that you request are actually put to use to run your heavy calculations and do not seat idle.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Python at scale"
    ]
  },
  {
    "objectID": "python/intro_hpc.html#a-better-approach",
    "href": "python/intro_hpc.html#a-better-approach",
    "title": "Python at scale",
    "section": "A better approach",
    "text": "A better approach\nBelow is what the workflow looks like.\n\nPrototype your code\nDevelop and test your Python code interactively to take advantage of the fact that Python is an interpreted language. Do this with little data, few samples, few iterations, and any other method you can use to make the code run faster. Use your own machine, a small interactive job in the cluster with salloc using IPython, or a small JupyterHub session.\nOnce you are confident that your code works, move on to the next steps.\n\n\nSSH connection to a cluster\nYou will need the username and password that you already used to access JupyterHub. In addition, you will now need a hostname that we will give you.\n\nRun the ssh command\n\n¬†‚Ä¢¬† Linux and macOS users\nLinux users: ‚ÄÇ‚ÄÇopen the terminal emulator of your choice.\nmacOS users: ¬†¬†open ‚ÄúTerminal‚Äù.\nThen type:\nssh userxx@hostname\nand press Enter.\n\n\nReplace userxx by your username (e.g.¬†user09).\nReplace hostname by the hostname we will give you the day of the workshop.\n\n\nWhen asked:\n\nAre you sure you want to continue connecting (yes/no/[fingerprint])?\n\nAnswer: ‚Äúyes‚Äù.\n\n\n¬†‚Ä¢¬† Windows users\nWe suggest using the free version of MobaXterm, a software that comes with a terminal emulator and a GUI interface for SSH sessions.\nHere is how to install MobaXterm:\n\ndownload the ‚ÄúInstaller edition‚Äù to your computer (green button to the right),\nunzip the file,\ndouble-click on the .msi file to launch the installation.\n\nHere is how to log in with MobaXterm:\n\nopen MobaXterm,\nclick on Session (top left corner),\nclick on SSH (top left corner),\nfill in the Remote host * box with the cluster hostname we gave you,\ntick the box Specify username,\nfill in the box with the username you selected (e.g.¬†user09),\npress OK,\nwhen asked Are you sure you want to continue connecting (yes/no/[fingerprint])?, answer: ‚Äúyes‚Äù.\n\n\nHere is a live demo.\n\n\n\n\nEnter the password\nWhen prompted, enter the password we gave you.\nYou will not see anything happen as you type the password. This is normal and it is working, so keep on typing the password.\n\nThis is called blind typing and is a Linux safety feature. It can be unsettling at first not to get any feed-back while typing as it really looks like it is not working. Type slowly and make sure not to make typos.\n\nThen press Enter.\nYou are now logged in and your prompt should look like the following (with your actual username):\n[userxx@login1 ~]$\n\n\nTroubleshooting\nProblems logging in are almost always due to typos. If you cannot log in, retry slowly, entering your password carefully.\n\n\n\nLoad a Python module\nThis is done with the Lmod tool through the module command. You can find the full documentation here and below are the commands you will need:\nGet help on the module command:\nmodule -h\n\nmodule help and module --help are synonyms.\n\nList modules that are already loaded:\nmodule list\nSee which modules are available for Python:\nmodule spider python\n\nAs you can see, there are many versions available.\n\nSee how to load Python 3.13.2:\nmodule spider python/3.13.2\nTo load python/3.13.2, you need StdEnv/2023, but it is already loaded by default (you can verify this with module list), so we can load our Python module directly:\nmodule load python/3.13.2\nYou can see that we now have Python 3.13.2 loaded:\nmodule list\nVerify the Python version:\npython --version\n\n\nCopy files to the cluster\nIf you need to copy files to the cluster, open a new terminal window on your machine and from your local terminal (make sure that you are not on the remote terminal by looking at the bash prompt) run:\nscp /local/path/to/file &lt;username&gt;@&lt;hostname&gt;:path/in/cluster\n\n# enter password\nFor those using MobaXTerm, you can also drag and drop files in the GUI.\n\n\nVirtual environment\nCreate and activate a virtual environment for the job:\npython -m venv ~/env\nsource ~/env/bin/activate\npython -m pip install --upgrade --no-index pip\npython -m pip install --no-index &lt;package&gt;\n\n\nLaunch a job\nNow you need to write a job script for the Slurm scheduler. This is a text file with a .sh extension which contains all the sbatch options and the actions of the job.\nThe Alliance wiki is a great source of information on how to get started. The section on running jobs in particular should be very useful.\n\nHere is an example of Slurm script:\n\n#!/bin/bash\n#SBATCH --job-name=python_run1      # job name\n#SBATCH --time=05:00:00             # max walltime 5 h\n#SBATCH --cpus-per-task=8           # number of cores\n#SBATCH --mem=9000                  # max memory (default unit is megabytes)\n#SBATCH --output=python_run1%j.out  # file name for the output\n#SBATCH --error=python_run1%j.err   # file name for errors\n\n# run your Python script \npython &lt;your-script-name&gt;.py\n\n%j gets replaced with the job number which is automatically generated by Slurm.\n\nThen, you can submit your job to the cluster:\nsbatch &lt;your-slurm-script-name&gt;.sh\nAnd you can check its status with:\nsq    # This is an Alliance alias for `squeue -u $USER $@`\n\nPD stands for pending\nR stands for running\n\nIf you don‚Äôt get any output when you run sq, it means that the job has finished running.\n\nLet‚Äôs try it\n\nMake sure that you have loaded the Python module before launching your job:\nmodule load python/3.13.2\nIf your script uses packages, make sure that you have also activated the virtual environment which contains the packages.\n\nCreate a dummy Python script called script.py by opening it in nano or your preferred text:\nnano script.py\nAdd in it:\n\n\nscript.py\n\ndef super_function(a, b):\n    return a + b\n\na = 3\nb = 10\n\nresult = super_function(a, b)\nprint(result)\n\nNow, create a script for Slurm in the same fashion (let‚Äôs call it script.sh):\nnano script.sh\nWith the content:\n\n\nscript.sh\n\n#!/bin/bash\n#SBATCH --job-name=our_script\n#SBATCH --time=00:00:20\n#SBATCH --output=script%j.out\n#SBATCH --error=script%j.err\n\npython script.py\n\n\nWe aren‚Äôt mentioning any number of CPUs so Slurm will default to one CPU. We also aren‚Äôt mentioning any memory, so Slurm will default to 256 MB per CPU.\n\n\n\nYour turn:\n\n\nHow do you launch this job?\nHow do you know that it is done?\nHow do you check the result?",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Python at scale"
    ]
  },
  {
    "objectID": "python/intro_objects.html",
    "href": "python/intro_objects.html",
    "title": "Python objects",
    "section": "",
    "text": "In Python, everything is an object. So let‚Äôs talk about Python objects.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Python objects"
    ]
  },
  {
    "objectID": "python/intro_objects.html#fundamental-definitions",
    "href": "python/intro_objects.html#fundamental-definitions",
    "title": "Python objects",
    "section": "Fundamental definitions",
    "text": "Fundamental definitions\n\nObject\nEvery piece of data in Python, whether it‚Äôs a number, a string, a list, or a class instance is an object. Objects reside in memory and have a unique identity (address in memory), which can be checked using the id function. Objects have a type (e.g., int, str, list) which determines their behaviour and the operations that can be performed on them. Objects are the actual ‚Äúthings‚Äù that your program manipulates.\n\n\nValue\nA value is what an object stores. For example, an integer object might have the value 42, or a string object might have the value \"hello\". Two different objects can have the same value (e.g.¬†two distinct integer objects both storing 5). The concept of ‚Äúvalue‚Äù is often used when discussing the data itself, independent of its specific memory location or object identity.\n\n\nVariable\nIn Python, a variable is a name that refers to an object. It acts as a label or reference to the specific memory location where an object is stored. When you assign a value to a variable, you are making that variable (name) point to an object holding that particular value.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Python objects"
    ]
  },
  {
    "objectID": "python/intro_objects.html#creating-and-deleting-objects",
    "href": "python/intro_objects.html#creating-and-deleting-objects",
    "title": "Python objects",
    "section": "Creating and deleting objects",
    "text": "Creating and deleting objects\n\nAssignment\nThe assignment statement (=) assigns a variable (or name, or label, or reference) to an object in memory. This object holds a value.\n\nFor instance, we can assign the variable a to some object in memory that holds the value 1:\n\n\na = 1\n\nYou can define multiple variables at once, assigning them the same object:\n\na = b = 10\nprint(a, b)\n\n10 10\n\n\n‚Ä¶ or different objects:\n\na, b = 1, 2\nprint(a, b)\n\n1 2\n\n\n\n\nYour turn:\n\na = 1\nb = a\na = 2\nWhat do you think the value of b is now?\n\n\n\n\n\n\n\nNoteExplanation\n\n\n\n\n\nThe variable a gets assigned to an object holding the value 1. Then the variable b gets assigned to that same object in memory (you can double-check this with id(a) == id(b)). Finally, we reassign the variable a to a new object in memory holding the value 2. Meanwhile, the variable b still points to the first object with a value of 1 (so now id(a) == id(b) is not true anymore).\n\n\n\n\n\nChoosing variables\nWhile I am using a and b a lot in this workshop (since the code has no other purpose than to demo the language itself), in your scripts you should use meaningful names (e.g.¬†survival, age, year, species, temperature). It will make reading the code this much easier.\nMake sure not to use the names of built-in functions or built-in constants.\n\n\nDeleting objects\nYou can delete variables with the del statement:\n\na = 3\nprint(a)\n\n3\n\n\n\ndel a\nprint(a)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[5], line 2\n      1 del a\n----&gt; 2 print(a)\n\nNameError: name 'a' is not defined\n\n\n\nThen the garbage collector automatically deletes from memory objects with no variables assigned to them.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Python objects"
    ]
  },
  {
    "objectID": "python/intro_objects.html#types",
    "href": "python/intro_objects.html#types",
    "title": "Python objects",
    "section": "Types",
    "text": "Types\nPython comes with multiple built-in types.\n\nExamples (non exhaustive):\n\n\ntype(1), type(1.0), type('1'), type(3+2j), type(True), type(sum)\n\n(int, float, str, complex, bool, builtin_function_or_method)\n\n\n\nint = integer\nfloat = floating point number\ncomplex = complex number\nstr = string\nbool = Boolean\n\nPython is dynamically-typed, meaning you do not need to explicitly declare the type of a variable. It is inferred at runtime based on the value of the object the variable is assigned to.\nVariables can be reassigned to objects holding different data types:\n\na = 2.3\ntype(a)\n\nfloat\n\n\n\na = \"A string.\"\ntype(a)\n\nstr\n\n\n\nType conversion\nYou can convert the type of some values. Here are some examples:\n\ntype('4'), type(int('4'))\n\n(str, int)\n\n\n\ntype(3), type(str(3))\n\n(int, str)\n\n\n\ntype(3), type(float(3))\n\n(int, float)\n\n\n\ntype(3.4), type(str(3.4))\n\n(float, str)\n\n\n\ntype(0), type(bool(0))\n\n(int, bool)\n\n\n\ntype(True), type(int(True))\n\n(bool, int)\n\n\nOf course, not all conversions are possible:\n\nint('red')\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[15], line 1\n----&gt; 1 int('red')\n\nValueError: invalid literal for int() with base 10: 'red'\n\n\n\nYou might be surprised by some of the conversions:\n\nint(3.9)\n\n3\n\n\n\nbool(3.4)\n\nTrue\n\n\n\nThat‚Äôs because the Boolean of zero is False and the Boolean of any non-zero number is True.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Python objects"
    ]
  },
  {
    "objectID": "python/intro_plot.html",
    "href": "python/intro_plot.html",
    "title": "Plotting in Python",
    "section": "",
    "text": "There are many packages that provide plotting in Python. Here is an overview of the most popular ones.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Plotting in Python"
    ]
  },
  {
    "objectID": "python/intro_plot.html#matplotlib",
    "href": "python/intro_plot.html#matplotlib",
    "title": "Plotting in Python",
    "section": "matplotlib",
    "text": "matplotlib\nmatplotlib is a very popular Python plotting library because it provides full control over the plots and produces graphs well-suited for publications. Many plot types can be created.\nThe downside of having full control is that it has a verbose imperative syntax. It also produces non-interactive plots.\n\nExample\nHere is one of the matplotlib website examples to give you an idea of the syntax:\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# make data:\nnp.random.seed(1)\nx = np.random.uniform(-3, 3, 256)\ny = np.random.uniform(-3, 3, 256)\nz = (1 - x/2 + x**5 + y**3) * np.exp(-x**2 - y**2)\nlevels = np.linspace(z.min(), z.max(), 7)\n\n# plot:\nfig, ax = plt.subplots()\n\nax.plot(x, y, 'o', markersize=2, color='grey')\nax.tricontourf(x, y, z, levels=levels)\n\nax.set(xlim=(-3, 3), ylim=(-3, 3))\n\nplt.show()",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Plotting in Python"
    ]
  },
  {
    "objectID": "python/intro_plot.html#seaborn",
    "href": "python/intro_plot.html#seaborn",
    "title": "Plotting in Python",
    "section": "seaborn",
    "text": "seaborn\nSeaborn is a higher level library built on top of matplotlib. This means that the plots are also non-interactive and that the options are more limited. On the plus side, the declarative syntax is very easy, making it a nice library for exploratory data analysis (EDA).\n\nExample\nHere is one example from the seaborn gallery:\n\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_theme(style=\"dark\")\n\n# Simulate data from a bivariate Gaussian\nn = 10000\nmean = [0, 0]\ncov = [(2, .4), (.4, .2)]\nrng = np.random.RandomState(0)\nx, y = rng.multivariate_normal(mean, cov, n).T\n\n# Draw a combo histogram and scatterplot with density contours\nf, ax = plt.subplots(figsize=(6, 6))\nsns.scatterplot(x=x, y=y, s=5, color=\".15\")\nsns.histplot(x=x, y=y, bins=50, pthresh=.1, cmap=\"mako\")\nsns.kdeplot(x=x, y=y, levels=5, color=\"w\", linewidths=1)\n\n\n\n\n\n\n\n\n\n\nWebsite",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Plotting in Python"
    ]
  },
  {
    "objectID": "python/intro_plot.html#bokeh",
    "href": "python/intro_plot.html#bokeh",
    "title": "Plotting in Python",
    "section": "bokeh",
    "text": "bokeh\nBokeh creates interactive plots great for dashboards and web apps. It is more efficient than other libraries for streaming or interactions with large datasets. It does have a fairly steep learning curve.\n\nWebsite",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Plotting in Python"
    ]
  },
  {
    "objectID": "python/intro_plot.html#plotly",
    "href": "python/intro_plot.html#plotly",
    "title": "Plotting in Python",
    "section": "plotly",
    "text": "plotly\nPlotly also creates interactive plots and its declarative option with the Plotly Express framework makes it very easy to use (the imperative approach is also possible). Static plots however are less sophisticated than with matplotlib and it is not as good as Bokeh for dashboard interactions.\n\nExample\n\nimport plotly.express as px\ndf = px.data.tips()\n\nfig = px.density_contour(df, x=\"total_bill\", y=\"tip\")\nfig.update_traces(contours_coloring=\"fill\", contours_showlabels = True)\nfig.show()\n\n                            \n                                            \n\n\n\n\nWebsite",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Plotting in Python"
    ]
  },
  {
    "objectID": "python/intro_plot.html#vega-altair",
    "href": "python/intro_plot.html#vega-altair",
    "title": "Plotting in Python",
    "section": "Vega-Altair",
    "text": "Vega-Altair\nVega-Altair is a declarative library with an easy syntax and interactive plots options, ideal for EDA.\n\nExample\nimport altair as alt\nfrom vega_datasets import data\n\nsource = data.us_employment()\n\npredicate = alt.datum.nonfarm_change &gt; 0\ncolor = alt.when(predicate).then(alt.value(\"steelblue\")).otherwise(alt.value(\"orange\"))\n\nalt.Chart(source).mark_bar().encode(\n    x=\"month:T\",\n    y=\"nonfarm_change:Q\",\n    color=color\n).properties(width=600)\n\n\n\nWebsite",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Plotting in Python"
    ]
  },
  {
    "objectID": "python/intro_plot.html#plotnine",
    "href": "python/intro_plot.html#plotnine",
    "title": "Plotting in Python",
    "section": "plotnine",
    "text": "plotnine\nPlotnine is an adaptation to Python of the popular R library ggplot2 based on the grammar of graphics concept.\n\nExample\nfrom plotnine import (\n    ggplot,\n    aes,\n    theme_matplotlib,\n    theme_set,\n    geom_tile,\n    scale_fill_continuous,\n    coord_cartesian\n)\n\nfrom plotnine.data import faithfuld\n\n# Set default theme for all the plots\ntheme_set(theme_matplotlib())\n\n(\n    ggplot(faithfuld, aes(\"waiting\", \"eruptions\", fill=\"density\")) \n    + geom_tile()\n)\n\n\n\nWebsite",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Plotting in Python"
    ]
  },
  {
    "objectID": "python/intro_plot.html#summary",
    "href": "python/intro_plot.html#summary",
    "title": "Plotting in Python",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\n\n\n\nLibrary\nSyntax\nInteractivity\nIdeal for\nWeaknesses\n\n\n\n\nMatplotlib\nImperative\nNo\nPublications\nVerbose, non-interactive\n\n\nSeaborn\nDeclarative\nNo\nStatistical EDA\nLimited for rare plot types\n\n\nBokeh\nImperative\nYes\nLive web apps\nStyling is less intuitive\n\n\nPlotly\nBoth\nYes\nDashboards\nStatic output less flexible\n\n\nAltair\nDeclarative\nYes\nFast EDA, web\nFewer custom options\n\n\nPlotnine\nDeclarative\nNo\nR users\nSomewhat niche",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Plotting in Python"
    ]
  },
  {
    "objectID": "python/intro_resources.html",
    "href": "python/intro_resources.html",
    "title": "Resources",
    "section": "",
    "text": "This section contains a list of useful Python resources.\n\n\nPython website\nOfficial documentation\nBeginners‚Äô guide\nOfficial Python tutorial\n\n\nAlliance wiki\nAlliance wiki Python page\n\n\nBooks\nTutorial for non-programmers\nAutomate the boring stuff with Python\n\n\nWorkshops\nSoftware Carpentry Python workshop\nData Carpentry Python workshop\n\n\nIDEs\nProject Jupyter\nList of IDEs with description\nComparison of IDEs\nEmacs Python IDE\n\n\nShells\nIPython\nptpython\nbpython\nXonsh\n\n\nGetting help\nStack Overflow [python] tag\n\n\nPackages\nPython package index (PyPI)\nBest tool for pkgs, projects, and versions management: uv",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Resources"
    ]
  },
  {
    "objectID": "python/intro_syntax.html",
    "href": "python/intro_syntax.html",
    "title": "Syntax",
    "section": "",
    "text": "First, let‚Äôs cover some basics of the Python syntax.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Syntax"
    ]
  },
  {
    "objectID": "python/intro_syntax.html#commands",
    "href": "python/intro_syntax.html#commands",
    "title": "Syntax",
    "section": "Commands",
    "text": "Commands\nShort commands are usually written one per line:\n\na = 2.0\nprint(a)\n\n2.0\n\n\nbut you can write multiple commands on the same line with the semi-colon separator:\n\na = 2.0; print(a)\n\n2.0\n\n\n\nIn a Python shell or when using Jupyter, you can omit the print function if you want to return a result directly (this is not true in functions definitions).\nSo the above could be run as:\n\na = 2.0\na\n\n2.0\n\n\nand\n\na = 2.0; a\n\n2.0\n\n\nBe careful though that if you are running a script (i.e.¬†you write this code in a text file with a .py extension and execute it by running python &lt;your-script&gt;.py in the command line), nothing will get printed with this method and you have to explicitly use the print function.\n\nSome commands (e.g.¬†function definitions, for loops, if else statements) span over multiple lines. The first line starts normally, but subsequent lines are indented to mark that they are part of the same command.\nThis indentation‚Äîone tab or a series of spaces (often 4 spaces, but the number can be customized in many IDEs)‚Äîhas a syntactic meaning in Python and is not just for human readability:\n\n# Incorrect code\nfor i in [1, 2]:\nprint(i)\n\n\n  Cell In[5], line 3\n    print(i)\n    ^\nIndentationError: expected an indented block after 'for' statement on line 2\n\n\n\n\n\n# Correct code\nfor i in [1, 2]:\n    print(i)\n\n1\n2\n\n\n\nIDEs and good text editors indent code automatically.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Syntax"
    ]
  },
  {
    "objectID": "python/intro_syntax.html#comments",
    "href": "python/intro_syntax.html#comments",
    "title": "Syntax",
    "section": "Comments",
    "text": "Comments\nComments (snippets of text for human consumption and ignored by the Python interpreter) are marked by the hashtag:\n\n# This is a full-line comment\n\nprint(a)         # This is an inline comment\n\n2.0\n\n\n\nPEP 8‚Äîthe style guide for Python code‚Äîsuggests a maximum of 72 characters per line for comments. Try to keep comments to the point and spread them over multiple lines if they are too long.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Syntax"
    ]
  },
  {
    "objectID": "python/intro_syntax.html#basic-operations",
    "href": "python/intro_syntax.html#basic-operations",
    "title": "Syntax",
    "section": "Basic operations",
    "text": "Basic operations\n\nprint(3 + 2)\n\n5\n\n\n\nprint(3.0 - 2.0)\n\n1.0\n\n\n\nprint(10 / 2)\n\n5.0\n\n\n\nNotice how the result can be of a different type.\n\nVariables can be used in operations:\n\na = 3\nprint(a + 2)\n\n5\n\n\na = a + 10 can be replaced by the more elegant:\n\na += 10\nprint(a)\n\n13\n\n\n\n\nYour turn:\n\nTransform the following code:\na = a * 2\nprint(a)\nby following these rules:\n\nturn the code as a one-liner,\nadd a comment to it,\nreplace the operation with a more elegant form.",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Syntax"
    ]
  },
  {
    "objectID": "python/intro_syntax.html#quotes",
    "href": "python/intro_syntax.html#quotes",
    "title": "Syntax",
    "section": "Quotes",
    "text": "Quotes\nPairs of single and double quotes are used to create strings.\n\nPEP 8 does not recommend one style over the other. It does suggest however that once you have chosen a style, you stick to it to make scripts consistent.\n\n\n\"This is a string.\"\n\n'This is a string.'\n\n\n\ntype(\"This is a string.\")\n\nstr\n\n\n\n'This is also a string.'\n\n'This is also a string.'\n\n\n\ntype('This is also a string.')\n\nstr\n\n\nApostrophes and textual quotes interfere with Python quotes. In these cases, use the opposite style to avoid any problem:\n\n# This doesn't work\n'This string isn't easy'\n\n\n  Cell In[17], line 2\n    'This string isn't easy'\n                           ^\nSyntaxError: unterminated string literal (detected at line 2)\n\n\n\n\n\n# This is good\n\"This string isn't easy\"\n\n\"This string isn't easy\"\n\n\n\n# This doesn't work\n\"He said: \"this is a problem.\"\"\n\n\n  Cell In[19], line 2\n    \"He said: \"this is a problem.\"\"\n               ^\nSyntaxError: invalid syntax\n\n\n\n\n\n# This is good\n'He said: \"this is a problem.\"'\n\n'He said: \"this is a problem.\"'\n\n\nSometimes, neither option works and you have to escape some of the quotes with \\:\n\n# This doesn't work\n\"He said: \"this string isn't easy\"\"\n\n\n  Cell In[21], line 2\n    \"He said: \"this string isn't easy\"\"\n                              ^\nSyntaxError: unterminated string literal (detected at line 2)\n\n\n\n\n\n# This doesn't work either\n'He said: \"this string isn't easy\"'\n\n\n  Cell In[22], line 2\n    'He said: \"this string isn't easy\"'\n                                     ^\nSyntaxError: unterminated string literal (detected at line 2)\n\n\n\n\n\n# You can use double quotes and escape double quotes in the string\n\"He said: \\\"this string isn't easy\\\"\"\n\n'He said: \"this string isn\\'t easy\"'\n\n\n\n# Or you can use single quotes and escape single quotes in the string\n'He said: \"this string isn\\'t easy\"'\n\n'He said: \"this string isn\\'t easy\"'",
    "crumbs": [
      "Python",
      "<b><em>Getting started</em></b>",
      "Syntax"
    ]
  },
  {
    "objectID": "python/llm_takeaways.html",
    "href": "python/llm_takeaways.html",
    "title": "Takeaways on coding with LLMs",
    "section": "",
    "text": "This section offers a few takeaways on coding with LLMs. Models are evolving so fast that these are likely to be wrong within years, months, or maybe even weeks, so take them for what they are!",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "Takeaways on coding with LLMs"
    ]
  },
  {
    "objectID": "python/llm_takeaways.html#education-and-exposure",
    "href": "python/llm_takeaways.html#education-and-exposure",
    "title": "Takeaways on coding with LLMs",
    "section": "Education and exposure",
    "text": "Education and exposure\nHowever one might feel about AI and its ethical implications (and there are many!), it is important, as citizens and researchers, to be educated on the topic. Education involves learning about the technology, its advantages, benefits, risks, and problems, but also having personal experience with AI tools.\nCriticism of these tools is absolutely valid if it comes from an educated and informed place, not when it comes from uninformed prejudices. As these tools evolve (and they are evolving very fast), it is important to remain up to date in our knowledge and understanding.\nFor non-specialists, the deep learning literature and programming forums might not be the best ways to keep up to date with the evolution of these tools. What has worked best for me is to follow a number of podcasts. In particular, I like Hard Fork from the New Yor Times‚Äîa fun and approachable, but well-researched podcast on technology which often deals with AI, as well as podcast episodes from Lawfare dealing with AI for questions related to law and geopolitics. There are many other podcasts on AI but they tend to target a technical audience.",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "Takeaways on coding with LLMs"
    ]
  },
  {
    "objectID": "python/llm_takeaways.html#critical-thinking",
    "href": "python/llm_takeaways.html#critical-thinking",
    "title": "Takeaways on coding with LLMs",
    "section": "Critical thinking",
    "text": "Critical thinking\nBe critical and don‚Äôt blindly trust answers from LLMs: they will ‚Äúhappily‚Äù tell you that the code is doing something while it is not (in the same way that they can give wrong answers to any question). It is crucial to double-check the code.\nBe mindful that code can be wrong in ways that are obvious and easy to spot or in ways that are much less obvious. It can even be harmful.\nThe more Python you know, the easier it will get to be critical of the code. Until you have enough knowledge to be able to understand and assess the code by yourself, don‚Äôt hesitate to use LLMs to explain the code to you. While they might not always write the right code to answer particular problems, they are usually excellent at explaining what snippets of code do and how they work.",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "Takeaways on coding with LLMs"
    ]
  },
  {
    "objectID": "python/llm_takeaways.html#constructive-usage",
    "href": "python/llm_takeaways.html#constructive-usage",
    "title": "Takeaways on coding with LLMs",
    "section": "Constructive usage",
    "text": "Constructive usage\nUse LLMs as assistants and instructors to brainstorm with and learn from, not as a magic boxes that will do everything for you. They do make coding a lot easier, they are tremendously useful, and they will make you able to write useful Python code a lot sooner, but you still have to think and learn.",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "Takeaways on coding with LLMs"
    ]
  },
  {
    "objectID": "python/llm_takeaways.html#inescapable",
    "href": "python/llm_takeaways.html#inescapable",
    "title": "Takeaways on coding with LLMs",
    "section": "Inescapable?",
    "text": "Inescapable?\nIt seems plausible that, as these tools become increasingly helpful and widely adopted, those who refuse to use them will find themselves at a growing disadvantage. In a sense, as with most transformative technologies, we might not really have a choice. For those struggling with the many ethical concerns, it might be more realistic to try to get good regulations and a more equitable system than to reject the technology altogether.",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>",
      "Takeaways on coding with LLMs"
    ]
  },
  {
    "objectID": "python/llm_webscraping_all_pages.html",
    "href": "python/llm_webscraping_all_pages.html",
    "title": "Getting the full data",
    "section": "",
    "text": "def get_dissertation_data(BASE_URL):\n    # Get main page and extract dissertation URLs\n    main_page = requests.get(BASE_URL)\n    soup = BeautifulSoup(main_page.content, \"html.parser\")\n\n    # Extract individual dissertation links\n    links = [urljoin(BASE_URL, a[\"href\"])\n             for a in soup.select(\".article-listing a\")]\n\n    data = []\n\n    for link in links[:10]:  # Reduced to 10 for testing; remove slice for full 100\n        try:\n            # Get individual dissertation page\n            page = requests.get(link)\n            page_soup = BeautifulSoup(page.content, \"html.parser\")\n\n            # Extract required fields\n            date = page_soup.select_one(\"#publication_date p\").text.strip()\n            major = page_soup.select_one(\"#department p\").text.strip()\n            advisor = page_soup.select_one(\"#advisor1 p\").text.strip()\n\n            data.append({\n                \"Date\": date,\n                \"Major\": major,\n                \"Advisor\": advisor\n            })\n\n        except Exception as e:\n            print(f\"Error processing {link}: {str(e)}\")\n\n    return pl.DataFrame(data)\n\nWe can verify that it still works:\n\ndf = get_dissertation_data(BASE_URL)\nprint(df)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[2], line 1\n----&gt; 1 df = get_dissertation_data(BASE_URL)\n      2 print(df)\n\nNameError: name 'BASE_URL' is not defined\n\n\n\n\nNote that we now have to pass the argument BASE_URL to the function.\n\nLet‚Äôs look at the range function to understand how it works:\n\nfor i in range(5):\n    print(i)\n\n0\n1\n2\n3\n4\n\n\nrange(5) is the same as range(0, 5). It goes from 0‚Äîsince Python starts indexing at 0‚Äîand that left boundary is included to 4 because the right boundary (5 here) is excluded.\nSo range(116) would go from 0 to 115. You could verify it with:\nfor i in range(116):\n    print(i)\n\n\nYour turn:\n\n\nWe want numbers from 2 to 117, so what arguments do we need to pass to the range function?\n\nHow can you test it?\n\n\nApplied to the series of webpages, that would be:\nfor i in range(2, 118):\n    print(f\"https://trace.tennessee.edu/utk_graddiss/index.{i}.html\")\nThis is good, so let‚Äôs create a list with those webpages.\nFirst, we initialize an empty list of the proper length (this makes the code much more efficient than forcing Python to perform dynamic memory allocation at each iteration of the loop):\n\nurl_list = [None] * 116\n\nNow we can fill in the list with the URLs with a loop:\n\nfor i in range(2, 118):\n    url_list[i] = f\"https://trace.tennessee.edu/utk_graddiss/index.{i}.html\"\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[5], line 2\n      1 for i in range(2, 118):\n----&gt; 2     url_list[i] = f\"https://trace.tennessee.edu/utk_graddiss/index.{i}.html\"\n\nIndexError: list assignment index out of range\n\n\n\nLet‚Äôs print our list to make sure that all is good:\n\nprint(url_list)\n\n[None, None, 'https://trace.tennessee.edu/utk_graddiss/index.2.html', 'https://trace.tennessee.edu/utk_graddiss/index.3.html', 'https://trace.tennessee.edu/utk_graddiss/index.4.html', 'https://trace.tennessee.edu/utk_graddiss/index.5.html', 'https://trace.tennessee.edu/utk_graddiss/index.6.html', 'https://trace.tennessee.edu/utk_graddiss/index.7.html', 'https://trace.tennessee.edu/utk_graddiss/index.8.html', 'https://trace.tennessee.edu/utk_graddiss/index.9.html', 'https://trace.tennessee.edu/utk_graddiss/index.10.html', 'https://trace.tennessee.edu/utk_graddiss/index.11.html', 'https://trace.tennessee.edu/utk_graddiss/index.12.html', 'https://trace.tennessee.edu/utk_graddiss/index.13.html', 'https://trace.tennessee.edu/utk_graddiss/index.14.html', 'https://trace.tennessee.edu/utk_graddiss/index.15.html', 'https://trace.tennessee.edu/utk_graddiss/index.16.html', 'https://trace.tennessee.edu/utk_graddiss/index.17.html', 'https://trace.tennessee.edu/utk_graddiss/index.18.html', 'https://trace.tennessee.edu/utk_graddiss/index.19.html', 'https://trace.tennessee.edu/utk_graddiss/index.20.html', 'https://trace.tennessee.edu/utk_graddiss/index.21.html', 'https://trace.tennessee.edu/utk_graddiss/index.22.html', 'https://trace.tennessee.edu/utk_graddiss/index.23.html', 'https://trace.tennessee.edu/utk_graddiss/index.24.html', 'https://trace.tennessee.edu/utk_graddiss/index.25.html', 'https://trace.tennessee.edu/utk_graddiss/index.26.html', 'https://trace.tennessee.edu/utk_graddiss/index.27.html', 'https://trace.tennessee.edu/utk_graddiss/index.28.html', 'https://trace.tennessee.edu/utk_graddiss/index.29.html', 'https://trace.tennessee.edu/utk_graddiss/index.30.html', 'https://trace.tennessee.edu/utk_graddiss/index.31.html', 'https://trace.tennessee.edu/utk_graddiss/index.32.html', 'https://trace.tennessee.edu/utk_graddiss/index.33.html', 'https://trace.tennessee.edu/utk_graddiss/index.34.html', 'https://trace.tennessee.edu/utk_graddiss/index.35.html', 'https://trace.tennessee.edu/utk_graddiss/index.36.html', 'https://trace.tennessee.edu/utk_graddiss/index.37.html', 'https://trace.tennessee.edu/utk_graddiss/index.38.html', 'https://trace.tennessee.edu/utk_graddiss/index.39.html', 'https://trace.tennessee.edu/utk_graddiss/index.40.html', 'https://trace.tennessee.edu/utk_graddiss/index.41.html', 'https://trace.tennessee.edu/utk_graddiss/index.42.html', 'https://trace.tennessee.edu/utk_graddiss/index.43.html', 'https://trace.tennessee.edu/utk_graddiss/index.44.html', 'https://trace.tennessee.edu/utk_graddiss/index.45.html', 'https://trace.tennessee.edu/utk_graddiss/index.46.html', 'https://trace.tennessee.edu/utk_graddiss/index.47.html', 'https://trace.tennessee.edu/utk_graddiss/index.48.html', 'https://trace.tennessee.edu/utk_graddiss/index.49.html', 'https://trace.tennessee.edu/utk_graddiss/index.50.html', 'https://trace.tennessee.edu/utk_graddiss/index.51.html', 'https://trace.tennessee.edu/utk_graddiss/index.52.html', 'https://trace.tennessee.edu/utk_graddiss/index.53.html', 'https://trace.tennessee.edu/utk_graddiss/index.54.html', 'https://trace.tennessee.edu/utk_graddiss/index.55.html', 'https://trace.tennessee.edu/utk_graddiss/index.56.html', 'https://trace.tennessee.edu/utk_graddiss/index.57.html', 'https://trace.tennessee.edu/utk_graddiss/index.58.html', 'https://trace.tennessee.edu/utk_graddiss/index.59.html', 'https://trace.tennessee.edu/utk_graddiss/index.60.html', 'https://trace.tennessee.edu/utk_graddiss/index.61.html', 'https://trace.tennessee.edu/utk_graddiss/index.62.html', 'https://trace.tennessee.edu/utk_graddiss/index.63.html', 'https://trace.tennessee.edu/utk_graddiss/index.64.html', 'https://trace.tennessee.edu/utk_graddiss/index.65.html', 'https://trace.tennessee.edu/utk_graddiss/index.66.html', 'https://trace.tennessee.edu/utk_graddiss/index.67.html', 'https://trace.tennessee.edu/utk_graddiss/index.68.html', 'https://trace.tennessee.edu/utk_graddiss/index.69.html', 'https://trace.tennessee.edu/utk_graddiss/index.70.html', 'https://trace.tennessee.edu/utk_graddiss/index.71.html', 'https://trace.tennessee.edu/utk_graddiss/index.72.html', 'https://trace.tennessee.edu/utk_graddiss/index.73.html', 'https://trace.tennessee.edu/utk_graddiss/index.74.html', 'https://trace.tennessee.edu/utk_graddiss/index.75.html', 'https://trace.tennessee.edu/utk_graddiss/index.76.html', 'https://trace.tennessee.edu/utk_graddiss/index.77.html', 'https://trace.tennessee.edu/utk_graddiss/index.78.html', 'https://trace.tennessee.edu/utk_graddiss/index.79.html', 'https://trace.tennessee.edu/utk_graddiss/index.80.html', 'https://trace.tennessee.edu/utk_graddiss/index.81.html', 'https://trace.tennessee.edu/utk_graddiss/index.82.html', 'https://trace.tennessee.edu/utk_graddiss/index.83.html', 'https://trace.tennessee.edu/utk_graddiss/index.84.html', 'https://trace.tennessee.edu/utk_graddiss/index.85.html', 'https://trace.tennessee.edu/utk_graddiss/index.86.html', 'https://trace.tennessee.edu/utk_graddiss/index.87.html', 'https://trace.tennessee.edu/utk_graddiss/index.88.html', 'https://trace.tennessee.edu/utk_graddiss/index.89.html', 'https://trace.tennessee.edu/utk_graddiss/index.90.html', 'https://trace.tennessee.edu/utk_graddiss/index.91.html', 'https://trace.tennessee.edu/utk_graddiss/index.92.html', 'https://trace.tennessee.edu/utk_graddiss/index.93.html', 'https://trace.tennessee.edu/utk_graddiss/index.94.html', 'https://trace.tennessee.edu/utk_graddiss/index.95.html', 'https://trace.tennessee.edu/utk_graddiss/index.96.html', 'https://trace.tennessee.edu/utk_graddiss/index.97.html', 'https://trace.tennessee.edu/utk_graddiss/index.98.html', 'https://trace.tennessee.edu/utk_graddiss/index.99.html', 'https://trace.tennessee.edu/utk_graddiss/index.100.html', 'https://trace.tennessee.edu/utk_graddiss/index.101.html', 'https://trace.tennessee.edu/utk_graddiss/index.102.html', 'https://trace.tennessee.edu/utk_graddiss/index.103.html', 'https://trace.tennessee.edu/utk_graddiss/index.104.html', 'https://trace.tennessee.edu/utk_graddiss/index.105.html', 'https://trace.tennessee.edu/utk_graddiss/index.106.html', 'https://trace.tennessee.edu/utk_graddiss/index.107.html', 'https://trace.tennessee.edu/utk_graddiss/index.108.html', 'https://trace.tennessee.edu/utk_graddiss/index.109.html', 'https://trace.tennessee.edu/utk_graddiss/index.110.html', 'https://trace.tennessee.edu/utk_graddiss/index.111.html', 'https://trace.tennessee.edu/utk_graddiss/index.112.html', 'https://trace.tennessee.edu/utk_graddiss/index.113.html', 'https://trace.tennessee.edu/utk_graddiss/index.114.html', 'https://trace.tennessee.edu/utk_graddiss/index.115.html']"
  },
  {
    "objectID": "python/llm_webscraping_all_pages.html#getting-the-full-data",
    "href": "python/llm_webscraping_all_pages.html#getting-the-full-data",
    "title": "Getting the full data",
    "section": "",
    "text": "def get_dissertation_data(BASE_URL):\n    # Get main page and extract dissertation URLs\n    main_page = requests.get(BASE_URL)\n    soup = BeautifulSoup(main_page.content, \"html.parser\")\n\n    # Extract individual dissertation links\n    links = [urljoin(BASE_URL, a[\"href\"])\n             for a in soup.select(\".article-listing a\")]\n\n    data = []\n\n    for link in links[:10]:  # Reduced to 10 for testing; remove slice for full 100\n        try:\n            # Get individual dissertation page\n            page = requests.get(link)\n            page_soup = BeautifulSoup(page.content, \"html.parser\")\n\n            # Extract required fields\n            date = page_soup.select_one(\"#publication_date p\").text.strip()\n            major = page_soup.select_one(\"#department p\").text.strip()\n            advisor = page_soup.select_one(\"#advisor1 p\").text.strip()\n\n            data.append({\n                \"Date\": date,\n                \"Major\": major,\n                \"Advisor\": advisor\n            })\n\n        except Exception as e:\n            print(f\"Error processing {link}: {str(e)}\")\n\n    return pl.DataFrame(data)\n\nWe can verify that it still works:\n\ndf = get_dissertation_data(BASE_URL)\nprint(df)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[2], line 1\n----&gt; 1 df = get_dissertation_data(BASE_URL)\n      2 print(df)\n\nNameError: name 'BASE_URL' is not defined\n\n\n\n\nNote that we now have to pass the argument BASE_URL to the function.\n\nLet‚Äôs look at the range function to understand how it works:\n\nfor i in range(5):\n    print(i)\n\n0\n1\n2\n3\n4\n\n\nrange(5) is the same as range(0, 5). It goes from 0‚Äîsince Python starts indexing at 0‚Äîand that left boundary is included to 4 because the right boundary (5 here) is excluded.\nSo range(116) would go from 0 to 115. You could verify it with:\nfor i in range(116):\n    print(i)\n\n\nYour turn:\n\n\nWe want numbers from 2 to 117, so what arguments do we need to pass to the range function?\n\nHow can you test it?\n\n\nApplied to the series of webpages, that would be:\nfor i in range(2, 118):\n    print(f\"https://trace.tennessee.edu/utk_graddiss/index.{i}.html\")\nThis is good, so let‚Äôs create a list with those webpages.\nFirst, we initialize an empty list of the proper length (this makes the code much more efficient than forcing Python to perform dynamic memory allocation at each iteration of the loop):\n\nurl_list = [None] * 116\n\nNow we can fill in the list with the URLs with a loop:\n\nfor i in range(2, 118):\n    url_list[i] = f\"https://trace.tennessee.edu/utk_graddiss/index.{i}.html\"\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[5], line 2\n      1 for i in range(2, 118):\n----&gt; 2     url_list[i] = f\"https://trace.tennessee.edu/utk_graddiss/index.{i}.html\"\n\nIndexError: list assignment index out of range\n\n\n\nLet‚Äôs print our list to make sure that all is good:\n\nprint(url_list)\n\n[None, None, 'https://trace.tennessee.edu/utk_graddiss/index.2.html', 'https://trace.tennessee.edu/utk_graddiss/index.3.html', 'https://trace.tennessee.edu/utk_graddiss/index.4.html', 'https://trace.tennessee.edu/utk_graddiss/index.5.html', 'https://trace.tennessee.edu/utk_graddiss/index.6.html', 'https://trace.tennessee.edu/utk_graddiss/index.7.html', 'https://trace.tennessee.edu/utk_graddiss/index.8.html', 'https://trace.tennessee.edu/utk_graddiss/index.9.html', 'https://trace.tennessee.edu/utk_graddiss/index.10.html', 'https://trace.tennessee.edu/utk_graddiss/index.11.html', 'https://trace.tennessee.edu/utk_graddiss/index.12.html', 'https://trace.tennessee.edu/utk_graddiss/index.13.html', 'https://trace.tennessee.edu/utk_graddiss/index.14.html', 'https://trace.tennessee.edu/utk_graddiss/index.15.html', 'https://trace.tennessee.edu/utk_graddiss/index.16.html', 'https://trace.tennessee.edu/utk_graddiss/index.17.html', 'https://trace.tennessee.edu/utk_graddiss/index.18.html', 'https://trace.tennessee.edu/utk_graddiss/index.19.html', 'https://trace.tennessee.edu/utk_graddiss/index.20.html', 'https://trace.tennessee.edu/utk_graddiss/index.21.html', 'https://trace.tennessee.edu/utk_graddiss/index.22.html', 'https://trace.tennessee.edu/utk_graddiss/index.23.html', 'https://trace.tennessee.edu/utk_graddiss/index.24.html', 'https://trace.tennessee.edu/utk_graddiss/index.25.html', 'https://trace.tennessee.edu/utk_graddiss/index.26.html', 'https://trace.tennessee.edu/utk_graddiss/index.27.html', 'https://trace.tennessee.edu/utk_graddiss/index.28.html', 'https://trace.tennessee.edu/utk_graddiss/index.29.html', 'https://trace.tennessee.edu/utk_graddiss/index.30.html', 'https://trace.tennessee.edu/utk_graddiss/index.31.html', 'https://trace.tennessee.edu/utk_graddiss/index.32.html', 'https://trace.tennessee.edu/utk_graddiss/index.33.html', 'https://trace.tennessee.edu/utk_graddiss/index.34.html', 'https://trace.tennessee.edu/utk_graddiss/index.35.html', 'https://trace.tennessee.edu/utk_graddiss/index.36.html', 'https://trace.tennessee.edu/utk_graddiss/index.37.html', 'https://trace.tennessee.edu/utk_graddiss/index.38.html', 'https://trace.tennessee.edu/utk_graddiss/index.39.html', 'https://trace.tennessee.edu/utk_graddiss/index.40.html', 'https://trace.tennessee.edu/utk_graddiss/index.41.html', 'https://trace.tennessee.edu/utk_graddiss/index.42.html', 'https://trace.tennessee.edu/utk_graddiss/index.43.html', 'https://trace.tennessee.edu/utk_graddiss/index.44.html', 'https://trace.tennessee.edu/utk_graddiss/index.45.html', 'https://trace.tennessee.edu/utk_graddiss/index.46.html', 'https://trace.tennessee.edu/utk_graddiss/index.47.html', 'https://trace.tennessee.edu/utk_graddiss/index.48.html', 'https://trace.tennessee.edu/utk_graddiss/index.49.html', 'https://trace.tennessee.edu/utk_graddiss/index.50.html', 'https://trace.tennessee.edu/utk_graddiss/index.51.html', 'https://trace.tennessee.edu/utk_graddiss/index.52.html', 'https://trace.tennessee.edu/utk_graddiss/index.53.html', 'https://trace.tennessee.edu/utk_graddiss/index.54.html', 'https://trace.tennessee.edu/utk_graddiss/index.55.html', 'https://trace.tennessee.edu/utk_graddiss/index.56.html', 'https://trace.tennessee.edu/utk_graddiss/index.57.html', 'https://trace.tennessee.edu/utk_graddiss/index.58.html', 'https://trace.tennessee.edu/utk_graddiss/index.59.html', 'https://trace.tennessee.edu/utk_graddiss/index.60.html', 'https://trace.tennessee.edu/utk_graddiss/index.61.html', 'https://trace.tennessee.edu/utk_graddiss/index.62.html', 'https://trace.tennessee.edu/utk_graddiss/index.63.html', 'https://trace.tennessee.edu/utk_graddiss/index.64.html', 'https://trace.tennessee.edu/utk_graddiss/index.65.html', 'https://trace.tennessee.edu/utk_graddiss/index.66.html', 'https://trace.tennessee.edu/utk_graddiss/index.67.html', 'https://trace.tennessee.edu/utk_graddiss/index.68.html', 'https://trace.tennessee.edu/utk_graddiss/index.69.html', 'https://trace.tennessee.edu/utk_graddiss/index.70.html', 'https://trace.tennessee.edu/utk_graddiss/index.71.html', 'https://trace.tennessee.edu/utk_graddiss/index.72.html', 'https://trace.tennessee.edu/utk_graddiss/index.73.html', 'https://trace.tennessee.edu/utk_graddiss/index.74.html', 'https://trace.tennessee.edu/utk_graddiss/index.75.html', 'https://trace.tennessee.edu/utk_graddiss/index.76.html', 'https://trace.tennessee.edu/utk_graddiss/index.77.html', 'https://trace.tennessee.edu/utk_graddiss/index.78.html', 'https://trace.tennessee.edu/utk_graddiss/index.79.html', 'https://trace.tennessee.edu/utk_graddiss/index.80.html', 'https://trace.tennessee.edu/utk_graddiss/index.81.html', 'https://trace.tennessee.edu/utk_graddiss/index.82.html', 'https://trace.tennessee.edu/utk_graddiss/index.83.html', 'https://trace.tennessee.edu/utk_graddiss/index.84.html', 'https://trace.tennessee.edu/utk_graddiss/index.85.html', 'https://trace.tennessee.edu/utk_graddiss/index.86.html', 'https://trace.tennessee.edu/utk_graddiss/index.87.html', 'https://trace.tennessee.edu/utk_graddiss/index.88.html', 'https://trace.tennessee.edu/utk_graddiss/index.89.html', 'https://trace.tennessee.edu/utk_graddiss/index.90.html', 'https://trace.tennessee.edu/utk_graddiss/index.91.html', 'https://trace.tennessee.edu/utk_graddiss/index.92.html', 'https://trace.tennessee.edu/utk_graddiss/index.93.html', 'https://trace.tennessee.edu/utk_graddiss/index.94.html', 'https://trace.tennessee.edu/utk_graddiss/index.95.html', 'https://trace.tennessee.edu/utk_graddiss/index.96.html', 'https://trace.tennessee.edu/utk_graddiss/index.97.html', 'https://trace.tennessee.edu/utk_graddiss/index.98.html', 'https://trace.tennessee.edu/utk_graddiss/index.99.html', 'https://trace.tennessee.edu/utk_graddiss/index.100.html', 'https://trace.tennessee.edu/utk_graddiss/index.101.html', 'https://trace.tennessee.edu/utk_graddiss/index.102.html', 'https://trace.tennessee.edu/utk_graddiss/index.103.html', 'https://trace.tennessee.edu/utk_graddiss/index.104.html', 'https://trace.tennessee.edu/utk_graddiss/index.105.html', 'https://trace.tennessee.edu/utk_graddiss/index.106.html', 'https://trace.tennessee.edu/utk_graddiss/index.107.html', 'https://trace.tennessee.edu/utk_graddiss/index.108.html', 'https://trace.tennessee.edu/utk_graddiss/index.109.html', 'https://trace.tennessee.edu/utk_graddiss/index.110.html', 'https://trace.tennessee.edu/utk_graddiss/index.111.html', 'https://trace.tennessee.edu/utk_graddiss/index.112.html', 'https://trace.tennessee.edu/utk_graddiss/index.113.html', 'https://trace.tennessee.edu/utk_graddiss/index.114.html', 'https://trace.tennessee.edu/utk_graddiss/index.115.html']"
  },
  {
    "objectID": "python/nlp_analysis.html",
    "href": "python/nlp_analysis.html",
    "title": "Sentiment analysis",
    "section": "",
    "text": "One of the common tasks of natural language processing is sentiment analysis. Let‚Äôs see how it works with TextBlob.",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Sentiment analysis"
    ]
  },
  {
    "objectID": "python/nlp_analysis.html#the-data",
    "href": "python/nlp_analysis.html#the-data",
    "title": "Sentiment analysis",
    "section": "The data",
    "text": "The data\nIt wouldn‚Äôt make much sense to do sentiment analysis on the first pdf page of Wyrd Sisters. Instead, let‚Äôs use some Goodreads reviews of Wyrd Sisters.\nThe method is as easy as everything we have seen so far: you simply use the sentiment attribute of a TextBlob object and you get a named tuple with the polarity on a continuous scale from -1 to +1 and a subjectivity ranging from 0 to 1.\nWe could get very fancy, scrape the site and analyse all the reviews, but this is not the purpose of this course. Instead, we will simply copy and paste a few reviews in the TextBlob function to turn them into TextBlob objects and look at their sentiment attributes.\nIf TextBlob does a good job at analysing those reviews, we should get a polarity close to 1 for four and five-star reviews and a polarity close to -1 for one-star reviews.",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Sentiment analysis"
    ]
  },
  {
    "objectID": "python/nlp_analysis.html#results",
    "href": "python/nlp_analysis.html#results",
    "title": "Sentiment analysis",
    "section": "Results",
    "text": "Results\n\nBe careful that you have to remove all end of lines when you paste the reviews into your code to make sure that you create a Python string.\n\nLet‚Äôs create a string with one of the four-star reviews:\n\nreview1 = \"How have I never read Terry Pratchett before? He's like ... Shakespeare and Wodehouse and Monty Python all wrapped into one! A student gave me this book while we were studying Macbeth in class. Wyrd Sisters is a sort of parallel story, which manages to poke fun at the play, revere the play, make inside jokes about the play, and ... well, generally turn the play on its head. All the while, you, the reader, get to feel very smart and superior for getting all the jokes and allusions. And yet it manages to avoid being gimmicky. It really is a good story with good characters, too. This is no Life of Brian where the story itself matters less than the hilarity of the parody. Wyrd Sisters may draw a good deal of life from Macbeth, but its real liveliness comes from Pratchett's skilled characterizations of a regicidal Duke, his murderess Dutchess, their depressed Fool, and three very colorful witches. Oh, it's just genius. My only problem is figuring out what Pratchett novel to read next ... he's dauntingly prolific!\"\n\nWe need to turn the string into a TextBlob object:\n\nr1 = TextBlob(review1)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 r1 = TextBlob(review1)\n\nNameError: name 'TextBlob' is not defined\n\n\n\nAnd now we can see the result of the sentiment analysis:\n\nprint(r1.sentiment)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[4], line 1\n----&gt; 1 print(r1.sentiment)\n\nNameError: name 'r1' is not defined\n\n\n\nThe result is a bit far from 1 for a four-star review. Maybe we can do better. TextBlob can use a more fancy approach for sentiment analysis based on a naive Bayes analyzer from NLTK trained on a movie reviews corpus. Let‚Äôs see if we get better results.\nFirst, we need to load the module:\n\nfrom textblob.sentiments import NaiveBayesAnalyzer\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[5], line 1\n----&gt; 1 from textblob.sentiments import NaiveBayesAnalyzer\n\nModuleNotFoundError: No module named 'textblob'\n\n\n\nThen we run the analysis:\n\nr1b = TextBlob(review1, analyzer=NaiveBayesAnalyzer())\nprint(r1b.sentiment)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[6], line 1\n----&gt; 1 r1b = TextBlob(review1, analyzer=NaiveBayesAnalyzer())\n      2 print(r1b.sentiment)\n\nNameError: name 'TextBlob' is not defined\n\n\n\nIt looks a lot better!\nLet‚Äôs try on a five-star review this time:\n\nreview2 = \"A veritable smorgasbord of Shakespeare references sees the 6th Discworld novel come to life, dragging the two most prominent witches (Granny and Nanny) and their occult-leaning protege, Magrat, though thickets and thick-cities alike as they attempt to make sure fate happens. Maybe with a few encouraging prods along the way‚Ä¶ A mixture of Macbeth and Hamlet with a little dollop of King Lear thrown in, along with many other Shakespeare nonsense that doesn‚Äôt stand out right way, Wyrd Sisters is one of PTerry‚Äôs very early masterpieces. His hands and head seem to meld together as one, where his imagination is not shackled by the human-only speed of his writing (or typing) or the darned debilitation of the English language.The plot simmers nicely, following and then not following the true path of how this kind of story goes. It‚Äôs so nice to see the Discworld countryside getting a deep look-in, and how well it contrasts with city-life, but also manages to co-exist very peacefully (as long as the city stays far away from the countryside, thank you). Whilst previously we visited vast open vistas on the Disc, these close-quarter scenes are even more brimful of life and curiosity and share yet another facet to not only PTerry‚Äôs imagination, but the world he has created. One of the best things about PTerry (and of any comedy at all) is that, whilst he does take the mickey out of Shakespeare and fantasy and all those things, he does it with such love and reverence that it shines through and makes the humour that much more poignant and, well, funny. (My previous review of this had me not enjoying it and I‚Äôm actually pretty baffled by that. I loved every single minute of this re-read and it‚Äôs curious how your tastes and feelings can change even after only a few years. I‚Äôll leave the old review below just for the sake of it: Wyrd Sisters is the second of the Witch mini-series, in the ever popular Discworld series. Equal Rites was the first and we were introduced to one of the greatest characters of all-time: Granny Weatherwax. Wyrd Sisters brings two more witches-and mentions of many others-in to fray: Nanny Ogg, Granny's best friend, and Magrat Garlick, a new-wave witch who thinks jangling jewellery and occult symbols makes you a better witch. Adding two new witches alongside Granny just emphasises how cantankerous, stubborn and bloody brilliant she is. Even they can't deny that she's the best. She is tolerated most of the time, but there's always an underlying current of total respect, in the same way you respect your grandparents because they lived through the war, even if they do still say \\\"does anyone want to get a Chinky?\\\" The plot is Shakespearean-Macbeth in particular-and takes many plot points from that, as well as a lot of the quotes. It's a wonderful juxtaposition of Discworld nonsense and Shakespearean tragedy that is twisted with unique Pratchett humour. It is written much the same way all the early Discworld books were. Very well, hardly any technical faults and smatterings of Pratchett humour. Despite the wonderful Granny, the amusing Nanny and the Straightforward but naive Magrat, and my love for all the Discworld witches, I couldn't enjoy this as much as I wanted. It was funny in a tittering kind of way, and the plot was interesting, but it never quite held my attention. I never felt like I wanted to read it all the time, or try and finish reading it. It took me quite a while to get through it (for other reasons I won't go in to) but it never really held me enough to want it. Still a better love story than Twilight.)\"\n\nr2 = TextBlob(review2)\nr2b = TextBlob(review2, analyzer=NaiveBayesAnalyzer())\n\nprint(r2.sentiment)\nprint(r2b.sentiment)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[7], line 3\n      1 review2 = \"A veritable smorgasbord of Shakespeare references sees the 6th Discworld novel come to life, dragging the two most prominent witches (Granny and Nanny) and their occult-leaning protege, Magrat, though thickets and thick-cities alike as they attempt to make sure fate happens. Maybe with a few encouraging prods along the way‚Ä¶ A mixture of Macbeth and Hamlet with a little dollop of King Lear thrown in, along with many other Shakespeare nonsense that doesn‚Äôt stand out right way, Wyrd Sisters is one of PTerry‚Äôs very early masterpieces. His hands and head seem to meld together as one, where his imagination is not shackled by the human-only speed of his writing (or typing) or the darned debilitation of the English language.The plot simmers nicely, following and then not following the true path of how this kind of story goes. It‚Äôs so nice to see the Discworld countryside getting a deep look-in, and how well it contrasts with city-life, but also manages to co-exist very peacefully (as long as the city stays far away from the countryside, thank you). Whilst previously we visited vast open vistas on the Disc, these close-quarter scenes are even more brimful of life and curiosity and share yet another facet to not only PTerry‚Äôs imagination, but the world he has created. One of the best things about PTerry (and of any comedy at all) is that, whilst he does take the mickey out of Shakespeare and fantasy and all those things, he does it with such love and reverence that it shines through and makes the humour that much more poignant and, well, funny. (My previous review of this had me not enjoying it and I‚Äôm actually pretty baffled by that. I loved every single minute of this re-read and it‚Äôs curious how your tastes and feelings can change even after only a few years. I‚Äôll leave the old review below just for the sake of it: Wyrd Sisters is the second of the Witch mini-series, in the ever popular Discworld series. Equal Rites was the first and we were introduced to one of the greatest characters of all-time: Granny Weatherwax. Wyrd Sisters brings two more witches-and mentions of many others-in to fray: Nanny Ogg, Granny's best friend, and Magrat Garlick, a new-wave witch who thinks jangling jewellery and occult symbols makes you a better witch. Adding two new witches alongside Granny just emphasises how cantankerous, stubborn and bloody brilliant she is. Even they can't deny that she's the best. She is tolerated most of the time, but there's always an underlying current of total respect, in the same way you respect your grandparents because they lived through the war, even if they do still say \\\"does anyone want to get a Chinky?\\\" The plot is Shakespearean-Macbeth in particular-and takes many plot points from that, as well as a lot of the quotes. It's a wonderful juxtaposition of Discworld nonsense and Shakespearean tragedy that is twisted with unique Pratchett humour. It is written much the same way all the early Discworld books were. Very well, hardly any technical faults and smatterings of Pratchett humour. Despite the wonderful Granny, the amusing Nanny and the Straightforward but naive Magrat, and my love for all the Discworld witches, I couldn't enjoy this as much as I wanted. It was funny in a tittering kind of way, and the plot was interesting, but it never quite held my attention. I never felt like I wanted to read it all the time, or try and finish reading it. It took me quite a while to get through it (for other reasons I won't go in to) but it never really held me enough to want it. Still a better love story than Twilight.)\"\n----&gt; 3 r2 = TextBlob(review2)\n      4 r2b = TextBlob(review2, analyzer=NaiveBayesAnalyzer())\n      6 print(r2.sentiment)\n\nNameError: name 'TextBlob' is not defined\n\n\n\nHere too, the naive Bayesian classifier performs a lot better.\nNow, let‚Äôs see what we get for a one-star review:\n\nreview3 = \"I struggled finishing the book as I lost interest.\"\n\nr3 = TextBlob(review3)\nr3b = TextBlob(review3, analyzer=NaiveBayesAnalyzer())\n\nprint(r3.sentiment)\nprint(r3b.sentiment)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[8], line 3\n      1 review3 = \"I struggled finishing the book as I lost interest.\"\n----&gt; 3 r3 = TextBlob(review3)\n      4 r3b = TextBlob(review3, analyzer=NaiveBayesAnalyzer())\n      6 print(r3.sentiment)\n\nNameError: name 'TextBlob' is not defined\n\n\n\nWell‚Ä¶ üôÅ Frankly, both models performed poorly here.\nLet‚Äôs try another one-star review:\n\nreview4 = \"I did not enjoy this book at all. Slow and tedious. It had some funny bits in the beginning, but I struggled to finish it.\"\n\nr4 = TextBlob(review4)\nr4b = TextBlob(review4, analyzer=NaiveBayesAnalyzer())\n\nprint(r4.sentiment)\nprint(r4b.sentiment)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[9], line 3\n      1 review4 = \"I did not enjoy this book at all. Slow and tedious. It had some funny bits in the beginning, but I struggled to finish it.\"\n----&gt; 3 r4 = TextBlob(review4)\n      4 r4b = TextBlob(review4, analyzer=NaiveBayesAnalyzer())\n      6 print(r4.sentiment)\n\nNameError: name 'TextBlob' is not defined\n\n\n\nHere again, both models perform poorly, but the Bayesian model does even worse than the default pattern analyzer.\nLet‚Äôs do a few more one-star reviews:\n\nreview5 = \"It doesn't get much more boring than that. Zero improvement from Equal Rights, a complete snore-fest, poorly paced and with a clear lack of stakes and humour. I quit Discworld.\"\n\nr5 = TextBlob(review5)\nr5b = TextBlob(review5, analyzer=NaiveBayesAnalyzer())\n\nprint(r5.sentiment)\nprint(r5b.sentiment)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[10], line 3\n      1 review5 = \"It doesn't get much more boring than that. Zero improvement from Equal Rights, a complete snore-fest, poorly paced and with a clear lack of stakes and humour. I quit Discworld.\"\n----&gt; 3 r5 = TextBlob(review5)\n      4 r5b = TextBlob(review5, analyzer=NaiveBayesAnalyzer())\n      6 print(r5.sentiment)\n\nNameError: name 'TextBlob' is not defined\n\n\n\n\nreview6 = \"Hated this book. To be fair, not my style. Only read parts of it because it was assigned for a book club.\"\n\nr6 = TextBlob(review6)\nr6b = TextBlob(review6, analyzer=NaiveBayesAnalyzer())\n\nprint(r6.sentiment)\nprint(r6b.sentiment)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[11], line 3\n      1 review6 = \"Hated this book. To be fair, not my style. Only read parts of it because it was assigned for a book club.\"\n----&gt; 3 r6 = TextBlob(review6)\n      4 r6b = TextBlob(review6, analyzer=NaiveBayesAnalyzer())\n      6 print(r6.sentiment)\n\nNameError: name 'TextBlob' is not defined\n\n\n\n\nreview7 = \"Dnf - boring\"\n\nr7 = TextBlob(review7)\nr7b = TextBlob(review7, analyzer=NaiveBayesAnalyzer())\n\nprint(r7.sentiment)\nprint(r7b.sentiment)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[12], line 3\n      1 review7 = \"Dnf - boring\"\n----&gt; 3 r7 = TextBlob(review7)\n      4 r7b = TextBlob(review7, analyzer=NaiveBayesAnalyzer())\n      6 print(r7.sentiment)\n\nNameError: name 'TextBlob' is not defined\n\n\n\nThese fared better, although, the results are not exactly impressive.",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Sentiment analysis"
    ]
  },
  {
    "objectID": "python/nlp_analysis.html#rule-based-vs-data-based-nlp",
    "href": "python/nlp_analysis.html#rule-based-vs-data-based-nlp",
    "title": "Sentiment analysis",
    "section": "Rule-based vs data-based NLP",
    "text": "Rule-based vs data-based NLP\nTextBlob (as well as NLTK on which it is built) uses a rule-based or lexicon-based approach to NLP. This is an old technique that requires linguistic knowledge, but is computationally basic. As we saw, it has many limitations.\nThe recent successes of large language models (LLMs) have shown unequivocally that AI algorithms fed vast amounts of data do a much better job. They do not need to be programmed explicitly since they learn by experience. They do however require a lot of computing power and data for training.\nSuch models are built from multiple complex artificial neural networks trained using machine learning frameworks such as PyTorch or JAX.\nAs Frederick Jelinek is famously often quoted for saying (although what he said was probably slightly different):\n\nEvery time I fire a linguist, the performance of the speech recognizer goes up.\n\n\nI will quickly demo how much better any of the LLMs out there does at this task.",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Sentiment analysis"
    ]
  },
  {
    "objectID": "python/nlp_install.html",
    "href": "python/nlp_install.html",
    "title": "Package installation",
    "section": "",
    "text": "In this first section, we will install the packages needed for this course.",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Package installation"
    ]
  },
  {
    "objectID": "python/nlp_install.html#python-packages",
    "href": "python/nlp_install.html#python-packages",
    "title": "Package installation",
    "section": "Python packages",
    "text": "Python packages\nPython can do a lot out of the box, but for specialized tasks, you need to install additional packages. Packages contain additional functions and variables. Some packages also contain data.\nYou can find Python packages in the Python Package Index (PyPI)‚Äîa repository of open source packages.\nTo know which packages to use, you can talk with colleagues or look at the literature to see what people in your community use.",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Package installation"
    ]
  },
  {
    "objectID": "python/nlp_install.html#package-managers",
    "href": "python/nlp_install.html#package-managers",
    "title": "Package installation",
    "section": "Package managers",
    "text": "Package managers\nThere are many ways to install Python packages.\nFor instance, people who need to use the Digital Research Alliance of Canada supercomputers have to use pip: the package installer for Python. This is the most lean and efficient fashion to manage Python packages.\nAn alternative to pip is conda: a package and environment manager for Python and other languages.\nFinally, the most convenient (but also the most bloated) option is to use Anaconda. This is what you have been using so far, so we will stick to the same workflow.\nAnaconda is a big project that comes with Python and a suite of packages needed for science. It also provides conda, as well as a graphical interface to manage your environments and packages. It makes things very easy for you, but it is also a very big and will take time to install and use up a lot of space.\nThe getting started with Navigator page of the Anaconda documentation goes over the steps necessary to create a new Python environment and install packages.\nFirst, launch the Navigator.",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Package installation"
    ]
  },
  {
    "objectID": "python/nlp_install.html#python-environments",
    "href": "python/nlp_install.html#python-environments",
    "title": "Package installation",
    "section": "Python environments",
    "text": "Python environments\nWhy do we need to create a Python environment?\nThere are a very large number of Python packages and some might conflict with each other. They may also have conflicting dependency requirements.\n\nFor instance, package A might need package B at version 3.4 (package B is called a dependency of package A‚Äîit is not a package you install explicitly, but it needs to be installed before package A can work), while package C requires package B at version 2.8. Dependencies get automatically installed when you install packages, but if you want to use package A and C together, you run into conflicts. Having different environments for different projects allows to only have the few packages that you need for each project in each environment and makes the whole situation a lot simpler.\n\nFollowing the Anaconda documentation, let‚Äôs create a new environment called text and activate it.",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Package installation"
    ]
  },
  {
    "objectID": "python/nlp_install.html#installing-packages",
    "href": "python/nlp_install.html#installing-packages",
    "title": "Package installation",
    "section": "Installing packages",
    "text": "Installing packages\nNow, we can install packages in our environment, still using the Anaconda Navigator.\nThe packages you need for this course are:\n\ntextblob\nrequests\npymupdf\n\nFollowing the Anaconda instructions, look for, then install each of these packages.\nYou are now ready for this course.",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Package installation"
    ]
  },
  {
    "objectID": "python/nlp_processing.html",
    "href": "python/nlp_processing.html",
    "title": "Text processing",
    "section": "",
    "text": "In this section, we will use the TextBlob package for part of speech tagging and basic tokenization.",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Text processing"
    ]
  },
  {
    "objectID": "python/nlp_processing.html#textblob",
    "href": "python/nlp_processing.html#textblob",
    "title": "Text processing",
    "section": "TextBlob",
    "text": "TextBlob\nTextBlob is the NLP package that we will use in this course for tagging, tokenization, normalization, and sentiment analysis.\nWe first need to load it in our session:\n\nfrom textblob import TextBlob\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[2], line 1\n----&gt; 1 from textblob import TextBlob\n\nModuleNotFoundError: No module named 'textblob'\n\n\n\nBefore we can use TextBlob on our text, we need to convert the page1 string into a TextBlob object:\n\ntext = TextBlob(page1)\ntype(text)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 text = TextBlob(page1)\n      2 type(text)\n\nNameError: name 'TextBlob' is not defined",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Text processing"
    ]
  },
  {
    "objectID": "python/nlp_processing.html#part-of-speech-tagging",
    "href": "python/nlp_processing.html#part-of-speech-tagging",
    "title": "Text processing",
    "section": "Part of speech tagging",
    "text": "Part of speech tagging\nPart of speech tagging attributes parts of speech (POS) tags to each word of a text.\nYou can do this simply by using the tags property on a TextBlob object: text.tags. Because there are a lot of words in the first pdf page, this would create a very long output.\nThe result is a list:\n\ntype(text.tags)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[4], line 1\n----&gt; 1 type(text.tags)\n\nNameError: name 'text' is not defined\n\n\n\nAnd each element of the list is a tuple:\n\ntype(text.tags[0])\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[5], line 1\n----&gt; 1 type(text.tags[0])\n\nNameError: name 'text' is not defined\n\n\n\nWe don‚Äôt have to print the full list. Let‚Äôs only print the first 20 tuples:\n\ntext.tags[:20]\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[6], line 1\n----&gt; 1 text.tags[:20]\n\nNameError: name 'text' is not defined\n\n\n\n\n\n\n\n\n\nNoteTagset from the University of Pennsylvania as reference\n\n\n\n\n\n\n\n\nTag\nDescription\n\n\n\n\nCC\nCoordinating conjunction\n\n\nCD\nCardinal number\n\n\nDT\nDeterminer\n\n\nEX\nExistential there\n\n\nFW\nForeign word\n\n\nIN\nPreposition or subordinating conjunction\n\n\nJJ\nAdjective\n\n\nJJR\nAdjective, comparative\n\n\nJJS\nAdjective, superlative\n\n\nLS\nList item marker\n\n\nMD\nModal\n\n\nNN\nNoun, singular or mass\n\n\nNNS\nNoun, plural\n\n\nNNP\nProper noun, singular\n\n\nNNPS\nProper noun, plural\n\n\nPDT\nPredeterminer\n\n\nPOS\nPossessive ending\n\n\nPRP\nPersonal pronoun\n\n\nPRP$\nPossessive pronoun\n\n\nRB\nAdverb\n\n\nRBR\nAdverb, comparative\n\n\nRBS\nAdverb, superlative\n\n\nRP\nParticle\n\n\nSYM\nSymbol\n\n\nTO\nto\n\n\nUH\nInterjection\n\n\nVB\nVerb, base form\n\n\nVBD\nVerb, past tense\n\n\nVBG\nVerb, gerund or present participle\n\n\nVBN\nVerb, past participle\n\n\nVBP\nVerb, non-3rd person singular present\n\n\nVBZ\nVerb, 3rd person singular present\n\n\nWDT\nWh-determiner\n\n\nWP\nWh-pronoun\n\n\nWP$\nPossessive wh-pronoun\n\n\nWRB\nWh-adverb",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Text processing"
    ]
  },
  {
    "objectID": "python/nlp_processing.html#noun-phrases-extraction",
    "href": "python/nlp_processing.html#noun-phrases-extraction",
    "title": "Text processing",
    "section": "Noun phrases extraction",
    "text": "Noun phrases extraction\nNoun phrases can be extracted with the noun_phrases property:\n\nprint(text.noun_phrases)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[7], line 1\n----&gt; 1 print(text.noun_phrases)\n\nNameError: name 'text' is not defined\n\n\n\nThe output is a WordList object:\n\ntype(text.noun_phrases)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[8], line 1\n----&gt; 1 type(text.noun_phrases)\n\nNameError: name 'text' is not defined",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Text processing"
    ]
  },
  {
    "objectID": "python/nlp_processing.html#tokenization",
    "href": "python/nlp_processing.html#tokenization",
    "title": "Text processing",
    "section": "Tokenization",
    "text": "Tokenization\n\nWords\nTextBlob allows to extract words easily with the words attribute:\n\nprint(text.words)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[9], line 1\n----&gt; 1 print(text.words)\n\nNameError: name 'text' is not defined\n\n\n\n\n\nYour turn:\n\nHow many words are there in the first pdf page of Wyrd Sisters?\n\n\n\nSentences\nExtracting sentences is just as easy with the sentences attribute.\nLet‚Äôs extract the first 10 sentences:\n\ntext.sentences[:10]\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[10], line 1\n----&gt; 1 text.sentences[:10]\n\nNameError: name 'text' is not defined\n\n\n\nThe output is however quite ugly. We could make this a lot more readable by printing each sentence separated by a blank line:\n\nfor s in text.sentences[:10]:\n    print(s)\n    print(\"\\n\")\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[11], line 1\n----&gt; 1 for s in text.sentences[:10]:\n      2     print(s)\n      3     print(\"\\n\")\n\nNameError: name 'text' is not defined\n\n\n\n\nIn Python strings (as in many other languages), \"\\n\" represents a new line.\n\nOr you could add lines of hyphens between the sentences:\n\nfor s in text.sentences[:10]:\n    print(s)\n    print(\"-\" * 100)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[12], line 1\n----&gt; 1 for s in text.sentences[:10]:\n      2     print(s)\n      3     print(\"-\" * 100)\n\nNameError: name 'text' is not defined\n\n\n\n\n\nYour turn:\n\n\nWhat is the type of text.sentences?\n\nCould you print just the 5th sentence?\n\nJust the last sentence?",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Text processing"
    ]
  },
  {
    "objectID": "python/nlp_processing.html#word-counts",
    "href": "python/nlp_processing.html#word-counts",
    "title": "Text processing",
    "section": "Word counts",
    "text": "Word counts\nWe already saw that we can extract words with the words attribute. Now, we can add the count method to get the frequency of specific words.\n\ntext.words.count(\"gods\")\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[13], line 1\n----&gt; 1 text.words.count(\"gods\")\n\nNameError: name 'text' is not defined",
    "crumbs": [
      "Python",
      "<b><em>Text analysis</em></b>",
      "Text processing"
    ]
  },
  {
    "objectID": "python/polars_inspection.html",
    "href": "python/polars_inspection.html",
    "title": "Data frame inspection",
    "section": "",
    "text": "Once we have a data frame, it is important to quickly get some basic information about it. In this section, we will see how to do so.\nLet‚Äôs start by reading an online CSV file from a URL:\nimport polars as pl\n\ndf = pl.read_csv(\"https://raw.githubusercontent.com/razoumov/publish/master/jeopardy.csv\")\nprint(df)\n\nshape: (216_930, 7)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Show Number ‚îÜ Air Date ‚îÜ Round     ‚îÜ Category        ‚îÜ Value   ‚îÜ Question       ‚îÜ Answer         ‚îÇ\n‚îÇ ---         ‚îÜ ---      ‚îÜ ---       ‚îÜ ---             ‚îÜ ---     ‚îÜ ---            ‚îÜ ---            ‚îÇ\n‚îÇ i64         ‚îÜ str      ‚îÜ str       ‚îÜ str             ‚îÜ str     ‚îÜ str            ‚îÜ str            ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 4680        ‚îÜ 12/31/04 ‚îÜ Jeopardy! ‚îÜ HISTORY         ‚îÜ $200    ‚îÜ For the last 8 ‚îÜ Copernicus     ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ years of his   ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ li‚Ä¶            ‚îÜ                ‚îÇ\n‚îÇ 4680        ‚îÜ 12/31/04 ‚îÜ Jeopardy! ‚îÜ ESPN's TOP 10   ‚îÜ $200    ‚îÜ No. 2: 1912    ‚îÜ Jim Thorpe     ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ ALL-TIME        ‚îÜ         ‚îÜ Olympian;      ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ ATHLETE‚Ä¶        ‚îÜ         ‚îÜ football‚Ä¶      ‚îÜ                ‚îÇ\n‚îÇ 4680        ‚îÜ 12/31/04 ‚îÜ Jeopardy! ‚îÜ EVERYBODY TALKS ‚îÜ $200    ‚îÜ The city of    ‚îÜ Arizona        ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ ABOUT IT...     ‚îÜ         ‚îÜ Yuma in this   ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ state‚Ä¶         ‚îÜ                ‚îÇ\n‚îÇ 4680        ‚îÜ 12/31/04 ‚îÜ Jeopardy! ‚îÜ THE COMPANY     ‚îÜ $200    ‚îÜ In 1963, live  ‚îÜ McDonald's     ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ LINE            ‚îÜ         ‚îÜ on \"The Art    ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ Link‚Ä¶          ‚îÜ                ‚îÇ\n‚îÇ 4680        ‚îÜ 12/31/04 ‚îÜ Jeopardy! ‚îÜ EPITAPHS &      ‚îÜ $200    ‚îÜ Signer of the  ‚îÜ John Adams     ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ TRIBUTES        ‚îÜ         ‚îÜ Dec. of        ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ Indep., ‚Ä¶      ‚îÜ                ‚îÇ\n‚îÇ ‚Ä¶           ‚îÜ ‚Ä¶        ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶               ‚îÜ ‚Ä¶       ‚îÜ ‚Ä¶              ‚îÜ ‚Ä¶              ‚îÇ\n‚îÇ 4999        ‚îÜ 5/11/06  ‚îÜ Double    ‚îÜ RIDDLE ME THIS  ‚îÜ $2,000  ‚îÜ This Puccini   ‚îÜ Turandot       ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ Jeopardy! ‚îÜ                 ‚îÜ         ‚îÜ opera turns on ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ th‚Ä¶            ‚îÜ                ‚îÇ\n‚îÇ 4999        ‚îÜ 5/11/06  ‚îÜ Double    ‚îÜ \"T\" BIRDS       ‚îÜ $2,000  ‚îÜ In North       ‚îÜ a titmouse     ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ Jeopardy! ‚îÜ                 ‚îÜ         ‚îÜ America this   ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ term is ‚Ä¶      ‚îÜ                ‚îÇ\n‚îÇ 4999        ‚îÜ 5/11/06  ‚îÜ Double    ‚îÜ AUTHORS IN      ‚îÜ $2,000  ‚îÜ In Penny Lane, ‚îÜ Clive Barker   ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ Jeopardy! ‚îÜ THEIR YOUTH     ‚îÜ         ‚îÜ where this     ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ \"Hel‚Ä¶          ‚îÜ                ‚îÇ\n‚îÇ 4999        ‚îÜ 5/11/06  ‚îÜ Double    ‚îÜ QUOTATIONS      ‚îÜ $2,000  ‚îÜ From Ft. Sill, ‚îÜ Geronimo       ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ Jeopardy! ‚îÜ                 ‚îÜ         ‚îÜ Okla. he made  ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ t‚Ä¶             ‚îÜ                ‚îÇ\n‚îÇ 4999        ‚îÜ 5/11/06  ‚îÜ Final     ‚îÜ HISTORIC NAMES  ‚îÜ None    ‚îÜ A silent movie ‚îÜ Grigori        ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ Jeopardy! ‚îÜ                 ‚îÜ         ‚îÜ title includes ‚îÜ Alexandrovich  ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ ‚Ä¶              ‚îÜ Potemkin       ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Data frame inspection"
    ]
  },
  {
    "objectID": "python/polars_inspection.html#printing-a-few-rows",
    "href": "python/polars_inspection.html#printing-a-few-rows",
    "title": "Data frame inspection",
    "section": "Printing a few rows",
    "text": "Printing a few rows\nPrint first rows (5 by default):\n\nprint(df.head())\n\nshape: (5, 7)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Show Number ‚îÜ Air Date ‚îÜ Round     ‚îÜ Category           ‚îÜ Value ‚îÜ Question          ‚îÜ Answer     ‚îÇ\n‚îÇ ---         ‚îÜ ---      ‚îÜ ---       ‚îÜ ---                ‚îÜ ---   ‚îÜ ---               ‚îÜ ---        ‚îÇ\n‚îÇ i64         ‚îÜ str      ‚îÜ str       ‚îÜ str                ‚îÜ str   ‚îÜ str               ‚îÜ str        ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 4680        ‚îÜ 12/31/04 ‚îÜ Jeopardy! ‚îÜ HISTORY            ‚îÜ $200  ‚îÜ For the last 8    ‚îÜ Copernicus ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                    ‚îÜ       ‚îÜ years of his li‚Ä¶  ‚îÜ            ‚îÇ\n‚îÇ 4680        ‚îÜ 12/31/04 ‚îÜ Jeopardy! ‚îÜ ESPN's TOP 10      ‚îÜ $200  ‚îÜ No. 2: 1912       ‚îÜ Jim Thorpe ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ ALL-TIME ATHLETE‚Ä¶  ‚îÜ       ‚îÜ Olympian;         ‚îÜ            ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                    ‚îÜ       ‚îÜ football‚Ä¶         ‚îÜ            ‚îÇ\n‚îÇ 4680        ‚îÜ 12/31/04 ‚îÜ Jeopardy! ‚îÜ EVERYBODY TALKS    ‚îÜ $200  ‚îÜ The city of Yuma  ‚îÜ Arizona    ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ ABOUT IT...        ‚îÜ       ‚îÜ in this state‚Ä¶    ‚îÜ            ‚îÇ\n‚îÇ 4680        ‚îÜ 12/31/04 ‚îÜ Jeopardy! ‚îÜ THE COMPANY LINE   ‚îÜ $200  ‚îÜ In 1963, live on  ‚îÜ McDonald's ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                    ‚îÜ       ‚îÜ \"The Art Link‚Ä¶    ‚îÜ            ‚îÇ\n‚îÇ 4680        ‚îÜ 12/31/04 ‚îÜ Jeopardy! ‚îÜ EPITAPHS &         ‚îÜ $200  ‚îÜ Signer of the     ‚îÜ John Adams ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ TRIBUTES           ‚îÜ       ‚îÜ Dec. of Indep., ‚Ä¶ ‚îÜ            ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\nprint(df.head(2))\n\nshape: (2, 7)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Show Number ‚îÜ Air Date ‚îÜ Round     ‚îÜ Category           ‚îÜ Value ‚îÜ Question          ‚îÜ Answer     ‚îÇ\n‚îÇ ---         ‚îÜ ---      ‚îÜ ---       ‚îÜ ---                ‚îÜ ---   ‚îÜ ---               ‚îÜ ---        ‚îÇ\n‚îÇ i64         ‚îÜ str      ‚îÜ str       ‚îÜ str                ‚îÜ str   ‚îÜ str               ‚îÜ str        ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 4680        ‚îÜ 12/31/04 ‚îÜ Jeopardy! ‚îÜ HISTORY            ‚îÜ $200  ‚îÜ For the last 8    ‚îÜ Copernicus ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                    ‚îÜ       ‚îÜ years of his li‚Ä¶  ‚îÜ            ‚îÇ\n‚îÇ 4680        ‚îÜ 12/31/04 ‚îÜ Jeopardy! ‚îÜ ESPN's TOP 10      ‚îÜ $200  ‚îÜ No. 2: 1912       ‚îÜ Jim Thorpe ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ ALL-TIME ATHLETE‚Ä¶  ‚îÜ       ‚îÜ Olympian;         ‚îÜ            ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                    ‚îÜ       ‚îÜ football‚Ä¶         ‚îÜ            ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\nPrint last rows (5 by default):\n\nprint(df.tail(2))\n\nshape: (2, 7)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Show Number ‚îÜ Air Date ‚îÜ Round     ‚îÜ Category        ‚îÜ Value   ‚îÜ Question       ‚îÜ Answer         ‚îÇ\n‚îÇ ---         ‚îÜ ---      ‚îÜ ---       ‚îÜ ---             ‚îÜ ---     ‚îÜ ---            ‚îÜ ---            ‚îÇ\n‚îÇ i64         ‚îÜ str      ‚îÜ str       ‚îÜ str             ‚îÜ str     ‚îÜ str            ‚îÜ str            ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 4999        ‚îÜ 5/11/06  ‚îÜ Double    ‚îÜ QUOTATIONS      ‚îÜ $2,000  ‚îÜ From Ft. Sill, ‚îÜ Geronimo       ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ Jeopardy! ‚îÜ                 ‚îÜ         ‚îÜ Okla. he made  ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ t‚Ä¶             ‚îÜ                ‚îÇ\n‚îÇ 4999        ‚îÜ 5/11/06  ‚îÜ Final     ‚îÜ HISTORIC NAMES  ‚îÜ None    ‚îÜ A silent movie ‚îÜ Grigori        ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ Jeopardy! ‚îÜ                 ‚îÜ         ‚îÜ title includes ‚îÜ Alexandrovich  ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ ‚Ä¶              ‚îÜ Potemkin       ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\nPrint random rows (this is very useful as the head and tail of your data frame may not be representative of your data):\n\nimport random\n\nprint(df.sample(4))\n\nshape: (4, 7)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Show Number ‚îÜ Air Date ‚îÜ Round     ‚îÜ Category        ‚îÜ Value   ‚îÜ Question       ‚îÜ Answer         ‚îÇ\n‚îÇ ---         ‚îÜ ---      ‚îÜ ---       ‚îÜ ---             ‚îÜ ---     ‚îÜ ---            ‚îÜ ---            ‚îÇ\n‚îÇ i64         ‚îÜ str      ‚îÜ str       ‚îÜ str             ‚îÜ str     ‚îÜ str            ‚îÜ str            ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 5861        ‚îÜ 2/22/10  ‚îÜ Double    ‚îÜ \"G\" IN THE GOOD ‚îÜ $1,200  ‚îÜ \"Balm\"-y       ‚îÜ Gilead         ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ Jeopardy! ‚îÜ BOOK            ‚îÜ         ‚îÜ region in      ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ present-day‚Ä¶   ‚îÜ                ‚îÇ\n‚îÇ 6061        ‚îÜ 1/10/11  ‚îÜ Jeopardy! ‚îÜ THE \"CAR\" POOL  ‚îÜ $1,000  ‚îÜ 14-letter      ‚îÜ cardiovascular ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ adjective      ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ meaning pe‚Ä¶    ‚îÜ                ‚îÇ\n‚îÇ 3865        ‚îÜ 5/25/01  ‚îÜ Jeopardy! ‚îÜ SCIENCE &       ‚îÜ $300    ‚îÜ Of the 6       ‚îÜ a screw        ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ NATURE          ‚îÜ         ‚îÜ simple         ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ machines in    ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ ph‚Ä¶            ‚îÜ                ‚îÇ\n‚îÇ 5404        ‚îÜ 2/21/08  ‚îÜ Jeopardy! ‚îÜ THEM LITERATURE ‚îÜ $200    ‚îÜ In 1928 A.A.   ‚îÜ Pooh           ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ TYPE FACTS      ‚îÜ         ‚îÜ Milne          ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ published \"‚Ä¶   ‚îÜ                ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Data frame inspection"
    ]
  },
  {
    "objectID": "python/polars_inspection.html#structure",
    "href": "python/polars_inspection.html#structure",
    "title": "Data frame inspection",
    "section": "Structure",
    "text": "Structure\nOverview of the data frame and its structure:\n\nprint(df.glimpse())\n\nRows: 216930\nColumns: 7\n$ Show Number &lt;i64&gt; 4680, 4680, 4680, 4680, 4680, 4680, 4680, 4680, 4680, 4680\n$ Air Date    &lt;str&gt; '12/31/04', '12/31/04', '12/31/04', '12/31/04', '12/31/04', '12/31/04', '12/31/04', '12/31/04', '12/31/04', '12/31/04'\n$ Round       &lt;str&gt; 'Jeopardy!', 'Jeopardy!', 'Jeopardy!', 'Jeopardy!', 'Jeopardy!', 'Jeopardy!', 'Jeopardy!', 'Jeopardy!', 'Jeopardy!', 'Jeopardy!'\n$ Category    &lt;str&gt; 'HISTORY', \"ESPN's TOP 10 ALL-TIME ATHLETES\", 'EVERYBODY TALKS ABOUT IT...', 'THE COMPANY LINE', 'EPITAPHS & TRIBUTES', '3-LETTER WORDS', 'HISTORY', \"ESPN's TOP 10 ALL-TIME ATHLETES\", 'EVERYBODY TALKS ABOUT IT...', 'THE COMPANY LINE'\n$ Value       &lt;str&gt; '$200 ', '$200 ', '$200 ', '$200 ', '$200 ', '$200 ', '$400 ', '$400 ', '$400 ', '$400 '\n$ Question    &lt;str&gt; \"For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory\", 'No. 2: 1912 Olympian; football star at Carlisle Indian School; 6 MLB seasons with the Reds, Giants & Braves', 'The city of Yuma in this state has a record average of 4,055 hours of sunshine each year', 'In 1963, live on \"The Art Linkletter Show\", this company served its billionth burger', 'Signer of the Dec. of Indep., framer of the Constitution of Mass., second President of the United States', 'In the title of an Aesop fable, this insect shared billing with a grasshopper', \"Built in 312 B.C. to link Rome & the South of Italy, it's still in use today\", 'No. 8: 30 steals for the Birmingham Barons; 2,306 steals for the Bulls', 'In the winter of 1971-72, a record 1,122 inches of snow fell at Rainier Paradise Ranger Station in this state', 'This housewares store was named for the packaging its merchandise came in & was first displayed on'\n$ Answer      &lt;str&gt; 'Copernicus', 'Jim Thorpe', 'Arizona', \"McDonald's\", 'John Adams', 'the ant', 'the Appian Way', 'Michael Jordan', 'Washington', 'Crate & Barrel'\n\nNone\n\n\n\nThis is similar to the str() function in R.\n\nTo print a list of the data types of each variable, you can use:\n\nprint(df.dtypes)\n\n[Int64, String, String, String, String, String, String]\n\n\nBut the printing of a Polars data frame already gives you this information (along with the shape).\nThe schema of a Polars data frame sets the names of the variables (columns) and their data types:\n\nprint(df.schema)\n\nSchema({'Show Number': Int64, 'Air Date': String, 'Round': String, 'Category': String, 'Value': String, 'Question': String, 'Answer': String})",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Data frame inspection"
    ]
  },
  {
    "objectID": "python/polars_inspection.html#summary-statistics",
    "href": "python/polars_inspection.html#summary-statistics",
    "title": "Data frame inspection",
    "section": "Summary statistics",
    "text": "Summary statistics\nThis is not always meaningful depending on your data:\n\nprint(df.describe())\n\nshape: (9, 8)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ statistic  ‚îÜ Show       ‚îÜ Air Date ‚îÜ Round      ‚îÜ Category   ‚îÜ Value   ‚îÜ Question   ‚îÜ Answer     ‚îÇ\n‚îÇ ---        ‚îÜ Number     ‚îÜ ---      ‚îÜ ---        ‚îÜ ---        ‚îÜ ---     ‚îÜ ---        ‚îÜ ---        ‚îÇ\n‚îÇ str        ‚îÜ ---        ‚îÜ str      ‚îÜ str        ‚îÜ str        ‚îÜ str     ‚îÜ str        ‚îÜ str        ‚îÇ\n‚îÇ            ‚îÜ f64        ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ         ‚îÜ            ‚îÜ            ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ count      ‚îÜ 216930.0   ‚îÜ 216930   ‚îÜ 216930     ‚îÜ 216778     ‚îÜ 216930  ‚îÜ 216928     ‚îÜ 216898     ‚îÇ\n‚îÇ null_count ‚îÜ 0.0        ‚îÜ 0        ‚îÜ 0          ‚îÜ 152        ‚îÜ 0       ‚îÜ 2          ‚îÜ 32         ‚îÇ\n‚îÇ mean       ‚îÜ 4264.23851 ‚îÜ null     ‚îÜ null       ‚îÜ null       ‚îÜ null    ‚îÜ null       ‚îÜ null       ‚îÇ\n‚îÇ            ‚îÜ 9          ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ         ‚îÜ            ‚îÜ            ‚îÇ\n‚îÇ std        ‚îÜ 1386.29633 ‚îÜ null     ‚îÜ null       ‚îÜ null       ‚îÜ null    ‚îÜ null       ‚îÜ null       ‚îÇ\n‚îÇ            ‚îÜ 5          ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ         ‚îÜ            ‚îÜ            ‚îÇ\n‚îÇ min        ‚îÜ 1.0        ‚îÜ 1/1/01   ‚îÜ Double     ‚îÜ A JIM      ‚îÜ $1,000  ‚îÜ \" 'Cause   ‚îÜ  Hamlet    ‚îÇ\n‚îÇ            ‚îÜ            ‚îÜ          ‚îÜ Jeopardy!  ‚îÜ CARREY     ‚îÜ         ‚îÜ I'm never  ‚îÜ            ‚îÇ\n‚îÇ            ‚îÜ            ‚îÜ          ‚îÜ            ‚îÜ FILM       ‚îÜ         ‚îÜ gonna stop ‚îÜ            ‚îÇ\n‚îÇ            ‚îÜ            ‚îÜ          ‚îÜ            ‚îÜ FESTIVAL   ‚îÜ         ‚îÜ ‚Ä¶          ‚îÜ            ‚îÇ\n‚îÇ 25%        ‚îÜ 3349.0     ‚îÜ null     ‚îÜ null       ‚îÜ null       ‚îÜ null    ‚îÜ null       ‚îÜ null       ‚îÇ\n‚îÇ 50%        ‚îÜ 4490.0     ‚îÜ null     ‚îÜ null       ‚îÜ null       ‚îÜ null    ‚îÜ null       ‚îÜ null       ‚îÇ\n‚îÇ 75%        ‚îÜ 5393.0     ‚îÜ null     ‚îÜ null       ‚îÜ null       ‚îÜ null    ‚îÜ null       ‚îÜ null       ‚îÇ\n‚îÇ max        ‚îÜ 6300.0     ‚îÜ 9/9/99   ‚îÜ Tiebreaker ‚îÜ √¢‚Ç¨‚Ñ¢70s     ‚îÜ None    ‚îÜ √¢‚Ç¨≈ìYou     ‚îÜ √¢‚Ç¨≈ìone     ‚îÇ\n‚îÇ            ‚îÜ            ‚îÜ          ‚îÜ            ‚îÜ CINEMA     ‚îÜ         ‚îÜ Can't Lose ‚îÜ giant leap ‚îÇ\n‚îÇ            ‚îÜ            ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ         ‚îÜ Me√¢‚Ç¨       ‚îÜ for        ‚îÇ\n‚îÇ            ‚îÜ            ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ         ‚îÜ            ‚îÜ mankind√¢‚Ä¶  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Data frame inspection"
    ]
  },
  {
    "objectID": "python/polars_lazy.html",
    "href": "python/polars_lazy.html",
    "title": "Lazy evaluation",
    "section": "",
    "text": "When it comes to high-performance computing, one of the strengths of Polars is that it supports lazy evaluation. Lazy evaluation instantly returns a future that can be used down the code without waiting for the result of the computation to get calculated. It also allows the query optimizer to combine operations, very much the way compiled languages work.\nIf you want to speedup your code, use lazy execution whenever possible.\n\nTry to use the lazy API from the start, when reading a file.\nIn previous examples, we used read_csv to read our data. This returns a Polars DataFrame. Instead, you can use scan_csv to create a LazyFrame:\n\nimport polars as pl\n\nurl = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\"\n\ndf = pl.read_csv(url)\ndf_lazy = pl.scan_csv(url)\n\nprint(type(df))\nprint(type(df_lazy))\n\n&lt;class 'polars.dataframe.frame.DataFrame'&gt;\n&lt;class 'polars.lazyframe.frame.LazyFrame'&gt;\n\n\n\nThere are scan functions for all the numerous IO methods Polars offers.\n\nIf you already have a DataFrame, you can create a LazyFrame from it with the lazy method:\n\ndf_lazy = df.lazy()\n\nWhen you run queries on a LazyFrame, instead of evaluating them, Polars creates a graph and runs many optimizations on it.\nTo evaluate the code and get the result, you use the collect method.\nWe will see this in action in the next section.",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Lazy evaluation"
    ]
  },
  {
    "objectID": "python/polars_resources.html",
    "href": "python/polars_resources.html",
    "title": "Resources",
    "section": "",
    "text": "Here is a list of resources for Polars.\n\n\nPolars website\n\nOfficial documentation\nPolars API\nGitHub repo\n\n\n\nBook\nKevin Heavey wrote Modern Polars following the model of the Modern Pandas book. This is a great resource, although getting a little outdated for the scaling chapter since Polars is evolving so fast.\n\n\nIntegration with other tools\n\nNumPy:\nSee the documentation, the from_numpy and to_numpy functions, the development progress of this integration, and performance advice.\nParallel computing:\nWith Ray thanks to this setting; with Spark, Dask, and Ray thanks to fugue.\nGPUs:\nWith the cuDF library from RAPIDS (in development).\nSQL:\nWith DuckDB.\nPlotting:\nA great section of the documentation shows how Polars integrates with many Python plotting frameworks.\nPublishing:\nThe documentation shows how to publish beautiful tables from Polars data frames with Great Tables.",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Resources"
    ]
  },
  {
    "objectID": "python/polars_subset.html",
    "href": "python/polars_subset.html",
    "title": "Subsetting data",
    "section": "",
    "text": "The syntax to subset data is very different in Polars compared to the indexing of pandas and other languages. Action verbs are used in a style very similar to that of R‚Äôs dplyr from the tidyverse.\nLet‚Äôs start with the same data frame we used in the previous section:\nimport polars as pl\n\ndf = pl.read_csv(\"https://raw.githubusercontent.com/razoumov/publish/master/jeopardy.csv\")\n\nprint(df)\n\nshape: (216_930, 7)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Show Number ‚îÜ Air Date ‚îÜ Round     ‚îÜ Category        ‚îÜ Value   ‚îÜ Question       ‚îÜ Answer         ‚îÇ\n‚îÇ ---         ‚îÜ ---      ‚îÜ ---       ‚îÜ ---             ‚îÜ ---     ‚îÜ ---            ‚îÜ ---            ‚îÇ\n‚îÇ i64         ‚îÜ str      ‚îÜ str       ‚îÜ str             ‚îÜ str     ‚îÜ str            ‚îÜ str            ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 4680        ‚îÜ 12/31/04 ‚îÜ Jeopardy! ‚îÜ HISTORY         ‚îÜ $200    ‚îÜ For the last 8 ‚îÜ Copernicus     ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ years of his   ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ li‚Ä¶            ‚îÜ                ‚îÇ\n‚îÇ 4680        ‚îÜ 12/31/04 ‚îÜ Jeopardy! ‚îÜ ESPN's TOP 10   ‚îÜ $200    ‚îÜ No. 2: 1912    ‚îÜ Jim Thorpe     ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ ALL-TIME        ‚îÜ         ‚îÜ Olympian;      ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ ATHLETE‚Ä¶        ‚îÜ         ‚îÜ football‚Ä¶      ‚îÜ                ‚îÇ\n‚îÇ 4680        ‚îÜ 12/31/04 ‚îÜ Jeopardy! ‚îÜ EVERYBODY TALKS ‚îÜ $200    ‚îÜ The city of    ‚îÜ Arizona        ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ ABOUT IT...     ‚îÜ         ‚îÜ Yuma in this   ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ state‚Ä¶         ‚îÜ                ‚îÇ\n‚îÇ 4680        ‚îÜ 12/31/04 ‚îÜ Jeopardy! ‚îÜ THE COMPANY     ‚îÜ $200    ‚îÜ In 1963, live  ‚îÜ McDonald's     ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ LINE            ‚îÜ         ‚îÜ on \"The Art    ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ Link‚Ä¶          ‚îÜ                ‚îÇ\n‚îÇ 4680        ‚îÜ 12/31/04 ‚îÜ Jeopardy! ‚îÜ EPITAPHS &      ‚îÜ $200    ‚îÜ Signer of the  ‚îÜ John Adams     ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ TRIBUTES        ‚îÜ         ‚îÜ Dec. of        ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ Indep., ‚Ä¶      ‚îÜ                ‚îÇ\n‚îÇ ‚Ä¶           ‚îÜ ‚Ä¶        ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶               ‚îÜ ‚Ä¶       ‚îÜ ‚Ä¶              ‚îÜ ‚Ä¶              ‚îÇ\n‚îÇ 4999        ‚îÜ 5/11/06  ‚îÜ Double    ‚îÜ RIDDLE ME THIS  ‚îÜ $2,000  ‚îÜ This Puccini   ‚îÜ Turandot       ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ Jeopardy! ‚îÜ                 ‚îÜ         ‚îÜ opera turns on ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ th‚Ä¶            ‚îÜ                ‚îÇ\n‚îÇ 4999        ‚îÜ 5/11/06  ‚îÜ Double    ‚îÜ \"T\" BIRDS       ‚îÜ $2,000  ‚îÜ In North       ‚îÜ a titmouse     ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ Jeopardy! ‚îÜ                 ‚îÜ         ‚îÜ America this   ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ term is ‚Ä¶      ‚îÜ                ‚îÇ\n‚îÇ 4999        ‚îÜ 5/11/06  ‚îÜ Double    ‚îÜ AUTHORS IN      ‚îÜ $2,000  ‚îÜ In Penny Lane, ‚îÜ Clive Barker   ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ Jeopardy! ‚îÜ THEIR YOUTH     ‚îÜ         ‚îÜ where this     ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ \"Hel‚Ä¶          ‚îÜ                ‚îÇ\n‚îÇ 4999        ‚îÜ 5/11/06  ‚îÜ Double    ‚îÜ QUOTATIONS      ‚îÜ $2,000  ‚îÜ From Ft. Sill, ‚îÜ Geronimo       ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ Jeopardy! ‚îÜ                 ‚îÜ         ‚îÜ Okla. he made  ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ t‚Ä¶             ‚îÜ                ‚îÇ\n‚îÇ 4999        ‚îÜ 5/11/06  ‚îÜ Final     ‚îÜ HISTORIC NAMES  ‚îÜ None    ‚îÜ A silent movie ‚îÜ Grigori        ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ Jeopardy! ‚îÜ                 ‚îÜ         ‚îÜ title includes ‚îÜ Alexandrovich  ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ ‚Ä¶              ‚îÜ Potemkin       ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Subsetting data"
    ]
  },
  {
    "objectID": "python/polars_subset.html#selecting-rows",
    "href": "python/polars_subset.html#selecting-rows",
    "title": "Subsetting data",
    "section": "Selecting rows",
    "text": "Selecting rows\nYou can select rows based on any expression that evaluates to a Boolean with filter:\n\ndf_sub = df.filter(\n    pl.col(\"Air Date\") == \"5/8/09\"\n    )\n\nprint(df_sub)\n\nshape: (61, 7)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Show Number ‚îÜ Air Date ‚îÜ Round     ‚îÜ Category        ‚îÜ Value   ‚îÜ Question       ‚îÜ Answer         ‚îÇ\n‚îÇ ---         ‚îÜ ---      ‚îÜ ---       ‚îÜ ---             ‚îÜ ---     ‚îÜ ---            ‚îÜ ---            ‚îÇ\n‚îÇ i64         ‚îÜ str      ‚îÜ str       ‚îÜ str             ‚îÜ str     ‚îÜ str            ‚îÜ str            ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Jeopardy! ‚îÜ OLD FOLKS IN    ‚îÜ $200    ‚îÜ goop.com is a  ‚îÜ Gwyneth        ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ THEIR 30s       ‚îÜ         ‚îÜ lifestyles     ‚îÜ Paltrow        ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ websi‚Ä¶         ‚îÜ                ‚îÇ\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Jeopardy! ‚îÜ MOVIES & TV     ‚îÜ $200    ‚îÜ On March 19,   ‚îÜ Jay Leno       ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ 2009 he said,  ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ \"I'‚Ä¶           ‚îÜ                ‚îÇ\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Jeopardy! ‚îÜ A STATE OF      ‚îÜ $200    ‚îÜ Baylor,        ‚îÜ Texas          ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ COLLEGE-NESS    ‚îÜ         ‚îÜ Stephen F.     ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ Austin, Ric‚Ä¶   ‚îÜ                ‚îÇ\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Jeopardy! ‚îÜ ANIMAL          ‚îÜ $200    ‚îÜ Synonym for    ‚îÜ a pride        ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ COLLECTIVE      ‚îÜ         ‚îÜ dignity that's ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ the‚Ä¶           ‚îÜ                ‚îÇ\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Jeopardy! ‚îÜ I'D RATHER BE   ‚îÜ $200    ‚îÜ If you're a    ‚îÜ a bunny hill   ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ SKIING          ‚îÜ         ‚îÜ beginner, you  ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ migh‚Ä¶          ‚îÜ                ‚îÇ\n‚îÇ ‚Ä¶           ‚îÜ ‚Ä¶        ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶               ‚îÜ ‚Ä¶       ‚îÜ ‚Ä¶              ‚îÜ ‚Ä¶              ‚îÇ\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Double    ‚îÜ ANATOMY         ‚îÜ $2,000  ‚îÜ The pons       ‚îÜ the cerebellum ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ Jeopardy! ‚îÜ                 ‚îÜ         ‚îÜ connects the 2 ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ hemisp‚Ä¶        ‚îÜ                ‚îÇ\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Double    ‚îÜ MATHEM-ATTACK!  ‚îÜ $2,000  ‚îÜ (&lt;a href=\"http ‚îÜ volume         ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ Jeopardy! ‚îÜ                 ‚îÜ         ‚îÜ ://www.j-archi ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ ve‚Ä¶            ‚îÜ                ‚îÇ\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Double    ‚îÜ NAME THE DECADE ‚îÜ $2,000  ‚îÜ Man first      ‚îÜ the 1910s      ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ Jeopardy! ‚îÜ                 ‚îÜ         ‚îÜ reaches the    ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ South Po‚Ä¶      ‚îÜ                ‚îÇ\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Double    ‚îÜ WORD ORIGINS    ‚îÜ $2,000  ‚îÜ A type of ear  ‚îÜ cochlear       ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ Jeopardy! ‚îÜ                 ‚îÜ         ‚îÜ implant to     ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ help ‚Ä¶         ‚îÜ                ‚îÇ\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Final     ‚îÜ EUROPEAN        ‚îÜ None    ‚îÜ He filed for   ‚îÜ Henry VIII     ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ Jeopardy! ‚îÜ HISTORY         ‚îÜ         ‚îÜ divorce citing ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ Le‚Ä¶            ‚îÜ                ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\nYou can combine conditions:\n\ndf_sub = df.filter(\n    pl.col(\"Air Date\") == \"5/8/09\",\n    pl.col(\"Round\") != \"Double Jeopardy!\"\n    )\n\nprint(df_sub)\n\nshape: (31, 7)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Show Number ‚îÜ Air Date ‚îÜ Round     ‚îÜ Category        ‚îÜ Value   ‚îÜ Question       ‚îÜ Answer         ‚îÇ\n‚îÇ ---         ‚îÜ ---      ‚îÜ ---       ‚îÜ ---             ‚îÜ ---     ‚îÜ ---            ‚îÜ ---            ‚îÇ\n‚îÇ i64         ‚îÜ str      ‚îÜ str       ‚îÜ str             ‚îÜ str     ‚îÜ str            ‚îÜ str            ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Jeopardy! ‚îÜ OLD FOLKS IN    ‚îÜ $200    ‚îÜ goop.com is a  ‚îÜ Gwyneth        ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ THEIR 30s       ‚îÜ         ‚îÜ lifestyles     ‚îÜ Paltrow        ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ websi‚Ä¶         ‚îÜ                ‚îÇ\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Jeopardy! ‚îÜ MOVIES & TV     ‚îÜ $200    ‚îÜ On March 19,   ‚îÜ Jay Leno       ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ 2009 he said,  ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ \"I'‚Ä¶           ‚îÜ                ‚îÇ\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Jeopardy! ‚îÜ A STATE OF      ‚îÜ $200    ‚îÜ Baylor,        ‚îÜ Texas          ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ COLLEGE-NESS    ‚îÜ         ‚îÜ Stephen F.     ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ Austin, Ric‚Ä¶   ‚îÜ                ‚îÇ\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Jeopardy! ‚îÜ ANIMAL          ‚îÜ $200    ‚îÜ Synonym for    ‚îÜ a pride        ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ COLLECTIVE      ‚îÜ         ‚îÜ dignity that's ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ the‚Ä¶           ‚îÜ                ‚îÇ\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Jeopardy! ‚îÜ I'D RATHER BE   ‚îÜ $200    ‚îÜ If you're a    ‚îÜ a bunny hill   ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ SKIING          ‚îÜ         ‚îÜ beginner, you  ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ migh‚Ä¶          ‚îÜ                ‚îÇ\n‚îÇ ‚Ä¶           ‚îÜ ‚Ä¶        ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶               ‚îÜ ‚Ä¶       ‚îÜ ‚Ä¶              ‚îÜ ‚Ä¶              ‚îÇ\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Jeopardy! ‚îÜ A STATE OF      ‚îÜ $1,000  ‚îÜ Grambling,     ‚îÜ Louisiana      ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ COLLEGE-NESS    ‚îÜ         ‚îÜ McNeese State, ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ Sout‚Ä¶          ‚îÜ                ‚îÇ\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Jeopardy! ‚îÜ ANIMAL          ‚îÜ $1,000  ‚îÜ A flock of     ‚îÜ crows          ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ COLLECTIVE      ‚îÜ         ‚îÜ these black    ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ birds i‚Ä¶       ‚îÜ                ‚îÇ\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Jeopardy! ‚îÜ I'D RATHER BE   ‚îÜ $1,000  ‚îÜ Bumps or       ‚îÜ moguls         ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ SKIING          ‚îÜ         ‚îÜ mounds of snow ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ that a‚Ä¶        ‚îÜ                ‚îÇ\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Jeopardy! ‚îÜ PARLEZ VOUS?    ‚îÜ $1,000  ‚îÜ \"Huitieme\" is  ‚îÜ eighth         ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ French for     ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ this ‚Ä¶         ‚îÜ                ‚îÇ\n‚îÇ 5690        ‚îÜ 5/8/09   ‚îÜ Final     ‚îÜ EUROPEAN        ‚îÜ None    ‚îÜ He filed for   ‚îÜ Henry VIII     ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ Jeopardy! ‚îÜ HISTORY         ‚îÜ         ‚îÜ divorce citing ‚îÜ                ‚îÇ\n‚îÇ             ‚îÜ          ‚îÜ           ‚îÜ                 ‚îÜ         ‚îÜ Le‚Ä¶            ‚îÜ                ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Subsetting data"
    ]
  },
  {
    "objectID": "python/polars_subset.html#selecting-columns",
    "href": "python/polars_subset.html#selecting-columns",
    "title": "Subsetting data",
    "section": "Selecting columns",
    "text": "Selecting columns\nTo select columns (variables), you use select:\n\ndf_sub = df.select(\n    pl.col(\"Show Number\"),\n    pl.col(\"Category\")\n    )\n\nprint(df_sub)\n\nshape: (216_930, 2)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Show Number ‚îÜ Category                        ‚îÇ\n‚îÇ ---         ‚îÜ ---                             ‚îÇ\n‚îÇ i64         ‚îÜ str                             ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 4680        ‚îÜ HISTORY                         ‚îÇ\n‚îÇ 4680        ‚îÜ ESPN's TOP 10 ALL-TIME ATHLETE‚Ä¶ ‚îÇ\n‚îÇ 4680        ‚îÜ EVERYBODY TALKS ABOUT IT...     ‚îÇ\n‚îÇ 4680        ‚îÜ THE COMPANY LINE                ‚îÇ\n‚îÇ 4680        ‚îÜ EPITAPHS & TRIBUTES             ‚îÇ\n‚îÇ ‚Ä¶           ‚îÜ ‚Ä¶                               ‚îÇ\n‚îÇ 4999        ‚îÜ RIDDLE ME THIS                  ‚îÇ\n‚îÇ 4999        ‚îÜ \"T\" BIRDS                       ‚îÇ\n‚îÇ 4999        ‚îÜ AUTHORS IN THEIR YOUTH          ‚îÇ\n‚îÇ 4999        ‚îÜ QUOTATIONS                      ‚îÇ\n‚îÇ 4999        ‚îÜ HISTORIC NAMES                  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Subsetting data"
    ]
  },
  {
    "objectID": "python/polars_subset.html#creating-new-columns-with-output-of-expressions",
    "href": "python/polars_subset.html#creating-new-columns-with-output-of-expressions",
    "title": "Subsetting data",
    "section": "Creating new columns with output of expressions",
    "text": "Creating new columns with output of expressions\nThe jeopardy dataset is made mostly of String variables. Let‚Äôs use another one here: the now archived global confirmed Covid-19 cases from John Hopkins University:\n\nurl = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\"\n\ndf = pl.read_csv(url)\n\nprint(df)\n\nshape: (289, 1_147)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Province/State ‚îÜ Country/Region ‚îÜ Lat        ‚îÜ Long      ‚îÜ ‚Ä¶ ‚îÜ 3/6/23 ‚îÜ 3/7/23 ‚îÜ 3/8/23 ‚îÜ 3/9/23 ‚îÇ\n‚îÇ ---            ‚îÜ ---            ‚îÜ ---        ‚îÜ ---       ‚îÜ   ‚îÜ ---    ‚îÜ ---    ‚îÜ ---    ‚îÜ ---    ‚îÇ\n‚îÇ str            ‚îÜ str            ‚îÜ f64        ‚îÜ f64       ‚îÜ   ‚îÜ i64    ‚îÜ i64    ‚îÜ i64    ‚îÜ i64    ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ null           ‚îÜ Afghanistan    ‚îÜ 33.93911   ‚îÜ 67.709953 ‚îÜ ‚Ä¶ ‚îÜ 209406 ‚îÜ 209436 ‚îÜ 209451 ‚îÜ 209451 ‚îÇ\n‚îÇ null           ‚îÜ Albania        ‚îÜ 41.1533    ‚îÜ 20.1683   ‚îÜ ‚Ä¶ ‚îÜ 334427 ‚îÜ 334427 ‚îÜ 334443 ‚îÜ 334457 ‚îÇ\n‚îÇ null           ‚îÜ Algeria        ‚îÜ 28.0339    ‚îÜ 1.6596    ‚îÜ ‚Ä¶ ‚îÜ 271477 ‚îÜ 271490 ‚îÜ 271494 ‚îÜ 271496 ‚îÇ\n‚îÇ null           ‚îÜ Andorra        ‚îÜ 42.5063    ‚îÜ 1.5218    ‚îÜ ‚Ä¶ ‚îÜ 47875  ‚îÜ 47875  ‚îÜ 47890  ‚îÜ 47890  ‚îÇ\n‚îÇ null           ‚îÜ Angola         ‚îÜ -11.2027   ‚îÜ 17.8739   ‚îÜ ‚Ä¶ ‚îÜ 105277 ‚îÜ 105277 ‚îÜ 105288 ‚îÜ 105288 ‚îÇ\n‚îÇ ‚Ä¶              ‚îÜ ‚Ä¶              ‚îÜ ‚Ä¶          ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶ ‚îÜ ‚Ä¶      ‚îÜ ‚Ä¶      ‚îÜ ‚Ä¶      ‚îÜ ‚Ä¶      ‚îÇ\n‚îÇ null           ‚îÜ West Bank and  ‚îÜ 31.9522    ‚îÜ 35.2332   ‚îÜ ‚Ä¶ ‚îÜ 703228 ‚îÜ 703228 ‚îÜ 703228 ‚îÜ 703228 ‚îÇ\n‚îÇ                ‚îÜ Gaza           ‚îÜ            ‚îÜ           ‚îÜ   ‚îÜ        ‚îÜ        ‚îÜ        ‚îÜ        ‚îÇ\n‚îÇ null           ‚îÜ Winter         ‚îÜ 39.9042    ‚îÜ 116.4074  ‚îÜ ‚Ä¶ ‚îÜ 535    ‚îÜ 535    ‚îÜ 535    ‚îÜ 535    ‚îÇ\n‚îÇ                ‚îÜ Olympics 2022  ‚îÜ            ‚îÜ           ‚îÜ   ‚îÜ        ‚îÜ        ‚îÜ        ‚îÜ        ‚îÇ\n‚îÇ null           ‚îÜ Yemen          ‚îÜ 15.552727  ‚îÜ 48.516388 ‚îÜ ‚Ä¶ ‚îÜ 11945  ‚îÜ 11945  ‚îÜ 11945  ‚îÜ 11945  ‚îÇ\n‚îÇ null           ‚îÜ Zambia         ‚îÜ -13.133897 ‚îÜ 27.849332 ‚îÜ ‚Ä¶ ‚îÜ 343135 ‚îÜ 343135 ‚îÜ 343135 ‚îÜ 343135 ‚îÇ\n‚îÇ null           ‚îÜ Zimbabwe       ‚îÜ -19.015438 ‚îÜ 29.154857 ‚îÜ ‚Ä¶ ‚îÜ 264127 ‚îÜ 264127 ‚îÜ 264276 ‚îÜ 264276 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\nTo create a new variable called daily_avg with the daily average of new cases, we use select again, but this time we add an expression:\n\ndf_new = df.select(\n    daily_avg=pl.col(\"3/9/23\") / 1143\n    )\n\nprint(df_new)\n\nshape: (289, 1)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ daily_avg  ‚îÇ\n‚îÇ ---        ‚îÇ\n‚îÇ f64        ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ 183.246719 ‚îÇ\n‚îÇ 292.613298 ‚îÇ\n‚îÇ 237.529309 ‚îÇ\n‚îÇ 41.898513  ‚îÇ\n‚îÇ 92.115486  ‚îÇ\n‚îÇ ‚Ä¶          ‚îÇ\n‚îÇ 615.247594 ‚îÇ\n‚îÇ 0.468066   ‚îÇ\n‚îÇ 10.450569  ‚îÇ\n‚îÇ 300.205599 ‚îÇ\n‚îÇ 231.212598 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\nSince the data is cumulative across dates, we took the last columns (totals cases for each row) and divided by the number of days of this dataset (total number of columns menus the four first columns).\n\nIf you want to keep all columns in the output, you use with_columns:\n\ndf_new = df.with_columns(\n    daily_avg=pl.col(\"3/9/23\") / 1143\n    )\n\nprint(df_new)\n\nshape: (289, 1_148)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Province/Sta ‚îÜ Country/Regi ‚îÜ Lat        ‚îÜ Long      ‚îÜ ‚Ä¶ ‚îÜ 3/7/23 ‚îÜ 3/8/23 ‚îÜ 3/9/23 ‚îÜ daily_avg  ‚îÇ\n‚îÇ te           ‚îÜ on           ‚îÜ ---        ‚îÜ ---       ‚îÜ   ‚îÜ ---    ‚îÜ ---    ‚îÜ ---    ‚îÜ ---        ‚îÇ\n‚îÇ ---          ‚îÜ ---          ‚îÜ f64        ‚îÜ f64       ‚îÜ   ‚îÜ i64    ‚îÜ i64    ‚îÜ i64    ‚îÜ f64        ‚îÇ\n‚îÇ str          ‚îÜ str          ‚îÜ            ‚îÜ           ‚îÜ   ‚îÜ        ‚îÜ        ‚îÜ        ‚îÜ            ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ null         ‚îÜ Afghanistan  ‚îÜ 33.93911   ‚îÜ 67.709953 ‚îÜ ‚Ä¶ ‚îÜ 209436 ‚îÜ 209451 ‚îÜ 209451 ‚îÜ 183.246719 ‚îÇ\n‚îÇ null         ‚îÜ Albania      ‚îÜ 41.1533    ‚îÜ 20.1683   ‚îÜ ‚Ä¶ ‚îÜ 334427 ‚îÜ 334443 ‚îÜ 334457 ‚îÜ 292.613298 ‚îÇ\n‚îÇ null         ‚îÜ Algeria      ‚îÜ 28.0339    ‚îÜ 1.6596    ‚îÜ ‚Ä¶ ‚îÜ 271490 ‚îÜ 271494 ‚îÜ 271496 ‚îÜ 237.529309 ‚îÇ\n‚îÇ null         ‚îÜ Andorra      ‚îÜ 42.5063    ‚îÜ 1.5218    ‚îÜ ‚Ä¶ ‚îÜ 47875  ‚îÜ 47890  ‚îÜ 47890  ‚îÜ 41.898513  ‚îÇ\n‚îÇ null         ‚îÜ Angola       ‚îÜ -11.2027   ‚îÜ 17.8739   ‚îÜ ‚Ä¶ ‚îÜ 105277 ‚îÜ 105288 ‚îÜ 105288 ‚îÜ 92.115486  ‚îÇ\n‚îÇ ‚Ä¶            ‚îÜ ‚Ä¶            ‚îÜ ‚Ä¶          ‚îÜ ‚Ä¶         ‚îÜ ‚Ä¶ ‚îÜ ‚Ä¶      ‚îÜ ‚Ä¶      ‚îÜ ‚Ä¶      ‚îÜ ‚Ä¶          ‚îÇ\n‚îÇ null         ‚îÜ West Bank    ‚îÜ 31.9522    ‚îÜ 35.2332   ‚îÜ ‚Ä¶ ‚îÜ 703228 ‚îÜ 703228 ‚îÜ 703228 ‚îÜ 615.247594 ‚îÇ\n‚îÇ              ‚îÜ and Gaza     ‚îÜ            ‚îÜ           ‚îÜ   ‚îÜ        ‚îÜ        ‚îÜ        ‚îÜ            ‚îÇ\n‚îÇ null         ‚îÜ Winter       ‚îÜ 39.9042    ‚îÜ 116.4074  ‚îÜ ‚Ä¶ ‚îÜ 535    ‚îÜ 535    ‚îÜ 535    ‚îÜ 0.468066   ‚îÇ\n‚îÇ              ‚îÜ Olympics     ‚îÜ            ‚îÜ           ‚îÜ   ‚îÜ        ‚îÜ        ‚îÜ        ‚îÜ            ‚îÇ\n‚îÇ              ‚îÜ 2022         ‚îÜ            ‚îÜ           ‚îÜ   ‚îÜ        ‚îÜ        ‚îÜ        ‚îÜ            ‚îÇ\n‚îÇ null         ‚îÜ Yemen        ‚îÜ 15.552727  ‚îÜ 48.516388 ‚îÜ ‚Ä¶ ‚îÜ 11945  ‚îÜ 11945  ‚îÜ 11945  ‚îÜ 10.450569  ‚îÇ\n‚îÇ null         ‚îÜ Zambia       ‚îÜ -13.133897 ‚îÜ 27.849332 ‚îÜ ‚Ä¶ ‚îÜ 343135 ‚îÜ 343135 ‚îÜ 343135 ‚îÜ 300.205599 ‚îÇ\n‚îÇ null         ‚îÜ Zimbabwe     ‚îÜ -19.015438 ‚îÜ 29.154857 ‚îÜ ‚Ä¶ ‚îÜ 264127 ‚îÜ 264276 ‚îÜ 264276 ‚îÜ 231.212598 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\nNotice that our new variable got added as the last column of the data frame.\n\nIf we want to write in place, we can reassign the output to the initial data frame:\n\ndf = df.with_columns(\n    daily_avg=pl.col(\"3/9/23\") / 1143\n    )",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Subsetting data"
    ]
  },
  {
    "objectID": "python/polars_subset.html#group-by-operations",
    "href": "python/polars_subset.html#group-by-operations",
    "title": "Subsetting data",
    "section": "Group by operations",
    "text": "Group by operations\nIn this Covid-19 dataset some countries (e.g.¬†Australia) are split between several provinces or states. If we want the total numbers for such countries we have to group the rows by the variable Country/Region, then get the sum for each group.\nGetting the sums of the latitude and longitude wouldn‚Äôt make any sense, so first we get rid of those two columns:\n\ndf_clean = df.select(\n    pl.col(\"*\").exclude(\"Lat\", \"Long\")\n    )\n\nprint(df_clean)\n\nshape: (289, 1_146)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Province/State ‚îÜ Country/Region  ‚îÜ 1/22/20 ‚îÜ 1/23/20 ‚îÜ ‚Ä¶ ‚îÜ 3/7/23 ‚îÜ 3/8/23 ‚îÜ 3/9/23 ‚îÜ daily_avg  ‚îÇ\n‚îÇ ---            ‚îÜ ---             ‚îÜ ---     ‚îÜ ---     ‚îÜ   ‚îÜ ---    ‚îÜ ---    ‚îÜ ---    ‚îÜ ---        ‚îÇ\n‚îÇ str            ‚îÜ str             ‚îÜ i64     ‚îÜ i64     ‚îÜ   ‚îÜ i64    ‚îÜ i64    ‚îÜ i64    ‚îÜ f64        ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ null           ‚îÜ Afghanistan     ‚îÜ 0       ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 209436 ‚îÜ 209451 ‚îÜ 209451 ‚îÜ 183.246719 ‚îÇ\n‚îÇ null           ‚îÜ Albania         ‚îÜ 0       ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 334427 ‚îÜ 334443 ‚îÜ 334457 ‚îÜ 292.613298 ‚îÇ\n‚îÇ null           ‚îÜ Algeria         ‚îÜ 0       ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 271490 ‚îÜ 271494 ‚îÜ 271496 ‚îÜ 237.529309 ‚îÇ\n‚îÇ null           ‚îÜ Andorra         ‚îÜ 0       ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 47875  ‚îÜ 47890  ‚îÜ 47890  ‚îÜ 41.898513  ‚îÇ\n‚îÇ null           ‚îÜ Angola          ‚îÜ 0       ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 105277 ‚îÜ 105288 ‚îÜ 105288 ‚îÜ 92.115486  ‚îÇ\n‚îÇ ‚Ä¶              ‚îÜ ‚Ä¶               ‚îÜ ‚Ä¶       ‚îÜ ‚Ä¶       ‚îÜ ‚Ä¶ ‚îÜ ‚Ä¶      ‚îÜ ‚Ä¶      ‚îÜ ‚Ä¶      ‚îÜ ‚Ä¶          ‚îÇ\n‚îÇ null           ‚îÜ West Bank and   ‚îÜ 0       ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 703228 ‚îÜ 703228 ‚îÜ 703228 ‚îÜ 615.247594 ‚îÇ\n‚îÇ                ‚îÜ Gaza            ‚îÜ         ‚îÜ         ‚îÜ   ‚îÜ        ‚îÜ        ‚îÜ        ‚îÜ            ‚îÇ\n‚îÇ null           ‚îÜ Winter Olympics ‚îÜ 0       ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 535    ‚îÜ 535    ‚îÜ 535    ‚îÜ 0.468066   ‚îÇ\n‚îÇ                ‚îÜ 2022            ‚îÜ         ‚îÜ         ‚îÜ   ‚îÜ        ‚îÜ        ‚îÜ        ‚îÜ            ‚îÇ\n‚îÇ null           ‚îÜ Yemen           ‚îÜ 0       ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 11945  ‚îÜ 11945  ‚îÜ 11945  ‚îÜ 10.450569  ‚îÇ\n‚îÇ null           ‚îÜ Zambia          ‚îÜ 0       ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 343135 ‚îÜ 343135 ‚îÜ 343135 ‚îÜ 300.205599 ‚îÇ\n‚îÇ null           ‚îÜ Zimbabwe        ‚îÜ 0       ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 264127 ‚îÜ 264276 ‚îÜ 264276 ‚îÜ 231.212598 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\nThere are many ways to select columns from a data frame.\n\nNow we can group by and get our sums:\n\ndf_countries = df_clean.group_by(\n    (pl.col(\"Country/Region\")).alias(\"Country totals\")\n    ).sum()\n\nprint(df_countries)\n\nshape: (201, 1_147)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Country     ‚îÜ Province/St ‚îÜ Country/Reg ‚îÜ 1/22/20 ‚îÜ ‚Ä¶ ‚îÜ 3/7/23  ‚îÜ 3/8/23  ‚îÜ 3/9/23  ‚îÜ daily_avg  ‚îÇ\n‚îÇ totals      ‚îÜ ate         ‚îÜ ion         ‚îÜ ---     ‚îÜ   ‚îÜ ---     ‚îÜ ---     ‚îÜ ---     ‚îÜ ---        ‚îÇ\n‚îÇ ---         ‚îÜ ---         ‚îÜ ---         ‚îÜ i64     ‚îÜ   ‚îÜ i64     ‚îÜ i64     ‚îÜ i64     ‚îÜ f64        ‚îÇ\n‚îÇ str         ‚îÜ str         ‚îÜ str         ‚îÜ         ‚îÜ   ‚îÜ         ‚îÜ         ‚îÜ         ‚îÜ            ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ Honduras    ‚îÜ null        ‚îÜ null        ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 472250  ‚îÜ 472250  ‚îÜ 472250  ‚îÜ 413.167104 ‚îÇ\n‚îÇ Burkina     ‚îÜ null        ‚îÜ null        ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 22056   ‚îÜ 22056   ‚îÜ 22056   ‚îÜ 19.296588  ‚îÇ\n‚îÇ Faso        ‚îÜ             ‚îÜ             ‚îÜ         ‚îÜ   ‚îÜ         ‚îÜ         ‚îÜ         ‚îÜ            ‚îÇ\n‚îÇ Venezuela   ‚îÜ null        ‚îÜ null        ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 552157  ‚îÜ 552157  ‚îÜ 552162  ‚îÜ 483.081365 ‚îÇ\n‚îÇ El Salvador ‚îÜ null        ‚îÜ null        ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 201785  ‚îÜ 201785  ‚îÜ 201785  ‚îÜ 176.539808 ‚îÇ\n‚îÇ Egypt       ‚îÜ null        ‚îÜ null        ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 515698  ‚îÜ 515759  ‚îÜ 515759  ‚îÜ 451.232721 ‚îÇ\n‚îÇ ‚Ä¶           ‚îÜ ‚Ä¶           ‚îÜ ‚Ä¶           ‚îÜ ‚Ä¶       ‚îÜ ‚Ä¶ ‚îÜ ‚Ä¶       ‚îÜ ‚Ä¶       ‚îÜ ‚Ä¶       ‚îÜ ‚Ä¶          ‚îÇ\n‚îÇ Belarus     ‚îÜ null        ‚îÜ null        ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 994037  ‚îÜ 994037  ‚îÜ 994037  ‚îÜ 869.673666 ‚îÇ\n‚îÇ Saint Lucia ‚îÜ null        ‚îÜ null        ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 30004   ‚îÜ 30004   ‚îÜ 30004   ‚îÜ 26.250219  ‚îÇ\n‚îÇ Ireland     ‚îÜ null        ‚îÜ null        ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 1703850 ‚îÜ 1704502 ‚îÜ 1704502 ‚îÜ 1491.25284 ‚îÇ\n‚îÇ             ‚îÜ             ‚îÜ             ‚îÜ         ‚îÜ   ‚îÜ         ‚îÜ         ‚îÜ         ‚îÜ 3          ‚îÇ\n‚îÇ Czechia     ‚îÜ null        ‚îÜ null        ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 4615945 ‚îÜ 4617114 ‚îÜ 4618256 ‚îÜ 4040.46894 ‚îÇ\n‚îÇ             ‚îÜ             ‚îÜ             ‚îÜ         ‚îÜ   ‚îÜ         ‚îÜ         ‚îÜ         ‚îÜ 1          ‚îÇ\n‚îÇ Switzerland ‚îÜ null        ‚îÜ null        ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 4413911 ‚îÜ 4413911 ‚îÜ 4413911 ‚îÜ 3861.68941 ‚îÇ\n‚îÇ             ‚îÜ             ‚îÜ             ‚îÜ         ‚îÜ   ‚îÜ         ‚îÜ         ‚îÜ         ‚îÜ 4          ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\nThe alias method allows us to give a name to the groups.\n\nNotice that the rows became out of order. Not to worry about order makes the code more efficient and does not affect future subsetting of our data frame. If you want to maintain the order however, you can use the maintain_order parameter:\n\ndf_countries = df_clean.group_by(\n    (pl.col(\"Country/Region\")).alias(\"Country\"),\n    maintain_order=True\n    ).sum()\n\nprint(df_countries)\n\nshape: (201, 1_147)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Country      ‚îÜ Province/Sta ‚îÜ Country/Regi ‚îÜ 1/22/20 ‚îÜ ‚Ä¶ ‚îÜ 3/7/23 ‚îÜ 3/8/23 ‚îÜ 3/9/23 ‚îÜ daily_avg  ‚îÇ\n‚îÇ ---          ‚îÜ te           ‚îÜ on           ‚îÜ ---     ‚îÜ   ‚îÜ ---    ‚îÜ ---    ‚îÜ ---    ‚îÜ ---        ‚îÇ\n‚îÇ str          ‚îÜ ---          ‚îÜ ---          ‚îÜ i64     ‚îÜ   ‚îÜ i64    ‚îÜ i64    ‚îÜ i64    ‚îÜ f64        ‚îÇ\n‚îÇ              ‚îÜ str          ‚îÜ str          ‚îÜ         ‚îÜ   ‚îÜ        ‚îÜ        ‚îÜ        ‚îÜ            ‚îÇ\n‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n‚îÇ Afghanistan  ‚îÜ null         ‚îÜ null         ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 209436 ‚îÜ 209451 ‚îÜ 209451 ‚îÜ 183.246719 ‚îÇ\n‚îÇ Albania      ‚îÜ null         ‚îÜ null         ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 334427 ‚îÜ 334443 ‚îÜ 334457 ‚îÜ 292.613298 ‚îÇ\n‚îÇ Algeria      ‚îÜ null         ‚îÜ null         ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 271490 ‚îÜ 271494 ‚îÜ 271496 ‚îÜ 237.529309 ‚îÇ\n‚îÇ Andorra      ‚îÜ null         ‚îÜ null         ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 47875  ‚îÜ 47890  ‚îÜ 47890  ‚îÜ 41.898513  ‚îÇ\n‚îÇ Angola       ‚îÜ null         ‚îÜ null         ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 105277 ‚îÜ 105288 ‚îÜ 105288 ‚îÜ 92.115486  ‚îÇ\n‚îÇ ‚Ä¶            ‚îÜ ‚Ä¶            ‚îÜ ‚Ä¶            ‚îÜ ‚Ä¶       ‚îÜ ‚Ä¶ ‚îÜ ‚Ä¶      ‚îÜ ‚Ä¶      ‚îÜ ‚Ä¶      ‚îÜ ‚Ä¶          ‚îÇ\n‚îÇ West Bank    ‚îÜ null         ‚îÜ null         ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 703228 ‚îÜ 703228 ‚îÜ 703228 ‚îÜ 615.247594 ‚îÇ\n‚îÇ and Gaza     ‚îÜ              ‚îÜ              ‚îÜ         ‚îÜ   ‚îÜ        ‚îÜ        ‚îÜ        ‚îÜ            ‚îÇ\n‚îÇ Winter       ‚îÜ null         ‚îÜ null         ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 535    ‚îÜ 535    ‚îÜ 535    ‚îÜ 0.468066   ‚îÇ\n‚îÇ Olympics     ‚îÜ              ‚îÜ              ‚îÜ         ‚îÜ   ‚îÜ        ‚îÜ        ‚îÜ        ‚îÜ            ‚îÇ\n‚îÇ 2022         ‚îÜ              ‚îÜ              ‚îÜ         ‚îÜ   ‚îÜ        ‚îÜ        ‚îÜ        ‚îÜ            ‚îÇ\n‚îÇ Yemen        ‚îÜ null         ‚îÜ null         ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 11945  ‚îÜ 11945  ‚îÜ 11945  ‚îÜ 10.450569  ‚îÇ\n‚îÇ Zambia       ‚îÜ null         ‚îÜ null         ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 343135 ‚îÜ 343135 ‚îÜ 343135 ‚îÜ 300.205599 ‚îÇ\n‚îÇ Zimbabwe     ‚îÜ null         ‚îÜ null         ‚îÜ 0       ‚îÜ ‚Ä¶ ‚îÜ 264127 ‚îÜ 264276 ‚îÜ 264276 ‚îÜ 231.212598 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\n\nYour turn:\n\n\nThe old Country/Region column is now irrelevant. Remove it from df_countries.\nHow could you get the total number of cases for each day for the whole world?",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>",
      "Polars: faster data frames",
      "Subsetting data"
    ]
  },
  {
    "objectID": "python/top_hpc.html",
    "href": "python/top_hpc.html",
    "title": "Faster Python",
    "section": "",
    "text": "Accelerated arrays with \n\n\n\n\nFaster data frames with ¬†\n\n\n\n\nGPU-accelerated Python",
    "crumbs": [
      "Python",
      "<b><em>Faster Python</em></b>"
    ]
  },
  {
    "objectID": "python/top_llm.html",
    "href": "python/top_llm.html",
    "title": "Learning Python with an LLM",
    "section": "",
    "text": "This introductory course on Python does not assume any prior programming experience.\n\n Start course ‚û§",
    "crumbs": [
      "Python",
      "<b><em>Learning Python with LLMs</em></b>"
    ]
  },
  {
    "objectID": "python/top_wb.html",
    "href": "python/top_wb.html",
    "title": "Python webinars",
    "section": "",
    "text": "Faster DataFrames with ¬†\n\n\n\n\nAccelerated arrays & AD with \n\n\n\n\nIntro programming for HSS\n\n\n\n\nuv package manager\n\n\n\n\n\n\nNext gen Python  ¬†notebooks",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>"
    ]
  },
  {
    "objectID": "python/wb_hss_prog.html",
    "href": "python/wb_hss_prog.html",
    "title": "Introduction to programming for the humanities",
    "section": "",
    "text": "An introduction to our programming course for the humanities at the Digital Humanities Summer Institute (DHSI).\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.)\n Slides content for easier browsing.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Intro programming for HSS"
    ]
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#computer-programming",
    "href": "python/wb_hss_prog_slides.html#computer-programming",
    "title": "Intro programming for the humanities ",
    "section": "Computer programming",
    "text": "Computer programming\nProgramming (or coding) consists of writing a set of instructions (a program) for computers so that they perform a task\nThere are many programming languages‚Äîeach with its own syntax‚Äîbut the core concepts apply to all languages. For this course, we will use Python\nPrograms accept inputs (data) and produce outputs (transformed data)"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#important-considerations",
    "href": "python/wb_hss_prog_slides.html#important-considerations",
    "title": "Intro programming for the humanities ",
    "section": "Important considerations",
    "text": "Important considerations\n\nFree and open source software (FOSS) vs proprietary\nCompiled vs interpreted language (speed vs convenience)\nLanguage adapted to particular usage\nLanguage used in your field (colleagues, collaborators, literature)"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#downsides-of-proprietary-software",
    "href": "python/wb_hss_prog_slides.html#downsides-of-proprietary-software",
    "title": "Intro programming for the humanities ",
    "section": "Downsides of proprietary software",
    "text": "Downsides of proprietary software\n\nResearchers who do not have access to the tool cannot reproduce your methods\nOnce you leave academia, you may not have access to the tool anymore\nYour university may stop paying for a license\nYou may get locked-in\nProprietary tools are black boxes\nLong-term access is uncertain\nProprietary tools fall behind popular open-source tools\nProprietary tools often fail to address specialized edge cases needed in research"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#the-argument-for-foss",
    "href": "python/wb_hss_prog_slides.html#the-argument-for-foss",
    "title": "Intro programming for the humanities ",
    "section": "The argument for FOSS",
    "text": "The argument for FOSS\n\nEqual access to everyone, including poorer countries or organizations (it‚Äôs free!)\nOpen science\nTransparency\nThe whole community can contribute to and have a say about development\nYou an build specific capabilities for your edge cases\nGuarantied long term access\nNo risk of getting locked-in"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#compiled-languages",
    "href": "python/wb_hss_prog_slides.html#compiled-languages",
    "title": "Intro programming for the humanities ",
    "section": "Compiled languages",
    "text": "Compiled languages\nYou write code, compile it into machine code, then use this to process your data\n\nCompiled languages are fast. The two step process however makes prototyping less practical and these languages are hard to learn and debug\n\nExamples of compiled languages include C, C++, Fortran, Go, Haskell"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#interpreted-languages",
    "href": "python/wb_hss_prog_slides.html#interpreted-languages",
    "title": "Intro programming for the humanities ",
    "section": "Interpreted languages",
    "text": "Interpreted languages\nInterpreted languages are executed directly\n\nYou get direct feed-back, making it easier to prototype. Interpreted languages are easy to learn and debug, but they are much slower\n\nExamples of interpreted languages include R, Python, Perl, and JavaScript"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#python",
    "href": "python/wb_hss_prog_slides.html#python",
    "title": "Intro programming for the humanities ",
    "section": "Python",
    "text": "Python\nPython is free and open-source, interpreted, and general-purpose\nIt was created by Dutch programmer Guido van Rossum in the 80s, with a launch in 1989\nThe PYPL PopularitY of Programming Language index is based on the number of tutorial searches in Google. Python has been going up steadily, reaching the first position in 2018. It is also ahead in other indices and is the language used by most of the deep learning community\nThis doesn‚Äôt mean that Python is better than other languages, but it means that there are a lot of resources and a large collection of external packages"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#text-editor-to-write-scripts",
    "href": "python/wb_hss_prog_slides.html#text-editor-to-write-scripts",
    "title": "Intro programming for the humanities ",
    "section": "Text editor to write scripts",
    "text": "Text editor to write scripts\nA text editor is not the same as a word processor such as Microsoft Office Word. Word documents are not plain text documents: they contain a lot of hidden formatting and are actually a collection of files. This is not what you want to write scripts\nExamples of good text editors (free and open source):\n\nEmacs\nVisual Studio Code\nVim"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#optional-an-ide",
    "href": "python/wb_hss_prog_slides.html#optional-an-ide",
    "title": "Intro programming for the humanities ",
    "section": "Optional: an IDE",
    "text": "Optional: an IDE\nIntegrated development environments (IDEs) are software that make running a language more friendly by adding functionality and convenience tools, usually within a graphical user interface (GUI)\nA popular IDE for Python is JupyterLab"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#debugging-and-profiling-tools",
    "href": "python/wb_hss_prog_slides.html#debugging-and-profiling-tools",
    "title": "Intro programming for the humanities ",
    "section": "Debugging and profiling tools",
    "text": "Debugging and profiling tools\nSome languages come with debugging tools that make it easier to find problems in the code\nProfilers allow you to spot bottlenecks in the execution of your code\nBenchmarking tools allow you to compare several versions of code to find which is faster"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#hardware",
    "href": "python/wb_hss_prog_slides.html#hardware",
    "title": "Intro programming for the humanities ",
    "section": "Hardware",
    "text": "Hardware\nPython is great in many respects, but it is not a fast language\nMany libraries for Python are written in faster compiled languages (e.g.¬†C, C++, Fortran)\nTo speed things up more, some code or sections of code can be run in parallel (instead of serially). To do this though, you need more hardware\nYou can run code using multiple CPUs (central processing unit). Some code can be accelerated using GPUs (graphical processing unit)\nFor very large scale projects such as very large simulations, deep learning, or big data projects, you can use supercomputers"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#python-shell",
    "href": "python/wb_hss_prog_slides.html#python-shell",
    "title": "Intro programming for the humanities ",
    "section": "Python shell",
    "text": "Python shell\nThe simplest way to use Python is to type commands directly in the Python shell. This sends commands directly to the interpreter\nThe Python shell has a prompt that looks like this:\n&gt;&gt;&gt;"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#ipython",
    "href": "python/wb_hss_prog_slides.html#ipython",
    "title": "Intro programming for the humanities ",
    "section": "IPython",
    "text": "IPython\nIPython is an improved shell with better performance and more functionality (e.g.¬†colour-coding, magic commands)\nThe prompt looks like:\nIn [x]:\n\nx is the command number (e.g.¬†for your first command, it will show In [1]:"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#jupyter",
    "href": "python/wb_hss_prog_slides.html#jupyter",
    "title": "Intro programming for the humanities ",
    "section": "Jupyter",
    "text": "Jupyter\nThe IPython shell was integrated into a fancy interface, the Jupyter notebook. This later lead to a fully fledged IDE (integrated development environment) called JupyterLab which contains notebooks, a command line, a file explorer, and other functionality\n\nEven though JupyterLab runs in your browser, it does not use the internet: it is all run locally on your machine (browsers are software that are great at displaying HTML files, so we use them to access the web, but they can also display files from your computer)"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#other-ides",
    "href": "python/wb_hss_prog_slides.html#other-ides",
    "title": "Intro programming for the humanities ",
    "section": "Other IDEs",
    "text": "Other IDEs\nJupyter has probably become the most popular IDE, but it is possible to run Python in other IDE such as Emacs"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#python-script",
    "href": "python/wb_hss_prog_slides.html#python-script",
    "title": "Intro programming for the humanities ",
    "section": "Python script",
    "text": "Python script\nYou can write your Python code in a text file with a .py extension and run the script in your terminal with:\npython script.py\nThis will execute the code non-interactively"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#packages",
    "href": "python/wb_hss_prog_slides.html#packages",
    "title": "Intro programming for the humanities ",
    "section": "Packages",
    "text": "Packages\nMany languages can have their functionality expanded by the installation of packages developed by the open source community. The potential is unlimited\nMany languages come with their own package manager\nIn Python, popular package managers include pip, Conda, and the newer much faster uv"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#syntax",
    "href": "python/wb_hss_prog_slides.html#syntax",
    "title": "Intro programming for the humanities ",
    "section": "Syntax",
    "text": "Syntax\nEach language uses its own syntax\n\nExample:\nIn Python, the tab (equal to four spaces by default) has meaning, while in R, it doesn‚Äôt (it only makes it easier for people to read code)"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#data-types",
    "href": "python/wb_hss_prog_slides.html#data-types",
    "title": "Intro programming for the humanities ",
    "section": "Data types",
    "text": "Data types\nEach language contains various data types such as integers, floating-point numbers (decimals), strings (series of characters), Booleans (true/false), etc.\n\nPython examples:\n\n\ntype(5)\n\nint\n\n\n\ntype(5.0)\n\nfloat\n\n\n\ntype(\"This is a string\")\n\nstr\n\n\n\ntype(True)\n\nbool"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#variables",
    "href": "python/wb_hss_prog_slides.html#variables",
    "title": "Intro programming for the humanities ",
    "section": "Variables",
    "text": "Variables\nValues can be assigned to names to create variables\n\nPython example\n\n\na = 3\n\na is now a variable containing the value 3:\n\nprint(a)\n\n3\n\n\n\na * 2\n\n6"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#data-structures",
    "href": "python/wb_hss_prog_slides.html#data-structures",
    "title": "Intro programming for the humanities ",
    "section": "Data structures",
    "text": "Data structures\nA data structure is a collection of values\n\nPython examples:\n\n\ntype([0, 5, \"something\"])\n\nlist\n\n\n\ntype((3, 5, \"something\"))\n\ntuple\n\n\n\ntype({0, 2, 6})\n\nset\n\n\nEach type of structure has its own characteristics (necessarily homogeneous or not, mutable or not, ordered or not, etc.). This gives several data storage options, each best in different situations"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#functions",
    "href": "python/wb_hss_prog_slides.html#functions",
    "title": "Intro programming for the humanities ",
    "section": "Functions",
    "text": "Functions\nFunctions are snippets of code that accomplish a specific task\nBuilt-in functions come with the language and are readily available. Other functions become available once a particular module or package is loaded. Finally, the user can definite their own functions\nSome functions take arguments\n\nPython examples:\n\n\nmax([3, 5, 2])\n\n5\n\n\n\ndef hello():\n    print(\"Hello everyone!\")\n\nhello()\n\nHello everyone!"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#control-flow",
    "href": "python/wb_hss_prog_slides.html#control-flow",
    "title": "Intro programming for the humanities ",
    "section": "Control flow",
    "text": "Control flow\nCommands are normally run sequentially, from top to bottom, but it is possible to alter the flow of execution by creating repeats (loops) or conditional executions\n\nPython examples:\n\n\nfor i in range(3):\n    print(i)\n\n0\n1\n2\n\n\n\nx = -3\n\nif x &gt; 0:\n    print(x + 2)\nelse:\n    print(x * 3)\n\n-9"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#internal-documentation",
    "href": "python/wb_hss_prog_slides.html#internal-documentation",
    "title": "Intro programming for the humanities ",
    "section": "Internal documentation",
    "text": "Internal documentation\nMost languages come with their internal documentation\n\nExample with Python:\n\nhelp(sum)\nHelp on built-in function sum in module builtins:\n\nsum(iterable, /, start=0)\n    Return the sum of a 'start' value (default: 0) plus an iterable of numbers\n\n    When the iterable is empty, return the start value.\n    This function is intended specifically for use with numeric values and may\n    reject non-numeric types."
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#the-internet",
    "href": "python/wb_hss_prog_slides.html#the-internet",
    "title": "Intro programming for the humanities ",
    "section": "The internet",
    "text": "The internet\nGoogle is often your best bet, but you need to know the vocabulary in order to ask questions\nStack Overflow is a fantastic community question & answer website"
  },
  {
    "objectID": "python/wb_hss_prog_slides.html#large-language-models-llms",
    "href": "python/wb_hss_prog_slides.html#large-language-models-llms",
    "title": "Intro programming for the humanities ",
    "section": "Large language models (LLMs)",
    "text": "Large language models (LLMs)\nOver the past few years, LLMs have become increasingly performant at coding\nPeople use them in different ways:\n\nAsk questions (explain code, documentation)\nAuto-completion\nFirst code draft\nDebugging\nVibe coding\n\nIn this course, I will show you how they can help you write code"
  },
  {
    "objectID": "python/wb_jax_content.html",
    "href": "python/wb_jax_content.html",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Accelerated arrays & AD",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_jax_content.html#context",
    "href": "python/wb_jax_content.html#context",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "Context",
    "text": "Context\n\nWhat is JAX?\n\nLibrary for Python developed by Google.\nKey data structure: Array.\nComposition, transformation, and differentiation of numerical programs.\nCompilation for CPUs, GPUs, and TPUs.\nNumPy-like and lower-level APIs.\nRequires strict functional programming.\n\n\n\nWhy JAX?\n\n\n\n\n\n\n\n\n\n01\n\n\nAutodiff method\n\n\n\n1\nStatic graph\nand XLA\n\n\n\n\n02\n\n\nFramework\n\n\n\n\n2\nDynamic graph\n\n\n\n1-&gt;2\n\n\n\n\n\na\n\nTensorFlow\n\n\n\n\n4\nDynamic graph\nand XLA\n\n\n\n2-&gt;4\n\n\n\n\n\nb\n\nPyTorch\n\n\n\n\n5\nPseudo-dynamic\nand XLA\n\n\n\n4-&gt;5\n\n\n\n\n\nd\n\nTensorFlow2\n\n\n\n\ne\n\nJAX\n\n\n\n\n\n03\n\n\nAdvantage\n\n\n\n\n\n7\nMostly\noptimized AD\n\n\n\n\n\n8\nConvenient\n\n\n\n\n\n9\nConvenient\n\n\n\n\n10\nConvenient and\nmostly optimized AD\n\n\n\n\n\n04\n\n\nDisadvantage\n\n\n\n\n\nA\nManual writing of IR\n\n\n\n\n\nB\nLimited AD optimization\n\n\n\n\n\nD\nDisappointing speed\n\n\n\n\nE\nPure functions\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummarized from a blog post by Chris Rackauckas.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Accelerated arrays & AD",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_jax_content.html#getting-started",
    "href": "python/wb_jax_content.html#getting-started",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "Getting started",
    "text": "Getting started\n\nInstallation\n Install from pip wheels:\n\nPersonal computer: use wheels installation commands from official site.\nAlliance clusters: python -m pip install jax --no-index.\n\n\nWindows: GPU support only via WSL.\n\n\n\nThe NumPy API\n\nNumPyJAX NumPy\n\n\n\nimport numpy as np\n\nprint(np.array([(1, 2, 3), (4, 5, 6)]))\n\n[[1 2 3]\n [4 5 6]]\n\n\n\nprint(np.arange(5))\n\n[0 1 2 3 4]\n\n\n\nprint(np.zeros(2))\n\n[0. 0.]\n\n\n\nprint(np.linspace(0, 2, 9))\n\n[0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ]\n\n\n\n\nimport jax.numpy as jnp\n\nprint(jnp.array([(1, 2, 3), (4, 5, 6)]))\n[[1 2 3]\n [4 5 6]]\nprint(jnp.arange(5))\n[0 1 2 3 4]\nprint(jnp.zeros(2))\n[0. 0.]\nprint(jnp.linspace(0, 2, 9))\n[0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ]",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Accelerated arrays & AD",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_jax_content.html#but-jax-numpy-is-not-numpy",
    "href": "python/wb_jax_content.html#but-jax-numpy-is-not-numpy",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "But JAX NumPy is not NumPy‚Ä¶",
    "text": "But JAX NumPy is not NumPy‚Ä¶\n\nDifferent types\n\nNumpyJAX NumPy\n\n\n\ntype(np.zeros((2, 3)))\n\nnumpy.ndarray\n\n\n\n\ntype(jnp.zeros((2, 3)))\njaxlib.xla_extension.ArrayImpl\n\n\n\n\n\nDifferent default data types\n\nNumpyJAX NumPy\n\n\n\nnp.zeros((2, 3)).dtype\n\ndtype('float64')\n\n\n\n\njnp.zeros((2, 3)).dtype\ndtype('float32')\n\nStandard for DL and libraries built for accelerators.\nFloat64 are very slow on GPUs and not supported on TPUs.\n\n\n\n\n\n\nImmutable arrays\n\nNumpyJAX NumPy\n\n\n\na = np.arange(5)\na[0] = 9\nprint(a)\n\n[9 1 2 3 4]\n\n\n\n\na = jnp.arange(5)\na[0] = 9\nTypeError: '&lt;class 'jaxlib.xla_extension.ArrayImpl'&gt;' object does not support item assignment. JAX arrays are immutable.\nb = a.at[0].set(9)\nprint(b)\n[9 1 2 3 4]\n\n\n\n\n\nStrict input control\n\nNumpyJAX NumPy\n\n\nNumPy is easy-going:\n\nnp.sum([1.0, 2.0])  # argument is a list\n\nnp.float64(3.0)\n\n\n\nnp.sum((1.0, 2.0))  # argument is a tuple\n\nnp.float64(3.0)\n\n\n\n\nTo avoid inefficiencies, JAX will only accept arrays:\njnp.sum([1.0, 2.0])\nTypeError: sum requires ndarray or scalar arguments, got &lt;class 'list'&gt;\njnp.sum((1.0, 2.0))\nTypeError: sum requires ndarray or scalar arguments, got &lt;class 'tuple'&gt;\n\n\n\n\n\nOut of bounds indexing\n\nNumpyJAX NumPy\n\n\nNumPy will error if you index out of bounds:\n\nprint(np.arange(5)[10])\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[10], line 1\n----&gt; 1 print(np.arange(5)[10])\n\nIndexError: index 10 is out of bounds for axis 0 with size 5\n\n\n\n\n\nJAX will silently return the closest boundary:\nprint(jnp.arange(5)[10])\n4\n\n\n\n\n\nPRNG\nTraditional pseudorandom number generators are based on nondeterministic state of OS.\nSlow and problematic for parallel executions.\nJAX relies on explicitly-set random state called a key:\nfrom jax import random\n\ninitial_key = random.PRNGKey(18)\nprint(initial_key)\n[ 0 18]\nEach key can only be used for one random function, but it can be split into new keys:\nnew_key1, new_key2 = random.split(initial_key)\n\ninitial_key can‚Äôt be used anymore now.\n\nprint(new_key1)\n[4197003906 1654466292]\nprint(new_key2)\n[1685972163 1654824463]\nWe need to keep one key to split whenever we need and we can use the other one.\nTo make sure we don‚Äôt reuse a key by accident, it is best to overwrite the initial key with one of the new ones.\nHere are easier names:\nkey = random.PRNGKey(18)\nkey, subkey = random.split(key)\nWe can now use subkey to generate a random array:\nx = random.normal(subkey, (3, 2))\n\n\nBenchmarking\nJAX uses asynchronous dispatch.\nInstead of waiting for a computation to complete before control returns to Python, the computation is dispatched to an accelerator and a future is created.\nTo get proper timings, we need to make sure the future is resolved by using the block_until_ready() method.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Accelerated arrays & AD",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_jax_content.html#jax-functioning",
    "href": "python/wb_jax_content.html#jax-functioning",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "JAX functioning",
    "text": "JAX functioning\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\n Just-in-time \n(JIT)\ncompilation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\n Transformations \n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\n Just-in-time \n(JIT)\ncompilation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\nxla\n\nAccelerated\n Linear Algebra \n(XLA)\n\n\n\nCPU\n\nCPU\n\n\n\nxla-&gt;CPU\n\n\n\n\n\nGPU\n\nGPU\n\n\n\nxla-&gt;GPU\n\n\n\n\n\nTPU\n\nTPU\n\n\n\nxla-&gt;TPU\n\n\n\n\n\ntransform\n\nVectorization\nParallelization\n ¬†¬†Differentiation ¬†\n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;xla",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Accelerated arrays & AD",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_jax_content.html#jit-compilation",
    "href": "python/wb_jax_content.html#jit-compilation",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "JIT compilation",
    "text": "JIT compilation\n\nJIT syntax\nfrom jax import jit\n\nkey = random.PRNGKey(8)\nkey, subkey1, subkey2 = random.split(key, 3)\n\na = random.normal(subkey1, (500, 500))\nb = random.normal(subkey2, (500, 500))\n\ndef sum_squared_error(a, b):\n    return jnp.sum((a-b)**2)\nOur function could simply be used as:\nsse = sum_squared_error(a, b)\nOur code will run faster if we create a JIT compiled version and use that instead:\nsum_squared_error_jit = jit(sum_squared_error)\n\nsse = sum_squared_error_jit(a, b)\nAlternatively, this can be written as:\nsse = jit(sum_squared_error)(a, b)\nOr with the @jit decorator:\n@jit\ndef sum_squared_error(a, b):\n    return jnp.sum((a - b) ** 2)\n\nsse = sum_squared_error(a, b)\n\n\nStatic vs traced variables\n@jit\ndef cond_func(x):\n    if x &lt; 0.0:\n        return x ** 2.0\n    else:\n        return x ** 3.0\n\nprint(cond_func(1.0))\njax.errors.TracerBoolConversionError: Attempted boolean conversion of traced array with shape bool[]\nJIT compilation uses tracing of the code based on shape and dtype so that the same compiled code can be reused for new values with the same characteristics.\nTracer objects are not real values but abstract representation that are more general.\nHere, an abstract general value does not work as it wouldn‚Äôt know which branch to take.\nOne solution is to tell jit() to exclude the problematic arguments from tracing ‚Ä¶\n‚Ä¶ with arguments positions:\ndef cond_func(x):\n    if x &lt; 0.0:\n        return x ** 2.0\n    else:\n        return x ** 3.0\n\ncond_func_jit = jit(cond_func, static_argnums=(0,))\n\nprint(cond_func_jit(2.0))\nprint(cond_func_jit(-2.0))\n8.0\n4.0\n‚Ä¶ with arguments names:\ndef cond_func(x):\n    if x &lt; 0.0:\n        return x ** 2.0\n    else:\n        return x ** 3.0\n\ncond_func_jit_alt = jit(cond_func, static_argnames=\"x\")\n\nprint(cond_func_jit_alt(2.0))\nprint(cond_func_jit_alt(-2.0))\n8.0\n4.0\n\n\nControl flow primitives\nAnother solution, is to use one of the structured control flow primitives:\nfrom jax import lax\n\nlax.cond(False, lambda x: x ** 2.0, lambda x: x ** 3.0, jnp.array([2.]))\nArray([8.], dtype=float32)\nlax.cond(True, lambda x: x ** 2.0, lambda x: x ** 3.0, jnp.array([-2.]))\nArray([4.], dtype=float32)\nOther control flow primitives:\n\nlax.while_loop\nlax.fori_loop\nlax.scan\n\nOther pseudo dynamic control flow functions:\n\nlax.select (NumPy API jnp.where and jnp.select)\nlax.switch (NumPy API jnp.piecewise)\n\n\n\nStatic vs traced operations\nSimilarly, you can mark problematic operations as static so that they don‚Äôt get traced during JIT compilation:\n@jit\ndef f(x):\n    return x.reshape(jnp.array(x.shape).prod())\n\nx = jnp.ones((2, 3))\nprint(f(x))\nTypeError: Shapes must be 1D sequences of concrete values of integer type, got [Traced&lt;ShapedArray(int32[])&gt;with&lt;DynamicJaxprTrace(level=1/0)&gt;]\nThe problem here is that the shape of the argument to prod() depends on the value of x which is unknown at compilation time.\nOne solution is to use the NumPy version of prod():\nimport numpy as np\n\n@jit\ndef f(x):\n    return x.reshape((np.prod(x.shape)))\n\nprint(f(x))\n[1. 1. 1. 1. 1. 1.]",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Accelerated arrays & AD",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_jax_content.html#functionally-pure-functions",
    "href": "python/wb_jax_content.html#functionally-pure-functions",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "Functionally pure functions",
    "text": "Functionally pure functions\n\nJaxprs\nimport jax\n\nx = jnp.array([1., 4., 3.])\ny = jnp.array([8., 1., 2.])\n\ndef f(x, y):\n    return 2 * x**jax.make_jaxpr(f)(x, y) \n{ lambda ; a:f32[3] b:f32[3]. let\n    c:f32[3] = integer_pow[y=2] a\n    d:f32[3] = mul 2.0 c\n    e:f32[3] = add d b\n  in (e,) }\n\n\nOutputs only based on inputs\ndef f(x):\n    return a + x\nf uses the variable a from the global environment.\nThe output does not solely depend on the inputs: not a pure function.\na = jnp.ones(3)\nprint(a)\n[1. 1. 1.]\ndef f(x):\n    return print(jit(f)(jnp.ones(3)))\n[2. 2. 2.]\n\nThings seem ok here because this is the first run (tracing).\n\nNow, let‚Äôs change the value of a to an array of zeros:\na = jnp.zeros(3)\nprint(a)\n[0. 0. 0.]\nAnd rerun the same code:\nprint(jit(f)(jnp.ones(3)))\n[2. 2. 2.]\n\nOur cached compiled program is run and we get a wrong result.\n\nThe new value for a will only take effect if we re-trigger tracing by changing the shape and/or dtype of x:\na = jnp.zeros(4)\nprint(a)\n[0. 0. 0. 0.]\nprint(jit(f)(jnp.ones(4)))\n[1. 1. 1. 1.]\nPassing to f() an argument of a different shape forced retracing.\n\n\nNo side effects\nSide effects: anything beside returned output.\nExamples:\n\nPrinting to standard output\nReading from file/writing to file\nModifying a global variable\n\nThe side effects will happen during tracing, but not on subsequent runs. You cannot rely on side effects in your code.\ndef f(a, b):\n    print(\"Calculating sum\")\n    return print(jit(f)(jnp.arange(3), jnp.arange(3)))\nCalculating sum\n[0 2 4]\n\nPrinting happened here because this is the first run.\n\nLet‚Äôs rerun the function:\nprint(jit(f)(jnp.arange(3), jnp.arange(3)))\n[0 2 4]\nThis time, no printing.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Accelerated arrays & AD",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_jax_content.html#other-transformations",
    "href": "python/wb_jax_content.html#other-transformations",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "Other transformations",
    "text": "Other transformations\n\nAutomatic differentiation\nConsidering the function f:\nf = lambda x: x**3 + 2*x**2 - 3*x + 8\nWe can create a new function dfdx that computes the gradient of f w.r.t. x:\nfrom jax import grad\n\ndfdx = grad(f)\ndfdx returns the derivatives.\nprint(dfdx(1.))\n4.0\n\n\nComposing transformations\nTransformations can be composed:\nprint(jit(grad(f))(1.))\n4.0\nprint(grad(jit(f))(1.))\n4.0\n\n\nForward and reverse modes\nOther autodiff methods:\n\nReverse-mode vector-Jacobian products: jax.vjp\nForward-mode Jacobian-vector products: jax.jvp\n\n\n\nHigher-order differentiation\nWith a single variable, the grad function calls can be nested:\nd2fdx = grad(dfdx)   # function to compute 2nd order derivatives\nd3fdx = grad(d2fdx)  # function to compute 3rd order derivatives\n...\nWith several variables:\n\njax.jacfwd for forward-mode\njax.jacrev for reverse-mode\n\n\n\nPytrees\nJAX has a nested container structure: pytree extremely useful for DNN.\n\n\nVectorization and parallelization\nOther transformations for parallel run of computations across batches of arrays:\n\nAutomatic vectorization with jax.vmap\nParallelization across devices with jax.pmap",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Accelerated arrays & AD",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_jax_content.html#pushing-optimizations-further",
    "href": "python/wb_jax_content.html#pushing-optimizations-further",
    "title": "Accelerated array computing and flexible differentiation with JAX",
    "section": "Pushing optimizations further",
    "text": "Pushing optimizations further\n\nLax API\njax.numpy is a high-level NumPy-like API wrapped around jax.lax.\njax.lax is a more efficient lower-level API itself wrapped around XLA.\n\n\nPallas: extension to write GPU and TPU kernels\n\n\n\n\n\n\n\n\n\ntracer\n\nTracing\n\n\n\njaxpr\n\nJaxprs\n(JAX expressions)\nintermediate\nrepresentation\n(IR)\n\n\n\ntracer-&gt;jaxpr\n\n\n\n\n\njit\n\n Just-in-time \n(JIT)\ncompilation\n\n\n\nhlo\n\nHigh-level\noptimized (HLO)\nprogram\n\n\n\njit-&gt;hlo\n\n\n\n\n\ntriton\n\nTriton\n\n\n\nGPU\n\nGPU\n\n\n\ntriton-&gt;GPU\n\n\n\n\n\nmosaic\n\nMosaic\n\n\n\nTPU\n\nTPU\n\n\n\nmosaic-&gt;TPU\n\n\n\n\n\ntransform\n\nVectorization\nParallelization\n ¬†¬†Differentiation ¬†\n\n\n\npy\n\nPure Python\nfunctions\n\n\n\npy-&gt;tracer\n\n\n\n\njaxpr-&gt;jit\n\n\n\n\njaxpr-&gt;transform\n\n\n\n\n\n\nhlo-&gt;triton\n\n\n\n\nhlo-&gt;mosaic",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Accelerated arrays & AD",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_marimo.html",
    "href": "python/wb_marimo.html",
    "title": "The next generation of Python notebooks",
    "section": "",
    "text": "Project Jupyter was extremely innovative when, back in 2011, they built an open source Notebook on top of the IPython shell (itself an improvement over the Python shell). Notebooks proved an extremely popular tool for literate programming and are widely used today.\nThey do however come with two major issues:\n\nThey are a nightmare for version control.\nThe JSON-like format of the .ipynb files used by Jupyter makes versioning a challenge without the use of proprietary tools or hacky back and forth conversions with, for instance, jupytext.\nIt is easy to forget to rerun cells in order and publish a non-reproducible notebook.\nA study of 10 million notebooks published on GitHub found that 36% of them had been run in a non-linear fashion.\n\nmarimo is a new generation of open source notebook for Python that addresses these problems by using a dataflow graph under the hood ensuring that cells remain up to date and using .py as its file format. marimo notebooks also provide excellent interactivity with direct synchronization with the Python kernel. Consequently, these new notebooks have seen a surge in popularity since their launch in 2023.\nIn this webinar, I will demo the installation and usage of marimo notebooks.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Next gen Python notebooks"
    ]
  },
  {
    "objectID": "python/wb_marimo_slides.html#notes",
    "href": "python/wb_marimo_slides.html#notes",
    "title": "The next generation of Python notebooks",
    "section": "Notes",
    "text": "Notes\n\nI am making an opinionated decision to use uv for installation\nNotebooks are great for prototyping but not at scale\nmarimo is not available on the Alliance clusters at this point"
  },
  {
    "objectID": "python/wb_marimo_slides.html#whats-wrong-with-jupyter",
    "href": "python/wb_marimo_slides.html#whats-wrong-with-jupyter",
    "title": "The next generation of Python notebooks",
    "section": "What‚Äôs wrong with Jupyter?",
    "text": "What‚Äôs wrong with Jupyter?\nJupyter notebooks are very popular but they come with downsides:\n\nVersion control nightmare\nAwkward JSON file format\nReproducibility issues"
  },
  {
    "objectID": "python/wb_marimo_slides.html#dag-dataflow",
    "href": "python/wb_marimo_slides.html#dag-dataflow",
    "title": "The next generation of Python notebooks",
    "section": "DAG dataflow",
    "text": "DAG dataflow\nmarimo notebooks automatically generate an intermediate representation (IR) in the form of a directed acyclic graph (DAG) of:\n\ndefinitions (defs) of global variables\nreferences (refs) of global variables\n\nEach cell is parsed into an abstract syntax tree (AST)\nStatically inferred (no runtime tracing)"
  },
  {
    "objectID": "python/wb_marimo_slides.html#python-files",
    "href": "python/wb_marimo_slides.html#python-files",
    "title": "The next generation of Python notebooks",
    "section": "Python files",
    "text": "Python files\n\n\nNotebooks are saved as .py files\nEach cell is stored as a function\nPure functions can be reused as modules\n\n\n\n\n\n\n\n\n\n\n ‚ûî\n\nEasy version control\nDirectly executable as scripts or web apps\nReadable in text editors"
  },
  {
    "objectID": "python/wb_marimo_slides.html#interactive-elements",
    "href": "python/wb_marimo_slides.html#interactive-elements",
    "title": "The next generation of Python notebooks",
    "section": "Interactive elements",
    "text": "Interactive elements\nmarimo.ui creates interactive user interface (UI) elements with first-class support\nNotebooks are automatically updated when values are changed via interactions"
  },
  {
    "objectID": "python/wb_marimo_slides.html#cool-features",
    "href": "python/wb_marimo_slides.html#cool-features",
    "title": "The next generation of Python notebooks",
    "section": "Cool features",
    "text": "Cool features\n\nTurn notebooks into apps\nIntegrated AI\nDocstrings on hover"
  },
  {
    "objectID": "python/wb_marimo_slides.html#the-constraints",
    "href": "python/wb_marimo_slides.html#the-constraints",
    "title": "The next generation of Python notebooks",
    "section": "The constraints",
    "text": "The constraints\nAll this comes at the cost of some constraints:\n\nGlobal variables must be unique\nIn-place transformations are not allowed\nMutations and attributes are not tracked\n\n\nAll this is good practice for strict functional programming (and JAX)!"
  },
  {
    "objectID": "python/wb_marimo_slides.html#computation-cost",
    "href": "python/wb_marimo_slides.html#computation-cost",
    "title": "The next generation of Python notebooks",
    "section": "Computation cost",
    "text": "Computation cost\nThere is a cost to updating the DAG at each change\nRuntime configurations and cell settings allow to control when re-runs happen"
  },
  {
    "objectID": "python/wb_marimo_slides.html#installation",
    "href": "python/wb_marimo_slides.html#installation",
    "title": "The next generation of Python notebooks",
    "section": "Installation",
    "text": "Installation\nCreate a uv project:\nuv init --bare\nInstall marimo in it as a development dependency:\nuv add --dev marimo\n(Optional) add tools marimo can make use of:\nuv add --dev ruff basedpyright mcp"
  },
  {
    "objectID": "python/wb_marimo_slides.html#launch-a-notebook",
    "href": "python/wb_marimo_slides.html#launch-a-notebook",
    "title": "The next generation of Python notebooks",
    "section": "Launch a notebook",
    "text": "Launch a notebook\nmarimo edit notebook.py\n\nIf you installed with uv, first activate the virtual env or run instead:\nuv run marimo edit notebook.py"
  },
  {
    "objectID": "python/wb_marimo_slides.html#configuration",
    "href": "python/wb_marimo_slides.html#configuration",
    "title": "The next generation of Python notebooks",
    "section": "Configuration",
    "text": "Configuration\nVia GUI\n top right corner (Notebook settings) ‚ûî User settings"
  },
  {
    "objectID": "python/wb_marimo_slides.html#official-website",
    "href": "python/wb_marimo_slides.html#official-website",
    "title": "The next generation of Python notebooks",
    "section": "Official website",
    "text": "Official website\nExcellent documentation:\nUser guides\nAPI reference"
  },
  {
    "objectID": "python/wb_marimo_slides.html#tutorials",
    "href": "python/wb_marimo_slides.html#tutorials",
    "title": "The next generation of Python notebooks",
    "section": "Tutorials",
    "text": "Tutorials\nmarimo tutorial intro\nFor more tutorials, replace intro with any of:\ndataflow\nui\nmarkdown\nplots\nsql\nlayout\nfileformat\nmarkdown-format\nfor-jupyter-users\n\nIf you installed with uv, first activate the virtual env or run instead:\nuv run marimo tutorial intro"
  },
  {
    "objectID": "python/wb_marimo_slides.html#key-bindings",
    "href": "python/wb_marimo_slides.html#key-bindings",
    "title": "The next generation of Python notebooks",
    "section": "Key bindings",
    "text": "Key bindings\nVim kbd available\nCommand mode\nEsc\nWith vim keybindings are enabled or other issues, use Ctrl+Esc or Shift+Esc instead\nNavigation between cells, copy/cut/paste cells\nEdit mode\nEnter or click on a cell\nEdit content"
  },
  {
    "objectID": "python/wb_marimo_slides.html#key-bindings-1",
    "href": "python/wb_marimo_slides.html#key-bindings-1",
    "title": "The next generation of Python notebooks",
    "section": "Key bindings",
    "text": "Key bindings\nCustomizable. List displayed by Ctrl-Shift-h"
  },
  {
    "objectID": "python/wb_marimo_slides.html#ipynb-notebooks-conversion",
    "href": "python/wb_marimo_slides.html#ipynb-notebooks-conversion",
    "title": "The next generation of Python notebooks",
    "section": "ipynb notebooks conversion",
    "text": "ipynb notebooks conversion\nmarimo convert notebook.ipynb -o notebook.py\n\nIPython magics are replaced by Python functions\n\n\nAfter a uv install, run (or activate the virtual env):\nuv run marimo convert notebook.ipynb -o notebook.py"
  },
  {
    "objectID": "python/wb_marimo_slides.html#installing-python-packages",
    "href": "python/wb_marimo_slides.html#installing-python-packages",
    "title": "The next generation of Python notebooks",
    "section": "Installing Python packages",
    "text": "Installing Python packages\nDirectly in the notebook following a pop-up when trying to use uninstalled package\n\nOf course this can also be done via the command line:\nuv add &lt;package&gt;\n\nExample:\n\nuv add numpy"
  },
  {
    "objectID": "python/wb_marimo_slides.html#outputs-displays",
    "href": "python/wb_marimo_slides.html#outputs-displays",
    "title": "The next generation of Python notebooks",
    "section": "Outputs displays",
    "text": "Outputs displays\n\n\nConsole outputs\nText written to stdout/stderr\n‚ûî displayed below cells by default\n‚ûî hidden in app mode\n\nExample:\n\n\n\ncell\n\nprint(\"This is a console output.\")\n\n\n\n\nCell outputs\n\n‚ûî displayed above cells by default\n‚ûî shown in app mode\n\nExample:\n\n\n\ncell\n\n\"This is a cell output.\""
  },
  {
    "objectID": "python/wb_marimo_slides.html#forbidden-re-assignments",
    "href": "python/wb_marimo_slides.html#forbidden-re-assignments",
    "title": "The next generation of Python notebooks",
    "section": "Forbidden re-assignments",
    "text": "Forbidden re-assignments\nVariables re-assignments are OK within cells, but not across cells\nThe cells with re-assignments will not run\n\nReusing i in loops across cells won‚Äôt work\n+=, -=, etc. won‚Äôt run"
  },
  {
    "objectID": "python/wb_marimo_slides.html#mutations-do-not-call-re-runs",
    "href": "python/wb_marimo_slides.html#mutations-do-not-call-re-runs",
    "title": "The next generation of Python notebooks",
    "section": "Mutations do not call re-runs",
    "text": "Mutations do not call re-runs\nLet‚Äôs consider:\n\n\ncell 0\n\nl = [1, 2, 3]\n\n\n\ncell 1\n\nlen(l)\n\n\n\ncell 2\n\nl.append(4)\n\nrunning the cell 2 will not update cell 1"
  },
  {
    "objectID": "python/wb_marimo_slides.html#deleting-cells",
    "href": "python/wb_marimo_slides.html#deleting-cells",
    "title": "The next generation of Python notebooks",
    "section": "Deleting cells",
    "text": "Deleting cells\nAutomatically deletes variables defined in them (and cells with refs to them are re-run)"
  },
  {
    "objectID": "python/wb_marimo_slides.html#no-cycles-permitted",
    "href": "python/wb_marimo_slides.html#no-cycles-permitted",
    "title": "The next generation of Python notebooks",
    "section": "No cycles permitted",
    "text": "No cycles permitted\nThis would make the DAG impossible:\n\n\ncell 0\n\nvar1 = 4\nprint(var2)\n\n\n\ncell 1\n\nvar2 = 7\nprint(var1)"
  },
  {
    "objectID": "python/wb_marimo_slides.html#attributes-are-not-tracked",
    "href": "python/wb_marimo_slides.html#attributes-are-not-tracked",
    "title": "The next generation of Python notebooks",
    "section": "Attributes are not tracked",
    "text": "Attributes are not tracked\nAssignments to attributes aren‚Äôt tracked:\n\n\ncell 0\n\nclass Object(object):\n    pass\n\nobj = Object()\nobj.somefield = \"somevalue\"\n\n\n\ncell 1\n\nprint(obj.somefield)\n\n\n\ncell 2\n\nobj.somefield = \"newvalue\"\n\ncell 1 is not re-run and updated automatically"
  },
  {
    "objectID": "python/wb_marimo_slides.html#dataflow-programming",
    "href": "python/wb_marimo_slides.html#dataflow-programming",
    "title": "The next generation of Python notebooks",
    "section": "Dataflow programming",
    "text": "Dataflow programming\nExecution order \\(\\neq\\) cell order\nThe execution order is determined by the DAG\nThis is a totally valid notebook:\n\n\ncell 0\n\nprint(new_var)\n\n\n\ncell 1\n\nnew_var = 8"
  },
  {
    "objectID": "python/wb_marimo_slides.html#dataflow-programming-1",
    "href": "python/wb_marimo_slides.html#dataflow-programming-1",
    "title": "The next generation of Python notebooks",
    "section": "Dataflow programming",
    "text": "Dataflow programming\nThese are perfectly equivalent notebooks (they have the same DAG):\n\n\n\n\ncell 0\n\na = 3\n\n\n\ncell 1\n\na1 = 8.9\na2 = 8.3\n\n\n\ncell 2\n\na3 = 3.0\n\n\n\ncell 3\n\na4 = 1.2\n\n\n\ncell 4\n\nmy_list = [a1, a2, a3, a4]\n\n\n\n\n\n\ncell 0\n\nmy_list = [a1, a2, a3, a4]\n\n\n\ncell 1\n\na = 3\n\n\n\ncell 2\n\na3 = 3.0\n\n\n\ncell 3\n\na1 = 8.9\na2 = 8.3\n\n\n\ncell 4\n\na4 = 1.2"
  },
  {
    "objectID": "python/wb_marimo_slides.html#dataflow-navigation",
    "href": "python/wb_marimo_slides.html#dataflow-navigation",
    "title": "The next generation of Python notebooks",
    "section": "Dataflow navigation",
    "text": "Dataflow navigation\n\n\nHere is our notebook:\n\n\ncell 0\n\na = 3\n\n\n\ncell 1\n\na1 = 8.9\na2 = 8.3\n\n\n\ncell 2\n\na3 = 3.0\n\n\n\ncell 3\n\na4 = 1.2\n\n\n\ncell 4\n\nmy_list = [a1, a2, a3, a4]\n\n\n\n\n‚ÄÉ‚ÄÉThis is the corresponding DAG:\n\n\n\n\n\n\n\n\n\n0\n\ncell 0\n\n\n\n1\n\ncell 1\n\n\n\n\n2\n\ncell 2\n\n\n\n\n4\n\ncell 4\n\n\n\n1-&gt;4\n\n\n\n\n\n3\n\ncell 3\n\n\n\n\n2-&gt;4\n\n\n\n\n\n3-&gt;4"
  },
  {
    "objectID": "python/wb_marimo_slides.html#dataflow-navigation-1",
    "href": "python/wb_marimo_slides.html#dataflow-navigation-1",
    "title": "The next generation of Python notebooks",
    "section": "Dataflow navigation",
    "text": "Dataflow navigation\nNavigating and understanding the dataflow is made easy by a number of tools:\n\nMinimap (Ctrl-Shift-i)\nDependency explorer (left menu)\nReference highlighting and jumping (hover on underlined refs, Ctrl+click to jump to defs)"
  },
  {
    "objectID": "python/wb_marimo_slides.html#managing-runs",
    "href": "python/wb_marimo_slides.html#managing-runs",
    "title": "The next generation of Python notebooks",
    "section": "Managing runs",
    "text": "Managing runs\nRe-running heavy computations to update the notebooks can be costly\nThis can be controlled by disabling/enabling:\n\nautorun on startup\nautorun on cell change (lazy execution)\nspecific cells"
  },
  {
    "objectID": "python/wb_marimo_slides.html#markdown",
    "href": "python/wb_marimo_slides.html#markdown",
    "title": "The next generation of Python notebooks",
    "section": "Markdown",
    "text": "Markdown\nYou can turn cells into markdown and select raw strings and/or f-string\n\n\n\n\n\n\nat the bottom right corner of every cell"
  },
  {
    "objectID": "python/wb_marimo_slides.html#markdown-extensions",
    "href": "python/wb_marimo_slides.html#markdown-extensions",
    "title": "The next generation of Python notebooks",
    "section": "Markdown extensions",
    "text": "Markdown extensions\n\n\ncell\n\n/// details | Click for details.\n\nYou can create accordion blocks.\n///\n\n\n\ncell\n\n/// admonition | Tips\n\nYou can create info blocks.\n///\n\n\n\ncell\n\n/// attention | Be careful!\n\nYou can create warning blocks.\n///"
  },
  {
    "objectID": "python/wb_marimo_slides.html#plots",
    "href": "python/wb_marimo_slides.html#plots",
    "title": "The next generation of Python notebooks",
    "section": "Plots",
    "text": "Plots\nPlotting works as you would expect\nJavaScript interactivity also works\n\n\ncell\n\nimport plotly.express as px\ndf = px.data.tips()\n\nfig = px.density_contour(df, x=\"total_bill\", y=\"tip\")\nfig.update_traces(contours_coloring=\"fill\", contours_showlabels = True)\nfig.show()"
  },
  {
    "objectID": "python/wb_marimo_slides.html#script",
    "href": "python/wb_marimo_slides.html#script",
    "title": "The next generation of Python notebooks",
    "section": "Script",
    "text": "Script\nYou can run a notebook as a script, without having to do any conversion, with:\npython notebook.py"
  },
  {
    "objectID": "python/wb_marimo_slides.html#apps",
    "href": "python/wb_marimo_slides.html#apps",
    "title": "The next generation of Python notebooks",
    "section": "Apps",
    "text": "Apps\nYou can run a notebook as an app with:\nmarimo run notebook.py"
  },
  {
    "objectID": "python/wb_marimo_slides.html#ai",
    "href": "python/wb_marimo_slides.html#ai",
    "title": "The next generation of Python notebooks",
    "section": "AI",
    "text": "AI\nCompletion\nProvided out of the box with GitHub Copilot. Tab to complete\nGenerate cells with AI\nBox at the bottom of notebook\nCells refactoring\nIn the menu of each cell"
  },
  {
    "objectID": "python/wb_marimo_slides.html#ai-1",
    "href": "python/wb_marimo_slides.html#ai-1",
    "title": "The next generation of Python notebooks",
    "section": "AI",
    "text": "AI\nChat\nButton on the left menu opens a chat panel\nGoing crazy\nmarimo new asks an LLM to generate a full notebook from scratch:\n\nExample:\n\nmarimo new \"Create a cool-looking 3D plot with matplotlib.\""
  },
  {
    "objectID": "python/wb_marimo_slides.html#the-marimo-module",
    "href": "python/wb_marimo_slides.html#the-marimo-module",
    "title": "The next generation of Python notebooks",
    "section": "The marimo module",
    "text": "The marimo module\nEvery notebook loads the marimo module automatically\nInteractive elements make use of the module, so it is convenient to create an alias:\n\n\ncell 0\n\nimport marimo as mo"
  },
  {
    "objectID": "python/wb_marimo_slides.html#create-an-interactive-element",
    "href": "python/wb_marimo_slides.html#create-an-interactive-element",
    "title": "The next generation of Python notebooks",
    "section": "Create an interactive element",
    "text": "Create an interactive element\nYou create an element with one of the mo.ui methods\nCall it at the end of the cell to display it:\n\n\ncell 1\n\nslider = mo.ui.slider(start=1, stop=10, step=1)\nslider\n\n\nUI elements are defs\n\nYou can embed it in a markdown output and format it with an f-string:\n\n\ncell 1\n\nslider = mo.ui.slider(start=1, stop=10, step=1)\nmo.md(f\"Pick a value: {slider}\")"
  },
  {
    "objectID": "python/wb_marimo_slides.html#access-the-value",
    "href": "python/wb_marimo_slides.html#access-the-value",
    "title": "The next generation of Python notebooks",
    "section": "Access the value",
    "text": "Access the value\nYou then need to access its value in another cell:\n\n\ncell 2\n\nslider.value\n\nWhich you can also embed in some markdown:\n\n\ncell 2\n\nmo.md(f\"You picked the value: {slider.value}\")"
  },
  {
    "objectID": "python/wb_marimo_slides.html#example",
    "href": "python/wb_marimo_slides.html#example",
    "title": "The next generation of Python notebooks",
    "section": "Example",
    "text": "Example\nCreate a date selector element:\n\n\ncell 0\n\ndate = mo.ui.date()\nmo.md(f\"Select a date: {date}\")\n\nPrint the selected date:\n\n\ncell 1\n\nmo.md(f\"Your selected date is: {date.value}\")"
  },
  {
    "objectID": "python/wb_marimo_slides.html#progress-bars",
    "href": "python/wb_marimo_slides.html#progress-bars",
    "title": "The next generation of Python notebooks",
    "section": "Progress bars",
    "text": "Progress bars\nSimilar to tqdm:\n\n\ncell\n\nimport time\n\nfor i in mo.status.progress_bar(range(50)):\n    print(i)\n    time.sleep(0.1)"
  },
  {
    "objectID": "python/wb_marimo_slides.html#python-files-for-notebooks",
    "href": "python/wb_marimo_slides.html#python-files-for-notebooks",
    "title": "The next generation of Python notebooks",
    "section": "Python files for notebooks",
    "text": "Python files for notebooks\nNotebooks get written in Python as:\n\n\nnotebook.py\n\nimport marimo\n\n__generated_with = \"&lt;some version&gt;\"\napp = marimo.App()\n\n\"&lt;your cells go here&gt;\"\n\nif __name__ == \"__main__\":\n    app.run()"
  },
  {
    "objectID": "python/wb_marimo_slides.html#notebook-settings",
    "href": "python/wb_marimo_slides.html#notebook-settings",
    "title": "The next generation of Python notebooks",
    "section": "Notebook settings",
    "text": "Notebook settings\nAdded as:\n\n\nnotebook.py\n\nimport marimo\n\n__generated_with = \"&lt;some version&gt;\"\napp = marimo.App(width=\"medium\", css_file=\"custom.css\", auto_download=[\"html\"])\n\n\"&lt;your cells go here&gt;\"\n\nif __name__ == \"__main__\":\n    app.run()"
  },
  {
    "objectID": "python/wb_marimo_slides.html#what-are-cells-really",
    "href": "python/wb_marimo_slides.html#what-are-cells-really",
    "title": "The next generation of Python notebooks",
    "section": "What are cells really?",
    "text": "What are cells really?\nCells are functions wrapped by an @app.cell decorator\nThis makes them easy to turn into apps\nWhen you create an empty cell, your .py file (let‚Äôs call it notebook.py) sees the following added:\n\n\nnotebook.py\n\n@app.cell\ndef _():\n    return"
  },
  {
    "objectID": "python/wb_marimo_slides.html#what-are-cells-really-1",
    "href": "python/wb_marimo_slides.html#what-are-cells-really-1",
    "title": "The next generation of Python notebooks",
    "section": "What are cells really?",
    "text": "What are cells really?\nNow, add in the cell:\n\n\ncell 0\n\nx = 8\ny = 9\n\nand you get in your .py file:\n\n\nnotebook.py\n\n@app.cell\ndef _():\n    x = 8\n    y = 9\n    return"
  },
  {
    "objectID": "python/wb_marimo_slides.html#what-are-cells-really-2",
    "href": "python/wb_marimo_slides.html#what-are-cells-really-2",
    "title": "The next generation of Python notebooks",
    "section": "What are cells really?",
    "text": "What are cells really?\nHide the code and the script turns into:\n\n\nnotebook.py\n\n@app.cell(hide_code=True)\ndef _():\n    x = 8\n    y = 9\n    return"
  },
  {
    "objectID": "python/wb_marimo_slides.html#references",
    "href": "python/wb_marimo_slides.html#references",
    "title": "The next generation of Python notebooks",
    "section": "References",
    "text": "References\nCell dependencies are passed as arguments to the function:\n\n\nNotebook cells:\n\n\ncell 1\n\nprint(x)\n\n\n\n\ncell 2\n\nprint(x, y)\n\n\n\n\nCorresponding Python file:\n\n\nnotebook.py\n\n@app.cell\ndef _(x):\n    print(x)\n    return\n\n\n\nnotebook.py\n\n@app.cell\ndef _(x, y):\n    print(x, y)\n    return"
  },
  {
    "objectID": "python/wb_marimo_slides.html#print-refs-and-defs",
    "href": "python/wb_marimo_slides.html#print-refs-and-defs",
    "title": "The next generation of Python notebooks",
    "section": "Print refs and defs",
    "text": "Print refs and defs\nmo.defs and mo.refs output the defs and refs of a cell:\n\n\ncell 0\n\nvar = 8\nprint(f\"The defs are: {mo.defs()} and the refs are: {mo.refs()}\")\n\n\n\ncell 1\n\nvar + 7\nprint(f\"The defs are: {mo.defs()} and the refs are: {mo.refs()}\")"
  },
  {
    "objectID": "python/wb_marimo_slides.html#how-is-md-turned-into-python",
    "href": "python/wb_marimo_slides.html#how-is-md-turned-into-python",
    "title": "The next generation of Python notebooks",
    "section": "How is md turned into Python?",
    "text": "How is md turned into Python?\nMarkdown text is wrapped in mo.md functions:\n\n\nnotebook.py\n\n@app.cell\ndef _(mo):\n    mo.md(\n        r\"\"\"\n    ## Heading\n\n    Some markdown with some *italic* formatting.\n    \"\"\"\n    )\n    return"
  },
  {
    "objectID": "python/wb_polars_content.html",
    "href": "python/wb_polars_content.html",
    "title": "DataFrames on steroids with Polars",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Faster data frames",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_polars_content.html#background",
    "href": "python/wb_polars_content.html#background",
    "title": "DataFrames on steroids with Polars",
    "section": "Background",
    "text": "Background\n\nTabular data\nMany fields of machine learning and data science rely on tabular data where:\n\ncolumns hold variables and are homogeneous (same data type),\nrows contain observations and can be heterogeneous.\n\nEarly computer options to manipulate such data were limited to spreadsheets.\nDataframes (data frames or DataFrames) are two dimensional objects that brought tabular data to programming.\n\n\nEarly history of dataframes\n\n\n\n\n\n\n\n\n\ny1\n1990\n\n\n\ny2\n2000\n\n\n\ny1--y2\n\n\n\n\ny3\n2008\n\n\n\ny2--y3\n\n\n\n\nl1\n\nS programming language\n\n\n\n\n\nl2\n\nR\n\n\n\n\n\n\nl3\n\nPandas (Python)\n\n\n\n\n\n\n\n\n\n\n\nThe world was simple ‚Ä¶ but slow. Another problem: high memory usage.\n\n\nIssues with Pandas\nWes McKinney (pandas creator) himself has complaints about it:\n\n‚Ä¢ Internals too far from ‚Äúthe metal‚Äù\n‚Ä¢ No support for memory-mapped datasets\n‚Ä¢ Poor performance in database and file ingest / export\n‚Ä¢ Warty missing data support\n‚Ä¢ Lack of transparency into memory use, RAM management\n‚Ä¢ Weak support for categorical data\n‚Ä¢ Complex groupby operations awkward and slow\n‚Ä¢ Appending data to a DataFrame tedious and very costly\n‚Ä¢ Limited, non-extensible type metadata\n‚Ä¢ Eager evaluation model, no query planning\n‚Ä¢ ‚ÄúSlow‚Äù, limited multicore algorithms for large datasets",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Faster data frames",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_polars_content.html#improving-performance",
    "href": "python/wb_polars_content.html#improving-performance",
    "title": "DataFrames on steroids with Polars",
    "section": "Improving performance",
    "text": "Improving performance\n\nParallel computing\nPython global interpreter lock (GIL) gets in the way of multi-threading.\nLibraries such as Ray, Dask, and Apache Spark allow use of multiple cores and bring dataframes on clusters.\nDask and Spark have APIs for Pandas and Modin makes this even more trivial by providing a drop-in replacement for Pandas on Dask, Spark, and Ray.\nfugue provides a unified interface for distributed computing that works on Spark, Dask, and Ray.\n\n\nAccelerators\nRAPIDS brings dataframes on the GPUs with the cuDF library.\nIntegration with pandas is easy.\n\n\nLazy out-of-core\nVaex exists as an alternative to pandas (no integration).\n\n\nSQL\nStructured query language (SQL) handles relational databases, but the distinction between SQL and dataframe software is getting increasingly blurry with most libraries now able to handle both.\nDuckDB is a very fast and popular option with good integration with pandas.\nMany additional options such as dbt and the snowflake snowpark Python API exist, although integration with pandas is not always as good.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Faster data frames",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_polars_content.html#arrives-polars",
    "href": "python/wb_polars_content.html#arrives-polars",
    "title": "DataFrames on steroids with Polars",
    "section": "Arrives Polars",
    "text": "Arrives Polars\n\nComparison with Pandas\n\n\n\n\nPandas\nPolars\n\n\n\n\nAvailable for\nPython\nRust, Python, R, NodeJS\n\n\nWritten in\nCython\nRust\n\n\nMultithreading\nSome operations\nYes (GIL released)\n\n\nIndex\nRows are indexed\nInteger positions are used\n\n\nEvaluation\nEager only\nLazy and eager\n\n\nQuery optimizer\nNo\nYes\n\n\nOut-of-core\nNo\nYes\n\n\nSIMD vectorization\nYes\nYes\n\n\nData in memory\nWith NumPy arrays\nWith Apache Arrow arrays\n\n\nMemory efficiency\nPoor\nExcellent\n\n\nHandling of missing data\nInconsistent\nConsistent, promotes type stability\n\n\n\n\n\nPolars integration with other tools\nAs good as Pandas‚Äô (except for cuDF, still in development).\n\nWith NumPy: see the documentation, the from_numpy and to_numpy functions, the development progress of this integration, and performance advice.\nParallel computing: with Ray thanks to this setting; with Spark, Dask, and Ray thanks to fugue.\nGPUs: with the cuDF library from RAPIDS (in development).\nSQL: with DuckDB.\n\nThe list is growing fast.\n\n\nBenchmarks\nComparisons between Polars and distributed (Dask, Ray, Spark) or GPU (RAPIDS) libraries aren‚Äôt the most pertinent since they can be used in combination with Polars and the benefits can be combined.\nIt makes most sense to compare Polars with another library occupying the same ‚Äúniche‚Äù such as Pandas or Vaex.\nThe net is full of benchmarks with consistent results: Polars is 3 to 150 times faster than Pandas.\nPandas is trying to fight back: v 2.0 came with optional Arrow support instead of NumPy, then it became the default engine, but performance remains way below that of Polars (e.g.¬†in DataCamp benchmarks, official benchmarks, many blog posts for whole scripts or individual tasks).\nAs for Vaex, it seems twice slower and development has stalled over the past 10 months.\nThe only framework performing better than Polars in some benchmarks is datatable (derived from the R package data.table), but it hasn‚Äôt been developed for 6 months‚Äîa sharp contrast with the fast development of Polars.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Faster data frames",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_polars_content.html#getting-started",
    "href": "python/wb_polars_content.html#getting-started",
    "title": "DataFrames on steroids with Polars",
    "section": "Getting started",
    "text": "Getting started\n\nInstallation\nPersonal computer:\npython -m venv ~/env                  # Create virtual env\nsource ~/env/bin/activate             # Activate virtual env\npip install --upgrade pip             # Update pip\npip install polars                    # Install Polars\n Alliance clusters (polars wheels are available, always prefer wheels when possible):\npython -m venv ~/env                  # Create virtual env\nsource ~/env/bin/activate             # Activate virtual env\npip install --upgrade pip --no-index  # Update pip from wheel\npip install polars --no-index         # Install Polars from wheel\n\n\nSyntax\nThe package is well documented.\nKevin Heavey wrote Modern Polars following the model of the Modern Pandas book. This is a great resource, although getting a little outdated for the scaling chapter since Polars is evolving so fast.\nOverall, the syntax feels somewhat similar to R‚Äôs dplyr from the tidyverse.\n\n\nTable visualization\nWhile Pandas comes with internal capabilities to make publication ready tables, Polars integrates very well with great-tables.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Faster data frames",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_polars_content.html#the-bottom-line",
    "href": "python/wb_polars_content.html#the-bottom-line",
    "title": "DataFrames on steroids with Polars",
    "section": "The bottom line",
    "text": "The bottom line\n\nA rich new field\nAfter years with the one Python option (Pandas), there is currently this exuberant explosion of faster alternatives for dataframes.\nIt might seem confusing and overwhelming, but in fact, the picture seems quite simple.\nFor now, the new memory standard seems to be Apache Arrow and the most efficient library making use of it is Polars.\n\n\nBest performance strategy for software\nThe best strategy thus seems to be at the moment:\n\nSingle machine: Polars.\nCluster: Polars + fugue (example benchmark, documentation of integration).\nGPUs available: Polars + RAPIDS library cuDF (integration coming soon).\nSQL: Polars + DuckDB (documentation of integration).\nOr combination of the above (if cluster with GPUs, etc.).\n\nAs so many libraries are developing an integration with Polars, it is becoming hard to still find reasons to use Pandas.\n\n\nPerformance tips\n\nRead the migration guide: it will help you write Polars code rather than ‚Äúliterally translated‚Äù Pandas code that runs, but doesn‚Äôt make use of Polars‚Äô strengths. The differences in style mostly come from the fact that Polars runs in parallel.\nExecution: lazy where possible.\nFile format: Apache Parquet.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "Faster data frames",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "python/wb_uv.html",
    "href": "python/wb_uv.html",
    "title": "A tool to rule them all:",
    "section": "",
    "text": "Despite being the most popular programming language, Python has never had a good package and version manager. Some languages come with an internal manager (e.g.¬†R, Julia) while others come with well-built command line managers (e.g.¬†Cargo for Rust). Python on the other hand has seen the development of an ever-growing and never-satisfactory suite of tools to manage its packages, versions, projects, and virtual environments: pip, pipx, pipenv, poetry, pyenv, venv, virtualenv to name just a few.\nIn February 2024, Astral might have finally put an end to the jumble when they launched uv, a fast and well-documented tool written in Rust which elegantly handles the gamut of tasks associated with Python versions, packages, and projects.\nIn this webinar, I will show you how to use uv to manage Python projects, packages, virtual environments, versions, and more.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "Python",
      "<em><b>Webinars</b></em>",
      "uv package manager"
    ]
  },
  {
    "objectID": "python/wb_uv_slides.html#a-cluttered-toolkit",
    "href": "python/wb_uv_slides.html#a-cluttered-toolkit",
    "title": "A tool to rule them all",
    "section": "A cluttered toolkit",
    "text": "A cluttered toolkit"
  },
  {
    "objectID": "python/wb_uv_slides.html#age-of-rust",
    "href": "python/wb_uv_slides.html#age-of-rust",
    "title": "A tool to rule them all",
    "section": "Age of Rust",
    "text": "Age of Rust"
  },
  {
    "objectID": "python/wb_uv_slides.html#uv",
    "href": "python/wb_uv_slides.html#uv",
    "title": "A tool to rule them all",
    "section": "uv",
    "text": "uv\n\nUniversal tool\nReally fast\nExcellent dependency resolution with PubGrub (you guessed it, also written in Rust)\nDependency deduplication"
  },
  {
    "objectID": "python/wb_uv_slides.html#python-versions-on-alliance-clusters-uv",
    "href": "python/wb_uv_slides.html#python-versions-on-alliance-clusters-uv",
    "title": "A tool to rule them all",
    "section": "Python versions on Alliance clusters (uv)",
    "text": "Python versions on Alliance clusters (uv)\nUse module\n\nList available Python versions:\n\nmodule spider python\n\nCheck how to load a particular version:\n\nmodule spider python/3.12.4\n\nLoad a particular version:\n\nmodule load python/3.12.4"
  },
  {
    "objectID": "python/wb_uv_slides.html#python-packages-on-alliance-clusters-uv",
    "href": "python/wb_uv_slides.html#python-packages-on-alliance-clusters-uv",
    "title": "A tool to rule them all",
    "section": "Python packages on Alliance clusters (uv)",
    "text": "Python packages on Alliance clusters (uv)\nCreate a Python virtual environment:\npython -m venv ~/env\nActivate it:\nsource ~/env/bin/activate\nUpdate pip from wheel:\npython -m pip install --upgrade pip --no-index\nUse pip with --no-index to use wheels whenever possible:\npython -m pip install --no-index jax[cuda12] jax-ai-stack[grain]"
  },
  {
    "objectID": "python/wb_uv_slides.html#install-uv",
    "href": "python/wb_uv_slides.html#install-uv",
    "title": "A tool to rule them all",
    "section": "Install uv",
    "text": "Install uv"
  },
  {
    "objectID": "python/wb_uv_slides.html#help",
    "href": "python/wb_uv_slides.html#help",
    "title": "A tool to rule them all",
    "section": "Help",
    "text": "Help\nList of commands and options:\nuv\nList of options:\nuv &lt;command&gt; -h    # e.g. uv init -h\nMan page:\nuv help &lt;command&gt;  # e.g. uv help init"
  },
  {
    "objectID": "python/wb_uv_slides.html#drop-in-replacement",
    "href": "python/wb_uv_slides.html#drop-in-replacement",
    "title": "A tool to rule them all",
    "section": "Drop-in replacement",
    "text": "Drop-in replacement\nYou can add uv in front of your usual venv and pip commands\nThis actually runs uv (and neither pip nor venv) so you get the speedup, but it keeps everything compatible"
  },
  {
    "objectID": "python/wb_uv_slides.html#create-a-virtual-env",
    "href": "python/wb_uv_slides.html#create-a-virtual-env",
    "title": "A tool to rule them all",
    "section": "Create a virtual env",
    "text": "Create a virtual env\nuv venv\n\nWith specific Python version:\n\nuv venv --python 3.12\nBy default, the virtual env is called .venv. If you don‚Äôt change its name, uv will use it automatically so you don‚Äôt need to source it"
  },
  {
    "objectID": "python/wb_uv_slides.html#install-packages-in-virtual-env",
    "href": "python/wb_uv_slides.html#install-packages-in-virtual-env",
    "title": "A tool to rule them all",
    "section": "Install packages in virtual env",
    "text": "Install packages in virtual env\nuv pip install jax flax\n\nFrom GitHub repo:\n\nuv pip install \"git+https://github.com/jax-ml/jax\"\nuv pip install \"git+https://github.com/jax-ml/jax@main\"\nuv pip install \"git+https://github.com/jax-ml/jax@766e68c4813a30e29b4fcefaa3253a42d0e197be\"\n\nFrom requirements.txt or pyproject.toml files:\n\nuv pip install -r requirements.txt\nuv pip install -r pyproject.toml"
  },
  {
    "objectID": "python/wb_uv_slides.html#all-your-usual-commands-work",
    "href": "python/wb_uv_slides.html#all-your-usual-commands-work",
    "title": "A tool to rule them all",
    "section": "All your usual commands work",
    "text": "All your usual commands work\nuv pip uninstall jax\nuv pip list\nuv pip freeze\n‚Ä¶"
  },
  {
    "objectID": "python/wb_uv_slides.html#automatic-installation",
    "href": "python/wb_uv_slides.html#automatic-installation",
    "title": "A tool to rule them all",
    "section": "Automatic installation",
    "text": "Automatic installation\nMissing Python versions are automatically installed when required\n\nExample:\n\nuv venv --python 3.12\n\nIf Python 3.12 is missing, uv will install it during the creation of this virtual env"
  },
  {
    "objectID": "python/wb_uv_slides.html#install-python",
    "href": "python/wb_uv_slides.html#install-python",
    "title": "A tool to rule them all",
    "section": "Install Python",
    "text": "Install Python\nPython versions can also be installed explicitly:\nuv python install 3.12.3\nuv python install '&gt;=3.8,&lt;3.10'\n\nSpecific implementations (default is cpython):\n\nuv python install pypy\nuv python install 'pypy&gt;=3.8,&lt;3.10'"
  },
  {
    "objectID": "python/wb_uv_slides.html#manage-versions",
    "href": "python/wb_uv_slides.html#manage-versions",
    "title": "A tool to rule them all",
    "section": "Manage versions",
    "text": "Manage versions\nView installed and available versions:\nuv python list\nUninstall Python version:\nuv python uninstall 3.10\n\nNoe that this is a lot more convenient than pyenv which requires the exact Python version number to uninstall (e.g.¬†pyenv uninstall 3.10.6)"
  },
  {
    "objectID": "python/wb_uv_slides.html#initialize-projects",
    "href": "python/wb_uv_slides.html#initialize-projects",
    "title": "A tool to rule them all",
    "section": "Initialize projects",
    "text": "Initialize projects\nuv init my_project\nInitialized project `my-project` at `/home/marie/my_project`\n\nWith specific Python version:\n\nuv init --python 3.12 my_project\n\nCustomize which files get created:\n\nuv init --no-readme --no-description"
  },
  {
    "objectID": "python/wb_uv_slides.html#project-structure",
    "href": "python/wb_uv_slides.html#project-structure",
    "title": "A tool to rule them all",
    "section": "Project structure",
    "text": "Project structure\n\neza -aT my_project\n\nmy_project\n‚îú‚îÄ‚îÄ .python-version\n‚îú‚îÄ‚îÄ main.py\n‚îú‚îÄ‚îÄ pyproject.toml\n‚îî‚îÄ‚îÄ README.md\n\n\n\nbat -p my_project/pyproject.toml\n\n[project]\nname = \"demo\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nreadme = \"README.md\"\nrequires-python = \"&gt;=3.13\"\ndependencies = [\n    \"matplotlib&gt;=3.10.1\",\n    \"polars&gt;=1.29.0\",\n]"
  },
  {
    "objectID": "python/wb_uv_slides.html#add-dependencies",
    "href": "python/wb_uv_slides.html#add-dependencies",
    "title": "A tool to rule them all",
    "section": "Add dependencies",
    "text": "Add dependencies\nYou need to cd into the project, then you can add dependencies:\ncd my_project\nuv add polars matplotlib\nThis creates a virtual env called .venv and a uv.lock:\neza -aTL 1\n\n\nmy_project\n‚îú‚îÄ‚îÄ .python-version\n‚îú‚îÄ‚îÄ .venv\n‚îú‚îÄ‚îÄ main.py\n‚îú‚îÄ‚îÄ pyproject.toml\n‚îú‚îÄ‚îÄ README.md\n‚îî‚îÄ‚îÄ uv.lock\n\n\nHere again, no need to source the virtual env as long as you use uv"
  },
  {
    "objectID": "python/wb_uv_slides.html#project-file",
    "href": "python/wb_uv_slides.html#project-file",
    "title": "A tool to rule them all",
    "section": "Project file",
    "text": "Project file\nGets populated automatically with dependencies:\nbat -p pyproject.toml\n\n\n[project]\nname = \"demo\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nreadme = \"README.md\"\nrequires-python = \"&gt;=3.13\"\ndependencies = [\n    \"matplotlib&gt;=3.10.1\",\n    \"polars&gt;=1.29.0\",\n]"
  },
  {
    "objectID": "python/wb_uv_slides.html#list-explicitly-installed-dependencies",
    "href": "python/wb_uv_slides.html#list-explicitly-installed-dependencies",
    "title": "A tool to rule them all",
    "section": "List explicitly installed dependencies",
    "text": "List explicitly installed dependencies\nuv tree -d 1\n\n\nResolved 13 packages in 0.74ms\ndemo v0.1.0\n‚îú‚îÄ‚îÄ matplotlib v3.10.1\n‚îî‚îÄ‚îÄ polars v1.29.0"
  },
  {
    "objectID": "python/wb_uv_slides.html#list-all-dependencies",
    "href": "python/wb_uv_slides.html#list-all-dependencies",
    "title": "A tool to rule them all",
    "section": "List all dependencies",
    "text": "List all dependencies\nuv pip list\n\n\nPackage         Version\n--------------- -----------\ncontourpy       1.3.2\ncycler          0.12.1\nfonttools       4.57.0\nkiwisolver      1.4.8\nmatplotlib      3.10.1\nnumpy           2.2.5\npackaging       25.0\npillow          11.2.1\npolars          1.29.0\npyparsing       3.2.3\npython-dateutil 2.9.0.post0\nsix             1.17.0"
  },
  {
    "objectID": "python/wb_uv_slides.html#manage-dependencies",
    "href": "python/wb_uv_slides.html#manage-dependencies",
    "title": "A tool to rule them all",
    "section": "Manage dependencies",
    "text": "Manage dependencies\nUpdate all dependencies in lock file and virtual env:\nuv sync -U\nRemove dependencies:\nuv remove matplotlib"
  },
  {
    "objectID": "python/wb_uv_slides.html#python-versions-pyenv-vs-uv",
    "href": "python/wb_uv_slides.html#python-versions-pyenv-vs-uv",
    "title": "A tool to rule them all",
    "section": "Python versions pyenv vs uv",
    "text": "Python versions pyenv vs uv\npyenv\npyenv install 3.10\n\n\n\n\n\nuv\nuv python install 3.10\nInstalled Python 3.10.17 in 1.49s\n\nYes, uv brags about how fast it installs things‚Ä¶ but it can!"
  },
  {
    "objectID": "python/wb_uv_slides.html#packages-pip-vs-uv-pip",
    "href": "python/wb_uv_slides.html#packages-pip-vs-uv-pip",
    "title": "A tool to rule them all",
    "section": "Packages: pip vs uv pip",
    "text": "Packages: pip vs uv pip\npip\nCreate virtual env:\npython -m venv .venv\nActivate it:\nsource .venv/bin/activate\nUpdate pip:\npython -m pip install --upgrade pip\nInstall package:\npython -m pip install jax-ai-stack"
  },
  {
    "objectID": "python/wb_uv_slides.html#packages-pip-vs-uv-pip-1",
    "href": "python/wb_uv_slides.html#packages-pip-vs-uv-pip-1",
    "title": "A tool to rule them all",
    "section": "Packages: pip vs uv pip",
    "text": "Packages: pip vs uv pip\nuv pip\nCreate virtual env:\nuv venv\n\nI am deleting my entire uv cache to make sure that I am not cheating in the comparison. You normally never do that since the cache prevents deduplication (saves space) and makes installations much faster\nrm -rf ~/.cache/uv\n\nInstall package:\nuv pip install jax-ai-stack"
  },
  {
    "objectID": "python/wb_uv_slides.html#packages-pip-vs-uv-pip-2",
    "href": "python/wb_uv_slides.html#packages-pip-vs-uv-pip-2",
    "title": "A tool to rule them all",
    "section": "Packages: pip vs uv pip",
    "text": "Packages: pip vs uv pip\nuv pip\nTo use the virtual env, I can activate it but I can also access it directly by running commands preceded by uv run\n\nFor instance, I can launch a JupyterLab with access to the project virtual env with:\n\nuv run --with jupyter jupyter lab\n\nor run a script with:\n\nuv run script.py"
  },
  {
    "objectID": "python/wb_uv_slides.html#use-case-virtual-env-with-specific-python-version",
    "href": "python/wb_uv_slides.html#use-case-virtual-env-with-specific-python-version",
    "title": "A tool to rule them all",
    "section": "Use case: virtual env with specific Python version",
    "text": "Use case: virtual env with specific Python version\nI needed to install a number of packages for a deep learning course with JAX, including Grain which still requires Python 3.12\nFollowing are the workflows with classic tools vs uv"
  },
  {
    "objectID": "python/wb_uv_slides.html#pyenv-venv-and-pip",
    "href": "python/wb_uv_slides.html#pyenv-venv-and-pip",
    "title": "A tool to rule them all",
    "section": "pyenv, venv, and pip",
    "text": "pyenv, venv, and pip\nInstall Python 3.12:\npyenv install 3.12\nCreate virtual env with Python 3.12 (requires identifying the path):\n~/.pyenv/versions/3.12.10/bin/python -m venv .venv\nActivate it:\nsource .venv/bin/activate\nUpdate pip:\npython -m pip install --upgrade pip\nInstall packages:\npython -m pip install datasets jax-ai-stack[grain] matplotlib tqdm transformers"
  },
  {
    "objectID": "python/wb_uv_slides.html#uv-2",
    "href": "python/wb_uv_slides.html#uv-2",
    "title": "A tool to rule them all",
    "section": "uv",
    "text": "uv\nuv init --python 3.12 demo\n\nAutomatically installs Python 3.12 if missing\n\ncd demo\nuv add datasets jax-ai-stack[grain] matplotlib tqdm transformers"
  },
  {
    "objectID": "python/wb_uv_slides.html#uv-advantages",
    "href": "python/wb_uv_slides.html#uv-advantages",
    "title": "A tool to rule them all",
    "section": "uv advantages",
    "text": "uv advantages\nMuch simpler\nMuch (much!) faster\nLeaves me with a nice pyproject.toml file:\n[project]\nname = \"fl\"\nversion = \"0.1.0\"\nrequires-python = \"&gt;=3.12\"\ndependencies = [\n    \"datasets&gt;=3.5.0\",\n    \"jax-ai-stack[grain]&gt;=2025.2.5\",\n    \"matplotlib&gt;=3.10.1\",\n    \"tqdm&gt;=4.67.1\",\n    \"transformers&gt;=4.50.3\",\n]\nand a uv.lock file that I can put under version control and share for reproducibility"
  },
  {
    "objectID": "python/wb_uv_slides.html#pipx-replacement",
    "href": "python/wb_uv_slides.html#pipx-replacement",
    "title": "A tool to rule them all",
    "section": "pipx replacement",
    "text": "pipx replacement\nPython tools are packages used for convenience (e.g.¬†linters, formatters) across projects, but not necessary for running your code\nThey are commonly installed via your Linux distribution package manager, Homebrew, or pipx\nThey can also be installed by uv:\nuv tool install ruff"
  },
  {
    "objectID": "python/wb_uv_slides.html#use-tools-without-installation",
    "href": "python/wb_uv_slides.html#use-tools-without-installation",
    "title": "A tool to rule them all",
    "section": "Use tools without installation",
    "text": "Use tools without installation\nTools can even be used without installation (from a temporary install)\nuvx ruff\n\nuvx is an alias for uv tool run"
  },
  {
    "objectID": "python/ws_text.html",
    "href": "python/ws_text.html",
    "title": "Playing with text",
    "section": "",
    "text": "There are fancy tools to scrape the web and play with text. In preparation for those, in this section, we will download a text file from the internet and play with it using simple commands.",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Playing with text"
    ]
  },
  {
    "objectID": "python/ws_text.html#downloading-a-text-file-from-a-url",
    "href": "python/ws_text.html#downloading-a-text-file-from-a-url",
    "title": "Playing with text",
    "section": "Downloading a text file from a URL",
    "text": "Downloading a text file from a URL\nFirst, we need to load the urllib.request module from the Python standard library. It contains functions to deal with URLs:\n\nimport urllib.request\n\nThe snippet of text we will play with is in a text file containing the very beginning of the novel Going Postal by Terry Pratchett and located at the URL https://mint.westdri.ca/python/data/pratchett.txt. We can create a variable that we call url (we can call it whatever we want) and that contains the string of the URL:\n\nurl = \"https://mint.westdri.ca/python/data/pratchett.txt\"\n\n\nprint(url)\n\nhttps://mint.westdri.ca/python/data/pratchett.txt\n\n\n\ntype(url)\n\nstr\n\n\nTo download a text file from a URL, we use the urllib.request.urlopen function:\n\nurllib.request.urlopen(url)\n\n&lt;http.client.HTTPResponse at 0x7a046b59db70&gt;\n\n\nThis return an HTTPResponse object. It is not very useful in this form, but we can get the text out of it by applying the read method:\n\nurllib.request.urlopen(url).read()\n\nb'They say that the prospect of being hanged in the morning concentrates a man\\'s mind wonderfully; unfortunately, what the mind inevitably concentrates on is that, in the morning, it will be in a body that is going to be hanged.\\nThe man going to be hanged had been named Moist von Lipwig by doting if unwise parents, but he was not going to embarrass the name, insofar as that was still possible, by being hung under it. To the world in general, and particularly on that bit of it known as the death warrant, he was Alfred Spangler.\\nAnd he took a more positive approach to the situation and had concentrated his mind on the prospect of not being hanged in the morning, and, most particularly, on the prospect of removing all the crumbling mortar from around a stone in his cell wall with a spoon. So far the work had taken him five weeks and reduced the spoon to something like a nail file. Fortunately, no one ever came to change the bedding here, or else they would have discovered the world\\'s heaviest mattress.\\nIt was a large and heavy stone that was currently the object of his attentions, and, at some point, a huge staple had been hammered into it as an anchor for manacles.\\nMoist sat down facing the wall, gripped the iron ring in both hands, braced his legs against the stones on either side, and heaved.\\nHis shoulders caught fire, and a red mist filled his vision, but the block slid out with a faint and inappropriate tinkling noise. Moist managed to ease it away from the hole and peered inside.\\nAt the far end was another block, and the mortar around it looked suspiciously strong and fresh.\\nJust in front of it was a new spoon. It was shiny.\\nAs he studied it, he heard the clapping behind him. He turned his head, tendons twanging a little riff of agony, and saw several of the wardens watching him through the bars.\\n\"Well done, Mr. Spangler!\" said one of them. \"Ron here owes me five dollars! I told him you were a sticker!! \\'He\\'s a sticker,\\' I said!\"\\n\"You set this up, did you, Mr. Wilkinson?\" said Moist weakly, watching the glint of light on the spoon.\\n\"Oh, not us, sir. Lord Vetinari\\'s orders. He insists that all condemned prisoners should be offered the prospect of freedom.\"\\n\"Freedom? But there\\'s a damn great stone through there!\"\\n\"Yes, there is that, sir, yes, there is that,\" said the warden. \"It\\'s only the prospect, you see. Not actual free freedom as such. Hah, that\\'d be a bit daft, eh?\"\\n\"I suppose so, yes,\" said Moist. He didn\\'t say \"you bastards.\" The wardens had treated him quite civilly these past six weeks, and he made a point of getting on with people. He was very, very good at it. People skills were part of his stock-in-trade; they were nearly the whole of it.\\nBesides, these people had big sticks. So, speaking carefully, he added: \"Some people might consider this cruel, Mr. Wilkinson.\"\\n\"Yes, sir, we asked him about that, sir, but he said no, it wasn\\'t. He said it provided\"--his forehead wrinkled \"--occ-you-pay-shun-all ther-rap-py, healthy exercise, prevented moping, and offered that greatest of all treasures, which is Hope, sir.\"\\n\"Hope,\" muttered Moist glumly.\\n\"Not upset, are you, sir?\"\\n\"Upset? Why should I be upset, Mr. Wilkinson?\"\\n\"Only the last bloke we had in this cell, he managed to get down that drain, sir. Very small man. Very agile.\"\\n'\n\n\nWe can save our text in a new variable:\n\nencoded_text = urllib.request.urlopen(url).read()\n\nNow, encoded_text is not of a very convenient type:\n\ntype(encoded_text)\n\nbytes\n\n\nBefore we can really start playing with it, we want to convert it to a string by decoding it:\n\ntext = encoded_text.decode(\"utf-8\")\ntype(text)\n\nstr\n\n\nWe know have a string, which is great to work on. Let‚Äôs print our text:\n\nprint(text)\n\nThey say that the prospect of being hanged in the morning concentrates a man's mind wonderfully; unfortunately, what the mind inevitably concentrates on is that, in the morning, it will be in a body that is going to be hanged.\nThe man going to be hanged had been named Moist von Lipwig by doting if unwise parents, but he was not going to embarrass the name, insofar as that was still possible, by being hung under it. To the world in general, and particularly on that bit of it known as the death warrant, he was Alfred Spangler.\nAnd he took a more positive approach to the situation and had concentrated his mind on the prospect of not being hanged in the morning, and, most particularly, on the prospect of removing all the crumbling mortar from around a stone in his cell wall with a spoon. So far the work had taken him five weeks and reduced the spoon to something like a nail file. Fortunately, no one ever came to change the bedding here, or else they would have discovered the world's heaviest mattress.\nIt was a large and heavy stone that was currently the object of his attentions, and, at some point, a huge staple had been hammered into it as an anchor for manacles.\nMoist sat down facing the wall, gripped the iron ring in both hands, braced his legs against the stones on either side, and heaved.\nHis shoulders caught fire, and a red mist filled his vision, but the block slid out with a faint and inappropriate tinkling noise. Moist managed to ease it away from the hole and peered inside.\nAt the far end was another block, and the mortar around it looked suspiciously strong and fresh.\nJust in front of it was a new spoon. It was shiny.\nAs he studied it, he heard the clapping behind him. He turned his head, tendons twanging a little riff of agony, and saw several of the wardens watching him through the bars.\n\"Well done, Mr. Spangler!\" said one of them. \"Ron here owes me five dollars! I told him you were a sticker!! 'He's a sticker,' I said!\"\n\"You set this up, did you, Mr. Wilkinson?\" said Moist weakly, watching the glint of light on the spoon.\n\"Oh, not us, sir. Lord Vetinari's orders. He insists that all condemned prisoners should be offered the prospect of freedom.\"\n\"Freedom? But there's a damn great stone through there!\"\n\"Yes, there is that, sir, yes, there is that,\" said the warden. \"It's only the prospect, you see. Not actual free freedom as such. Hah, that'd be a bit daft, eh?\"\n\"I suppose so, yes,\" said Moist. He didn't say \"you bastards.\" The wardens had treated him quite civilly these past six weeks, and he made a point of getting on with people. He was very, very good at it. People skills were part of his stock-in-trade; they were nearly the whole of it.\nBesides, these people had big sticks. So, speaking carefully, he added: \"Some people might consider this cruel, Mr. Wilkinson.\"\n\"Yes, sir, we asked him about that, sir, but he said no, it wasn't. He said it provided\"--his forehead wrinkled \"--occ-you-pay-shun-all ther-rap-py, healthy exercise, prevented moping, and offered that greatest of all treasures, which is Hope, sir.\"\n\"Hope,\" muttered Moist glumly.\n\"Not upset, are you, sir?\"\n\"Upset? Why should I be upset, Mr. Wilkinson?\"\n\"Only the last bloke we had in this cell, he managed to get down that drain, sir. Very small man. Very agile.\"\n\n\n\nAnd now we can start playing with the data üôÇ",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Playing with text"
    ]
  },
  {
    "objectID": "python/ws_text.html#counting-things",
    "href": "python/ws_text.html#counting-things",
    "title": "Playing with text",
    "section": "Counting things",
    "text": "Counting things\nOne of the things we can do with our text is counting things.\n\nCounting characters\nFor instance, we can count the number of characters thanks to the len function:\n\nlen(text)\n\n3294\n\n\nWe can count the number of occurrences of any sequence of character with the method count.\nFor instance, the see how many times the letter ‚Äúe‚Äù appears in the text, we would run:\n\ntext.count(\"e\")\n\n301\n\n\nFor the name of the main character ‚ÄúMoist‚Äù, we would do:\n\ntext.count(\"Moist\")\n\n6\n\n\n\n\nCounting words\nOr we could try to see how many words there are in this text.\n\n\nYour turn:\n\nHow would you go about this?\n\nAnother method to count the number of words is to use the split method:\n\nwords = text.split()\nprint(words)\n\n['They', 'say', 'that', 'the', 'prospect', 'of', 'being', 'hanged', 'in', 'the', 'morning', 'concentrates', 'a', \"man's\", 'mind', 'wonderfully;', 'unfortunately,', 'what', 'the', 'mind', 'inevitably', 'concentrates', 'on', 'is', 'that,', 'in', 'the', 'morning,', 'it', 'will', 'be', 'in', 'a', 'body', 'that', 'is', 'going', 'to', 'be', 'hanged.', 'The', 'man', 'going', 'to', 'be', 'hanged', 'had', 'been', 'named', 'Moist', 'von', 'Lipwig', 'by', 'doting', 'if', 'unwise', 'parents,', 'but', 'he', 'was', 'not', 'going', 'to', 'embarrass', 'the', 'name,', 'insofar', 'as', 'that', 'was', 'still', 'possible,', 'by', 'being', 'hung', 'under', 'it.', 'To', 'the', 'world', 'in', 'general,', 'and', 'particularly', 'on', 'that', 'bit', 'of', 'it', 'known', 'as', 'the', 'death', 'warrant,', 'he', 'was', 'Alfred', 'Spangler.', 'And', 'he', 'took', 'a', 'more', 'positive', 'approach', 'to', 'the', 'situation', 'and', 'had', 'concentrated', 'his', 'mind', 'on', 'the', 'prospect', 'of', 'not', 'being', 'hanged', 'in', 'the', 'morning,', 'and,', 'most', 'particularly,', 'on', 'the', 'prospect', 'of', 'removing', 'all', 'the', 'crumbling', 'mortar', 'from', 'around', 'a', 'stone', 'in', 'his', 'cell', 'wall', 'with', 'a', 'spoon.', 'So', 'far', 'the', 'work', 'had', 'taken', 'him', 'five', 'weeks', 'and', 'reduced', 'the', 'spoon', 'to', 'something', 'like', 'a', 'nail', 'file.', 'Fortunately,', 'no', 'one', 'ever', 'came', 'to', 'change', 'the', 'bedding', 'here,', 'or', 'else', 'they', 'would', 'have', 'discovered', 'the', \"world's\", 'heaviest', 'mattress.', 'It', 'was', 'a', 'large', 'and', 'heavy', 'stone', 'that', 'was', 'currently', 'the', 'object', 'of', 'his', 'attentions,', 'and,', 'at', 'some', 'point,', 'a', 'huge', 'staple', 'had', 'been', 'hammered', 'into', 'it', 'as', 'an', 'anchor', 'for', 'manacles.', 'Moist', 'sat', 'down', 'facing', 'the', 'wall,', 'gripped', 'the', 'iron', 'ring', 'in', 'both', 'hands,', 'braced', 'his', 'legs', 'against', 'the', 'stones', 'on', 'either', 'side,', 'and', 'heaved.', 'His', 'shoulders', 'caught', 'fire,', 'and', 'a', 'red', 'mist', 'filled', 'his', 'vision,', 'but', 'the', 'block', 'slid', 'out', 'with', 'a', 'faint', 'and', 'inappropriate', 'tinkling', 'noise.', 'Moist', 'managed', 'to', 'ease', 'it', 'away', 'from', 'the', 'hole', 'and', 'peered', 'inside.', 'At', 'the', 'far', 'end', 'was', 'another', 'block,', 'and', 'the', 'mortar', 'around', 'it', 'looked', 'suspiciously', 'strong', 'and', 'fresh.', 'Just', 'in', 'front', 'of', 'it', 'was', 'a', 'new', 'spoon.', 'It', 'was', 'shiny.', 'As', 'he', 'studied', 'it,', 'he', 'heard', 'the', 'clapping', 'behind', 'him.', 'He', 'turned', 'his', 'head,', 'tendons', 'twanging', 'a', 'little', 'riff', 'of', 'agony,', 'and', 'saw', 'several', 'of', 'the', 'wardens', 'watching', 'him', 'through', 'the', 'bars.', '\"Well', 'done,', 'Mr.', 'Spangler!\"', 'said', 'one', 'of', 'them.', '\"Ron', 'here', 'owes', 'me', 'five', 'dollars!', 'I', 'told', 'him', 'you', 'were', 'a', 'sticker!!', \"'He's\", 'a', \"sticker,'\", 'I', 'said!\"', '\"You', 'set', 'this', 'up,', 'did', 'you,', 'Mr.', 'Wilkinson?\"', 'said', 'Moist', 'weakly,', 'watching', 'the', 'glint', 'of', 'light', 'on', 'the', 'spoon.', '\"Oh,', 'not', 'us,', 'sir.', 'Lord', \"Vetinari's\", 'orders.', 'He', 'insists', 'that', 'all', 'condemned', 'prisoners', 'should', 'be', 'offered', 'the', 'prospect', 'of', 'freedom.\"', '\"Freedom?', 'But', \"there's\", 'a', 'damn', 'great', 'stone', 'through', 'there!\"', '\"Yes,', 'there', 'is', 'that,', 'sir,', 'yes,', 'there', 'is', 'that,\"', 'said', 'the', 'warden.', '\"It\\'s', 'only', 'the', 'prospect,', 'you', 'see.', 'Not', 'actual', 'free', 'freedom', 'as', 'such.', 'Hah,', \"that'd\", 'be', 'a', 'bit', 'daft,', 'eh?\"', '\"I', 'suppose', 'so,', 'yes,\"', 'said', 'Moist.', 'He', \"didn't\", 'say', '\"you', 'bastards.\"', 'The', 'wardens', 'had', 'treated', 'him', 'quite', 'civilly', 'these', 'past', 'six', 'weeks,', 'and', 'he', 'made', 'a', 'point', 'of', 'getting', 'on', 'with', 'people.', 'He', 'was', 'very,', 'very', 'good', 'at', 'it.', 'People', 'skills', 'were', 'part', 'of', 'his', 'stock-in-trade;', 'they', 'were', 'nearly', 'the', 'whole', 'of', 'it.', 'Besides,', 'these', 'people', 'had', 'big', 'sticks.', 'So,', 'speaking', 'carefully,', 'he', 'added:', '\"Some', 'people', 'might', 'consider', 'this', 'cruel,', 'Mr.', 'Wilkinson.\"', '\"Yes,', 'sir,', 'we', 'asked', 'him', 'about', 'that,', 'sir,', 'but', 'he', 'said', 'no,', 'it', \"wasn't.\", 'He', 'said', 'it', 'provided\"--his', 'forehead', 'wrinkled', '\"--occ-you-pay-shun-all', 'ther-rap-py,', 'healthy', 'exercise,', 'prevented', 'moping,', 'and', 'offered', 'that', 'greatest', 'of', 'all', 'treasures,', 'which', 'is', 'Hope,', 'sir.\"', '\"Hope,\"', 'muttered', 'Moist', 'glumly.', '\"Not', 'upset,', 'are', 'you,', 'sir?\"', '\"Upset?', 'Why', 'should', 'I', 'be', 'upset,', 'Mr.', 'Wilkinson?\"', '\"Only', 'the', 'last', 'bloke', 'we', 'had', 'in', 'this', 'cell,', 'he', 'managed', 'to', 'get', 'down', 'that', 'drain,', 'sir.', 'Very', 'small', 'man.', 'Very', 'agile.\"']\n\n\n\n\nYour turn:\n\nWhat is the type of the variable words?\n\nTo get its length, we can use the len function:\n\nlen(words)\n\n590\n\n\nNow, let‚Äôs try to count how many times the word the is in the text.\n\n\nYour turn:\n\nWe could use:\n\ntext.count(\"the\") + text.count(\"The\")\n\n49\n\n\nbut it won‚Äôt answer our question. Why?\n\nInstead, we should use the list of words that we called words and count how many of them are equal to the. We do this with a loop:\n\n# We set our counter (the number of occurrences) to zero:\noccurrences = 0\n\n# And now we can use a loop to test the words one by one and add 1 to our counter each time the equality returns true\nfor word in words:\n    if word == \"the\" or word == \"The\":\n        occurrences += 1\n\nprint(occurrences)\n\n36\n\n\n\nAn alternative syntax that looks a lot more elegant is the following:\n\nsum(word == \"the\" or word == \"The\" for word in words)\n\n36\n\n\nHowever, elegance and short syntax don‚Äôt necessarily mean fast code.\nWe can benchmark Python code very easy when we use Jupyter or IPython by using the magic %%timeit at the top of a code cell.\nLet‚Äôs try it:\n%%timeit\n\n# We set our counter (the number of occurrences) to zero:\noccurrences = 0\n\n# And now we can use a loop to test the words one by one and add 1 to our counter each time the equality returns true\nfor word in words:\n    if word == \"the\" or word == \"The\":\n        occurrences += 1\n9.52 Œºs ¬± 510 ns per loop (mean ¬± std. dev. of 7 runs, 100,000 loops each)\n\nI removed the print function so that we don‚Äôt end up printing the result a bunch of times: timeit does a lot of tests and takes the average. At each run, we would have a printed result!\n\nAnd for the other method\n%%timeit\n\noccurrences = sum(word == \"the\" or word == \"The\" for word in words)\n24.2 Œºs ¬± 243 ns per loop (mean ¬± std. dev. of 7 runs, 10,000 loops each)\n\nTo make a fair comparison with the previous expression, I am not printing the result here either, but assigning it to a variable.\n\nAs you can see, the short neat-looking expression takes more than twice the time of the not so nice-looking one. Without benchmarking, it is very hard to predict what code is efficient.\n\n\nRemoving punctuation\nNow, let‚Äôs count the number of times the word ‚Äúsir‚Äù occurs in the text:\n\noccurrences = 0\n\nfor word in words:\n    if word == \"sir\" or word == \"Sir\":\n        occurrences += 1\n\nprint(occurrences)\n\n0\n\n\nMmm‚Ä¶ that is strange because, if we read the text, we can see that the word ‚Äúsir‚Äù actually occurs in the text‚Ä¶\nLooking carefully at our list words, we can see what the problem is: the word ‚Äúsir‚Äù appears as sir., sir,, sir.\", sir?\".\nThis shows that in order to do a cleaner job and get our method to work for any word, we need to remove the punctuation.\nStep one, we remove the punctuation from our text string:\n\nimport string\n\nclean_text = text.translate(str.maketrans('', '', string.punctuation))\nprint(clean_text)\n\nThey say that the prospect of being hanged in the morning concentrates a mans mind wonderfully unfortunately what the mind inevitably concentrates on is that in the morning it will be in a body that is going to be hanged\nThe man going to be hanged had been named Moist von Lipwig by doting if unwise parents but he was not going to embarrass the name insofar as that was still possible by being hung under it To the world in general and particularly on that bit of it known as the death warrant he was Alfred Spangler\nAnd he took a more positive approach to the situation and had concentrated his mind on the prospect of not being hanged in the morning and most particularly on the prospect of removing all the crumbling mortar from around a stone in his cell wall with a spoon So far the work had taken him five weeks and reduced the spoon to something like a nail file Fortunately no one ever came to change the bedding here or else they would have discovered the worlds heaviest mattress\nIt was a large and heavy stone that was currently the object of his attentions and at some point a huge staple had been hammered into it as an anchor for manacles\nMoist sat down facing the wall gripped the iron ring in both hands braced his legs against the stones on either side and heaved\nHis shoulders caught fire and a red mist filled his vision but the block slid out with a faint and inappropriate tinkling noise Moist managed to ease it away from the hole and peered inside\nAt the far end was another block and the mortar around it looked suspiciously strong and fresh\nJust in front of it was a new spoon It was shiny\nAs he studied it he heard the clapping behind him He turned his head tendons twanging a little riff of agony and saw several of the wardens watching him through the bars\nWell done Mr Spangler said one of them Ron here owes me five dollars I told him you were a sticker Hes a sticker I said\nYou set this up did you Mr Wilkinson said Moist weakly watching the glint of light on the spoon\nOh not us sir Lord Vetinaris orders He insists that all condemned prisoners should be offered the prospect of freedom\nFreedom But theres a damn great stone through there\nYes there is that sir yes there is that said the warden Its only the prospect you see Not actual free freedom as such Hah thatd be a bit daft eh\nI suppose so yes said Moist He didnt say you bastards The wardens had treated him quite civilly these past six weeks and he made a point of getting on with people He was very very good at it People skills were part of his stockintrade they were nearly the whole of it\nBesides these people had big sticks So speaking carefully he added Some people might consider this cruel Mr Wilkinson\nYes sir we asked him about that sir but he said no it wasnt He said it providedhis forehead wrinkled occyoupayshunall therrappy healthy exercise prevented moping and offered that greatest of all treasures which is Hope sir\nHope muttered Moist glumly\nNot upset are you sir\nUpset Why should I be upset Mr Wilkinson\nOnly the last bloke we had in this cell he managed to get down that drain sir Very small man Very agile\n\n\n\nAnd now we split it into words:\n\nclean_words = clean_text.split()\nprint(clean_words)\n\n['They', 'say', 'that', 'the', 'prospect', 'of', 'being', 'hanged', 'in', 'the', 'morning', 'concentrates', 'a', 'mans', 'mind', 'wonderfully', 'unfortunately', 'what', 'the', 'mind', 'inevitably', 'concentrates', 'on', 'is', 'that', 'in', 'the', 'morning', 'it', 'will', 'be', 'in', 'a', 'body', 'that', 'is', 'going', 'to', 'be', 'hanged', 'The', 'man', 'going', 'to', 'be', 'hanged', 'had', 'been', 'named', 'Moist', 'von', 'Lipwig', 'by', 'doting', 'if', 'unwise', 'parents', 'but', 'he', 'was', 'not', 'going', 'to', 'embarrass', 'the', 'name', 'insofar', 'as', 'that', 'was', 'still', 'possible', 'by', 'being', 'hung', 'under', 'it', 'To', 'the', 'world', 'in', 'general', 'and', 'particularly', 'on', 'that', 'bit', 'of', 'it', 'known', 'as', 'the', 'death', 'warrant', 'he', 'was', 'Alfred', 'Spangler', 'And', 'he', 'took', 'a', 'more', 'positive', 'approach', 'to', 'the', 'situation', 'and', 'had', 'concentrated', 'his', 'mind', 'on', 'the', 'prospect', 'of', 'not', 'being', 'hanged', 'in', 'the', 'morning', 'and', 'most', 'particularly', 'on', 'the', 'prospect', 'of', 'removing', 'all', 'the', 'crumbling', 'mortar', 'from', 'around', 'a', 'stone', 'in', 'his', 'cell', 'wall', 'with', 'a', 'spoon', 'So', 'far', 'the', 'work', 'had', 'taken', 'him', 'five', 'weeks', 'and', 'reduced', 'the', 'spoon', 'to', 'something', 'like', 'a', 'nail', 'file', 'Fortunately', 'no', 'one', 'ever', 'came', 'to', 'change', 'the', 'bedding', 'here', 'or', 'else', 'they', 'would', 'have', 'discovered', 'the', 'worlds', 'heaviest', 'mattress', 'It', 'was', 'a', 'large', 'and', 'heavy', 'stone', 'that', 'was', 'currently', 'the', 'object', 'of', 'his', 'attentions', 'and', 'at', 'some', 'point', 'a', 'huge', 'staple', 'had', 'been', 'hammered', 'into', 'it', 'as', 'an', 'anchor', 'for', 'manacles', 'Moist', 'sat', 'down', 'facing', 'the', 'wall', 'gripped', 'the', 'iron', 'ring', 'in', 'both', 'hands', 'braced', 'his', 'legs', 'against', 'the', 'stones', 'on', 'either', 'side', 'and', 'heaved', 'His', 'shoulders', 'caught', 'fire', 'and', 'a', 'red', 'mist', 'filled', 'his', 'vision', 'but', 'the', 'block', 'slid', 'out', 'with', 'a', 'faint', 'and', 'inappropriate', 'tinkling', 'noise', 'Moist', 'managed', 'to', 'ease', 'it', 'away', 'from', 'the', 'hole', 'and', 'peered', 'inside', 'At', 'the', 'far', 'end', 'was', 'another', 'block', 'and', 'the', 'mortar', 'around', 'it', 'looked', 'suspiciously', 'strong', 'and', 'fresh', 'Just', 'in', 'front', 'of', 'it', 'was', 'a', 'new', 'spoon', 'It', 'was', 'shiny', 'As', 'he', 'studied', 'it', 'he', 'heard', 'the', 'clapping', 'behind', 'him', 'He', 'turned', 'his', 'head', 'tendons', 'twanging', 'a', 'little', 'riff', 'of', 'agony', 'and', 'saw', 'several', 'of', 'the', 'wardens', 'watching', 'him', 'through', 'the', 'bars', 'Well', 'done', 'Mr', 'Spangler', 'said', 'one', 'of', 'them', 'Ron', 'here', 'owes', 'me', 'five', 'dollars', 'I', 'told', 'him', 'you', 'were', 'a', 'sticker', 'Hes', 'a', 'sticker', 'I', 'said', 'You', 'set', 'this', 'up', 'did', 'you', 'Mr', 'Wilkinson', 'said', 'Moist', 'weakly', 'watching', 'the', 'glint', 'of', 'light', 'on', 'the', 'spoon', 'Oh', 'not', 'us', 'sir', 'Lord', 'Vetinaris', 'orders', 'He', 'insists', 'that', 'all', 'condemned', 'prisoners', 'should', 'be', 'offered', 'the', 'prospect', 'of', 'freedom', 'Freedom', 'But', 'theres', 'a', 'damn', 'great', 'stone', 'through', 'there', 'Yes', 'there', 'is', 'that', 'sir', 'yes', 'there', 'is', 'that', 'said', 'the', 'warden', 'Its', 'only', 'the', 'prospect', 'you', 'see', 'Not', 'actual', 'free', 'freedom', 'as', 'such', 'Hah', 'thatd', 'be', 'a', 'bit', 'daft', 'eh', 'I', 'suppose', 'so', 'yes', 'said', 'Moist', 'He', 'didnt', 'say', 'you', 'bastards', 'The', 'wardens', 'had', 'treated', 'him', 'quite', 'civilly', 'these', 'past', 'six', 'weeks', 'and', 'he', 'made', 'a', 'point', 'of', 'getting', 'on', 'with', 'people', 'He', 'was', 'very', 'very', 'good', 'at', 'it', 'People', 'skills', 'were', 'part', 'of', 'his', 'stockintrade', 'they', 'were', 'nearly', 'the', 'whole', 'of', 'it', 'Besides', 'these', 'people', 'had', 'big', 'sticks', 'So', 'speaking', 'carefully', 'he', 'added', 'Some', 'people', 'might', 'consider', 'this', 'cruel', 'Mr', 'Wilkinson', 'Yes', 'sir', 'we', 'asked', 'him', 'about', 'that', 'sir', 'but', 'he', 'said', 'no', 'it', 'wasnt', 'He', 'said', 'it', 'providedhis', 'forehead', 'wrinkled', 'occyoupayshunall', 'therrappy', 'healthy', 'exercise', 'prevented', 'moping', 'and', 'offered', 'that', 'greatest', 'of', 'all', 'treasures', 'which', 'is', 'Hope', 'sir', 'Hope', 'muttered', 'Moist', 'glumly', 'Not', 'upset', 'are', 'you', 'sir', 'Upset', 'Why', 'should', 'I', 'be', 'upset', 'Mr', 'Wilkinson', 'Only', 'the', 'last', 'bloke', 'we', 'had', 'in', 'this', 'cell', 'he', 'managed', 'to', 'get', 'down', 'that', 'drain', 'sir', 'Very', 'small', 'man', 'Very', 'agile']\n\n\nThis is a much better list to work from and this one will work for any word. For the word ‚Äúsir‚Äù for instance, we would do:\n\noccurrences = 0\n\nfor word in clean_words:\n    if word == \"sir\" or word == \"Sir\":\n        occurrences += 1\n\nprint(occurrences)\n\n7\n\n\n\n\nRemoving case\nNow, having to look for the word of interest with and without capital letter as we have been doing so far is not the most robust method: what if the text had ‚ÄúSIR‚Äù in all caps? After all, Death in Pratchett novels speaks in all caps! Of course, we could add this as a third option (if word == \"sir\" or word == \"Sir\" or word == \"SIR\"), but that is becoming a little tedious.\nA better solution is to turn the whole text into lower case before splitting it into words. That way we don‚Äôt have to worry about case.\nLet‚Äôs remove all capital letters:\n\nfinal_text = clean_text.lower()\n\nNow we split it into words:\n\nfinal_words = final_text.split()\nprint(final_words)\n\n['they', 'say', 'that', 'the', 'prospect', 'of', 'being', 'hanged', 'in', 'the', 'morning', 'concentrates', 'a', 'mans', 'mind', 'wonderfully', 'unfortunately', 'what', 'the', 'mind', 'inevitably', 'concentrates', 'on', 'is', 'that', 'in', 'the', 'morning', 'it', 'will', 'be', 'in', 'a', 'body', 'that', 'is', 'going', 'to', 'be', 'hanged', 'the', 'man', 'going', 'to', 'be', 'hanged', 'had', 'been', 'named', 'moist', 'von', 'lipwig', 'by', 'doting', 'if', 'unwise', 'parents', 'but', 'he', 'was', 'not', 'going', 'to', 'embarrass', 'the', 'name', 'insofar', 'as', 'that', 'was', 'still', 'possible', 'by', 'being', 'hung', 'under', 'it', 'to', 'the', 'world', 'in', 'general', 'and', 'particularly', 'on', 'that', 'bit', 'of', 'it', 'known', 'as', 'the', 'death', 'warrant', 'he', 'was', 'alfred', 'spangler', 'and', 'he', 'took', 'a', 'more', 'positive', 'approach', 'to', 'the', 'situation', 'and', 'had', 'concentrated', 'his', 'mind', 'on', 'the', 'prospect', 'of', 'not', 'being', 'hanged', 'in', 'the', 'morning', 'and', 'most', 'particularly', 'on', 'the', 'prospect', 'of', 'removing', 'all', 'the', 'crumbling', 'mortar', 'from', 'around', 'a', 'stone', 'in', 'his', 'cell', 'wall', 'with', 'a', 'spoon', 'so', 'far', 'the', 'work', 'had', 'taken', 'him', 'five', 'weeks', 'and', 'reduced', 'the', 'spoon', 'to', 'something', 'like', 'a', 'nail', 'file', 'fortunately', 'no', 'one', 'ever', 'came', 'to', 'change', 'the', 'bedding', 'here', 'or', 'else', 'they', 'would', 'have', 'discovered', 'the', 'worlds', 'heaviest', 'mattress', 'it', 'was', 'a', 'large', 'and', 'heavy', 'stone', 'that', 'was', 'currently', 'the', 'object', 'of', 'his', 'attentions', 'and', 'at', 'some', 'point', 'a', 'huge', 'staple', 'had', 'been', 'hammered', 'into', 'it', 'as', 'an', 'anchor', 'for', 'manacles', 'moist', 'sat', 'down', 'facing', 'the', 'wall', 'gripped', 'the', 'iron', 'ring', 'in', 'both', 'hands', 'braced', 'his', 'legs', 'against', 'the', 'stones', 'on', 'either', 'side', 'and', 'heaved', 'his', 'shoulders', 'caught', 'fire', 'and', 'a', 'red', 'mist', 'filled', 'his', 'vision', 'but', 'the', 'block', 'slid', 'out', 'with', 'a', 'faint', 'and', 'inappropriate', 'tinkling', 'noise', 'moist', 'managed', 'to', 'ease', 'it', 'away', 'from', 'the', 'hole', 'and', 'peered', 'inside', 'at', 'the', 'far', 'end', 'was', 'another', 'block', 'and', 'the', 'mortar', 'around', 'it', 'looked', 'suspiciously', 'strong', 'and', 'fresh', 'just', 'in', 'front', 'of', 'it', 'was', 'a', 'new', 'spoon', 'it', 'was', 'shiny', 'as', 'he', 'studied', 'it', 'he', 'heard', 'the', 'clapping', 'behind', 'him', 'he', 'turned', 'his', 'head', 'tendons', 'twanging', 'a', 'little', 'riff', 'of', 'agony', 'and', 'saw', 'several', 'of', 'the', 'wardens', 'watching', 'him', 'through', 'the', 'bars', 'well', 'done', 'mr', 'spangler', 'said', 'one', 'of', 'them', 'ron', 'here', 'owes', 'me', 'five', 'dollars', 'i', 'told', 'him', 'you', 'were', 'a', 'sticker', 'hes', 'a', 'sticker', 'i', 'said', 'you', 'set', 'this', 'up', 'did', 'you', 'mr', 'wilkinson', 'said', 'moist', 'weakly', 'watching', 'the', 'glint', 'of', 'light', 'on', 'the', 'spoon', 'oh', 'not', 'us', 'sir', 'lord', 'vetinaris', 'orders', 'he', 'insists', 'that', 'all', 'condemned', 'prisoners', 'should', 'be', 'offered', 'the', 'prospect', 'of', 'freedom', 'freedom', 'but', 'theres', 'a', 'damn', 'great', 'stone', 'through', 'there', 'yes', 'there', 'is', 'that', 'sir', 'yes', 'there', 'is', 'that', 'said', 'the', 'warden', 'its', 'only', 'the', 'prospect', 'you', 'see', 'not', 'actual', 'free', 'freedom', 'as', 'such', 'hah', 'thatd', 'be', 'a', 'bit', 'daft', 'eh', 'i', 'suppose', 'so', 'yes', 'said', 'moist', 'he', 'didnt', 'say', 'you', 'bastards', 'the', 'wardens', 'had', 'treated', 'him', 'quite', 'civilly', 'these', 'past', 'six', 'weeks', 'and', 'he', 'made', 'a', 'point', 'of', 'getting', 'on', 'with', 'people', 'he', 'was', 'very', 'very', 'good', 'at', 'it', 'people', 'skills', 'were', 'part', 'of', 'his', 'stockintrade', 'they', 'were', 'nearly', 'the', 'whole', 'of', 'it', 'besides', 'these', 'people', 'had', 'big', 'sticks', 'so', 'speaking', 'carefully', 'he', 'added', 'some', 'people', 'might', 'consider', 'this', 'cruel', 'mr', 'wilkinson', 'yes', 'sir', 'we', 'asked', 'him', 'about', 'that', 'sir', 'but', 'he', 'said', 'no', 'it', 'wasnt', 'he', 'said', 'it', 'providedhis', 'forehead', 'wrinkled', 'occyoupayshunall', 'therrappy', 'healthy', 'exercise', 'prevented', 'moping', 'and', 'offered', 'that', 'greatest', 'of', 'all', 'treasures', 'which', 'is', 'hope', 'sir', 'hope', 'muttered', 'moist', 'glumly', 'not', 'upset', 'are', 'you', 'sir', 'upset', 'why', 'should', 'i', 'be', 'upset', 'mr', 'wilkinson', 'only', 'the', 'last', 'bloke', 'we', 'had', 'in', 'this', 'cell', 'he', 'managed', 'to', 'get', 'down', 'that', 'drain', 'sir', 'very', 'small', 'man', 'very', 'agile']\n\n\n\n\nYour turn:\n\nWhat would the code look like now to count the number of times the word ‚Äúsir‚Äù appears?\n\n\n\n\nCounting unique words\nYet something else we can count is the number of unique words in the text. The simplest way to do this is to turn our list of words into a set and see how many elements this set contains:\n\nlen(set(final_words))\n\n292",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Playing with text"
    ]
  },
  {
    "objectID": "python/ws_text.html#extracting-characters-from-strings",
    "href": "python/ws_text.html#extracting-characters-from-strings",
    "title": "Playing with text",
    "section": "Extracting characters from strings",
    "text": "Extracting characters from strings\n\nIndexing\nLet‚Äôs go back to our text. Remember that we have this object text which is a list.\n\ntype(text)\n\nstr\n\n\nYou can extract characters from strings by indexing.\nIndexing in Python is done with square brackets and starts at 0 (the first element has index 0). This means that we can extract the first character with:\n\nprint(text[0])\n\nT\n\n\n\n\nYour turn:\n\nHow would you index the 4th element? Try it out. It should return ‚Äúy‚Äù.\n\nYou can extract the last element with a minus sign (and this time, the indexing starts at 1):\n\nprint(text[-1])\n\n\n\n\n\nWe aren‚Äôt getting any output here because the last character is the special character \\n which encodes for a line break. You can see it when you don‚Äôt use the print function (print makes things look nicer and transforms those characters into what they represent):\n\ntext[-1]\n\n'\\n'\n\n\n\n\nYour turn:\n\nQuestion 1:\nHow would you get the last letter of the text?\nQuestion 2:\nHow would you index the 11th element from the end? Give it a try. You should get ‚ÄúV‚Äù.\n\n\n\nSlicing\nYou can also extract multiple contiguous elements with a slice. A slice is also defined with square brackets, but this time you add a colon in it. Left of the colon is the start of the slice and right of the colon is the end of the slice.\nIn Python, the left element of a slice is included, but the right element is excluded.\nFirst, let‚Äôs omit both indices on either side of the colon:\n\nprint(text[:])\n\nThey say that the prospect of being hanged in the morning concentrates a man's mind wonderfully; unfortunately, what the mind inevitably concentrates on is that, in the morning, it will be in a body that is going to be hanged.\nThe man going to be hanged had been named Moist von Lipwig by doting if unwise parents, but he was not going to embarrass the name, insofar as that was still possible, by being hung under it. To the world in general, and particularly on that bit of it known as the death warrant, he was Alfred Spangler.\nAnd he took a more positive approach to the situation and had concentrated his mind on the prospect of not being hanged in the morning, and, most particularly, on the prospect of removing all the crumbling mortar from around a stone in his cell wall with a spoon. So far the work had taken him five weeks and reduced the spoon to something like a nail file. Fortunately, no one ever came to change the bedding here, or else they would have discovered the world's heaviest mattress.\nIt was a large and heavy stone that was currently the object of his attentions, and, at some point, a huge staple had been hammered into it as an anchor for manacles.\nMoist sat down facing the wall, gripped the iron ring in both hands, braced his legs against the stones on either side, and heaved.\nHis shoulders caught fire, and a red mist filled his vision, but the block slid out with a faint and inappropriate tinkling noise. Moist managed to ease it away from the hole and peered inside.\nAt the far end was another block, and the mortar around it looked suspiciously strong and fresh.\nJust in front of it was a new spoon. It was shiny.\nAs he studied it, he heard the clapping behind him. He turned his head, tendons twanging a little riff of agony, and saw several of the wardens watching him through the bars.\n\"Well done, Mr. Spangler!\" said one of them. \"Ron here owes me five dollars! I told him you were a sticker!! 'He's a sticker,' I said!\"\n\"You set this up, did you, Mr. Wilkinson?\" said Moist weakly, watching the glint of light on the spoon.\n\"Oh, not us, sir. Lord Vetinari's orders. He insists that all condemned prisoners should be offered the prospect of freedom.\"\n\"Freedom? But there's a damn great stone through there!\"\n\"Yes, there is that, sir, yes, there is that,\" said the warden. \"It's only the prospect, you see. Not actual free freedom as such. Hah, that'd be a bit daft, eh?\"\n\"I suppose so, yes,\" said Moist. He didn't say \"you bastards.\" The wardens had treated him quite civilly these past six weeks, and he made a point of getting on with people. He was very, very good at it. People skills were part of his stock-in-trade; they were nearly the whole of it.\nBesides, these people had big sticks. So, speaking carefully, he added: \"Some people might consider this cruel, Mr. Wilkinson.\"\n\"Yes, sir, we asked him about that, sir, but he said no, it wasn't. He said it provided\"--his forehead wrinkled \"--occ-you-pay-shun-all ther-rap-py, healthy exercise, prevented moping, and offered that greatest of all treasures, which is Hope, sir.\"\n\"Hope,\" muttered Moist glumly.\n\"Not upset, are you, sir?\"\n\"Upset? Why should I be upset, Mr. Wilkinson?\"\n\"Only the last bloke we had in this cell, he managed to get down that drain, sir. Very small man. Very agile.\"\n\n\n\nThis returns the full text. This is because when a slice boundary is omitted, by default it starts at the very beginning of the object you are slicing.\nWe can test that we indeed get the full text by comparing it to the non-sliced version of text:\n\ntext[:] == text\n\nTrue\n\n\nNow, let‚Äôs slice the first 10 elements of text:\n\nprint(text[:10])\n\nThey say t\n\n\n\nLet‚Äôs explain this code a bit:\nWe want our slice to start at the beginning of the text, so we are omitting that boundary (we could also use 0 left of the colon).\nBecause indexing starts at 0, the 10th element is actually not ‚Äút‚Äù, but the following ‚Äúh‚Äù. The reason we get ‚Äút‚Äù rather than ‚Äúh‚Äù is because the right boundary of a slice is excluded.\n\n\n\nYour turn:\n\nQuestion 1:\nTry to write some code that will return ‚Äúprospect‚Äù.\n\n\n\nQuestion 2:\nNow, remember how we created the words object earlier? Try to use it to get the same result.\n\n\n\n\n\n\nStriding\nA last way to extract characters out of a string is to use strides. A stride is defined with square brackets and 3 values separated by colons. The first value is the left boundary (included), the second value is the right boundary (excluded), and the third value is the step. By default (if omitted), the step is 1.\n\n\nYour turn:\n\nQuestion 1:\nWhat do you think that text[::] would return?\nQuestion 2:\nHow would you test it?\nQuestion 3:\nHow would you get every 3rd character of the whole text?\n\nNow, a fun one: the step can also take a negative value. With -1, we get the text backward! This is because - indicates that we want to step from the end and 1 means that we want every character:\n\nprint(text[::-1])\n\n\n\".eliga yreV .nam llams yreV .ris ,niard taht nwod teg ot deganam eh ,llec siht ni dah ew ekolb tsal eht ylnO\"\n\"?nosnikliW .rM ,tespu eb I dluohs yhW ?tespU\"\n\"?ris ,uoy era ,tespu toN\"\n.ylmulg tsioM derettum \",epoH\"\n\".ris ,epoH si hcihw ,serusaert lla fo tsetaerg taht dereffo dna ,gnipom detneverp ,esicrexe yhtlaeh ,yp-par-reht lla-nuhs-yap-uoy-cco--\" delknirw daeherof sih--\"dedivorp ti dias eH .t'nsaw ti ,on dias eh tub ,ris ,taht tuoba mih deksa ew ,ris ,seY\"\n\".nosnikliW .rM ,leurc siht redisnoc thgim elpoep emoS\" :dedda eh ,ylluferac gnikaeps ,oS .skcits gib dah elpoep eseht ,sediseB\n.ti fo elohw eht ylraen erew yeht ;edart-ni-kcots sih fo trap erew slliks elpoeP .ti ta doog yrev ,yrev saw eH .elpoep htiw no gnitteg fo tniop a edam eh dna ,skeew xis tsap eseht yllivic etiuq mih detaert dah snedraw ehT \".sdratsab uoy\" yas t'ndid eH .tsioM dias \",sey ,os esoppus I\"\n\"?he ,tfad tib a eb d'taht ,haH .hcus sa modeerf eerf lautca toN .ees uoy ,tcepsorp eht ylno s'tI\" .nedraw eht dias \",taht si ereht ,sey ,ris ,taht si ereht ,seY\"\n\"!ereht hguorht enots taerg nmad a s'ereht tuB ?modeerF\"\n\".modeerf fo tcepsorp eht dereffo eb dluohs srenosirp denmednoc lla taht stsisni eH .sredro s'iraniteV droL .ris ,su ton ,hO\"\n.noops eht no thgil fo tnilg eht gnihctaw ,ylkaew tsioM dias \"?nosnikliW .rM ,uoy did ,pu siht tes uoY\"\n\"!dias I ',rekcits a s'eH' !!rekcits a erew uoy mih dlot I !srallod evif em sewo ereh noR\" .meht fo eno dias \"!relgnapS .rM ,enod lleW\"\n.srab eht hguorht mih gnihctaw snedraw eht fo lareves was dna ,ynoga fo ffir elttil a gnignawt snodnet ,daeh sih denrut eH .mih dniheb gnippalc eht draeh eh ,ti deiduts eh sA\n.ynihs saw tI .noops wen a saw ti fo tnorf ni tsuJ\n.hserf dna gnorts ylsuoicipsus dekool ti dnuora ratrom eht dna ,kcolb rehtona saw dne raf eht tA\n.edisni dereep dna eloh eht morf yawa ti esae ot deganam tsioM .esion gnilknit etairporppani dna tniaf a htiw tuo dils kcolb eht tub ,noisiv sih dellif tsim der a dna ,erif thguac sredluohs siH\n.devaeh dna ,edis rehtie no senots eht tsniaga sgel sih decarb ,sdnah htob ni gnir nori eht deppirg ,llaw eht gnicaf nwod tas tsioM\n.selcanam rof rohcna na sa ti otni deremmah neeb dah elpats eguh a ,tniop emos ta ,dna ,snoitnetta sih fo tcejbo eht yltnerruc saw taht enots yvaeh dna egral a saw tI\n.sserttam tseivaeh s'dlrow eht derevocsid evah dluow yeht esle ro ,ereh gniddeb eht egnahc ot emac reve eno on ,yletanutroF .elif lian a ekil gnihtemos ot noops eht decuder dna skeew evif mih nekat dah krow eht raf oS .noops a htiw llaw llec sih ni enots a dnuora morf ratrom gnilbmurc eht lla gnivomer fo tcepsorp eht no ,ylralucitrap tsom ,dna ,gninrom eht ni degnah gnieb ton fo tcepsorp eht no dnim sih detartnecnoc dah dna noitautis eht ot hcaorppa evitisop erom a koot eh dnA\n.relgnapS derflA saw eh ,tnarraw htaed eht sa nwonk ti fo tib taht no ylralucitrap dna ,lareneg ni dlrow eht oT .ti rednu gnuh gnieb yb ,elbissop llits saw taht sa rafosni ,eman eht ssarrabme ot gniog ton saw eh tub ,stnerap esiwnu fi gnitod yb giwpiL nov tsioM deman neeb dah degnah eb ot gniog nam ehT\n.degnah eb ot gniog si taht ydob a ni eb lliw ti ,gninrom eht ni ,taht si no setartnecnoc ylbativeni dnim eht tahw ,yletanutrofnu ;yllufrednow dnim s'nam a setartnecnoc gninrom eht ni degnah gnieb fo tcepsorp eht taht yas yehT",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Playing with text"
    ]
  },
  {
    "objectID": "python/ws_text.html#string-concatenation",
    "href": "python/ws_text.html#string-concatenation",
    "title": "Playing with text",
    "section": "String concatenation",
    "text": "String concatenation\nStrings are fun because they can be concatenated with the operator +:\n\nprint(\"This is the beginning of Going Postal:\" + \"\\n\\n\" + text)\n\nThis is the beginning of Going Postal:\n\nThey say that the prospect of being hanged in the morning concentrates a man's mind wonderfully; unfortunately, what the mind inevitably concentrates on is that, in the morning, it will be in a body that is going to be hanged.\nThe man going to be hanged had been named Moist von Lipwig by doting if unwise parents, but he was not going to embarrass the name, insofar as that was still possible, by being hung under it. To the world in general, and particularly on that bit of it known as the death warrant, he was Alfred Spangler.\nAnd he took a more positive approach to the situation and had concentrated his mind on the prospect of not being hanged in the morning, and, most particularly, on the prospect of removing all the crumbling mortar from around a stone in his cell wall with a spoon. So far the work had taken him five weeks and reduced the spoon to something like a nail file. Fortunately, no one ever came to change the bedding here, or else they would have discovered the world's heaviest mattress.\nIt was a large and heavy stone that was currently the object of his attentions, and, at some point, a huge staple had been hammered into it as an anchor for manacles.\nMoist sat down facing the wall, gripped the iron ring in both hands, braced his legs against the stones on either side, and heaved.\nHis shoulders caught fire, and a red mist filled his vision, but the block slid out with a faint and inappropriate tinkling noise. Moist managed to ease it away from the hole and peered inside.\nAt the far end was another block, and the mortar around it looked suspiciously strong and fresh.\nJust in front of it was a new spoon. It was shiny.\nAs he studied it, he heard the clapping behind him. He turned his head, tendons twanging a little riff of agony, and saw several of the wardens watching him through the bars.\n\"Well done, Mr. Spangler!\" said one of them. \"Ron here owes me five dollars! I told him you were a sticker!! 'He's a sticker,' I said!\"\n\"You set this up, did you, Mr. Wilkinson?\" said Moist weakly, watching the glint of light on the spoon.\n\"Oh, not us, sir. Lord Vetinari's orders. He insists that all condemned prisoners should be offered the prospect of freedom.\"\n\"Freedom? But there's a damn great stone through there!\"\n\"Yes, there is that, sir, yes, there is that,\" said the warden. \"It's only the prospect, you see. Not actual free freedom as such. Hah, that'd be a bit daft, eh?\"\n\"I suppose so, yes,\" said Moist. He didn't say \"you bastards.\" The wardens had treated him quite civilly these past six weeks, and he made a point of getting on with people. He was very, very good at it. People skills were part of his stock-in-trade; they were nearly the whole of it.\nBesides, these people had big sticks. So, speaking carefully, he added: \"Some people might consider this cruel, Mr. Wilkinson.\"\n\"Yes, sir, we asked him about that, sir, but he said no, it wasn't. He said it provided\"--his forehead wrinkled \"--occ-you-pay-shun-all ther-rap-py, healthy exercise, prevented moping, and offered that greatest of all treasures, which is Hope, sir.\"\n\"Hope,\" muttered Moist glumly.\n\"Not upset, are you, sir?\"\n\"Upset? Why should I be upset, Mr. Wilkinson?\"\n\"Only the last bloke we had in this cell, he managed to get down that drain, sir. Very small man. Very agile.\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf you want to go much beyond this (e.g.¬†sentences tokenization, natural language processing (NLP), etc.), you probably want to install a library for this such as NLTK or spaCy.",
    "crumbs": [
      "Python",
      "<em><b>Workshops</b></em>",
      "Playing with text"
    ]
  },
  {
    "objectID": "r/hpc_clusters.html",
    "href": "r/hpc_clusters.html",
    "title": "R on HPC clusters",
    "section": "",
    "text": "In this section, you will learn how to use R on an Alliance cluster: load modules, install packages, and run jobs.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "R on HPC clusters"
    ]
  },
  {
    "objectID": "r/hpc_clusters.html#modules",
    "href": "r/hpc_clusters.html#modules",
    "title": "R on HPC clusters",
    "section": "Modules",
    "text": "Modules\nOn the Alliance clusters, a number of utilities are available right away (e.g.¬†Bash utilities, git, tmux, various text editors). Before you can use more specialized software however, you have to load the module corresponding to the version of your choice as well as any potential dependencies.\n\nModules already loaded\nTo see the list of loaded modules, run:\nmodule list\nAs you can see, some modules get loaded by default.\n\n\nR\nFirst, of course, we need an R module.\nTo see which versions of R are available on a cluster, run:\nmodule spider r\nTo see the dependencies of a particular version (e.g.¬†r/4.5.0), run:\nmodule spider r/4.5.0\nThis shows us that we need StdEnv/2023 to load r/4.5.0.\n\n\nYour turn:\n\nCheck whether StdEnv/2023 is already loaded or whether we need to load it.\n\n\n\nC compiler\nIf you plan on installing any R package, you will also need a C compiler.\nIn theory, one could use the proprietary Intel compiler which is loaded by default on the Alliance clusters, but it is recommended to replace it with the GCC compiler (R packages can be compiled by any C compiler‚Äîalso including Clang and LLVM‚Äîbut the default GCC compiler is the best way to avoid headaches).\n\n\nYour turn:\n\n\nHow can you check which gcc versions are available on our training cluster?\nWhat are the dependencies required by gcc/13.3?\n\n\n\n\nLoading the modules\nOnce you know which modules you need, you can load them.\nmodule load gcc/13.3 r/4.5.0\n\nIf you are loading dependencies, the order is important: the dependencies must be listed before the modules which depend on them. Here, we aren‚Äôt loading dependencies so the order doesn‚Äôt matter.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "R on HPC clusters"
    ]
  },
  {
    "objectID": "r/hpc_clusters.html#installing-r-packages",
    "href": "r/hpc_clusters.html#installing-r-packages",
    "title": "R on HPC clusters",
    "section": "Installing R packages",
    "text": "Installing R packages\n\nFor this course, all packages have already been installed in a communal library to save us time and avoiding putting stress on the login node by all installing packages at the same time. The section below is thus for reference only.\n\n\n\n\n\n\nTo install a package, launch the interactive R console with:\nR\nIn the R console, run:\ninstall.packages(\"&lt;package_name&gt;\", repos=\"&lt;url-cran-mirror&gt;\")\nor, to install multiple packages at once:\ninstall.packages(c(\"&lt;package1&gt;\", \"&lt;package2&gt;\", \"&lt;package3&gt;\"), repos=\"&lt;url-cran-mirror&gt;\")\nFor the repos argument, chose a CRAN mirror close to the location of your cluster from this list or use https://cloud.r-project.org/.\n\nExample (please don‚Äôt run it since I already pre-installed all packages):\ninstall.packages(c(\"bench\", \"memoise\"), repos=\"https://muug.ca/mirror/cran/\")\n\nThe first time you install a package, R will ask you whether you want to create a personal library in your home directory. Answer yes to both questions. Your packages will now install under ~/.\n\nSome packages require additional modules to be loaded before they can be installed. Other packages need additional R packages as dependencies. In either case, you will get explicit error messages. Adding the argument dependencies = T helps in the second case, but you will still have to add packages manually from time to time.\n\nTo leave the R console, press &lt;Ctrl+D&gt;.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "R on HPC clusters"
    ]
  },
  {
    "objectID": "r/hpc_clusters.html#running-r-jobs",
    "href": "r/hpc_clusters.html#running-r-jobs",
    "title": "R on HPC clusters",
    "section": "Running R jobs",
    "text": "Running R jobs\nThere are two types of jobs that can be launched on an Alliance cluster: interactive jobs and batch jobs. We will practice both and discuss their respective merits and when to use which.\nFor this course, I purposefully built a rather small cluster (10 nodes with 4 CPUs and 15GB each) to give a tangible illustration of the constraints of resource sharing.\n\nInteractive jobs\n\nWhile it is fine to run R on the login node when you install packages, you must start a SLURM job before any heavy computation.\n\nTo run R interactively, you should launch an salloc session.\n\nExample to launch an interactive job on a single CPU with 3500MB of memory for 2h:\n\nsalloc --time=2:00:00 --mem-per-cpu=3500M\nThis takes you to a compute node where you can now launch R to run computations:\nR\n\nThis however leads to the same inefficient use of resources as happens when running an RStudio server: all the resources that you requested are blocked for you while your job is running, whether you are making use of them (running heavy computations) or not (thinking, typing code, running computations that use only a fraction of the requested resources).\nInteractive jobs are thus best kept to develop code.\n\n\n\nScripts\nTo run an R script called &lt;your_script&gt;.R, you first need to write a job script:\n\nExample to run a script on 4 CPUs with 3500MB per CPU for 15min:\n\n\n&lt;your_job&gt;.sh\n\n#!/bin/bash\n#SBATCH --account=def-&lt;your_account&gt;\n#SBATCH --time=15\n#SBATCH --mem-per-cpu=3500M\n#SBATCH --cpus-per-task=4\n#SBATCH --job-name=\"&lt;your_job&gt;\"\nmodule load StdEnv/2023 gcc/13.3 r/4.5.0\nRscript &lt;your_script&gt;.R\n\n\n\nNote that R scripts are run with the command Rscript (not R).\n\nThen launch your job with:\nsbatch &lt;your_job&gt;.sh\nYou can monitor your job with sq (an alias for squeue -u $USER $@).\n\nBatch jobs are the best approach to run parallel computations, particularly when they require a lot of hardware.\nIt will save you lots of waiting time (Alliance clusters) or money (commercial clusters).",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "R on HPC clusters"
    ]
  },
  {
    "objectID": "r/hpc_foreach.html",
    "href": "r/hpc_foreach.html",
    "title": "foreach and doFuture",
    "section": "",
    "text": "One of the options to parallelize code with the future package is to use foreach with doFuture. In this section, we will go over an example using the random forest algorithm.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "foreach and doFuture"
    ]
  },
  {
    "objectID": "r/hpc_foreach.html#our-example-code-random-forest",
    "href": "r/hpc_foreach.html#our-example-code-random-forest",
    "title": "foreach and doFuture",
    "section": "Our example code: random forest",
    "text": "Our example code: random forest\n\nOn the iris dataset\nRandom forest is a commonly used ensemble learning technique for classification and regression. The idea is to combine the results from many decision trees on bootstrap samples of the dataset to improve the predictive accuracy and control over-fitting. The algorithm used was developed by Tin Kam Ho, then improved by Leo Breiman and Adele Cutler. An implementation in R is provided by the randomForest() function from the randomForest package. Let‚Äôs use it to classify the iris dataset that comes packaged with R.\nFirst, let‚Äôs have a look at the dataset:\n\n# Structure of the dataset\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n# Dimensions of the dataset\ndim(iris)\n\n[1] 150   5\n\n# First 6 data points\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n# The 3 species (3 levels of the factor)\nlevels(iris$Species)\n\n[1] \"setosa\"     \"versicolor\" \"virginica\" \n\n\nThe goal is to create a random forest model (let‚Äôs call it rf) that can classify an iris flower in one of the 3 species based on the 4 measurements of its sepals and petals.\n\nlibrary(randomForest)\n\nrandomForest 4.7-1.1\n\n\nType rfNews() to see new features/changes/bug fixes.\n\nset.seed(123)\nrf &lt;- randomForest(Species ~ ., data=iris)\n\n\nOur response variable (Species) is a factor, so classification is assumed.\nThe . on the right side of the formula represents all other variables (so we are using all variables, except for the response variable Species of course, as feature variables).\n\n\nrf\n\n\nCall:\n randomForest(formula = Species ~ ., data = iris) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 4.67%\nConfusion matrix:\n           setosa versicolor virginica class.error\nsetosa         50          0         0        0.00\nversicolor      0         47         3        0.06\nvirginica       0          4        46        0.08\n\n\nAs can be seen by the confusion matrix, our model performs well.\nWe can use it on new data to make predictions. Let‚Äôs try with some made-up data:\n\nnew_data &lt;- data.frame(\n  Sepal.Length = c(5.3, 4.6, 6.5),\n  Sepal.Width = c(3.1, 3.9, 2.5),\n  Petal.Length = c(1.5, 1.5, 5.0),\n  Petal.Width = c(0.2, 0.1, 2.1)\n)\n\nnew_data\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width\n1          5.3         3.1          1.5         0.2\n2          4.6         3.9          1.5         0.1\n3          6.5         2.5          5.0         2.1\n\npredict(rf, new_data)\n\n        1         2         3 \n   setosa    setosa virginica \nLevels: setosa versicolor virginica\n\n\n\n\nLet‚Äôs make it big\nNow, the iris dataset only has 150 observations and we used the default number of trees (500) of the randomForest() function, so things ran fast. Often, random forests are run on large datasets. Let‚Äôs artificially increase the iris dataset and use more trees to create a situation in which parallelization would make sense.\nOne easy way is to replicate each row 100 times (and we can then delete the row names that get created by this operation):\n\nbig_iris &lt;- iris[rep(seq_len(nrow(iris)), each = 1e2), ]\nrownames(big_iris) &lt;- NULL\n\n\ndim(big_iris)\n\n[1] 15000     5\n\n\nAnd then we can run randomForest() on this dataset and 2000 trees.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "foreach and doFuture"
    ]
  },
  {
    "objectID": "r/hpc_foreach.html#hidden-parallelism-check",
    "href": "r/hpc_foreach.html#hidden-parallelism-check",
    "title": "foreach and doFuture",
    "section": "Hidden parallelism check",
    "text": "Hidden parallelism check\nBefore parallelizing your code, remember to check whether the package you are using is already doing any parallelization under the hood (after all, maybe the randomForest package runs things in parallel. We don‚Äôt know).\nOne way to do this is to test the package on your local machine and, while some sample code is running, to open htop and see how many cores are used.\nWhy do this on your local machine? because on the cluster, if you launch htop while your batch job is running, you will be looking at processes running on the login node while your code is running on compute node(s). So this will not help you. You could salloc on the/one of the compute node(s) running your job and run htop there, but in production clusters, compute nodes are large and you will see all the processes from all the other users using that compute node. So this test is just easier done locally.\nOn my machine I ran:\nlibrary(randomForest)\n\nbig_iris &lt;- iris[rep(seq_len(nrow(iris)), each = 1e2), ]\nrownames(big_iris) &lt;- NULL\n\nset.seed(123)\nrf &lt;- randomForest(Species ~ ., data=big_iris, ntree=2000)\nAnd I could confirm that the function does not run in parallel.\nSo let‚Äôs parallelize this code.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "foreach and doFuture"
    ]
  },
  {
    "objectID": "r/hpc_foreach.html#the-foreach-package",
    "href": "r/hpc_foreach.html#the-foreach-package",
    "title": "foreach and doFuture",
    "section": "The foreach package",
    "text": "The foreach package\nThe foreach package provides a construct for repeated executions, i.e.¬†it can replace for loops, while loops, repeat loops, and functional programming code written with the *apply functions or the purrr package. The foreach vignette gives many examples.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "foreach and doFuture"
    ]
  },
  {
    "objectID": "r/hpc_foreach.html#the-dofuture-package",
    "href": "r/hpc_foreach.html#the-dofuture-package",
    "title": "foreach and doFuture",
    "section": "The doFuture package",
    "text": "The doFuture package\nThe most useful part of foreach is that it allows for easily parallelization with countless backends: doFuture, doMC, doMPI, doParallel, doRedis, doRNG, doSNOW, and doAzureParallel.\nThe doFuture package is the most modern of these backends. It allows to evaluate foreach expressions across the evaluation strategies of the future package very easily. All you have to do is to register it as a backend, declare the evaluation strategy of futures of your choice, make sure to generate parallel-safe random numbers for reproducibility (if your code uses randomness), and replace %do% with %dofuture%.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "foreach and doFuture"
    ]
  },
  {
    "objectID": "r/hpc_foreach.html#benchmarks",
    "href": "r/hpc_foreach.html#benchmarks",
    "title": "foreach and doFuture",
    "section": "Benchmarks",
    "text": "Benchmarks\nWe will run and benchmark all versions of our code by submitting batch jobs to Slurm.\n\nInitial code\nFirst, let‚Äôs benchmark the initial (non parallel, not using foreach) code. We need to create an R script. Let‚Äôs call it reference.R (I will use Emacs, but you can use the nano text editor with the command nano to write the script if you want):\n\n\nreference.R\n\nlibrary(randomForest)\nlibrary(bench)\n\nbig_iris &lt;- iris[rep(seq_len(nrow(iris)), each = 1e2), ]\nrownames(big_iris) &lt;- NULL\n\ncat(\"\\nBenchmarking results:\\n\\n\")\n\nset.seed(123)\nmark(rf &lt;- randomForest(Species ~ ., data=big_iris, ntree=2000))\n\nThen we need to create a Bash script for Slurm. Let‚Äôs call it reference.sh:\n\n\nreference.sh\n\n#!/bin/bash\n#SBATCH --time=5\n#SBATCH --mem-per-cpu=7500M\n\nRscript reference.R\n\n\nYou can see the full list of sbatch options here.\n\nAnd now we submit the job with:\nsbatch reference.sh\nYou can monitor your job with sq. The result will be written to a file called slurm-xx.out with xx being the number of the job that just ran. To see the result, we can simply print the content of that file to screen with cat (you can run ls to see the list of files in the current directory). Make sure that your job has finished running before printing the result (otherwise you might get a partial output which can be confusing).\ncat slurm-xx.out    # Replace xx by the job number\nrandomForest 4.7-1.1\nType rfNews() to see new features/changes/bug fixes.\n\nBenchmarking results:\n\n# A tibble: 1 √ó 13\n  expression      min median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc total_time\n  &lt;bch:expr&gt;    &lt;bch&gt; &lt;bch:&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;   &lt;bch:tm&gt;\n1 rf &lt;- random‚Ä¶ 6.33s  6.33s     0.158        NA    0.474     1     3      6.33s\n# ‚Ñπ 4 more variables: result &lt;list&gt;, memory &lt;list&gt;, time &lt;list&gt;, gc &lt;list&gt;\nWarning message:\nSome expressions had a GC in every iteration; so filtering is disabled.\n\n\nforeach expression\nNow, let‚Äôs try the foreach version:\n\n\nforeach.R\n\nlibrary(foreach)\nlibrary(randomForest)\nlibrary(bench)\n\nbig_iris &lt;- iris[rep(seq_len(nrow(iris)), each = 1e2), ]\nrownames(big_iris) &lt;- NULL\n\ncat(\"\\nBenchmarking results:\\n\\n\")\n\nset.seed(123)\nmark(\n  rf &lt;- foreach(ntree = rep(250, 8), .combine = combine) %do%\n    randomForest(Species ~ ., data=big_iris, ntree=ntree)\n)\n\n\n\nforeach.sh\n\n#!/bin/bash\n#SBATCH --time=5\n#SBATCH --mem-per-cpu=7500M\n\nRscript foreach.R\n\nsbatch foreach.sh\nrandomForest 4.7-1.1\nType rfNews() to see new features/changes/bug fixes.\n\nBenchmarking results:\n\n# A tibble: 1 √ó 13\n  expression      min median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc total_time\n  &lt;bch:expr&gt;    &lt;bch&gt; &lt;bch:&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;   &lt;bch:tm&gt;\n1 rf &lt;- foreac‚Ä¶ 7.04s  7.04s     0.142        NA     4.55     1    32      7.04s\n# ‚Ñπ 4 more variables: result &lt;list&gt;, memory &lt;list&gt;, time &lt;list&gt;, gc &lt;list&gt;\nWarning message:\nSome expressions had a GC in every iteration; so filtering is disabled.\n\nThe foreach expression is slower than the standard expression (it is always the case: foreach slows things down before this overhead gets offset by parallelization).\n\n\n\nPlan sequential\nYou might wonder why the sequential evaluation strategy exists (i.e.¬†why go through all the trouble of writing your code with foreach and doFuture to then run it without parallelism?).\nThere are many reasons:\n\nIt can be very useful for debugging.\nIt makes it easy to switch the futures execution strategy back and forth for different sections of the code (maybe you don‚Äôt want to run everything in parallel).\nIt allows other people to run the same code on their different hardware without changing it (if they don‚Äôt have the resources to run things in parallel, they only have to change the execution strategy).\n\nTo turn the code into a parallelizable version with doFuture, we replace %do% with %dofuture%.\nHere, we also need to use the option .options.future = list(seed = TRUE): whenever your parallel code rely on a random process, it isn‚Äôt enough to use set.seed() to ensure reproducibility, you also need to generate parallel-safe random numbers. In random forest, each tree is trained on a random subset of the data and random variables are selected for splitting at each node. The option .options.future = list(seed = TRUE) pregenerates the random seeds using L‚ÄôEcuyer-CMRG RNG streams1.\nThis is the parallelizable foreach code, but run sequentially:\n\n\nsequential.R\n\nlibrary(doFuture)    # Also loads foreach and future\nlibrary(randomForest)\nlibrary(bench)\n\nregisterDoFuture()   # Set the parallel backend\nplan(sequential)     # Set the evaluation strategy\n\nbig_iris &lt;- iris[rep(seq_len(nrow(iris)), each = 1e2), ]\nrownames(big_iris) &lt;- NULL\n\ncat(\"\\nBenchmarking results:\\n\\n\")\n\nset.seed(123)\nmark(\n  rf &lt;- foreach(\n    ntree = rep(250, 8),\n    .options.future = list(seed = TRUE),\n    .combine = combine\n  ) %dofuture%\n    randomForest(Species ~ ., data=big_iris, ntree=ntree)\n)\n\n\n\nsequential.sh\n\n#!/bin/bash\n#SBATCH --time=5\n#SBATCH --mem-per-cpu=7500M\n\nRscript sequential.R\n\nsbatch sequential.sh\nLoading required package: foreach\nLoading required package: future\nrandomForest 4.7-1.1\nType rfNews() to see new features/changes/bug fixes.\n\nBenchmarking results:\n\n# A tibble: 1 √ó 13\n  expression      min median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc total_time\n  &lt;bch:expr&gt;    &lt;bch&gt; &lt;bch:&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;   &lt;bch:tm&gt;\n1 rf &lt;- foreac‚Ä¶ 8.39s  8.39s     0.119        NA     3.81     1    32      8.39s\n# ‚Ñπ 4 more variables: result &lt;list&gt;, memory &lt;list&gt;, time &lt;list&gt;, gc &lt;list&gt;\nWarning message:\nSome expressions had a GC in every iteration; so filtering is disabled.\n\nEach time we add unnecessary complexity in the code, things run a little slower.\n\n\n\nMulti-processing in shared memory\nNow, it is time to parallelize. First, we will use multiple cores on a single node (shared-memory parallelism).\n\nNumber of cores\nThe future package provides the availableCores() function to detect the number of available cores. We will run it as part of our script as a check on our available hardware.\nThe cluster for this course is made of 20 nodes with 4 CPUs each. We want to test shared memory parallelism, so our job needs to stay within one node. We can thus ask for a maximum of 4 CPUs and we want to ensure that we aren‚Äôt getting them on different nodes. Let‚Äôs go with that maximum of 4 cores.\n\n\nMultisession\nShared memory multi-processing can be run with plan(multisession) that will spawn new R sessions in the background to evaluate futures.\n\n\nmultisession.R\n\nlibrary(doFuture)\nlibrary(randomForest)\nlibrary(bench)\n\n# Check number of cores:\ncat(\"\\nWe have\", availableCores(), \"cores.\\n\\n\")\n\nregisterDoFuture()   # Set the parallel backend\nplan(multisession)   # Set the evaluation strategy\n\nbig_iris &lt;- iris[rep(seq_len(nrow(iris)), each = 1e2), ]\nrownames(big_iris) &lt;- NULL\n\ncat(\"\\nBenchmarking results:\\n\\n\")\n\nset.seed(123)\nmark(\n  rf &lt;- foreach(\n    ntree = rep(250, 8),\n    .options.future = list(seed = TRUE),\n    .combine = combine\n  ) %dofuture%\n    randomForest(Species ~ ., data=big_iris, ntree=ntree)\n)\n\n\n\nmultisession.sh\n\n#!/bin/bash\n#SBATCH --time=5\n#SBATCH --mem-per-cpu=7500M\n#SBATCH --cpus-per-task=4\n\nRscript multisession.R\n\nsbatch multisession.sh\nLoading required package: foreach\nLoading required package: future\nrandomForest 4.7-1.1\nType rfNews() to see new features/changes/bug fixes.\n\nWe have 4 cores.\n\nBenchmarking results:\n\n# A tibble: 1 √ó 13\n  expression      min median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc total_time\n  &lt;bch:expr&gt;    &lt;bch&gt; &lt;bch:&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;   &lt;bch:tm&gt;\n1 rf &lt;- foreac‚Ä¶ 2.72s  2.72s     0.368        NA     2.21     1     6      2.72s\n# ‚Ñπ 4 more variables: result &lt;list&gt;, memory &lt;list&gt;, time &lt;list&gt;, gc &lt;list&gt;\nWarning message:\nSome expressions had a GC in every iteration; so filtering is disabled.\nSpeedup: 3.1.\n\nNot too bad, considering that the ideal speedup, without any overhead, would be 4.\n\n\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=4\ncould be used instead of:\n#SBATCH --cpus-per-task=4\nWhat matters is to have 4 cores running on the same node to be in a shared memory parallelism scenario.\n\n\n\nMulticore\nShared memory multi-processing can also be run with plan(multicore) (except on Windows) that will fork the current R process to evaluate futures.\n\n\nmulticore.R\n\nlibrary(doFuture)\nlibrary(randomForest)\nlibrary(bench)\n\n# Check number of cores:\ncat(\"\\nWe have\", availableCores(), \"cores.\\n\\n\")\n\nregisterDoFuture()   # Set the parallel backend\nplan(multicore)      # Set the evaluation strategy\n\nbig_iris &lt;- iris[rep(seq_len(nrow(iris)), each = 1e2), ]\nrownames(big_iris) &lt;- NULL\n\ncat(\"\\nBenchmarking results:\\n\\n\")\n\nset.seed(123)\nmark(\n  rf &lt;- foreach(\n    ntree = rep(250, 8),\n    .options.future = list(seed = TRUE),\n    .combine = combine\n  ) %dofuture%\n    randomForest(Species ~ ., data=big_iris, ntree=ntree)\n)\n\n\n\nmulticore.sh\n\n#!/bin/bash\n#SBATCH --time=5\n#SBATCH --mem-per-cpu=7500M\n#SBATCH --cpus-per-task=4\n\nRscript multicore.R\n\nsbatch multicore.sh\nLoading required package: foreach\nLoading required package: future\nrandomForest 4.7-1.1\nType rfNews() to see new features/changes/bug fixes.\n\nWe have 4 cores.\n\nBenchmarking results:\n\n# A tibble: 1 √ó 13\n  expression      min median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc total_time\n  &lt;bch:expr&gt;    &lt;bch&gt; &lt;bch:&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;   &lt;bch:tm&gt;\n1 rf &lt;- foreac‚Ä¶ 3.15s  3.15s     0.318        NA     13.7     1    43      3.15s\n# ‚Ñπ 4 more variables: result &lt;list&gt;, memory &lt;list&gt;, time &lt;list&gt;, gc &lt;list&gt;\nWarning message:\nSome expressions had a GC in every iteration; so filtering is disabled.\nSpeedup: 2.7.\n\nWhile in theory we should get a similar speedup, we are getting a lower one here.\n\n\n\n\nMulti-proc in distributed memory\nLet‚Äôs run our distributed parallel code using 8 cores across 2 nodes.\nWe need to create a cluster of workers. We do this by creating a character vector with the names of the nodes our tasks are running on and passing it to the makeCluster() function from the parallel package (included in R):\n# Create a character vector with the nodes names\nhosts &lt;- system(\"srun hostname -s\", intern = T)\n\n# Create the cluster of workers\ncl &lt;- parallel::makeCluster(hosts)\nWe can verify that we did get 8 tasks by accessing the SLURM_NTASKS environment variable from within R:\nas.numeric(Sys.getenv(\"SLURM_NTASKS\"))\nHere is the R script:\n\n\ndistributed.R\n\nlibrary(doFuture)\nlibrary(randomForest)\nlibrary(bench)\n\n# Check number of tasks:\ncat(\"\\nWe have\", as.numeric(Sys.getenv(\"SLURM_NTASKS\")), \"tasks.\\n\\n\")\n\n# Create a character vector with the nodes names\nhosts &lt;- system(\"srun hostname -s\", intern = T)\n\n# Look at the location of our tasks:\ncat(\"\\nOur tasks are running on the following nodes: \", hosts)\n\n# Create the cluster of workers\ncl &lt;- parallel::makeCluster(hosts)\n\nregisterDoFuture()           # Set the parallel backend\nplan(cluster, workers = cl)  # Set the evaluation strategy\n\nbig_iris &lt;- iris[rep(seq_len(nrow(iris)), each = 1e2), ]\nrownames(big_iris) &lt;- NULL\n\ncat(\"\\nBenchmarking results:\\n\\n\")\n\nset.seed(123)\nmark(\n  rf &lt;- foreach(\n    ntree = rep(250, 8),\n    .options.future = list(seed = TRUE),\n    .combine = combine\n  ) %dofuture%\n    randomForest(Species ~ ., data=big_iris, ntree=ntree)\n)\n\n\nThe cluster of workers can be stopped with:\nparallel::stopCluster(cl)\nHere, this is not necessary since our job stops running as soon as the execution is complete, but in other systems, this will prevent you from monopolizing hardware or paying unnecessarily.\n\nAnd now we need to ask Slurm for 8 tasks on 2 nodes:\n\n\ndistributed.sh\n\n#!/bin/bash\n#SBATCH --time=5\n#SBATCH --mem-per-cpu=7500M\n#SBATCH --ntasks-per-node=4\n#SBATCH --nodes=2\n\nRscript distributed.R\n\nsbatch distributed.sh\nLoading required package: foreach\nLoading required package: future\nrandomForest 4.7-1.1\nType rfNews() to see new features/changes/bug fixes.\n\nWe have 8 tasks.\n\nOur tasks are running on the following nodes: \"node1\" \"node1\" \"node1\" \"node1\" \"node2\" \"node2\" \"node2\" \"node2\"\n\nBenchmarking results:\n\n# A tibble: 1 √ó 13\n  expression      min median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc total_time\n  &lt;bch:expr&gt;    &lt;bch&gt; &lt;bch:&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;   &lt;bch:tm&gt;\n1 rf &lt;- foreac‚Ä¶  1.6s   1.6s     0.624        NA     3.12     1     5       1.6s\n# ‚Ñπ 4 more variables: result &lt;list&gt;, memory &lt;list&gt;, time &lt;list&gt;, gc &lt;list&gt;\nWarning message:\nSome expressions had a GC in every iteration; so filtering is disabled.\nSpeedup: 5.2.\n\nThe overhead is larger in distributed parallelism due to message passing between nodes. We are further from the ideal speedup of 8, but we still got a speedup larger than what we could have obtained with shared-memory parallelism.\n\n\n#SBATCH --ntasks=8\ncould be used instead of:\n#SBATCH --ntasks-per-node=4\n#SBATCH --nodes=2\nHowever the latter is slightly better because it allows us to use 2 full nodes instead of having tasks running on any number of nodes. However, it also means that we might have to wait longer for our job to run as it is more restrictive.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "foreach and doFuture"
    ]
  },
  {
    "objectID": "r/hpc_foreach.html#footnotes",
    "href": "r/hpc_foreach.html#footnotes",
    "title": "foreach and doFuture",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nL‚ÄôEcuyer, P. (1999). Good parameters and implementations for combined multiple recursive random number generators. Operations Research, 47, 159‚Äì164.‚Ü©Ô∏é",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "foreach and doFuture"
    ]
  },
  {
    "objectID": "r/hpc_memory.html",
    "href": "r/hpc_memory.html",
    "title": "Memory management",
    "section": "",
    "text": "Memory can be a limiting factor and releasing it when not needed can be critical to avoid out of memory states. On the other hand, memoisation is an optimization technique which consists of caching the results of heavy computations for re-use.\nMemory and speed are thus linked in a trade-off.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Memory management"
    ]
  },
  {
    "objectID": "r/hpc_memory.html#releasing-memory",
    "href": "r/hpc_memory.html#releasing-memory",
    "title": "Memory management",
    "section": "Releasing memory",
    "text": "Releasing memory\nIt is best to avoid creating very large intermediate objects that take space in memory unnecessarily.\n\nOne option is to use nested functions or functions chained with pipes.\nAnother option is to create the intermediate objects within the local environment of a function as they will automatically be deleted as soon as the function has finished running.\n\nLet‚Äôs go over a basic example: let‚Äôs extract the sepal width variable from the iris dataset (one of the datasets that come packaged with R), take the natural logarithm of the values, and round them to one decimal place.\nFirst, let‚Äôs delete all objects inside our environment to make our little test as clean as possible:\n\nrm(list=ls())\nls()\n\ncharacter(0)\n\n\nNow, we could perform our task this way:\n\nsepalwidth &lt;- iris$Sepal.Width\nsepalwidth_ln &lt;- log(sepalwidth)\nround(sepalwidth_ln, 1)\n\n  [1] 1.3 1.1 1.2 1.1 1.3 1.4 1.2 1.2 1.1 1.1 1.3 1.2 1.1 1.1 1.4 1.5 1.4 1.3\n [19] 1.3 1.3 1.2 1.3 1.3 1.2 1.2 1.1 1.2 1.3 1.2 1.2 1.1 1.2 1.4 1.4 1.1 1.2\n [37] 1.3 1.3 1.1 1.2 1.3 0.8 1.2 1.3 1.3 1.1 1.3 1.2 1.3 1.2 1.2 1.2 1.1 0.8\n [55] 1.0 1.0 1.2 0.9 1.1 1.0 0.7 1.1 0.8 1.1 1.1 1.1 1.1 1.0 0.8 0.9 1.2 1.0\n [73] 0.9 1.0 1.1 1.1 1.0 1.1 1.1 1.0 0.9 0.9 1.0 1.0 1.1 1.2 1.1 0.8 1.1 0.9\n [91] 1.0 1.1 1.0 0.8 1.0 1.1 1.1 1.1 0.9 1.0 1.2 1.0 1.1 1.1 1.1 1.1 0.9 1.1\n[109] 0.9 1.3 1.2 1.0 1.1 0.9 1.0 1.2 1.1 1.3 1.0 0.8 1.2 1.0 1.0 1.0 1.2 1.2\n[127] 1.0 1.1 1.0 1.1 1.0 1.3 1.0 1.0 1.0 1.1 1.2 1.1 1.1 1.1 1.1 1.1 1.0 1.2\n[145] 1.2 1.1 0.9 1.1 1.2 1.1\n\n\nBut this creates the unnecessary intermediate variables sepalwidth and sepalwidth_ln which get stored in memory:\n\nls()\n\n[1] \"sepalwidth\"    \"sepalwidth_ln\"\n\n\nFor very large objects, this is not ideal.\nLet‚Äôs clear objects in our environment again:\n\nrm(list=ls())\nls()\n\ncharacter(0)\n\n\nA better option is to use nested functions:\n\nround(log(iris$Sepal.Width), 1)\n\n  [1] 1.3 1.1 1.2 1.1 1.3 1.4 1.2 1.2 1.1 1.1 1.3 1.2 1.1 1.1 1.4 1.5 1.4 1.3\n [19] 1.3 1.3 1.2 1.3 1.3 1.2 1.2 1.1 1.2 1.3 1.2 1.2 1.1 1.2 1.4 1.4 1.1 1.2\n [37] 1.3 1.3 1.1 1.2 1.3 0.8 1.2 1.3 1.3 1.1 1.3 1.2 1.3 1.2 1.2 1.2 1.1 0.8\n [55] 1.0 1.0 1.2 0.9 1.1 1.0 0.7 1.1 0.8 1.1 1.1 1.1 1.1 1.0 0.8 0.9 1.2 1.0\n [73] 0.9 1.0 1.1 1.1 1.0 1.1 1.1 1.0 0.9 0.9 1.0 1.0 1.1 1.2 1.1 0.8 1.1 0.9\n [91] 1.0 1.1 1.0 0.8 1.0 1.1 1.1 1.1 0.9 1.0 1.2 1.0 1.1 1.1 1.1 1.1 0.9 1.1\n[109] 0.9 1.3 1.2 1.0 1.1 0.9 1.0 1.2 1.1 1.3 1.0 0.8 1.2 1.0 1.0 1.0 1.2 1.2\n[127] 1.0 1.1 1.0 1.1 1.0 1.3 1.0 1.0 1.0 1.1 1.2 1.1 1.1 1.1 1.1 1.1 1.0 1.2\n[145] 1.2 1.1 0.9 1.1 1.2 1.1\n\n\nAn equivalent option is to chain functions:\n\niris$Sepal.Width |&gt; log() |&gt; round(1)\n\n  [1] 1.3 1.1 1.2 1.1 1.3 1.4 1.2 1.2 1.1 1.1 1.3 1.2 1.1 1.1 1.4 1.5 1.4 1.3\n [19] 1.3 1.3 1.2 1.3 1.3 1.2 1.2 1.1 1.2 1.3 1.2 1.2 1.1 1.2 1.4 1.4 1.1 1.2\n [37] 1.3 1.3 1.1 1.2 1.3 0.8 1.2 1.3 1.3 1.1 1.3 1.2 1.3 1.2 1.2 1.2 1.1 0.8\n [55] 1.0 1.0 1.2 0.9 1.1 1.0 0.7 1.1 0.8 1.1 1.1 1.1 1.1 1.0 0.8 0.9 1.2 1.0\n [73] 0.9 1.0 1.1 1.1 1.0 1.1 1.1 1.0 0.9 0.9 1.0 1.0 1.1 1.2 1.1 0.8 1.1 0.9\n [91] 1.0 1.1 1.0 0.8 1.0 1.1 1.1 1.1 0.9 1.0 1.2 1.0 1.1 1.1 1.1 1.1 0.9 1.1\n[109] 0.9 1.3 1.2 1.0 1.1 0.9 1.0 1.2 1.1 1.3 1.0 0.8 1.2 1.0 1.0 1.0 1.2 1.2\n[127] 1.0 1.1 1.0 1.1 1.0 1.3 1.0 1.0 1.0 1.1 1.2 1.1 1.1 1.1 1.1 1.1 1.0 1.2\n[145] 1.2 1.1 0.9 1.1 1.2 1.1\n\n\nAnother option is to create the intermediate variables in the local environment of a function:\n\nget_sepalwidth &lt;- function(dataset) {\n  sepalwidth &lt;- dataset$Sepal.Width\n  sepalwidth_ln &lt;- log(sepalwidth)\n  round(sepalwidth_ln, 1)\n}\n\nget_sepalwidth(iris)\n\n  [1] 1.3 1.1 1.2 1.1 1.3 1.4 1.2 1.2 1.1 1.1 1.3 1.2 1.1 1.1 1.4 1.5 1.4 1.3\n [19] 1.3 1.3 1.2 1.3 1.3 1.2 1.2 1.1 1.2 1.3 1.2 1.2 1.1 1.2 1.4 1.4 1.1 1.2\n [37] 1.3 1.3 1.1 1.2 1.3 0.8 1.2 1.3 1.3 1.1 1.3 1.2 1.3 1.2 1.2 1.2 1.1 0.8\n [55] 1.0 1.0 1.2 0.9 1.1 1.0 0.7 1.1 0.8 1.1 1.1 1.1 1.1 1.0 0.8 0.9 1.2 1.0\n [73] 0.9 1.0 1.1 1.1 1.0 1.1 1.1 1.0 0.9 0.9 1.0 1.0 1.1 1.2 1.1 0.8 1.1 0.9\n [91] 1.0 1.1 1.0 0.8 1.0 1.1 1.1 1.1 0.9 1.0 1.2 1.0 1.1 1.1 1.1 1.1 0.9 1.1\n[109] 0.9 1.3 1.2 1.0 1.1 0.9 1.0 1.2 1.1 1.3 1.0 0.8 1.2 1.0 1.0 1.0 1.2 1.2\n[127] 1.0 1.1 1.0 1.1 1.0 1.3 1.0 1.0 1.0 1.1 1.2 1.1 1.1 1.1 1.1 1.1 1.0 1.2\n[145] 1.2 1.1 0.9 1.1 1.2 1.1\n\n\nNone of these options left intermediate variables in our environment:\n\nls()\n\n[1] \"get_sepalwidth\"\n\n\nNote that in the case of a very large function, it might still be beneficial to run rm() inside the function to clear the memory for other processes coming next within that function. But this is a pretty rare case.\nIf you really have to create large intermediate objects in the global environment, make sure to delete them as soon as you don‚Äôt need them anymore (e.g.¬†rm(sepalwidth, sepalwidth_ln)).\n\nrm() deletes the names of variables (the pointers to objects in memory). But as soon as all the pointers to an object in memory are deleted, the garbage collector clears its value and releases the memory it used.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Memory management"
    ]
  },
  {
    "objectID": "r/hpc_memory.html#caching",
    "href": "r/hpc_memory.html#caching",
    "title": "Memory management",
    "section": "Caching",
    "text": "Caching\nMemoisation is a technique by which some results are cached to avoid re-calculating them. This is convenient in a variety of settings (e.g.¬†to reduce calls to an API, to avoid repeating heavy computations). In particular, it improves the efficiency of recursive function calls dramatically.\nLet‚Äôs consider the calculation of the Fibonacci numbers as an example. Those numbers form a sequence starting with 0, 11, after which each number is the sum of the previous two (so the series starts with: 0, 1, 1, 2, 3, 5, 8, 13...).\nHere is a function that would return the nth Fibonacci number2:\nfib &lt;- function(n) {\n  if(n == 0) {\n    return(0)\n  } else if(n == 1) {\n    return(1)\n  } else {\n    Recall(n - 1) + Recall(n - 2)\n  }\n}\nIt can be written more tersely as:\n\nfib &lt;- function(n) {\n  if(n == 0) return(0)\n  if(n == 1) return(1)\n  Recall(n - 1) + Recall(n - 2)\n}\n\n\nRecall() is a placeholder for the name of the recursive function. We could have used fib() instead, but Recall() is more robust as it allows for function renaming.\n\nMemoisation is very useful here because, for each Fibonacci number, we need to calculate the two preceding Fibonacci numbers and to calculate each of those we need to calculate the two Fibonacci numbers preceding that one and to calculate‚Ä¶ etc. That is a large number of calculations, but, thanks to caching, we don‚Äôt have to calculate any one of them more than once.\nThe packages R.cache and memoise both allow for memoisation with an incredibly simple syntax.\nApplying the latter to our function gives us:\n\nlibrary(memoise)\n\nfibmem &lt;- memoise(\n  function(n) {\n    if(n == 0) return(0)\n    if(n == 1) return(1)\n    Recall(n - 1) + Recall(n - 2)\n  }\n)\n\nWe can do some benchmarking to see the speedup for the 30th Fibonacci number:\n\nlibrary(bench)\n\nn &lt;- 30\nmark(fib(n), fibmem(n))\n\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n\n\n# A tibble: 2 √ó 6\n  expression      min   median `itr/sec` mem_alloc `gc/sec`\n  &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n1 fib(n)        1.62s    1.62s     0.616    32.9KB     18.5\n2 fibmem(n)   41.22¬µs  44.62¬µs 20807.       68.3KB     14.6\n\n\nThe speedup is over 35,000!",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Memory management"
    ]
  },
  {
    "objectID": "r/hpc_memory.html#footnotes",
    "href": "r/hpc_memory.html#footnotes",
    "title": "Memory management",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAlternative versions have the sequence start with 1, 1 or with 1, 2.‚Ü©Ô∏é\nThere are more efficient ways to calculate the Fibonacci numbers, but this inefficient function is a great example to show the advantage of memoisation.‚Ü©Ô∏é",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Memory management"
    ]
  },
  {
    "objectID": "r/hpc_parallel_r.html",
    "href": "r/hpc_parallel_r.html",
    "title": "Running R code in parallel",
    "section": "",
    "text": "The parallel package has been part of the base package group since R version 2.14.0.\nThis means that it is comes with R, however it needs to be loaded in a session before its content can be accessed:\nlibrary(parallel)\nMost parallel approaches in R build on this package.\nAll other packages mentioned in this lesson are external packages and need to be installed with install.packages()."
  },
  {
    "objectID": "r/hpc_parallel_r.html#base-r-parallel-package",
    "href": "r/hpc_parallel_r.html#base-r-parallel-package",
    "title": "Running R code in parallel",
    "section": "",
    "text": "The parallel package has been part of the base package group since R version 2.14.0.\nThis means that it is comes with R, however it needs to be loaded in a session before its content can be accessed:\nlibrary(parallel)\nMost parallel approaches in R build on this package.\nAll other packages mentioned in this lesson are external packages and need to be installed with install.packages()."
  },
  {
    "objectID": "r/hpc_parallel_r.html#parallelly-package",
    "href": "r/hpc_parallel_r.html#parallelly-package",
    "title": "Running R code in parallel",
    "section": "parallelly package",
    "text": "parallelly package\nThe parallelly package‚Äîpart of the futureverse suite of packages developed by Henrik Bengtsson‚Äîadds functionality to the parallel package."
  },
  {
    "objectID": "r/hpc_partition.html",
    "href": "r/hpc_partition.html",
    "title": "Partitioning data with multidplyr",
    "section": "",
    "text": "The package multidplyr provides simple techniques to partition data across a set of workers on the same node.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Partitioning data"
    ]
  },
  {
    "objectID": "r/hpc_partition.html#data-partitioning-for-memory",
    "href": "r/hpc_partition.html#data-partitioning-for-memory",
    "title": "Partitioning data with multidplyr",
    "section": "Data partitioning for memory",
    "text": "Data partitioning for memory\n\nCase example\nWhat if we have an even bigger dataset?\nThe randomForest() function has limitations:\n\nIt is a memory hog.\nIt doesn‚Äôt run if your data frame has too many rows.\n\nIf you try to run:\n\n\nbigger.R\n\nlibrary(randomForest)\n\nbigger_iris &lt;- iris[rep(seq_len(nrow(iris)), each = 1e3), ]\nrownames(bigger_iris) &lt;- NULL\n\nset.seed(123)\nrf &lt;- randomForest(Species ~ ., data = bigger_iris)\n\nrf\n\non a single core, you will get:\nrandomForest 4.7-1.1\nType rfNews() to see new features/changes/bug fixes.\n/var/spool/slurmd/job00016/slurm_script: line 5: 74451 Killed                  Rscript data_partition.R\nslurmstepd: error: Detected 1 oom-kill event(s) in StepId=16.batch. Some of your processes may have been killed by the cgroup out-of-memory handler.\nYou have ran out of memory.\nReducing the number of trees won‚Äôt help as the problem comes from the size of the data frame.\nSimilarly, using foreach and doFuture as we did previously won‚Äôt help either because that spreads the number of trees on various cores, but again, the problem doesn‚Äôt come from the number of trees, but for the size of the dataset.\n\nWith plan(multisession), you would get:\nCluster with multisession\nError in unserialize(node$con) :\n  MultisessionFuture (doFuture2-3) failed to receive message results from cluster RichSOCKnode #3 (PID 445273 on localhost ‚Äòlocalhost‚Äô). The reason reported was ‚Äòerror reading from connection‚Äô. Post-mortem diagnostic: No process exists with this PID, i.e. the localhost worker is no longer alive. The total size of the 3 globals exported is 5.15 MiB. There are three globals: ‚Äòbig_iris‚Äô (5.15 MiB of class ‚Äòlist‚Äô), ‚Äò...future.seeds_ii‚Äô (160 bytes of class ‚Äòlist‚Äô) and ‚Äò...future.x_ii‚Äô (112 bytes of class ‚Äòlist‚Äô)\nAnd with plan(multicore):\nCluster with multicore\nError: Failed to retrieve the result of MulticoreFuture (doFuture2-2) from the forked worker (on localhost; PID 444769). Post-mortem diagnostic: No process exists with this PID, i.e. the forked localhost worker is no longer alive. The total size of the 3 globals exported is 5.15 MiB. There are three globals: ‚Äòbig_iris‚Äô (5.15 MiB of class ‚Äòlist‚Äô), ‚Äò...future.seeds_ii‚Äô (160 bytes of class ‚Äòlist‚Äô) and ‚Äò...future.x_ii‚Äô (112 bytes of class ‚Äòlist‚Äô)\nIn addition: Warning message:\nIn mccollect(jobs = jobs, wait = TRUE) :\n  1 parallel job did not deliver a result\n\nYou can even try spreading the trees on multiple nodes, but things will fail as well, without any error message.\nOf course, you could always try on a different machine‚Äîone with more memory. I used my machine which has more memory than this training cluster and it worked.\nBut then, what if big_iris is even bigger? Say, if we have this for instance:\nbigger_iris &lt;- iris[rep(seq_len(nrow(iris)), each = 1e4), ]\nThen no amount of memory will save you and you will get errors similar to this:\nError in randomForest.default(m, y, ...) : \n  long vectors (argument 28) are not supported in .C\nThat‚Äôs because randomForest() does not accept datasets with too many rows.\n\nThe bottom line is that there are situation in which the data is just too big. In such cases, you want to look at data parallelism: instead of splitting your code into tasks that can run in parallel as we did previously, you split the data into chunks and run the code in parallel on those chunks.\n\n\nOf course, you could also simply run the code on a subset of your data. In many situation, reducing your data by sampling it properly will be good enough. But there are situations in which you want to use a huge dataset.\n\nYou could split the data manually and run the code on each chunk, but it would be tedious and very lengthy. And to run the code on all the chunks in parallel, you could implement that yourself. There is a much simpler option provided by the multidplyr package.\n\n\nUsing multidplyr\nTo see what happens as we use multidplyr, let‚Äôs first run the code in an interactive session on one node with 4 cores:\n# Launch the interactive job\nsalloc --time=50 --mem-per-cpu=7500M --cpus-per-task=4\n\n# Then launch R\nR\nFirst, we load the packages that are running in the main session:\n\nlibrary(multidplyr)\nlibrary(dplyr, warn.conflicts = FALSE)\n\n\nWe load dplyr for the do() function.\nNotice that we aren‚Äôt loading the randomForest package yet: that‚Äôs because we will use it on workers, not in the main session.\n\nThen we need to create a cluster of workers. Let‚Äôs use 4 workers that we will run on a full node:\n\ncl &lt;- new_cluster(4)\ncl\n\n4 session cluster [....]\n\n\nNow we can load the randomForest package on each worker:\ncluster_library(cl, \"randomForest\")\nrandomForest 4.7-1.1\nType rfNews() to see new features/changes/bug fixes.\n\nAttaching package: ‚ÄòrandomForest‚Äô\n\nThe following object is masked from ‚Äòpackage:dplyr‚Äô:\n\n    combine\nOf course, we need to generate our big dataset:\n\nbigger_iris &lt;- iris[rep(seq_len(nrow(iris)), each = 1e3), ]\nrownames(bigger_iris) &lt;- NULL\n\nThen we create a partitioned data frame on the workers with the partition() function. The function will try to split the data as heavenly as possible among workers.\nIf you group observations by some variable (with dplyr::group_by()) beforehand, multidplyr will ensure that all data points in a group end up on the same worker. This is very convenient in a lot of cases, but is not relevant here. Without grouping observations first, it is unclear how partition() chooses which observation goes to which worker. In our data, we have all the setosa observations first, then all the versicolor, and finally all the virginica. We want to make sure that the randomForest() function runs on a sample of all 3 species. We will thus randomly shuffle the data before partitioning it (when we were parallelizing by splitting the trees, we didn‚Äôt have to worry about that since each subset of trees was running on the entire dataset):\n\n# Shuffle the rows of the data frame randomly\nset.seed(11)\nbigger_iris_shuffled &lt;- bigger_iris[sample(nrow(bigger_iris)), ]\n\n# You can check that they are shuffled\nhead(bigger_iris_shuffled)\n\n       Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n65570           6.7         3.1          4.4         1.4 versicolor\n19004           5.1         3.8          1.5         0.3     setosa\n73612           6.1         2.8          4.7         1.2 versicolor\n28886           5.2         3.4          1.4         0.2     setosa\n121310          5.6         2.8          4.9         2.0  virginica\n21667           5.1         3.7          1.5         0.4     setosa\n\n\n# Create the partitioned data frame\nsplit_iris &lt;- partition(bigger_iris_shuffled, cl)\nsplit_iris\nSource: party_df [150,000 x 5]\nShards: 4 [37,500--37,500 rows]\n\n# A data frame: 150,000 √ó 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;\n1          6.7         3.1          4.4         1.4 versicolor\n2          5.6         2.8          4.9         2   virginica\n3          6.4         2.8          5.6         2.2 virginica\n4          5.6         2.5          3.9         1.1 versicolor\n5          4.7         3.2          1.6         0.2 setosa\n6          6.7         3            5           1.7 versicolor\n# ‚Ñπ 149,994 more rows\n# ‚Ñπ Use `print(n = ...)` to see more rows\nIf we want the code to be reproducible, we should set the seed on each worker:\ncluster_send(cl, set.seed(123))\n\nRun cluster_send() to send code to each worker when you aren‚Äôt interested in any result (as is the case here) and cluster_call() if you want a computation to be executed on each worker and a result to be returned.\n\nNow we can run the randomForest() function on each worker:\nsplit_rfs &lt;- split_iris %&gt;%\n  do(rf = randomForest(Species ~ ., data = .))\nsplit_rfs is a partitioned data frame containing the results from each worker (the intermediate randomForest models):\nsplit_rfs\nSource: party_df [4 x 1]\nShards: 4 [1--1 rows]\n\n# A data frame: 4 √ó 1\n  rf\n  &lt;list&gt;\n1 &lt;rndmFrs.&gt;\n2 &lt;rndmFrs.&gt;\n3 &lt;rndmFrs.&gt;\n4 &lt;rndmFrs.&gt;\nNow we need to bring the partitioned results in the main process:\nrfs &lt;- split_rfs %&gt;% collect()\nrfs is a data frame with a single column called rf:\nrfs\n# A tibble: 4 √ó 1\n  rf\n  &lt;list&gt;\n1 &lt;rndmFrs.&gt;\n2 &lt;rndmFrs.&gt;\n3 &lt;rndmFrs.&gt;\n4 &lt;rndmFrs.&gt;\nWhich means that rfs$rf is a list:\ntypeof(rfs$rf)\n[1] \"list\"\nEach element of this list is a randomForest object (the 4 intermediate models created by the 4 workers):\nrfs$rf\n[[1]]\n\nCall:\n randomForest(formula = Species ~ ., data = .)\n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 0%\nConfusion matrix:\n           setosa versicolor virginica class.error\nsetosa      12500          0         0           0\nversicolor      0      12500         0           0\nvirginica       0          0     12500           0\n\n[[2]]\n\nCall:\n randomForest(formula = Species ~ ., data = .)\n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 0%\nConfusion matrix:\n           setosa versicolor virginica class.error\nsetosa      12500          0         0           0\nversicolor      0      12500         0           0\nvirginica       0          0     12500           0\n\n[[3]]\n\nCall:\n randomForest(formula = Species ~ ., data = .)\n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 0%\nConfusion matrix:\n           setosa versicolor virginica class.error\nsetosa      12500          0         0           0\nversicolor      0      12500         0           0\nvirginica       0          0     12500           0\n\n[[4]]\n\nCall:\n randomForest(formula = Species ~ ., data = .)\n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 0%\nConfusion matrix:\n           setosa versicolor virginica class.error\nsetosa      12500          0         0           0\nversicolor      0      12500         0           0\nvirginica       0          0     12500           0\n\nIf you don‚Äôt need to explore the intermediate objects, you can combine the commands as:\nrfs &lt;- split_iris %&gt;%\n  do(rf = randomForest(Species ~ ., data = .)) %&gt;%\n  collect()\n\nFinally, we need to combine the 4 randomForest models into a single one. This can be done with the combine() function from the randomForest package (the same function we already used in our foreach expressions):\nrf_all &lt;- do.call(combine, rfs$rf)\n\nBe careful that randomForest and dplyr both have a combine() function. The one we want here is the one from the randomForest package. To avoid all conflict and confusion, you can use randomForest::combine(). combine() is ok if you make sure to load dplyr before randomForest since latest loaded functions overwrite earlier loaded ones.\n\nWhy are we using do.call()? If we use:\ncombine(rfs$rf)\nWe get the silly message:\nError in combine(rfs$rf) :\n  Argument must be a list of randomForest objects\nThat is because randomForest::combine() expects a list of randomForest objects, but cannot accept an object of type list.\nHere is our final randomForest model:\nrf_all\nCall:\n randomForest(formula = Species ~ ., data = .)\n               Type of random forest: classification\n                     Number of trees: 2000\nNo. of variables tried at each split: 2\nThis is it: by splitting our data frame on 4 cores, we could run the code and create a randomForest model using whole of the data.\nWe can test our model:\nnew_data &lt;- data.frame(\n  Sepal.Length = c(5.3, 4.6, 6.5),\n  Sepal.Width = c(3.1, 3.9, 2.5),\n  Petal.Length = c(1.5, 1.5, 5.0),\n  Petal.Width = c(0.2, 0.1, 2.1)\n)\n\npredict(rf_all, new_data)\n        1         2         3\n   setosa    setosa virginica\nLevels: setosa versicolor virginica\nRunning this in an interactive session was useful to see what happens, but the way you would actually do this is by writing a script (let‚Äôs call it partition.R):\n\n\npartition.R\n\nlibrary(multidplyr)\nlibrary(dplyr, warn.conflicts = FALSE)\n\n# Create cluster of workers\ncl &lt;- new_cluster(4)\n\n# Load randomForest on each worker\ncluster_library(cl, \"randomForest\")\n\n# Create our big data frame\nbigger_iris &lt;- iris[rep(seq_len(nrow(iris)), each = 1e3), ]\nrownames(bigger_iris) &lt;- NULL\n\n# Create a partitioned data frame on the workers\nsplit_iris &lt;- partition(bigger_iris, cl)\n\n# Set the seed on each worker\ncluster_send(cl, set.seed(123))\n\n# Run the randomForest() function on each worker\nrfs &lt;- split_iris %&gt;%\n  do(rf = randomForest(Species ~ ., data = .)) %&gt;%\n  collect()\n\n# Combine the randomForest models into one\nrf_all &lt;- do.call(combine, rfs$rf)\n\nAnd run it with a Bash partition.sh script:\n\n\npartition.sh\n\n#!/bin/bash\n#SBATCH --time=10\n#SBATCH --mem-per-cpu=7500M\n#SBATCH --cpus-per-task=4\n\nRscript partition.R\n\n\n\nConclusion\nmultidplyr allowed us to split our data frame across multiple workers on one node and this solved the memory issue we had with our large dataset.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Partitioning data"
    ]
  },
  {
    "objectID": "r/hpc_partition.html#data-partitioning-for-speed",
    "href": "r/hpc_partition.html#data-partitioning-for-speed",
    "title": "Partitioning data with multidplyr",
    "section": "Data partitioning for speed",
    "text": "Data partitioning for speed\nBeside the memory advantage, are we getting any speedup from data parallelization? i.e.¬†how does this code compare with the parallelization we did as regard the number of trees with foreach and doFuture?\nWe want to make sure to compare the same things. So we go back to our smaller big_iris and we up the number of trees back to 2000.\nWe will compare it with the plans multisession and multicore that we performed earlier. The minimum and median times for these two options for shared memory parallelism were of 2.72s and 3.15s respectively.\n\n\npartition_bench.R\n\nlibrary(multidplyr)\nlibrary(dplyr, warn.conflicts = FALSE)\nlibrary(bench)\n\ncl &lt;- new_cluster(4)\ncluster_library(cl, \"randomForest\")\n\nbig_iris &lt;- iris[rep(seq_len(nrow(iris)), each = 1e2), ]\nrownames(big_iris) &lt;- NULL\n\ncluster_send(cl, set.seed(123))\n\npart_rf &lt;- function(data, cluster) {\n  split_data &lt;- partition(data, cluster)\n  rfs &lt;- split_data %&gt;%\n    do(rf = randomForest(Species ~ ., data = ., ntree = 2000)) %&gt;%\n    collect()\n  do.call(combine, rfs$rf)\n}\n\nmark(rf_all &lt;- part_rf(big_iris, cl))\n\n\n\npartition_bench.sh\n\n#!/bin/bash\n#SBATCH --time=10\n#SBATCH --mem-per-cpu=7500M\n#SBATCH --cpus-per-task=4\n\nRscript partition_bench.R\n\nsbatch partition_bench.sh\nrandomForest 4.7-1.1\nType rfNews() to see new features/changes/bug fixes.\n\nAttaching package: ‚ÄòrandomForest‚Äô\n\nThe following object is masked from ‚Äòpackage:dplyr‚Äô:\n\n    combine\n\n# A tibble: 1 √ó 13\n  expression      min median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc total_time\n  &lt;bch:expr&gt;    &lt;bch&gt; &lt;bch:&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;   &lt;bch:tm&gt;\n1 rf_all &lt;- pa‚Ä¶ 2.48s  2.48s     0.403        NA     2.02     1     5      2.48s\n# ‚Ñπ 4 more variables: result &lt;list&gt;, memory &lt;list&gt;, time &lt;list&gt;, gc &lt;list&gt;\nWarning message:\nSome expressions had a GC in every iteration; so filtering is disabled.\n\nWhat about distributed memory?\nCan multidplyr run in distributed memory? There is nothing on this in the documentation, so I tried it.\nI upped the number of workers to 8 and ran the code on 2 nodes with 4 cores per node and got no speedup. I also created a dataset 10 times bigger (with each = 1e4), which creates an OOM on 4 cores one a single node and tried it on 11 nodes with 4 cores (10 to match the 10 times size increase, plus one to play safe). This didn‚Äôt solve the OOM issue. I tried various other tests, all with no success.\nIn conclusion, it seems that multidply‚Äôs way of creating a cluster of workers doesn‚Äôt have a mechanism to spread them across nodes and that the package thus does not allow to split data across nodes.\nIn cases where your data is so big that it doesn‚Äôt fit in the memory of a single node, it doesn‚Äôt seem that any R package currently allow to split the data automatically for you.\n\n\nConclusion\nAs we could see, we got similar results: in this case, it is the same to spread the number of trees running on the full data on 4 cores (as we did with foreach and doFuture or to run all the trees on the data spread on 4 cores.\nThe difference being that foreach and doFuture allowed us to spread the trees across nodes while multidplyr does not allow this for the data.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Partitioning data"
    ]
  },
  {
    "objectID": "r/hpc_partition.html#direct-data-loading",
    "href": "r/hpc_partition.html#direct-data-loading",
    "title": "Partitioning data with multidplyr",
    "section": "Direct data loading",
    "text": "Direct data loading\nThe method we used is very convenient, but it involves copying the data to the workers. If you want to save some memory, you can load the split data directly to the workers.\nFor this, first, split your data into several files and have all those files (and only those files) in a directory.\nThen, you can run:\nlibrary(multidplyr)\nlibrary(dplyr)\nlibrary(vroom)\n\n# Create the cluster of workers\ncl &lt;- new_cluster(4)\n\n# Create a character vector with the list of data files\nfiles &lt;- dir(\"/path/to/data/directory\", full.names = TRUE)\n\n# Split up the vector amongst the workers\ncluster_assign_partition(cl, files = files)\n\n# Create a data frame called split_iris on each worker\ncluster_send(cl, split_iris &lt;- vroom(files))\n\n# Create the partitioned data frame from the workers' data frames\nsplit_iris &lt;- party_df(cl, \"split_iris\")\nFrom here on, you can work as we did earlier.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Partitioning data"
    ]
  },
  {
    "objectID": "r/hpc_rcpp.html",
    "href": "r/hpc_rcpp.html",
    "title": "Writing C++ in R with Rcpp",
    "section": "",
    "text": "Sometimes, parallelization is not an option, either because the code is hard to parallelize or because of lack of hardware. In such cases, one way to increase speed is to replace slow R code with C++ code. The package Rcpp makes this easier by creating mappings between both languages and allowing you to embed snippets of C++ code directly in R and removing the need for pre-compilation.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Writing C++ in R with Rcpp"
    ]
  },
  {
    "objectID": "r/hpc_rcpp.html#back-to-fibonacci",
    "href": "r/hpc_rcpp.html#back-to-fibonacci",
    "title": "Writing C++ in R with Rcpp",
    "section": "Back to Fibonacci",
    "text": "Back to Fibonacci\nDo you remember the Fibonacci numbers? Here was a naive implementation in R:\n\nfib &lt;- function(n) {\n  if(n == 0) return(0)\n  if(n == 1) return(1)\n  Recall(n - 1) + Recall(n - 2)\n}\n\nThis function gives the nth number in the sequence.\n\nExample:\n\n\nfib(30)\n\n[1] 832040",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Writing C++ in R with Rcpp"
    ]
  },
  {
    "objectID": "r/hpc_rcpp.html#rcpp",
    "href": "r/hpc_rcpp.html#rcpp",
    "title": "Writing C++ in R with Rcpp",
    "section": "Rcpp",
    "text": "Rcpp\nLet‚Äôs translate this function in C++ within R!\nFirst we need to load the Rcpp package:\n\nlibrary(Rcpp)\n\nWe then use the function cppFunction() to assign to an R function a function written in C++:\n\nfibRcpp &lt;- cppFunction( '\nint fibonacci(const int x) {\n   if (x == 0) return(0);\n   if (x == 1) return(1);\n   return (fibonacci(x - 1)) + fibonacci(x - 2);\n}\n' )\n\nWe can call our function as any R function:\nfibRcpp(30)\n[1] 832040\nWe can compare both functions:\nlibrary(bench)\n\nn &lt;- 30\nmark(fib(n), fibRcpp(n))\n# A tibble: 2 √ó 13\n  expression      min   median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc\n  &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;\n1 fib(n)        1.66s    1.66s     0.601    44.7KB     22.8     1    38\n2 fibRcpp(n)   1.08ms   1.08ms   901.       2.49KB      0     451     0\n  total_time result    memory                 time            \n    &lt;bch:tm&gt; &lt;list&gt;    &lt;list&gt;                 &lt;list&gt;          \n1      1.66s &lt;dbl [1]&gt; &lt;Rprofmem [6,778 √ó 3]&gt; &lt;bench_tm [1]&gt;  \n2   500.37ms &lt;int [1]&gt; &lt;Rprofmem [1 √ó 3]&gt;     &lt;bench_tm [451]&gt;\n  gc                \n  &lt;list&gt;            \n1 &lt;tibble [1 √ó 3]&gt;  \n2 &lt;tibble [451 √ó 3]&gt;\nWarning message:\nSome expressions had a GC in every iteration; so filtering is disabled.\nThe speedup is 1,537, which is amazing.\nIn this particular example, we saw that memoisation gives an even more incredible speedup (35,000!), but while memoisation will only work in very specific situations (e.g.¬†recursive function calls), using C++ code is a general method to provide speedup. It is particularly useful when:\n\nthere are large numbers of function calls (R is particularly slow with function calls),\nyou need data structures that are missing in R,\nyou want to create efficient packages (fast R packages are written in C++ and many use Rcpp).\n\n\nIn this example, we declared the C++ function directly in R. It is possible to use source files instead.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "Writing C++ in R with Rcpp"
    ]
  },
  {
    "objectID": "r/hpc_run.html",
    "href": "r/hpc_run.html",
    "title": "SSH login",
    "section": "",
    "text": "This section will show you how to access our temporary remote cluster through SSH.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "SSH login"
    ]
  },
  {
    "objectID": "r/hpc_run.html#why-not-use-an-rstudio-server",
    "href": "r/hpc_run.html#why-not-use-an-rstudio-server",
    "title": "SSH login",
    "section": "Why not use an RStudio server?",
    "text": "Why not use an RStudio server?\nIn our introduction to R, we used an RStudio server running on a remote cluster. In this course, we will log in a similar remote supercomputer using Secure Shell, then run R scripts from the command line.\nWhy are we not making use of the interactivity of R which is an interpreted language and why are we not using the added comfort of an IDE? The short answer is: resource efficiency.\nOnce you have developed your code in an interactive fashion in the IDE of your choice using small hardware resources on a sample of your data, running scripts allows you to only request large resources when you need them (i.e.¬†when your code is running). This prevents heavy resources from sitting idle when not in use, as would happen in an interactive session while you type, think, etc. It will save you money on commercial clusters and waiting time on the Alliance clusters.\nThis course being about high-performance R, let‚Äôs learn to use it through scripts.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "SSH login"
    ]
  },
  {
    "objectID": "r/hpc_run.html#remote-connection-to-the-cluster",
    "href": "r/hpc_run.html#remote-connection-to-the-cluster",
    "title": "SSH login",
    "section": "Remote connection to the cluster",
    "text": "Remote connection to the cluster\n\nStep 1: get the info\nDuring the workshop, we will give you 3 pieces of information:\n\na link to a list of usernames,\nthe hostname for our temporary training cluster,\nthe password to access that cluster.\n\n\n\nStep 2: claim a username\nAdd your first name or a pseudo next to a free username on the list to claim it.\nYour username is the name that was already on the list, NOT what you wrote next to it (which doesn‚Äôt matter at all and only serves at signalling that this username is now taken).\nYour username will look like userxx‚Äîxx being 2 digits‚Äîwith no space and no capital letter.\n\n\nStep 3: run the ssh command\n\n¬†‚Ä¢¬† Linux and macOS users\nLinux users: ‚ÄÇ‚ÄÇopen the terminal emulator of your choice.\nmacOS users: ¬†¬†open ‚ÄúTerminal‚Äù.\nThen type:\nssh userxx@hostname\nand press Enter.\n\n\nReplace userxx by your username (e.g.¬†user09).\nReplace hostname by the hostname we will give you the day of the workshop.\n\n\nWhen asked:\n\nAre you sure you want to continue connecting (yes/no/[fingerprint])?\n\nAnswer: ‚Äúyes‚Äù.\n\n\n¬†‚Ä¢¬† Windows users\nWe suggest using the free version of MobaXterm. MobaXterm comes with a terminal emulator and a GUI interface for SSH sessions.\nHere is how to log in with MobaXterm:\n\nopen MobaXterm,\nclick on Session (top left corner),\nclick on SSH (top left corner),\nfill in the Remote host * box with the cluster hostname we gave you,\ntick the box Specify username,\nfill in the box with the username you selected (e.g.¬†user09),\npress OK,\nwhen asked Are you sure you want to continue connecting (yes/no/[fingerprint])?, answer: ‚Äúyes‚Äù.\n\n\nHere is a live demo.\n\n\n\n\nStep 4: enter the password\nWhen prompted, enter the password we gave you.\nYou will not see anything happen as you type the password. This is normal and it is working, so keep on typing the password.\n\nThis is called blind typing and is a Linux safety feature. It can be unsettling at first not to get any feed-back while typing as it really looks like it is not working. Type slowly and make sure not to make typos.\n\nThen press Enter.\nYou are now logged in and your prompt should look like the following (with your actual username):\n[userxx@login1 ~]$\n\n\nTroubleshooting\nProblems logging in are almost always due to typos. If you cannot log in, retry slowly, entering your password carefully.",
    "crumbs": [
      "R",
      "<b><em>High-performance R</em></b>",
      "SSH login"
    ]
  },
  {
    "objectID": "r/hss_automation.html",
    "href": "r/hss_automation.html",
    "title": "Automation",
    "section": "",
    "text": "One of the strengths of programming is the ability to automate tasks.\nIn this section, we will see how a loop can automate the creation of file names.\n\nLet‚Äôs say that we now want to import data from 5 files arc1.csv, ‚Ä¶, arc5.csv and create 5 data frames with their data.\nWe need a character vector with the file names.\nWe could create it this way:\n\nfiles &lt;- c(\n  \"https://mint.westdri.ca/r/hss_data/arc1.csv\",\n  \"https://mint.westdri.ca/r/hss_data/arc2.csv\",\n  \"https://mint.westdri.ca/r/hss_data/arc3.csv\",\n  \"https://mint.westdri.ca/r/hss_data/arc4.csv\",\n  \"https://mint.westdri.ca/r/hss_data/arc5.csv\"\n)\n\nIt works of course:\n\nfiles\n\n[1] \"https://mint.westdri.ca/r/hss_data/arc1.csv\"\n[2] \"https://mint.westdri.ca/r/hss_data/arc2.csv\"\n[3] \"https://mint.westdri.ca/r/hss_data/arc3.csv\"\n[4] \"https://mint.westdri.ca/r/hss_data/arc4.csv\"\n[5] \"https://mint.westdri.ca/r/hss_data/arc5.csv\"\n\n\nBut if we had 50 files instead of 5, it would be quite a tedium! And if we had 500 files, it would be unrealistic. A better approach is to write a loop.\nIn order to store the results of a loop, we need to create an empty object and assign to it the result of the loop at each iteration. It is very important to pre-allocate memory: by creating an empty object of the final size, the necessary memory to hold this object is requested once (then the object gets filled in while the loop runs). Without this, more memory would have to be allocated at each iteration of the loop and this is highly inefficient.\nSo let‚Äôs create an empty vector of length 5 and of type character:\n\nfiles &lt;- character(5)\n\nNow we can fill in our vector with the proper values with the loop:\n\nfor (i in 1:5) {\n  files[i] &lt;- paste0(\"https://mint.westdri.ca/r/hss_data/arc\", i, \".csv\")\n}\n\nThis gives us the same result, but the big difference is that it is scalable:\n\nfiles\n\n[1] \"https://mint.westdri.ca/r/hss_data/arc1.csv\"\n[2] \"https://mint.westdri.ca/r/hss_data/arc2.csv\"\n[3] \"https://mint.westdri.ca/r/hss_data/arc3.csv\"\n[4] \"https://mint.westdri.ca/r/hss_data/arc4.csv\"\n[5] \"https://mint.westdri.ca/r/hss_data/arc5.csv\"\n\n\nNow, if our files were not named following such a nice sequence, we would have to modify our loop a little. Below are two examples:\n\nfiles &lt;- character(5)\n\nfor (i in seq_along(c(3, 6, 9, 10, 14))) {\n  files[i] &lt;- paste0(\n    \"https://mint.westdri.ca/r/hss_data/arc\",\n    c(3, 6, 9, 10, 14)[i],\n    \".csv\"\n  )\n}\n\nfiles\n\n[1] \"https://mint.westdri.ca/r/hss_data/arc3.csv\" \n[2] \"https://mint.westdri.ca/r/hss_data/arc6.csv\" \n[3] \"https://mint.westdri.ca/r/hss_data/arc9.csv\" \n[4] \"https://mint.westdri.ca/r/hss_data/arc10.csv\"\n[5] \"https://mint.westdri.ca/r/hss_data/arc14.csv\"\n\n\n\nfiles &lt;- character(5)\n\nfor (i in seq_along(c(\"_a\", \"_b\", \"_c\", \"_d\", \"_e\"))) {\n  files[i] &lt;- paste0(\n    \"https://mint.westdri.ca/r/hss_data/arc\",\n    c(\"_a\", \"_b\", \"_c\", \"_d\", \"_e\")[i],\n    \".csv\"\n  )\n}\n\nfiles\n\n[1] \"https://mint.westdri.ca/r/hss_data/arc_a.csv\"\n[2] \"https://mint.westdri.ca/r/hss_data/arc_b.csv\"\n[3] \"https://mint.westdri.ca/r/hss_data/arc_c.csv\"\n[4] \"https://mint.westdri.ca/r/hss_data/arc_d.csv\"\n[5] \"https://mint.westdri.ca/r/hss_data/arc_e.csv\"\n\n\n\nIf you had all the files in one directory, an alternative approach would be to create a list of all the names matching a regular expression.\nIn our case, we would use:\nfiles &lt;- list.files(pattern=\"^arc\\\\d+\\\\.csv$\")",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Automation"
    ]
  },
  {
    "objectID": "r/hss_explore.html",
    "href": "r/hss_explore.html",
    "title": "Data exploration",
    "section": "",
    "text": "An important first step of data analysis is to have a look at the data. In this section, we will explore the us_contagious_diseases dataset from the dslabs package.",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data exploration"
    ]
  },
  {
    "objectID": "r/hss_explore.html#load-the-dslabs-package",
    "href": "r/hss_explore.html#load-the-dslabs-package",
    "title": "Data exploration",
    "section": "Load the dslabs package",
    "text": "Load the dslabs package\nThis package contains a number of datasets. To access any of them, we first need to load the package:\n\nlibrary(dslabs)\n\n\nlibrary() is a function:\n\nclass(library)\n\n[1] \"function\"\n\n\nFunctions are the ‚Äúverbs‚Äù of programming languages. They do things.\nlibrary() is a function that loads packages into the current session so that their content becomes available.\ndslabs is the argument that we pass to the function library(): it is this particular packages that we are loading in the session here.\nclass() is also a function: it tells what class an object belongs to. In class(library), library is the argument of the function class().",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data exploration"
    ]
  },
  {
    "objectID": "r/hss_explore.html#printing-data-to-screen",
    "href": "r/hss_explore.html#printing-data-to-screen",
    "title": "Data exploration",
    "section": "Printing data to screen",
    "text": "Printing data to screen\nTo print all the data, we would simply run us_contagious_diseases. There are a lot of rows however, so we only want to print a subset to the screen.\nTo print the first six rows, we use the function head(), using our data as the argument:\n\nhead(us_contagious_diseases)\n\n      disease   state year weeks_reporting count population\n1 Hepatitis A Alabama 1966              50   321    3345787\n2 Hepatitis A Alabama 1967              49   291    3364130\n3 Hepatitis A Alabama 1968              52   314    3386068\n4 Hepatitis A Alabama 1969              49   380    3412450\n5 Hepatitis A Alabama 1970              51   413    3444165\n6 Hepatitis A Alabama 1971              51   378    3481798\n\n\nIf you look at the documentation of the head() function (by running ?head), you can see that it accepts another argument that allows us to set the number of rows to print.\nLet‚Äôs print the first 15 rows:\n\nhead(us_contagious_diseases, n = 15)\n\n       disease   state year weeks_reporting count population\n1  Hepatitis A Alabama 1966              50   321    3345787\n2  Hepatitis A Alabama 1967              49   291    3364130\n3  Hepatitis A Alabama 1968              52   314    3386068\n4  Hepatitis A Alabama 1969              49   380    3412450\n5  Hepatitis A Alabama 1970              51   413    3444165\n6  Hepatitis A Alabama 1971              51   378    3481798\n7  Hepatitis A Alabama 1972              45   342    3524543\n8  Hepatitis A Alabama 1973              45   467    3571209\n9  Hepatitis A Alabama 1974              45   244    3620548\n10 Hepatitis A Alabama 1975              46   286    3671246\n11 Hepatitis A Alabama 1976              50   220    3721914\n12 Hepatitis A Alabama 1977              43   206    3771085\n13 Hepatitis A Alabama 1978              41   203    3817217\n14 Hepatitis A Alabama 1979              47   257    3858703\n15 Hepatitis A Alabama 1980              37   200    3893888\n\n\n\nBy default, n = 6 which is why head() prints six rows unless we specify otherwise. The L in the documentation of the print() function (n = 6L) means that 6 is an integer. You can ignore this for now.\nArguments can be passed to functions as positional arguments (then they have to respect the position of the function definition) or as named arguments (in that case, you need to use the arguments names).\nThat means that iff we keep the arguments in the right order, we can omit the name of the argument (n here) and only write its value (15). :\n\nhead(us_contagious_diseases, 15)\n\n       disease   state year weeks_reporting count population\n1  Hepatitis A Alabama 1966              50   321    3345787\n2  Hepatitis A Alabama 1967              49   291    3364130\n3  Hepatitis A Alabama 1968              52   314    3386068\n4  Hepatitis A Alabama 1969              49   380    3412450\n5  Hepatitis A Alabama 1970              51   413    3444165\n6  Hepatitis A Alabama 1971              51   378    3481798\n7  Hepatitis A Alabama 1972              45   342    3524543\n8  Hepatitis A Alabama 1973              45   467    3571209\n9  Hepatitis A Alabama 1974              45   244    3620548\n10 Hepatitis A Alabama 1975              46   286    3671246\n11 Hepatitis A Alabama 1976              50   220    3721914\n12 Hepatitis A Alabama 1977              43   206    3771085\n13 Hepatitis A Alabama 1978              41   203    3817217\n14 Hepatitis A Alabama 1979              47   257    3858703\n15 Hepatitis A Alabama 1980              37   200    3893888\n\n\nIf the arguments are given to the function out of order however, we do need to use their names.\nThis won‚Äôt work because R needs an integer for n or for the 2nd argument:\n\nhead(15, us_contagious_diseases)\n\nError in head.default(15, us_contagious_diseases): invalid 'n' - must be numeric, possibly NA.\n\n\nThis however works:\n\nhead(n = 15, us_contagious_diseases)\n\n       disease   state year weeks_reporting count population\n1  Hepatitis A Alabama 1966              50   321    3345787\n2  Hepatitis A Alabama 1967              49   291    3364130\n3  Hepatitis A Alabama 1968              52   314    3386068\n4  Hepatitis A Alabama 1969              49   380    3412450\n5  Hepatitis A Alabama 1970              51   413    3444165\n6  Hepatitis A Alabama 1971              51   378    3481798\n7  Hepatitis A Alabama 1972              45   342    3524543\n8  Hepatitis A Alabama 1973              45   467    3571209\n9  Hepatitis A Alabama 1974              45   244    3620548\n10 Hepatitis A Alabama 1975              46   286    3671246\n11 Hepatitis A Alabama 1976              50   220    3721914\n12 Hepatitis A Alabama 1977              43   206    3771085\n13 Hepatitis A Alabama 1978              41   203    3817217\n14 Hepatitis A Alabama 1979              47   257    3858703\n15 Hepatitis A Alabama 1980              37   200    3893888\n\n\n\nWe can also print the last 6 rows of the data:\n\ntail(us_contagious_diseases)\n\n       disease   state year weeks_reporting count population\n16060 Smallpox Wyoming 1947              49     1     276297\n16061 Smallpox Wyoming 1948              24     1     280803\n16062 Smallpox Wyoming 1949               0     0     285544\n16063 Smallpox Wyoming 1950               1     2     290529\n16064 Smallpox Wyoming 1951               1     1     295744\n16065 Smallpox Wyoming 1952               1     1     301083\n\n\n\n\nYour turn:\n\nHow would you print the last 10 rows of the data?",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data exploration"
    ]
  },
  {
    "objectID": "r/hss_explore.html#structure-of-the-data-object",
    "href": "r/hss_explore.html#structure-of-the-data-object",
    "title": "Data exploration",
    "section": "Structure of the data object",
    "text": "Structure of the data object\nus_contagious_diseases is an R object containing the dataset, but what kind of object is it?\n\nclass(us_contagious_diseases)\n\n[1] \"data.frame\"\n\n\nOur data is in a class of R object called a data frame.\nWe can get its full structure with:\n\nstr(us_contagious_diseases)\n\n'data.frame':   16065 obs. of  6 variables:\n $ disease        : Factor w/ 7 levels \"Hepatitis A\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ state          : Factor w/ 51 levels \"Alabama\",\"Alaska\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ year           : num  1966 1967 1968 1969 1970 ...\n $ weeks_reporting: num  50 49 52 49 51 51 45 45 45 46 ...\n $ count          : num  321 291 314 380 413 378 342 467 244 286 ...\n $ population     : num  3345787 3364130 3386068 3412450 3444165 ...\n\n\nThe names of the variables can be obtained with:\n\nnames(us_contagious_diseases)\n\n[1] \"disease\"         \"state\"           \"year\"            \"weeks_reporting\"\n[5] \"count\"           \"population\"     \n\n\nYou can display the data frame in a tabular fashion thanks to:\nView(us_contagious_diseases)",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data exploration"
    ]
  },
  {
    "objectID": "r/hss_explore.html#dimensions-of-our-data-frame",
    "href": "r/hss_explore.html#dimensions-of-our-data-frame",
    "title": "Data exploration",
    "section": "Dimensions of our data frame",
    "text": "Dimensions of our data frame\n\ndim(us_contagious_diseases)\n\n[1] 16065     6\n\nncol(us_contagious_diseases)\n\n[1] 6\n\nnrow(us_contagious_diseases)\n\n[1] 16065\n\n\n\nlength(us_contagious_diseases)\n\n[1] 6\n\nlength(us_contagious_diseases$disease)\n\n[1] 16065",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data exploration"
    ]
  },
  {
    "objectID": "r/hss_explore.html#summary-statistics",
    "href": "r/hss_explore.html#summary-statistics",
    "title": "Data exploration",
    "section": "Summary statistics",
    "text": "Summary statistics\n\nsummary(us_contagious_diseases)\n\n        disease            state            year      weeks_reporting\n Hepatitis A:2346   Alabama   :  315   Min.   :1928   Min.   : 0.00  \n Measles    :3825   Alaska    :  315   1st Qu.:1950   1st Qu.:31.00  \n Mumps      :1785   Arizona   :  315   Median :1975   Median :46.00  \n Pertussis  :2856   Arkansas  :  315   Mean   :1971   Mean   :37.38  \n Polio      :2091   California:  315   3rd Qu.:1990   3rd Qu.:50.00  \n Rubella    :1887   Colorado  :  315   Max.   :2011   Max.   :52.00  \n Smallpox   :1275   (Other)   :14175                                 \n     count          population      \n Min.   :     0   Min.   :   86853  \n 1st Qu.:     7   1st Qu.: 1018755  \n Median :    69   Median : 2749249  \n Mean   :  1493   Mean   : 4107584  \n 3rd Qu.:   525   3rd Qu.: 4996229  \n Max.   :132342   Max.   :37607525  \n                  NA's   :214",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data exploration"
    ]
  },
  {
    "objectID": "r/hss_help.html",
    "href": "r/hss_help.html",
    "title": "Help and documentation",
    "section": "",
    "text": "One of the strengths of R is its great documentation. Here, we will learn how to make use of it.",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Help and documentation"
    ]
  },
  {
    "objectID": "r/hss_help.html#general-documentation",
    "href": "r/hss_help.html#general-documentation",
    "title": "Help and documentation",
    "section": "General documentation",
    "text": "General documentation\nTo get started with R, you can launch the general documentation with:\nhelp.start()",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Help and documentation"
    ]
  },
  {
    "objectID": "r/hss_help.html#help-on-functions",
    "href": "r/hss_help.html#help-on-functions",
    "title": "Help and documentation",
    "section": "Help on functions",
    "text": "Help on functions\nTo get help on specific objects (e.g.¬†the function sum), you can run:\nhelp(sum)\nor:\n?sum\n\nThe documentation pages always follow the same format:\n\nName of the object and the package it comes from\nA short description of the object\nThe code to use it\nAn explanation of the arguments (in the case of functions)\nExplanation with greater details\nThe value returned (in the case of functions)\nExamples of code snippets that can be run",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Help and documentation"
    ]
  },
  {
    "objectID": "r/hss_manipulate.html",
    "href": "r/hss_manipulate.html",
    "title": "Data extraction",
    "section": "",
    "text": "It is often useful to focus on sections of the data to plot or analyse. In this section, we will see how to extract various elements of the us_contagious_diseases dataset from the dslabs package.",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data extraction"
    ]
  },
  {
    "objectID": "r/hss_manipulate.html#load-packages",
    "href": "r/hss_manipulate.html#load-packages",
    "title": "Data extraction",
    "section": "Load packages",
    "text": "Load packages\nOne of the tidyverse packages is very useful for data manipulation: dplyr. Let‚Äôs load the dslabs package again as well as dplyr:\n\nlibrary(dslabs)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data extraction"
    ]
  },
  {
    "objectID": "r/hss_manipulate.html#indexing",
    "href": "r/hss_manipulate.html#indexing",
    "title": "Data extraction",
    "section": "Indexing",
    "text": "Indexing\nYou can extract a subset of the data using their position by indexing. Indexing in R starts with 1 (in many languages, the first index is 0) and it is done with square brackets. Since a data frame has two dimensions, there are two possible indices in the square brackets:\n\nthe row index,\nthe column index.\n\nYou can index a single element:\n\nus_contagious_diseases[1, 1]\n\n[1] Hepatitis A\nLevels: Hepatitis A Measles Mumps Pertussis Polio Rubella Smallpox\n\nus_contagious_diseases[1, 2]\n\n[1] Alabama\n51 Levels: Alabama Alaska Arizona Arkansas California Colorado ... Wyoming\n\n\nOr a full row:\n\nus_contagious_diseases[1, ]\n\n      disease   state year weeks_reporting count population\n1 Hepatitis A Alabama 1966              50   321    3345787\n\nus_contagious_diseases[3000, ]\n\n     disease                state year weeks_reporting count population\n3000 Measles District Of Columbia 1981              27     2     631010\n\n\n\n\nYour turn:\n\nHow would you index the year column?",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data extraction"
    ]
  },
  {
    "objectID": "r/hss_manipulate.html#filtering-rows",
    "href": "r/hss_manipulate.html#filtering-rows",
    "title": "Data extraction",
    "section": "Filtering rows",
    "text": "Filtering rows\nYou can also filter data points based on their values:\n\nus_contagious_diseases |&gt;\n  filter(state == \"California\") |&gt;\n  count()\n\n    n\n1 315\n\n\n\n\nYour turn:\n\nHow many data points are there for the state of Arizona?\n\n\nus_contagious_diseases |&gt;\n  filter(state == \"California\" & year &gt; 2000)\n\n       disease      state year weeks_reporting count population\n1  Hepatitis A California 2001              40  1599   34199784\n2  Hepatitis A California 2002              49  1364   34529758\n3  Hepatitis A California 2003              46  1045   34861711\n4  Hepatitis A California 2004              48   788   35195792\n5  Hepatitis A California 2005              49   905   35532154\n6  Hepatitis A California 2006              52   688   35870957\n7  Hepatitis A California 2007              51   312   36212364\n8  Hepatitis A California 2008              52   337   36556548\n9  Hepatitis A California 2009              52   239   36903684\n10 Hepatitis A California 2010              49   201   37253956\n11 Hepatitis A California 2011              49   176   37607525\n12     Measles California 2001              40    34   34199784\n13     Measles California 2002              33     0   34529758\n14       Mumps California 2001              49    37   34199784\n15       Mumps California 2002              49    66   34529758\n16   Pertussis California 2001              40   440   34199784\n17   Pertussis California 2002              43   698   34529758\n18   Pertussis California 2003              41   635   34861711\n19   Pertussis California 2004              36   498   35195792\n20   Pertussis California 2005              45  1609   35532154\n21   Pertussis California 2006              42   831   35870957\n22   Pertussis California 2007              29    95   36212364\n23   Pertussis California 2008              39   276   36556548\n24   Pertussis California 2009              40   415   36903684\n25   Pertussis California 2010              48  1265   37253956\n26   Pertussis California 2011              49  1145   37607525\n27     Rubella California 2001               1     0   34199784\n28     Rubella California 2002              29     2   34529758\n\n\n\nus_contagious_diseases |&gt;\n  filter(state == \"California\" & year &gt; 2000) |&gt;\n  arrange(year)\n\n       disease      state year weeks_reporting count population\n1  Hepatitis A California 2001              40  1599   34199784\n2      Measles California 2001              40    34   34199784\n3        Mumps California 2001              49    37   34199784\n4    Pertussis California 2001              40   440   34199784\n5      Rubella California 2001               1     0   34199784\n6  Hepatitis A California 2002              49  1364   34529758\n7      Measles California 2002              33     0   34529758\n8        Mumps California 2002              49    66   34529758\n9    Pertussis California 2002              43   698   34529758\n10     Rubella California 2002              29     2   34529758\n11 Hepatitis A California 2003              46  1045   34861711\n12   Pertussis California 2003              41   635   34861711\n13 Hepatitis A California 2004              48   788   35195792\n14   Pertussis California 2004              36   498   35195792\n15 Hepatitis A California 2005              49   905   35532154\n16   Pertussis California 2005              45  1609   35532154\n17 Hepatitis A California 2006              52   688   35870957\n18   Pertussis California 2006              42   831   35870957\n19 Hepatitis A California 2007              51   312   36212364\n20   Pertussis California 2007              29    95   36212364\n21 Hepatitis A California 2008              52   337   36556548\n22   Pertussis California 2008              39   276   36556548\n23 Hepatitis A California 2009              52   239   36903684\n24   Pertussis California 2009              40   415   36903684\n25 Hepatitis A California 2010              49   201   37253956\n26   Pertussis California 2010              48  1265   37253956\n27 Hepatitis A California 2011              49   176   37607525\n28   Pertussis California 2011              49  1145   37607525\n\n\n\nus_contagious_diseases |&gt;\n  filter(state == \"California\" & year &gt; 2000) |&gt;\n  arrange(count)\n\n       disease      state year weeks_reporting count population\n1      Measles California 2002              33     0   34529758\n2      Rubella California 2001               1     0   34199784\n3      Rubella California 2002              29     2   34529758\n4      Measles California 2001              40    34   34199784\n5        Mumps California 2001              49    37   34199784\n6        Mumps California 2002              49    66   34529758\n7    Pertussis California 2007              29    95   36212364\n8  Hepatitis A California 2011              49   176   37607525\n9  Hepatitis A California 2010              49   201   37253956\n10 Hepatitis A California 2009              52   239   36903684\n11   Pertussis California 2008              39   276   36556548\n12 Hepatitis A California 2007              51   312   36212364\n13 Hepatitis A California 2008              52   337   36556548\n14   Pertussis California 2009              40   415   36903684\n15   Pertussis California 2001              40   440   34199784\n16   Pertussis California 2004              36   498   35195792\n17   Pertussis California 2003              41   635   34861711\n18 Hepatitis A California 2006              52   688   35870957\n19   Pertussis California 2002              43   698   34529758\n20 Hepatitis A California 2004              48   788   35195792\n21   Pertussis California 2006              42   831   35870957\n22 Hepatitis A California 2005              49   905   35532154\n23 Hepatitis A California 2003              46  1045   34861711\n24   Pertussis California 2011              49  1145   37607525\n25   Pertussis California 2010              48  1265   37253956\n26 Hepatitis A California 2002              49  1364   34529758\n27 Hepatitis A California 2001              40  1599   34199784\n28   Pertussis California 2005              45  1609   35532154\n\n\n\nus_contagious_diseases |&gt;\n  filter(state == \"California\" & year &gt; 2000) |&gt;\n  arrange(desc(count))\n\n       disease      state year weeks_reporting count population\n1    Pertussis California 2005              45  1609   35532154\n2  Hepatitis A California 2001              40  1599   34199784\n3  Hepatitis A California 2002              49  1364   34529758\n4    Pertussis California 2010              48  1265   37253956\n5    Pertussis California 2011              49  1145   37607525\n6  Hepatitis A California 2003              46  1045   34861711\n7  Hepatitis A California 2005              49   905   35532154\n8    Pertussis California 2006              42   831   35870957\n9  Hepatitis A California 2004              48   788   35195792\n10   Pertussis California 2002              43   698   34529758\n11 Hepatitis A California 2006              52   688   35870957\n12   Pertussis California 2003              41   635   34861711\n13   Pertussis California 2004              36   498   35195792\n14   Pertussis California 2001              40   440   34199784\n15   Pertussis California 2009              40   415   36903684\n16 Hepatitis A California 2008              52   337   36556548\n17 Hepatitis A California 2007              51   312   36212364\n18   Pertussis California 2008              39   276   36556548\n19 Hepatitis A California 2009              52   239   36903684\n20 Hepatitis A California 2010              49   201   37253956\n21 Hepatitis A California 2011              49   176   37607525\n22   Pertussis California 2007              29    95   36212364\n23       Mumps California 2002              49    66   34529758\n24       Mumps California 2001              49    37   34199784\n25     Measles California 2001              40    34   34199784\n26     Rubella California 2002              29     2   34529758\n27     Measles California 2002              33     0   34529758\n28     Rubella California 2001               1     0   34199784",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data extraction"
    ]
  },
  {
    "objectID": "r/hss_manipulate.html#selecting-columns",
    "href": "r/hss_manipulate.html#selecting-columns",
    "title": "Data extraction",
    "section": "Selecting columns",
    "text": "Selecting columns\nWe saw how to index columns from their position. It is also possible to select them based on their names:\n\nhead(us_contagious_diseases$year, 50)\n\n [1] 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980\n[16] 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995\n[31] 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010\n[46] 2011 1966 1967 1968 1969\n\n\nIf you want to select several columns, you can use the select() function from dplyr:\n\nus_contagious_diseases |&gt;\n  filter(state == \"California\" & year &gt; 2000 & disease == \"Hepatitis A\") |&gt;\n  select(year, count, population)\n\n   year count population\n1  2001  1599   34199784\n2  2002  1364   34529758\n3  2003  1045   34861711\n4  2004   788   35195792\n5  2005   905   35532154\n6  2006   688   35870957\n7  2007   312   36212364\n8  2008   337   36556548\n9  2009   239   36903684\n10 2010   201   37253956\n11 2011   176   37607525",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data extraction"
    ]
  },
  {
    "objectID": "r/hss_manipulate.html#grouping-data",
    "href": "r/hss_manipulate.html#grouping-data",
    "title": "Data extraction",
    "section": "Grouping data",
    "text": "Grouping data\nIt is often useful to group data by categories to compute some summary statistics.\nFor instance, we can group by year and calculate the total numbers of infections:\n\nus_contagious_diseases |&gt;\n  group_by(year) |&gt;\n  summarise(total = sum(count))\n\n# A tibble: 84 √ó 2\n    year  total\n   &lt;dbl&gt;  &lt;dbl&gt;\n 1  1928 524563\n 2  1929 380196\n 3  1930 439289\n 4  1931 482886\n 5  1932 404683\n 6  1933 391485\n 7  1934 739509\n 8  1935 739224\n 9  1936 292530\n10  1937 314425\n# ‚Ñπ 74 more rows\n\n\nAlternatively, we can group by state and get the totals:\n\nus_contagious_diseases |&gt;\n  group_by(state) |&gt; \n  summarise(total = sum(count))\n\n# A tibble: 51 √ó 2\n   state                  total\n   &lt;fct&gt;                  &lt;dbl&gt;\n 1 Alabama               257979\n 2 Alaska                 29136\n 3 Arizona               240233\n 4 Arkansas              177556\n 5 California           1906067\n 6 Colorado              322845\n 7 Connecticut           463148\n 8 Delaware               44427\n 9 District Of Columbia   77012\n10 Florida               268383\n# ‚Ñπ 41 more rows\n\n\nWe can also group by year and state and get the totals:\n\nus_contagious_diseases |&gt;\n  group_by(year, state) |&gt; \n  summarise(total = sum(count))\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 4,284 √ó 3\n# Groups:   year [84]\n    year state                total\n   &lt;dbl&gt; &lt;fct&gt;                &lt;dbl&gt;\n 1  1928 Alabama               9246\n 2  1928 Alaska                   0\n 3  1928 Arizona               1268\n 4  1928 Arkansas              9157\n 5  1928 California            4960\n 6  1928 Colorado              2510\n 7  1928 Connecticut          10247\n 8  1928 Delaware               607\n 9  1928 District Of Columbia  2609\n10  1928 Florida               1892\n# ‚Ñπ 4,274 more rows",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data extraction"
    ]
  },
  {
    "objectID": "r/hss_publish.html",
    "href": "r/hss_publish.html",
    "title": "Publishing",
    "section": "",
    "text": "You might have heard of R Markdown: a way to intertwine code and prose in a single scientific document. The company behind R Markdown has now developed its successor: Quarto.\n\nQuarto allows the creation of webpages, websites, presentations, books, pdf, etc. from code in R, Python, or Julia and markdown text.\nIf you are interested in an introduction to this tool, you can have a look at our workshop or our webinar on Quarto.\nBy the way, this entire website was created with Quarto üôÇ",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Publishing"
    ]
  },
  {
    "objectID": "r/hss_run.html",
    "href": "r/hss_run.html",
    "title": "Running R",
    "section": "",
    "text": "This section covers the various ways R can be run, then shows you how to access our temporary RStudio server for this course.",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Running R"
    ]
  },
  {
    "objectID": "r/hss_run.html#running-r",
    "href": "r/hss_run.html#running-r",
    "title": "Running R",
    "section": "Running R",
    "text": "Running R\nR being an interpreted language, it can be run non-interactively or interactively.\n\nRunning R non-interactively\nIf you write code in a text file (called a script), you can then execute it with:\nRscript my_script.R\n\nThe command to execute scripts is Rscript rather than R.\nBy convention, R scripts take the extension .R.\n\n\n\nRunning R interactively\nThere are several ways to run R interactively.\n\nDirectly in the console (the name for the R shell):\n\n\n\nIn Jupyter with the R kernel (IRkernel package).\nIn another IDE (e.g.¬†in Emacs with ESS).\nIn the RStudio IDE.\n\nThe RStudio IDE is popular and this is what we will use today. RStudio can can be run locally, but for this course, we will use an RStudio server.",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Running R"
    ]
  },
  {
    "objectID": "r/hss_run.html#accessing-our-rstudio-server",
    "href": "r/hss_run.html#accessing-our-rstudio-server",
    "title": "Running R",
    "section": "Accessing our RStudio server",
    "text": "Accessing our RStudio server\nYou do not need to install anything on your machine for this course as we will provide access to a temporary RStudio server.\n\nA username, a password, and the URL of the RStudio server will be given to you during the workshop.\n\nSign in using the username and password you will be given while ignoring the OTP entry. This will take you to the server options page of a JupyterHub.\n\nSelect the following server options:\n\nTime: 2 hours\nNumber of cores: 1\nMemory: 3700 MB\nUser interface: JupyterLab\n\n\nThen press Start to launch the JupyterHub. There, click on the RStudio button and the RStudio server will open in a new tab.\n\nNote that this temporary cluster will only be available for the duration of this course.",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Running R"
    ]
  },
  {
    "objectID": "r/hss_run.html#using-rstudio",
    "href": "r/hss_run.html#using-rstudio",
    "title": "Running R",
    "section": "Using RStudio",
    "text": "Using RStudio\nFor those unfamiliar with the RStudio IDE, you can download the following cheatsheet:\n\n\n\n\nfrom Posit Cheatsheets",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Running R"
    ]
  },
  {
    "objectID": "r/hss_vis.html",
    "href": "r/hss_vis.html",
    "title": "Data visualization",
    "section": "",
    "text": "To understand data, it is often extremely useful to visualize them. In this section, we will plot the US infectious disease data.",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data visualization"
    ]
  },
  {
    "objectID": "r/hss_vis.html#load-packages",
    "href": "r/hss_vis.html#load-packages",
    "title": "Data visualization",
    "section": "Load packages",
    "text": "Load packages\nThe most popular R package for data visualization is the tidyverse package ggplot2. Let‚Äôs load it in addition to our previous packages:\n\nlibrary(dslabs)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\nLet‚Äôs start by plotting the total number of cases for all states and all diseases per year. We already saw in the previous section how to group and summarise the data. Let‚Äôs create a new data frame with our prepared data:\n\nus_year_totals &lt;- us_contagious_diseases |&gt;\n  group_by(year) |&gt;\n  summarise(total = sum(count))\n\nThis is what our data frame looks like:\n\nhead(us_year_totals)\n\n# A tibble: 6 √ó 2\n   year  total\n  &lt;dbl&gt;  &lt;dbl&gt;\n1  1928 524563\n2  1929 380196\n3  1930 439289\n4  1931 482886\n5  1932 404683\n6  1933 391485\n\n\nNow we can use it to make a first plot.",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data visualization"
    ]
  },
  {
    "objectID": "r/hss_vis.html#the-canvas",
    "href": "r/hss_vis.html#the-canvas",
    "title": "Data visualization",
    "section": "The Canvas",
    "text": "The Canvas\nThe first component of a plot is the data:\n\nggplot(us_year_totals)\n\n\n\n\n\n\n\n\nThe second component sets the way variables are mapped on the axes. This is done with the aes() (aesthetics) function:\n\nggplot(us_year_totals, aes(year, total))",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data visualization"
    ]
  },
  {
    "objectID": "r/hss_vis.html#geometric-representations-of-the-data",
    "href": "r/hss_vis.html#geometric-representations-of-the-data",
    "title": "Data visualization",
    "section": "Geometric representations of the data",
    "text": "Geometric representations of the data\nOnto this canvas, we can add ‚Äúgeoms‚Äù (geometrical objects) representing the data. The type of ‚Äúgeom‚Äù defines the type of representation (e.g.¬†boxplot, histogram, bar chart).\nTo represent the data as a scatterplot, we use the geom_point() function:\n\nggplot(us_year_totals, aes(year, total)) +\n  geom_point()\n\n\n\n\n\n\n\n\nThis immediately shows that the number of contagious infections in the US has declined sharply since the early 60s.\nMultiple ‚Äúgeoms‚Äù can be added on top of each other. For instance, we can add a smoothed conditional means function with geom_smooth(). That will help us see patterns in the data:\n\nggplot(us_year_totals, aes(year, total)) +\n  geom_point() +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThere is a bump of cases in the early 40s. Due to WWII maybe?\nThe default smoothing function uses the LOESS (locally estimated scatterplot smoothing) method, which is a nonlinear regression. We can change the method to a linear model:\n\nggplot(us_year_totals, aes(year, total)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nLine width, color, and whether or not the standard error (se) is shown can be customized:\n\nggplot(us_year_totals, aes(year, total)) +\n  geom_point() +\n  geom_smooth(\n    method = lm,\n    se = FALSE,\n    color = \"#999999\",\n    linewidth = 0.5\n  )\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data visualization"
    ]
  },
  {
    "objectID": "r/hss_vis.html#colour-representations",
    "href": "r/hss_vis.html#colour-representations",
    "title": "Data visualization",
    "section": "Colour representations",
    "text": "Colour representations\nSo far, we have pooled the data for all diseases together, but maybe different diseases show different trends.\nLet‚Äôs create a new data frame with the totals per year and per disease so that we can create plots with more information:\n\nus_year_disease_totals &lt;- us_contagious_diseases |&gt;\n  group_by(year, disease) |&gt;\n  summarise(total = sum(count), .groups = 'drop')\n\nhead(us_year_disease_totals)\n\n# A tibble: 6 √ó 3\n   year disease   total\n  &lt;dbl&gt; &lt;fct&gt;     &lt;dbl&gt;\n1  1928 Measles  483337\n2  1928 Polio      4756\n3  1928 Smallpox  36470\n4  1929 Measles  339061\n5  1929 Polio      2746\n6  1929 Smallpox  38389\n\n\nNow we can use a different colour for each disease:\n\nggplot(us_year_disease_totals, aes(year, total)) +\n  geom_point(aes(color = disease))\n\n\n\n\n\n\n\n\nThis shows how prevalent measles was until the 70s.\nWhen plotting quickly to understand the data, aesthetics don‚Äôt matter. If you want to produce plots for publications or presentations, of course you should then spend some time tweaking their style and readability.",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data visualization"
    ]
  },
  {
    "objectID": "r/hss_vis.html#colour-scales",
    "href": "r/hss_vis.html#colour-scales",
    "title": "Data visualization",
    "section": "Colour scales",
    "text": "Colour scales\nMany colour scales exist. scale_color_brewer(), based on color brewer 2.0, is one of many methods to change the color scale. Here is the list of available scales for this particular method:\n\n\n\n\n\nWhen choosing a colour scale, it is very important to remember that various forms of colour blindness are common. Try to choose distinctive colours. Some palettes are specifically designed to work well for everyone.\nHere, let‚Äôs try the Dark2 palette:\n\nggplot(us_year_disease_totals, aes(year, total)) +\n  geom_point(aes(color = disease)) +\n  scale_color_brewer(palette = \"Dark2\")",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data visualization"
    ]
  },
  {
    "objectID": "r/hss_vis.html#labels",
    "href": "r/hss_vis.html#labels",
    "title": "Data visualization",
    "section": "Labels",
    "text": "Labels\nLet‚Äôs improve our axes labels and legend and add a title to the plot:\n\nggplot(us_year_disease_totals, aes(year, total)) +\n  geom_point(aes(color = disease)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(\n    title = \"Infectious diseases in the US\",\n    x = \"Year\",\n    y = \"Number of cases\",\n    color = \"Diseases\"\n  )",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data visualization"
    ]
  },
  {
    "objectID": "r/hss_vis.html#themes",
    "href": "r/hss_vis.html#themes",
    "title": "Data visualization",
    "section": "Themes",
    "text": "Themes\nggplot2 comes with a number of preset themes.\nEdward Tufte developed, amongst others, the principle of data-ink ratio which emphasizes that ink should be used primarily where it communicates meaningful messages. It is indeed common to see charts where more ink is used in labels or background than in the actual representation of the data.\nThe default ggplot2 theme could be criticized as not following this principle. Let‚Äôs change it:\n\nggplot(us_year_disease_totals, aes(year, total)) +\n  geom_point(aes(color = disease)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(\n    title = \"Infectious diseases in the US\",\n    x = \"Year\",\n    y = \"Number of cases\",\n    color = \"Diseases\"\n  ) +\n  theme_classic()\n\n\n\n\n\n\n\n\nThe theme() function allows to tweak the theme in any number of ways. For instance, what if we don‚Äôt like the default position of the title and we would rather have it centered?\n\nggplot(us_year_disease_totals, aes(year, total)) +\n  geom_point(aes(color = disease)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(\n    title = \"Infectious diseases in the US\",\n    x = \"Year\",\n    y = \"Number of cases\",\n    color = \"Diseases\"\n  ) +\n  theme_classic() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\nWe can also move the legend to give more space to the actual graph:\n\nggplot(us_year_disease_totals, aes(year, total)) +\n  geom_point(aes(color = disease)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(\n    title = \"Infectious diseases in the US\",\n    x = \"Year\",\n    y = \"Number of cases\",\n    color = \"Diseases\"\n  ) +\n  theme_classic() +\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"bottom\")",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data visualization"
    ]
  },
  {
    "objectID": "r/hss_vis.html#facets",
    "href": "r/hss_vis.html#facets",
    "title": "Data visualization",
    "section": "Facets",
    "text": "Facets\nInstead of plotting the data for all diseases on a single graph, we can create facets:\n\nggplot(us_year_disease_totals, aes(year, total)) +\n  geom_point(aes(color = disease), show.legend = FALSE) +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(\n    title = \"Infectious diseases in the US\",\n    x = \"Year\",\n    y = \"Number of cases\"\n  ) +\n  facet_wrap(~ disease) +\n  theme(plot.title = element_text(hjust = 0.5))",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data visualization"
    ]
  },
  {
    "objectID": "r/hss_vis.html#saving-plots",
    "href": "r/hss_vis.html#saving-plots",
    "title": "Data visualization",
    "section": "Saving plots",
    "text": "Saving plots\nPlots can be saved to file thanks to the ggsave() function from ggplot2.\nLet‚Äôs save our last plot:\nggsave(\"us_infectious_diseases.png\")\n\nBy default, ggsave() saves the last plot and guesses the file type from the file name extension. Arguments exist to select another plot to save to file, set the height and width, the resolution, add a background, etc. See ?ggsave for a list of options.",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data visualization"
    ]
  },
  {
    "objectID": "r/hss_vis.html#ggplot2-extensions",
    "href": "r/hss_vis.html#ggplot2-extensions",
    "title": "Data visualization",
    "section": "ggplot2 extensions",
    "text": "ggplot2 extensions\nThanks to its popularity, ggplot2 has seen a proliferation of packages extending its capabilities. A full list can be found here.",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>",
      "Data visualization"
    ]
  },
  {
    "objectID": "r/index.html",
    "href": "r/index.html",
    "title": "R",
    "section": "",
    "text": "Getting started with ¬†\nAn intro course on R\n\n\n\n\n ¬†for the humanities\nR course for HSS\n\n\n\n\n\n\nHigh-performance ¬†\nA course on HPC in R\n\n\n\n\nWorkshops\nVarious R topics\n\n\n\n\n\n\n60 min webinars\nVarious R topics",
    "crumbs": [
      "R",
      "<br>&nbsp;<img src=\"img/logo_r.png\" class=\"img-fluid\" style=\"width:1.5em\" alt=\"noshadow\"><br><br>"
    ]
  },
  {
    "objectID": "r/intro_basics.html",
    "href": "r/intro_basics.html",
    "title": "First steps in R",
    "section": "",
    "text": "In this section, we take our first few steps in R: we will access the R documentation, see how to set R options, and talk about a few concepts.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "First steps in R"
    ]
  },
  {
    "objectID": "r/intro_basics.html#help-and-documentation",
    "href": "r/intro_basics.html#help-and-documentation",
    "title": "First steps in R",
    "section": "Help and documentation",
    "text": "Help and documentation\nFor some general documentation on R, you can run:\nhelp.start()\nTo get help on a function (e.g.¬†sum), you can run:\nhelp(sum)\nDepending on your settings, this will open a documentation for sum in a pager or in your browser.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "First steps in R"
    ]
  },
  {
    "objectID": "r/intro_basics.html#r-settings",
    "href": "r/intro_basics.html#r-settings",
    "title": "First steps in R",
    "section": "R settings",
    "text": "R settings\nSettings are saved in a .Rprofile file. You can edit the file directly in any text editor or from within R.\nList all options:\noptions()\nReturn the value of a particular option:\n\ngetOption(\"help_type\")\n\n[1] \"text\"\n\n\nSet an option:\noptions(help_type = \"html\")",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "First steps in R"
    ]
  },
  {
    "objectID": "r/intro_basics.html#assignment",
    "href": "r/intro_basics.html#assignment",
    "title": "First steps in R",
    "section": "Assignment",
    "text": "Assignment\nR can accept the equal sign (=) for assignments, but it is more idiomatic to use the assignment sign (&lt;-) whenever you bind a name to a value and to use the equal sign everywhere else.\n\na &lt;- 3\n\nOnce you have bound a name to a value, you can recall the value with that name:\n\na  # Note that you do not need to use a print() function in R\n\n[1] 3\n\n\nYou can remove an object from the environment by deleting its name:\n\nrm(a)\n\nLet‚Äôs confirm that a doesn‚Äôt exist anymore in the environment:\n\na\n\nError in eval(expr, envir, enclos): object 'a' not found\n\n\nThe garbage collector will take care of deleting the object itself from memory.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "First steps in R"
    ]
  },
  {
    "objectID": "r/intro_basics.html#comments",
    "href": "r/intro_basics.html#comments",
    "title": "First steps in R",
    "section": "Comments",
    "text": "Comments\nAnything to the left of # is a comment and is ignored by R:\n\n# This is an inline comment\n\na &lt;- 3  # This is also a comment",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "First steps in R"
    ]
  },
  {
    "objectID": "r/intro_data_structure.html",
    "href": "r/intro_data_structure.html",
    "title": "Data types and structures",
    "section": "",
    "text": "This section covers the various data types and structures available in R.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data types and structures"
    ]
  },
  {
    "objectID": "r/intro_data_structure.html#summary-of-structures",
    "href": "r/intro_data_structure.html#summary-of-structures",
    "title": "Data types and structures",
    "section": "Summary of structures",
    "text": "Summary of structures\n\n\n\nDimension\nHomogeneous\nHeterogeneous\n\n\n\n\n1 d\nAtomic vector\nList\n\n\n2 d\nMatrix\nData frame\n\n\n3 d\nArray",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data types and structures"
    ]
  },
  {
    "objectID": "r/intro_data_structure.html#atomic-vectors",
    "href": "r/intro_data_structure.html#atomic-vectors",
    "title": "Data types and structures",
    "section": "Atomic vectors",
    "text": "Atomic vectors\n\nWith a single element\n\na &lt;- 2\na\n\n[1] 2\n\ntypeof(a)\n\n[1] \"double\"\n\nstr(a)\n\n num 2\n\nlength(a)\n\n[1] 1\n\ndim(a)\n\nNULL\n\n\nThe dim attribute of a vector doesn‚Äôt exist (hence the NULL). This makes vectors different from one-dimensional arrays which have a dim of 1.\nYou might have noticed that 2 is a double (double precision floating point number, equivalent of ‚Äúfloat‚Äù in other languages). In R, this is the default, even if you don‚Äôt type 2.0. This prevents the kind of weirdness you can find in, for instance, Python.\nIn Python:\n&gt;&gt;&gt; 2 == 2.0\nTrue\n&gt;&gt;&gt; type(2) == type(2.0)\nFalse\n&gt;&gt;&gt; type(2)\n&lt;class 'int'&gt;\n&gt;&gt;&gt; type(2.0)\n&lt;class 'float'&gt;\nIn R:\n&gt; 2 == 2.0\n[1] TRUE\n&gt; typeof(2) == typeof(2.0)\n[1] TRUE\n&gt; typeof(2)\n[1] \"double\"\n&gt; typeof(2.0)\n[1] \"double\"\nIf you want to define an integer variable, you use:\n\nb &lt;- 2L\nb\n\n[1] 2\n\ntypeof(b)\n\n[1] \"integer\"\n\nmode(b)\n\n[1] \"numeric\"\n\nstr(b)\n\n int 2\n\n\nThere are six vector types:\n\nlogical\ninteger\ndouble\ncharacter\ncomplex\nraw\n\n\n\nWith multiple elements\n\nc &lt;- c(2, 4, 1)\nc\n\n[1] 2 4 1\n\ntypeof(c)\n\n[1] \"double\"\n\nmode(c)\n\n[1] \"numeric\"\n\nstr(c)\n\n num [1:3] 2 4 1\n\n\n\nd &lt;- c(TRUE, TRUE, NA, FALSE)\nd\n\n[1]  TRUE  TRUE    NA FALSE\n\ntypeof(d)\n\n[1] \"logical\"\n\nstr(d)\n\n logi [1:4] TRUE TRUE NA FALSE\n\n\n\nNA (‚ÄúNot Available‚Äù) is a logical constant of length one. It is an indicator for a missing value.\n\nVectors are homogeneous, so all elements need to be of the same type.\nIf you use elements of different types, R will convert some of them to ensure that they become of the same type:\n\ne &lt;- c(\"This is a string\", 3, \"test\")\ne\n\n[1] \"This is a string\" \"3\"                \"test\"            \n\ntypeof(e)\n\n[1] \"character\"\n\nstr(e)\n\n chr [1:3] \"This is a string\" \"3\" \"test\"\n\n\n\nf &lt;- c(TRUE, 3, FALSE)\nf\n\n[1] 1 3 0\n\ntypeof(f)\n\n[1] \"double\"\n\nstr(f)\n\n num [1:3] 1 3 0\n\n\n\ng &lt;- c(2L, 3, 4L)\ng\n\n[1] 2 3 4\n\ntypeof(g)\n\n[1] \"double\"\n\nstr(g)\n\n num [1:3] 2 3 4\n\n\n\nh &lt;- c(\"string\", TRUE, 2L, 3.1)\nh\n\n[1] \"string\" \"TRUE\"   \"2\"      \"3.1\"   \n\ntypeof(h)\n\n[1] \"character\"\n\nstr(h)\n\n chr [1:4] \"string\" \"TRUE\" \"2\" \"3.1\"\n\n\nThe binary operator : is equivalent to the seq() function and generates a regular sequence of integers:\n\ni &lt;- 1:5\ni\n\n[1] 1 2 3 4 5\n\ntypeof(i)\n\n[1] \"integer\"\n\nstr(i)\n\n int [1:5] 1 2 3 4 5\n\nidentical(2:8, seq(2, 8))\n\n[1] TRUE",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data types and structures"
    ]
  },
  {
    "objectID": "r/intro_data_structure.html#matrices",
    "href": "r/intro_data_structure.html#matrices",
    "title": "Data types and structures",
    "section": "Matrices",
    "text": "Matrices\n\nj &lt;- matrix(1:12, nrow = 3, ncol = 4)\nj\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12\n\ntypeof(j)\n\n[1] \"integer\"\n\nstr(j)\n\n int [1:3, 1:4] 1 2 3 4 5 6 7 8 9 10 ...\n\nlength(j)\n\n[1] 12\n\ndim(j)\n\n[1] 3 4\n\n\nThe default is byrow = FALSE. If you want the matrix to be filled in by row, you need to set this argument to TRUE:\n\nk &lt;- matrix(1:12, nrow = 3, ncol = 4, byrow = TRUE)\nk\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    5    6    7    8\n[3,]    9   10   11   12",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data types and structures"
    ]
  },
  {
    "objectID": "r/intro_data_structure.html#arrays",
    "href": "r/intro_data_structure.html#arrays",
    "title": "Data types and structures",
    "section": "Arrays",
    "text": "Arrays\n\nl &lt;- array(as.double(1:24), c(3, 2, 4))\nl\n\n, , 1\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\n, , 2\n\n     [,1] [,2]\n[1,]    7   10\n[2,]    8   11\n[3,]    9   12\n\n, , 3\n\n     [,1] [,2]\n[1,]   13   16\n[2,]   14   17\n[3,]   15   18\n\n, , 4\n\n     [,1] [,2]\n[1,]   19   22\n[2,]   20   23\n[3,]   21   24\n\ntypeof(l)\n\n[1] \"double\"\n\nstr(l)\n\n num [1:3, 1:2, 1:4] 1 2 3 4 5 6 7 8 9 10 ...\n\nlength(l)\n\n[1] 24\n\ndim(l)\n\n[1] 3 2 4",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data types and structures"
    ]
  },
  {
    "objectID": "r/intro_data_structure.html#lists",
    "href": "r/intro_data_structure.html#lists",
    "title": "Data types and structures",
    "section": "Lists",
    "text": "Lists\n\nm &lt;- list(2, 3)\nm\n\n[[1]]\n[1] 2\n\n[[2]]\n[1] 3\n\ntypeof(m)\n\n[1] \"list\"\n\nstr(m)\n\nList of 2\n $ : num 2\n $ : num 3\n\nlength(m)\n\n[1] 2\n\ndim(m)\n\nNULL\n\n\nAs with atomic vectors, lists do not have a dim attribute. Lists are in fact a different type of vectors.\nLists can be heterogeneous:\n\nn &lt;- list(2L, 3, c(2, 1), FALSE, \"string\")\nn\n\n[[1]]\n[1] 2\n\n[[2]]\n[1] 3\n\n[[3]]\n[1] 2 1\n\n[[4]]\n[1] FALSE\n\n[[5]]\n[1] \"string\"\n\ntypeof(n)\n\n[1] \"list\"\n\nstr(n)\n\nList of 5\n $ : int 2\n $ : num 3\n $ : num [1:2] 2 1\n $ : logi FALSE\n $ : chr \"string\"\n\nlength(n)\n\n[1] 5",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data types and structures"
    ]
  },
  {
    "objectID": "r/intro_data_structure.html#data-frames",
    "href": "r/intro_data_structure.html#data-frames",
    "title": "Data types and structures",
    "section": "Data frames",
    "text": "Data frames\nData frames contain tabular data. Under the hood, a data frame is a list of vectors.\n\no &lt;- data.frame(\n  country = c(\"Canada\", \"USA\", \"Mexico\"),\n  var = c(2.9, 3.1, 4.5)\n)\no\n\n  country var\n1  Canada 2.9\n2     USA 3.1\n3  Mexico 4.5\n\ntypeof(o)\n\n[1] \"list\"\n\nstr(o)\n\n'data.frame':   3 obs. of  2 variables:\n $ country: chr  \"Canada\" \"USA\" \"Mexico\"\n $ var    : num  2.9 3.1 4.5\n\nlength(o)\n\n[1] 2\n\ndim(o)\n\n[1] 3 2",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Data types and structures"
    ]
  },
  {
    "objectID": "r/intro_functions.html",
    "href": "r/intro_functions.html",
    "title": "Function definition",
    "section": "",
    "text": "R comes with a number of built-in functions. Packages can provide additional ones. In many cases however, you will want to create your own functions to perform exactly the computations that you need.\nIn this section, we will see how to define new functions.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Function definition"
    ]
  },
  {
    "objectID": "r/intro_functions.html#syntax",
    "href": "r/intro_functions.html#syntax",
    "title": "Function definition",
    "section": "Syntax",
    "text": "Syntax\nHere is the syntax to define a new function:\nname &lt;- function(arguments) {\n  body\n}",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Function definition"
    ]
  },
  {
    "objectID": "r/intro_functions.html#example",
    "href": "r/intro_functions.html#example",
    "title": "Function definition",
    "section": "Example",
    "text": "Example\nLet‚Äôs define a function that we call compare which will compare the value between 2 numbers:\n\ncompare &lt;- function(x, y) {\n  x == y\n}\n\n\ncompare is the name of our function.\nx and y are the placeholders for the arguments that our function will accept (our function will need 2 arguments to run successfully).\nx == y is the body of the function, that is, the computation performed by our function.\n\nWe can now use our function:\n\ncompare(2, 3)\n\n[1] FALSE",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Function definition"
    ]
  },
  {
    "objectID": "r/intro_functions.html#what-is-returned-by-a-function",
    "href": "r/intro_functions.html#what-is-returned-by-a-function",
    "title": "Function definition",
    "section": "What is returned by a function?",
    "text": "What is returned by a function?\nIn R, the result of the last statement is printed automatically:\n\ntest &lt;- function(x, y) {\n  x\n  y\n}\ntest(2, 3)\n\n[1] 3\n\n\nIf you want to also print other results, you need to explicitly use the print() function:\n\ntest &lt;- function(x, y) {\n  print(x)\n  y\n}\ntest(2, 3)\n\n[1] 2\n\n\n[1] 3\n\n\nNote that, unlike print(), the function return() exits the function:\n\ntest &lt;- function(x, y) {\n  return(x)\n  y\n}\ntest(2, 3)\n\n[1] 2\n\n\n\ntest &lt;- function(x, y) {\n  return(x)\n  return(y)\n}\ntest(2, 3)\n\n[1] 2",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Function definition"
    ]
  },
  {
    "objectID": "r/intro_indexing.html",
    "href": "r/intro_indexing.html",
    "title": "Indexing",
    "section": "",
    "text": "This section covers indexing from the various data structures.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Indexing"
    ]
  },
  {
    "objectID": "r/intro_indexing.html#indexing-atomic-vectors",
    "href": "r/intro_indexing.html#indexing-atomic-vectors",
    "title": "Indexing",
    "section": "Indexing atomic vectors",
    "text": "Indexing atomic vectors\n\nHere is an example with an atomic vector of size one:\n\nIndexing in R starts at 1 and is done with square brackets next to the element to index:\n\nx &lt;- 2\nx\n\n[1] 2\n\nx[1]\n\n[1] 2\n\n\nWhat happens if we index out of range?\n\nx[2]\n\n[1] NA\n\n\n\nExample for an atomic vector with multiple elements:\n\n\nx &lt;- c(2, 4, 1)\nx\n\n[1] 2 4 1\n\nx[2]\n\n[1] 4\n\nx[2:4]\n\n[1]  4  1 NA\n\n\n\nModifying mutable objects\nIndexing also allows to modify some of the values of mutable objects:\n\nx\n\n[1] 2 4 1\n\nx[2] &lt;- 0\nx\n\n[1] 2 0 1\n\n\n\n\nCopy-on-modify\nNot all languages behave the same when you assign the same mutable object to several variables, then modify one of them.\n\nIn Python: no copy-on-modify\n\nDon‚Äôt try to run this code in R. This is for information only.\n\n\n\nPython\n\na = [1, 2, 3]\nb = a\nb\n\n[1, 2, 3]\n\n\nPython\n\na[0] = 4           # In Python, indexing starts at 0\na\n\n[4, 2, 3]\n\n\nPython\n\nb\n\n[4, 2, 3]\nModifying a also modifies b: this is because no copy is made when you modify a. If you want to keep b unchanged, you need to assign an explicit copy of a to it with b = copy.copy(a).\n\n\nIn R: copy-on-modify\n\na &lt;- c(1, 2, 3)\nb &lt;- a\nb\n\n[1] 1 2 3\n\na[1] &lt;- 4          # In R, indexing starts at 1\na\n\n[1] 4 2 3\n\nb\n\n[1] 1 2 3\n\n\nHere, the default is to create a new copy in memory when a is transformed so that b remains unchanged.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Indexing"
    ]
  },
  {
    "objectID": "r/intro_indexing.html#indexing-matrices-and-arrays",
    "href": "r/intro_indexing.html#indexing-matrices-and-arrays",
    "title": "Indexing",
    "section": "Indexing matrices and arrays",
    "text": "Indexing matrices and arrays\n\nx &lt;- matrix(1:12, nrow = 3, ncol = 4)\nx\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12\n\nx[2, 3]\n\n[1] 8\n\nx &lt;- array(as.double(1:24), c(3, 2, 4))\nx\n\n, , 1\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\n, , 2\n\n     [,1] [,2]\n[1,]    7   10\n[2,]    8   11\n[3,]    9   12\n\n, , 3\n\n     [,1] [,2]\n[1,]   13   16\n[2,]   14   17\n[3,]   15   18\n\n, , 4\n\n     [,1] [,2]\n[1,]   19   22\n[2,]   20   23\n[3,]   21   24\n\nx[2, 1, 3]\n\n[1] 14",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Indexing"
    ]
  },
  {
    "objectID": "r/intro_indexing.html#indexing-lists",
    "href": "r/intro_indexing.html#indexing-lists",
    "title": "Indexing",
    "section": "Indexing lists",
    "text": "Indexing lists\n\nx &lt;- list(2L, 3:8, c(2, 1), FALSE, \"string\")\nx\n\n[[1]]\n[1] 2\n\n[[2]]\n[1] 3 4 5 6 7 8\n\n[[3]]\n[1] 2 1\n\n[[4]]\n[1] FALSE\n\n[[5]]\n[1] \"string\"\n\n\nIndexing a list returns a list:\n\nx[3]\n\n[[1]]\n[1] 2 1\n\ntypeof(x[3])\n\n[1] \"list\"\n\n\nTo extract elements of a list, double square brackets are required:\n\nx[[3]]\n\n[1] 2 1\n\ntypeof(x[[3]])\n\n[1] \"double\"\n\n\n\n\nYour turn:\n\nTry to extract the number 7 from this list.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Indexing"
    ]
  },
  {
    "objectID": "r/intro_indexing.html#indexing-data-frames",
    "href": "r/intro_indexing.html#indexing-data-frames",
    "title": "Indexing",
    "section": "Indexing data frames",
    "text": "Indexing data frames\n\nx &lt;- data.frame(\n  country = c(\"Canada\", \"USA\", \"Mexico\"),\n  var = c(2.9, 3.1, 4.5)\n)\nx\n\n  country var\n1  Canada 2.9\n2     USA 3.1\n3  Mexico 4.5\n\n\nIndexing dataframes can be done by using indices, as we saw for matrices:\n\nx[2, 1]\n\n[1] \"USA\"\n\n\nIt can also be done using column names thanks to the $ symbol (a column is a vector, so indexing from a column is the same as indexing from a vector):\n\nx$country[2]\n\n[1] \"USA\"\n\n\nA data frame is actually a list of vectors representing the various columns:\n\ntypeof(x)\n\n[1] \"list\"\n\n\nIndexing a column can thus also be done by indexing the element of the list with double square brackets (although this is a slower method).\nWe get the same result with:\n\nx[[1]][2]\n\n[1] \"USA\"",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Indexing"
    ]
  },
  {
    "objectID": "r/intro_packages.html",
    "href": "r/intro_packages.html",
    "title": "Packages",
    "section": "",
    "text": "Packages are a set of functions, constants, and/or data developed by the community that add functionality to R.\nIn this section, we look at where to find packages and how to install them.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Packages"
    ]
  },
  {
    "objectID": "r/intro_packages.html#looking-for-packages",
    "href": "r/intro_packages.html#looking-for-packages",
    "title": "Packages",
    "section": "Looking for packages",
    "text": "Looking for packages\n\nPackage finder.\nYour peers and the literature.\nList of CRAN packages.\nList of CRAN task views (list of packages with information for a large number of wide topics).",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Packages"
    ]
  },
  {
    "objectID": "r/intro_packages.html#managing-r-packages",
    "href": "r/intro_packages.html#managing-r-packages",
    "title": "Packages",
    "section": "Managing R packages",
    "text": "Managing R packages\n\nFor this course, you won‚Äôt have to install any package as they have already been installed in our RStudio server.\n\nR packages can be installed, updated, and removed from within R:\ninstall.packages(\"&lt;package_name&gt;\", repos=\"&lt;url-cran-mirror&gt;\")\nremove.packages(\"&lt;package-name&gt;\")\nupdate_packages()\n\nExample:\n\ninstall.packages(\"rvest\", repos=\"https://mirror.rcg.sfu.ca/mirror/CRAN/\")\n\nrepos argument: chose a CRAN mirror close to the location of your cluster or use https://cloud.r-project.org/.\n\n\nThe first time you install a package, R will ask you whether you want to create a personal library in your home directory. Answer yes to both questions. Your packages will now install under ~/.\n\n\nSome packages require additional modules to be loaded before they can be installed. Other packages need additional R packages as dependencies. In either case, you will get explicit error messages. Adding the argument dependencies = T helps in the second case, but you will still have to add packages manually from time to time.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Packages"
    ]
  },
  {
    "objectID": "r/intro_packages.html#loading-packages",
    "href": "r/intro_packages.html#loading-packages",
    "title": "Packages",
    "section": "Loading packages",
    "text": "Loading packages\nTo make a package available in an R session, you load it with the library() function.\n\nExample:\n\nlibrary(readxl)\nAlternatively, you can access a function from a package without loading it with the syntax: package::function().\n\nExample:\n\nreadxl::read_excel(\"file.xlsx\")",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Packages"
    ]
  },
  {
    "objectID": "r/intro_packages.html#package-documentation",
    "href": "r/intro_packages.html#package-documentation",
    "title": "Packages",
    "section": "Package documentation",
    "text": "Package documentation\n\nSelect a package from the list of CRAN packages.\nGoogle ‚Äúcran‚Äù and the name of your package (e.g.¬†‚Äúcran dplyr‚Äù).\nLook up a package in the package documentation.\nGet a list of functions within a package with the help() function (installed, but not loaded in session):\n\n\nExample to get a list of functions in the dplyr package:\n\nhelp(package = \"dplyr\")\n\nGet help on a function within a package:\n\nIf you are using RStudio or the HTML format for your R help and you already ran the command to get the list of functions within a package (e.g.¬†help(package = \"dplyr\")), you can get help on any function by clicking on its name.\nIf you are using the text format for help (for instance, if you are running R remotely on the command line), you can get help for any function by adding its name at as the first argument of the previous command.\n\nExample to get help on the function bind() of the package dplyr:\n\nhelp(bind, package = \"dplyr\")\nOf course, if the dplyr package is already loaded in your session, you can simply run help(bind).\n\nGet a list of all help files with alias or concept or title matching a regular expression in all installed packages:\n\n\nExample to get a list of all help files with alias or concept or title matching bind:\n\n??bind\nYou can then open those help files as seen previously.\n\nGet a list of all vignettes for all installed packages:\n\nIf you are using RStudio or the HTML help format:\nbrowseVignettes()\nIf you are using the text help format:\nvignette()\n\nGet a list of vignettes available for a package (not all packages have vignettes):\n\n\nExample to get a list of vignettes for the package dplyr:\n\nIf you are using RStudio or the HTML help format:\nvignette(package = \"dplyr\")\nIf you are using the text help format:\nbrowseVignettes(package = \"dplyr\")\nYou can then open those help vignettes as seen previously.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Packages"
    ]
  },
  {
    "objectID": "r/intro_publishing.html",
    "href": "r/intro_publishing.html",
    "title": "Publishing",
    "section": "",
    "text": "You might have heard of R Markdown: a way to intertwine code and prose in a single scientific document. The company behind R Markdown has now developed its successor: Quarto.\n\nQuarto allows the creation of webpages, websites, presentations, books, pdf, etc. from code in R, Python, or Julia and markdown text.\nIf you are interested in an introduction to this tool, you can have a look at our workshop or our webinar on Quarto.\nBy the way, this entire website was created with Quarto üôÇ",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Publishing"
    ]
  },
  {
    "objectID": "r/intro_run.html",
    "href": "r/intro_run.html",
    "title": "Running R",
    "section": "",
    "text": "This section covers the various ways R can be run, then shows you how to access our temporary RStudio server for this course.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Running R"
    ]
  },
  {
    "objectID": "r/intro_run.html#running-r",
    "href": "r/intro_run.html#running-r",
    "title": "Running R",
    "section": "Running R",
    "text": "Running R\nR being an interpreted language, it can be run non-interactively or interactively.\n\nRunning R non-interactively\nIf you write code in a text file (called a script), you can then execute it with:\nRscript my_script.R\n\nThe command to execute scripts is Rscript rather than R.\nBy convention, R scripts take the extension .R.\n\n\n\nRunning R interactively\nThere are several ways to run R interactively.\n\nDirectly in the console (the name for the R shell):\n\n\n\nIn Jupyter with the R kernel (IRkernel package).\nIn another IDE (e.g.¬†in Emacs with ESS).\nIn the RStudio IDE.\n\nThe RStudio IDE is popular and this is what we will use today. RStudio can can be run locally, but for this course, we will use an RStudio server.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Running R"
    ]
  },
  {
    "objectID": "r/intro_run.html#accessing-our-rstudio-server",
    "href": "r/intro_run.html#accessing-our-rstudio-server",
    "title": "Running R",
    "section": "Accessing our RStudio server",
    "text": "Accessing our RStudio server\nYou do not need to install anything on your machine for this course as we will provide access to a temporary RStudio server.\n\nA username, a password, and the URL of the RStudio server will be given to you during the workshop.\n\nSign in using the username and password you will be given while ignoring the OTP entry. This will take you to the server options page of a JupyterHub.\n\nSelect the following server options:\n\nTime: 2 hours\nNumber of cores: 1\nMemory: 3700 MB\nUser interface: JupyterLab\n\n\nThen press Start to launch the JupyterHub. There, click on the RStudio button and the RStudio server will open in a new tab.\n\nNote that this temporary cluster will only be available for the duration of this course.",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Running R"
    ]
  },
  {
    "objectID": "r/intro_run.html#using-rstudio",
    "href": "r/intro_run.html#using-rstudio",
    "title": "Running R",
    "section": "Using RStudio",
    "text": "Using RStudio\nFor those unfamiliar with the RStudio IDE, you can download the following cheatsheet:\n\n\n\n\nfrom Posit Cheatsheets",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "Running R"
    ]
  },
  {
    "objectID": "r/intro_why.html",
    "href": "r/intro_why.html",
    "title": "R: why and for whom?",
    "section": "",
    "text": "There are other high level programming languages such as Python or Julia, so when might it make sense for you to turn to R?",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "R: why and for whom?"
    ]
  },
  {
    "objectID": "r/intro_why.html#why-r",
    "href": "r/intro_why.html#why-r",
    "title": "R: why and for whom?",
    "section": "Why R?",
    "text": "Why R?\nHere are a number of reasons why you might want to consider using R:\n\nFree and open source\nHigh-level and easy to learn\nLarge community\nVery well documented\nUnequalled number of statistics and modelling packages\nIntegrated package manager\nEasy connection with fast compiled languages such as C and C++\nPowerful IDEs (e.g.¬†RStudio, ESS, Jupyter)",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "R: why and for whom?"
    ]
  },
  {
    "objectID": "r/intro_why.html#for-whom",
    "href": "r/intro_why.html#for-whom",
    "title": "R: why and for whom?",
    "section": "For whom?",
    "text": "For whom?\nFor whom is R particularly well suited?\n\nFields with heavy statistics, modelling, or Bayesian analysis such as biology, linguistics, economics, or statistics\nData science using a lot of tabular data",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "R: why and for whom?"
    ]
  },
  {
    "objectID": "r/intro_why.html#downsides-of-r",
    "href": "r/intro_why.html#downsides-of-r",
    "title": "R: why and for whom?",
    "section": "Downsides of R",
    "text": "Downsides of R\nOf course, R also has its downsides:\n\nInconsistent syntax full of quirks\nSlow\nLarge memory usage",
    "crumbs": [
      "R",
      "<em><b>Getting started</b></em>",
      "R: why and for whom?"
    ]
  },
  {
    "objectID": "r/top_hss.html",
    "href": "r/top_hss.html",
    "title": "R for the humanities",
    "section": "",
    "text": "R is a free and open-source programming language for statistical computing, modelling, and graphics, with an unbeatable collection of statistical packages. It is extremely popular in the humanities and social sciences.\nThis course does not assume any programming knowledge.\n\n Start course ‚û§",
    "crumbs": [
      "R",
      "<em><b>R for the humanities</b></em>"
    ]
  },
  {
    "objectID": "r/top_wb.html",
    "href": "r/top_wb.html",
    "title": "R webinars",
    "section": "",
    "text": "GIS mappingwith R\n\n\n\n\nHigh-performance computing in R",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>"
    ]
  },
  {
    "objectID": "r/wb_gis_mapping.html",
    "href": "r/wb_gis_mapping.html",
    "title": "GIS mapping with R",
    "section": "",
    "text": "In this webinar, we will see how to create all sorts of GIS maps with the packages sf, tmap, raster, leaflet, ggplot2, grid (part of Base R), and mapview:\n\nsimple maps\ninset maps\nfaceted maps\nanimated maps\ninteractive maps\nraster maps\n\nFinally, we will learn how to add basemaps from OpenStreetMap and Google Maps.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "GIS mapping with R"
    ]
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#types-of-spatial-data",
    "href": "r/wb_gis_mapping_slides.html#types-of-spatial-data",
    "title": "GIS mapping with R",
    "section": "Types of spatial data",
    "text": "Types of spatial data\nVector data\nDiscrete objects\nContain: ‚ÄÇ- geometry:‚ÄÇ shape & location of the objects\n‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ- attributes:‚ÄÇ additional variables (e.g.¬†name, year, type)\nCommon file format:‚ÄÇ GeoJSON, shapefile\n\nExamples: countries, roads, rivers, towns"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#types-of-spatial-data-1",
    "href": "r/wb_gis_mapping_slides.html#types-of-spatial-data-1",
    "title": "GIS mapping with R",
    "section": "Types of spatial data",
    "text": "Types of spatial data\nRaster data\nContinuous phenomena or spatial fields\nCommon file formats:‚ÄÇ TIFF, GeoTIFF, NetCDF, Esri grid\n\nExamples: temperature, air quality, elevation, water depth"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#vector-data-1",
    "href": "r/wb_gis_mapping_slides.html#vector-data-1",
    "title": "GIS mapping with R",
    "section": "Vector data",
    "text": "Vector data\nTypes\n\npoint:‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇ¬† single set of coordinates\nmulti-point:‚ÄÉ‚ÄÉ multiple sets of coordinates\npolyline:‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇ¬† multiple sets for which the order matters\nmulti-polyline:‚ÄÉ multiple of the above\npolygon:‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇ¬† same as polyline but first & last sets are the same\nmulti-polygon:‚ÄÉ multiple of the above"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#raster-data-1",
    "href": "r/wb_gis_mapping_slides.html#raster-data-1",
    "title": "GIS mapping with R",
    "section": "Raster data",
    "text": "Raster data\nGrid of equally sized rectangular cells containing values for some variables\nSize of cells = resolution\nFor computing efficiency, rasters do not have coordinates of each cell, but the bounding box & the number of rows & columns"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#coordinate-reference-systems-crs",
    "href": "r/wb_gis_mapping_slides.html#coordinate-reference-systems-crs",
    "title": "GIS mapping with R",
    "section": "Coordinate Reference Systems (CRS)",
    "text": "Coordinate Reference Systems (CRS)\nA location on Earth‚Äôs surface can be identified by its coordinates & some reference system called CRS\nThe coordinates (x, y) are called longitude & latitude\nThere can be a 3rd coordinate (z) for elevation or other measurement‚Äîusually a vertical one\nAnd a 4th (m) for some other data attribute‚Äîusually a horizontal measurement\nIn 3D, longitude & latitude are expressed in angular units (e.g.¬†degrees) & the reference system needed is an angular CRS or geographic coordinate system (GCS)\nIn 2D, they are expressed in linear units (e.g.¬†meters) & the reference system needed is a planar CRS or projected coordinate system (PCS)"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#datums",
    "href": "r/wb_gis_mapping_slides.html#datums",
    "title": "GIS mapping with R",
    "section": "Datums",
    "text": "Datums\nSince the Earth is not a perfect sphere, we use spheroidal models to represent its surface. Those are called geodetic datums\nSome datums are global, others local (more accurate in a particular area of the globe, but only useful there)\n\nExamples of commonly used global datums:\n\nWGS84 (World Geodesic System 1984)\nNAD83 (North American Datum of 1983)"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#angular-crs",
    "href": "r/wb_gis_mapping_slides.html#angular-crs",
    "title": "GIS mapping with R",
    "section": "Angular CRS",
    "text": "Angular CRS\nAn angular CRS contains a datum, an angular unit & references such as a prime meridian (e.g.¬†the Royal Observatory, Greenwich, England)\nIn an angular CRS or GCS:\n\nLongitude (\\(\\lambda\\)) represents the angle between the prime meridian & the meridian that passes through that location\nLatitude (\\(\\phi\\)) represents the angle between the line that passes through the center of the Earth & that location & its projection on the equatorial plane\n\nLongitude & latitude are thus angular coordinates"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#projections",
    "href": "r/wb_gis_mapping_slides.html#projections",
    "title": "GIS mapping with R",
    "section": "Projections",
    "text": "Projections\nTo create a two-dimensional map, you need to project this 3D angular CRS into a 2D one\nVarious projections offer different characteristics. For instance:\n\nsome respect areas (equal-area)\nsome respect the shape of geographic features (conformal)\nsome almost respect both for small areas\n\nIt is important to choose one with sensible properties for your goals\n\nExamples of projections:\n\nMercator\nUTM\nRobinson"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#planar-crs",
    "href": "r/wb_gis_mapping_slides.html#planar-crs",
    "title": "GIS mapping with R",
    "section": "Planar CRS",
    "text": "Planar CRS\nA planar CRS is defined by a datum, a projection & a set of parameters such as a linear unit & the origins\nCommon planar CRS have been assigned a unique ID called EPSG code which is much more convenient to use\nIn a planar CRS, coordinates will not be in degrees anymore but in meters (or other length unit)"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#projecting-into-a-new-crs",
    "href": "r/wb_gis_mapping_slides.html#projecting-into-a-new-crs",
    "title": "GIS mapping with R",
    "section": "Projecting into a new CRS",
    "text": "Projecting into a new CRS\nYou can change the projection of your data\nVector data won‚Äôt suffer any loss of precision, but raster data will\n‚Üí¬† best to try to avoid reprojecting rasters: if you want to combine various datasets which have different projections, reproject vector data instead"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#resources",
    "href": "r/wb_gis_mapping_slides.html#resources",
    "title": "GIS mapping with R",
    "section": "Resources",
    "text": "Resources\nOpen GIS data\nFree GIS Data: list of free GIS datasets\nBooks\nGeocomputation with R by Robin Lovelace, Jakub Nowosad & Jannes Muenchow\nSpatial Data Science by Edzer Pebesma & Roger Bivand\nSpatial Data Science with R by Robert J. Hijmans\nUsing Spatial Data with R by Claudia A. Engel\nTutorial\nAn Introduction to Spatial Data Analysis and Visualisation in R by the CDRC"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#resources-1",
    "href": "r/wb_gis_mapping_slides.html#resources-1",
    "title": "GIS mapping with R",
    "section": "Resources",
    "text": "Resources\nWebsite\nr-spatial by Edzer Pebesma, Marius Appel & Daniel N√ºst\nCRAN package list\nAnalysis of Spatial Data\nMailing list\nR Special Interest Group on using Geographical data and Mapping"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#data-manipulation",
    "href": "r/wb_gis_mapping_slides.html#data-manipulation",
    "title": "GIS mapping with R",
    "section": "Data manipulation",
    "text": "Data manipulation\nOlder packages\n\nsp\nraster\nrgdal\nrgeos\n\nNewer generation\n\nsf: vector data\nterra: raster data (also has vector data capabilities)"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#mapping",
    "href": "r/wb_gis_mapping_slides.html#mapping",
    "title": "GIS mapping with R",
    "section": "Mapping",
    "text": "Mapping\nStatic maps\n\nggplot2 + ggspatial\ntmap\n\nDynamic maps\n\nleaflet\nggplot2 + gganimate\nmapview\nggmap\ntmap"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#sf-simple-features-in-r",
    "href": "r/wb_gis_mapping_slides.html#sf-simple-features-in-r",
    "title": "GIS mapping with R",
    "section": "sf: Simple Features in R",
    "text": "sf: Simple Features in R\nGeospatial vectors: points, lines, polygons\nSimple Features‚Äîdefined by the Open Geospatial Consortium (OGC) & formalized by ISO‚Äîis a set of standards now used by most GIS libraries\nWell-known text (WKT) is a markup language for representing vector geometry objects according to those standards\nA compact computer version also exists‚Äîwell-known binary (WKB)‚Äîused by spatial databases\nThe package sp predates Simple Features\nsf‚Äîlaunched in 2016‚Äîimplements these standards in R in the form of sf objects: data.frames (or tibbles) containing the attributes, extended by sfc objects or simple feature geometries list-columns"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#sf",
    "href": "r/wb_gis_mapping_slides.html#sf",
    "title": "GIS mapping with R",
    "section": "sf",
    "text": "sf\nUseful links\n\nGitHub repo\nPaper\nResources\nCheatsheet\n6 vignettes: 1, 2, 3, 4, 5, 6"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#sf-objects",
    "href": "r/wb_gis_mapping_slides.html#sf-objects",
    "title": "GIS mapping with R",
    "section": "sf objects",
    "text": "sf objects"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#sf-objects-1",
    "href": "r/wb_gis_mapping_slides.html#sf-objects-1",
    "title": "GIS mapping with R",
    "section": "sf objects",
    "text": "sf objects"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#sf-objects-2",
    "href": "r/wb_gis_mapping_slides.html#sf-objects-2",
    "title": "GIS mapping with R",
    "section": "sf objects",
    "text": "sf objects"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#sf-objects-3",
    "href": "r/wb_gis_mapping_slides.html#sf-objects-3",
    "title": "GIS mapping with R",
    "section": "sf objects",
    "text": "sf objects"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#sf-objects-4",
    "href": "r/wb_gis_mapping_slides.html#sf-objects-4",
    "title": "GIS mapping with R",
    "section": "sf objects",
    "text": "sf objects"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#sf-functions",
    "href": "r/wb_gis_mapping_slides.html#sf-functions",
    "title": "GIS mapping with R",
    "section": "sf functions",
    "text": "sf functions\nMost functions start with st_ (which refers to ‚Äúspatial type‚Äù)"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#terra-geospatial-rasters",
    "href": "r/wb_gis_mapping_slides.html#terra-geospatial-rasters",
    "title": "GIS mapping with R",
    "section": "terra: Geospatial rasters",
    "text": "terra: Geospatial rasters\nFaster and simpler replacement for the raster package by the same team\nMostly implemented in C++\nCan work with datasets too large to be loaded into memory"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#terra",
    "href": "r/wb_gis_mapping_slides.html#terra",
    "title": "GIS mapping with R",
    "section": "terra",
    "text": "terra\nUseful links\n\nGitHub repo\nResources\nFull manual"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#tmap-layered-grammar-of-graphics-gis-maps",
    "href": "r/wb_gis_mapping_slides.html#tmap-layered-grammar-of-graphics-gis-maps",
    "title": "GIS mapping with R",
    "section": "tmap: Layered grammar of graphics GIS maps",
    "text": "tmap: Layered grammar of graphics GIS maps"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#tmap",
    "href": "r/wb_gis_mapping_slides.html#tmap",
    "title": "GIS mapping with R",
    "section": "tmap",
    "text": "tmap\nUseful links\n\nGitHub repo\nResources\n\nHelp pages and vignettes\n?tmap-element\nvignette(\"tmap-getstarted\")\n# All the usual help pages, e.g.:\n?tm_layout"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#tmap-functions",
    "href": "r/wb_gis_mapping_slides.html#tmap-functions",
    "title": "GIS mapping with R",
    "section": "tmap functions",
    "text": "tmap functions\nMain functions start with tmap_\nFunctions creating map elements start with tm_"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#tmap-functioning",
    "href": "r/wb_gis_mapping_slides.html#tmap-functioning",
    "title": "GIS mapping with R",
    "section": "tmap functioning",
    "text": "tmap functioning\nVery similar to ggplot2\nTypically, a map contains:\n\nOne or multiple layer(s) (the order matters as they stack on top of each other)\nSome layout (e.g.¬†customization of title, background, margins): tm_layout\nA compass: tm_compass\nA scale bar: tm_scale_bar\n\nEach layer contains:\n\nSome data: tm_shape\nHow that data will be represented: e.g.¬†tm_polygons, tm_lines, tm_raster"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#tmap-example",
    "href": "r/wb_gis_mapping_slides.html#tmap-example",
    "title": "GIS mapping with R",
    "section": "tmap example",
    "text": "tmap example"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#tmap-example-1",
    "href": "r/wb_gis_mapping_slides.html#tmap-example-1",
    "title": "GIS mapping with R",
    "section": "tmap example",
    "text": "tmap example"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#tmap-example-2",
    "href": "r/wb_gis_mapping_slides.html#tmap-example-2",
    "title": "GIS mapping with R",
    "section": "tmap example",
    "text": "tmap example"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#tmap-example-3",
    "href": "r/wb_gis_mapping_slides.html#tmap-example-3",
    "title": "GIS mapping with R",
    "section": "tmap example",
    "text": "tmap example"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#tmap-example-4",
    "href": "r/wb_gis_mapping_slides.html#tmap-example-4",
    "title": "GIS mapping with R",
    "section": "tmap example",
    "text": "tmap example"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#tmap-example-5",
    "href": "r/wb_gis_mapping_slides.html#tmap-example-5",
    "title": "GIS mapping with R",
    "section": "tmap example",
    "text": "tmap example"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#tmap-example-6",
    "href": "r/wb_gis_mapping_slides.html#tmap-example-6",
    "title": "GIS mapping with R",
    "section": "tmap example",
    "text": "tmap example"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#tmap-example-7",
    "href": "r/wb_gis_mapping_slides.html#tmap-example-7",
    "title": "GIS mapping with R",
    "section": "tmap example",
    "text": "tmap example"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#ggplot2-the-standard-in-r-plots",
    "href": "r/wb_gis_mapping_slides.html#ggplot2-the-standard-in-r-plots",
    "title": "GIS mapping with R",
    "section": "ggplot2 (the standard in R plots)",
    "text": "ggplot2 (the standard in R plots)\nUseful links\n\nGitHub repo\nResources\nCheatsheet"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#ggplot2",
    "href": "r/wb_gis_mapping_slides.html#ggplot2",
    "title": "GIS mapping with R",
    "section": "ggplot2",
    "text": "ggplot2\ngeom_sf allows to plot sf objects (i.e.¬†make maps)"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#data",
    "href": "r/wb_gis_mapping_slides.html#data",
    "title": "GIS mapping with R",
    "section": "Data",
    "text": "Data\nFor this webinar, we will use:\n\nthe Alaska as well as the Western Canada & USA subsets of the Randolph Glacier Inventory version 6.01\nthe USGS time series of the named glaciers of Glacier National Park2\nthe Alaska as well as the Western Canada & USA subsets of the consensus estimate for the ice thickness distribution of all glaciers on Earth dataset3\n\nThe datasets can be downloaded as zip files from these websites\nRGI Consortium (2017). Randolph Glacier Inventory ‚Äì A Dataset of Global Glacier Outlines: Version 6.0: Technical Report, Global Land Ice Measurements from Space, Colorado, USA. Digital Media. DOI: https://doi.org/10.7265/N5-RGI-60.Fagre, D.B., McKeon, L.A., Dick, K.A. & Fountain, A.G., 2017, Glacier margin time series (1966, 1998, 2005, 2015) of the named glaciers of Glacier National Park, MT, USA: U.S. Geological Survey data release. DOI: https://doi.org/10.5066/F7P26WB1.Farinotti, Daniel, 2019, A consensus estimate for the ice thickness distribution of all glaciers on Earth - dataset, Zurich. ETH Zurich. DOI: https://doi.org/10.3929/ethz-b-000315707."
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#packages-1",
    "href": "r/wb_gis_mapping_slides.html#packages-1",
    "title": "GIS mapping with R",
    "section": "Packages",
    "text": "Packages\nPackages need to be installed before they can be loaded in a session\nPackages on CRAN can be installed with:\ninstall.packages(\"&lt;package-name&gt;\")\n basemaps is not on CRAN & needs to be installed from GitHub thanks to devtools:\ninstall.packages(\"devtools\")\ndevtools::install_github(\"16EAGLE/basemaps\")"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#packages-2",
    "href": "r/wb_gis_mapping_slides.html#packages-2",
    "title": "GIS mapping with R",
    "section": "Packages",
    "text": "Packages\nWe load all the packages that we will need at the top of the script:\nlibrary(sf)                 # spatial vector data manipulation\nlibrary(tmap)               # map production & tiled web map\nlibrary(dplyr)              # non GIS specific (tabular data manipulation)\nlibrary(magrittr)           # non GIS specific (pipes)\nlibrary(purrr)              # non GIS specific (functional programming)\nlibrary(rnaturalearth)      # basemap data access functions\nlibrary(rnaturalearthdata)  # basemap data\nlibrary(mapview)            # tiled web map\nlibrary(grid)               # (part of base R) used to create inset map\nlibrary(ggplot2)            # alternative to tmap for map production\nlibrary(ggspatial)          # spatial framework for ggplot2\nlibrary(terra)              # gridded spatial data manipulation\nlibrary(ggmap)              # download basemap data\nlibrary(basemaps)           # download basemap data\nlibrary(magick)             # wrapper around ImageMagick STL\nlibrary(leaflet)            # integrate Leaflet JS in R"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#randolph-glacier-inventory",
    "href": "r/wb_gis_mapping_slides.html#randolph-glacier-inventory",
    "title": "GIS mapping with R",
    "section": "Randolph Glacier Inventory",
    "text": "Randolph Glacier Inventory\nThis dataset contains the contour of all glaciers on Earth\nWe will focus on glaciers in Western North America\nYou can download & unzip 02_rgi60_WesternCanadaUS & 01_rgi60_Alaska from the Randolph Glacier Inventory version 6.0"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#reading-in-data",
    "href": "r/wb_gis_mapping_slides.html#reading-in-data",
    "title": "GIS mapping with R",
    "section": "Reading in data",
    "text": "Reading in data\nData get imported & turned into sf objects with the function sf::st_read:\nak &lt;- st_read(\"data/01_rgi60_Alaska\")\n\nMake sure to use the absolute paths or the paths relative to your working directory (which can be obtained with getwd)"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#reading-in-data-1",
    "href": "r/wb_gis_mapping_slides.html#reading-in-data-1",
    "title": "GIS mapping with R",
    "section": "Reading in data",
    "text": "Reading in data\nak &lt;- st_read(\"data/01_rgi60_Alaska\")\nReading layer `01_rgi60_Alaska' from data source `./data/01_rgi60_Alaska'\n               using driver `ESRI Shapefile'\nSimple feature collection with 27108 features and 22 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -176.1425 ymin: 52.05727 xmax: -126.8545 ymax: 69.35167\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#reading-in-data-2",
    "href": "r/wb_gis_mapping_slides.html#reading-in-data-2",
    "title": "GIS mapping with R",
    "section": "Reading in data",
    "text": "Reading in data\n\n\nYour turn:\n\nRead in the data for the rest of north western America (from 02_rgi60_WesternCanadaUS) and create an sf object called wes"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#first-look-at-the-data",
    "href": "r/wb_gis_mapping_slides.html#first-look-at-the-data",
    "title": "GIS mapping with R",
    "section": "First look at the data",
    "text": "First look at the data\nak\nSimple feature collection with 27108 features and 22 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -176.1425 ymin: 52.05727 xmax: -126.8545 ymax: 69.35167\nGeodetic CRS:  WGS 84\nFirst 10 features:\n           RGIId        GLIMSId  BgnDate  EndDate    CenLon   CenLat O1Region\n1  RGI60-01.00001 G213177E63689N 20090703 -9999999 -146.8230 63.68900        1\n2  RGI60-01.00002 G213332E63404N 20090703 -9999999 -146.6680 63.40400        1\n3  RGI60-01.00003 G213920E63376N 20090703 -9999999 -146.0800 63.37600        1\n4  RGI60-01.00004 G213880E63381N 20090703 -9999999 -146.1200 63.38100        1\n5  RGI60-01.00005 G212943E63551N 20090703 -9999999 -147.0570 63.55100        1\n6  RGI60-01.00006 G213756E63571N 20090703 -9999999 -146.2440 63.57100        1\n7  RGI60-01.00007 G213771E63551N 20090703 -9999999 -146.2295 63.55085        1\n8  RGI60-01.00008 G213704E63543N 20090703 -9999999 -146.2960 63.54300        1\n9  RGI60-01.00009 G212400E63659N 20090703 -9999999 -147.6000 63.65900        1\n10 RGI60-01.00010 G212830E63513N 20090703 -9999999 -147.1700 63.51300        1\nO2Region   Area Zmin Zmax Zmed Slope Aspect  Lmax Status Connect Form\n1         2  0.360 1936 2725 2385    42    346   839      0       0    0\n2         2  0.558 1713 2144 2005    16    162  1197      0       0    0\n3         2  1.685 1609 2182 1868    18    175  2106      0       0    0\n4         2  3.681 1273 2317 1944    19    195  4175      0       0    0\n5         2  2.573 1494 2317 1914    16    181  2981      0       0    0\n6         2 10.470 1201 3547 1740    22     33 10518      0       0    0\n7         2  0.649 1918 2811 2194    23    151  1818      0       0    0\n8         2  0.200 2826 3555 3195    45     80   613      0       0    0\n9         2  1.517 1750 2514 1977    18    274  2255      0       0    0\n10        2  3.806 1280 1998 1666    17     35  3332      0       0    0\nTermType Surging Linkages Name                       geometry\n1         0       9        9 &lt;NA&gt; POLYGON ((-146.818 63.69081...\n2         0       9        9 &lt;NA&gt; POLYGON ((-146.6635 63.4076...\n3         0       9        9 &lt;NA&gt; POLYGON ((-146.0723 63.3834...\n4         0       9        9 &lt;NA&gt; POLYGON ((-146.149 63.37919...\n5         0       9        9 &lt;NA&gt; POLYGON ((-147.0431 63.5502...\n6         0       9        9 &lt;NA&gt; POLYGON ((-146.2436 63.5562...\n7         0       9        9 &lt;NA&gt; POLYGON ((-146.2495 63.5531...\n8         0       9        9 &lt;NA&gt; POLYGON ((-146.2992 63.5443...\n9         0       9        9 &lt;NA&gt; POLYGON ((-147.6147 63.6643...\n10        0       9        9 &lt;NA&gt; POLYGON ((-147.1494 63.5098..."
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#structure-of-the-data",
    "href": "r/wb_gis_mapping_slides.html#structure-of-the-data",
    "title": "GIS mapping with R",
    "section": "Structure of the data",
    "text": "Structure of the data\nstr(ak)\nClasses ‚Äòsf‚Äô and 'data.frame':  27108 obs. of  23 variables:\n$ RGIId   : chr  \"RGI60-01.00001\" \"RGI60-01.00002\" \"RGI60-01.00003\" ...\n$ GLIMSId : chr  \"G213177E63689N\" \"G213332E63404N\" \"G213920E63376N\" ...\n$ BgnDate : chr  \"20090703\" \"20090703\" \"20090703\" \"20090703\" ...\n$ EndDate : chr  \"-9999999\" \"-9999999\" \"-9999999\" \"-9999999\" ...\n$ CenLon  : num  -147 -147 -146 -146 -147 ...\n$ CenLat  : num  63.7 63.4 63.4 63.4 63.6 ...\n$ O1Region: chr  \"1\" \"1\" \"1\" \"1\" ...\n$ O2Region: chr  \"2\" \"2\" \"2\" \"2\" ...\n$ Area    : num  0.36 0.558 1.685 3.681 2.573 ...\n$ Zmin    : int  1936 1713 1609 1273 1494 1201 1918 2826 1750 1280 ...\n$ Zmax    : int  2725 2144 2182 2317 2317 3547 2811 3555 2514 1998 ...\n$ Zmed    : int  2385 2005 1868 1944 1914 1740 2194 3195 1977 1666 ...\n$ Slope   : num  42 16 18 19 16 22 23 45 18 17 ...\n$ Aspect  : int  346 162 175 195 181 33 151 80 274 35 ...\n$ Lmax    : int  839 1197 2106 4175 2981 10518 1818 613 2255 3332 ...\n$ Status  : int  0 0 0 0 0 0 0 0 0 0 ...\n$ Connect : int  0 0 0 0 0 0 0 0 0 0 ...\n$ Form    : int  0 0 0 0 0 0 0 0 0 0 ...\n$ TermType: int  0 0 0 0 0 0 0 0 0 0 ...\n$ Surging : int  9 9 9 9 9 9 9 9 9 9 ...\n$ Linkages: int  9 9 9 9 9 9 9 9 9 9 ...\n$ Name    : chr  NA NA NA NA ...\n$ geometry:sfc_POLYGON of length 27108; first list element: List of 1\n..$ : num [1:65, 1:2] -147 -147 -147 -147 -147 ...\n..- attr(*, \"class\")= chr [1:3] \"XY\" \"POLYGON\" \"sfg\"\n- attr(*, \"sf_column\")= chr \"geometry\"\n- attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA ...\n..- attr(*, \"names\")= chr [1:22] \"RGIId\" \"GLIMSId\" \"BgnDate\" \"EndDate\" ..."
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#inspect-your-data",
    "href": "r/wb_gis_mapping_slides.html#inspect-your-data",
    "title": "GIS mapping with R",
    "section": "Inspect your data",
    "text": "Inspect your data\n\n\nYour turn:\n\nInspect the wes object you created."
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#glacier-national-park-dataset",
    "href": "r/wb_gis_mapping_slides.html#glacier-national-park-dataset",
    "title": "GIS mapping with R",
    "section": "Glacier National Park dataset",
    "text": "Glacier National Park dataset\nThis dataset contains a time series of the retreat of 39 glaciers of Glacier National Park, MT, USA\nfor the years 1966, 1998, 2005 & 2015\nYou can download and unzip the 4 sets of files from the USGS website"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#read-in-and-clean-datasets",
    "href": "r/wb_gis_mapping_slides.html#read-in-and-clean-datasets",
    "title": "GIS mapping with R",
    "section": "Read in and clean datasets",
    "text": "Read in and clean datasets\nCreate a function that reads and cleans the data:\nprep &lt;- function(dir) {\n  g &lt;- st_read(dir)\n  g %&lt;&gt;% rename_with(~ tolower(gsub(\"Area....\", \"area\", .x)))\n  g %&lt;&gt;% dplyr::select(\n    year,\n    objectid,\n    glacname,\n    area,\n    shape_leng,\n    x_coord,\n    y_coord,\n    source_sca,\n    source\n  )\n}"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#combine-datasets-into-one-sf-object",
    "href": "r/wb_gis_mapping_slides.html#combine-datasets-into-one-sf-object",
    "title": "GIS mapping with R",
    "section": "Combine datasets into one sf object",
    "text": "Combine datasets into one sf object\nCheck that the CRS are all the same:\nall(sapply(\n  list(st_crs(gnp[[1]]),\n       st_crs(gnp[[2]]),\n       st_crs(gnp[[3]]),\n       st_crs(gnp[[4]])),\n  function(x) x == st_crs(gnp[[1]])\n))\n[1] TRUE"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#combine-datasets-into-one-sf-object-1",
    "href": "r/wb_gis_mapping_slides.html#combine-datasets-into-one-sf-object-1",
    "title": "GIS mapping with R",
    "section": "Combine datasets into one sf object",
    "text": "Combine datasets into one sf object\nWe can rbind the elements of our list:\ngnp &lt;- do.call(\"rbind\", gnp)\nYou can inspect your new sf object by calling it or with str"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#estimate-for-ice-thickness",
    "href": "r/wb_gis_mapping_slides.html#estimate-for-ice-thickness",
    "title": "GIS mapping with R",
    "section": "Estimate for ice thickness",
    "text": "Estimate for ice thickness\nThis dataset contains an estimate for the ice thickness of all glaciers on Earth\nThe nomenclature follows the Randolph Glacier Inventory\nIce thickness being a spatial field, this is raster data\nWe will use data in RGI60-02.16664_thickness.tif from the ETH Z√ºrich Research Collection which corresponds to one of the glaciers (Agassiz) of Glacier National Park"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#load-raster-data",
    "href": "r/wb_gis_mapping_slides.html#load-raster-data",
    "title": "GIS mapping with R",
    "section": "Load raster data",
    "text": "Load raster data\nRead in data and create a SpatRaster object:\nras &lt;- rast(\"data/RGI60-02/RGI60-02.16664_thickness.tif\")"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#inspect-our-spatraster-object",
    "href": "r/wb_gis_mapping_slides.html#inspect-our-spatraster-object",
    "title": "GIS mapping with R",
    "section": "Inspect our SpatRaster object",
    "text": "Inspect our SpatRaster object\nras\nclass       : SpatRaster \ndimensions  : 93, 74, 1  (nrow, ncol, nlyr)\nresolution  : 25, 25  (x, y)\nextent      : 707362.5, 709212.5, 5422962, 5425288  (xmin, xmax, ymin, ymax)\ncoord. ref. : +proj=utm +zone=11 +datum=WGS84 +units=m +no_defs \nsource      : RGI60-02.16664_thickness.tif \nname        : RGI60-02.16664_thickness \nnlyr gives us the number of bands (a single one here). You can also run str(ras)"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#our-data",
    "href": "r/wb_gis_mapping_slides.html#our-data",
    "title": "GIS mapping with R",
    "section": "Our data",
    "text": "Our data\nWe now have 3 sf objects & 1 SpatRaster object:\n\nak: ‚ÄÉcontour of glaciers in AK\nwes: ‚ÄÇcontour of glaciers in the rest of Western North America\ngnp: ‚ÄÇtime series of 39 glaciers in Glacier National Park, MT, USA\nras: ‚ÄÇice thickness of the Agassiz Glacier from Glacier National Park"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#lets-map-our-sf-object-ak",
    "href": "r/wb_gis_mapping_slides.html#lets-map-our-sf-object-ak",
    "title": "GIS mapping with R",
    "section": "Let‚Äôs map our sf object ak",
    "text": "Let‚Äôs map our sf object ak\nAt a bare minimum, we need tm_shape with the data & some info as to how to represent that data:\ntm_shape(ak) +\n  tm_polygons()"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#we-need-to-label-customize-it",
    "href": "r/wb_gis_mapping_slides.html#we-need-to-label-customize-it",
    "title": "GIS mapping with R",
    "section": "We need to label & customize it",
    "text": "We need to label & customize it\ntm_shape(ak) +\n  tm_polygons() +\n  tm_layout(\n    title = \"Glaciers of Alaska\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 500, 1000),\n    position = c(\"right\", \"BOTTOM\")\n  )"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#make-a-map-of-the-wes-object",
    "href": "r/wb_gis_mapping_slides.html#make-a-map-of-the-wes-object",
    "title": "GIS mapping with R",
    "section": "Make a map of the wes object",
    "text": "Make a map of the wes object\n\n\nYour turn:\n\nMake a map with the wes object you created with the data for Western North America excluding AK"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#now-lets-make-a-map-with-ak-wes",
    "href": "r/wb_gis_mapping_slides.html#now-lets-make-a-map-with-ak-wes",
    "title": "GIS mapping with R",
    "section": "Now, let‚Äôs make a map with ak & wes",
    "text": "Now, let‚Äôs make a map with ak & wes\n\nThe Coordinate Reference Systems (CRS) must be the same\n\n\nsf has a function to retrieve the CRS of an sf object: st_crs\n\n\nst_crs(ak) == st_crs(wes)\n[1] TRUE\n\n\nSo we‚Äôre good (we will see later what to do if this is not the case)"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#our-combined-map",
    "href": "r/wb_gis_mapping_slides.html#our-combined-map",
    "title": "GIS mapping with R",
    "section": "Our combined map",
    "text": "Our combined map\nLet‚Äôs start again with a minimum map without any layout to test things out:\ntm_shape(ak) +\n  tm_polygons() +\n  tm_shape(wes) +\n  tm_polygons()\n\n\nUh ‚Ä¶ oh ‚Ä¶"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#what-went-wrong",
    "href": "r/wb_gis_mapping_slides.html#what-went-wrong",
    "title": "GIS mapping with R",
    "section": "What went wrong?",
    "text": "What went wrong?\nMaps are bound by ‚Äúbounding boxes‚Äù. In tmap, they are called bbox\ntmap sets the bbox the first time tm_shape is called. In our case, the bbox was thus set to the bbox of the ak object\nWe need to create a new bbox for our new map"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#retrieving-bounding-boxes",
    "href": "r/wb_gis_mapping_slides.html#retrieving-bounding-boxes",
    "title": "GIS mapping with R",
    "section": "Retrieving bounding boxes",
    "text": "Retrieving bounding boxes\nsf has a function to retrieve the bbox of an sf object: st_bbox\nThe bbox of ak is:\nst_bbox(ak)\nxmin         ymin       xmax         ymax\n-176.14247   52.05727   -126.85450   69.35167"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#combining-bounding-boxes",
    "href": "r/wb_gis_mapping_slides.html#combining-bounding-boxes",
    "title": "GIS mapping with R",
    "section": "Combining bounding boxes",
    "text": "Combining bounding boxes\nbbox objects can‚Äôt be combined directly\nHere is how we can create a new bbox encompassing both of our bboxes:\n\nFirst, we transform our bboxes to sfc objects with st_as_sfc\nThen we combine those objects into a new sfc object with st_union\nFinally, we retrieve the bbox of that object with st_bbox:\n\nnwa_bbox &lt;- st_bbox(\n  st_union(\n    st_as_sfc(st_bbox(wes)),\n    st_as_sfc(st_bbox(ak))\n  )\n)"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#back-to-our-map",
    "href": "r/wb_gis_mapping_slides.html#back-to-our-map",
    "title": "GIS mapping with R",
    "section": "Back to our map",
    "text": "Back to our map\nWe can now use our new bounding box for the map of Western North America:\ntm_shape(ak, bbox = nwa_bbox) +\n  tm_polygons() +\n  tm_shape(wes) +\n  tm_polygons() +\n  tm_layout(\n    title = \"Glaciers of Western North America\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 1000, 2000),\n    position = c(\"right\", \"BOTTOM\")\n  )"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#lets-add-a-basemap",
    "href": "r/wb_gis_mapping_slides.html#lets-add-a-basemap",
    "title": "GIS mapping with R",
    "section": "Let‚Äôs add a basemap",
    "text": "Let‚Äôs add a basemap\nWe will use data from Natural Earth, a public domain map dataset\nThere are much more fancy options, but they usually involve creating accounts (e.g.¬†with Google) to access some API\nIn addition, this dataset can be accessed direction from within R thanks to the rOpenSci packages:\n\nrnaturalearth: provides the functions\nrnaturalearthdata: provides the data"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#create-an-sf-object-with-statesprovinces",
    "href": "r/wb_gis_mapping_slides.html#create-an-sf-object-with-statesprovinces",
    "title": "GIS mapping with R",
    "section": "Create an sf object with states/provinces",
    "text": "Create an sf object with states/provinces\nstates_all &lt;- ne_states(\n  country = c(\"canada\", \"united states of america\"),\n  returnclass = \"sf\"\n)\n\nne_ stands for ‚ÄúNatural Earth‚Äù"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#select-relevant-statesprovinces",
    "href": "r/wb_gis_mapping_slides.html#select-relevant-statesprovinces",
    "title": "GIS mapping with R",
    "section": "Select relevant states/provinces",
    "text": "Select relevant states/provinces\nstates &lt;- states_all %&gt;%\n  filter(name_en == \"Alaska\" |\n           name_en == \"British Columbia\" |\n           name_en == \"Yukon\" |\n           name_en == \"Northwest Territories\" |\n           name_en ==  \"Alberta\" |\n           name_en == \"California\" |\n           name_en == \"Washington\" |\n           name_en == \"Oregon\" |\n           name_en == \"Idaho\" |\n           name_en == \"Montana\" |\n           name_en == \"Wyoming\" |\n           name_en == \"Colorado\" |\n           name_en == \"Nevada\" |\n           name_en == \"Utah\"\n         )"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#add-the-basemap-to-our-map",
    "href": "r/wb_gis_mapping_slides.html#add-the-basemap-to-our-map",
    "title": "GIS mapping with R",
    "section": "Add the basemap to our map",
    "text": "Add the basemap to our map\n\n\nWhat do we need to make sure of first?\n\n\n\nst_crs(states) == st_crs(ak)\n[1] TRUE"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#add-the-basemap-to-our-map-1",
    "href": "r/wb_gis_mapping_slides.html#add-the-basemap-to-our-map-1",
    "title": "GIS mapping with R",
    "section": "Add the basemap to our map",
    "text": "Add the basemap to our map\nWe add the basemap as a 3rd layer\nMind the order! If you put the basemap last, it will cover your data\nOf course, we will use our nwa_bbox bounding box again\nWe will also break tm_polygons into tm_borders and tm_fill for ak and wes in order to colourise them with slightly different colours"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#add-the-basemap-to-our-map-2",
    "href": "r/wb_gis_mapping_slides.html#add-the-basemap-to-our-map-2",
    "title": "GIS mapping with R",
    "section": "Add the basemap to our map",
    "text": "Add the basemap to our map\ntm_shape(states, bbox = nwa_bbox) +\n  tm_polygons(col = \"#f2f2f2\", lwd = 0.2) +\n  tm_shape(ak) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_shape(wes) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_layout(\n    title = \"Glaciers of Western North America\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 1000, 2000),\n    position = c(\"right\", \"BOTTOM\")\n  )"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#tmap-styles",
    "href": "r/wb_gis_mapping_slides.html#tmap-styles",
    "title": "GIS mapping with R",
    "section": "tmap styles",
    "text": "tmap styles\ntmap has a number of styles that you can try\nFor instance, to set the style to ‚Äúclassic‚Äù, run the following before making your map:\ntmap_style(\"classic\")\n\nOther options are:\n‚Äúwhite‚Äù (default), ‚Äúgray‚Äù, ‚Äúnatural‚Äù, ‚Äúcobalt‚Äù, ‚Äúcol_blind‚Äù, ‚Äúalbatross‚Äù, ‚Äúbeaver‚Äù, ‚Äúbw‚Äù, ‚Äúwatercolor‚Äù"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#tmap-styles-1",
    "href": "r/wb_gis_mapping_slides.html#tmap-styles-1",
    "title": "GIS mapping with R",
    "section": "tmap styles",
    "text": "tmap styles\nTo return to the default, you need to run\ntmap_style(\"white\")\nor\ntmap_options_reset()\nwhich will reset every tmap option"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#first-lets-map-it",
    "href": "r/wb_gis_mapping_slides.html#first-lets-map-it",
    "title": "GIS mapping with R",
    "section": "First, let‚Äôs map it",
    "text": "First, let‚Äôs map it\nLet‚Äôs use the same tm_borders and tm_fill we just used:\ntm_shape(gnp) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_layout(\n    title = \"Glaciers of Glacier National Park\",\n    title.position = c(\"center\", \"top\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 10, 20),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#create-an-inset-map",
    "href": "r/wb_gis_mapping_slides.html#create-an-inset-map",
    "title": "GIS mapping with R",
    "section": "Create an inset map",
    "text": "Create an inset map\nAs always, first we check that the CRS are the same:\nst_crs(gnp) == st_crs(ak)\n[1] FALSE\n\nAH!"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#crs-transformation",
    "href": "r/wb_gis_mapping_slides.html#crs-transformation",
    "title": "GIS mapping with R",
    "section": "CRS transformation",
    "text": "CRS transformation\nWe need to reproject gnp into the CRS of our other sf objects (e.g.¬†ak):\ngnp &lt;- st_transform(gnp, st_crs(ak))\n\nWe can verify that the CRS are now the same:\nst_crs(gnp) == st_crs(ak)\n[1] TRUE"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#inset-maps-first-step",
    "href": "r/wb_gis_mapping_slides.html#inset-maps-first-step",
    "title": "GIS mapping with R",
    "section": "Inset maps: first step",
    "text": "Inset maps: first step\nAdd a rectangle showing the location of the GNP map in the main North America map\nWe need to create a new sfc object from the gnp bbox so that we can add it to our previous map as a new layer:\ngnp_zone &lt;- st_bbox(gnp) %&gt;%\n  st_as_sfc()"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#inset-maps-second-step",
    "href": "r/wb_gis_mapping_slides.html#inset-maps-second-step",
    "title": "GIS mapping with R",
    "section": "Inset maps: second step",
    "text": "Inset maps: second step\nCreate a tmap object of the main map. Of course, we need to edit the title. Also, note the presence of our new layer:\nmain_map &lt;- tm_shape(states, bbox = nwa_bbox) +\n  tm_polygons(col = \"#f2f2f2\", lwd = 0.2) +\n  tm_shape(ak) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_shape(wes) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_shape(gnp_zone) +\n  tm_borders(lwd = 1.5, col = \"#ff9900\") +\n  tm_layout(\n    title = \"Glaciers of Glacier National Park\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 500, 1000),\n    position = c(\"right\", \"BOTTOM\")\n  )"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#inset-maps-third-step",
    "href": "r/wb_gis_mapping_slides.html#inset-maps-third-step",
    "title": "GIS mapping with R",
    "section": "Inset maps: third step",
    "text": "Inset maps: third step\nCreate a tmap object of the inset map\nWe make sure to matching colours & edit the layouts for better readability:\ninset_map &lt;- tm_shape(gnp) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_layout(\n    legend.show = F,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.03, 0.03, 0.03, 0.03),\n    outer.margins = 0,\n    frame = \"#ff9900\",\n    frame.lwd = 3\n  )"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#inset-maps-final-step",
    "href": "r/wb_gis_mapping_slides.html#inset-maps-final-step",
    "title": "GIS mapping with R",
    "section": "Inset maps: final step",
    "text": "Inset maps: final step\nCombine the two tmap objects\nWe print the main map & add the inset map with grid::viewport:\nmain_map\nprint(inset_map, vp = viewport(0.41, 0.26, width = 0.5, height = 0.5))"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#map-of-the-agassiz-glacier",
    "href": "r/wb_gis_mapping_slides.html#map-of-the-agassiz-glacier",
    "title": "GIS mapping with R",
    "section": "Map of the Agassiz Glacier",
    "text": "Map of the Agassiz Glacier\nSelect the data points corresponding to the Agassiz Glacier:\nag &lt;- gnp %&gt;% filter(glacname == \"Agassiz Glacier\")"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#map-of-the-agassiz-glacier-1",
    "href": "r/wb_gis_mapping_slides.html#map-of-the-agassiz-glacier-1",
    "title": "GIS mapping with R",
    "section": "Map of the Agassiz Glacier",
    "text": "Map of the Agassiz Glacier\ntm_shape(ag) +\n  tm_polygons() +\n  tm_layout(\n    title = \"Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#map-of-the-agassiz-glacier-2",
    "href": "r/wb_gis_mapping_slides.html#map-of-the-agassiz-glacier-2",
    "title": "GIS mapping with R",
    "section": "Map of the Agassiz Glacier",
    "text": "Map of the Agassiz Glacier\n\n\nNot great ‚Ä¶"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#map-based-on-attribute-variables",
    "href": "r/wb_gis_mapping_slides.html#map-based-on-attribute-variables",
    "title": "GIS mapping with R",
    "section": "Map based on attribute variables",
    "text": "Map based on attribute variables\ntm_shape(ag) +\n  tm_polygons(\"year\", palette = \"Blues\") +\n  tm_layout(\n    title = \"Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#using-ggplot2-instead-of-tmap",
    "href": "r/wb_gis_mapping_slides.html#using-ggplot2-instead-of-tmap",
    "title": "GIS mapping with R",
    "section": "Using ggplot2 instead of tmap",
    "text": "Using ggplot2 instead of tmap\nAs an alternative to tmap, ggplot2 can plot maps with the geom_sf function:\nggplot(ag) +\n  geom_sf(aes(fill = year)) +\n  scale_fill_brewer(palette = \"Blues\") +\n  labs(title = \"Agassiz Glacier\") +\n  annotation_scale(location = \"bl\", width_hint = 0.4) +\n  annotation_north_arrow(location = \"tr\", which_north = \"true\",\n                         pad_x = unit(0.75, \"in\"), pad_y = unit(0.5, \"in\"),\n                         style = north_arrow_fancy_orienteering) +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5))\nThe package ggspatial adds a lot of functionality to ggplot2 for spatial data"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#faceted-map-of-the-retreat-of-agassiz",
    "href": "r/wb_gis_mapping_slides.html#faceted-map-of-the-retreat-of-agassiz",
    "title": "GIS mapping with R",
    "section": "Faceted map of the retreat of Agassiz",
    "text": "Faceted map of the retreat of Agassiz\ntm_shape(ag) +\n  tm_polygons(col = \"#86baff\") +\n  tm_layout(\n    main.title = \"Agassiz Glacier\",\n    main.title.position = c(\"center\", \"top\"),\n    main.title.size = 1.2,\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0, 0.03, 0, 0.03),\n    outer.margins = 0,\n    panel.label.bg.color = \"#fcfcfc\",\n    frame = F,\n    asp = 0.6\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 0.6\n  ) +\n  tm_facets(\n    by = \"year\",\n    free.coords = F,\n    ncol = 4\n  )"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#animated-map-of-the-retreat-of-agassiz",
    "href": "r/wb_gis_mapping_slides.html#animated-map-of-the-retreat-of-agassiz",
    "title": "GIS mapping with R",
    "section": "Animated map of the Retreat of Agassiz",
    "text": "Animated map of the Retreat of Agassiz\nFirst, we need to create a tmap object with facets:\nagassiz_anim &lt;- tm_shape(ag) +\n  tm_polygons(col = \"#86baff\") +\n  tm_layout(\n    title = \"Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.08, 0, 0.08, 0),\n    outer.margins = 0,\n    panel.label.bg.color = \"#fcfcfc\"\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  ) +\n  tm_facets(\n    along = \"year\",\n    free.coords = F\n  )"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#animated-map-of-the-retreat-of-agassiz-1",
    "href": "r/wb_gis_mapping_slides.html#animated-map-of-the-retreat-of-agassiz-1",
    "title": "GIS mapping with R",
    "section": "Animated map of the Retreat of Agassiz",
    "text": "Animated map of the Retreat of Agassiz\nThen we can pass that object to tmap_animation:\ntmap_animation(\n  agassiz_anim,\n  filename = \"ag.gif\",\n  dpi = 300,\n  inner.margins = c(0.08, 0, 0.08, 0),\n  delay = 100\n)"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#map-of-ice-thickness-of-agassiz",
    "href": "r/wb_gis_mapping_slides.html#map-of-ice-thickness-of-agassiz",
    "title": "GIS mapping with R",
    "section": "Map of ice thickness of Agassiz",
    "text": "Map of ice thickness of Agassiz\nNow, let‚Äôs map the estimated ice thickness on Agassiz Glacier. This time, we use tm_raster:\ntm_shape(ras) +\n  tm_raster(title = \"\") +\n  tm_layout(\n    title = \"Ice thickness (m) of Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.bg.color = \"#ffffff\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#combining-with-randolph-data",
    "href": "r/wb_gis_mapping_slides.html#combining-with-randolph-data",
    "title": "GIS mapping with R",
    "section": "Combining with Randolph data",
    "text": "Combining with Randolph data\nAs always, we check whether the CRS are the same:\nst_crs(ag) == st_crs(ras)\n[1] FALSE\nWe need to reproject ag (remember that it is best to avoid reprojecting raster data):\nag %&lt;&gt;% st_transform(st_crs(ras))"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#combining-with-randolph-data-1",
    "href": "r/wb_gis_mapping_slides.html#combining-with-randolph-data-1",
    "title": "GIS mapping with R",
    "section": "Combining with Randolph data",
    "text": "Combining with Randolph data\nThe layers hide each other (the order matters!). You can use tm_borders for one of them or transparency (alpha). We also adjust the legend:\ntm_shape(ras) +\n  tm_raster(title = \"Ice (m)\") +\n  tm_shape(ag) +\n  tm_polygons(\"year\", palette = \"Blues\", alpha = 0.2, title = \"Contour\") +\n  tm_layout(\n    title = \"Ice thickness (m) and retreat of Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.bg.color = \"#ffffff\",\n    legend.text.size = 0.7,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#refining-raster-maps",
    "href": "r/wb_gis_mapping_slides.html#refining-raster-maps",
    "title": "GIS mapping with R",
    "section": "Refining raster maps",
    "text": "Refining raster maps\nLet‚Äôs go back to our ice thickness map:"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#basemap-with-ggmap",
    "href": "r/wb_gis_mapping_slides.html#basemap-with-ggmap",
    "title": "GIS mapping with R",
    "section": "Basemap with ggmap",
    "text": "Basemap with ggmap\nbasemap &lt;- get_map(\n  bbox = c(\n    left = st_bbox(ag)[1],\n    bottom = st_bbox(ag)[2],\n    right = st_bbox(ag)[3],\n    top = st_bbox(ag)[4]\n  ),\n  source = \"osm\"\n)\n\nggmap is a powerful package, but Google now requires an API key obtained through registration"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#basemap-with-basemaps",
    "href": "r/wb_gis_mapping_slides.html#basemap-with-basemaps",
    "title": "GIS mapping with R",
    "section": "Basemap with basemaps",
    "text": "Basemap with basemaps\nThe package basemaps allows to download open source basemap data from several sources, but those cannot easily be combined with sf objects\nThis plots a satellite image of the Agassiz Glacier:\nbasemap_plot(ag, map_service = \"esri\", map_type = \"world_imagery\")"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#satellite-image-of-the-agassiz-glacier",
    "href": "r/wb_gis_mapping_slides.html#satellite-image-of-the-agassiz-glacier",
    "title": "GIS mapping with R",
    "section": "Satellite image of the Agassiz Glacier",
    "text": "Satellite image of the Agassiz Glacier"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#mapview",
    "href": "r/wb_gis_mapping_slides.html#mapview",
    "title": "GIS mapping with R",
    "section": "mapview",
    "text": "mapview\nmapview(gnp)"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#tmap-1",
    "href": "r/wb_gis_mapping_slides.html#tmap-1",
    "title": "GIS mapping with R",
    "section": "tmap",
    "text": "tmap\nSo far, we have used the plot mode of tmap. There is also a view mode which allows interactive viewing in a browser through Leaflet\nChange to view mode:\ntmap_mode(\"view\")\n\nYou can also toggle between modes with ttm\n\nRe-plot the last map we plotted with tmap:\ntmap_last()"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#leaflet",
    "href": "r/wb_gis_mapping_slides.html#leaflet",
    "title": "GIS mapping with R",
    "section": "leaflet",
    "text": "leaflet\nleaflet creates a map widget to which you add layers\nmap &lt;- leaflet()\naddTiles(map)"
  },
  {
    "objectID": "r/wb_gis_mapping_slides.html#resources-2",
    "href": "r/wb_gis_mapping_slides.html#resources-2",
    "title": "GIS mapping with R",
    "section": "Resources",
    "text": "Resources\nHere are some resources on the topic to get started.\n\nR companion to Geographic Information Analysis\nSpatial data analysis"
  },
  {
    "objectID": "r/wb_hpc_content.html",
    "href": "r/wb_hpc_content.html",
    "title": "High-performance research computing in ",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "High-performance computing",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_hpc_content.html#running-r-on-hpc-clusters",
    "href": "r/wb_hpc_content.html#running-r-on-hpc-clusters",
    "title": "High-performance research computing in ",
    "section": "Running R on HPC clusters",
    "text": "Running R on HPC clusters\n\nLoading modules\n\nIntel vs GCC compilers\nTo compile R packages, you need a C compiler.\nIn theory, you could use the proprietary Intel compiler which is loaded by default on the Alliance clusters, but it is recommended to replace it with the GCC compiler (R packages can even be compiled with Clang and LLVM, but the default GCC compiler is the best way to avoid headaches).\nIt is thus much simpler to always load a gcc module before loading an r module.\n\n\nR module\nTo see what versions of R are available on a cluster, run:\nmodule spider r\nTo see the dependencies of a particular version (e.g.¬†r/4.2.1), run:\nmodule spider r/4.2.1\n\nStdEnv/2020 is a required module for this version.\nOn most Alliance clusters, it is automatically loaded, so you don‚Äôt need to include it. You can double-check with module list or you can include it (before r/4.2.1) just to be sure.\n\nFinally, load your modules:\nmodule load StdEnv/2020 gcc/11.3.0 r/4.2.1",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "High-performance computing",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_hpc_content.html#installing-r-packages",
    "href": "r/wb_hpc_content.html#installing-r-packages",
    "title": "High-performance research computing in ",
    "section": "Installing R packages",
    "text": "Installing R packages\nTo install a package, launch the interactive R console with:\nR\nIn the R console, run:\ninstall.packages(\"&lt;package_name&gt;\", repos=\"&lt;url-cran-mirror&gt;\")\n\nrepos argument: chose a CRAN mirror close to the location of your cluster or use https://cloud.r-project.org/.\n\n\nThe first time you install a package, R will ask you whether you want to create a personal library in your home directory. Answer yes to both questions. Your packages will now install under ~/.\n\n\nSome packages require additional modules to be loaded before they can be installed. Other packages need additional R packages as dependencies. In either case, you will get explicit error messages. Adding the argument dependencies = TRUE helps in the second case, but you will still have to add packages manually from time to time.\n\nLet‚Äôs install the packages needed for this webinar:\ninstall.packages(\n  c(\"tidyverse\", \"bench\", \"doFuture\", \"doRNG\", \"randomForest\", \"Rcpp\"),\n  repos=\"https://mirror.rcg.sfu.ca/mirror/CRAN/\"  # closest mirror from Cedar\n)\n\nThis will also install the dependencies foreach, future, and iterators.\n\nTo leave the R console, press &lt;Ctrl+D&gt;.",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "High-performance computing",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_hpc_content.html#running-r-jobs",
    "href": "r/wb_hpc_content.html#running-r-jobs",
    "title": "High-performance research computing in ",
    "section": "Running R jobs",
    "text": "Running R jobs\n\nScripts\nTo run an R script called &lt;your_script&gt;.R, you first need to write a job script:\n\nExample:\n\n\n&lt;your_job&gt;.sh\n\n#!/bin/bash\n#SBATCH --account=def-&lt;your_account&gt;\n#SBATCH --time=15\n#SBATCH --mem-per-cpu=3000M\n#SBATCH --cpus-per-task=4\n#SBATCH --job-name=\"&lt;your_job&gt;\"\nmodule load StdEnv/2020 gcc/11.3.0 r/4.2.1\nRscript &lt;your_script&gt;.R   # Note that R scripts are run with the command `Rscript`\n\n\nThen launch your job with:\nsbatch &lt;your_job&gt;.sh\nYou can monitor your job with sq (an alias for squeue -u $USER $@).\n\n\nInteractive jobs\n\nWhile it is fine to run R on the login node when you install packages, you must start a SLURM job before any heavy computation.\n\nTo run R interactively, you should launch an salloc session.\nHere is what I will use for this webinar:\nsalloc --time=1:10:00 --mem-per-cpu=7000M --ntasks=8\nThis takes me to a compute node where I can launch R to run computations:\nR",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "High-performance computing",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_hpc_content.html#performance",
    "href": "r/wb_hpc_content.html#performance",
    "title": "High-performance research computing in ",
    "section": "Performance",
    "text": "Performance\n\nProfiling\nThe first thing to do if you want to improve your code efficiency is to identify bottlenecks in your code. Common tools are:\n\nthe base R function Rprof()\nthe package profvis\n\nprofvis is a newer tool, built by posit (formerly RStudio). Under the hood, it runs Rprof() to collect data, then produces an interactive html widget with a flame graph that allows for an easy visual identification of slow sections of code. While this tool integrates well within the RStudio IDE or the RPubs ecosystem, it is not very well suited for remote work on a cluster. One option is to profile your code with small data on your own machine. Another option is to use the base profiler with Rprof() directly as in this example.\n\n\nBenchmarking\nOnce you have identified expressions that are particularly slow, you can use benchmarking tools to compare variations of the code.\nIn the most basic fashion, you can use system.time(), but this is limited and imprecise.\nThe microbenchmark package is a popular option.\nIt gives the minimum time, lower quartile, mean, median, upper quartile, and maximum time of R expressions.\nThe newer bench package has less overhead, is more accurate, and‚Äîfor sequential code‚Äîgives information on memory usage and garbage collections. This is the package I will use today.",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "High-performance computing",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_hpc_content.html#parallel-programming",
    "href": "r/wb_hpc_content.html#parallel-programming",
    "title": "High-performance research computing in ",
    "section": "Parallel programming",
    "text": "Parallel programming\n\nMulti-threading\nWe talk about multi-threading when a single process (with its own memory) runs multiple threads.\nThe execution can happen in parallel‚Äîif each thread has access to a CPU core‚Äîor by alternating some of the threads on some CPU cores.\nBecause all threads in a process write to the same memory addresses, multi-threading can lead to race conditions.\nMulti-threading does not seem to be a common approach to parallelizing R code.\n\n\nMulti-processing in shared memory\nMulti-processing in shared memory happens when multiple processes execute code on multiple CPU cores of a single node (or a single machine).\nThe different processes need to communicate with each other, but because they are all running on the CPU cores of a single node, messages can pass via shared memory.\n\n\nMulti-processing in distributed memory\nWhen processes involved in the execution of some code run on multiple nodes of a cluster, messages between them need to travel over the cluster interconnect. In that case, we talk about distributed memory.",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "High-performance computing",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_hpc_content.html#running-r-code-in-parallel",
    "href": "r/wb_hpc_content.html#running-r-code-in-parallel",
    "title": "High-performance research computing in ",
    "section": "Running R code in parallel",
    "text": "Running R code in parallel\n\nPackage parallel (base R)\nThe parallel package has been part of the ‚Äúbase‚Äù package group since version 2.14.0.\nThis means that it is comes with R.\nMost parallel approaches in R build on this package.\nWe will make use of it to create and close an ad-hoc cluster.\n\nThe parallelly package adds functionality to the parallel package.\n\n\n\nPackage foreach\nThe foreach package implements a looping construct without an explicit counter. It doesn‚Äôt require the preallocation of an output container, it brings to R an equivalent of the Python or Julia list comprehensions, and mostly, it allows for an easy execution of loops in parallel. Unlike loops, it creates variables (loops are used for their side-effect).\nLet‚Äôs look at an example to calculate the sum of 1e4 random vectors of length 3.\nWe will use foreach and iterators (which creates convenient iterators for foreach):\n\nlibrary(foreach)\nlibrary(iterators)\n\nClassic while loop:\n\nset.seed(2)\nresult1 &lt;- numeric(3)            # Preallocate output container\ni &lt;- 0                           # Initialise counter variable\n\nwhile(i &lt; 1e4) {                 # Finally we run the loop\n  result1 &lt;- result1 + runif(3)  # Calculate the sum\n  i &lt;- i + 1                     # Update the counter\n}\n\nWith foreach:\n\nset.seed(2)\nresult2 &lt;- foreach(icount(1e4), .combine = '+') %do% runif(3)\n\nVerify:\n\nall.equal(result1, result2)\n\n[1] TRUE\n\n\nThe best part of foreach is that you can turn sequential loops into parallel ones by registering a parallel backend and replacing %do% with %dopar%.\nThere are many parallelization backends available: doFuture, doMC, doMPI, doFuture, doParallel, doRedis, doRNG, doSNOW, and doAzureParallel.\nIn this webinar, I will use doFuture which allows to evaluate foreach expressions following any of the strategies of the future package.\nSo first, what is the future package?\n\n\nPackage future\nA future is an object that acts as an abstract representation for a value in the future. A future can be resolved (if the value has been computed) or unresolved. If the value is queried while the future is unresolved, the process is blocked until the future is resolved.\nFutures allow for asynchronous and parallel evaluations. The future package provides a simple and unified API to evaluate futures.\n\n\nPlans\nThe future package does this thanks to the plan function:\n\nplan(sequential): futures are evaluated sequentially in the current R session\nplan(multisession): futures are evaluated by new R sessions spawned in the background (multi-processing in shared memory)\nplan(multicore): futures are evaluated in processes forked from the existing process (multi-processing in shared memory)\nplan(cluster): futures are evaluated on an ad-hoc cluster (allows for distributed parallelism across multiple nodes)\n\n\n\nConsistency\nTo ensure a consistent behaviour across plans, all evaluations are done in a local environment:\n\nlibrary(future)\n\na &lt;- 1\n\nb %&lt;-% {\n  a &lt;- 2\n}\n\na\n\n[1] 1\n\n\n\n\nLet‚Äôs return to our example\nWe had:\nset.seed(2)\nresult2 &lt;- foreach(icount(1e4), .combine = '+') %do% runif(3)\nWe can replace %do% with %dopar%:\nset.seed(2)\nresult3 &lt;- foreach(icount(1e4), .combine = '+') %dopar% runif(3)\nSince we haven‚Äôt registered any parallel backend, the expression will still be evaluated sequentially.\nTo run this in parallel, we need to load doFuture, register it as a backend (with registerDoFuture()), and choose a parallel strategy (e.g.¬†plan(multicore)):\nlibrary(foreach)\nlibrary(doFuture)\n\nregisterDoFuture()\nplan(multicore)\n\nset.seed(2)\nresult3 &lt;- foreach(icount(1e4), .combine = '+') %dopar% runif(3)\n\nWith the overhead of parallelization, it actually doesn‚Äôt make sense to parallelize such a short code, so let‚Äôs go over a toy example and do some benchmarking.",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "High-performance computing",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_hpc_content.html#toy-example",
    "href": "r/wb_hpc_content.html#toy-example",
    "title": "High-performance research computing in ",
    "section": "Toy example",
    "text": "Toy example\n\nLoad packages\nFor this toy example, I will use a modified version of one of the examples in the foreach vignette: I will b uild a classification model made of a forest of decision trees thanks to the randomForest package.\nBecause the code includes randomly generated numbers, I will use the doRNG package which replaces foreach::%dopar% wit h doRNG::%dorng%. This follows the recommendations of Pierre L‚ÄôEcuyer (1999)1 and ensures reproducibility.\nlibrary(doFuture)       # This will also load the `future` package\nlibrary(doRNG)          # This will also load the `foreach` package\nlibrary(randomForest)\nlibrary(bench)          # To do some benchmarking\nLoading required package: foreach\nLoading required package: future\nLoading required package: rngtools\n\n\nThe code to parallelize\nThe goal is to create a classifier based on some data (here a matrix of random numbers for simplicity) and a response variable (as factor). This model could then be passed in the predict() function with novel data to generate predictions of classification. But here we are only interested in the creation of the model as this is the part that is computationally intensive. We aren‚Äôt interested in actually using it.\nset.seed(11)\ntraindata &lt;- matrix(runif(1e5), 100)\nfac &lt;- gl(2, 50)\n\nrf &lt;- foreach(ntree = rep(250, 8), .combine = combine) %do%\n  randomForest(x = traindata, y = fac, ntree = ntree)\n\nrf\nCall:\n randomForest(x = traindata, y = fac, ntree = ntree)\n               Type of random forest: classification\n                     Number of trees: 2000\nNo. of variables tried at each split: 31\n\n\nReference timing\nThis is the non parallelizable code with %do%:\ntref &lt;- mark(\n  rf1 &lt;- foreach(ntree = rep(250, 8), .combine = combine) %do%\n    randomForest(x = traindata, y = fac, ntree = ntree),\n  memory = FALSE\n)\n\ntref$median\n[1] 5.66s\n\n\nPlan sequential\nThis is the parallelizable foreach code, but run sequentially:\nregisterDoFuture()   # Set the parallel backend\nplan(sequential)     # Set the evaluation strategy\n\n# Using bench::mark()\ntseq &lt;- mark(\n  rf2 &lt;- foreach(ntree = rep(250, 8), .combine = combine) %dorng%\n    randomForest(x = traindata, y = fac, ntree = ntree),\n  memory = FALSE\n)\n\ntseq$median\n[1] 5.78s\n\nNo surprise: those are similar.\n\n\n\nMulti-processing in shared memory\nfuture provides availableCores() to detect the number of available cores:\navailableCores()\nsystem\n     4\n\nSimilar to parallel::detectCores().\n\nThis detects the number of CPU cores available to me on the current compute node, that is, what I can use for shared memory multi-processing.\n\n\nPlan multisession\nShared memory multi-processing can be run with plan(multisession) that will spawn new R sessions in the background to evaluate futures:\nplan(multisession)\n\ntms &lt;- mark(\n  rf2 &lt;- foreach(ntree = rep(250, 8), .combine = combine) %dorng%\n    randomForest(x = traindata, y = fac, ntree = ntree),\n  memory = FALSE\n)\n\ntms$median\n[1] 2s\n\nWe got a speedup of 5.78 / 2 = 2.9.\n\n\n\nPlan multicore\nShared memory multi-processing can also be run with plan(multicore) (except on Windows) that will fork the current R process to evaluate futures:\nplan(multicore)\n\ntmc &lt;- mark(\n  rf2 &lt;- foreach(ntree = rep(250, 8), .combine = combine) %dorng%\n    randomForest(x = traindata, y = fac, ntree = ntree),\n  memory = FALSE\n)\n\ntmc$median\n[1] 1.9s\n\nWe got a very similar speedup of 5.78 / 1.9 = 3.0.\n\n\n\nMulti-processing in distributed memory\nI requested 8 tasks from Slurm on a training cluster made of nodes with 4 CPU cores each. Let‚Äôs verify that I got them by accessing the SLURM_NTASKS environment variable from within R:\nas.numeric(Sys.getenv(\"SLURM_NTASKS\"))\n[1] 8\nI can create a character vector with the name of the node each task is running on:\n(hosts &lt;- system(\"srun hostname | cut -f 1 -d '.'\", intern = TRUE))\nchr [1:8] \"node1\" \"node1\" \"node1\" \"node1\" \"node2\" \"node2\" \"node2\" \"node2\"\nThis allows me to create a cluster of workers:\n(cl &lt;- parallel::makeCluster(hosts))      # Defaults to type=\"PSOCK\"\nsocket cluster with 8 nodes on hosts ‚Äònode1‚Äô, ‚Äònode2‚Äô\n\n\nPlan cluster\nI can now try the code with distributed parallelism using all 8 CPU cores across both nodes:\nplan(cluster, workers = cl)\n\ntdis &lt;- mark(\n  rf2 &lt;- foreach(ntree = rep(250, 8), .combine = combine) %dorng%\n    randomForest(x = traindata, y = fac, ntree = ntree),\n  memory = FALSE\n)\n\ntdis$median\n[1] 1.14s\n\nSpeedup: 5.78 / 1.14 = 5.1.\n\nThe cluster of workers can be stopped with:\nparallel::stopCluster(cl)\n\n\nAlternative approaches\nThe multidplyr package partitions data frames across worker processes, allows you to run the usual tidyverse functions on each partition, then collects the processed data.\nThe furrr package is a parallel equivalent to the purrr package from the tidyverse.\nIf you work with genomic data, you might want to have a look at the BiocParallel package from Bioconductor.\nYet another option to run distributed R code is to use the sparklyr package (an R interface to Spark).\nRmpi is a wrapper to MPI (Message-Passing Interface). It has proved slow and problematic on Cedar though.\nThe boot package provides functions and datasets specifically for bootstrapping in parallel.",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "High-performance computing",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_hpc_content.html#write-c-with-rcpp",
    "href": "r/wb_hpc_content.html#write-c-with-rcpp",
    "title": "High-performance research computing in ",
    "section": "Write C++ with Rcpp",
    "text": "Write C++ with Rcpp\n\nWhen?\n\nCode that cannot easily be parallelized (e.g.¬†multiple recursive function calls)\nLarge number of function calls\nNeed for data structures missing in R\nCreation of efficient packages\n\n\n\nHow?\nRcpp provides C++ classes with mappings to R‚Äôs .Call(). C++ functions can be declared in source files or directly in R scripts.",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "High-performance computing",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_hpc_content.html#footnotes",
    "href": "r/wb_hpc_content.html#footnotes",
    "title": "High-performance research computing in ",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nL‚ÄôEcuyer, P. (1999). Good parameters and implementations for combined multiple recursive random number generators. Operations Research, 47, 159‚Äì164.‚Ü©Ô∏é",
    "crumbs": [
      "R",
      "<em><b>Webinars</b></em>",
      "High-performance computing",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "r/wb_package.html",
    "href": "r/wb_package.html",
    "title": "Creating R packages",
    "section": "",
    "text": "Coming up in spring 2024."
  },
  {
    "objectID": "r/ws_demo.html",
    "href": "r/ws_demo.html",
    "title": "A little demo of programming in R",
    "section": "",
    "text": "R is a free and open-source programming language with a large collection of packages for statistical computing, modeling, and graphics. It is extremely popular in several academic fields including statistics, biology, economics, data mining, data analysis, and linguistics.\nThis high-level presentation will give you a sense of what R can be used for through a series of examples (data visualization, web scraping, and GIS). I will also talk about the strengths and weaknesses of R and who would benefit most from learning it.\n\nSlides (Click and wait: the presentation might take a few instants to load) \n\n Slides content for easier browsing.",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "A little demo of R programming"
    ]
  },
  {
    "objectID": "r/ws_demo_slides.html#history",
    "href": "r/ws_demo_slides.html#history",
    "title": "A little demo of programming in",
    "section": "History",
    "text": "History\nCreated by academic statisticians Ross Ihaka and Robert Gentleman\nThe name comes from the language S which was a great influence as well as the first initial of the developers\nLaunched in 1993\nA GNU Project since 1997"
  },
  {
    "objectID": "r/ws_demo_slides.html#why-r",
    "href": "r/ws_demo_slides.html#why-r",
    "title": "A little demo of programming in",
    "section": "Why R?",
    "text": "Why R?\nFree and open source\nHigh-level and easy to learn\nLarge community\nVery well documented\nUnequalled number of statistics and modelling packages\nIntegrated package manager\nEasy connection with fast compiled languages such as C and C++\nPowerful IDEs (e.g.¬†RStudio, ESS, Jupyter)"
  },
  {
    "objectID": "r/ws_demo_slides.html#for-whom",
    "href": "r/ws_demo_slides.html#for-whom",
    "title": "A little demo of programming in",
    "section": "For whom?",
    "text": "For whom?\nFields with heavy statistics, modelling, or Bayesian inference such as biology, linguistics, economics, or statistics\nData science"
  },
  {
    "objectID": "r/ws_demo_slides.html#downsides",
    "href": "r/ws_demo_slides.html#downsides",
    "title": "A little demo of programming in",
    "section": "Downsides",
    "text": "Downsides\nInconsistent syntax full of quirks\nSlow\nLarge memory usage"
  },
  {
    "objectID": "r/ws_demo_slides.html#an-interpreted-language",
    "href": "r/ws_demo_slides.html#an-interpreted-language",
    "title": "A little demo of programming in",
    "section": "An interpreted language",
    "text": "An interpreted language\nR being an interpreted language, it can be run non-interactively or interactively"
  },
  {
    "objectID": "r/ws_demo_slides.html#running-r-non-interactively",
    "href": "r/ws_demo_slides.html#running-r-non-interactively",
    "title": "A little demo of programming in",
    "section": "Running R non-interactively",
    "text": "Running R non-interactively\nIf you write code in a text file (called a script), you can then execute it with:\nRscript my_script.R\n\nThe command to execute scripts is Rscript rather than R\nBy convention, R scripts take the extension .R"
  },
  {
    "objectID": "r/ws_demo_slides.html#running-r-interactively",
    "href": "r/ws_demo_slides.html#running-r-interactively",
    "title": "A little demo of programming in",
    "section": "Running R interactively",
    "text": "Running R interactively\nThere are several ways to run R interactively:\n\ndirectly in the console (the name for the R shell)\nin Jupyter with the R kernel (IRkernel package)\nin another IDE (e.g.¬†in Emacs with ESS)\nin the RStudio IDE"
  },
  {
    "objectID": "r/ws_demo_slides.html#documentation",
    "href": "r/ws_demo_slides.html#documentation",
    "title": "A little demo of programming in",
    "section": "Documentation",
    "text": "Documentation\nThe R documentation is excellent. Get info on any function with ? (e.g.¬†?sum)"
  },
  {
    "objectID": "r/ws_demo_slides.html#basic-operations",
    "href": "r/ws_demo_slides.html#basic-operations",
    "title": "A little demo of programming in",
    "section": "Basic operations",
    "text": "Basic operations\n\na &lt;- 5\n4 + a\n\n[1] 9\n\nc &lt;- c(2, 4, 1)\nc * 5\n\n[1] 10 20  5\n\nsum(c)\n\n[1] 7"
  },
  {
    "objectID": "r/ws_demo_slides.html#statistics-probabilities-and-modelling",
    "href": "r/ws_demo_slides.html#statistics-probabilities-and-modelling",
    "title": "A little demo of programming in",
    "section": "Statistics, probabilities, and modelling",
    "text": "Statistics, probabilities, and modelling\nR really shines when it comes to statistics and modelling\nWe will spend the rest of the hour diving into very complex and heavy Bayesian statistics"
  },
  {
    "objectID": "r/ws_demo_slides.html#just-kidding",
    "href": "r/ws_demo_slides.html#just-kidding",
    "title": "A little demo of programming in",
    "section": "Just kidding üôÇ",
    "text": "Just kidding üôÇ\nIn this demo, I will stick to fun topics"
  },
  {
    "objectID": "r/ws_demo_slides.html#datasets",
    "href": "r/ws_demo_slides.html#datasets",
    "title": "A little demo of programming in",
    "section": "Datasets",
    "text": "Datasets\nR comes with a number of datasets. You can get a list by running data()"
  },
  {
    "objectID": "r/ws_demo_slides.html#datasets-1",
    "href": "r/ws_demo_slides.html#datasets-1",
    "title": "A little demo of programming in",
    "section": "Datasets",
    "text": "Datasets\nThe ggplot2 package provides additional ones, such as the mpg dataset:\n\nlibrary(ggplot2)\nhead(mpg, 4)  # we are printing only the first 4 rows\n\n# A tibble: 4 √ó 11\n  manufacturer model displ  year   cyl trans      drv     cty   hwy fl   \n  &lt;chr&gt;        &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;\n1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p    \n2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p    \n3 audi         a4      2    2008     4 manual(m6) f        20    31 p    \n4 audi         a4      2    2008     4 auto(av)   f        21    30 p    \n  class  \n  &lt;chr&gt;  \n1 compact\n2 compact\n3 compact\n4 compact"
  },
  {
    "objectID": "r/ws_demo_slides.html#the-canvas",
    "href": "r/ws_demo_slides.html#the-canvas",
    "title": "A little demo of programming in",
    "section": "The canvas",
    "text": "The canvas\n The first component is the data:\n\nggplot(data = mpg)"
  },
  {
    "objectID": "r/ws_demo_slides.html#the-canvas-1",
    "href": "r/ws_demo_slides.html#the-canvas-1",
    "title": "A little demo of programming in",
    "section": "The canvas",
    "text": "The canvas\nThe second component sets the way variables are mapped on the axes. This is done with the aes() (aesthetics) function:\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy))"
  },
  {
    "objectID": "r/ws_demo_slides.html#geometric-representations-of-the-data",
    "href": "r/ws_demo_slides.html#geometric-representations-of-the-data",
    "title": "A little demo of programming in",
    "section": "Geometric representations of the data",
    "text": "Geometric representations of the data\nOnto this canvas, we can add ‚Äúgeoms‚Äù (geometrical objects) representing the data.\nTo represent the data as a scatterplot, we use the geom_point() function:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point()"
  },
  {
    "objectID": "r/ws_demo_slides.html#colour-coding-based-on-variables",
    "href": "r/ws_demo_slides.html#colour-coding-based-on-variables",
    "title": "A little demo of programming in",
    "section": "Colour-coding based on variables",
    "text": "Colour-coding based on variables\nWe can colour-code the points in the scatterplot based on the drv variable, showing the lower fuel efficiency of 4WD vehicles:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv))"
  },
  {
    "objectID": "r/ws_demo_slides.html#colour-coding-based-on-variables-1",
    "href": "r/ws_demo_slides.html#colour-coding-based-on-variables-1",
    "title": "A little demo of programming in",
    "section": "Colour-coding based on variables",
    "text": "Colour-coding based on variables\nOr we can colour-code them based on the class variable:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class))"
  },
  {
    "objectID": "r/ws_demo_slides.html#multiple-geoms",
    "href": "r/ws_demo_slides.html#multiple-geoms",
    "title": "A little demo of programming in",
    "section": "Multiple geoms",
    "text": "Multiple geoms\nMultiple ‚Äúgeoms‚Äù can be added on top of each other. For instance, we can add a smoothed conditional means function that aids at seeing patterns in the data with geom_smooth():\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth()"
  },
  {
    "objectID": "r/ws_demo_slides.html#colour-scales",
    "href": "r/ws_demo_slides.html#colour-scales",
    "title": "A little demo of programming in",
    "section": "Colour scales",
    "text": "Colour scales"
  },
  {
    "objectID": "r/ws_demo_slides.html#ggplot-extensions",
    "href": "r/ws_demo_slides.html#ggplot-extensions",
    "title": "A little demo of programming in",
    "section": "ggplot extensions",
    "text": "ggplot extensions\nMany packages build on ggplot2 and add functionality"
  },
  {
    "objectID": "r/ws_demo_slides.html#combining-plots",
    "href": "r/ws_demo_slides.html#combining-plots",
    "title": "A little demo of programming in",
    "section": "Combining plots",
    "text": "Combining plots\nOne ggplot extension is the patchwork package which allows to combine multiple plots on the same frame"
  },
  {
    "objectID": "r/ws_demo_slides.html#html-and-css",
    "href": "r/ws_demo_slides.html#html-and-css",
    "title": "A little demo of programming in",
    "section": "HTML and CSS",
    "text": "HTML and CSS\nHyperText Markup Language (HTML) is the standard markup language for websites: it encodes the information related to the formatting and structure of webpages. Additionally, some of the customization can be stored in Cascading Style Sheets (CSS) files.\nHTML uses tags of the form:\n&lt;some_tag&gt;Your content&lt;/some_tag&gt;\nSome tags have attributes:\n&lt;some_tag attribute_name=\"attribute value\"&gt;Your content&lt;/some_tag&gt;\n\nExamples:\n\n\n&lt;h2&gt;This is a heading of level 2&lt;/h2&gt;\n&lt;b&gt;This is bold&lt;/b&gt;\n&lt;a href=\"https://some.url\"&gt;This is the text for a link&lt;/a&gt;"
  },
  {
    "objectID": "r/ws_demo_slides.html#example-for-this-workshop",
    "href": "r/ws_demo_slides.html#example-for-this-workshop",
    "title": "A little demo of programming in",
    "section": "Example for this workshop",
    "text": "Example for this workshop\nWe will use a website from the University of Tennessee containing a database of PhD theses from that university\nOur goal is to scrape data from this site to produce a dataframe with the date, major, and advisor for each dissertation\n\nWe will only do this for the first page which contains the links to the 100 most recent theses. If you really wanted to gather all the data, you would have to do this for all pages"
  },
  {
    "objectID": "r/ws_demo_slides.html#package",
    "href": "r/ws_demo_slides.html#package",
    "title": "A little demo of programming in",
    "section": "Package",
    "text": "Package\nTo do all this, we will use the package rvest, part of the tidyverse (a modern set of R packages). It is a package influenced by the popular Python package Beautiful Soup and it makes scraping websites with R really easy\nLet‚Äôs load it:\n\nlibrary(rvest)"
  },
  {
    "objectID": "r/ws_demo_slides.html#read-in-html-from-main-site",
    "href": "r/ws_demo_slides.html#read-in-html-from-main-site",
    "title": "A little demo of programming in",
    "section": "Read in HTML from main site",
    "text": "Read in HTML from main site\nAs mentioned above, our site is the database of PhD dissertations from the University of Tennessee\nLet‚Äôs create a character vector with the URL:\n\nurl &lt;- \"https://trace.tennessee.edu/utk_graddiss/index.html\"\n\nFirst, we read in the html data from that page:\n\nhtml &lt;- read_html(url)\n\nLet‚Äôs have a look at the raw data:\n\nhtml\n\n{html_document}\n&lt;html lang=\"en\"&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] &lt;body&gt;\\n&lt;!-- FILE /srv/sequoia/main/data/trace.tennessee.edu/assets/heade ..."
  },
  {
    "objectID": "r/ws_demo_slides.html#extract-all-urls",
    "href": "r/ws_demo_slides.html#extract-all-urls",
    "title": "A little demo of programming in",
    "section": "Extract all URLs",
    "text": "Extract all URLs\n\ndat &lt;- html %&gt;% html_elements(\".article-listing a\")\ndat[1:6]\n\n{xml_nodeset (6)}\n[1] &lt;a href=\"https://trace.tennessee.edu/utk_graddiss/12328\"&gt;Essays in Macroe ...\n[2] &lt;a href=\"https://trace.tennessee.edu/utk_graddiss/12671\"&gt;UNDERSTANDING AN ...\n[3] &lt;a href=\"https://trace.tennessee.edu/utk_graddiss/12672\"&gt;Soil Nitrous Oxi ...\n[4] &lt;a href=\"https://trace.tennessee.edu/utk_graddiss/12329\"&gt;CHARACTERIZATION ...\n[5] &lt;a href=\"https://trace.tennessee.edu/utk_graddiss/12330\"&gt;View from the To ...\n[6] &lt;a href=\"https://trace.tennessee.edu/utk_graddiss/12331\"&gt;Exploration of V ..."
  },
  {
    "objectID": "r/ws_demo_slides.html#extract-all-urls-1",
    "href": "r/ws_demo_slides.html#extract-all-urls-1",
    "title": "A little demo of programming in",
    "section": "Extract all URLs",
    "text": "Extract all URLs\nWe now have a list of lists\nBefore running for loops, it is important to initialize empty loops. It is much more efficient than growing the result at each iteration\nSo let‚Äôs initialize an empty list that we call list_urls of the appropriate size:\n\nlist_urls &lt;- vector(\"list\", length(dat))"
  },
  {
    "objectID": "r/ws_demo_slides.html#extract-all-urls-2",
    "href": "r/ws_demo_slides.html#extract-all-urls-2",
    "title": "A little demo of programming in",
    "section": "Extract all URLs",
    "text": "Extract all URLs\nNow we can run a loop to fill in our list:\n\nfor (i in seq_along(dat)) {\n  list_urls[[i]] &lt;- dat[[i]] %&gt;% html_attr(\"href\")\n}\n\nLet‚Äôs print again the first element of list_urls to make sure all looks good:\n\nlist_urls[[1]]\n\n[1] \"https://trace.tennessee.edu/utk_graddiss/12328\"\n\n\nWe now have a list of URLs (in the form of character vectors) as we wanted"
  },
  {
    "objectID": "r/ws_demo_slides.html#extract-data-from-each-page",
    "href": "r/ws_demo_slides.html#extract-data-from-each-page",
    "title": "A little demo of programming in",
    "section": "Extract data from each page",
    "text": "Extract data from each page\nWe will now extract the data (date, major, and advisor) for all URLs in our list.\nAgain, before running a for loop, we need to allocate memory first by creating an empty container (here a list):"
  },
  {
    "objectID": "r/ws_demo_slides.html#extract-data-from-each-page-1",
    "href": "r/ws_demo_slides.html#extract-data-from-each-page-1",
    "title": "A little demo of programming in",
    "section": "Extract data from each page",
    "text": "Extract data from each page\n\nlist_data &lt;- vector(\"list\", length(list_urls))\n\nfor (i in seq_along(list_urls)) {\n  html &lt;- read_html(list_urls[[i]])\n  date &lt;- html %&gt;%\n    html_element(\"#publication_date p\") %&gt;%\n    html_text2()\n  major &lt;- html %&gt;%\n    html_element(\"#department p\") %&gt;%\n    html_text2()\n  advisor &lt;- html %&gt;%\n    html_element(\"#advisor1 p\") %&gt;%\n    html_text2()\n  Sys.sleep(0.1)  # Add a little delay\n  list_data[[i]] &lt;- cbind(date, major, advisor)\n}"
  },
  {
    "objectID": "r/ws_demo_slides.html#store-results-in-dataframe",
    "href": "r/ws_demo_slides.html#store-results-in-dataframe",
    "title": "A little demo of programming in",
    "section": "Store results in DataFrame",
    "text": "Store results in DataFrame\nWe can turn this big list into a dataframe:\n\nresult &lt;- do.call(rbind.data.frame, list_data)\n\nWe can capitalize the headers:\n\nnames(result) &lt;- c(\"Date\", \"Major\", \"Advisor\")"
  },
  {
    "objectID": "r/ws_demo_slides.html#our-final-data",
    "href": "r/ws_demo_slides.html#our-final-data",
    "title": "A little demo of programming in",
    "section": "Our final data",
    "text": "Our final data\nresult is a long dataframe, so we will only print the first few elements:\n\nhead(result, 6)\n\n    Date                                           Major               Advisor\n1 5-2025                                       Economics     Andrew, S, Hanson\n2 8-2025                               Civil Engineering Nicholas E. Wierschem\n3 8-2025          Plant, Soil and Environmental Sciences         Debasish Saha\n4 5-2025 Biochemistry and Cellular and Molecular Biology              Jae Park\n5 5-2025                 Higher Education Administration       Pamella Angelle\n6 5-2025                                            &lt;NA&gt;        Andrea S. Lear"
  },
  {
    "objectID": "r/ws_demo_slides.html#save-results-to-file",
    "href": "r/ws_demo_slides.html#save-results-to-file",
    "title": "A little demo of programming in",
    "section": "Save results to file",
    "text": "Save results to file\nIf we wanted, we could save our data to a CSV file:\nwrite.csv(result, \"dissertations_data.csv\", row.names = FALSE)"
  },
  {
    "objectID": "r/ws_demo_slides.html#data-reading-and-manipulation",
    "href": "r/ws_demo_slides.html#data-reading-and-manipulation",
    "title": "A little demo of programming in",
    "section": "Data reading and manipulation",
    "text": "Data reading and manipulation\n\nSpatial vectors: great modern packages are sf or terra\nRaster data: the package terra\n\nI will skip the data preparation due to lack of time, but you can look at the code in this webinar or this workshop"
  },
  {
    "objectID": "r/ws_demo_slides.html#mapping-data",
    "href": "r/ws_demo_slides.html#mapping-data",
    "title": "A little demo of programming in",
    "section": "Mapping data",
    "text": "Mapping data\nGood options to create maps include ggplot2 (the package we already used for plotting) or tmap"
  },
  {
    "objectID": "r/ws_demo_slides.html#map-of-glaciers-in-western-north-america",
    "href": "r/ws_demo_slides.html#map-of-glaciers-in-western-north-america",
    "title": "A little demo of programming in",
    "section": "Map of glaciers in western North America",
    "text": "Map of glaciers in western North America\ntm_shape(states, bbox = nwa_bbox) +\n  tm_polygons(col = \"#f2f2f2\", lwd = 0.2) +\n  tm_shape(ak) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_shape(wes) +\n  tm_borders(col = \"#3399ff\") +\n  tm_fill(col = \"#86baff\") +\n  tm_layout(\n    title = \"Glaciers of Western North America\",\n    title.position = c(\"center\", \"top\"),\n    title.size = 1.1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.06, 0.01, 0.09, 0.01),\n    outer.margins = 0,\n    frame.lwd = 0.2\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    size = 1.2,\n    text.size = 0.6\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 1000, 2000),\n    position = c(\"right\", \"BOTTOM\")\n  )"
  },
  {
    "objectID": "r/ws_demo_slides.html#multi-layer-map-of-the-retreat-of-a-glacier",
    "href": "r/ws_demo_slides.html#multi-layer-map-of-the-retreat-of-a-glacier",
    "title": "A little demo of programming in",
    "section": "Multi-layer map of the retreat of a glacier",
    "text": "Multi-layer map of the retreat of a glacier\ntm_shape(ag) +\n  tm_polygons(\"year\", palette = \"Blues\") +\n  tm_layout(\n    title = \"Agassiz Glacier\",\n    title.position = c(\"center\", \"top\"),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.color = \"#fcfcfc\",\n    legend.text.size = 1,\n    bg.color = \"#fcfcfc\",\n    inner.margins = c(0.07, 0.03, 0.07, 0.03),\n    outer.margins = 0\n  ) +\n  tm_compass(\n    type = \"arrow\",\n    position = c(\"right\", \"top\"),\n    text.size = 0.7\n  ) +\n  tm_scale_bar(\n    breaks = c(0, 0.5, 1),\n    position = c(\"right\", \"BOTTOM\"),\n    text.size = 1\n  )"
  },
  {
    "objectID": "r/ws_demo_slides.html#animated-map-of-the-retreat-of-a-glacier",
    "href": "r/ws_demo_slides.html#animated-map-of-the-retreat-of-a-glacier",
    "title": "A little demo of programming in",
    "section": "Animated map of the retreat of a glacier",
    "text": "Animated map of the retreat of a glacier\ntmap_animation(tm_shape(ag) +\n                 tm_polygons(col = \"#86baff\") +\n                 tm_layout(\n                   title = \"Agassiz Glacier\",\n                   title.position = c(\"center\", \"top\"),\n                   legend.position = c(\"left\", \"bottom\"),\n                   legend.title.color = \"#fcfcfc\",\n                   legend.text.size = 1,\n                   bg.color = \"#fcfcfc\",\n                   inner.margins = c(0.08, 0, 0.08, 0),\n                   outer.margins = 0,\n                   panel.label.bg.color = \"#fcfcfc\"\n                 ) +\n                 tm_compass(\n                   type = \"arrow\",\n                   position = c(\"right\", \"top\"),\n                   text.size = 0.7\n                 ) +\n                 tm_scale_bar(\n                   breaks = c(0, 0.5, 1),\n                   position = c(\"right\", \"BOTTOM\"),\n                   text.size = 1\n                 ) +\n                 tm_facets(\n                   along = \"year\",\n                   free.coords = F\n                 )filename = \"ag.gif\",\n               dpi = 300,\n               inner.margins = c(0.08, 0, 0.08, 0),\n               delay = 100\n               )"
  },
  {
    "objectID": "r/ws_demo_slides.html#regular-r-training",
    "href": "r/ws_demo_slides.html#regular-r-training",
    "title": "A little demo of programming in",
    "section": "Regular R training",
    "text": "Regular R training\nEach region under the Alliance offers regular courses and workshops in R (and many other topics)\nIn the west, Alex Razoumov and myself offer regular free workshops, courses, and webinars for researchers in Canadian academic institutions\nYou can find our program here or join our mailing list here"
  },
  {
    "objectID": "r/ws_hss_intro.html",
    "href": "r/ws_hss_intro.html",
    "title": "Introduction to R for the humanities",
    "section": "",
    "text": "R is a free and open-source programming language for statistical computing, modelling, and graphics, with an unbeatable collection of statistical packages. It is extremely popular in some academic fields such as statistics, biology, bioinformatics, data mining, data analysis, and linguistics.\nThis introductory course does not assume any prior knowledge.",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro R for the humanities"
    ]
  },
  {
    "objectID": "r/ws_hss_intro.html#running-r",
    "href": "r/ws_hss_intro.html#running-r",
    "title": "Introduction to R for the humanities",
    "section": "Running R",
    "text": "Running R\nR being an interpreted language, it can be run non-interactively or interactively.\n\nRunning R non-interactively\nIf you write code in a text file (called a script), you can then execute it with:\nRscript my_script.R\n\nThe command to execute scripts is Rscript rather than R.\nBy convention, R scripts take the extension .R.\n\n\n\nRunning R interactively\nThere are several ways to run R interactively.\n\nDirectly in the console (the name for the R shell):\n\n\n\nIn Jupyter with the R kernel (IRkernel package).\nIn another IDE (e.g.¬†in Emacs with ESS).\nIn the RStudio IDE.\n\nThe RStudio IDE is popular and this is what we will use today. RStudio can can be run locally, but for this course, we will use an RStudio server.\n\n\nAccessing our RStudio server\nFor this workshop, we will use a temporary RStudio server.\nTo access it, go to the website given during the workshop and sign in using the username and password you will be given (you can ignore the OTP entry).\nThis will take you to our JupyterHub. There, click on the RStudio button and our RStudio server will open in a new tab.\n\n\nUsing RStudio\nFor those unfamiliar with the RStudio IDE, you can download the following cheatsheet:\n\n\n\nfrom Posit Cheatsheets",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro R for the humanities"
    ]
  },
  {
    "objectID": "r/ws_hss_intro.html#help-and-documentation",
    "href": "r/ws_hss_intro.html#help-and-documentation",
    "title": "Introduction to R for the humanities",
    "section": "Help and documentation",
    "text": "Help and documentation\nFor some general documentation on R, you can run:\nhelp.start()\nTo get help on a function (e.g.¬†sum), you can run:\nhelp(sum)\nDepending on your settings, this will open a documentation for sum in a pager or in your browser.",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro R for the humanities"
    ]
  },
  {
    "objectID": "r/ws_hss_intro.html#basic-syntax",
    "href": "r/ws_hss_intro.html#basic-syntax",
    "title": "Introduction to R for the humanities",
    "section": "Basic syntax",
    "text": "Basic syntax\n\nAssignment\nR can accept the equal sign (=) for assignments, but it is more idiomatic to use the assignment sign (&lt;-) whenever you bind a name to a value and to use the equal sign everywhere else.\n\na &lt;- 3\n\nOnce you have bound a name to a value, you can recall the value with that name:\n\na  # Note that you do not need to use a print() function in R\n\n[1] 3\n\n\nYou can remove an object from the environment by deleting its name:\n\nrm(a)\na\n\nError in eval(expr, envir, enclos): object 'a' not found\n\n\nThe garbage collector will take care of deleting the object itself from memory.\n\n\nComments\nAnything to the left of # is a comment and is ignored by R:\n\n# This is an inline comment\n\na &lt;- 3  # This is also a comment",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro R for the humanities"
    ]
  },
  {
    "objectID": "r/ws_hss_intro.html#data-types-and-structures",
    "href": "r/ws_hss_intro.html#data-types-and-structures",
    "title": "Introduction to R for the humanities",
    "section": "Data types and structures",
    "text": "Data types and structures\n\n\n\nDimension\nHomogeneous\nHeterogeneous\n\n\n\n\n1 d\nAtomic vector\nList\n\n\n2 d\nMatrix\nData frame\n\n\n3 d\nArray\n\n\n\n\n\nAtomic vectors\n\nvec &lt;- c(2, 4, 1)\nvec\n\n[1] 2 4 1\n\ntypeof(vec)\n\n[1] \"double\"\n\nstr(vec)\n\n num [1:3] 2 4 1\n\n\n\nvec &lt;- c(TRUE, TRUE, NA, FALSE)\nvec\n\n[1]  TRUE  TRUE    NA FALSE\n\ntypeof(vec)\n\n[1] \"logical\"\n\nstr(vec)\n\n logi [1:4] TRUE TRUE NA FALSE\n\n\n\nNA (‚ÄúNot Available‚Äù) is a logical constant of length one. It is an indicator for a missing value.\n\nVectors are homogeneous, so all elements need to be of the same type.\nIf you use elements of different types, R will convert some of them to ensure that they become of the same type:\n\nvec &lt;- c(\"This is a string\", 3, \"test\")\nvec\n\n[1] \"This is a string\" \"3\"                \"test\"            \n\ntypeof(vec)\n\n[1] \"character\"\n\nstr(vec)\n\n chr [1:3] \"This is a string\" \"3\" \"test\"\n\n\n\nvec &lt;- c(TRUE, 3, FALSE)\nvec\n\n[1] 1 3 0\n\ntypeof(vec)\n\n[1] \"double\"\n\nstr(vec)\n\n num [1:3] 1 3 0\n\n\n\n\nData frames\nData frames contain tabular data. Under the hood, a data frame is a list of vectors.\n\ndat &lt;- data.frame(\n  country = c(\"Canada\", \"USA\", \"Mexico\"),\n  var = c(2.9, 3.1, 4.5)\n)\ndat\n\n  country var\n1  Canada 2.9\n2     USA 3.1\n3  Mexico 4.5\n\ntypeof(dat)\n\n[1] \"list\"\n\nstr(dat)\n\n'data.frame':   3 obs. of  2 variables:\n $ country: chr  \"Canada\" \"USA\" \"Mexico\"\n $ var    : num  2.9 3.1 4.5\n\nlength(dat)\n\n[1] 2\n\ndim(dat)\n\n[1] 3 2",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro R for the humanities"
    ]
  },
  {
    "objectID": "r/ws_hss_intro.html#function-definition",
    "href": "r/ws_hss_intro.html#function-definition",
    "title": "Introduction to R for the humanities",
    "section": "Function definition",
    "text": "Function definition\n\ncompare &lt;- function(x, y) {\n  x == y\n}\n\nWe can now use our function:\n\ncompare(2, 3)\n\n[1] FALSE\n\n\nNote that the result of the last statement is printed automatically:\n\ntest &lt;- function(x, y) {\n  x\n  y\n}\ntest(2, 3)\n\n[1] 3\n\n\nIf you want to return other results, you need to explicitly use the print() function:\n\ntest &lt;- function(x, y) {\n  print(x)\n  y\n}\ntest(2, 3)\n\n[1] 2\n\n\n[1] 3",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro R for the humanities"
    ]
  },
  {
    "objectID": "r/ws_hss_intro.html#control-flow",
    "href": "r/ws_hss_intro.html#control-flow",
    "title": "Introduction to R for the humanities",
    "section": "Control flow",
    "text": "Control flow\n\nConditionals\n\ntest_sign &lt;- function(x) {\n  if (x &gt; 0) {\n    \"x is positif\"\n  } else if (x &lt; 0) {\n    \"x is negatif\"\n  } else {\n    \"x is equal to zero\"\n  }\n}\n\n\ntest_sign(3)\n\n[1] \"x is positif\"\n\ntest_sign(-2)\n\n[1] \"x is negatif\"\n\ntest_sign(0)\n\n[1] \"x is equal to zero\"\n\n\n\n\nLoops\n\nfor (i in 1:10) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n\n\nNotice that here we need to use the print() function.",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro R for the humanities"
    ]
  },
  {
    "objectID": "r/ws_hss_intro.html#packages",
    "href": "r/ws_hss_intro.html#packages",
    "title": "Introduction to R for the humanities",
    "section": "Packages",
    "text": "Packages\nPackages are a set of functions and/or data that add functionality to R.\n\nLooking for packages\n\nPackage finder\nYour peers and the literature\n\n\n\nPackage documentation\n\nList of CRAN packages\nPackage documentation\n\n\n\nManaging R packages\nR packages can be installed, updated, and removed from within R:\ninstall.packages(\"package-name\")\nremove.packages(\"package-name\")\nupdate_packages()\n\n\nLoading packages\nTo make a package available in an R session, you load it with the library() function.\n\nExample:\n\nlibrary(readxl)\nAlternatively, you can access a function from a package without loading it with the syntax: package::function().\n\nExample:\n\nreadxl::read_excel(\"file.xlsx\")",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro R for the humanities"
    ]
  },
  {
    "objectID": "r/ws_hss_intro.html#publishing",
    "href": "r/ws_hss_intro.html#publishing",
    "title": "Introduction to R for the humanities",
    "section": "Publishing",
    "text": "Publishing\nYou might have heard of R Markdown. It allows for the creation of dynamic publication-quality documents mixing code blocks, text, graphs‚Ä¶\nThe team which created R Markdown has now created an even better tool: Quarto. If you are interested in an introduction to this tool, you can have a look at our workshop or our webinar on Quarto.",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro R for the humanities"
    ]
  },
  {
    "objectID": "r/ws_hss_intro.html#resources",
    "href": "r/ws_hss_intro.html#resources",
    "title": "Introduction to R for the humanities",
    "section": "Resources",
    "text": "Resources\n\nAlliance wiki\n\nR page\n\n\n\nR main site\n\nDownload page\n\n\n\nRStudio\n\nPosit site (Posit is the brand new name of the RStudio company)\nPosit cheatsheets\n\n\n\nSoftware Carpentry\n\nData analysis using R in the digital humanities\n\n\n\nOnline book\n\nR for Data Science (heavily based on the tidyverse)",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro R for the humanities"
    ]
  },
  {
    "objectID": "r/ws_hss_intro.html#recording",
    "href": "r/ws_hss_intro.html#recording",
    "title": "Introduction to R for the humanities",
    "section": "Recording",
    "text": "Recording\n\nVideos of this workshop for the Digital Research Alliance of Canada HSS Winter Series 2023:\n\n\nFirst part\n\n\n\nSecond part",
    "crumbs": [
      "R",
      "<b><em>Workshops</em></b>",
      "Intro R for the humanities"
    ]
  },
  {
    "objectID": "talks/2023_driconnect.html",
    "href": "talks/2023_driconnect.html",
    "title": "The instruments for advanced research computing are here, but are researchers ready?",
    "section": "",
    "text": "Presented at DRI (Digital Research Infrastructure) Connect in Vancouver, BC, in June 2023.\n\nThe current times are exciting: we are witnessing a growth of computing power while the open source community is vigorously building impressive machine learning and scientific programming tools.\nThis boom of hardware and software assets cannot however translate into research if graduate students aren‚Äôt able to take advantage of it. Curricula often lack training pertinent to the use of such resources. Worse yet, in many fields faculties and PIs don‚Äôt have the necessary background to help their students with high-performance programming. The training team at Simon Fraser University Research Computing Group aims to fill this gap in the West on behalf of the Alliance and all Western Canadian universities.\nThis talk will present an overview of the training we provide, from introductory skill sets for researchers new to ARC and HPC to advanced topics in parallel programming.\n\nSlides \n\n Slides content for easier browsing.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "ARC instruments"
    ]
  },
  {
    "objectID": "talks/2023_driconnect_slides.html#topics",
    "href": "talks/2023_driconnect_slides.html#topics",
    "title": "The instruments for advanced research computing are here, but are researchers ready?",
    "section": "Topics",
    "text": "Topics\n\nUnix shell\nHPC\nVersion control with Git/DataLad\nScientific programming in R/Python/Julia\nParallel computing in R/Julia/Chapel\nDeep learning with PyTorch\nScientific visualization\nContainers/Alliance clouds/VMs\nWebscraping in R/Python\nGIS in R\nScientific publishing with Quarto"
  },
  {
    "objectID": "talks/2023_driconnect_slides.html#fast",
    "href": "talks/2023_driconnect_slides.html#fast",
    "title": "The instruments for advanced research computing are here, but are researchers ready?",
    "section": "Fast",
    "text": "Fast"
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_content.html",
    "href": "talks/2023_stafftostaff_quarto_content.html",
    "title": "Quarto as a great teaching tool",
    "section": "",
    "text": "Content from the talk slides for easier browsing.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Quarto as a teaching tool",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_content.html#markup-markdown",
    "href": "talks/2023_stafftostaff_quarto_content.html#markup-markdown",
    "title": "Quarto as a great teaching tool",
    "section": "Markup & markdown",
    "text": "Markup & markdown\n\nMarkup languages\n\nControl the formatting of text documents\nPowerful but the unrendered text is visually cluttered and hard to read\n\n\nExample: Tex‚Äîoften with macro package LaTeX‚Äîto create pdfs\n\n\\documentclass{article}\n\\title{My title}\n\\author{My name}\n\\usepackage{datetime}\n\\newdate{date}{24}{11}{2022}\n\\date{\\displaydate{date}}\n\\begin{document}\n \\maketitle\n \\section{First section}\n Some text in the first section.\n\\end{document}\n\nExample: HTML‚Äîoften with css/scss files‚Äîto create webpages\n\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en-US\"&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"utf-8\" /&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width\" /&gt;\n    &lt;title&gt;My title&lt;/title&gt;\n    &lt;address class=\"author\"&gt;My name&lt;/address&gt;\n    &lt;input type=\"date\" value=\"2022-11-24\" /&gt;\n  &lt;/head&gt;\n  &lt;h1&gt;First section&lt;/h1&gt;\n  &lt;body&gt;\n    Some text in the first section.\n  &lt;/body&gt;\n&lt;/html&gt;\n\n\nMarkdown\n\nRemoves the visual clutter and makes texts readable prior to rendering\nCreated in 2004\nBy now quasi-ubiquitous\nInitially created for webpages\nRaw HTML can be inserted when easy syntax falls short\n\n\nPandoc‚Äôs extended Markdown\nPandoc (free and open-source markup formats converter) supports an extended Markdown syntax with functionality for figures, tables, callout blocks, LaTeX equations, citations‚Ä¶\nRemains as readable as basic Markdown, but can be rendered in any format (pdf, books, entire websites, Word documents‚Ä¶)\n\nRemoves the visual clutter and makes texts readable prior to rendering\nCreated in 2004\nBy now quasi-ubiquitous\nInitially created for webpages\nRaw HTML can be inserted when easy syntax falls short\n\n\nPrevious example using Pandoc‚Äôs Markdown:\n\n---\ntitle: My title\nauthor: My name\n---\n# First section\nSome text in the first section.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Quarto as a teaching tool",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_content.html#literate-programming",
    "href": "talks/2023_stafftostaff_quarto_content.html#literate-programming",
    "title": "Quarto as a great teaching tool",
    "section": "Literate programming",
    "text": "Literate programming\nLiterate programming is a methodology that combines snippets of code and written text.\nFirst introduced in 1984, this approach to the creation of documents has truly exploded in popularity in recent years thanks to the development of new tools such as R Markdown and, later, Jupyter notebooks",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Quarto as a teaching tool",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_content.html#quarto",
    "href": "talks/2023_stafftostaff_quarto_content.html#quarto",
    "title": "Quarto as a great teaching tool",
    "section": "Quarto",
    "text": "Quarto\nWebsite\nRepo\nDocumentation index\n\nHow it works\nCode blocks are executed by Jupyter (Python or Julia) or knitr (R), then pandoc renders the document into any format\n\nJulia/Python:\n From Quarto documentation\n\n\nR:\n From Quarto documentation\nCode blocks are executed by Jupyter (Python or Julia) or knitr (R), then pandoc renders the document into any format\nCan be used from .qmd text files or directly from RStudio or Jupyter notebooks.\n\n\n\nSupported languages\nSyntax highlighting in pretty much any language\nExecutable code blocks in Python, R, Julia, Observable JS\nOutput formats\n- HTML\n- PDF\n- MS Word\n- OpenOffice\n- ePub\n- Revealjs\n- PowerPoint\n- Beamer\n- GitHub Markdown\n- CommonMark\n- Hugo\n- Docusaurus\n- Markua\n- MediaWiki\n- DokuWiki\n- ZimWiki\n- Jira Wiki\n- XWiki\n- JATS\n- Jupyter\n- ConTeXt\n- RTF\n- reST\n- AsciiDoc\n- Org-Mode\n- Muse\n- GNU\n- Groff\n\n\nDocument structure & syntax\n\nFront matter\nWritten in YAML\nSets the options for the document. Let‚Äôs see a few examples.\n\nCan be very basic:\n\n---\ntitle: \"My title\"\nauthor: \"My name\"\n---\nWritten in YAML\nSets the options for the document. Let‚Äôs see a few examples.\n\nOr more sophisticated:\n\n---\ntitle: \"Some title\"\nsubtitle: \"Some subtitle\"\ninstitute: \"Simon Fraser University\"\n---\n\n\nText\nWritten in Pandoc‚Äôs extended Markdown\n\n\nCode blocks\nSyntax highlighting only:\n{.language} code\nSyntax highlighting and code execution:\n```{language}\ncode\n```\nOptions can be added to individual blocks:\n```{language}\n#| option: value\n\ncode\n```\n\n\n\nRendering\nTwo commands:\nquarto render file.qmd    # Renders the document\nquarto preview file.qmd   # Displays a live preview",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Quarto as a teaching tool",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2023_stafftostaff_quarto_content.html#quarto-as-a-teaching-tool",
    "href": "talks/2023_stafftostaff_quarto_content.html#quarto-as-a-teaching-tool",
    "title": "Quarto as a great teaching tool",
    "section": "Quarto as a teaching tool",
    "text": "Quarto as a teaching tool\n\nGeneral considerations\n\nExtremely well documented\nSolid team behind the work\nFree and open source\nUses only well established and well tested tools\n\n\n\nWebpages/websites\n\nFast, easy, and clean\nSites work on screens of any size out of the box (uses Bootstrap 5)\nCan be customized with CSS/SCSS, but good out of the box\nCode blocks can have a little copy button\nSite/pages can be hosted anywhere easily\n\n\n\nAdvantages of code execution\n\nPeople can see the output without running the code\nForces to test every bit of code\nIf the code broke when giving an old workshop, prevents the embarrassment of discovering it in the middle of a live demo\nNo need for a complex system linking code scripts with teaching documents",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Quarto as a teaching tool",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2024_bccai.html",
    "href": "talks/2024_bccai.html",
    "title": "Big data in the agrotech industry",
    "section": "",
    "text": "Presented at the Agricultural Excellence Conference in Abbotsford, BC, in November 2024, in collaboration with Simon Fraser University‚Äôs Big Data Hub and BC Centre for Agritech Innovation.\n\n\nThis two-part workshop illustrates how big data is used in the agriculture sector, clarifies concepts, and provides the basis to communicate in the field.\nSession 1 demystifies big data and covers three case studies in the agrotech industry, while session 2 presents an overview of big data challenges and provides the tools necessary to communicate with consultants to find solutions.\n\nSession 1 (Click and wait: the presentation might take a few instants to load)\nSlides content for easier browsing. \nSession 2 (Click and wait: the presentation might take a few instants to load)\nSlides content for easier browsing.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Big data in agrotech industry"
    ]
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#simon-fraser-university",
    "href": "talks/2024_bccai_part1_slides.html#simon-fraser-university",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Simon Fraser University",
    "text": "Simon Fraser University\n\nSFU hosts the Cedar supercomputer‚Äîa cluster of 100,400 CPUs and 1,352 GPUs soon to be replaced by an even larger computer cluster"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#simon-fraser-university-1",
    "href": "talks/2024_bccai_part1_slides.html#simon-fraser-university-1",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Simon Fraser University",
    "text": "Simon Fraser University\nSFU also works with the Digital Research Alliance of Canada to offer researchers large amounts of computing power to solve challenging data and technology problems, as well as training to optimize their solutions"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#sfus-big-data-hub",
    "href": "talks/2024_bccai_part1_slides.html#sfus-big-data-hub",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "SFU‚Äôs Big Data Hub",
    "text": "SFU‚Äôs Big Data Hub\n\nSince 2016, Simon Fraser University‚Äôs Big Data Hub has been offering workshops, events, and consulting services to researchers and industry partners helping them remain at the top of the fast evolving data landscape"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#bc-centre-for-agritech-innovation",
    "href": "talks/2024_bccai_part1_slides.html#bc-centre-for-agritech-innovation",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "BC Centre for Agritech Innovation",
    "text": "BC Centre for Agritech Innovation\n\nSince 2022, SFU BCCAI has been helping small and medium enterprises in the farming industry to embrace technology driven solutions"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#bc-centre-for-agritech-innovation-1",
    "href": "talks/2024_bccai_part1_slides.html#bc-centre-for-agritech-innovation-1",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "BC Centre for Agritech Innovation",
    "text": "BC Centre for Agritech Innovation\n\n\n\n\n\n\n\n\n\n\nsupport\n\nAgritech projects\n\n\n\ntraining\n\nTraining & upscaling\n\n\n\n\nnetwork\n\nAgritech network"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#session-1",
    "href": "talks/2024_bccai_part1_slides.html#session-1",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Session 1",
    "text": "Session 1\n\n\n\nToday\n\nA (hopefully) friendly lecture to:\n\nDemystify big data\nDemonstrate the critical importance of big data in agriculture and farming"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#session-2",
    "href": "talks/2024_bccai_part1_slides.html#session-2",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Session 2",
    "text": "Session 2\n\n\n\nTomorrow at 11am in the Mount Baker Room\n\nAn interactive workshop to:\n\nBrainstorm on how big data can benefit your operation\nHelp you make the transition to smart farming"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#the-3-v-volume",
    "href": "talks/2024_bccai_part1_slides.html#the-3-v-volume",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "The 3 ‚ÄúV‚Äù: Volume",
    "text": "The 3 ‚ÄúV‚Äù: Volume\n\n\nBefore\nFarmers were taking measurements (e.g.¬†on soil moisture) manually creating low volumes of data"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#the-3-v-volume-1",
    "href": "talks/2024_bccai_part1_slides.html#the-3-v-volume-1",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "The 3 ‚ÄúV‚Äù: Volume",
    "text": "The 3 ‚ÄúV‚Äù: Volume\n\n\nBefore\nFarmers were taking measurements (e.g.¬†on soil moisture) manually creating low volumes of data\nNow\nInternet of Things (IoT) (e.g.¬†hundreds of soil moisture sensors) collects large volumes of data"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#the-3-v-variety",
    "href": "talks/2024_bccai_part1_slides.html#the-3-v-variety",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "The 3 ‚ÄúV‚Äù: Variety",
    "text": "The 3 ‚ÄúV‚Äù: Variety\n\n\nBefore\nThere was a limited set of data a producer could collect"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#the-3-v-variety-1",
    "href": "talks/2024_bccai_part1_slides.html#the-3-v-variety-1",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "The 3 ‚ÄúV‚Äù: Variety",
    "text": "The 3 ‚ÄúV‚Äù: Variety\n\n\nBefore\nThere was a limited set of data a producer could collect\nNow\nThere are so many different types of data (e.g.¬†satellite images, market data gathered from internet browsing‚Ä¶)"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#the-3-v-velocity",
    "href": "talks/2024_bccai_part1_slides.html#the-3-v-velocity",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "The 3 ‚ÄúV‚Äù: Velocity",
    "text": "The 3 ‚ÄúV‚Äù: Velocity\n\n\nBefore\nA farmer could only gather so much data, even with a lot of employees"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#the-3-v-velocity-1",
    "href": "talks/2024_bccai_part1_slides.html#the-3-v-velocity-1",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "The 3 ‚ÄúV‚Äù: Velocity",
    "text": "The 3 ‚ÄúV‚Äù: Velocity\n\n\nBefore\nA farmer could only gather so much data, even with a lot of employees\nNow\nData is generated in real time and accumulates at high speed"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#why-has-big-data-become-so-essential",
    "href": "talks/2024_bccai_part1_slides.html#why-has-big-data-become-so-essential",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Why has big data become so essential?",
    "text": "Why has big data become so essential?\nAll this data is key to the development of artificial intelligence (AI)\n\nso‚Ä¶\n\n\nWhat is AI?"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#ai",
    "href": "talks/2024_bccai_part1_slides.html#ai",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "AI",
    "text": "AI\nVery loosely, you can think of neural networks (the most powerful form of AI) as an attempt to create a computer model that mimics the brain\n\n\n\n\n\nBiological neurons\n\n\n\n\n\n\n\n\nNeural network"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#ai-1",
    "href": "talks/2024_bccai_part1_slides.html#ai-1",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "AI",
    "text": "AI\nIn traditional computing, a programmer writes code that gives a computer detailed instructions of what to do\nThese instructions are called a program\n\n\n\n\n \n\n Some action"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#ai-2",
    "href": "talks/2024_bccai_part1_slides.html#ai-2",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "AI",
    "text": "AI\n\n\nWith neural networks, instead of writing a program, a programmer writes a model, then feeds it lots of data and the model changes little by little over time\nThe model ‚Äúlearns‚Äù thanks to this data\n\n\n\nSimplilearn has a video explaining how neural networks work in 5 min"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#ai-3",
    "href": "talks/2024_bccai_part1_slides.html#ai-3",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "AI",
    "text": "AI\n\n\nThis learning is nothing magical: some numbers in the model get tweaked a tiny bit, with each new piece of data, to make the model a little bit better\n\n\n\n\n\n\nFrom xkcd.com"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#ai-4",
    "href": "talks/2024_bccai_part1_slides.html#ai-4",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "AI",
    "text": "AI\nBasically, we start with a model, train it with data, and we end up with a trained model that can be used as a traditional computer program\n\nThat trained model can be used to get predictions, generate art or speech, identify objects in images or spams in emails‚Ä¶\nThe only difference from traditional computing is that we don‚Äôt write the program ourselves. Instead, we write a starting point (the untrained model), then train it with A LOT of data and let it get better by itself"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#ai-5",
    "href": "talks/2024_bccai_part1_slides.html#ai-5",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "AI",
    "text": "AI\n\n\nTo get a very good model at the end‚Äîone that can write human language like ChatGPT or voice assistants for instance‚Äîyou really need A LOT OF DATA"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#ai-an-example",
    "href": "talks/2024_bccai_part1_slides.html#ai-an-example",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "AI: an example",
    "text": "AI: an example\nImagine that you want a program able to detect tomatoes in pictures\nThis could be very useful to get real time data on your upcoming crop so that you can plan adequately (hiring staff, setting price, looking for markets)\nFor humans, this is straightforward\nYet, this is impossible to achieve with traditional programming because there are too many factors (location of the tomatoes in the image, quality of the picture, colour of the tomatoes‚Ä¶)"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#ai-an-example-1",
    "href": "talks/2024_bccai_part1_slides.html#ai-an-example-1",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "AI: an example",
    "text": "AI: an example\n\n\nHowever, by feeding a very large number of images with and without tomatoes along with labels that give the number of tomatoes for each image to a neural network, we can train it to recognize tomatoes in images that it has never seen\nWith each pair of image/label (e.g.¬†‚ÄúPicture 34, label: 56 tomatoes‚Äù), the model gets better"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#ai-an-example-2",
    "href": "talks/2024_bccai_part1_slides.html#ai-an-example-2",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "AI: an example",
    "text": "AI: an example\n\n\nWe don‚Äôt write the program to do this. We write the starting model, then let it adjust by itself based on the data\nIt is a form of learning by experience, which is exactly what happens to us as we grow up. It is a form of programming that is much closer to how brains work than traditional programming\n\n\n\n\n\n\nLawal, M. O. (2021). Tomato detection based on modified YOLOv3 framework. Scientific Reports, 11(1), 1-11."
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#why-now",
    "href": "talks/2024_bccai_part1_slides.html#why-now",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Why now?",
    "text": "Why now?\nThe idea is not new, but it is only recently that we have had enough computing power, internet connectivity, and storage capacity to implement it"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#smart-farming",
    "href": "talks/2024_bccai_part1_slides.html#smart-farming",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Smart farming",
    "text": "Smart farming\n\n\nWe already talked about data collection thanks to the Internet of Things (e.g.¬†moisture sensors)"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#smart-farming-1",
    "href": "talks/2024_bccai_part1_slides.html#smart-farming-1",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Smart farming",
    "text": "Smart farming\n\n\nBut this goes much further as AI algorithms can be used for ‚Äúprecision agriculture‚Äù\n\n\n\n\nKarunathilake, E. M. B. M., Le, A. T., Heo, S., Chung, Y. S., & Mansoor, S. (2023). The path to smart farming: Innovations and opportunities in precision agriculture. Agriculture, 13(8), 1593."
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#smart-farming-2",
    "href": "talks/2024_bccai_part1_slides.html#smart-farming-2",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Smart farming",
    "text": "Smart farming\n\n\nMany AI tools are involved in improving all domains of agriculture, from irrigation management to supply chain and demand forecasting\nThe benefits are huge for both farmers (increased yields, reduced costs, better planning) and the environment (optimization of resources and pesticide use)\n\n\n\n\nKarunathilake, E. M. B. M., Le, A. T., Heo, S., Chung, Y. S., & Mansoor, S. (2023). The path to smart farming: Innovations and opportunities in precision agriculture. Agriculture, 13(8), 1593."
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#decision-making",
    "href": "talks/2024_bccai_part1_slides.html#decision-making",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Decision making",
    "text": "Decision making\n\n\nBefore\nFarmers had to make decisions as best they could based on their experience and their limited data"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#decision-making-1",
    "href": "talks/2024_bccai_part1_slides.html#decision-making-1",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Decision making",
    "text": "Decision making\n\n\nBefore\nFarmers had to take decisions as best they could based on their experience and their limited data\nNow\nFarmers can use powerful models to make informed decision in real time. This can be followed by the automation of some action (e.g.¬†watering)"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#livestock-monitoring",
    "href": "talks/2024_bccai_part1_slides.html#livestock-monitoring",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Livestock monitoring",
    "text": "Livestock monitoring\n\n\nA case study\nLivestock successfully monitored remotely via sound sensors and algorithms for background noise filtering\nAnimal welfare and efficiency improvements\n\n\n\n\n\n\nJung, D. H., Kim, N. Y., Moon, S. H., Jhin, C., Kim, H. J., Yang, J. S., ‚Ä¶ & Park, S. H. (2021). Deep learning-based cattle vocal classification model and real-time livestock monitoring system with noise filtering. Animals, 11(2), 357."
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#market-analysis-and-supply-chain-optimization",
    "href": "talks/2024_bccai_part1_slides.html#market-analysis-and-supply-chain-optimization",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Market analysis and supply chain optimization",
    "text": "Market analysis and supply chain optimization\nA review\n\n\nSystematic literature review of peer-reviewed articles and conference papers published between 2014 and 20241 showed large improvements of demand forecasting accuracy and supply chain optimization\nReal time data analysis helped with predictive maintenance, market volatility, resource constraints, and climate variability\n\n\n\n\n\nElufioye, O. A., Ike, C. U., Odeyemi, O., Usman, F. O., & Mhlongo, N. Z. (2024). Ai-Driven predictive analytics in agricultural supply chains: a review: assessing the benefits and challenges of ai in forecasting demand and optimizing supply in agriculture. Computer Science & IT Research Journal, 5(2), 473-497."
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#challenges",
    "href": "talks/2024_bccai_part1_slides.html#challenges",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Challenges",
    "text": "Challenges\nThere are challenges to the implementation of such transformative methods\n\nInfrastructure development\nSkill gaps among agricultural professionals\n\n\nWe are here to help!\n\n\n\n\n\n\n\n\n\n\nCome to session 2 tomorrow!"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#session-2-1",
    "href": "talks/2024_bccai_part1_slides.html#session-2-1",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Session 2",
    "text": "Session 2\nJoin us tomorrow at 11am in the Mount Baker Room for our 2nd session:\n\nDiagnosing and implementing big data solutions\n\nWe will have an interactive workshop to:\n\nBrainstorm on how big data can benefit your operation\nHelp you make the transition to smart farming\n\n\n\nIf you are unable to attend, you can find the slides here, but it will be an interactive clinic with most of the material covered in the activity"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#getting-in-touch",
    "href": "talks/2024_bccai_part1_slides.html#getting-in-touch",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Getting in touch",
    "text": "Getting in touch\n\nSFU‚Äôs Big Data Hub\nWebsite\nContact us\nConsultation services\nPartnerships\n\nBCCAI\nWebsite\nContact us\nAgritech development program\nTraining"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#understanding-neural-networks",
    "href": "talks/2024_bccai_part1_slides.html#understanding-neural-networks",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Understanding neural networks",
    "text": "Understanding neural networks\nTo go a bit further than the video mentioned earlier, 3Blue1Brown by Grant Sanderson has a series of 4 videos on neural networks which is easy to watch, fun, and does an excellent job at introducing the functioning of a simple neural network"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#literature",
    "href": "talks/2024_bccai_part1_slides.html#literature",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Literature",
    "text": "Literature\nOpen-access preprints:\nArxiv Sanity Preserver by Andrej Karpathy\nML papers in the computer science category on arXiv\nML papers in the stats category on arXiv\nDistill ML research online journal"
  },
  {
    "objectID": "talks/2024_bccai_part1_slides.html#acknowledgements",
    "href": "talks/2024_bccai_part1_slides.html#acknowledgements",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Acknowledgements",
    "text": "Acknowledgements\n\n\n\n\n\n\n\n Carson Li (BCCAI) suggested an outline for this talk\n Ian Chan (BCCAI) provided copious feedback"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#simon-fraser-university",
    "href": "talks/2024_bccai_part2_slides.html#simon-fraser-university",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Simon Fraser University",
    "text": "Simon Fraser University\n\nSFU hosts the Cedar supercomputer‚Äîa cluster of 100,400 CPUs and 1,352 GPUs soon to be replaced by an even larger computer cluster"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#simon-fraser-university-1",
    "href": "talks/2024_bccai_part2_slides.html#simon-fraser-university-1",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Simon Fraser University",
    "text": "Simon Fraser University\nSFU also works with the Digital Research Alliance of Canada to offer researchers large amounts of computing power to solve challenging data and technology problems, as well as training to optimize their solutions"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#sfus-big-data-hub",
    "href": "talks/2024_bccai_part2_slides.html#sfus-big-data-hub",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "SFU‚Äôs Big Data Hub",
    "text": "SFU‚Äôs Big Data Hub\n\nSince 2016, Simon Fraser University‚Äôs Big Data Hub has been offering workshops, events, and consulting services to researchers and industry partners helping them remain at the top of the fast evolving data landscape"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#bc-centre-for-agritech-innovation",
    "href": "talks/2024_bccai_part2_slides.html#bc-centre-for-agritech-innovation",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "BC Centre for Agritech Innovation",
    "text": "BC Centre for Agritech Innovation\n\nSince 2022, SFU BCCAI has been helping small and medium enterprises in the farming industry to embrace technology driven solutions"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#bc-centre-for-agritech-innovation-1",
    "href": "talks/2024_bccai_part2_slides.html#bc-centre-for-agritech-innovation-1",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "BC Centre for Agritech Innovation",
    "text": "BC Centre for Agritech Innovation\n\n\n\n\n\n\n\n\n\n\nsupport\n\nAgritech projects\n\n\n\ntraining\n\nTraining & upscaling\n\n\n\n\nnetwork\n\nAgritech network"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#session-1",
    "href": "talks/2024_bccai_part2_slides.html#session-1",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Session 1",
    "text": "Session 1\n\n\n\nYesterday\n\nA (hopefully) friendly lecture to:\n\nDemystify big data\nDemonstrate the critical importance of big data in agriculture and farming\n\n\nIf you missed the session, you can find the slides here"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#session-1-recap",
    "href": "talks/2024_bccai_part2_slides.html#session-1-recap",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Session 1 recap",
    "text": "Session 1 recap\n\n\nBig data is defined by the 3 ‚ÄúV‚Äù:\n\nVolume (lots of data is generated)\nVariety (images, sounds, text‚Ä¶)\nVelocity (generated continuously)"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#session-1-recap-1",
    "href": "talks/2024_bccai_part2_slides.html#session-1-recap-1",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Session 1 recap",
    "text": "Session 1 recap\nBig data has become crucial because it allows to train artificial intelligence models"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#session-1-recap-2",
    "href": "talks/2024_bccai_part2_slides.html#session-1-recap-2",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Session 1 recap",
    "text": "Session 1 recap\n\n\nOnce trained, those models are extremely powerful and capable of performing tasks impossible for traditional computer programs\n(e.g.¬†creating art, generating human text, chat bots, excellent forecasting and optimization, computer vision, self-driving cars‚Ä¶)"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#session-1-recap-3",
    "href": "talks/2024_bccai_part2_slides.html#session-1-recap-3",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Session 1 recap",
    "text": "Session 1 recap\n\n\nBig data and AI are transforming all sectors, including agriculture because they allow:\n\nReal time monitoring\nBetter decision making\nOptimizations\nAutomation of tasks"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#session-1-recap-4",
    "href": "talks/2024_bccai_part2_slides.html#session-1-recap-4",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Session 1 recap",
    "text": "Session 1 recap\nHowever there are challenges to the implementation of such transformative methods\n\nInfrastructure development\nSkill gaps among agricultural professionals\n\n\nWe are here to help\nThis is the goal of today‚Äôs session"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#session-2",
    "href": "talks/2024_bccai_part2_slides.html#session-2",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Session 2",
    "text": "Session 2\n\n\n\nToday\n\nAn interactive workshop to:\n\nBrainstorm on how big data can benefit your operation\nHelp you make the transition to smart farming"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#data-management",
    "href": "talks/2024_bccai_part2_slides.html#data-management",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Data management",
    "text": "Data management\n\n\nFirst, let‚Äôs focus on your data\nI will ask you to think about:\n\nThe data you use for your operation\nHow you are collecting it and storing it\nHow you could automate this"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#analytics",
    "href": "talks/2024_bccai_part2_slides.html#analytics",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Analytics",
    "text": "Analytics\n\n\nNow, let‚Äôs think about what this data is actually used for:\n\nWhat is purpose of this data?\nHow do you analyse it?\nWhat could be the benefits of using AI to process your data?"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#challenges",
    "href": "talks/2024_bccai_part2_slides.html#challenges",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Challenges",
    "text": "Challenges\n\n\nWhat are the challenges of such an implementation\n\nat the financial level\nat the practical level\ndue to knowledge gaps\n\n\n\n\n\nFrom xkcd.com"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#who-to-turn-to",
    "href": "talks/2024_bccai_part2_slides.html#who-to-turn-to",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Who to turn to?",
    "text": "Who to turn to?\n\nConnecting with other operators can be extremely powerful in this transformation\n\n\nYou may also need to talk with researchers\n\n\nYou will need to find a technology provider\n\n\nHere my colleagues from the Big Data Hub and the BCCAI will jump in to orientate you\n\nSFU‚Äôs Big Data Hub\nWebsite\nContact us\nConsultation services\nPartnerships\n\nBC Center for Agriculture Innovation\nWebsite\nContact us\nAgritech development program\nTraining"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#communication-with-experts",
    "href": "talks/2024_bccai_part2_slides.html#communication-with-experts",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Communication with experts",
    "text": "Communication with experts\n\n\nYou need basic concepts and vocabulary to communicate your needs to technology providers and researchers\n\nWhat concept do you feel that you are lacking and that we should cover?\nVocabulary clarification\n\n\n\n\n\n\n\nFrom xkcd.com"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#understanding-neural-networks",
    "href": "talks/2024_bccai_part2_slides.html#understanding-neural-networks",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Understanding neural networks",
    "text": "Understanding neural networks\n3Blue1Brown by Grant Sanderson has a series of 4 videos on neural networks which is easy to watch, fun, and does an excellent job at introducing the functioning of a simple neural network"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#literature",
    "href": "talks/2024_bccai_part2_slides.html#literature",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Literature",
    "text": "Literature\nOpen-access preprints:\nArxiv Sanity Preserver by Andrej Karpathy\nML papers in the computer science category on arXiv\nML papers in the stats category on arXiv\nDistill ML research online journal"
  },
  {
    "objectID": "talks/2024_bccai_part2_slides.html#acknowledgements",
    "href": "talks/2024_bccai_part2_slides.html#acknowledgements",
    "title": "Harnessing big datafor agricultural excellence",
    "section": "Acknowledgements",
    "text": "Acknowledgements\n\n\n\n\n\n\n\n Carson Li (BCCAI) suggested an outline for this talk\n Ian Chan (BCCAI) provided copious feedback"
  },
  {
    "objectID": "talks/2025_dhsi_content.html",
    "href": "talks/2025_dhsi_content.html",
    "title": "Coding fundamentals for humanists",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Python for the humanities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2025_dhsi_content.html#the-course",
    "href": "talks/2025_dhsi_content.html#the-course",
    "title": "Coding fundamentals for humanists",
    "section": "The course",
    "text": "The course\n\nWebsite (https://dhsi-2025.netlify.app/)\n\n\n\n\nOverview\n\nCore concepts of programming languages\nIntro to Python and JupyterLab\nBasics of Python\nUsing LLMs to write code\nAPI querying in Python\nWebscraping with Python and LLMs\nYour turn: get data from a website via an API or scraping\nPresentations: share your results, problems encountered, and what you learnt",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Python for the humanities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2025_dhsi_content.html#new-this-year",
    "href": "talks/2025_dhsi_content.html#new-this-year",
    "title": "Coding fundamentals for humanists",
    "section": "New this year",
    "text": "New this year\n\nPre-written Jupyter notebooks to fill\n\nExample of notebook given to students:\n\n\n\nExample of completed notebook:\n\n\n\n\nUse of LLMs to teach Python\nIt allowed students:\n\nto be much more independent,\nnot to get frustrated over small road-blocks,\nto go much further than in previous years,\nto keep learning on their own,\nto now be able to apply Python to their research\n\nOn our end, we learnt how to better use LLMs to teach",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Python for the humanities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2025_dhsi_content.html#samples-of-students-results",
    "href": "talks/2025_dhsi_content.html#samples-of-students-results",
    "title": "Coding fundamentals for humanists",
    "section": "Samples of students results",
    "text": "Samples of students results\n\nReddit data\n\n\nExported as a Python list:\n\n\n\n\nExported as a Python polars data frame:\n\n\n\n\n\nNumbers of published books\n\n\n\n\n\n\n\n\n\n\n\nSpotify playlist\n\n\n\nThe Guardian archives",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Python for the humanities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2025_dhsi_content.html#thanks-to-all-dhsi-organizers",
    "href": "talks/2025_dhsi_content.html#thanks-to-all-dhsi-organizers",
    "title": "Coding fundamentals for humanists",
    "section": "Thanks to all DHSI organizers!",
    "text": "Thanks to all DHSI organizers!",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Python for the humanities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2025_driconnect.html",
    "href": "talks/2025_driconnect.html",
    "title": "Communication to the research community",
    "section": "",
    "text": "Presented at DRI (Digital Research Infrastructure) Connect in Montreal, QC, in May 2025.\n\nThe Digital Research Alliance of Canada has two equally important audiences: stake holders and researchers.\nStake holders because without money nothing can be done.\nResearchers because without them what‚Äôs the point?\nThe communication to stake holders is mature, well established and polished: a beautiful website, a good newsletter. The communication to the research community however could be improved: links to important resources such as the Alliance wiki and computing training events are lacking or buried and hard to find on both the website and the newsletter. The upcoming launch of a training discovery platform will help, but not fully solve, these gaps.\nI suggest that members of the National Training Coordination Council, Alliance staff, and anybody interested in this topic gather to discuss this question in a respectful and open-minded way. If we work together, we should be able to improve the research-facing side of the Alliance and communicate our technical services more effectively to the research community.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "On communication"
    ]
  },
  {
    "objectID": "talks/2025_driconnect_slides.html#topics",
    "href": "talks/2025_driconnect_slides.html#topics",
    "title": "Communication to the research community",
    "section": "Topics",
    "text": "Topics\nAlliance website\nAlliance newsletter\nTraining emails"
  },
  {
    "objectID": "talks/2025_driconnect_slides.html#buttons-on-the-front-page-leading-to-2-sub-websites",
    "href": "talks/2025_driconnect_slides.html#buttons-on-the-front-page-leading-to-2-sub-websites",
    "title": "Communication to the research community",
    "section": "2 buttons on the front page leading to 2 sub-websites",
    "text": "2 buttons on the front page leading to 2 sub-websites\n\n\nStakeholders, click here\n\n\n\nResearchers, click here\n\n\n\n‚Ü™ Current site\n\n\n\n‚Ü™ Site with practical info for researchers:\n\nStatus of clusters\nLink to wiki\nHow to open tickets\nLink to training platform\nAnnouncements of upcoming training"
  },
  {
    "objectID": "talks/2025_driconnect_slides.html#buttons-on-the-front-page-leading-to-2-sub-websites-1",
    "href": "talks/2025_driconnect_slides.html#buttons-on-the-front-page-leading-to-2-sub-websites-1",
    "title": "Communication to the research community",
    "section": "2 buttons on the front page leading to 2 sub-websites",
    "text": "2 buttons on the front page leading to 2 sub-websites\n My arguments:\nIt would make the information researchers need easy to find\n2 distinct audiences with different expectations vis-√†-vis the Alliance ¬†‚û° ¬†2 sub-websites"
  },
  {
    "objectID": "talks/2025_driconnect_slides.html#buttons-on-the-front-page-leading-to-2-sub-websites-2",
    "href": "talks/2025_driconnect_slides.html#buttons-on-the-front-page-leading-to-2-sub-websites-2",
    "title": "Communication to the research community",
    "section": "2 buttons on the front page leading to 2 sub-websites",
    "text": "2 buttons on the front page leading to 2 sub-websites\n\nDo you find this idea worthwhile?\nAre there reasons not to implement something along those lines?\nWho would be a good contact to pursue this idea?\nCould we make plans?"
  },
  {
    "objectID": "talks/2025_driconnect_slides.html#different-newsletters-for-2-different-audiences",
    "href": "talks/2025_driconnect_slides.html#different-newsletters-for-2-different-audiences",
    "title": "Communication to the research community",
    "section": "2 different newsletters for 2 different audiences",
    "text": "2 different newsletters for 2 different audiences\n\n\nStakeholders‚Äô newsletter\nCurrent content\n(minus recent additions about training)\n\n\n\nResearchers‚Äô newsletter\n\nStatus of clusters\nLink to wiki\nHow to open tickets\nLink to training platform\nAnnouncements of upcoming training"
  },
  {
    "objectID": "talks/2025_driconnect_slides.html#different-newsletters-for-2-different-audiences-1",
    "href": "talks/2025_driconnect_slides.html#different-newsletters-for-2-different-audiences-1",
    "title": "Communication to the research community",
    "section": "2 different newsletters for 2 different audiences",
    "text": "2 different newsletters for 2 different audiences\n My argument: same thing!\nStake holders want to see that the Alliance is great, productive, and involved in transformative computing\nResearchers want practical information that can be useful to them"
  },
  {
    "objectID": "talks/2025_driconnect_slides.html#different-newsletters-for-2-different-audiences-2",
    "href": "talks/2025_driconnect_slides.html#different-newsletters-for-2-different-audiences-2",
    "title": "Communication to the research community",
    "section": "2 different newsletters for 2 different audiences",
    "text": "2 different newsletters for 2 different audiences\n\nDo you find this idea worthwhile?\nAre there reasons not to implement something along those lines?\nWho would be a good contact to pursue this idea?\nCould we make plans?"
  },
  {
    "objectID": "talks/2025_driconnect_slides.html#the-problem",
    "href": "talks/2025_driconnect_slides.html#the-problem",
    "title": "Communication to the research community",
    "section": "The problem",
    "text": "The problem\n\nMost researchers do not know about the services that we are offering\nWe do not have ways to reach out to them to inform them\n\nExplora is here and will help a lot! ü•≥\nBut it won‚Äôt solve everything:\n\nUsers will need to be informed and reminded that Explora exists\nSome users might prefer to get emails about upcoming training events"
  },
  {
    "objectID": "talks/2025_driconnect_slides.html#mailing-list-access",
    "href": "talks/2025_driconnect_slides.html#mailing-list-access",
    "title": "Communication to the research community",
    "section": "Mailing list access",
    "text": "Mailing list access\nWe teach and help all Canadian academic researchers‚Äînot just Alliance clusters users\nThey are however our main target audience\nBeing allowed to email CCDB users to inform them of our services (with option to opt-out) would be a great solution"
  },
  {
    "objectID": "talks/2025_driconnect_slides.html#ethics",
    "href": "talks/2025_driconnect_slides.html#ethics",
    "title": "Communication to the research community",
    "section": "Ethics",
    "text": "Ethics\nResponsible management is of course paramount and we would:\n\nstrictly respect opt-out requests\nstore data securely\nrespect privacy\nabide by anti-spamming laws"
  },
  {
    "objectID": "talks/2025_driconnect_slides.html#alternative-solution",
    "href": "talks/2025_driconnect_slides.html#alternative-solution",
    "title": "Communication to the research community",
    "section": "Alternative solution",
    "text": "Alternative solution\nAn alternative solution would be for an Alliance personnel to send emails on our behalf to advertise our events\nThis seems impractical and add to the work load of the Alliance but remains an option"
  },
  {
    "objectID": "talks/2025_driconnect_slides.html#thoughts-and-discussion",
    "href": "talks/2025_driconnect_slides.html#thoughts-and-discussion",
    "title": "Communication to the research community",
    "section": "Thoughts and discussion",
    "text": "Thoughts and discussion\nAre the concerns around allowing us to use CCDB emails about:\n\nprivacy?\ndata safety?\nspamming laws?\nother?\nIs there anything we could do to alleviate these concerns?\nWho would be a good contact to pursue this conversation?"
  },
  {
    "objectID": "talks/2025_teaching_with_llm_content.html",
    "href": "talks/2025_teaching_with_llm_content.html",
    "title": "Teaching programming with LLMs",
    "section": "",
    "text": "Content from the talk slides for easier browsing.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Teaching coding with LLMs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2025_teaching_with_llm_content.html#rationale",
    "href": "talks/2025_teaching_with_llm_content.html#rationale",
    "title": "Teaching programming with LLMs",
    "section": "Rationale",
    "text": "Rationale\n\nOne week is too little to teach Python to beginners:\n\nUsing LLMs is the only realistic way to bring them to a place where they can apply knowledge to their research.\nStudents get frustrated by failures:\n\nThey want to make progress on something meaningful. Spending hours debugging error messages about some obscure detail of their code makes them angry and discouraged.\nLLMs seemed like the perfect answer for this audience:\n\nThis is definitely the future. LLMs can take care of the nitty gritty aspects of the code for them while they focus on the higher level they are interested in.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Teaching coding with LLMs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2025_teaching_with_llm_content.html#how-i-went-about-it",
    "href": "talks/2025_teaching_with_llm_content.html#how-i-went-about-it",
    "title": "Teaching programming with LLMs",
    "section": "How I went about it",
    "text": "How I went about it\n\nCourse intro\nThe course started the same way as the traditional course:\n\nHigh-level intro to programming\nHow to choose a language (FOSS vs proprietary, compiled vs interpreted, etc.)\nHigh-level intro to Python\nTools needed for programming (text editor, IDE, etc.)\nIntro to Python shell, IPython, Jupyter, scripts\nIntro to general concepts (packages, syntax, data types, variables, functions, etc.)\n\n\n\nIntro to LLMs\n\n\n\n\nFirst play with text\n\n\n\nTraditional approach (e.g.¬†2024)\n\n\n\n\nLLM experiment (2025)\n\n\n\n\n\n\n\nWeb scraping\n\n\n\nTraditional approach (e.g.¬†2024)\n\n\n\n\nLLM experiment (2025)",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Teaching coding with LLMs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2025_teaching_with_llm_content.html#reflections-on-the-experiment",
    "href": "talks/2025_teaching_with_llm_content.html#reflections-on-the-experiment",
    "title": "Teaching programming with LLMs",
    "section": "Reflections on the experiment",
    "text": "Reflections on the experiment\n\nSociety is changing fast\n\n2024\nAll I could hear at DHSI was opposition to AI:\n\nIssues with copyright (valid point!).\nArtists having their work stolen.\nAI being bad and wrong and evil and to be avoided at all cost.\n\n\n\n2025\nI came prepared to convince them that, despite the (absolutely real) downsides, they have to learn to use LLMs if they don‚Äôt want to fall behind and be at a disadvantage.\nWhat I found ‚Ä¶\nEverybody was way more comfortable than I was using LLMs. Everybody had a subscription. (And everybody was perplexed by my reassuring lecture on the usefulness of LLMs ‚Ä¶).\nOne year is a very long time at the moment.\nI was aware that we need to keep up with\n\nthe technology (that‚Äôs feasible),\nthe regulations (easy for now!).\n\nBut I hadn‚Äôt anticipated that we also need to keep up with societal change.\n\n\n\nWhat did they think?\nExit surveys had several positive comments about the use of LLMs.\nOne attendee pointed out however that they don‚Äôt need us to use an LLM and that there was no point going to a course if that is what we were doing (good point‚Ä¶).\n\n\nWill I do it again?\nNo.\nIt is too messy in the context of a classroom: everybody goes down their own rabbit hole with their own LLM. LLMs are amazing private tutors but their non-deterministic nature makes them impossible to use in the way I envisaged.\nThe only way not to have it feel like I am herding squirrels is if I am the only one using an LLM while they passively watch.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Teaching coding with LLMs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/2025_teaching_with_llm_content.html#what-now",
    "href": "talks/2025_teaching_with_llm_content.html#what-now",
    "title": "Teaching programming with LLMs",
    "section": "What now?",
    "text": "What now?\nTeaching them to use LLMs is silly: they know!\nBut now LLMs can teach them everything we can.\nSo then the question becomes ‚Ä¶\n\nHave we become irrelevant?\n\n\n\nMaybe not yet.\nOne attendee had fantastic suggestions in their feedback form. We could:\n\nCurate a dataset.\nHave them do a more structured and simpler project in this artificially created world.\n\n\n\n\n\n\n\n\n\nWe need to start teaching differently\n\n\n\nWe need to go beyond simple teaching if we want to remain relevant.\nOrganizing a course experience that goes beyond knowledge delivery could be an answer.\n(There is more than a hint of unconvinced wishful thinking in all this though ‚Ä¶).\n\n\n\n\n\n\nLLMs can help us be better instructors. See for instance:\n\n\n\nfrom https://www.nature.com/articles/s41539-025-00300-x\n\n\n\n\nConclusions\nIt is probably best to leave LLMs out of the classroom, but we need to realize that all students are using them (probably more than us).\nSo as not to become irrelevant, we need to adapt and offer fancy interactive curated courses, not just content delivery. LLMs can help us with that since they can create synthetic datasets, come up with exercises, give us ideas, provide feedback, etc.\n\n\nEpilogue\nAnd then came Gemini 3 and Claude Opus 4.5 ‚Ä¶",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Teaching coding with LLMs",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "talks/dhsi.html",
    "href": "talks/dhsi.html",
    "title": "Coding fundamentals for humanists",
    "section": "",
    "text": "This presentation gives an overview of the course Coding fundamentals for humanists offered at Digital Humanities Summer Institute (DHSI) every year.\nThe course covers core concepts of programming languages, an introduction to JupyterLab, the basics of Python, API querying, and web scraping. The format is a combination of lectures, hands-on exercises, guidance on how to use large language models (LLMs) for coding, and projects relevant to the attendees‚Äô academic research.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "<br>&nbsp;<em><b>Conference talks</b></em><br><br>",
      "Coding fundamentals"
    ]
  },
  {
    "objectID": "talks/dhsi_slides.html#goal",
    "href": "talks/dhsi_slides.html#goal",
    "title": "Coding fundamentals for humanists",
    "section": "Goal",
    "text": "Goal\n\n\n\n\nDemystify coding\n\n\n\n\nGive you confidence\n\n\n\n\n\nExplain foundational concepts\n\n\n\n\nGive you tools for your research"
  },
  {
    "objectID": "talks/dhsi_slides.html#who-should-attend",
    "href": "talks/dhsi_slides.html#who-should-attend",
    "title": "Coding fundamentals for humanists",
    "section": "Who should attend?",
    "text": "Who should attend?\nAnyone without any coding experience who would like to use coding for their research or who is interested in understanding what coding is and how it works\nThis course is particularly useful as a prerequisite to other DHSI courses using Python"
  },
  {
    "objectID": "talks/dhsi_slides.html#overview",
    "href": "talks/dhsi_slides.html#overview",
    "title": "Coding fundamentals for humanists",
    "section": "Overview",
    "text": "Overview\n\n\n\n\nCore concepts of programming languages\n\n\n\n\nIntroduction to JupyterLab\n\n\n\n\nBasics of Python\n\n\n\n\nUsing LLMs to write code\n\n\n\n\n\n\n\nAPI querying in Python\n\n\n\n\nWeb scraping with Python\n\n\n\n\nYour turn: get data from a website\n\n\n\n\nPresentations: share what you learnt"
  },
  {
    "objectID": "talks/dhsi_slides.html#website",
    "href": "talks/dhsi_slides.html#website",
    "title": "Coding fundamentals for humanists",
    "section": "Website",
    "text": "Website\n\n\n Each year we build a website\nEasier for attendees to follow along, copy code snippets, etc.\nThe sites never get taken down so attendees can rely on them to find information later on"
  },
  {
    "objectID": "talks/dhsi_slides.html#presentation",
    "href": "talks/dhsi_slides.html#presentation",
    "title": "Coding fundamentals for humanists",
    "section": "Presentation",
    "text": "Presentation\nWe start the course with a presentation explaining the concepts"
  },
  {
    "objectID": "talks/dhsi_slides.html#hands-on",
    "href": "talks/dhsi_slides.html#hands-on",
    "title": "Coding fundamentals for humanists",
    "section": "Hands-on",
    "text": "Hands-on\n\n\n Then move to hands-on"
  },
  {
    "objectID": "talks/dhsi_slides.html#jupyterlab",
    "href": "talks/dhsi_slides.html#jupyterlab",
    "title": "Coding fundamentals for humanists",
    "section": "JupyterLab",
    "text": "JupyterLab\n\n\n We use the free and open-source JupyterLab as an interface to Python to make it easier to play with code"
  },
  {
    "objectID": "talks/dhsi_slides.html#we-write-the-jupyter-notebooks-in-advance",
    "href": "talks/dhsi_slides.html#we-write-the-jupyter-notebooks-in-advance",
    "title": "Coding fundamentals for humanists",
    "section": "We write the Jupyter notebooks in advance",
    "text": "We write the Jupyter notebooks in advance\nExample of notebook you will download:"
  },
  {
    "objectID": "talks/dhsi_slides.html#and-we-let-you-fill-in-the-code",
    "href": "talks/dhsi_slides.html#and-we-let-you-fill-in-the-code",
    "title": "Coding fundamentals for humanists",
    "section": "And we let you fill-in the code",
    "text": "And we let you fill-in the code\nExample of completed notebook:"
  },
  {
    "objectID": "talks/dhsi_slides.html#guidance-on-using-llms",
    "href": "talks/dhsi_slides.html#guidance-on-using-llms",
    "title": "Coding fundamentals for humanists",
    "section": "Guidance on using LLMs",
    "text": "Guidance on using LLMs\nWhen used well, large language models can allow students:\n\nTo be much more independent\nNot to get frustrated over small road-blocks\nTo go much further faster\nTo keep learning on their own\nTo be able to apply Python to their research\n\n\nWe will show you what works and what doesn‚Äôt when using LLMs to write code"
  },
  {
    "objectID": "talks/dhsi_slides.html#end-of-course-projects",
    "href": "talks/dhsi_slides.html#end-of-course-projects",
    "title": "Coding fundamentals for humanists",
    "section": "End of course projects",
    "text": "End of course projects\nAt the end of the course, attendees work in pairs on a project of their choice (which can be their own research) with our help\nFollowing are samples of data our past students successfully scraped from various websites"
  },
  {
    "objectID": "talks/dhsi_slides.html#guardian-archives",
    "href": "talks/dhsi_slides.html#guardian-archives",
    "title": "Coding fundamentals for humanists",
    "section": "Guardian archives",
    "text": "Guardian archives"
  },
  {
    "objectID": "talks/dhsi_slides.html#spotify-playlist",
    "href": "talks/dhsi_slides.html#spotify-playlist",
    "title": "Coding fundamentals for humanists",
    "section": "Spotify playlist",
    "text": "Spotify playlist"
  },
  {
    "objectID": "talks/dhsi_slides.html#numbers-of-published-books",
    "href": "talks/dhsi_slides.html#numbers-of-published-books",
    "title": "Coding fundamentals for humanists",
    "section": "Numbers of published books",
    "text": "Numbers of published books"
  },
  {
    "objectID": "talks/dhsi_slides.html#reddit-data",
    "href": "talks/dhsi_slides.html#reddit-data",
    "title": "Coding fundamentals for humanists",
    "section": "Reddit data",
    "text": "Reddit data\n\n\nExported as a Python list:\n\n\n\n\nExported as a Python polars data frame:"
  },
  {
    "objectID": "tools/index.html",
    "href": "tools/index.html",
    "title": "Tools",
    "section": "",
    "text": "Workshops\nVarious tools\n\n\n\n\n60 min webinars\nVarious tools",
    "crumbs": [
      "Tools",
      "<br>&nbsp;<em><b>Tools</b></em><br><br>"
    ]
  },
  {
    "objectID": "tools/wb_dvc.html",
    "href": "tools/wb_dvc.html",
    "title": "Version control for data science and machine learning with DVC",
    "section": "",
    "text": "Data version control (DVC) is an open source tool that brings all the versioning and collaboration capabilities you use on your code with Git to your data and machine learning workflow.\nIf you use datasets in your work, it makes it easy to track their evolution.\nIf you are in the field of machine learning, it additionally allows you to track your models, manage your pipelines from parameters to metrics, collaborate on your experiments, and integrate with the continuous integration tool for machine learning projects CML.\nThis webinar will show you how to get started with DVC, first in the simple case where you just want to put your data under version control, then in the more complex situation where you want to manage your machine learning workflow in a more organized and reproducible fashion.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Data version control with DVC"
    ]
  },
  {
    "objectID": "tools/wb_dvc_slides.html#on-version-control",
    "href": "tools/wb_dvc_slides.html#on-version-control",
    "title": "Version control for data science & machine learning with DVC",
    "section": "On version control",
    "text": "On version control\nI won‚Äôt introduce here the benefits of using a good version control system such as Git\n\n\n\nOn the benefits of VCS"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#extending-git-for-data",
    "href": "tools/wb_dvc_slides.html#extending-git-for-data",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Extending Git for data",
    "text": "Extending Git for data\nWhile Git is a wonderful tool for text files versioning (code, writings in markup formats), it isn‚Äôt a tool to manage changes to datasets\nSeveral open source tools‚Äîeach with a different structure and functioning‚Äîextend Git capabilities to track data: Git LFS, git-annex, lakeFS, Dolt, DataLad"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#extending-git-for-models-and-experiments",
    "href": "tools/wb_dvc_slides.html#extending-git-for-models-and-experiments",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Extending Git for models and experiments",
    "text": "Extending Git for models and experiments\nReproducible research and collaboration on data science and machine learning projects involve more than datasets management:\nExperiments and the models they produce also need to be tracked"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#many-moving-parts",
    "href": "tools/wb_dvc_slides.html#many-moving-parts",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Many moving parts",
    "text": "Many moving parts\n\n*hp = hyperparameter\n\n\n\n\n\n\n\n\n\n\ndata1\n\ndata1\n\n\n\nmodel1\n\nmodel1\n\n\n\ndata1-&gt;model1\n\n\n\n\n\nmodel2\n\nmodel2\n\n\n\ndata1-&gt;model2\n\n\n\n\n\nmodel3\n\nmodel3\n\n\n\ndata1-&gt;model3\n\n\n\n\n\ndata2\n\ndata2\n\n\n\ndata2-&gt;model1\n\n\n\n\n\ndata2-&gt;model2\n\n\n\n\n\ndata2-&gt;model3\n\n\n\n\n\ndata3\n\ndata3\n\n\n\ndata3-&gt;model1\n\n\n\n\n\ndata3-&gt;model2\n\n\n\n\n\ndata3-&gt;model3\n\n\n\n\n\nhp1\n\nhp1\n\n\n\nhp1-&gt;model1\n\n\n\n\n\nhp1-&gt;model2\n\n\n\n\n\nhp1-&gt;model3\n\n\n\n\n\nhp2\n\nhp2\n\n\n\nhp2-&gt;model1\n\n\n\n\n\nhp2-&gt;model2\n\n\n\n\n\nhp2-&gt;model3\n\n\n\n\n\nhp3\n\nhp3\n\n\n\nhp3-&gt;model1\n\n\n\n\n\nhp3-&gt;model2\n\n\n\n\n\nhp3-&gt;model3\n\n\n\n\n\nperformance\n\nperformance1 ... performance27\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel1-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel2-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\nmodel3-&gt;performance\n\n\n\n\n\n\n\n\n\n\n\nHow did we get performance17 again? ü§Ø"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#dvc-principles",
    "href": "tools/wb_dvc_slides.html#dvc-principles",
    "title": "Version control for data science & machine learning with DVC",
    "section": "DVC principles",
    "text": "DVC principles\nLarge files (datasets, models‚Ä¶) are kept outside Git\nEach large file or directory put under DVC tracking has an associated .dvc file\nGit only tracks the .dvc files (metadata)\n\nWorkflows can be tracked for collaboration and reproducibility\n\n\nDVC functions as a Makefile and allows to only rerun what is necessary"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#installation",
    "href": "tools/wb_dvc_slides.html#installation",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Installation",
    "text": "Installation\nFor Linux (other OSes, refer to the doc):\n\npip:\npip install dvc\nconda\npipx (if you want dvc available everywhere without having to activate virtual envs):\npipx install dvc\n\n\nOptional dependencies [s3], [gdrive], etc. for remote storage"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#how-to-run",
    "href": "tools/wb_dvc_slides.html#how-to-run",
    "title": "Version control for data science & machine learning with DVC",
    "section": "How to run",
    "text": "How to run\nMultiple options:\n\nTerminal:\ndvc ...\nVS Code extension\nPython library if installed via pip or conda:\nimport dvc.api\n\n\nIn this webinar, I will use DVC through the command line"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#acknowledgements",
    "href": "tools/wb_dvc_slides.html#acknowledgements",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nCode and data for this webinar modified from:\n\nReal Python\nDataLad handbook\nDVC documentation"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#the-project",
    "href": "tools/wb_dvc_slides.html#the-project",
    "title": "Version control for data science & machine learning with DVC",
    "section": "The project",
    "text": "The project\ntree -L 3\n‚îú‚îÄ‚îÄ LICENSE\n‚îú‚îÄ‚îÄ data\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ prepared\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ raw\n‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ train\n‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ val\n‚îú‚îÄ‚îÄ metrics\n‚îú‚îÄ‚îÄ model\n‚îú‚îÄ‚îÄ requirements.txt\n‚îî‚îÄ‚îÄ src\n    ‚îú‚îÄ‚îÄ evaluate.py\n    ‚îú‚îÄ‚îÄ prepare.py\n    ‚îî‚îÄ‚îÄ train.py"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#initialize-git-repo",
    "href": "tools/wb_dvc_slides.html#initialize-git-repo",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Initialize Git repo",
    "text": "Initialize Git repo\ngit init\nInitialized empty Git repository in dvc/.git/\n\nThis creates the .git directory\n\n\ngit status\nOn branch main\n\nNo commits yet\n\nUntracked files:\n    LICENSE\n    data/\n    requirements.txt\n    src/"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#initialize-dvc-project",
    "href": "tools/wb_dvc_slides.html#initialize-dvc-project",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Initialize DVC project",
    "text": "Initialize DVC project\ndvc init\nInitialized DVC repository.\n\nYou can now commit the changes to git.\n\nYou will also see a note about usage analytics collection and info on how to opt out\n\n\nA .dvc directory and a .dvcignore file got created"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#commit-dvc-system-files",
    "href": "tools/wb_dvc_slides.html#commit-dvc-system-files",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Commit DVC system files",
    "text": "Commit DVC system files\nDVC automatically staged its system file for us:\ngit status\nOn branch main\n\nNo commits yet\n\nChanges to be committed:\n    new file:   .dvc/.gitignore\n    new file:   .dvc/config\n    new file:   .dvcignore\n\nUntracked files:\n    LICENSE\n    data/\n    requirements.txt\n    src/"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#commit-dvc-system-files-1",
    "href": "tools/wb_dvc_slides.html#commit-dvc-system-files-1",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Commit DVC system files",
    "text": "Commit DVC system files\nSo we can directly commit:\ngit commit -m \"Initialize DVC\""
  },
  {
    "objectID": "tools/wb_dvc_slides.html#prepare-repo",
    "href": "tools/wb_dvc_slides.html#prepare-repo",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Prepare repo",
    "text": "Prepare repo\nLet‚Äôs work in a virtual environment:\n# Create venv and add to .gitignore\npython -m venv venv && echo venv &gt; .gitignore\n\n# Activate venv\nsource venv/bin/activate\n\n# Update pip\npython -m pip install --upgrade pip\n\n# Install packages needed\npython -m pip install -r requirements.txt"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#clean-working-tree",
    "href": "tools/wb_dvc_slides.html#clean-working-tree",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Clean working tree",
    "text": "Clean working tree\ngit add .gitignore LICENSE requirements.txt\ngit commit -m \"Add general files\"\ngit add src\ngit commit -m \"Add scripts\"\ngit status\nOn branch main\nUntracked files:\n    data/\n\n\nNow, it is time to deal with the data"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#put-data-under-dvc-tracking",
    "href": "tools/wb_dvc_slides.html#put-data-under-dvc-tracking",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Put data under DVC tracking",
    "text": "Put data under DVC tracking\nWe are still not tracking any data:\ndvc status\nThere are no data or pipelines tracked in this project yet.\nYou can choose what to track as a unit (i.e.¬†each picture individually, the whole data directory as a unit)\nLet‚Äôs break it down by set:\ndvc add data/raw/train\ndvc add data/raw/val"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#section",
    "href": "tools/wb_dvc_slides.html#section",
    "title": "Version control for data science & machine learning with DVC",
    "section": "",
    "text": "This adds data to .dvc/cache/files and created 3 files in data/raw:\n\n.gitignore\ntrain.dvc\nval.dvc\n\nThe .gitignore tells Git not to track the data:\ncat data/raw/.gitignore\n/train\n/val\nThe .dvc files contain the metadata for the cached directories"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#tracked-data",
    "href": "tools/wb_dvc_slides.html#tracked-data",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Tracked data",
    "text": "Tracked data\nWe are all good:\ndvc status\nData and pipelines are up to date."
  },
  {
    "objectID": "tools/wb_dvc_slides.html#data-deduplication",
    "href": "tools/wb_dvc_slides.html#data-deduplication",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Data (de)duplication",
    "text": "Data (de)duplication\nLink between checked-out version of a file/directory and the cache:\n\nCache ‚ü∑ working directory\n\n\n\n\n\n\n\n\nDuplication\nEditable\n\n\n\n\nReflinks*\nOnly when needed\nYes\n\n\nHardlinks/Symlinks\nNo\nNo\n\n\nCopies\nYes\nYes\n\n\n\n\n*Reflinks only available for a few file systems (Btrfs, XFS, OCFS2, or APFS)"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#commit-the-metafiles",
    "href": "tools/wb_dvc_slides.html#commit-the-metafiles",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Commit the metafiles",
    "text": "Commit the metafiles\nThe metafiles should be put under Git version control\n\nYou can configure DVC to automatically stage its newly created system files:\ndvc config [--system] [--global] core.autostage true\n\nYou can then commit directly:\ngit commit -m \"Initial version of data\"\ngit status\nOn branch main\nnothing to commit, working tree clean"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#track-changes-to-the-data",
    "href": "tools/wb_dvc_slides.html#track-changes-to-the-data",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Track changes to the data",
    "text": "Track changes to the data\nLet‚Äôs make some change to the data:\nrm data/raw/val/n03445777/ILSVRC2012_val*\n\nRemember that Git is not tracking the data:\ngit status\nOn branch main\nnothing to commit, working tree clean\n\n\nBut DVC is:\ndvc status\ndata/raw/val.dvc:\n    changed outs:\n            modified:           data/raw/val"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#add-changes-to-dvc",
    "href": "tools/wb_dvc_slides.html#add-changes-to-dvc",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Add changes to DVC",
    "text": "Add changes to DVC\ndvc add data/raw/val\ndvc status\nData and pipelines are up to date.\n\nNow we need to commit the changes to the .dvc file to Git:\ngit status\nOn branch main\nChanges to be committed:\n    modified:   data/raw/val.dvc\n\nStaging happened automatically because I have set the autostage option to true on my system\n\ngit commit -m \"Delete data/raw/val/n03445777/ILSVRC2012_val*\""
  },
  {
    "objectID": "tools/wb_dvc_slides.html#check-out-older-versions",
    "href": "tools/wb_dvc_slides.html#check-out-older-versions",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Check out older versions",
    "text": "Check out older versions\nWhat if we want to go back to the 1st version of our data?\nFor this, we first use Git to checkout the proper commit, then run dvc checkout to have the data catch up to the .dvc file\nTo avoid forgetting to run the commands that will make DVC catch up to Git, we can automate this process by installing Git hooks:\ndvc install"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#git-workflows",
    "href": "tools/wb_dvc_slides.html#git-workflows",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Git workflows",
    "text": "Git workflows\ngit checkout is ok to have a look, but a detached HEAD is not a good place to create new commits\nLet‚Äôs create a new branch and switch to it:\ngit switch -c alternative\nSwitched to a new branch 'alternative'\nGoing back and forth between both versions of our data is now as simple as switching branch:\ngit switch main\ngit switch alternative"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#classic-workflow",
    "href": "tools/wb_dvc_slides.html#classic-workflow",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Classic workflow",
    "text": "Classic workflow\nThe Git project (including .dvc files) go to a Git remote (GitHub/GitLab/Bitbucket/server)\nThe data go to a DVC remote (AWS/Azure/Google Drive/server/etc.)"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#dvc-remotes",
    "href": "tools/wb_dvc_slides.html#dvc-remotes",
    "title": "Version control for data science & machine learning with DVC",
    "section": "DVC remotes",
    "text": "DVC remotes\nDVC can use many cloud storage or remote machines/server via SSH, WebDAV, etc.\nLet‚Äôs create a local remote here:\n# Create a directory outside the project\nmkdir ../remote\n\n# Setup default (-d) remote\ndvc remote add -d local_remote ../remote\nSetting 'local_remote' as a default remote.\ncat .dvc/config\n[core]\n    remote = local_remote\n['remote \"local_remote\"']\n    url = ../../remote"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#commit-remote-config",
    "href": "tools/wb_dvc_slides.html#commit-remote-config",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Commit remote config",
    "text": "Commit remote config\nThe new remote configuration should be committed:\ngit status\nOn branch alternative\n\nChanges not staged for commit:\n    modified:   .dvc/config\ngit add .\ngit commit -m \"Config remote\""
  },
  {
    "objectID": "tools/wb_dvc_slides.html#push-to-remotes",
    "href": "tools/wb_dvc_slides.html#push-to-remotes",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Push to remotes",
    "text": "Push to remotes\nLet‚Äôs push the data from the cache (.dvc/cache) to the remote:\ndvc push\n2702 files pushed\n\nWith Git hooks installed, dvc push is automatically run after git push\n(But the data is pushed to the DVC remote while the files tracked by Git get pushed to the Git remote)\n\nBy default, the entire data cache gets pushed to the remote, but there are many options\n\nExample: only push data corresponding to a certain .dvc files\ndvc push data/raw/val.dvc"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#pull-from-remotes",
    "href": "tools/wb_dvc_slides.html#pull-from-remotes",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Pull from remotes",
    "text": "Pull from remotes\ndvc fetch downloads data from the remote into the cache. To have it update the working directory, follow by dvc checkout\nYou can do these 2 commands at the same time with dvc pull"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#dvc-pipelines",
    "href": "tools/wb_dvc_slides.html#dvc-pipelines",
    "title": "Version control for data science & machine learning with DVC",
    "section": "DVC pipelines",
    "text": "DVC pipelines\nDVC pipelines create reproducible workflows and are functionally similar to Makefiles\nEach step in a pipeline is created with dvc stage add and add an entry to a dvc.yaml file\n\ndvc stage add options:\n-n: name of stage\n-d: dependency\n-o: output\n\n\nEach stage contains:\n\ncmd: the command executed\ndeps: the dependencies\nouts: the outputs\n\nThe file is then used to visualize the pipeline and run it"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#example",
    "href": "tools/wb_dvc_slides.html#example",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Example",
    "text": "Example\nLet‚Äôs create a pipeline to run a classifier on our data\nThe pipeline contains 3 steps:\n\nprepare\ntrain\nevaluate"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#create-a-pipeline",
    "href": "tools/wb_dvc_slides.html#create-a-pipeline",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Create a pipeline",
    "text": "Create a pipeline\n1st stage (data preparation):\ndvc stage add -n prepare -d src/prepare.py -d data/raw \\\n    -o data/prepared/train.csv -o data/prepared/test.csv \\\n    python src/prepare.py\nAdded stage 'prepare' in 'dvc.yaml'"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#create-a-pipeline-1",
    "href": "tools/wb_dvc_slides.html#create-a-pipeline-1",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Create a pipeline",
    "text": "Create a pipeline\n2nd stage (training)\ndvc stage add -n train -d src/train.py -d data/prepared/train.csv \\\n    -o model/model.joblib \\\n    python src/train.py\nAdded stage `train` in 'dvc.yaml'"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#create-a-pipeline-2",
    "href": "tools/wb_dvc_slides.html#create-a-pipeline-2",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Create a pipeline",
    "text": "Create a pipeline\n3rd stage (evaluation)\ndvc stage add -n evaluate -d src/evaluate.py -d model/model.joblib \\\n    -M metrics/accuracy.json \\\n    python src/evaluate.py\nAdded stage `evaluate` in 'dvc.yaml'"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#commit-pipeline",
    "href": "tools/wb_dvc_slides.html#commit-pipeline",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Commit pipeline",
    "text": "Commit pipeline\ngit commit -m \"Define pipeline\"\nprepare:\n    changed deps:\n            modified:           data/raw\n            modified:           src/prepare.py\n    changed outs:\n            deleted:            data/prepared/test.csv\n            deleted:            data/prepared/train.csv\ntrain:\n    changed deps:\n            deleted:            data/prepared/train.csv\n            modified:           src/train.py\n    changed outs:\n            deleted:            model/model.joblib\nevaluate:\n    changed deps:\n            deleted:            model/model.joblib\n            modified:           src/evaluate.py\n    changed outs:\n            deleted:            metrics/accuracy.json\n[main 4aa331b] Define pipeline\n 3 files changed, 27 insertions(+)\n create mode 100644 data/prepared/.gitignore\n create mode 100644 dvc.yaml\n create mode 100644 model/.gitignore"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#visualize-pipeline-in-a-dag",
    "href": "tools/wb_dvc_slides.html#visualize-pipeline-in-a-dag",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Visualize pipeline in a DAG",
    "text": "Visualize pipeline in a DAG\ndvc dag\n+--------------------+         +------------------+\n| data/raw/train.dvc |         | data/raw/val.dvc |\n+--------------------+         +------------------+\n                  ***           ***\n                     **       **\n                       **   **\n                    +---------+\n                    | prepare |\n                    +---------+\n                          *\n                          *\n                          *\n                      +-------+\n                      | train |\n                      +-------+\n                          *\n                          *\n                          *\n                    +----------+\n                    | evaluate |\n                    +----------+"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#run-pipeline",
    "href": "tools/wb_dvc_slides.html#run-pipeline",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Run pipeline",
    "text": "Run pipeline\ndvc repro\n'data/raw/train.dvc' didn't change, skipping\n'data/raw/val.dvc' didn't change, skipping\nRunning stage 'prepare':\n&gt; python src/prepare.py\nGenerating lock file 'dvc.lock'\nUpdating lock file 'dvc.lock'\n\nRunning stage 'train':\n&gt; python src/train.py\nUpdating lock file 'dvc.lock'\n\nRunning stage 'evaluate':\n&gt; python src/evaluate.py\nUpdating lock file 'dvc.lock'\nUse `dvc push` to send your updates to remote storage."
  },
  {
    "objectID": "tools/wb_dvc_slides.html#dvc-repro-breakdown",
    "href": "tools/wb_dvc_slides.html#dvc-repro-breakdown",
    "title": "Version control for data science & machine learning with DVC",
    "section": "dvc repro breakdown",
    "text": "dvc repro breakdown\n\ndvc repro runs the dvc.yaml file in a Makefile fashion\nFirst, it looks at the dependencies: the data didn‚Äôt change\nThen it ran the commands to produce the outputs (since it is our first run, we had no outputs)\nWhen the 1st stage is run, a dvc.lock is created with information on that part of the run\nWhen the 2nd and 3rd stages are run, dvc.lock is updated\nAt the end of the run dvc.lock contains all the info about the run we just did (version of the data used, etc.)\nA new directory called runs is created in .dvc/cache with cached data for this run"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#results-of-the-run",
    "href": "tools/wb_dvc_slides.html#results-of-the-run",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Results of the run",
    "text": "Results of the run\n\nThe prepared data was created in data/prepared (with a .gitignore to exclude it from Git‚Äîyou don‚Äôt want to track results in Git, but the scripts that can reproduce them)\nA model was saved in model (with another .gitignore file)\nThe accuracy of this run was created in metrics"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#clean-working-tree-1",
    "href": "tools/wb_dvc_slides.html#clean-working-tree-1",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Clean working tree",
    "text": "Clean working tree\nNow, we definitely want to create a commit with the dvc.lock\nWe could add the metrics resulting from this run in the same commit:\ngit add metrics\ngit commit -m \"First pipeline run and results\"\n\nOur working tree is now clean and our data/pipeline up to date:\ngit status\nOn branch alternative\nnothing to commit, working tree clean\ndvc status\nData and pipelines are up to date."
  },
  {
    "objectID": "tools/wb_dvc_slides.html#modify-pipeline",
    "href": "tools/wb_dvc_slides.html#modify-pipeline",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Modify pipeline",
    "text": "Modify pipeline\nFrom now on, if we edit one of the scripts, or one of the dependencies, dvc status will tell us what changed and dvc repro will only rerun the parts of the pipeline to update the result, pretty much as a Makefile would"
  },
  {
    "objectID": "tools/wb_dvc_slides.html#going-further-next-time",
    "href": "tools/wb_dvc_slides.html#going-further-next-time",
    "title": "Version control for data science & machine learning with DVC",
    "section": "Going further ‚Ä¶ next time",
    "text": "Going further ‚Ä¶ next time\n DVC is a sophisticated tool with many additional features:\n\nCreation of data registries\nDVCLive\nA Python library to log experiment metrics\nVisualize the performance logs as plots\nContinuous integration\nWith the sister project CML (Continuous Machine Learning)"
  },
  {
    "objectID": "tools/wb_help_content.html",
    "href": "tools/wb_help_content.html",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Getting help online",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_help_content.html#when-you-are-stuck",
    "href": "tools/wb_help_content.html#when-you-are-stuck",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "When you are stuck",
    "text": "When you are stuck\nFirst, look for information that is already out there.\nThen, ask for help.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Getting help online",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_help_content.html#look-for-information",
    "href": "tools/wb_help_content.html#look-for-information",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Look for information",
    "text": "Look for information\n\nRead carefully any error message.\nRead the documentation (local or online).\nMake sure you have up-to-date versions.\nGoogle (using carefully selected keywords or the error message).\nLook for open issues & bug reports.\n\n\nError messages\nRead them!.\nFamiliarise yourself with the error types in the languages you use.\n\nExample: Python‚Äôs syntax errors vs exceptions.\n\nWarnings ‚â† errors\nLook for bits you understand (don‚Äôt get put off by what you don‚Äôt understand).\nIdentify the locations of the errors to go investigate that part of the code.\n\n\nDocumentation\nYou need to find it.\nYou need to understand it.\n\n\nFinding documentation\nOnline:\nTake the time to look for the official documentation & other high quality sources for the languages & tools you use.\n\nExamples:\n\nPython: Reference manual, Standard library manual, Tutorial,\nNumPy: Tutorial,\nR: Open source book ‚ÄúR for Data Science‚Äù, Open source book ‚ÄúAdvanced R‚Äù,\nJulia: Documentation,\nBash: Manual,\nGit: Manual, Open source book.\n\n\nIn the program itself.\nUnderstanding the documentation.\n\n\nUp-to-date versions\nFirst, you need to know what needs to be updated.\nKeeping a system up to date includes updating:\n\nthe OS,\nthe program,\n(any potential IDE),\npackages.\n\nThen, you need to update regularly.\n\n\nGoogle\nGoogle‚Äôs algorithms are great at guessing what we are looking for.\nBut there is a frequency problem:\nSearches relating to programming-specific questions represent too small a fraction of the overall searches for results to be relevant unless you use key vocabulary.\nBe precise.\nLearn the vocabulary of your language/tool to know what to search for.\n\n\nOpen issues & bug reports\nIf the tool you are using is open source, look for issues matching your problem in the source repository (e.g.¬†on GitHub or GitLab).\n\n\nWhat if the answer isn‚Äôt out there?\nWhen everything has failed & you have to ask for help, you need to know:\n\nWhere to ask.\nHow to ask.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Getting help online",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_help_content.html#where-to-ask",
    "href": "tools/wb_help_content.html#where-to-ask",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Where to ask",
    "text": "Where to ask\n\nQ&A sites\nMostly, Stack Overflow & the Stack Exchange network co-founded in 2008 & 2009 by Jeff Atwood & Joel Spolsky.\n\n\nForums\nMostly, Discourse co-founded in 2013 by Jeff Atwood, Robin Ward & Sam Saffron.\nA few other older forums.\nWhich one to choose is a matter of personal preference.\nPossible considerations:\n\nSome niche topics have very active communities on Discourse.\nStack Overflow & some older forums can be intimidating with higher expectations for the questions quality & a more direct handling of mistakes.\nFor conversations, advice, or multiple step questions, go to Discourse.\nStack Overflow has over 13 million users.\nStack Overflow & co have a very efficient approach.\n\n\n\nStack Overflow & co\nPick the best site to ask your question.\nA few of the Stack Exchange network sites:\n\nStack Overflow: programming.\nSuper User: computer hardware & software.\nUnix & Linux: *nix OS.\nTEX: TeX/LaTeX.\nCross Validated: stats; data mining, collecting, analysis & visualization; ML.\nData Science: focus on implementation & processes.\nOpen Data.\nGIS.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Getting help online",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_help_content.html#how-to-ask",
    "href": "tools/wb_help_content.html#how-to-ask",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "How to ask",
    "text": "How to ask\n\nFamiliarize yourself with the site by reading posts.\nRead the ‚ÄúTour‚Äù page (SO/SE) or take the ‚ÄúNew user tutorial‚Äù (Discourse).\nMake sure the question has not already been asked.\nFormat the question properly.\nGive a minimum reproducible example.\nDo not share sensitive data.\nShow your attempts.\n\nAvoid cross-posting. If you really have to, make sure to cross-reference.\n\nHow to ask: SO & co\n\nDon‚Äôt ask opinion-based questions.\nDon‚Äôt ask for package, tool, or service recommendations.\nDon‚Äôt ask more than one question in a single post.\nCheck your spelling, grammar, punctuation, capitalized sentences, etc.\nAvoid greetings, signatures, thank-yous; keep it to the point.\nAvoid apologies about being a beginner, this being your first post, the question being stupid, etc: do the best you can & skip the personal, self-judgmental & irrelevant bits.\n\n\n\nFormatting your question\nNowadays, most sites (including Stack Overflow & Discourse) allow markdown rendering.\nSome older forums implement other markup languages (e.g.¬†BBCode).\nThe information is always easy to find. Spend the time to format your question properly. People will be much less inclined to help you if you don‚Äôt show any effort & if your question is a nightmare to read.\n\n\nA typical downvoted question\nCode:\nhowdy!!\ni am new to R sorry for a very silly question.i looked all oever the itnernwet, but i dint find\nanyanswer. i tried to use ggplot i get the error: Error in loadNamespace(i, c(lib.loc, .libPaths()),\nversionCheck = vI[[i]]) : there is no package called 'stringi'\nthank youu very much!!!!!\nmarie\nRendered output:\n\n\n\nSame question, fixed\nWhen I try to load the package `ggplot2` with:\n\n```{r}\nlibrary(ggplot2)\n```\nI get the error:\n\n&gt; Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :\nthere is no package called 'stringi'\n\nWhat am I doing wrong?\n\n\n\nStill not good enough\nThis question is actually a duplicate of a question asked which is itself a duplicate of another question.\n\n\nMinimal reproducible examples\nThere are great posts on how to create a good minimal reproducible example. In particular:\nHow to create a Minimal, Reproducible Example\nFor R (but concepts apply to any language):\nHow to make a great R reproducible example\nWhat‚Äôs a reproducible example (reprex) and how do I do one?\n\nLoad all necessary packages.\nLoad or create necessary data.\nSimplify the data & the code as much as possible while still reproducing the problem.\nUse simple variable names.\n\n\n\nData for your example\n\nYour own data\n\nDo not upload data somewhere on the web to be downloaded.\nMake sure that the data is anonymised.\nDon‚Äôt keep more variables & more data points than are necessary to reproduce the problem.\nSimplify the variable names.\nIn R, you can use functions such as dput() to turn your reduced, anonymised data into text that is easy to copy/paste & can then be used to recreate the data.\n\n\n\nCreate a toy dataset\nYou can also create a toy dataset.\nFunctions that create random data, series, or repetitions are very useful here.\n\n\nPre-packaged datasets\nSome languages/packages come with pre-packaged datasets. If your code involves such languages/packages, you can make use of these datasets to create your reproducible example.\nFor example, R comes with many datasets directly available, including iris, mtcars, trees, airquality. In the R console, try:\n?iris\n?mtcars",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Getting help online",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_help_content.html#additional-considerations",
    "href": "tools/wb_help_content.html#additional-considerations",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "Additional considerations",
    "text": "Additional considerations\nEven if you always find answers to your questions without having to post yourself, consider signing up to these sites:\n\nIt allows you to upvote (SO/SE) or like (Discourse) the questions & answers that help you‚Äîand why not thank in this fashion those that are making your life easier?\nIt makes you a part of these communities.\nOnce you are signed up, maybe you will start being more involved & contribute with questions & answers of your own.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Getting help online",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_help_content.html#a-last-word",
    "href": "tools/wb_help_content.html#a-last-word",
    "title": "So, you are stuck ‚Ä¶ now what?",
    "section": "A last word",
    "text": "A last word\nWhile it takes some work to ask a good question, do not let this discourage you from posting on Stack Overflow: if you ask a good question, you will get many great answers. You will learn in the process of developing your question (you may actually find the answer in that process) & you will learn from the answers.\nIt is forth the effort.\nHere is the Stack Overflow documentation on how to ask a good question.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Getting help online",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_lazygit.html",
    "href": "tools/wb_lazygit.html",
    "title": "A great Git UI: lazygit",
    "section": "",
    "text": "While it is important to know how to use Git from the command line, this makes for an austere experience: a series of commands are required to gather information on the state of the working tree, see changes to files, or get a schematic of the commit history. Committing sections of files interactively and other operations are just awkward affairs. On the other hand, the many graphic interfaces for Git are often buggy, slow, and limiting.\nOne option is to write exciting functions with tools such as fzf to make things more friendly and visual. A simpler and more polished option is to use an already built user interface for Git that runs directly in the command line. lazygit is one such open source tool. After years of development, it is a mature, beautiful tool that allows to perform any Git operation in the command line in a convenient, fast, and visual fashion.\nIn this webinar, I will demo how I use lazygit in my daily workflow to run routine as well as more complex Git commands.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "A great Git TUI: lazygit"
    ]
  },
  {
    "objectID": "tools/wb_lazygit_slides.html#git-interfaces",
    "href": "tools/wb_lazygit_slides.html#git-interfaces",
    "title": "A great Git UI: lazygit",
    "section": "Git interfaces",
    "text": "Git interfaces\nThere are 3 main ways to use Git:\n\nThrough a Git GUI\nFrom the command line\nIntegrated within IDE"
  },
  {
    "objectID": "tools/wb_lazygit_slides.html#git-interfaces-1",
    "href": "tools/wb_lazygit_slides.html#git-interfaces-1",
    "title": "A great Git UI: lazygit",
    "section": "Git interfaces",
    "text": "Git interfaces\nThey all have downsides:\n\nThrough a Git GUI ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÇ¬†‚ûî ‚ÄÇSlow and buggy\nFrom the command line ‚ÄÇ‚ÄÇ‚ûî ‚ÄÇAustere and unintuitive\nIntegrated within IDE ‚ÄÉ‚ÄÉ‚ÄÇ‚ûî ‚ÄÇLimited"
  },
  {
    "objectID": "tools/wb_lazygit_slides.html#on-the-beauty-of-tuis",
    "href": "tools/wb_lazygit_slides.html#on-the-beauty-of-tuis",
    "title": "A great Git UI: lazygit",
    "section": "On the beauty of TUIs",
    "text": "On the beauty of TUIs\nTerminal user interfaces (TUIs) were precursors to graphical user interfaces (GUIs), but they did not disappear\nPeople continue to build TUIs because they uniquely provide the speed of the command line and the easy of use of GUIs\nGitHub is full of sleek, modern, open source TUIs for all sorts of applications\nSeveral of them provide an interface to Git\nMy personal TUIs of choice are ranger as file manager and lazygit for Git"
  },
  {
    "objectID": "tools/wb_lazygit_slides.html#lazygit",
    "href": "tools/wb_lazygit_slides.html#lazygit",
    "title": "A great Git UI: lazygit",
    "section": "lazygit",
    "text": "lazygit\nWith over 52k stars on GitHub, lazygit, created and maintained by Jesse Duffield is probably the most polished Git TUI\nI followed it as it grew and developed over the past 5 years. It was great from the start, but by now, it is a truly beautiful mature tool\nIt is cross-platform. You can find installation instructions in the README"
  },
  {
    "objectID": "tools/wb_lazygit_slides.html#lazygit-1",
    "href": "tools/wb_lazygit_slides.html#lazygit-1",
    "title": "A great Git UI: lazygit",
    "section": "lazygit",
    "text": "lazygit\nGet command options:\nlazygit -h\nPrint default configurations with:\nlazygit -c\n\nlazygit is fully customizable"
  },
  {
    "objectID": "tools/wb_lazygit_slides.html#resources",
    "href": "tools/wb_lazygit_slides.html#resources",
    "title": "A great Git UI: lazygit",
    "section": "Resources",
    "text": "Resources\n\nRepo\nDefault kbds\nConfiguration options"
  },
  {
    "objectID": "tools/wb_lazygit_slides.html#time-for-a-demo",
    "href": "tools/wb_lazygit_slides.html#time-for-a-demo",
    "title": "A great Git UI: lazygit",
    "section": "Time for a demo!",
    "text": "Time for a demo!\nI will spend the rest of this webinar showing you how to use Git through lazygit"
  },
  {
    "objectID": "tools/wb_marimo_content.html",
    "href": "tools/wb_marimo_content.html",
    "title": "The next generation of Python notebooks",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Next gen Python notebooks",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_marimo_content.html#notes",
    "href": "tools/wb_marimo_content.html#notes",
    "title": "The next generation of Python notebooks",
    "section": "Notes",
    "text": "Notes\n\nI am making an opinionated decision to use uv for installation.\nNotebooks are great for prototyping but not at scale.\nmarimo is not available on the Alliance clusters at this point.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Next gen Python notebooks",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_marimo_content.html#a-new-notebook",
    "href": "tools/wb_marimo_content.html#a-new-notebook",
    "title": "The next generation of Python notebooks",
    "section": "A new notebook",
    "text": "A new notebook\n\nWhat‚Äôs wrong with Jupyter?\nJupyter notebooks are very popular but they come with downsides:\n\nVersion control nightmare.\nAwkward JSON file format.\nReproducibility issues.\n\n\n\nDAG dataflow\nmarimo notebooks automatically generate an intermediate representation (IR) in the form of a directed acyclic graph (DAG) of:\n\ndefinitions (defs) of global variables,\nreferences (refs) of global variables.\n\nEach cell is parsed into an abstract syntax tree (AST).\nStatically inferred (no runtime tracing).\n\n\nPython files\n\n\n\nNotebooks are saved as .py files.\nEach cell is stored as a function.\nPure functions can be reused as modules.\n\n\n‚ûî\n\n\nEasy version control.\nDirectly executable as scripts or web apps.\nReadable in text editors.\n\n\n\n\n\nInteractive elements\nmarimo.ui creates interactive user interface (UI) elements with first-class support.\nNotebooks are automatically updated when values are changed via interactions.\n\n\nCool features\n\nTurn notebooks into apps.\nIntegrated AI.\nDocstrings on hover.\n\n\n\nThe constraints\nAll this comes at the cost of some constraints:\n\nGlobal variables must be unique.\nIn-place transformations are not allowed.\nMutations and attributes are not tracked.\n\n\nAll this is good practice for strict functional programming (and JAX)!\n\n\n\nComputation cost\nThere is a cost to updating the DAG at each change.\nRuntime configurations and cell settings allow to control when re-runs happen.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Next gen Python notebooks",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_marimo_content.html#getting-started",
    "href": "tools/wb_marimo_content.html#getting-started",
    "title": "The next generation of Python notebooks",
    "section": "Getting started",
    "text": "Getting started\n\nInstallation\nCreate a uv project:\nuv init --bare\nInstall marimo in it as a development dependency:\nuv add --dev marimo\n(Optional) add tools marimo can make use of:\nuv add --dev ruff basedpyright mcp\n\n\nLaunch a notebook\nmarimo edit notebook.py\n\nIf you installed with uv, first activate the virtual env or run instead:\nuv run marimo edit notebook.py\n\n\n\nConfiguration\nVia GUI\n top right corner (Notebook settings) ‚ûî User settings\n\nPackage manager\n ‚ûî User settings ‚ûî Packages & Data ‚ûî Package Management ‚ûî Manager: uv\n\n\nAI pair programming\n\nCode completion\nUse GitHub Copilot without account.\n\n\nAI assistant\nUse any of the classic LLMs with API key.\n\n\nMCP servers\n\nmarimo docs\nContext7\n\nUser settings are saved in ~/.config/marimo/marimo.toml (or similar in different OS).\n[mcp]\npresets = [\"marimo\", \"context7\"]\n\n[mcp.mcpServers]\n\n[runtime]\nwatcher_on_save = \"lazy\"\nauto_reload = \"off\"\ndefault_sql_output = \"auto\"\nauto_instantiate = true\nstd_stream_max_bytes = 1000000\ndefault_auto_download = []\non_cell_change = \"autorun\"\noutput_max_bytes = 8000000\nreactive_tests = true\n\n[formatting]\nline_length = 79\n\n[completion]\ncopilot = \"github\"\nactivate_on_typing = true\n\n[snippets]\ncustom_paths = []\ninclude_default_snippets = true\n\n[keymap]\npreset = \"default\"\ndestructive_delete = true\n\nLogs are found at ~/.cache/marimo/logs (or similar).\n\n\n\n\n\nOfficial website\nExcellent documentation:\nUser guides.\nAPI reference.\n\n\nTutorials\nmarimo tutorial intro\nFor more tutorials, replace intro with any of:\ndataflow\nui\nmarkdown\nplots\nsql\nlayout\nfileformat\nmarkdown-format\nfor-jupyter-users\n\nIf you installed with uv, first activate the virtual env or run instead:\nuv run marimo tutorial intro\n\n\n\nKey bindings\nVim kbd available.\n\nCommand mode\nEsc\nWith vim keybindings are enabled or other issues, use Ctrl+Esc or Shift+Esc instead.\nNavigation between cells, copy/cut/paste cells.\n\n\nEdit mode\nEnter or click on a cell.\nEdit content.\nCustomizable. List displayed by Ctrl-Shift-h.\n\n\n\n\n\n\n\n\nipynb notebooks conversion\nmarimo convert notebook.ipynb -o notebook.py\n\nIPython magics are replaced by Python functions.\n\n\nAfter a uv install, run (or activate the virtual env):\nuv run marimo convert notebook.ipynb -o notebook.py",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Next gen Python notebooks",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_marimo_content.html#general-usage",
    "href": "tools/wb_marimo_content.html#general-usage",
    "title": "The next generation of Python notebooks",
    "section": "General Usage",
    "text": "General Usage\n\nInstalling Python packages\nDirectly in the notebook following a pop-up when trying to use uninstalled package.\n\nOf course this can also be done via the command line:\nuv add &lt;package&gt;\n\nExample:\n\nuv add numpy\n\n\n\nOutputs displays\n\n\n\nConsole outputs\nText written to stdout/stderr\n‚ûî displayed below cells by default,\n‚ûî hidden in app mode.\n\nExample:\n\n\n\ncell\n\nprint(\"This is a console output.\")\n\n\n\n\n\n\nCell outputs\n\n‚ûî displayed above cells by default,\n‚ûî shown in app mode.\n\nExample:\n\n\n\ncell\n\n\"This is a cell output.\"\n\n\n\n\n\n\nForbidden re-assignments\nVariables re-assignments are OK within cells, but not across cells.\nThe cells with re-assignments will not run.\n\nReusing i in loops across cells won‚Äôt work.\n+=, -=, etc. won‚Äôt run.\n\n\nSolutions\n\n\n\nUse cell local variables\nVariables prefixed with _ are cell local.\n(names can thus be reused between cells).\n\n\ncell 0\n\n_a = 3\nprint(_a)\n\n\n\ncell 1\n\nprint(_a)\n\nname '_a' is not defined\n\n_i can be reused between cells:\n\n\ncell\n\nfor _i in range(10):\n    print(_i)\n\n\n\n\n\n‚ÄÇor\n\n\nWrap in functions\nFunctions create local environments.\nVariables created in functions don‚Äôt enter the global environment.\n‚ûî their names can be reused in functions in different cells.\n\n\ncell\n\ndef _():\n     for i in range(10):\n         print(i)\n\n_()\n\n\n\n\n\n\n\nMutations do not call re-runs\nLet‚Äôs consider:\n\n\ncell 0\n\nl = [1, 2, 3]\n\n\n\ncell 1\n\nlen(l)\n\n\n\ncell 2\n\nl.append(4)\n\nrunning the cell 2 will not update cell 1.\n\nSolutions\n\n\nMutate variables in the cells in which they are defined:\n\n\ncell 0\n\nl = [1, 2, 3]\nl.append(4)\n\n\n\ncell 1\n\nlen(l)\n\n\n\n‚ÄÇor\n\nCreate new variables:\n\n\ncell 0\n\nl = [1, 2, 3]\n\n\n\ncell 1\n\nlen(l)\n\n\n\ncell 2\n\nl2 = l + [4]\n\n\n\ncell 3\n\nlen(l2)\n\n\n\n\n\n\nDeleting cells\nAutomatically deletes variables defined in them (and cells with refs to them are re-run).\n\n\nNo cycles permitted\nThis would make the DAG impossible:\n\n\ncell 0\n\nvar1 = 4\nprint(var2)\n\n\n\ncell 1\n\nvar2 = 7\nprint(var1)\n\n\n\nAttributes are not tracked\nAssignments to attributes aren‚Äôt tracked:\n\n\ncell 0\n\nclass Object(object):\n    pass\n\nobj = Object()\nobj.somefield = \"somevalue\"\n\n\n\ncell 1\n\nprint(obj.somefield)\n\n\n\ncell 2\n\nobj.somefield = \"newvalue\"\n\ncell 1 is not re-run and updated automatically.\n\n\nDataflow programming\nExecution order \\(\\neq\\) cell order.\nThe execution order is determined by the DAG.\nThis is a totally valid notebook:\n\n\ncell 0\n\nprint(new_var)\n\n\n\ncell 1\n\nnew_var = 8\n\nThese are perfectly equivalent notebooks (they have the same DAG):\n\n\n\n\ncell 0\n\na = 3\n\n\n\ncell 1\n\na1 = 8.9\na2 = 8.3\n\n\n\ncell 2\n\na3 = 3.0\n\n\n\ncell 3\n\na4 = 1.2\n\n\n\ncell 4\n\nmy_list = [a1, a2, a3, a4]\n\n\n\n\n\n\ncell 0\n\nmy_list = [a1, a2, a3, a4]\n\n\n\ncell 1\n\na = 3\n\n\n\ncell 2\n\na3 = 3.0\n\n\n\ncell 3\n\na1 = 8.9\na2 = 8.3\n\n\n\ncell 4\n\na4 = 1.2\n\n\n\n\n\nDataflow navigation\n\n\nHere is our notebook:\n\n\ncell 0\n\na = 3\n\n\n\ncell 1\n\na1 = 8.9\na2 = 8.3\n\n\n\ncell 2\n\na3 = 3.0\n\n\n\ncell 3\n\na4 = 1.2\n\n\n\ncell 4\n\nmy_list = [a1, a2, a3, a4]\n\n\n\n\n‚ÄÉ‚ÄÉThis is the corresponding DAG:\n\n\n\n\n\n\n\n\n\n0\n\ncell 0\n\n\n\n1\n\ncell 1\n\n\n\n\n2\n\ncell 2\n\n\n\n\n4\n\ncell 4\n\n\n\n1-&gt;4\n\n\n\n\n\n3\n\ncell 3\n\n\n\n\n2-&gt;4\n\n\n\n\n\n3-&gt;4\n\n\n\n\n\n\n\n\n\n\n\n\nNavigating and understanding the dataflow is made easy by a number of tools:\n\nMinimap (Ctrl-Shift-i).\nDependency explorer (left menu).\nReference highlighting and jumping (hover on underlined refs, Ctrl+click to jump to defs).\n\n\n\nManaging runs\nRe-running heavy computations to update the notebooks can be costly.\nThis can be controlled by disabling/enabling:\n\nautorun on startup,\nautorun on cell change (lazy execution),\nspecific cells.\n\n\n\nMarkdown\nYou can turn cells into markdown and select raw strings and/or f-string.\n\n\n\n\n\n\nat the bottom right corner of every cell.\n\n\n\nMarkdown extensions\n\n\ncell\n\n/// details | Click for details.\n\nYou can create accordion blocks.\n///\n\n\n\ncell\n\n/// admonition | Tips\n\nYou can create info blocks.\n///\n\n\n\ncell\n\n/// attention | Be careful!\n\nYou can create warning blocks.\n///\n\n\n\nPlots\nPlotting works as you would expect.\nJavaScript interactivity also works.\n\n\ncell\n\nimport plotly.express as px\ndf = px.data.tips()\n\nfig = px.density_contour(df, x=\"total_bill\", y=\"tip\")\nfig.update_traces(contours_coloring=\"fill\", contours_showlabels = True)\nfig.show()\n\n\n\nScript\nYou can run a notebook as a script, without having to do any conversion, with:\npython notebook.py\n\n\nApps\nYou can run a notebook as an app with:\nmarimo run notebook.py\n\n\nAI\n\nCompletion\nProvided out of the box with GitHub Copilot. Tab to complete.\n\n\nGenerate cells with AI\nBox at the bottom of notebook.\n\n\nCells refactoring\nIn the menu of each cell.\n\n\nChat\nButton on the left menu opens a chat panel.\n\n\nGoing crazy\nmarimo new asks an LLM to generate a full notebook from scratch:\n\nExample:\n\nmarimo new \"Create a cool-looking 3D plot with matplotlib.\"",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Next gen Python notebooks",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_marimo_content.html#interactive-ui",
    "href": "tools/wb_marimo_content.html#interactive-ui",
    "title": "The next generation of Python notebooks",
    "section": "Interactive UI",
    "text": "Interactive UI\n\nThe marimo module\nEvery notebook loads the marimo module automatically.\nInteractive elements make use of the module, so it is convenient to create an alias:\n\n\ncell 0\n\nimport marimo as mo\n\n\n\nCreate an interactive element\nYou create an element with one of the mo.ui methods.\nCall it at the end of the cell to display it:\n\n\ncell 1\n\nslider = mo.ui.slider(start=1, stop=10, step=1)\nslider\n\n\nUI elements are defs.\n\nYou can embed it in a markdown output and format it with an f-string:\n\n\ncell 1\n\nslider = mo.ui.slider(start=1, stop=10, step=1)\nmo.md(f\"Pick a value: {slider}\")\n\n\n\nAccess the value\nYou then need to access its value in another cell:\n\n\ncell 2\n\nslider.value\n\nWhich you can also embed in some markdown:\n\n\ncell 2\n\nmo.md(f\"You picked the value: {slider.value}\")\n\n\n\nExample\nCreate a date selector element:\n\n\ncell 0\n\ndate = mo.ui.date()\nmo.md(f\"Select a date: {date}\")\n\nPrint the selected date:\n\n\ncell 1\n\nmo.md(f\"Your selected date is: {date.value}\")\n\n\n\nProgress bars\nSimilar to tqdm:\n\n\ncell\n\nimport time\n\nfor i in mo.status.progress_bar(range(50)):\n    print(i)\n    time.sleep(0.1)",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Next gen Python notebooks",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_marimo_content.html#under-the-hood",
    "href": "tools/wb_marimo_content.html#under-the-hood",
    "title": "The next generation of Python notebooks",
    "section": "Under the hood",
    "text": "Under the hood\n\nPython files for notebooks\nNotebooks get written in Python as:\n\n\nnotebook.py\n\nimport marimo\n\n__generated_with = \"&lt;some version&gt;\"\napp = marimo.App()\n\n\"&lt;your cells go here&gt;\"\n\nif __name__ == \"__main__\":\n    app.run()\n\n\n\nNotebook settings\nAdded as:\n\n\nnotebook.py\n\nimport marimo\n\n__generated_with = \"&lt;some version&gt;\"\napp = marimo.App(width=\"medium\", css_file=\"custom.css\", auto_download=[\"html\"])\n\n\"&lt;your cells go here&gt;\"\n\nif __name__ == \"__main__\":\n    app.run()\n\n\n\nWhat are cells really?\nCells are functions wrapped by an @app.cell decorator.\nThis makes them easy to turn into apps.\nWhen you create an empty cell, your .py file (let‚Äôs call it notebook.py) sees the following added:\n\n\nnotebook.py\n\n@app.cell\ndef _():\n    return\n\nNow, add in the cell:\n\n\ncell 0\n\nx = 8\ny = 9\n\nand you get in your .py file:\n\n\nnotebook.py\n\n@app.cell\ndef _():\n    x = 8\n    y = 9\n    return\n\nHide the code and the script turns into:\n\n\nnotebook.py\n\n@app.cell(hide_code=True)\ndef _():\n    x = 8\n    y = 9\n    return\n\n\n\nReferences\nCell dependencies are passed as arguments to the function:\n\n\nNotebook cells:\n\n\ncell 1\n\nprint(x)\n\n\n\n\ncell 2\n\nprint(x, y)\n\n\n\n\nCorresponding Python file:\n\n\nnotebook.py\n\n@app.cell\ndef _(x):\n    print(x)\n    return\n\n\n\nnotebook.py\n\n@app.cell\ndef _(x, y):\n    print(x, y)\n    return\n\n\n\n\n\nPrint refs and defs\nmo.defs and mo.refs output the defs and refs of a cell:\n\n\ncell 0\n\nvar = 8\nprint(f\"The defs are: {mo.defs()} and the refs are: {mo.refs()}\")\n\n\n\ncell 1\n\nvar + 7\nprint(f\"The defs are: {mo.defs()} and the refs are: {mo.refs()}\")\n\n\n\nHow is md turned into Python?\nMarkdown text is wrapped in mo.md functions:\n\n\nnotebook.py\n\n@app.cell\ndef _(mo):\n    mo.md(\n        r\"\"\"\n    ## Heading\n\n    Some markdown with some *italic* formatting.\n    \"\"\"\n    )\n    return",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Next gen Python notebooks",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_quarto.html",
    "href": "tools/wb_quarto.html",
    "title": "The new R Markdown:",
    "section": "",
    "text": "This webinar will show you how to easily create beautiful publications (webpages, pdf, websites, presentations, books‚Ä¶)‚Äîcomplete with formatted text, dynamic code and figures with Quarto.\nQuarto is the successor to R Markdown. By combining the powers of Jupyter or knitr with Pandoc, it works with R, but also with Python and Julia code blocks and it adds new functionalities to the old tool.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Quarto: the new R Markdown"
    ]
  },
  {
    "objectID": "tools/wb_quarto_slides.html#markup-languages",
    "href": "tools/wb_quarto_slides.html#markup-languages",
    "title": "The new R Markdown:",
    "section": "Markup languages",
    "text": "Markup languages\n\nControl the formatting of text documents\nPowerful but the unrendered text is visually cluttered and hard to read"
  },
  {
    "objectID": "tools/wb_quarto_slides.html#markup-languages-1",
    "href": "tools/wb_quarto_slides.html#markup-languages-1",
    "title": "The new R Markdown:",
    "section": "Markup languages",
    "text": "Markup languages\n\nControl the formatting of text documents\nPowerful but the unrendered text is visually cluttered and hard to read\n\n\nExample: Tex‚Äîoften with macro package LaTeX‚Äîto create pdfs\n\n\\documentclass{article}\n\\title{My title}\n\\author{My name}\n\\usepackage{datetime}\n\\newdate{date}{24}{11}{2022}\n\\date{\\displaydate{date}}\n\\begin{document}\n \\maketitle\n \\section{First section}\n Some text in the first section.\n\\end{document}"
  },
  {
    "objectID": "tools/wb_quarto_slides.html#markup-languages-2",
    "href": "tools/wb_quarto_slides.html#markup-languages-2",
    "title": "The new R Markdown:",
    "section": "Markup languages",
    "text": "Markup languages\n\nControl the formatting of text documents\nPowerful but the unrendered text is visually cluttered and hard to read\n\n\nExample: HTML‚Äîoften with css/scss files‚Äîto create webpages\n\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en-US\"&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"utf-8\" /&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width\" /&gt;\n    &lt;title&gt;My title&lt;/title&gt;\n    &lt;address class=\"author\"&gt;My name&lt;/address&gt;\n    &lt;input type=\"date\" value=\"2022-11-24\" /&gt;\n  &lt;/head&gt;\n  &lt;h1&gt;First section&lt;/h1&gt;\n  &lt;body&gt;\n    Some text in the first section.\n  &lt;/body&gt;\n&lt;/html&gt;"
  },
  {
    "objectID": "tools/wb_quarto_slides.html#markdown",
    "href": "tools/wb_quarto_slides.html#markdown",
    "title": "The new R Markdown:",
    "section": "Markdown",
    "text": "Markdown\n\nRemoves the visual clutter and makes texts readable prior to rendering\nCreated in 2004\nBy now quasi-ubiquitous\nInitially created for webpages\nRaw HTML can be inserted when easy syntax falls short\n\n\nPandoc‚Äôs extended Markdown\nPandoc (free and open-source markup formats converter) supports an extended Markdown syntax with functionality for figures, tables, callout blocks, LaTeX equations, citations‚Ä¶\nRemains as readable as basic Markdown, but can be rendered in any format (pdf, books, entire websites, Word documents‚Ä¶)"
  },
  {
    "objectID": "tools/wb_quarto_slides.html#markdown-1",
    "href": "tools/wb_quarto_slides.html#markdown-1",
    "title": "The new R Markdown:",
    "section": "Markdown",
    "text": "Markdown\n\nRemoves the visual clutter and makes texts readable prior to rendering\nCreated in 2004\nBy now quasi-ubiquitous\nInitially created for webpages\nRaw HTML can be inserted when easy syntax falls short\n\n\nPrevious example using Pandoc‚Äôs Markdown:\n\n---\ntitle: My title\nauthor: My name\ndate: 2022-11-24\n---\n# First section\nSome text in the first section."
  },
  {
    "objectID": "tools/wb_quarto_slides.html#how-it-works",
    "href": "tools/wb_quarto_slides.html#how-it-works",
    "title": "The new R Markdown:",
    "section": "How it works",
    "text": "How it works\nCode blocks are executed by Jupyter (Python or Julia) or knitr (R), then pandoc renders the document into any format\n\nJulia/Python:\n From Quarto documentation\nR:\n From Quarto documentation"
  },
  {
    "objectID": "tools/wb_quarto_slides.html#how-it-works-1",
    "href": "tools/wb_quarto_slides.html#how-it-works-1",
    "title": "The new R Markdown:",
    "section": "How it works",
    "text": "How it works\nCode blocks are executed by Jupyter (Python or Julia) or knitr (R), then pandoc renders the document into any format\nCan be used from .qmd text files or directly from RStudio or Jupyter notebooks."
  },
  {
    "objectID": "tools/wb_quarto_slides.html#supported-languages",
    "href": "tools/wb_quarto_slides.html#supported-languages",
    "title": "The new R Markdown:",
    "section": "Supported languages",
    "text": "Supported languages\nSyntax highlighting in pretty much any language\n\nExecutable code blocks in Python, R, Julia, Observable JS\n\n\nOutput formats\n- HTML\n- PDF\n- MS Word\n- OpenOffice\n- ePub\n- Revealjs\n- PowerPoint\n- Beamer\n- GitHub Markdown\n- CommonMark\n- Hugo\n- Docusaurus\n- Markua\n- MediaWiki\n- DokuWiki\n- ZimWiki\n- Jira Wiki\n- XWiki\n- JATS\n- Jupyter\n- ConTeXt\n- RTF\n- reST\n- AsciiDoc\n- Org-Mode\n- Muse\n- GNU\n- Groff"
  },
  {
    "objectID": "tools/wb_quarto_slides.html#document-structure-syntax-front-matter",
    "href": "tools/wb_quarto_slides.html#document-structure-syntax-front-matter",
    "title": "The new R Markdown:",
    "section": "Document structure & syntax: front matter",
    "text": "Document structure & syntax: front matter\nWritten in YAML\nSets the options for the document. Let‚Äôs see a few examples.\n\n\nCan be very basic:\n\n---\ntitle: \"My title\"\nauthor: \"My name\"\nformat: html\n---"
  },
  {
    "objectID": "tools/wb_quarto_slides.html#document-structure-syntax-front-matter-1",
    "href": "tools/wb_quarto_slides.html#document-structure-syntax-front-matter-1",
    "title": "The new R Markdown:",
    "section": "Document structure & syntax: front matter",
    "text": "Document structure & syntax: front matter\nWritten in YAML\nSets the options for the document. Let‚Äôs see a few examples.\n\nOr more sophisticated:\n\n---\ntitle: \"Some title\"\nsubtitle: \"Some subtitle\"\ninstitute: \"Simon Fraser University\"\ndate: \"2022-11-24\"\nexecute:\n  error: true\n  echo: true\nformat:\n  revealjs:\n    theme: [default, custom.scss]\n    highlight-style: monokai\n    code-line-numbers: false\n    embed-resources: true\n---"
  },
  {
    "objectID": "tools/wb_quarto_slides.html#document-structure-syntax-text",
    "href": "tools/wb_quarto_slides.html#document-structure-syntax-text",
    "title": "The new R Markdown:",
    "section": "Document structure & syntax: text",
    "text": "Document structure & syntax: text\nWritten in Pandoc‚Äôs extended Markdown"
  },
  {
    "objectID": "tools/wb_quarto_slides.html#document-structure-syntax-code-blocks",
    "href": "tools/wb_quarto_slides.html#document-structure-syntax-code-blocks",
    "title": "The new R Markdown:",
    "section": "Document structure & syntax: code blocks",
    "text": "Document structure & syntax: code blocks\nSyntax highlighting only:\n```{.language}\ncode\n```\n\nSyntax highlighting and code execution:\n```{language}\ncode\n```\n\n\nOptions can be added to individual blocks:\n```{language}\n#| option: value\n\ncode\n```"
  },
  {
    "objectID": "tools/wb_quarto_slides.html#rendering",
    "href": "tools/wb_quarto_slides.html#rendering",
    "title": "The new R Markdown:",
    "section": "Rendering",
    "text": "Rendering\nTwo commands:\nquarto render file.qmd     # Renders the document\nquarto preview file.qmd    # Displays a live preview"
  },
  {
    "objectID": "tools/wb_quarto_slides.html#some-advantages-of-quarto",
    "href": "tools/wb_quarto_slides.html#some-advantages-of-quarto",
    "title": "The new R Markdown:",
    "section": "Some advantages of Quarto",
    "text": "Some advantages of Quarto\nGeneral considerations\n\nExtremely well documented\nSolid team behind the work\nFree and open source\nUses only well established and well tested tools"
  },
  {
    "objectID": "tools/wb_quarto_slides.html#some-advantages-of-quarto-1",
    "href": "tools/wb_quarto_slides.html#some-advantages-of-quarto-1",
    "title": "The new R Markdown:",
    "section": "Some advantages of Quarto",
    "text": "Some advantages of Quarto\nWebpages/websites\n\nFast, easy, and clean\nSites work on screens of any size out of the box (uses Bootstrap 5)\nCan be customized with CSS/SCSS, but good out of the box\nCode blocks can have a copy button\nGreat search functionality\nSite/pages can be hosted anywhere easily"
  },
  {
    "objectID": "tools/wb_quarto_slides.html#some-advantages-of-quarto-2",
    "href": "tools/wb_quarto_slides.html#some-advantages-of-quarto-2",
    "title": "The new R Markdown:",
    "section": "Some advantages of Quarto",
    "text": "Some advantages of Quarto\nAdvantages of code execution\n\nPeople can see code outputs without running code\nForces to test every bit of code\nNo need for a complex system linking code scripts with publishing documents"
  },
  {
    "objectID": "tools/wb_quarto_slides.html#resources",
    "href": "tools/wb_quarto_slides.html#resources",
    "title": "The new R Markdown:",
    "section": "Resources",
    "text": "Resources\nOfficial sites\nWebsite\nRepo\nDocumentation index\nInstallation\nYou can find information in the Quarto documentation or in our previous workshop on Quarto\nBasic examples\nYou can find several examples in our previous workshop on Quarto"
  },
  {
    "objectID": "tools/wb_tools2.html",
    "href": "tools/wb_tools2.html",
    "title": "A few more of our favourite tools",
    "section": "",
    "text": "In a previous webinar, we presented three of our favourite command line tools. Today, we will introduce other tools we find really useful in our daily workflow:\n\nlazygit: a wonderful terminal UI for Git,\nbat: a great syntax highlighter,\nripgrep: a fast alternative to grep,\nfd: a /really/ fast alternative to find,\npass: a command line password manager.\n\nAlong the way, I will use a few other neat command line tools such as hyperfine‚Äîfor sophisticated benchmarking‚Äîand diff-so-fancy‚Äîwhich makes your diffs a lot more readable.\nFor the Emacs users among you, we will finish the workshop with two Emacs utilities:\n\nTRAMP: a remote file access system,\nHelm: a ‚Äúframework for incremental completions and narrowing selections‚Äù.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "More command line tools"
    ]
  },
  {
    "objectID": "tools/wb_tools3_content.html",
    "href": "tools/wb_tools3_content.html",
    "title": "Modern shell utilities",
    "section": "",
    "text": "Content from the webinar slides for easier browsing.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_tools3_content.html#how-to-choose-tools",
    "href": "tools/wb_tools3_content.html#how-to-choose-tools",
    "title": "Modern shell utilities",
    "section": "How to choose tools?",
    "text": "How to choose tools?\n\nPopularity (GitHub stars)\nIs it maintained? (date of last commit)\nNumber of maintainers\nHow polished is the documentation?\nHow fast is it? (what language is it written in? Shell/Python will be slower, compiled languages (Rust, C, Go) will be faster.)",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_tools3_content.html#ls-in-colours-eza",
    "href": "tools/wb_tools3_content.html#ls-in-colours-eza",
    "title": "Modern shell utilities",
    "section": "ls in colours: eza",
    "text": "ls in colours: eza\n\nWhat is eza?\neza is a replacement for ls.\n\nAdds colours.\nBetter default options.\nAdd tree feature.\n\n\n\nInstallation\n\nOn your machine\nInstructions here.\n\n\nOn the Alliance clusters\neza is not installed on the Alliance clusters, so you have to install it locally under your own user. This is easy to do because it is written in Rust and can be installed with the Rust package manager.\nLoad a Rust module, install eza, and make sure ~/.cargo/bin is in your path:\nmodule load rust/1.76.0\ncargo install eza\n\nYou only need to do this once. Once installed, eza will be accessible on subsequent sessions.\n\n\n\n\nUsage\neza\n‚ûî Different colours for directories, symlinks, and different types of files and better defaults (compare ls -al with eza -al).\neza by default shows the output in a human readable format and without the group.\nThe flags are similar to those of ls with the additional -T, equivalent to running the tree utility:\neza -T python/\n\n\nAlias\nYou can alias it to ls by adding to your .bashrc or .zshrc file:\nalias ls=eza\nIf you ever want to use the true ls utility, you can do so with \\ls.\n\n\nAlternative\nIf you want a simpler and more lightweight way to add colours to your ls outputs, you can look at LS_COLORS (I did this for years until I found eza).\nTo install it locally in the Alliance clusters, you download and uncompress a script, and copy it to a proper location:\nmkdir ./LS_COLORS &&\n    curl -L https://api.github.com/repos/trapd00r/LS_COLORS/tarball/master |\n        tar xzf - --directory=./LS_COLORS --strip=1 &&\n    mkdir -p ~/.local/share &&\n    cp ~/LS_COLORS/lscolors.sh ~/.local/share &&\n    rm -r ~/LS_COLORS\nThen you add to your .bashrc/.zshrc file the sourcing of the script and an alias to ls:\nsource ~/.local/share/lscolors.sh\nalias ls='ls --color'",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_tools3_content.html#a-cat-with-wings-bat",
    "href": "tools/wb_tools3_content.html#a-cat-with-wings-bat",
    "title": "Modern shell utilities",
    "section": "A cat with wings: bat",
    "text": "A cat with wings: bat\n\nWhat is bat?\nbat is a replacement for cat.\n\nAdds syntax highlighting for most programming languages.\nAdds line numbers.\nAdds pager-like search.\nAdds pager-like navigation.\n\n\n\nInstallation\n\nOn your machine\nInstructions here.\n\n\nOn the Alliance clusters\nbat is already installed on the Alliance clusters.\n\n\n\nUsage\nUse bat as you would use cat:\nbat /home/marie/parvus/prog/progpy/pydoc/basics.py\nand you are in your default pager.\nAmong other options, you can disable the frame with -n and also remove the line numbers with -p.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_tools3_content.html#faster-find-fd",
    "href": "tools/wb_tools3_content.html#faster-find-fd",
    "title": "Modern shell utilities",
    "section": "Faster find: fd",
    "text": "Faster find: fd\n\nWhat is fd?\nfd is a replacement for find.\n\nWritten in Rust, automatic parallelism ‚ûî with vastly improved performance.\nMore friendly syntax.\nBy default excludes binaries as well as hidden files and directories.\nBy default excludes patterns from .gitignore or other .ignore files.\n\n\n\nInstallation\n\nOn your machine\nInstructions here.\n\n\nOn the Alliance clusters\nfd is already installed on the Alliance clusters.\n\n\n\nBasic usage\nSearch file names for a pattern recursively in current directory:\nfd jx\n\nfd uses regexp by default, so you can use pattern symbols:\nfd jx.*txt\n\nSearch file names recursively in another directory:\nfd top bash/\n\n\nPrint all files in some directory\nCurrent directory:\nfd\nAnother directory:\nfd . bash/\n\n\nOptions\nSearch for files with a particular file extension:\nfd -e txt\nUse a globbing pattern instead of regexp:\nfd -g wb* bash/\nExecute command for each result of fd in parallel:\nfd top bash/ -x rg layout\nExecute command once with all results of fd as arguments:\nfd top bash/ -X rg layout\n\n\nExcluded files and directories\nBy default, fd excludes hidden files/directories and patterns in .gitignore (you can disable this with -H and -I respectively).\nThis makes fd combined with tree sometimes more useful than tree alone.\nCompare tree bash/ with:\nfd . bash/ | tree --fromfile\n\nYou can make this a function:\nft () { fd $@ | tree --fromfile }\n\nExclude additional directories or patterns:\nfd -E *.txt -E img/ . bash/\n\n\nMy personal alias\nI prefer to disable the default settings and exclude patterns based on a file I created:\nalias fd='fd -u --ignore-file /home/marie/.fdignore'",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_tools3_content.html#rip-grep-ripgrep",
    "href": "tools/wb_tools3_content.html#rip-grep-ripgrep",
    "title": "Modern shell utilities",
    "section": "RIP grep: ripgrep",
    "text": "RIP grep: ripgrep\n\nWhat is ripgrep?\nripgrep provides the rg utility‚Äîa replacement for grep.\n\nWritten in Rust, automatic parallelism ‚ûî with vastly improved performance.\nBy default excludes patterns from .gitignore or other .ignore files.\nBy default excludes binaries as well as hidden files and directories.\nBy default doesn‚Äôt follow symlinks\n\n\n\nInstallation\n\nOn your machine\nInstructions here.\n\n\nOn the Alliance clusters\nrg is already installed on the Alliance clusters.\n\n\n\nUsage\nSearch lines in a file matching a pattern:\nrg colour /home/marie/parvus/prog/mint/bash/wb_tools3_slides.qmd\nSearch lines matching pattern in all files in current directory (recursively):\nrg colour\nrg and fd follow the same principles:\n\nUse regexp by default.\nUse globbing pattern instead with -g.\nSearch recursively by default.\nSame excluded files.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_tools3_content.html#smart-cd-zoxide",
    "href": "tools/wb_tools3_content.html#smart-cd-zoxide",
    "title": "Modern shell utilities",
    "section": "Smart cd: zoxide",
    "text": "Smart cd: zoxide\n\nWhat is zoxide?\nzoxide allows to easily jump to any directory.\n\n\nInstallation\n\nOn your machine\nInstructions here.\n\nfzf (see below) adds cool functionality to it, so you might want to install it as well.\n\n\n\nOn the Alliance clusters\nzoxide is not installed on the Alliance clusters, but local installation is easy.\n\nInstall the binary in ~/.local/bin with:\n\ncurl -sSfL https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh | sh\n\nAdd ~/.local/bin to your PATH by adding to your .bashrc:\n\nexport PATH=$PATH:~/.local/bin\n\nAdd to your .bashrc file (for Zsh, replace bash with zsh in .zshrc):\n\neval \"$(zoxide init bash)\"\n\n\n\nChoose a different command name\nUse this instead to use the command of your choice (e.g.¬†j and ji) instead of the default z and zi:\neval \"$(zoxide init --cmd j bash)\"\n\n\nUsage\nType z (or whatever command you chose) instead of cd.\nYou can simplify the path to just a few characters.\nIf there are multiple locations matching your entry, the algorithm will chose the highest ranking one based on your visit frequency and how recently you visited a path.\nThis means that you can visit your usual places with a few key strokes. For less frequent places, add more info.\nFinally, if you want to choose amongst all possible options in a completion framework, use zi instead and zoxide will open fzf.\n\n\nAlternative\nA tool that served me well until someone pointed zoxide to me is autojump.\n\nInstallation\nInstructions here for your machine.\nautojump is installed on the Alliance clusters, but you need add to your .bashrc or .zshrc:\n[[ -s $EPREFIX/etc/profile.d/autojump.sh ]] && source $EPREFIX/etc/profile.d/autojump.sh\n\n\nUsage\nSimilar to zoxide but you first need to visit directories so that they get entered in a database.\nj is a wrapper for autojump, jc jumps to subdirectories of current directory.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_tools3_content.html#fuzzy-finding-with-fzf",
    "href": "tools/wb_tools3_content.html#fuzzy-finding-with-fzf",
    "title": "Modern shell utilities",
    "section": "Fuzzy finding with fzf",
    "text": "Fuzzy finding with fzf\n\nWhat is fzf?\nfzf allows to find elements of any list through incremental completion and fuzzy matching. It can be paired with any number of commands.\n\n\nInstallation\n\nOn your machine\nInstructions here.\n\n\nOn the Alliance clusters\nfzf is already installed on the Alliance clusters.\nTo get fzf kbds and fuzzy completion in your shell, add to your .bashrc:\neval \"$(fzf --bash)\"\nand/or your .zshrc:\nsource &lt;(fzf --zsh)\n\n\n\nDirect usage\nIf you run fzf directly, it will search the current directory recursively, do a narrowing selection, and print the result:\nfzf\nYou can make use of fd to remove unnecessary entries:\nexport FZF_DEFAULT_COMMAND='fd -u --ignore-file /home/marie/.fdignore'\n\n\nfzf kbds\nThere are 3 default kbds:\n\nCtl+t ‚ûî paste selected file/dir into the command.\nCtl+r ‚ûî paste selected command from history into the command.\nAlt+c ‚ûî cd into selected dir.\n\n\n\nPipe to fzf\nYou can also pipe the output of any command that returns a list of elements into fzf.\nLook for a file/directory:\nls | fzf\nMany flags to select order of entries, type of completion, preview, case-sensitivity, and more.\nLook for a running process:\nps -ef | fzf --cycle -i -e +s --tac --reverse\nOf course, you can create aliases and functions using fzf.\nYou can put the previous command into an alias:\nalias proc='ps -ef | fzf --cycle -i -e +s --tac --reverse'\nOr write a function to kill a running process:\nproc_kill () {\n    local pid\n    pid=$(ps -ef |\n              sed 1d |\n              fzf --cycle --reverse -i -e -m --bind \"ctrl-o:toggle-all\" \\\n                  --header \"Tab: toggle, C-o: toggle-all\" |\n              awk '{print $2}')\n    echo $pid | xargs kill -${1:-15}\n}\nSearch your command history:\nhis () {\n    fc -ln 1 |\n        rg -v '^q$|^x$|^vs$|^ek .*$|^zoom$|^c$|^cca$|^rs ...$|^hobu$|^cd$|^kzo$|^ih.?$|^zre$|^j m$|^y$|^g$|^-$|^auradd$' |\n        fzf --cycle -i -e +s --tac --reverse |\n        sed 's/ *[0-9]* *//'\n}\nSearch your command history and run the selection:\nhis_run () {\n    $(fc -ln 1 |\n          rg -v '^q$|^x$|^vs$|^ek .*$|^zoom$|^c$|^cca$|^rs ...$|^hobu$|^cd$|^kzo$|^ih.?$|^zre$|^j m$|^y$|^g$|^-$|^auradd$' |\n          fzf --cycle -i -e +s --tac --reverse |\n          sed 's/ *[0-9]* *//')\n}\nAn example with preview to open the selection with emacsclient:\nie () {\n    emacsclient -c $(\n        fzf --cycle -i -e --reverse \\\n            --preview=\"source-highlight --failsafe -f esc256 -i {}\"\n                )\n}",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_tools3_content.html#file-system-tuis",
    "href": "tools/wb_tools3_content.html#file-system-tuis",
    "title": "Modern shell utilities",
    "section": "File system TUIs",
    "text": "File system TUIs\n\nWhat is a TUI?\nTerminal user interfaces (TUIs) are the predecessors to graphical user interfaces (GUIs) which are entirely text based and run in terminals.\nThey have remained very popular among command line aficionados because they are fast, efficient, powerful, and keyboard-driven, while being friendly and visual.\nFantastic modern ones keep being built for tasks as diverse as interfaces to Git, music players, games, emails, dashboards, and, for our purpose here, file system management.\n\n\nOlder popular file system TUIs\nThere are many file system TUIs and all of them are actually really good. The two most notable ones used to be:\n\nranger\n\nExtremely sophisticated, easy to customize, tons of features.\n\nBuilt in Python, it can be slow for operations in directories with thousands of files.\n\n\nnnn\n\nMinimalist and very fast (written in C).\n\nNot easy to customize (many customizations require compiling from source). Most functionalities rely on plugins that need to be installed. Not easy to get started with.\n\n\n\nThe new kid: yazi\nyazi is a brand new fs TUI that has quickly become the most popular.\nIt is extremely modern, very fast (written in Rust), very well documented, intuitive, easy to customize, and integrates with modern utilities such as fd, rg, zoxide, and fzf out of the box.\nOnly at version 0.4, it is not fully mature yet, but it has already more stars on GitHub than ranger and nnn because it combines ease of customization and sophistication with speed.\n\n\nAlternatives\nIn decreasing number of stars on GitHub:\n\nbroot\nsuperfile\nlf\nxplr\nfff (now archived)\nvifm\nmc",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_tools3_content.html#z-shell-plugins",
    "href": "tools/wb_tools3_content.html#z-shell-plugins",
    "title": "Modern shell utilities",
    "section": "Z shell plugins",
    "text": "Z shell plugins\n\nMy 3 favourite plugins\nThere are many plugins for Z shell and the (very bloated) Oh My Zsh, but I am sticking to 3 great plugins inspired or directly coming from the Fish shell:\n\nSyntax highlighting\nAutosuggestions\nHistory substring search\n\n\n\nInstallation\nAll plugins can be installed (info in their README) or simply Git cloned. zsh-syntax-highlighting is already installed on the Alliance clusters, so you only need to clone the other two:\n# create a directory to store the scripts\nmkdir ~/.zsh_plugins\n# autosuggestions\ngit clone https://github.com/zsh-users/zsh-autosuggestions.git ~/.zsh_plugins/zsh-autosuggestions\n# history substring search\ngit clone https://github.com/zsh-users/zsh-history-substring-search.git ~/.zsh_plugins/zsh-history-substring-search\nThen you need to source them (including zsh-syntax-highlighting), so add to your .zshrc file:\nsource $EPREFIX/usr/share/zsh/site-functions/zsh-syntax-highlighting.zsh\nsource ~/.zsh_plugins/zsh-history-substring-search/zsh-history-substring-search.zsh\nsource ~/.zsh_plugins/zsh-autosuggestions/zsh-autosuggestions.zsh\n\n\nUsage\nYou now have syntax highlighting in your shell inputs.\nTo use the history substring search, start typing some command then press Alt+p or Alt+n. It will cycle through all entries in your history that start that way\nFinally, the autosuggestion will suggest commands based on your history and/or classic suggestions. Accept the whole command with Ctl+e or a single word with Alt+f.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "Modern shell utilities",
      "<em>Slides content</em>"
    ]
  },
  {
    "objectID": "tools/wb_typst.html",
    "href": "tools/wb_typst.html",
    "title": "Typst",
    "section": "",
    "text": "Typst is a new open-source markup typesetting system which aims to be as powerful as LaTeX with a much faster compiler, a much simpler installation, much fewer moving parts, and a much easier learning curve.\nThe straightforward and unobtrusive syntax allows for math formulae, tables, graphs, bibliography management, and presentation mode.\nScripting (conditionals, loops, functions, and methods) as well as data loading produce reactive documents with automatically updated tables or plots.\nFinally, Typst integrates perfectly with Quarto.\nWhile this tool is new and still in active development, it already has close to 50k stars on GitHub and a contributors pool of close to 400 people, making it a very popular tool embraced by the scientific community.\nIf you are using a word processing program (e.g.¬†MS Word) to write your thesis, articles, and other scientific documents, Typst can easily allow you to switch to a text-based approach with all the benefits that this entails (version control with Git, use of a powerful text editor, embedding code in documents, etc.).\n\nComing up in spring 2026.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "A new typesetting system"
    ]
  },
  {
    "objectID": "tools/wb_uv.html",
    "href": "tools/wb_uv.html",
    "title": "A tool to rule them all:",
    "section": "",
    "text": "Despite being the most popular programming language, Python has never had a good package and version manager. Some languages come with an internal manager (e.g.¬†R, Julia) while others come with well-built command line managers (e.g.¬†Cargo for Rust). Python on the other hand has seen the development of an ever-growing and never-satisfactory suite of tools to manage its packages, versions, projects, and virtual environments: pip, pipx, pipenv, poetry, pyenv, venv, virtualenv to name just a few.\nIn February 2024, Astral might have finally put an end to the jumble when they launched uv, a fast and well-documented tool written in Rust which elegantly handles the gamut of tasks associated with Python versions, packages, and projects.\nIn this webinar, I will show you how to use uv to manage Python projects, packages, virtual environments, versions, and more.\n\nSlides (Click and wait: this reveal.js presentation may take a little time to load.) \n\n Slides content for easier browsing.",
    "crumbs": [
      "Tools",
      "<b><em>Webinars</em></b>",
      "uv package manager"
    ]
  },
  {
    "objectID": "tools/wb_uv_slides.html#a-cluttered-toolkit",
    "href": "tools/wb_uv_slides.html#a-cluttered-toolkit",
    "title": "A tool to rule them all",
    "section": "A cluttered toolkit",
    "text": "A cluttered toolkit"
  },
  {
    "objectID": "tools/wb_uv_slides.html#age-of-rust",
    "href": "tools/wb_uv_slides.html#age-of-rust",
    "title": "A tool to rule them all",
    "section": "Age of Rust",
    "text": "Age of Rust"
  },
  {
    "objectID": "tools/wb_uv_slides.html#uv",
    "href": "tools/wb_uv_slides.html#uv",
    "title": "A tool to rule them all",
    "section": "uv",
    "text": "uv\n\nUniversal tool\nReally fast\nExcellent dependency resolution with PubGrub (you guessed it, also written in Rust)\nDependency deduplication"
  },
  {
    "objectID": "tools/wb_uv_slides.html#python-versions-on-alliance-clusters-uv",
    "href": "tools/wb_uv_slides.html#python-versions-on-alliance-clusters-uv",
    "title": "A tool to rule them all",
    "section": "Python versions on Alliance clusters (uv)",
    "text": "Python versions on Alliance clusters (uv)\nUse module\n\nList available Python versions:\n\nmodule spider python\n\nCheck how to load a particular version:\n\nmodule spider python/3.12.4\n\nLoad a particular version:\n\nmodule load python/3.12.4"
  },
  {
    "objectID": "tools/wb_uv_slides.html#python-packages-on-alliance-clusters-uv",
    "href": "tools/wb_uv_slides.html#python-packages-on-alliance-clusters-uv",
    "title": "A tool to rule them all",
    "section": "Python packages on Alliance clusters (uv)",
    "text": "Python packages on Alliance clusters (uv)\nCreate a Python virtual environment:\npython -m venv ~/env\nActivate it:\nsource ~/env/bin/activate\nUpdate pip from wheel:\npython -m pip install --upgrade pip --no-index\nUse pip with --no-index to use wheels whenever possible:\npython -m pip install --no-index jax[cuda12] jax-ai-stack[grain]"
  },
  {
    "objectID": "tools/wb_uv_slides.html#install-uv",
    "href": "tools/wb_uv_slides.html#install-uv",
    "title": "A tool to rule them all",
    "section": "Install uv",
    "text": "Install uv"
  },
  {
    "objectID": "tools/wb_uv_slides.html#help",
    "href": "tools/wb_uv_slides.html#help",
    "title": "A tool to rule them all",
    "section": "Help",
    "text": "Help\nList of commands and options:\nuv\nList of options:\nuv &lt;command&gt; -h    # e.g. uv init -h\nMan page:\nuv help &lt;command&gt;  # e.g. uv help init"
  },
  {
    "objectID": "tools/wb_uv_slides.html#drop-in-replacement",
    "href": "tools/wb_uv_slides.html#drop-in-replacement",
    "title": "A tool to rule them all",
    "section": "Drop-in replacement",
    "text": "Drop-in replacement\nYou can add uv in front of your usual venv and pip commands\nThis actually runs uv (and neither pip nor venv) so you get the speedup, but it keeps everything compatible"
  },
  {
    "objectID": "tools/wb_uv_slides.html#create-a-virtual-env",
    "href": "tools/wb_uv_slides.html#create-a-virtual-env",
    "title": "A tool to rule them all",
    "section": "Create a virtual env",
    "text": "Create a virtual env\nuv venv\n\nWith specific Python version:\n\nuv venv --python 3.12\nBy default, the virtual env is called .venv. If you don‚Äôt change its name, uv will use it automatically so you don‚Äôt need to source it"
  },
  {
    "objectID": "tools/wb_uv_slides.html#install-packages-in-virtual-env",
    "href": "tools/wb_uv_slides.html#install-packages-in-virtual-env",
    "title": "A tool to rule them all",
    "section": "Install packages in virtual env",
    "text": "Install packages in virtual env\nuv pip install jax flax\n\nFrom GitHub repo:\n\nuv pip install \"git+https://github.com/jax-ml/jax\"\nuv pip install \"git+https://github.com/jax-ml/jax@main\"\nuv pip install \"git+https://github.com/jax-ml/jax@766e68c4813a30e29b4fcefaa3253a42d0e197be\"\n\nFrom requirements.txt or pyproject.toml files:\n\nuv pip install -r requirements.txt\nuv pip install -r pyproject.toml"
  },
  {
    "objectID": "tools/wb_uv_slides.html#all-your-usual-commands-work",
    "href": "tools/wb_uv_slides.html#all-your-usual-commands-work",
    "title": "A tool to rule them all",
    "section": "All your usual commands work",
    "text": "All your usual commands work\nuv pip uninstall jax\nuv pip list\nuv pip freeze\n‚Ä¶"
  },
  {
    "objectID": "tools/wb_uv_slides.html#automatic-installation",
    "href": "tools/wb_uv_slides.html#automatic-installation",
    "title": "A tool to rule them all",
    "section": "Automatic installation",
    "text": "Automatic installation\nMissing Python versions are automatically installed when required\n\nExample:\n\nuv venv --python 3.12\n\nIf Python 3.12 is missing, uv will install it during the creation of this virtual env"
  },
  {
    "objectID": "tools/wb_uv_slides.html#install-python",
    "href": "tools/wb_uv_slides.html#install-python",
    "title": "A tool to rule them all",
    "section": "Install Python",
    "text": "Install Python\nPython versions can also be installed explicitly:\nuv python install 3.12.3\nuv python install '&gt;=3.8,&lt;3.10'\n\nSpecific implementations (default is cpython):\n\nuv python install pypy\nuv python install 'pypy&gt;=3.8,&lt;3.10'"
  },
  {
    "objectID": "tools/wb_uv_slides.html#manage-versions",
    "href": "tools/wb_uv_slides.html#manage-versions",
    "title": "A tool to rule them all",
    "section": "Manage versions",
    "text": "Manage versions\nView installed and available versions:\nuv python list\nUninstall Python version:\nuv python uninstall 3.10\n\nNoe that this is a lot more convenient than pyenv which requires the exact Python version number to uninstall (e.g.¬†pyenv uninstall 3.10.6)"
  },
  {
    "objectID": "tools/wb_uv_slides.html#initialize-projects",
    "href": "tools/wb_uv_slides.html#initialize-projects",
    "title": "A tool to rule them all",
    "section": "Initialize projects",
    "text": "Initialize projects\nuv init my_project\nInitialized project `my-project` at `/home/marie/my_project`\n\nWith specific Python version:\n\nuv init --python 3.12 my_project\n\nCustomize which files get created:\n\nuv init --no-readme --no-description"
  },
  {
    "objectID": "tools/wb_uv_slides.html#project-structure",
    "href": "tools/wb_uv_slides.html#project-structure",
    "title": "A tool to rule them all",
    "section": "Project structure",
    "text": "Project structure\n\neza -aT my_project\n\nmy_project\n‚îú‚îÄ‚îÄ .python-version\n‚îú‚îÄ‚îÄ main.py\n‚îú‚îÄ‚îÄ pyproject.toml\n‚îú‚îÄ‚îÄ README.md\n‚îî‚îÄ‚îÄ uv.lock\n\n\n\nbat -p my_project/pyproject.toml\n\n[project]\nname = \"my-project\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nreadme = \"README.md\"\nrequires-python = \"&gt;=3.13\"\ndependencies = []"
  },
  {
    "objectID": "tools/wb_uv_slides.html#add-dependencies",
    "href": "tools/wb_uv_slides.html#add-dependencies",
    "title": "A tool to rule them all",
    "section": "Add dependencies",
    "text": "Add dependencies\nYou need to cd into the project, then you can add dependencies:\ncd my_project\nuv add polars matplotlib\nThis creates a virtual env called .venv and a uv.lock:\neza -aTL 1\n\n\nmy_project\n‚îú‚îÄ‚îÄ .python-version\n‚îú‚îÄ‚îÄ main.py\n‚îú‚îÄ‚îÄ pyproject.toml\n‚îú‚îÄ‚îÄ README.md\n‚îî‚îÄ‚îÄ uv.lock\n\n\nHere again, no need to source the virtual env as long as you use uv"
  },
  {
    "objectID": "tools/wb_uv_slides.html#project-file",
    "href": "tools/wb_uv_slides.html#project-file",
    "title": "A tool to rule them all",
    "section": "Project file",
    "text": "Project file\nGets populated automatically with dependencies:\nbat -p pyproject.toml\n\n\n[project]\nname = \"my-project\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nreadme = \"README.md\"\nrequires-python = \"&gt;=3.13\"\ndependencies = []"
  },
  {
    "objectID": "tools/wb_uv_slides.html#list-explicitly-installed-dependencies",
    "href": "tools/wb_uv_slides.html#list-explicitly-installed-dependencies",
    "title": "A tool to rule them all",
    "section": "List explicitly installed dependencies",
    "text": "List explicitly installed dependencies\nuv tree -d 1\n\n\nUsing CPython 3.13.7 interpreter at: /usr/bin/python3.13\nResolved 1 package in 0.57ms\nmy-project v0.1.0"
  },
  {
    "objectID": "tools/wb_uv_slides.html#list-all-dependencies",
    "href": "tools/wb_uv_slides.html#list-all-dependencies",
    "title": "A tool to rule them all",
    "section": "List all dependencies",
    "text": "List all dependencies\nuv pip list\n\n\nUsing Python 3.12.10 environment at: /home/marie/.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu\nPackage Version\n------- -------\npip     24.3.1"
  },
  {
    "objectID": "tools/wb_uv_slides.html#manage-dependencies",
    "href": "tools/wb_uv_slides.html#manage-dependencies",
    "title": "A tool to rule them all",
    "section": "Manage dependencies",
    "text": "Manage dependencies\nUpdate all dependencies in lock file and virtual env:\nuv sync -U\nRemove dependencies:\nuv remove matplotlib"
  },
  {
    "objectID": "tools/wb_uv_slides.html#python-versions-pyenv-vs-uv",
    "href": "tools/wb_uv_slides.html#python-versions-pyenv-vs-uv",
    "title": "A tool to rule them all",
    "section": "Python versions pyenv vs uv",
    "text": "Python versions pyenv vs uv\npyenv\npyenv install 3.10\n\n\n\n\n\nuv\nuv python install 3.10\nInstalled Python 3.10.17 in 1.49s\n\nYes, uv brags about how fast it installs things‚Ä¶ but it can!"
  },
  {
    "objectID": "tools/wb_uv_slides.html#packages-pip-vs-uv-pip",
    "href": "tools/wb_uv_slides.html#packages-pip-vs-uv-pip",
    "title": "A tool to rule them all",
    "section": "Packages: pip vs uv pip",
    "text": "Packages: pip vs uv pip\npip\nCreate virtual env:\npython -m venv .venv\nActivate it:\nsource .venv/bin/activate\nUpdate pip:\npython -m pip install --upgrade pip\nInstall package:\npython -m pip install jax-ai-stack"
  },
  {
    "objectID": "tools/wb_uv_slides.html#packages-pip-vs-uv-pip-1",
    "href": "tools/wb_uv_slides.html#packages-pip-vs-uv-pip-1",
    "title": "A tool to rule them all",
    "section": "Packages: pip vs uv pip",
    "text": "Packages: pip vs uv pip\nuv pip\nCreate virtual env:\nuv venv\n\nI am deleting my entire uv cache to make sure that I am not cheating in the comparison. You normally never do that since the cache prevents deduplication (saves space) and makes installations much faster\nrm -rf ~/.cache/uv\n\nInstall package:\nuv pip install jax-ai-stack"
  },
  {
    "objectID": "tools/wb_uv_slides.html#packages-pip-vs-uv-pip-2",
    "href": "tools/wb_uv_slides.html#packages-pip-vs-uv-pip-2",
    "title": "A tool to rule them all",
    "section": "Packages: pip vs uv pip",
    "text": "Packages: pip vs uv pip\nuv pip\nTo use the virtual env, I can activate it but I can also access it directly by running commands preceded by uv run\n\nFor instance, I can launch a JupyterLab with access to the project virtual env with:\n\nuv run --with jupyter jupyter lab\n\nor run a script with:\n\nuv run script.py"
  },
  {
    "objectID": "tools/wb_uv_slides.html#use-case-virtual-env-with-specific-python-version",
    "href": "tools/wb_uv_slides.html#use-case-virtual-env-with-specific-python-version",
    "title": "A tool to rule them all",
    "section": "Use case: virtual env with specific Python version",
    "text": "Use case: virtual env with specific Python version\nI needed to install a number of packages for a deep learning course with JAX, including Grain which still requires Python 3.12\nFollowing are the workflows with classic tools vs uv"
  },
  {
    "objectID": "tools/wb_uv_slides.html#pyenv-venv-and-pip",
    "href": "tools/wb_uv_slides.html#pyenv-venv-and-pip",
    "title": "A tool to rule them all",
    "section": "pyenv, venv, and pip",
    "text": "pyenv, venv, and pip\nInstall Python 3.12:\npyenv install 3.12\nCreate virtual env with Python 3.12 (requires identifying the path):\n~/.pyenv/versions/3.12.10/bin/python -m venv .venv\nActivate it:\nsource .venv/bin/activate\nUpdate pip:\npython -m pip install --upgrade pip\nInstall packages:\npython -m pip install datasets jax-ai-stack[grain] matplotlib tqdm transformers"
  },
  {
    "objectID": "tools/wb_uv_slides.html#uv-2",
    "href": "tools/wb_uv_slides.html#uv-2",
    "title": "A tool to rule them all",
    "section": "uv",
    "text": "uv\nuv init --python 3.12 demo\n\nAutomatically installs Python 3.12 if missing\n\ncd demo\nuv add datasets jax-ai-stack[grain] matplotlib tqdm transformers"
  },
  {
    "objectID": "tools/wb_uv_slides.html#uv-advantages",
    "href": "tools/wb_uv_slides.html#uv-advantages",
    "title": "A tool to rule them all",
    "section": "uv advantages",
    "text": "uv advantages\nMuch simpler\nMuch (much!) faster\nLeaves me with a nice pyproject.toml file:\n[project]\nname = \"fl\"\nversion = \"0.1.0\"\nrequires-python = \"&gt;=3.12\"\ndependencies = [\n    \"datasets&gt;=3.5.0\",\n    \"jax-ai-stack[grain]&gt;=2025.2.5\",\n    \"matplotlib&gt;=3.10.1\",\n    \"tqdm&gt;=4.67.1\",\n    \"transformers&gt;=4.50.3\",\n]\nand a uv.lock file that I can put under version control and share for reproducibility"
  },
  {
    "objectID": "tools/wb_uv_slides.html#pipx-replacement",
    "href": "tools/wb_uv_slides.html#pipx-replacement",
    "title": "A tool to rule them all",
    "section": "pipx replacement",
    "text": "pipx replacement\nPython tools are packages used for convenience (e.g.¬†linters, formatters) across projects, but not necessary for running your code\nThey are commonly installed via your Linux distribution package manager, Homebrew, or pipx\nThey can also be installed by uv:\nuv tool install ruff"
  },
  {
    "objectID": "tools/wb_uv_slides.html#use-tools-without-installation",
    "href": "tools/wb_uv_slides.html#use-tools-without-installation",
    "title": "A tool to rule them all",
    "section": "Use tools without installation",
    "text": "Use tools without installation\nTools can even be used without installation (from a temporary install)\nuvx ruff\n\nuvx is an alias for uv tool run"
  }
]