{
  "hash": "209a0d042e363f23bae576566d880df5",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: DataFrames in Python\nauthor: Marie-Hélène Burle\n---\n\n:::{.def}\n\nIn programming languages, tabular data is handled in objects called DataFrames (or data frames or Data Frames). They were first implemented in the statistical language S, then in R, then they made it to Python.\n\nIn this section, we will have a briefly look at the tools available in Python to work with DataFrames.\n\n:::\n\n## [pandas](https://pandas.pydata.org/)\n\nAs the first (and only) implementation of DataFrames in Python, [pandas](https://pandas.pydata.org/) was the *de facto* DataFrame library for a very long time. Free and open-source, it is built on top of the array library [NumPy](https://numpy.org/) and was directly inspired by R Data Frames.\n\npandas is still widely used and you will come across it everywhere. Looking back on its design, even its creator [Wes McKinney](https://wesmckinney.com/) saw flaws in its implementation.\n\nSince July 1, 2024 there has been a new and much faster library called Polars. For this reason, we decided not to teach pandas in this course but to focus instead on the newer and better tool.\n\n## [Polars](https://docs.pola.rs/)\n\n[Polars](https://docs.pola.rs/) is a free and open-source new framework for DataFrames in Rust, R, JS, Ruby, and Python. It uses [Apache Arrow](https://arrow.apache.org/) columnar memory format which is the new standard for efficiency. It allows for [lazy evaluation](https://en.wikipedia.org/wiki/Lazy_evaluation) (which allows it to work with more data than can fit in memory), multi-threaded queries, [SIMD](https://en.wikipedia.org/wiki/Single_instruction,_multiple_data) vectorization, automatic parallelization, and better support for missing data.\n\nWe are only covering a succinct introduction to Polars here, but we will cover more in the [section on plotting with seaborn](intro_seaborn.qmd) later in this course. You can also have a look at [our introductory course on Polars](hpc_polars.qmd) for more details. Finally, we will offer a course on using Polars on GPU later this term.\n\n### DataFrame exploration\n\nLet's use the [la_riots dataset](https://github.com/vega/vega-datasets/blob/main/datapackage.md#la_riots), an open-source dataset on fatalities during the civil unrest in Los Angeles in April and May 1992, provided by the plotting library [Vega-Altair](https://altair-viz.github.io/). The dataset is hosted online as a CSV file.\n\nYou can read in a CSV file (local or from the Internet) with [`polars.read_csv`](https://docs.pola.rs/api/python/stable/reference/api/polars.read_csv.html):\n\n::: {#95331565 .cell execution_count=1}\n``` {.python .cell-code}\nimport polars as pl\n\nfile_path = \"https://cdn.jsdelivr.net/npm/vega-datasets/data/la-riots.csv\"\n\ndf = pl.read_csv(file_path)\n```\n:::\n\n\nLet's have a look at the first 5 rows of data:\n\n::: {#56fd088b .cell execution_count=2}\n``` {.python .cell-code}\nprint(df.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (5, 11)\n┌────────────┬───────────┬─────┬────────┬───┬──────────────┬─────────────┬─────────────┬───────────┐\n│ first_name ┆ last_name ┆ age ┆ gender ┆ … ┆ neighborhood ┆ type        ┆ longitude   ┆ latitude  │\n│ ---        ┆ ---       ┆ --- ┆ ---    ┆   ┆ ---          ┆ ---         ┆ ---         ┆ ---       │\n│ str        ┆ str       ┆ i64 ┆ str    ┆   ┆ str          ┆ str         ┆ f64         ┆ f64       │\n╞════════════╪═══════════╪═════╪════════╪═══╪══════════════╪═════════════╪═════════════╪═══════════╡\n│ Cesar A.   ┆ Aguilar   ┆ 18  ┆ Male   ┆ … ┆ Westlake     ┆ Officer-inv ┆ -118.273976 ┆ 34.059281 │\n│            ┆           ┆     ┆        ┆   ┆              ┆ olved       ┆             ┆           │\n│            ┆           ┆     ┆        ┆   ┆              ┆ shooting    ┆             ┆           │\n│ George     ┆ Alvarez   ┆ 42  ┆ Male   ┆ … ┆ Chinatown    ┆ Not riot-re ┆ -118.234098 ┆ 34.06269  │\n│            ┆           ┆     ┆        ┆   ┆              ┆ lated       ┆             ┆           │\n│ Wilson     ┆ Alvarez   ┆ 40  ┆ Male   ┆ … ┆ Hawthorne    ┆ Homicide    ┆ -118.326816 ┆ 33.901662 │\n│ Brian E.   ┆ Andrew    ┆ 30  ┆ Male   ┆ … ┆ Compton      ┆ Officer-inv ┆ -118.21539  ┆ 33.903457 │\n│            ┆           ┆     ┆        ┆   ┆              ┆ olved       ┆             ┆           │\n│            ┆           ┆     ┆        ┆   ┆              ┆ shooting    ┆             ┆           │\n│ Vivian     ┆ Austin    ┆ 87  ┆ Female ┆ … ┆ Harvard Park ┆ Death       ┆ -118.304741 ┆ 33.985667 │\n└────────────┴───────────┴─────┴────────┴───┴──────────────┴─────────────┴─────────────┴───────────┘\n```\n:::\n:::\n\n\nThe list of columns (variable names) can be accessed with the `columns` attribute:\n\n::: {#5dfdd833 .cell execution_count=3}\n``` {.python .cell-code}\nprint(df.columns)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['first_name', 'last_name', 'age', 'gender', 'race', 'death_date', 'address', 'neighborhood', 'type', 'longitude', 'latitude']\n```\n:::\n:::\n\n\nAn overview of the structure of the data can be accessed with the method `glimpse`:\n\n::: {#8a22f083 .cell execution_count=4}\n``` {.python .cell-code}\ndf.glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 63\nColumns: 11\n$ first_name   <str> 'Cesar A.', 'George', 'Wilson', 'Brian E.', 'Vivian', 'Franklin', 'Carol', 'Patrick', 'Hector', 'Jerel L.'\n$ last_name    <str> 'Aguilar', 'Alvarez', 'Alvarez', 'Andrew', 'Austin', 'Benavidez', 'Benson', 'Bettan', 'Castro', 'Channell'\n$ age          <i64> 18, 42, 40, 30, 87, 27, 42, 30, 49, 26\n$ gender       <str> 'Male', 'Male', 'Male', 'Male', 'Female', 'Male', 'Female', 'Male', 'Male', 'Male'\n$ race         <str> 'Latino', 'Latino', 'Latino', 'Black', 'Black', 'Latino', 'Black', 'White', 'Latino', 'Black'\n$ death_date   <str> '1992-04-30', '1992-05-01', '1992-05-23', '1992-04-30', '1992-05-03', '1992-04-30', '1992-05-02', '1992-04-30', '1992-04-30', '1992-04-30'\n$ address      <str> '2009 W. 6th St.', 'Main & College streets', '3100 Rosecrans Ave.', 'Rosecrans & Chester avenues', '1600 W. 60th St.', '4404 S. Western Ave.', 'Harbor Freeway near Slauson Avenue', '2740 W. Olympic Blvd.', 'Vermont & Leeward avenues', 'Santa Monica Boulevard & Seward Street'\n$ neighborhood <str> 'Westlake', 'Chinatown', 'Hawthorne', 'Compton', 'Harvard Park', 'Vermont Square', 'South Park', 'Koreatown', 'Koreatown', 'Hollywood'\n$ type         <str> 'Officer-involved shooting', 'Not riot-related', 'Homicide', 'Officer-involved shooting', 'Death', 'Officer-involved shooting', 'Death', 'Homicide', 'Homicide', 'Death'\n$ longitude    <f64> -118.2739756, -118.2340982, -118.326816, -118.2153903, -118.304741, -118.3088215, -118.2805037, -118.293181, -118.291654, -118.3323783\n$ latitude     <f64> 34.0592814, 34.0626901, 33.901662, 33.9034569, 33.985667, 34.0034731, 33.98916756, 34.052068, 34.0587022, 34.09129756\n\n```\n:::\n:::\n\n\nAnd summary statistics with the method `describe`:\n\n::: {#643e31bd .cell execution_count=5}\n``` {.python .cell-code}\nprint(df.describe())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (9, 12)\n┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n│ statistic ┆ first_nam ┆ last_name ┆ age       ┆ … ┆ neighborh ┆ type      ┆ longitude ┆ latitude │\n│ ---       ┆ e         ┆ ---       ┆ ---       ┆   ┆ ood       ┆ ---       ┆ ---       ┆ ---      │\n│ str       ┆ ---       ┆ str       ┆ f64       ┆   ┆ ---       ┆ str       ┆ f64       ┆ f64      │\n│           ┆ str       ┆           ┆           ┆   ┆ str       ┆           ┆           ┆          │\n╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n│ count     ┆ 63        ┆ 63        ┆ 62.0      ┆ … ┆ 63        ┆ 63        ┆ 63.0      ┆ 63.0     │\n│ null_coun ┆ 0         ┆ 0         ┆ 1.0       ┆ … ┆ 0         ┆ 0         ┆ 0.0       ┆ 0.0      │\n│ t         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n│ mean      ┆ null      ┆ null      ┆ 32.370968 ┆ … ┆ null      ┆ null      ┆ -118.2799 ┆ 34.02671 │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ 1         ┆ 3        │\n│ std       ┆ null      ┆ null      ┆ 14.253253 ┆ … ┆ null      ┆ null      ┆ 0.105198  ┆ 0.098471 │\n│ min       ┆ Aaron     ┆ Aguilar   ┆ 15.0      ┆ … ┆ Altadena  ┆ Death     ┆ -118.4717 ┆ 33.78985 │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ 45        ┆ 7        │\n│ 25%       ┆ null      ┆ null      ┆ 21.0      ┆ … ┆ null      ┆ null      ┆ -118.3098 ┆ 33.97418 │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ 22        ┆          │\n│ 50%       ┆ null      ┆ null      ┆ 31.0      ┆ … ┆ null      ┆ null      ┆ -118.2914 ┆ 34.00548 │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ 95        ┆ 5        │\n│ 75%       ┆ null      ┆ null      ┆ 38.0      ┆ … ┆ null      ┆ null      ┆ -118.2531 ┆ 34.07023 │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ 97        ┆ 8        │\n│ max       ┆ Wilson    ┆ Williams  ┆ 87.0      ┆ … ┆ Westlake  ┆ Officer-i ┆ -117.7306 ┆ 34.28709 │\n│           ┆           ┆           ┆           ┆   ┆           ┆ nvolved   ┆ 47        ┆ 8        │\n│           ┆           ┆           ┆           ┆   ┆           ┆ shooting  ┆           ┆          │\n└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n```\n:::\n:::\n\n\n### Subsetting\n\nLet's read in [another online dataset from Vega-Altair](https://github.com/vega/vega-datasets/blob/main/datapackage.md#disasters) into a DataFrame:\n\n::: {#8cb74c98 .cell execution_count=6}\n``` {.python .cell-code}\ndf = pl.read_csv(\"https://cdn.jsdelivr.net/npm/vega-datasets/data/disasters.csv\")\n\nprint(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (803, 3)\n┌───────────────────────┬──────┬─────────┐\n│ Entity                ┆ Year ┆ Deaths  │\n│ ---                   ┆ ---  ┆ ---     │\n│ str                   ┆ i64  ┆ i64     │\n╞═══════════════════════╪══════╪═════════╡\n│ All natural disasters ┆ 1900 ┆ 1267360 │\n│ All natural disasters ┆ 1901 ┆ 200018  │\n│ All natural disasters ┆ 1902 ┆ 46037   │\n│ All natural disasters ┆ 1903 ┆ 6506    │\n│ All natural disasters ┆ 1905 ┆ 22758   │\n│ …                     ┆ …    ┆ …       │\n│ Wildfire              ┆ 2013 ┆ 35      │\n│ Wildfire              ┆ 2014 ┆ 16      │\n│ Wildfire              ┆ 2015 ┆ 67      │\n│ Wildfire              ┆ 2016 ┆ 39      │\n│ Wildfire              ┆ 2017 ┆ 75      │\n└───────────────────────┴──────┴─────────┘\n```\n:::\n:::\n\n\nWe can subset it by rows:\n\n::: {#0e0080c1 .cell execution_count=7}\n``` {.python .cell-code}\ndf_sub_row = df.filter(pl.col(\"Year\") == 2001)\n\nprint(df_sub_row)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (9, 3)\n┌───────────────────────┬──────┬────────┐\n│ Entity                ┆ Year ┆ Deaths │\n│ ---                   ┆ ---  ┆ ---    │\n│ str                   ┆ i64  ┆ i64    │\n╞═══════════════════════╪══════╪════════╡\n│ All natural disasters ┆ 2001 ┆ 39493  │\n│ Drought               ┆ 2001 ┆ 99     │\n│ Earthquake            ┆ 2001 ┆ 21348  │\n│ Epidemic              ┆ 2001 ┆ 8515   │\n│ Extreme temperature   ┆ 2001 ┆ 1787   │\n│ Extreme weather       ┆ 2001 ┆ 1911   │\n│ Flood                 ┆ 2001 ┆ 5014   │\n│ Landslide             ┆ 2001 ┆ 786    │\n│ Wildfire              ┆ 2001 ┆ 33     │\n└───────────────────────┴──────┴────────┘\n```\n:::\n:::\n\n\nOr by columns:\n\n::: {#8329a86f .cell execution_count=8}\n``` {.python .cell-code}\ndf_sub_col = df.select(\n    pl.col(\"Entity\"),\n    pl.col(\"Year\")\n    )\n\nprint(df_sub_col)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (803, 2)\n┌───────────────────────┬──────┐\n│ Entity                ┆ Year │\n│ ---                   ┆ ---  │\n│ str                   ┆ i64  │\n╞═══════════════════════╪══════╡\n│ All natural disasters ┆ 1900 │\n│ All natural disasters ┆ 1901 │\n│ All natural disasters ┆ 1902 │\n│ All natural disasters ┆ 1903 │\n│ All natural disasters ┆ 1905 │\n│ …                     ┆ …    │\n│ Wildfire              ┆ 2013 │\n│ Wildfire              ┆ 2014 │\n│ Wildfire              ┆ 2015 │\n│ Wildfire              ┆ 2016 │\n│ Wildfire              ┆ 2017 │\n└───────────────────────┴──────┘\n```\n:::\n:::\n\n\n### Transformations\n\nSelected columns can be modified:\n\n::: {#4d047950 .cell execution_count=9}\n``` {.python .cell-code}\ndf_col_mod = df.select(\n    pl.col(\"Entity\"),\n    pl.col(\"Year\"),\n    (pl.col(\"Deaths\") / 1000).alias(\"Kilodeaths\")\n)\n\nprint(df_col_mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (803, 3)\n┌───────────────────────┬──────┬────────────┐\n│ Entity                ┆ Year ┆ Kilodeaths │\n│ ---                   ┆ ---  ┆ ---        │\n│ str                   ┆ i64  ┆ f64        │\n╞═══════════════════════╪══════╪════════════╡\n│ All natural disasters ┆ 1900 ┆ 1267.36    │\n│ All natural disasters ┆ 1901 ┆ 200.018    │\n│ All natural disasters ┆ 1902 ┆ 46.037     │\n│ All natural disasters ┆ 1903 ┆ 6.506      │\n│ All natural disasters ┆ 1905 ┆ 22.758     │\n│ …                     ┆ …    ┆ …          │\n│ Wildfire              ┆ 2013 ┆ 0.035      │\n│ Wildfire              ┆ 2014 ┆ 0.016      │\n│ Wildfire              ┆ 2015 ┆ 0.067      │\n│ Wildfire              ┆ 2016 ┆ 0.039      │\n│ Wildfire              ┆ 2017 ┆ 0.075      │\n└───────────────────────┴──────┴────────────┘\n```\n:::\n:::\n\n\nThe transformed columns can be created alongside all the columns of the original DataFrame:\n\n::: {#2d81d4ea .cell execution_count=10}\n``` {.python .cell-code}\ndf_mod = df.with_columns((pl.col(\"Deaths\") / 1000).alias(\"Kilodeaths\"))\n\nprint(df_mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (803, 4)\n┌───────────────────────┬──────┬─────────┬────────────┐\n│ Entity                ┆ Year ┆ Deaths  ┆ Kilodeaths │\n│ ---                   ┆ ---  ┆ ---     ┆ ---        │\n│ str                   ┆ i64  ┆ i64     ┆ f64        │\n╞═══════════════════════╪══════╪═════════╪════════════╡\n│ All natural disasters ┆ 1900 ┆ 1267360 ┆ 1267.36    │\n│ All natural disasters ┆ 1901 ┆ 200018  ┆ 200.018    │\n│ All natural disasters ┆ 1902 ┆ 46037   ┆ 46.037     │\n│ All natural disasters ┆ 1903 ┆ 6506    ┆ 6.506      │\n│ All natural disasters ┆ 1905 ┆ 22758   ┆ 22.758     │\n│ …                     ┆ …    ┆ …       ┆ …          │\n│ Wildfire              ┆ 2013 ┆ 35      ┆ 0.035      │\n│ Wildfire              ┆ 2014 ┆ 16      ┆ 0.016      │\n│ Wildfire              ┆ 2015 ┆ 67      ┆ 0.067      │\n│ Wildfire              ┆ 2016 ┆ 39      ┆ 0.039      │\n│ Wildfire              ┆ 2017 ┆ 75      ┆ 0.075      │\n└───────────────────────┴──────┴─────────┴────────────┘\n```\n:::\n:::\n\n\n### Group by operations\n\nIf you want to perform operations on rows sharing the same value for some variable, you group those rows with [`polars.DataFrame.group_by`](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.group_by.html#polars.DataFrame.group_by).\n\nFor instance, if we want to get the total number of deaths for each category of disaster, we can do:\n\n::: {#711e41ed .cell execution_count=11}\n``` {.python .cell-code}\ntotals = df.group_by(\n    pl.col(\"Entity\")\n).agg(\n    pl.col(\"Deaths\").sum()\n)\n\nprint(totals)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (11, 2)\n┌───────────────────────┬──────────┐\n│ Entity                ┆ Deaths   │\n│ ---                   ┆ ---      │\n│ str                   ┆ i64      │\n╞═══════════════════════╪══════════╡\n│ Epidemic              ┆ 9596463  │\n│ Mass movement (dry)   ┆ 5030     │\n│ Volcanic activity     ┆ 96366    │\n│ All natural disasters ┆ 32607156 │\n│ Drought               ┆ 11731294 │\n│ …                     ┆ …        │\n│ Landslide             ┆ 63068    │\n│ Flood                 ┆ 6954992  │\n│ Extreme weather       ┆ 1396601  │\n│ Extreme temperature   ┆ 182604   │\n│ Wildfire              ┆ 3925     │\n└───────────────────────┴──────────┘\n```\n:::\n:::\n\n\nNotice that the rows became out of order. Not to worry about order makes the code more efficient and does not affect future subsetting of our DataFrame. If you want to maintain the order however, you can use the `maintain_order` parameter (but this slows down the operation):\n\n::: {#e5d0d730 .cell execution_count=12}\n``` {.python .cell-code}\ntotals = df.group_by(\n    pl.col(\"Entity\"),\n    maintain_order=True\n).agg(\n    pl.col(\"Deaths\").sum()\n)\n\nprint(totals)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (11, 2)\n┌───────────────────────┬──────────┐\n│ Entity                ┆ Deaths   │\n│ ---                   ┆ ---      │\n│ str                   ┆ i64      │\n╞═══════════════════════╪══════════╡\n│ All natural disasters ┆ 32607156 │\n│ Drought               ┆ 11731294 │\n│ Earthquake            ┆ 2576801  │\n│ Epidemic              ┆ 9596463  │\n│ Extreme temperature   ┆ 182604   │\n│ …                     ┆ …        │\n│ Flood                 ┆ 6954992  │\n│ Landslide             ┆ 63068    │\n│ Mass movement (dry)   ┆ 5030     │\n│ Volcanic activity     ┆ 96366    │\n│ Wildfire              ┆ 3925     │\n└───────────────────────┴──────────┘\n```\n:::\n:::\n\n\n:::{.exo}\n\n:::{.yourturn}\n\nYour turn:\n\n:::\n\nCreate a new DataFrame, ordered by year, that shows the total number of deaths for each year:\n\n::: {#22f4f7c8 .cell execution_count=13}\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (117, 2)\n┌──────┬─────────┐\n│ Year ┆ Deaths  │\n│ ---  ┆ ---     │\n│ i64  ┆ i64     │\n╞══════╪═════════╡\n│ 1900 ┆ 1267360 │\n│ 1901 ┆ 200018  │\n│ 1902 ┆ 46037   │\n│ 1903 ┆ 6506    │\n│ 1905 ┆ 22758   │\n│ …    ┆ …       │\n│ 2013 ┆ 22225   │\n│ 2014 ┆ 20882   │\n│ 2015 ┆ 23893   │\n│ 2016 ┆ 10201   │\n│ 2017 ┆ 2087    │\n└──────┴─────────┘\n```\n:::\n:::\n\n\n:::\n\n### Combining contexts\n\n`select`, `with_columns`, `filter`, and `group_by` are called [contexts]{.emph} in the Polars terminology (the data transformations performed in these contexts are called [expressions]{.emph}).\n\nContexts can be combined. For instance, we can create a new DataFrame with the number of deaths for each decade:\n\n::: {#f740e76e .cell execution_count=14}\n``` {.python .cell-code}\ndecade_totals = df.filter(\n    pl.col(\"Entity\") == \"All natural disasters\"\n).with_columns(\n    (pl.col(\"Year\") // 10 * 10).alias(\"Decade\")\n).group_by(\n    pl.col(\"Decade\"),\n    maintain_order=True\n).agg(\n    pl.col(\"Deaths\").sum()\n)\n\nprint(decade_totals)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (12, 2)\n┌────────┬─────────┐\n│ Decade ┆ Deaths  │\n│ ---    ┆ ---     │\n│ i64    ┆ i64     │\n╞════════╪═════════╡\n│ 1900   ┆ 4497847 │\n│ 1910   ┆ 3326492 │\n│ 1920   ┆ 8726293 │\n│ 1930   ┆ 4701024 │\n│ 1940   ┆ 3871695 │\n│ …      ┆ …       │\n│ 1970   ┆ 986867  │\n│ 1980   ┆ 796782  │\n│ 1990   ┆ 527613  │\n│ 2000   ┆ 839986  │\n│ 2010   ┆ 454950  │\n└────────┴─────────┘\n```\n:::\n:::\n\n\nOr one with the number of deaths for that decade for each type of disaster:\n\n::: {#57ebd6fc .cell execution_count=15}\n``` {.python .cell-code}\ndecade_totals_by_type = df.with_columns(\n    (pl.col(\"Year\") // 10 * 10).alias(\"Decade\"),\n).group_by([pl.col(\"Decade\"), pl.col(\"Entity\")],\n    maintain_order=True\n).agg(\n    pl.col(\"Deaths\").sum()\n)\n\nprint(decade_totals_by_type)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (122, 3)\n┌────────┬───────────────────────┬─────────┐\n│ Decade ┆ Entity                ┆ Deaths  │\n│ ---    ┆ ---                   ┆ ---     │\n│ i64    ┆ str                   ┆ i64     │\n╞════════╪═══════════════════════╪═════════╡\n│ 1900   ┆ All natural disasters ┆ 4497847 │\n│ 1910   ┆ All natural disasters ┆ 3326492 │\n│ 1920   ┆ All natural disasters ┆ 8726293 │\n│ 1930   ┆ All natural disasters ┆ 4701024 │\n│ 1940   ┆ All natural disasters ┆ 3871695 │\n│ …      ┆ …                     ┆ …       │\n│ 1970   ┆ Wildfire              ┆ 5       │\n│ 1980   ┆ Wildfire              ┆ 396     │\n│ 1990   ┆ Wildfire              ┆ 859     │\n│ 2000   ┆ Wildfire              ┆ 629     │\n│ 2010   ┆ Wildfire              ┆ 429     │\n└────────┴───────────────────────┴─────────┘\n```\n:::\n:::\n\n\n### Lazy evaluation\n\nWhen it comes to high-performance computing, one of the strengths of Polars is that it supports [lazy evaluation](https://en.wikipedia.org/wiki/Lazy_evaluation). Lazy evaluation instantly returns a future that can be used without waiting for the result of the computation. Moreover, when you run queries on a LazyFrame, Polars creates a graph and runs [optimizations](https://docs.pola.rs/user-guide/lazy/optimizations/) on it, very much the way compiled languages work.\n\nIf you want to speedup your code, use lazy execution whenever possible and try to use the lazy API from the start, when reading a file.\n\nIn the previous examples, we used [`polars.read_csv`](https://docs.pola.rs/api/python/stable/reference/api/polars.read_csv.html#polars.read_csv) to read our data. This returns a Polars DataFrame:\n\n::: {#f078d70c .cell execution_count=16}\n``` {.python .cell-code}\nurl = \"https://cdn.jsdelivr.net/npm/vega-datasets/data/disasters.csv\"\n\ndf = pl.read_csv(url)\ntype(df)\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\npolars.dataframe.frame.DataFrame\n```\n:::\n:::\n\n\nInstead, you can use [`polars.scan_csv`](https://docs.pola.rs/api/python/stable/reference/api/polars.scan_csv.html#polars.scan_csv) to create a LazyFrame:\n\n::: {#b07ea7ca .cell execution_count=17}\n``` {.python .cell-code}\ndf_lazy = pl.scan_csv(url)\ntype(df_lazy)\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\npolars.lazyframe.frame.LazyFrame\n```\n:::\n:::\n\n\nIf you already have a DataFrame, you can create a LazyFrame from it with the [`polars.DataFrame.lazy`](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.lazy.html#polars.DataFrame.lazy) method:\n\n::: {#09eeeb60 .cell execution_count=18}\n``` {.python .cell-code}\ndf_lazy = df.lazy()\n```\n:::\n\n\nTo get results from a LazyFrame, you use [`polars.LazyFrame.collect`](https://docs.pola.rs/api/python/stable/reference/lazyframe/api/polars.LazyFrame.collect.html).\n\nThis won't work because a LazyFrame has no attribute `shape`:\n\n::: {#6e624a65 .cell execution_count=19}\n``` {.python .cell-code}\ndf_lazy.filter(pl.col(\"Year\") == 2001).shape\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-bright-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-bright-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansi-bright-cyan-fg\">Cell</span><span class=\"ansi-bright-cyan-fg\"> </span><span class=\"ansi-green-fg\">In[19]</span><span class=\"ansi-green-fg\">, line 1</span>\n<span class=\"ansi-bright-green-fg\">----&gt; </span><span class=\"ansi-bright-green-fg\">1</span> <span class=\"ansi-bright-white-fg ansi-yellow-bg\">df_lazy</span><span style=\"color:rgb(255,95,135)\" class=\"ansi-yellow-bg\">.</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">filter</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">(</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">pl</span><span style=\"color:rgb(255,95,135)\" class=\"ansi-yellow-bg\">.</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">col</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">(</span><span style=\"color:rgb(215,215,135)\" class=\"ansi-yellow-bg\">\"</span><span style=\"color:rgb(215,215,135)\" class=\"ansi-yellow-bg\">Year</span><span style=\"color:rgb(215,215,135)\" class=\"ansi-yellow-bg\">\"</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">)</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\"> </span><span style=\"color:rgb(255,95,135)\" class=\"ansi-yellow-bg\">==</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\"> </span><span style=\"color:rgb(175,135,255)\" class=\"ansi-yellow-bg\">2001</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">)</span><span style=\"color:rgb(255,95,135)\" class=\"ansi-yellow-bg\">.</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">shape</span>\n\n<span class=\"ansi-bright-red-fg\">AttributeError</span>: 'LazyFrame' object has no attribute 'shape'</pre>\n```\n:::\n\n:::\n:::\n\n\nYou need to `collect` the result first:\n\n::: {#d233554a .cell execution_count=20}\n``` {.python .cell-code}\ndf_lazy.filter(pl.col(\"Year\") == 2001).collect().shape\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\n(9, 3)\n```\n:::\n:::\n\n\n`collect` turns your LazyFrame into a DataFrame, but it only does so on the subset needed for your query:\n\n::: {#2e614505 .cell execution_count=21}\n``` {.python .cell-code}\ntype(df_lazy.filter(pl.col(\"Year\") == 2001).collect())\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```\npolars.dataframe.frame.DataFrame\n```\n:::\n:::\n\n\nThis allows you to work with data too big to fit in memory!\n\n",
    "supporting": [
      "intro_df_files"
    ],
    "filters": [],
    "includes": {}
  }
}