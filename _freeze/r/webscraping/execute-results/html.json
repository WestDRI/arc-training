{
  "hash": "9d8bb921e262fa26f6e985614773e718",
  "result": {
    "markdown": "---\ntitle: Web scraping with R\nauthor: Marie-Hélène Burle\n---\n\n:::{.def}\n\nThe internet is a trove of information. A lot of it is publicly available and thus suitable for use in research. Extracting that information and putting it in an organized format for analysis can, however, be extremely tedious. Web scraping tools allow to automate parts of that process and R is a popular language for the task.\n\nIn this workshop, we will guide you through a simple example using the package [rvest](https://rvest.tidyverse.org/).\n\n:::\n\n:::{.callout-accordion collapse=\"true\"}\n\n## ***Running R***\n\nFor this workshop, we will use our temporary RStudio server. To access it:\n\n1.  Go to the website given during the workshop,\n2.  Sign in using your username and password given during the workshop (you can ignore the OTP entry),\n3.  Choose the following `Server Options`:\n\n    - Time: `1.5` hours\n    - Number of cores: `1`\n    - Memory: `3600` MB\n    - User interface: `JupyterLab`\n\n<!-- ![](img/jupyter_options.png){fig-alt=\"noshadow\"} -->\n\n4.  In JupyterLab, click on the RStudio button (big blue symbol with a white R in it).\n\n:::{.note}\n\nOur RStudio server already has the two packages that we will be using installed ([rvest](https://cran.r-project.org/web/packages/rvest/index.html) and [tibble](https://cran.r-project.org/web/packages/tibble/index.html)). If you want to run the code on your machine, you need to install them with `install.packages()` first.\n\n:::\n\n:::\n\n## HTML and CSS\n\n\n\n## Web scrapping\n\n\n\n## Example\n\n### Goal\n\nWe will use [a website](https://trace.tennessee.edu/utk_graddiss/index.html) from the [University of Tennessee](https://www.utk.edu/) containing a database of PhD theses from that university.\n\nOur goal is to scrape data from this site to produce a dataframe with the date, major, and principal investigator (PI) for each dissertation.\n\n:::{.note}\n\nWe will only do this for the first page which contains the links for the 100 most recent theses. If you really wanted to gather all the data, you would have to do this for all pages.\n\n:::\n\n### Package\n\nWe will use the package [rvest](https://cran.r-project.org/web/packages/rvest/index.html), part of the [tidyverse](https://www.tidyverse.org/)—a modern set of R packages.\n\nLet's load it:\n\n```{.r}\nlibrary(rvest)\n```\n\n### Read in HTML data\n\nAs mentioned above, our site is the [database of PhD dissertations of the University of Tennessee](https://trace.tennessee.edu/utk_graddiss/index.html).\n\nLet's create a character vector with the url:\n\n```{.r}\nurl <- \"https://trace.tennessee.edu/utk_graddiss/index.html\"\n```\n\nFirst, we read in the html data from that page:\n\n```{.r}\nhtml <- read_html(url)\n```\n\nLet's have a look at the raw data:\n\n```{.r}\nhtml\n```\n\n```\n{html_document}\n<html lang=\"en\">\n[1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] <body>\\n<!-- FILE /srv/sequoia/main/data/trace.tennessee.edu/assets/heade ...\n```\n\n### Extracting relevant data\n\n#### Method\n\nTo find the relevant CSS element, you can use a web inspector or, even easier, the [SelectorGadget](https://selectorgadget.com/)—a JavaScript bookmarklet built by [Andrew Cantino](https://andrewcantino.com/).\n\n#### Extracting a single link\n\nFirst, let's try to extract a single link:\n\n```{.r}\ntest <- html %>% html_element(\".article-listing\")\ntest\n```\n\n```\n{html_node}\n<p class=\"article-listing\">\n[1] <a href=\"https://trace.tennessee.edu/utk_graddiss/7600\">The Novel Chlorin ...\n```\n\nThe link is in there, but we need to do more extracting.\n\n```{.r}\nstr(test)\n```\n\n```\nList of 2\n $ node:<externalptr> \n $ doc :<externalptr> \n - attr(*, \"class\")= chr \"xml_node\"\n```\n\n```{.r}\na_test <- test %>% html_element(\"a\")\na_test\n```\n\nMuch better, but we now need to extract the `href` attribute:\n\n```\n{xml_nodeset (1)}\n[1] <a href=\"https://trace.tennessee.edu/utk_graddiss/7600\">The Novel Chlorin ...\n```\n\n```{.r}\na_test %>% html_attrs()\n```\n\n```\n[[1]]\n                                           href \n\"https://trace.tennessee.edu/utk_graddiss/7600\" \n```\n\n```{.r}\nlink_test <- a_test %>% html_attr(\"href\")\nlink_test\n```\n\n```\n[1] \"https://trace.tennessee.edu/utk_graddiss/7600\"\n```\n\n```{.r}\nstr(link_test)\n```\n\n```\nchr \"https://trace.tennessee.edu/utk_graddiss/7600\"\n```\n\n#### Getting data from our test link\n\n`link_test` is a character vector representing a URL. We know how to deal with this!\n\nFirst, as we did earlier with the database site, we need to read in the html data:\n\n```{.r}\nhtml_test <- read_html(link_test)\nhtml_test\n```\n\n```\n<html lang=\"en\">\n[1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] <body>\\n<!-- FILE /srv/sequoia/main/data/trace.tennessee.edu/assets/heade ...\n```\n\nNow, we want to extract the publication date. Let's use the [SelectorGadget](https://selectorgadget.com/) again.\n\nWe need the element `#publication_date p`. Let's extract it:\n\n```{.r}\ndate <- html_test %>% html_element(\"#publication_date p\") %>% html_text2()\ndate\n```\n\n```\n[1] \"5-2023\"\n```\n\nWe also want the major for this thesis. The [SelectorGadget](https://selectorgadget.com/) allows us to find that this time, it is the `#department p` element that we need. Let's extract it:\n\n```{.r}\nmajor <- html_test %>% html_element(\"#department p\") %>% html_text2()\nmajor\n```\n\n```\n[1] \"Chemistry\"\n```\n\nAnd for the PI, we need the `#advisor1 p` element:\n\n```{.r}\npi <- html_test %>% html_element(\"#advisor1 p\") %>% html_text2()\npi\n```\n\n```\n[1] \"Craig E. Barnes\"\n```\n\n```{.r}\ncbind(date, major, pi)\n```\n\n```\n     date     major       pi               \n[1,] \"5-2023\" \"Chemistry\" \"Craig E. Barnes\"\n```\n\n#### Extracting all links\n\nInstead of using `html_element()`, this time we will use `html_elements()` which extracts *all* matching elements (instead of just the first one):\n\n```{.r}\ndat <- html %>% html_elements(\".article-listing\")\ndat\n```\n\n```\n{xml_nodeset (100)}\n [1] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n [2] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n [3] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n [4] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n [5] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n [6] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n [7] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n [8] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n [9] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n[10] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n[11] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n[12] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n[13] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n[14] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n[15] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n[16] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n[17] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n[18] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n[19] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n[20] <p class=\"article-listing\"><a href=\"https://trace.tennessee.edu/utk_grad ...\n...\n```\n\n```{.r}\nstr(dat)\n```\n\n```\nList of 100\n $ :List of 2\n  ..$ node:<externalptr> \n  ..$ doc :<externalptr> \n  ..- attr(*, \"class\")= chr \"xml_node\"\n $ :List of 2\n  ..$ node:<externalptr> \n  ..$ doc :<externalptr> \n  ..- attr(*, \"class\")= chr \"xml_node\"\n $ :List of 2\n  ..$ node:<externalptr> \n  ..$ doc :<externalptr> \n  ..- attr(*, \"class\")= chr \"xml_node\"\n $ :List of 2\n  ..$ node:<externalptr> \n  ..$ doc :<externalptr> \n  ..- attr(*, \"class\")= chr \"xml_node\"\n...\n```\n\nWe now have a list of lists.\n\nAs we did for a single link, we want to extract all the links to have a list of links.\n\nBefore running for loops, it is important to initialize empty loops. It is much more efficient than growing the result at each iteration.\n\nSo let's initialize an empty list:\n\n```{.r}\nlist_links <- vector(\"list\", length(dat))\n```\n\nLet's have a look at one element of our list (the second one for instance):\n\n```{.r}\nlist_links[[2]]\n```\n\n```\nNULL\n```\n\nWe now have an empty list of the appropriate size. We can run our loop:\n\n```{.r}\nfor (i in seq_along(dat)) {\n  list_links[[i]] <- dat[[i]] %>%\n    html_element(\"a\") %>%\n    html_attr(\"href\")\n}\n```\n\nLet's print again the second element of our list to make sure all looks good:\n\n```{.r}\nlist_links[[2]]\n```\n\n```\n[1] \"https://trace.tennessee.edu/utk_graddiss/7714\"\n```\n\nWe have a character vector with one link. That's great! `list_links` is a list of links (in the form of character vectors) as we wanted.\n\n#### Getting the data from the list of links\n\nWe will now extract the data (date, major, and PI) for all links in our list.\n\nAgain, before running a for loop, we need to allocate memory first by creating an empty container:\n\n```{.r}\nlist_data <- vector(\"list\", length(list_links))\n```\n\nAnd here is our big loop to get the data from our list of links:\n\n```{.r}\nfor (i in seq_along(list_links)) {\n  html <- read_html(list_links[[i]])\n  date <- html %>%\n    html_element(\"#publication_date p\") %>%\n    html_text2()\n  major <- html %>%\n    html_element(\"#department p\") %>%\n    html_text2()\n  pi <- html %>%\n    html_element(\"#advisor1 p\") %>%\n    html_text2()\n  list_data[[i]] <- cbind(date, major, pi)\n}\n```\n\nLet's make sure all looks good by printing the second element of `list_data`:\n\n```{.r}\nlist_data[[2]]\n```\n\n```\n[,1]      [,2]        [,3]                 \n[1,] \"12-2022\" \"Chemistry\" \"Dr. Ampofo K. Darko\"\n```\n\nAll looking good, so let's turn this big list into a tibble:\n\n```{.r}\nresult <- do.call(rbind.data.frame, list_data) %>%\n  tibble::as_tibble()\n```\n\n:::{.note}\n\nThe notation `tibble::as_tibble()` means that we are using the function `as_tibble()` from the package [tibble](https://tibble.tidyverse.org/). A tibble is the [tidyverse](https://www.tidyverse.org/) version of a dataframe. One advantage is that it will only print the first 10 rows by default instead of printing the whole dataframe.\n\n:::\n\nHere is our result:\n\n```{.r}\nresult\n```\n\n```\n# A tibble: 100 × 3\n   date    major                                      pi                   \n   <chr>   <chr>                                      <chr>                \n 1 5-2023  Chemistry                                  Craig E. Barnes      \n 2 12-2022 Chemistry                                  Dr. Ampofo K. Darko  \n 3 12-2022 Industrial Engineering                     James Ostrowski      \n 4 5-2022  Entomology, Plant Pathology and Nematology Heather Kelly        \n 5 5-2022  Mechanical Engineering                     Caleb D. Rucker      \n 6 12-2022 Electrical Engineering                     Yilu Liu             \n 7 5-2022  Comparative and Experimental Medicine      Brian K. Whitlock    \n 8 5-2022  History                                    Jay Rubenstein       \n 9 12-2022 Anthropology                               Dawnie W. Steadman   \n10 12-2022 Mechanical Engineering                     Stephanie C. TerMaath\n# … with 90 more rows\n# ℹ Use `print(n = ...)` to see more rows\n```\n\nWe can rename the headers:\n\n```{.r}\nnames(result) <- c(\"Date\", \"Major\", \"PI\")\n```\n\nAnd this is our final result:\n\n```{.r}\nresult\n```\n\n```\n# A tibble: 100 × 3\n   Date    Major                                      PI                   \n   <chr>   <chr>                                      <chr>                \n 1 5-2023  Chemistry                                  Craig E. Barnes      \n 2 12-2022 Chemistry                                  Dr. Ampofo K. Darko  \n 3 12-2022 Industrial Engineering                     James Ostrowski      \n 4 5-2022  Entomology, Plant Pathology and Nematology Heather Kelly        \n 5 5-2022  Mechanical Engineering                     Caleb D. Rucker      \n 6 12-2022 Electrical Engineering                     Yilu Liu             \n 7 5-2022  Comparative and Experimental Medicine      Brian K. Whitlock    \n 8 5-2022  History                                    Jay Rubenstein       \n 9 12-2022 Anthropology                               Dawnie W. Steadman   \n10 12-2022 Mechanical Engineering                     Stephanie C. TerMaath\n# … with 90 more rows\n# ℹ Use `print(n = ...)` to see more rows\n```\n\n",
    "supporting": [
      "webscraping_files"
    ],
    "filters": [],
    "includes": {}
  }
}