{
  "hash": "bd39116806345a4b2d93673a21c7a218",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: High-performance research computing in ![](img/logo_r.png){width=\"2em\" fig-alt=\"noshadow\"}\naliases:\n  - hpc_intro_slides.html\n  - intro_hpc_slides.html\nfrontlogo: /img/logo_sfudrac.png\nauthor: Marie-Hélène Burle\ndate: 2023-01-31\ndate-format: long\nexecute:\n  freeze: auto\n  cache: true\n  error: true\n  echo: true\nformat:\n  revealjs:\n    embed-resources: true\n    theme: [default, ../revealjs.scss]\n    logo: /img/favicon_sfudrac.png\n    highlight-style: ayu\n    code-line-numbers: false\n    template-partials:\n      - ../title-slide.html\n    pointer:\n      color: \"#b5111b\"\n      pointerSize: 32\n    link-external-newwindow: true\n    footer: <a href=\"wb_hpc.html\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" fill=\"rgb(153, 153, 153)\" class=\"bi bi-arrow-90deg-up\" viewBox=\"0 0 16 16\"><path fill-rule=\"evenodd\" d=\"M4.854 1.146a.5.5 0 0 0-.708 0l-4 4a.5.5 0 1 0 .708.708L4 2.707V12.5A2.5 2.5 0 0 0 6.5 15h8a.5.5 0 0 0 0-1h-8A1.5 1.5 0 0 1 5 12.5V2.707l3.146 3.147a.5.5 0 1 0 .708-.708l-4-4z\"/></svg>&nbsp;Back to webinar page</a>\nrevealjs-plugins:\n  - pointer\n---\n\n# Running R on HPC clusters\n\n# Loading modules\n\n## Intel vs GCC compilers {.center}\n\nTo compile R packages, you need a C compiler.\n\nIn theory, you could use the proprietary Intel compiler which is loaded by default on the Alliance clusters, but it is recommended to replace it with the GCC compiler (R packages can even be compiled with Clang and LLVM, but the default GCC compiler is the best way to avoid headaches).\n\nIt is thus much simpler to always load a `gcc` module before loading an `r` module.\n\n## R module {.center}\n\nTo see what versions of R are available on a cluster, run:\n\n```{.bash}\nmodule spider r\n```\n\nTo see the dependencies of a particular version (e.g. `r/4.2.1`), run:\n\n```{.bash}\nmodule spider r/4.2.1\n```\n\n:::{.note}\n\n`StdEnv/2020` is a required module for this version.\n\nOn most Alliance clusters, it is automatically loaded, so you don't need to include it. You can double-check with `module list` or you can include it (before `r/4.2.1`) just to be sure.\n\n:::\n\nFinally, load your modules:\n\n```{.bash}\nmodule load StdEnv/2020 gcc/11.3.0 r/4.2.1\n```\n\n# Installing R packages\n\n---\n\nTo install a package, launch the interactive R console with:\n\n```{.bash}\nR\n```\n\nIn the R console, run:\n\n```{.r}\ninstall.packages(\"<package_name>\", repos=\"<url-cran-mirror>\")\n```\n\n:::{.note}\n\n`repos` argument: chose a [CRAN mirror close to the location of your cluster](https://cran.r-project.org/mirrors.html) or use <https://cloud.r-project.org/>.\n\n:::\n\n:::{.note}\n\nThe first time you install a package, R will ask you whether you want to create a personal library in your home directory. Answer `yes` to both questions. Your packages will now install under `~/`.\n\n:::\n\n:::{.note}\n\nSome packages require additional modules to be loaded before they can be installed. Other packages need additional R packages as dependencies. In either case, you will get explicit error messages. Adding the argument `dependencies = TRUE` helps in the second case, but you will still have to add packages manually from time to time.\n\n:::\n\n---\n\nLet's install the packages needed for this webinar:\n\n```{.r}\ninstall.packages(\n  c(\"tidyverse\", \"bench\", \"doFuture\", \"doRNG\", \"randomForest\", \"Rcpp\"),\n  repos=\"https://mirror.rcg.sfu.ca/mirror/CRAN/\"  # closest mirror from Cedar\n)\n```\n\n:::{.note}\n\nThis will also install the dependencies `foreach`, `future`, and `iterators`.\n\n:::\n\nTo leave the R console, press `<Ctrl+D>`.\n\n# Running R jobs\n\n## Scripts {.center}\n\nTo run an R script called `<your_script>.R`, you first need to write a job script:\n\n:::{.example}\n\nExample:\n\n```{.bash filename=\"<your_job>.sh\"}\n#!/bin/bash\n#SBATCH --account=def-<your_account>\n#SBATCH --time=15\n#SBATCH --mem-per-cpu=3000M\n#SBATCH --cpus-per-task=4\n#SBATCH --job-name=\"<your_job>\"\nmodule load StdEnv/2020 gcc/11.3.0 r/4.2.1\nRscript <your_script>.R\t  # Note that R scripts are run with the command `Rscript`\n```\n\n:::\n\nThen launch your job with:\n\n```{.bash}\nsbatch <your_job>.sh\n```\n\nYou can monitor your job with `sq` (an alias for `squeue -u $USER $@`).\n\n## Interactive jobs {.center}\n\n:::{.note}\n\nWhile it is fine to run R on the login node when you install packages, you **must start a SLURM job before any heavy computation**.\n\n:::\n\nTo run R interactively, you should launch an `salloc` session.\n\nHere is what I will use for this webinar:\n\n```{.bash}\nsalloc --time=1:10:00 --mem-per-cpu=7000M --ntasks=8\n```\n\nThis takes me to a compute node where I can launch R to run computations:\n\n```{.bash}\nR\n```\n\n# Performance\n\n## Profiling {.center}\n\nThe first thing to do if you want to improve your code efficiency is to identify bottlenecks in your code. Common tools are:\n\n- the base R function `Rprof()`\n- the package [profvis](https://cran.r-project.org/web/packages/profvis/index.html)\n\n[profvis](https://cran.r-project.org/web/packages/profvis/index.html) is a newer tool, built by [posit](https://posit.co/) (formerly RStudio). Under the hood, it runs `Rprof()` to collect data, then produces an interactive html widget with a flame graph that allows for an easy visual identification of slow sections of code. While this tool integrates well within the RStudio IDE or the [RPubs ecosystem](https://rpubs.com/wch/178493), it is not very well suited for remote work on a cluster. One option is to profile your code with small data on your own machine. Another option is to use the base profiler with `Rprof()` directly as in [this example](https://rstudio.github.io/r-manuals/r-exts/Tidying-and-profiling-R-code.html#profiling-r-code-for-speed).\n\n## Benchmarking {.center}\n\nOnce you have identified expressions that are particularly slow, you can use benchmarking tools to compare variations of the code.\n\nIn the most basic fashion, you can use `system.time()`, but this is limited and imprecise.\n\nThe [microbenchmark](https://cran.r-project.org/web/packages/microbenchmark/index.html) package is a popular option.\n\nIt gives the minimum time, lower quartile, mean, median, upper quartile, and maximum time of R expressions.\n\nThe newer [bench](https://cran.r-project.org/web/packages/bench/index.html) package has less overhead, is more accurate, and—for sequential code—gives information on memory usage and garbage collections. This is the package I will use today.\n\n# Parallel programming\n\n## Multi-threading {.center}\n\nWe talk about **multi-threading** when a single process (with its own memory) runs multiple threads.\n\nThe execution can happen in parallel—if each thread has access to a CPU core—or by alternating some of the threads on some CPU cores.\n\nBecause all threads in a process write to the same memory addresses, multi-threading can lead to [race conditions](https://en.wikipedia.org/wiki/Race_condition).\n\nMulti-threading does not seem to be a common approach to parallelizing R code.\n\n## Multi-processing in shared memory {.center}\n\n**Multi-processing in shared memory** happens when multiple processes execute code on multiple CPU cores of a single node (or a single machine).\n\nThe different processes need to communicate with each other, but because they are all running on the CPU cores of a single node, messages can pass via shared memory.\n\n## Multi-processing in distributed memory {.center}\n\nWhen processes involved in the execution of some code run on multiple nodes of a cluster, messages between them need to travel over the cluster interconnect. In that case, we talk about **distributed memory**.\n\n# Running R code in parallel\n\n## Package parallel (base R) {.center}\n\nThe `parallel` package has been part of the \"base\" package group since version 2.14.0. \\\nThis means that it is comes with R.\n\nMost parallel approaches in R build on this package.\n\nWe will make use of it to create and close an ad-hoc cluster.\n\n:::{.note}\n\nThe [parallelly](https://parallelly.futureverse.org/) package adds functionality to the `parallel` package.\n\n:::\n\n## Package foreach {.center}\n\nThe [foreach](https://cran.r-project.org/web/packages/foreach/index.html) package implements a looping construct without an explicit counter. It doesn't require the preallocation of an output container, it brings to R an equivalent of the Python or Julia list comprehensions, and mostly, it allows for an easy execution of loops in parallel. Unlike loops, it creates variables (loops are used for their side-effect).\n\nLet's look at an example to calculate the sum of 1e4 random vectors of length 3.\n\nWe will use `foreach` and `iterators` (which creates convenient iterators for `foreach`):\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(foreach)\nlibrary(iterators)\n```\n:::\n\n---\n\nClassic while loop:\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2)\nresult1 <- numeric(3)            # Preallocate output container\ni <- 0                           # Initialise counter variable\n\nwhile(i < 1e4) {                 # Finally we run the loop\n  result1 <- result1 + runif(3)  # Calculate the sum\n  i <- i + 1                     # Update the counter\n}\n```\n:::\n\nWith foreach:\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2)\nresult2 <- foreach(icount(1e4), .combine = '+') %do% runif(3)\n```\n:::\n\nVerify:\n\n::: {.cell}\n\n```{.r .cell-code}\nall.equal(result1, result2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n---\n\nThe best part of `foreach` is that you can turn sequential loops into parallel ones by registering a parallel backend and replacing `%do%` with `%dopar%`.\n\nThere are many parallelization backends available: `doFuture`, `doMC`, `doMPI`, `doFuture`, `doParallel`, `doRedis`, `doRNG`, `doSNOW`, and `doAzureParallel`.\n\nIn this webinar, I will use [`doFuture`](https://cran.r-project.org/web/packages/doFuture/index.html) which allows to evaluate `foreach` expressions following any of the strategies of the [`future`](https://cran.r-project.org/web/packages/future/index.html) package.\n\nSo first, what is the [`future`](https://cran.r-project.org/web/packages/future/index.html) package?\n\n## Package future {.center}\n\nA [future](https://en.wikipedia.org/wiki/Futures_and_promises) is an object that acts as an abstract representation for a value in the future. A future can be *resolved* (if the value has been computed) or *unresolved*. If the value is queried while the future is unresolved, the process is blocked until the future is resolved.\n\nFutures allow for asynchronous and parallel evaluations. The `future` package provides a simple and unified API to evaluate futures.\n\n## Plans {.center}\n\nThe `future` package does this thanks to the `plan` function:\n\n- `plan(sequential)`: futures are evaluated sequentially in the current R session\n- `plan(multisession)`: futures are evaluated by new R sessions spawned in the background (*multi-processing in shared memory*)\n- `plan(multicore)`: futures are evaluated in processes forked from the existing process (*multi-processing in shared memory*)\n- `plan(cluster)`: futures are evaluated on an ad-hoc cluster (allows for *distributed parallelism* across multiple nodes)\n\n## Consistency {.center}\n\nTo ensure a consistent behaviour across plans, all evaluations are done in a local environment:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(future)\n\na <- 1\n\nb %<-% {\n  a <- 2\n}\n\na\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n:::\n\n## Let's return to our example {.center}\n\nWe had:\n\n```{.r}\nset.seed(2)\nresult2 <- foreach(icount(1e4), .combine = '+') %do% runif(3)\n```\n\nWe can replace `%do%` with `%dopar%`:\n\n```{.r}\nset.seed(2)\nresult3 <- foreach(icount(1e4), .combine = '+') %dopar% runif(3)\n```\n\nSince we haven't registered any parallel backend, the expression will still be evaluated sequentially.\n\n---\n\nTo run this in parallel, we need to load `doFuture`, register it as a backend (with `registerDoFuture()`), and choose a parallel strategy (e.g. `plan(multicore)`):\n\n```{.r}\nlibrary(foreach)\nlibrary(doFuture)\n\nregisterDoFuture()\nplan(multicore)\n\nset.seed(2)\nresult3 <- foreach(icount(1e4), .combine = '+') %dopar% runif(3)\n```\n\n:::{.note}\n\nWith the overhead of parallelization, it actually doesn't make sense to parallelize such a short code, so let's go over a toy example and do some benchmarking.\n\n:::\n\n# Toy example\n\n## Load packages\n\nFor this toy example, I will use a modified version of one of the examples in the [foreach vignette](https://cran.r-project.org/web/packages/foreach/vignettes/foreach.html): I will b\nuild a classification model made of a forest of decision trees thanks to the [`randomForest`](https://cran.r-project.org/web/packages/randomForest/index.html) package.\n\nBecause the code includes randomly generated numbers, I will use the [`doRNG`](https://cran.r-project.org/web/packages/doRNG/index.html) package which replaces `foreach::%dopar%` wit\nh `doRNG::%dorng%`. This follows the recommendations of Pierre L'Ecuyer (1999)[^1] and ensures reproducibility.\n\n[^1]: [L'Ecuyer, P. (1999). Good parameters and implementations for combined multiple recursive random number generators. Operations Research, 47, 159–164.](https://pubsonline.informs.org/doi/abs/10.1287/opre.47.1.159)\n\n```{.r}\nlibrary(doFuture)       # This will also load the `future` package\nlibrary(doRNG)          # This will also load the `foreach` package\nlibrary(randomForest)\nlibrary(bench)          # To do some benchmarking\n```\n\n```\nLoading required package: foreach\nLoading required package: future\nLoading required package: rngtools\n```\n\n## The code to parallelize {.center}\n\nThe goal is to create a classifier based on some data (here a matrix of random numbers for simplicity) and a response variable (as factor). This model could then be passed in the `predict()` function with novel data to generate predictions of classification. But here we are only interested in the creation of the model as this is the part that is computationally intensive. We aren't interested in actually using it.\n\n```{.r}\nset.seed(11)\ntraindata <- matrix(runif(1e5), 100)\nfac <- gl(2, 50)\n\nrf <- foreach(ntree = rep(250, 8), .combine = combine) %do%\n  randomForest(x = traindata, y = fac, ntree = ntree)\n\nrf\n```\n\n```\nCall:\n randomForest(x = traindata, y = fac, ntree = ntree)\n               Type of random forest: classification\n                     Number of trees: 2000\nNo. of variables tried at each split: 31\n```\n\n## Reference timing {.center}\n\nThis is the non parallelizable code with `%do%`:\n\n```{.r}\ntref <- mark(\n  rf1 <- foreach(ntree = rep(250, 8), .combine = combine) %do%\n    randomForest(x = traindata, y = fac, ntree = ntree),\n  memory = FALSE\n)\n\ntref$median\n```\n\n```\n[1] 5.66s\n```\n\n## Plan sequential {.center}\n\nThis is the parallelizable `foreach` code, but run sequentially:\n\n```{.r}\nregisterDoFuture()   # Set the parallel backend\nplan(sequential)     # Set the evaluation strategy\n\n# Using bench::mark()\ntseq <- mark(\n  rf2 <- foreach(ntree = rep(250, 8), .combine = combine) %dorng%\n    randomForest(x = traindata, y = fac, ntree = ntree),\n  memory = FALSE\n)\n\ntseq$median\n```\n\n```\n[1] 5.78s\n```\n\n:::{.note}\n\nNo surprise: those are similar.\n\n:::\n\n## Multi-processing in shared memory {.center}\n\n`future` provides `availableCores()` to detect the number of available cores:\n\n```{.r}\navailableCores()\n```\n\n```\nsystem\n     4\n```\n\n:::{.note}\n\nSimilar to `parallel::detectCores()`.\n\n:::\n\nThis detects the number of CPU cores available to me on the current compute node, that is, what I can use for shared memory multi-processing.\n\n## Plan multisession {.center}\n\nShared memory multi-processing can be run with `plan(multisession)` that will spawn new R sessions in the background to evaluate futures:\n\n```{.r}\nplan(multisession)\n\ntms <- mark(\n  rf2 <- foreach(ntree = rep(250, 8), .combine = combine) %dorng%\n    randomForest(x = traindata, y = fac, ntree = ntree),\n  memory = FALSE\n)\n\ntms$median\n```\n\n```\n[1] 2s\n```\n\n:::{.note}\n\nWe got a speedup of `5.78 / 2 = 2.9`.\n\n:::\n\n## Plan multicore {.center}\n\nShared memory multi-processing can also be run with `plan(multicore)` (except on Windows) that will fork the current R process to evaluate futures:\n\n```{.r}\nplan(multicore)\n\ntmc <- mark(\n  rf2 <- foreach(ntree = rep(250, 8), .combine = combine) %dorng%\n    randomForest(x = traindata, y = fac, ntree = ntree),\n  memory = FALSE\n)\n\ntmc$median\n```\n\n```\n[1] 1.9s\n```\n\n:::{.note}\n\nWe got a very similar speedup of `5.78 / 1.9 = 3.0`.\n\n:::\n\n## Multi-processing in distributed memory {.center}\n\nI requested 8 tasks from [Slurm](https://en.wikipedia.org/wiki/Slurm_Workload_Manager) on a training cluster made of nodes with 4 CPU cores each. Let's verify that I got them by accessing the `SLURM_NTASKS` environment variable from within R:\n\n```{.r}\nas.numeric(Sys.getenv(\"SLURM_NTASKS\"))\n```\n\n```\n[1] 8\n```\n\nI can create a character vector with the name of the node each task is running on:\n\n```{.r}\n(hosts <- system(\"srun hostname | cut -f 1 -d '.'\", intern = TRUE))\n```\n\n```\nchr [1:8] \"node1\" \"node1\" \"node1\" \"node1\" \"node2\" \"node2\" \"node2\" \"node2\"\n```\n\nThis allows me to create a cluster of workers:\n\n```{.r}\n(cl <- parallel::makeCluster(hosts))      # Defaults to type=\"PSOCK\"\n```\n\n```\nsocket cluster with 8 nodes on hosts ‘node1’, ‘node2’\n```\n\n## Plan cluster {.center}\n\nI can now try the code with distributed parallelism using all 8 CPU cores across both nodes:\n\n```{.r}\nplan(cluster, workers = cl)\n\ntdis <- mark(\n  rf2 <- foreach(ntree = rep(250, 8), .combine = combine) %dorng%\n    randomForest(x = traindata, y = fac, ntree = ntree),\n  memory = FALSE\n)\n\ntdis$median\n```\n\n```\n[1] 1.14s\n```\n\n:::{.note}\n\nSpeedup: `5.78 / 1.14 = 5.1`.\n\n:::\n\nThe cluster of workers can be stopped with:\n\n```{.r}\nparallel::stopCluster(cl)\n```\n\n## Alternative approaches {.center}\n\nThe [multidplyr](https://cran.r-project.org/web/packages/multidplyr/index.html) package partitions data frames across worker processes, allows you to run the usual [tidyverse](https://www.tidyverse.org/) functions on each partition, then collects the processed data.\n\nThe [furrr](https://cran.r-project.org/web/packages/furrr/index.html) package is a parallel equivalent to the [purrr](https://cran.r-project.org/web/packages/purrr/index.html) package from the [tidyverse](https://www.tidyverse.org/).\n\nIf you work with genomic data, you might want to have a look at the [BiocParallel](https://bioconductor.org/packages/release/bioc/html/BiocParallel.html) package from [Bioconductor](https://bioconductor.org/).\n\nYet another option to run distributed R code is to use the [sparklyr](https://cran.r-project.org/web/packages/sparklyr/index.html) package (an R interface to [Spark](https://spark.apache.org/)).\n\n[Rmpi](https://cran.r-project.org/web/packages/Rmpi/index.html) is a wrapper to [MPI (Message-Passing Interface)](https://en.wikipedia.org/wiki/Message_Passing_Interface). It has proved slow and problematic on Cedar though.\n\nThe [boot](https://cran.r-project.org/web/packages/boot/index.html) package provides functions and datasets specifically for bootstrapping in parallel.\n\n# Write C++ with [Rcpp](https://cran.r-project.org/web/packages/Rcpp/index.html)\n\n---\n\n<br>\n\n### When?\n\n- Code that cannot easily be parallelized (e.g. multiple recursive function calls)\n- Large number of function calls\n- Need for data structures missing in R\n- Creation of efficient packages\n\n### How?\n\nRcpp provides C++ classes with mappings to R's `.Call()`. C++ functions can be declared in source files or directly in R scripts.\n\n<!-- ## Example -->\n\n<!-- get the 3 next numbers from the [Fibonacci sequence](https://en.wikipedia.org/wiki/Fibonacci_number): -->\n\n<!-- ```{r} -->\n<!-- start <- n -->\n<!-- i <- 2 -->\n<!-- while (fib[i] < 10) { -->\n<!--   fib <- c(fib, fib[i-1] + fib[i]) -->\n<!--   i <- i + 1 -->\n<!-- } -->\n<!-- print(fib) -->\n<!-- ``` -->\n\n<!-- ## Timing -->\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}