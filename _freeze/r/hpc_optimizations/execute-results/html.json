{
  "hash": "e347f40ca5527d6af55003c8ad6c70ba",
  "result": {
    "markdown": "---\ntitle: Optimizations\naliases:\n  - optimizations.html\nauthor: Marie-Hélène Burle\n---\n\n\n:::{.def}\n\nA lot of hardware is not the answer to poorly written code. Before considering parallelization, you should think about ways to optimize your code sequentially.\n\nWhy?\n\n- Not all code can be parallelized.\n- Parallelization is costly (waiting time to access a cluster or money).\n- The optimization of the sequential code will also benefit the parallel code.\n\nIn many cases, writing better code will save you more computing time than parallelization.\n\nIn this section, we will cover several principles by playing with the programmatic implementation of the [fizz buzz](https://en.wikipedia.org/wiki/Fizz_buzz#:~:text=Fizz%20buzz%20is%20a%20group,with%20the%20word%20%22fizzbuzz%22) game.\n\n:::\n\n## Toy example\n\n[Fizz buzz](https://en.wikipedia.org/wiki/Fizz_buzz#:~:text=Fizz%20buzz%20is%20a%20group,with%20the%20word%20%22fizzbuzz%22) is a children game to practice divisions. Players take turn counting out loud while replacing:\n\n- any number divisible by 3 with the word \"Fizz\",\n- any number divisible by 5 with the word \"Buzz\",\n- any number divisible by both 3 and 5 with the word \"FizzBuzz\".\n\nLet's write functions that output series from `1` to `n` following these rules and time them to draw general principles about code efficiency.\n\n## Setup\n\nFirst of all, we need to load the necessary modules:\n\n```{.bash}\nmodule load StdEnv/2020 gcc/11.3.0 r/4.3.1\n```\n\nThen we need to launch a job.\n\n### Interactive job\n\nIf there are few of us, we will use interactive sessions with one CPU each with:\n\n```{.bash}\nsalloc --time=2:00:00 --mem-per-cpu=3500M\n```\n\nWe can then launch R and load the benchmarking package we will use throughout this section:\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-1_ea52281d6ce36927302fcc64c7832eff'}\n\n```{.r .cell-code}\nlibrary(bench)\n```\n:::\n\n\n### Batch jobs\n\nIf there are more of us than there are CPUs in the cluster, we will run batch jobs. In this Case:\n\n- Create an R script called `optim.R` with the code to run (you can reuse the same script for all sections on this page by editing it). Don't forget to load the package `bench` in your script.\n- Create a bash script called `optim.sh` with the following:\n\n```{.bash filename=\"<your_job>.sh\"}\n#!/bin/bash\n#SBATCH --account=def-<your_account>\n#SBATCH --time=15\n#SBATCH --mem-per-cpu=3500M\n#SBATCH --cpus-per-task=4\n#SBATCH --job-name=\"<your_job>\"\nmodule load StdEnv/2020 gcc/11.3.0 r/4.3.1\nRscript <your_script>.R\n```\n\n- Run the jobs with:\n\n```sh\nsbatch optim.sh\n```\n\n## Optimizations\n\n### Pre-allocate memory\n\nIn order to store the results of a loop, we need to create an object and assign to it the result of the loop at each iteration. In this first function, we create an empty object `z` of class integer and of length `0` for that purpose:\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-2_9c82f0f2025e5713556230094be4222b'}\n\n```{.r .cell-code}\nf1 <- function(n) {\n  z <- integer()\n  for(i in 1:n) {\n    if(i %% 3 == 0 && i %% 5 == 0) {\n      z[i] <- \"FizzBuzz\"\n    } else if(i %% 3 == 0) {\n      z[i] <- \"Fizz\"\n    } else if(i %% 5 == 0) {\n      z[i] <- \"Buzz\"\n    } else {\n      z[i] <- i\n    }\n  }\n  z\n}\n```\n:::\n\n\nThe second function is similar, but this time, we initialize `z` with its final length. This means that we are pre-allocating memory for the full vector before we run the loop instead of growing the vector at each iteration:\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-3_e126f17501b711f9942dae4b416a200e'}\n\n```{.r .cell-code}\nf2 <- function(n) {\n  z <- integer(n)\n  for(i in 1:n) {\n    if(i %% 3 == 0 && i %% 5 == 0) {\n      z[i] <- \"FizzBuzz\"\n    } else if(i %% 3 == 0) {\n      z[i] <- \"Fizz\"\n    } else if(i %% 5 == 0) {\n      z[i] <- \"Buzz\"\n    } else {\n      z[i] <- i\n    }\n  }\n  z\n}\n```\n:::\n\n\nLet's make sure that our functions work by testing it on a small number:\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-4_0d07183f530283f017931937572e2d65'}\n\n```{.r .cell-code}\nf1(20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"1\"        \"2\"        \"Fizz\"     \"4\"        \"Buzz\"     \"Fizz\"    \n [7] \"7\"        \"8\"        \"Fizz\"     \"Buzz\"     \"11\"       \"Fizz\"    \n[13] \"13\"       \"14\"       \"FizzBuzz\" \"16\"       \"17\"       \"Fizz\"    \n[19] \"19\"       \"Buzz\"    \n```\n:::\n\n```{.r .cell-code}\nf2(20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"1\"        \"2\"        \"Fizz\"     \"4\"        \"Buzz\"     \"Fizz\"    \n [7] \"7\"        \"8\"        \"Fizz\"     \"Buzz\"     \"11\"       \"Fizz\"    \n[13] \"13\"       \"14\"       \"FizzBuzz\" \"16\"       \"17\"       \"Fizz\"    \n[19] \"19\"       \"Buzz\"    \n```\n:::\n:::\n\n\nNow, let's benchmark them for a large number:\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-5_d936bcd74ff0b1c5986729b3893461f0'}\n\n```{.r .cell-code}\nn <- 1e5\nmark(f1(n), f2(n))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  expression      min   median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n1 f1(n)         139ms    140ms      7.01   16.65MB     26.3\n2 f2(n)         123ms    124ms      8.04    1.24MB     30.5\n```\n:::\n:::\n\n\n`f2()` is consistently faster, although very slightly. In many cases, the difference you will find will be a lot greater.\n\nNote also the large difference in memory allocation.\n\n### No, loops are not a big 'no no'\n\nBy now, you might be thinking: \"Wait... aren't loops a big 'no no' in R? I've always been told that they are slow and that one should always use functional programming! We are talking about optimization in this course and we are using loops?!?\"\n\nThere are a lot of misconceptions around R loops. They can be very slow if you don't pre-allocate memory. Otherwise they are almost always faster than functions (the `apply()` family or the [tidyverse](https://www.tidyverse.org/) equivalent of the `purrr::map()` family). You can choose to use a functional programming approach for style and readability, but not for speed.\n\nLet's test it.\n\nFirst we create a function:\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-6_14e08592cb15ea9403bb228ee75ff524'}\n\n```{.r .cell-code}\nf3 <- function(n) {\n  if(n %% 3 == 0 && n %% 5 == 0) {\n    \"FizzBuzz\"\n  } else if(n %% 3 == 0) {\n    \"Fizz\"\n  } else if(n %% 5 == 0) {\n    \"Buzz\"\n  } else {\n    n\n  }\n}\n```\n:::\n\n\nThen we pass it through `sapply()`. We can test that it works on a small number:\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-7_e00d16689b9ef147618e688d9dde9e4e'}\n\n```{.r .cell-code}\nsapply(1:20, f3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"1\"        \"2\"        \"Fizz\"     \"4\"        \"Buzz\"     \"Fizz\"    \n [7] \"7\"        \"8\"        \"Fizz\"     \"Buzz\"     \"11\"       \"Fizz\"    \n[13] \"13\"       \"14\"       \"FizzBuzz\" \"16\"       \"17\"       \"Fizz\"    \n[19] \"19\"       \"Buzz\"    \n```\n:::\n:::\n\n\nFinally, we compare the timing with that of `f2()`:\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-8_a110aa7f84e68768f53338d0b8703c9e'}\n\n```{.r .cell-code}\nmark(f2(n), sapply(1:n, f3))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  expression           min   median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr>      <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n1 f2(n)              132ms    135ms      7.40    1.15MB     35.2\n2 sapply(1:n, f3)    180ms    189ms      5.18    3.35MB     31.1\n```\n:::\n:::\n\n\nAs you can see, the loop is faster.\n\n### Avoid unnecessary operations\n\n#### Example 1\n\nCalling `z` as the last command in our function is the same as calling `return(z)`.\n\nFrom the R documentation:\n\n> If the end of a function is reached without calling return, the value of the last evaluated expression is returned.\n\nNow, what about using `print()` instead?\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-9_15b9dac70cce66ced1594080b3c9e4ca'}\n\n```{.r .cell-code}\nf4 <- function(n) {\n  z <- integer(n)\n  for(i in 1:n) {\n    if(i %% 3 == 0 && i %% 5 == 0) {\n      z[i] <- \"FizzBuzz\"\n    } else if(i %% 3 == 0) {\n      z[i] <- \"Fizz\"\n    } else if(i %% 5 == 0) {\n      z[i] <- \"Buzz\"\n    } else {\n      z[i] <- i\n    }\n  }\n  print(z)\n}\n```\n:::\n\n\nLet's benchmark it against `f2()`:\n\n```{.r}\nmark(f2(n), f4(n))\n```\n\n```\n [1] \"1\"        \"2\"        \"Fizz\"     \"4\"        \"Buzz\"     \"Fizz\"    \n [7] \"7\"        \"8\"        \"Fizz\"     \"Buzz\"     \"11\"       \"Fizz\"    \n[13] \"13\"       \"14\"       \"FizzBuzz\" \"16\"       \"17\"       \"Fizz\"    \n[19] \"19\"       \"Buzz\"     \"Fizz\"     \"22\"       \"23\"       \"Fizz\"    \n[25] \"Buzz\"     \"26\"       \"Fizz\"     \"28\"       \"29\"       \"FizzBuzz\"\n[31] \"31\"       \"32\"       \"Fizz\"     \"34\"       \"Buzz\"     \"Fizz\"    \n[37] \"37\"       \"38\"       \"Fizz\"     \"Buzz\"     \"41\"       \"Fizz\"\n...\n\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n# A tibble: 2 × 6\n  expression      min   median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n1 f2(1e+05)  151.88ms 157.65ms     6.30     1.25MB     29.9\n2 f4(1e+05)     3.25s    3.25s     0.308    1.04GB     26.8\n```\n\nWhat happened?\n\n`print()` returns its argument, but it additionally prints it to the standard output. This is why the `mark()` function printed the output of `f4()` before printing the timings.\n\nAs you can see, printing takes a long time.\n\n:::{.note}\n\nThe code in this website is run by Quarto. Since, by default, RStudio will only print the first 1,000 results, the timing you will get for `f4()` in RStudio will be much less bad as it won't include the time it takes to print the remaining 99,000 results.\n\n:::\n\nIf you are evaluating `f2()` on its own (e.g. `f2(20)`), the returned result will also be printed to standard output and both functions will be equivalent. However, if you are using the function in another context, printing becomes an unnecessary and timely operation and `f4()` would be a very bad option. `f4()` is thus not a good function.\n\nHere is an example in which `f4()` would perform a totally unnecessary operation that `f2()` avoids:\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-10_464a7f98efa992df678389a96b441dad'}\n\n```{.r .cell-code}\na <- f2(20)\n```\n:::\n\n\n:::{.note}\n\nNo unnecessary printing.\n\n:::\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-11_50ffd76c7cb68b777071404022ee2d66'}\n\n```{.r .cell-code}\na <- f4(20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"1\"        \"2\"        \"Fizz\"     \"4\"        \"Buzz\"     \"Fizz\"    \n [7] \"7\"        \"8\"        \"Fizz\"     \"Buzz\"     \"11\"       \"Fizz\"    \n[13] \"13\"       \"14\"       \"FizzBuzz\" \"16\"       \"17\"       \"Fizz\"    \n[19] \"19\"       \"Buzz\"    \n```\n:::\n:::\n\n\n:::{.note}\n\nUnnecessary printing.\n\n:::\n\nFor 1e5, the difference in timing between running an unnecessary printing vs not is a factor of 21!\n\nEven worse would be to use:\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-12_f01580a56fbc45b15696059dd267cddd'}\n\n```{.r .cell-code}\nf5 <- function(n) {\n  for(i in 1:n) {\n    if(i %% 3 == 0 && i %% 5 == 0) {\n      print(\"FizzBuzz\")\n    } else if(i %% 3 == 0) {\n      print(\"Fizz\")\n    } else if(i %% 5 == 0) {\n      print(\"Buzz\")\n    } else {\n      print(i)\n    }\n  }\n}\n```\n:::\n\n\nHere the difference in timing is a factor of 50...\n\n#### Example 2\n\nOne modulo operation and equality test can be removed by replacing `i %% 3 == 0 && i %% 5 == 0` by `i %% 15 == 0`. We now have three modulo operations and equality tests per iteration instead of four. This gives us a little speedup:\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-13_366f3e62734a9e8bd2f006357ff28ba2'}\n\n```{.r .cell-code}\nf6 <- function(n) {\n  z <- integer(n)\n  for(i in 1:n) {\n    if(i %% 15 == 0) {\n      z[i] <- \"FizzBuzz\"\n    } else if(i %% 3 == 0) {\n      z[i] <- \"Fizz\"\n    } else if(i %% 5 == 0) {\n      z[i] <- \"Buzz\"\n    } else {\n      z[i] <- i\n    }\n  }\n  z\n}\n\nmark(f2(n), f6(n))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  expression      min   median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n1 f2(n)         125ms    132ms      7.60    1.25MB     28.5\n2 f6(n)         115ms    121ms      8.32    1.22MB     30.0\n```\n:::\n:::\n\n\nBut we can remove an additional modulo operation and equality test at each iteration by assigning `i %% 3 == 0` and `i %% 5 == 0` to variables:\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-14_2205ec5cccf51a45d7ac4b41bdb660ac'}\n\n```{.r .cell-code}\nf7 <- function(n) {\n  z <- integer(n)\n  for(i in 1:n) {\n    div3 <- (i %% 3 == 0)\n    div5 <- (i %% 5 == 0)\n    if(div3 && div5) {\n      z[i] <- \"FizzBuzz\"\n    } else if(div3) {\n      z[i] <- \"Fizz\"\n    } else if(div5) {\n      z[i] <- \"Buzz\"\n    } else {\n      z[i] <- i\n    }\n  }\n  z\n}\n```\n:::\n\n\nNow we only have two modulo operations and equality tests per iteration and we get another little speedup:\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-15_b24fb2eda13c59eca042cb8d76e9992a'}\n\n```{.r .cell-code}\nmark(f6(n), f7(n))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  expression      min   median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n1 f6(n)         118ms    119ms      8.20    1.15MB     32.8\n2 f7(n)         111ms    113ms      8.83    1.22MB     28.2\n```\n:::\n:::\n\n\n#### Example 3\n\nWe can assign `1:n` to `z` instead of initializing it as an empty vector, thus rendering the assignment of `i` to `z[i]` in the last else statement unnecessary:\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-16_9d2c164d535e03f84b1719b5085063d6'}\n\n```{.r .cell-code}\nf8 <- function(n) {\n  z <- 1:n\n  for(i in z) {\n    div3 <- (i %% 3 == 0)\n    div5 <- (i %% 5 == 0)\n    if(div3 && div5) {\n      z[i] <- \"FizzBuzz\"\n    } else if(div3) {\n      z[i] <- \"Fizz\"\n    } else if(div5) {\n      z[i] <- \"Buzz\"\n    } \n  }\n  z\n}\n```\n:::\n\n\nThis function works:\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-17_0241eaa771ebb719941273cdde53c676'}\n\n```{.r .cell-code}\nf8(20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"1\"        \"2\"        \"Fizz\"     \"4\"        \"Buzz\"     \"Fizz\"    \n [7] \"7\"        \"8\"        \"Fizz\"     \"Buzz\"     \"11\"       \"Fizz\"    \n[13] \"13\"       \"14\"       \"FizzBuzz\" \"16\"       \"17\"       \"Fizz\"    \n[19] \"19\"       \"Buzz\"    \n```\n:::\n:::\n\n\nand we get a really good speedup here:\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-18_b3b6d57849b724e132d111d9c7a9bb95'}\n\n```{.r .cell-code}\nmark(f7(n), f8(n))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  expression      min   median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n1 f7(n)       100.3ms    108ms      9.14    1.15MB     31.1\n2 f8(n)        62.6ms     65ms     15.4     1.15MB     40.4\n```\n:::\n:::\n\n\n### Vectorize whenever possible\n\nWe can actually get rid of the loop and use a vectorized approach.\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-19_1626282a2e49b067e1f38f64911deb1e'}\n\n```{.r .cell-code}\nf9 <- function(n) {\n  z <- 1:n\n  div3 <- (z %% 3 == 0)\n  div5 <- (z %% 5 == 0)\n  z[div3] <- \"Fizz\"\n  z[div5] <- \"Buzz\"\n  z[(div3 & div5)] <- \"FizzBuzz\"\n  z\n}\n```\n:::\n\n\nThis still give us the same result:\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-20_5e917cd9dfa57e3e9aa60196b54d9f14'}\n\n```{.r .cell-code}\nf9(20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"1\"        \"2\"        \"Fizz\"     \"4\"        \"Buzz\"     \"Fizz\"    \n [7] \"7\"        \"8\"        \"Fizz\"     \"Buzz\"     \"11\"       \"Fizz\"    \n[13] \"13\"       \"14\"       \"FizzBuzz\" \"16\"       \"17\"       \"Fizz\"    \n[19] \"19\"       \"Buzz\"    \n```\n:::\n:::\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-21_705f07cd1a558f06a753acb23fe5fd3c'}\n\n```{.r .cell-code}\nmark(f8(n), f9(n))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  expression      min   median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n1 f8(n)        62.4ms   65.9ms      15.2    1.15MB    39.9 \n2 f9(n)          18ms   18.4ms      51.9    5.62MB     5.99\n```\n:::\n:::\n\n\nThe speedup of 3.8 shows how important it is to use vectorization whenever possible.\n\n### Replace costly operations where possible\n\nSometimes, it isn't obvious that one method will be faster than another. Benchmarking alternative expressions can teach you which ones are faster.\n\nFor instance, it is much faster to index a column from a dataframe by its name (e.g. `dataframe$column1`) than by using list indexing (e.g. `dataframe[[1]]`).\n\nSometimes, packages exist which bring much more efficiency than can be achieved with base R. In the case of data frames for example, there is [data.table](https://cran.r-project.org/web/packages/data.table/index.html).\n\n### Conclusion\n\nStarting from our first function `f1()`, we have gained a speedup of 7.4, simply by writing better code and without using parallelization and additional hardware:\n\n\n::: {.cell hash='hpc_optimizations_cache/html/unnamed-chunk-22_1bf427707e7f300cea1f9feda775e614'}\n\n```{.r .cell-code}\nmark(f1(n), f9(n))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  expression      min   median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n1 f1(n)       131.5ms  132.2ms      7.42   16.65MB    33.4 \n2 f9(n)        17.4ms   17.9ms     53.9     5.57MB     5.99\n```\n:::\n:::\n\n\nIf we used a silly function such as `f5()` as our starting function, the speedup would be 370.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}