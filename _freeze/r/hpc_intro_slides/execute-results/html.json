{
  "hash": "82c01769dde2d37855a624b9d8a86541",
  "result": {
    "markdown": "---\ntitle: Introduction to high-performance research computing in R\nfrontlogo: /img/sfudrac.png\nauthor: Marie-Hélène Burle\ndate: 2023-01-31\ndate-format: long\nexecute:\n  error: true\n  echo: true\nformat:\n  revealjs:\n    # embed-resources: true\n    theme: [default, ../revealjs.scss]\n    logo: /img/sfudrac_logo.png\n    highlight-style: monokai\n    code-line-numbers: false\n    code-overflow: wrap\n    template-partials:\n      - ../title-slide.html\n    pointer:\n      color: \"#b5111b\"\n      pointerSize: 32\n    link-external-newwindow: true\n    footer: <a href=\"hpc_intro.html\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" fill=\"rgb(153, 153, 153)\" class=\"bi bi-arrow-90deg-up\" viewBox=\"0 0 16 16\"><path fill-rule=\"evenodd\" d=\"M4.854 1.146a.5.5 0 0 0-.708 0l-4 4a.5.5 0 1 0 .708.708L4 2.707V12.5A2.5 2.5 0 0 0 6.5 15h8a.5.5 0 0 0 0-1h-8A1.5 1.5 0 0 1 5 12.5V2.707l3.146 3.147a.5.5 0 1 0 .708-.708l-4-4z\"/></svg>&nbsp;Back to workshop page</a>\nrevealjs-plugins:\n  - pointer\n---\n\n\n# Running R on Alliance clusters\n\n## Loading modules: Intel vs GCC compilers\n\nTo compile R packages, you need a C compiler.\n\nIn theory, you could use the proprietary Intel compiler which is loaded by default on the Alliance clusters, but it is recommended to replace it with the GCC compiler (R packages can even be compiled with Clang and LLVM, but the default GCC compiler is the best way to avoid headaches).\n\nIt is thus much simpler to always load a `gcc` module before loading an `r` module.\n\n## Loading modules: R module\n\nTo see what versions of R are available on a cluster, run:\n\n```{.bash}\n$ module spider r\n```\n\nTo see the dependencies of a particular version (e.g. `r/4.2.1`), run:\n\n```{.bash}\n$ module spider r/4.2.1\n```\n\n:::{.note}\n\n`StdEnv/2020` is a required module for this version.\n\nOn most Alliance clusters, it is automatically loaded, so you don't need to include it. You can double-check with `module list` or you can include it (before `r/4.2.1`) just to be sure.\n\n:::\n\nFinally, load your modules:\n\n```{.bash}\n$ module load StdEnv/2020 gcc/11.3.0 r/4.2.1\n```\n\n## Installing R packages\n\nTo install a package, launch the interactive R console with:\n\n```{.bash}\n$ R\n```\n\nIn the R console, run:\n\n```{.r}\ninstall.packages(\"<package_name>\", repos=\"<url-cran-mirror>\")\n```\n\n:::{.note}\n\n\nYou have to select a CRAN mirror from [this list](https://cran.r-project.org/mirrors.html){target=\"_blank\"}. Ideally, use a mirror close to the location of the cluster you are using or use <https://cloud.r-project.org/>. \\\n<https://mirror.rcg.sfu.ca/mirror/CRAN/> is the closest mirror for Cedar.\n\n:::\n\n:::{.note}\n\nThe first time you install a package, R will ask you whether you want to create a personal library in your home directory. Answer `yes` to both questions. Your packages will now install under `~/`.\n\n:::\n\n:::{.note}\n\nA handful of packages require additional modules to be loaded before they can be installed. This will be indicated in the error messages you will get when you try to install them.\n\n:::\n\n## Installing R packages\n\nLet's install the packages needed for this webinar:\n\n```{.r}\ninstall.packages(\n  c(\"profvis\", \"bench\", \"doParallel\", \"furrr\", \"Rmpi\", \"Rcpp\"),\n  repos=\"https://mirror.rcg.sfu.ca/mirror/CRAN/\"\n)\n```\n\n## Running R jobs\n\n:::{.note}\n\nWhile it is totally fine to run R on the login node when you install packages, you **must start a SLURM job before any heavy computation**.\n\n:::\n\n### Interactive jobs\n\nTo run R interactively, you should launch an `salloc` session before launching R:\n\n```{.bash}\n$ salloc --time=1:00:00 --mem-per-cpu=3000M --cpus-per-task=4\n$ R\n```\n\n---\n\n### Scripts\n\nTo run an R script called `<your_script>.R`, you first need to write a job script.\n\n:::{.example}\n\nExample:\n\n```{.bash filename=\"<your_job>.sh\"}\n#!/bin/bash\n#SBATCH --account=def-<your_account>\n#SBATCH --time=15\n#SBATCH --mem-per-cpu=3000M\n#SBATCH --cpus-per-task=4\n#SBATCH --job-name=\"<your_job>\"\nmodule load StdEnv/2020 gcc/11.3.0 r/4.2.1\nRscript <your_script>.R\n```\n\n:::{.note}\n\nNote that R scripts are run with the command `Rscript`.\n\n:::\n\n:::\n\nThen launch your job with:\n\n```{.bash}\n$ sbatch <your_job>.sh\n```\n\nYou can monitor your job with `sq` (an alias for `squeue -u $USER $@`).\n\n# Performance\n\n## system.time()\n\nget info on efficiency\n\n.```{.r}\nsystem.time({\n\n})\n```\n\n## Profiling\n\nThe first thing to do if you want to improve your code efficiency is to identify bottlenecks.\n\nWe will use the package [profvis](https://cran.r-project.org/web/packages/profvis/index.html):\n\n```{.r}\nlibrary(profvis)\n```\n\n## Benchmarking\n\nWe will use the [bench](https://cran.r-project.org/web/packages/bench/index.html) package described by Jim Hester in a [Tidyverse blog post](https://www.tidyverse.org/blog/2018/06/bench-1.0.1/):\n\n\n::: {.cell hash='hpc_intro_slides_cache/revealjs/unnamed-chunk-1_b7e689ba69d4399037ce0dd2ca91352b'}\n\n```{.r .cell-code}\nlibrary(bench)\n```\n:::\n\n\n`bench::mark()` compares the run time, memory usage, and garbage collections of equivalent codes.\n\n\n\n\n# Parallel R\n\nhttps://bookdown.org/rdpeng/RProgDA/profiling-and-benchmarking.html\nhttps://bookdown.org/rdpeng/rprogdatascience/profiling-r-code.html\nhttps://bookdown.org/rdpeng/rprogdatascience/data-analysis-case-study-changes-in-fine-particle-air-pollution-in-the-u.s..html#loading-and-processing-the-raw-data\nhttps://cran.r-project.org/web/packages/rsimsum/vignettes/C-plotting.html\nhttps://cran.r-project.org/web/packages/rsimsum/vignettes/A-introduction.html\nhttps://www.tidyverse.org/blog/2018/06/bench-1.0.1/\nhttps://github.com/ecophilina/herring-birds/blob/master/scripts/02-get-data.R\n\n<!-- https://adv-r.hadley.nz/rcpp.html -->\n<!-- https://gallery.rcpp.org/ -->\n<!-- https://www.tidyverse.org/blog/2018/06/bench-1.0.1/ -->\n<!-- http://rstudio.github.io/profvis/index.html -->\n<!-- https://bookdown.org/rdpeng/rprogdatascience/parallel-computation.html#example-bootstrapping-a-statistic -->\n<!-- http://zevross.com/blog/2019/02/12/dramatically-speed-up-your-r-purrr-functions-with-the-furrr-package/ -->\n<!-- https://furrr.futureverse.org/ -->\n<!-- https://www.tidyverse.org/blog/2020/10/furrr-0-2-0/ -->\n<!-- https://cran.r-project.org/web/packages/foreach/vignettes/foreach.html -->\n<!-- https://www.blasbenito.com/post/02_parallelizing_loops_with_r/ -->\n<!-- https://docs.alliancecan.ca/wiki/R#install.packages.28.29 -->\n<!-- https://yxue-me.com/post/2019-05-12-a-glossary-of-parallel-computing-packages-in-r-2019/ -->\n<!-- https://dept.stat.lsa.umich.edu/~jerrick/courses/stat701/notes/parallel.html -->\n<!-- https://docs.csc.fi/support/tutorials/parallel-r/ -->\n<!-- https://bioinfomagician.wordpress.com/2013/11/25/mpi-tutorial-for-r-rmpi/ -->\n<!-- https://help.rc.ufl.edu/doc/R_MPI_Example -->\n\n\n<!-- https://towardsdatascience.com/getting-started-with-parallel-programming-in-r-d5f801d43745 -->\n<!-- https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html -->\n<!-- https://yxue-me.com/post/2019-05-12-a-glossary-of-parallel-computing-packages-in-r-2019/ -->\n<!-- https://subscription.packtpub.com/book/big-data-and-business-intelligence/9781784394004/1/ch01lvl1sec09/the-r-parallel-package -->\n<!-- https://www.r-bloggers.com/2017/08/implementing-parallel-processing-in-r/ -->\n<!-- https://www.stat.umn.edu/geyer/3701/notes/parallel.html -->\n<!-- https://www.stat.umn.edu/geyer/8054/notes/parallel.html -->\n<!-- https://blog.esciencecenter.nl/parallel-r-in-a-nutshell-4391d45b5461 -->\n<!-- https://dept.stat.lsa.umich.edu/~jerrick/courses/stat701/notes/parallel.html -->\n<!-- https://bookdown.org/rdpeng/rprogdatascience/parallel-computation.html -->\n<!-- https://docs.alliancecan.ca/wiki/R#doParallel_and_foreach -->\n<!-- https://www.r-bloggers.com/2016/01/strategies-to-speedup-r-code/ -->\n<!-- https://www.datacamp.com/tutorial/r-tutorial-apply-family -->\n<!-- https://bookdown.org/rdpeng/rprogdatascience/profiling-r-code.html -->\n\n<!-- Start large (4GB) on a test script. Then: -->\n<!-- While the script is running, check how much memory is used in real time by typing: sstat yourjobID.batch --format=\"JobID,MaxRSS\" -->\n<!-- Or -->\n<!-- When the script is done running, check how much was used by typing: sacct -o MaxRSS -j yourjobID -->\n<!-- If you check the slurm.out file and you’re getting “oom-kill” errors, you need to request more memory -->\n<!-- If you’re using less than you asked for, it’s beneficial to reduce the memory in --mem or --mem-per-cpu (this way your job will get scheduled sooner) -->\n<!-- Resubmit your job with your new estimate. -->\n\n\n<!-- Independent repeats of computations (e.g. bootstrapping) -->\n\n<!-- No communication needed between computations. -->\n\n## parallel package (base R)\n\nThe `parallel` package has been part of the \"base\" package group since version 2.14.0. \\\nThis means that it is comes with R and is loaded by default.\n\n<!-- (a) Start up M ‘worker’ processes, and do any initialization needed on the workers. -->\n<!-- (b) Send any data required for each task to the workers. -->\n<!-- (c) Split the task into M roughly equally-sized chunks, and send the chunks (including the R -->\n<!-- code needed) to the workers. -->\n<!-- (d) Wait for all the workers to complete their tasks, and ask them for their results. -->\n<!-- (e) Repeat steps (b–d) for any further tasks. -->\n<!-- (f) Shut down the worker processes. -->\n\n## furrr package\n\nThe [furrr](https://cran.r-project.org/web/packages/furrr/index.html) package xxx Davis Vaughan xxx in this [Tidyverse blog post](https://www.tidyverse.org/blog/2020/10/furrr-0-2-0/).\n\n## doParallel package\n\nand foreach package\n\n\n## boot package\n\n\n## Rmpi package\n\n[Rmpi](https://cran.r-project.org/web/packages/Rmpi/index.html) is a wrapper to MPI (Message-Passing Interface)\n\n# Using C++ with the [Rcpp](https://cran.r-project.org/web/packages/Rcpp/index.html) package\n\n\n\n## Use cases\n\n- Code that can't be parallelized\n- Large number of function calls\n- Data structures missing in R\n- Creation of packages\n\n## Functioning\n\n## Example\n\n\n\n# Questions?\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}