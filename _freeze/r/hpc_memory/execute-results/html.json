{
  "hash": "eb56262bd2fb336ca446a60f319fe279",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Memory management\naliases:\n  - memory.html\nauthor: Marie-Hélène Burle\n---\n\n\n\n\n:::{.def}\n\nMemory can be a limiting factor and releasing it when not needed can be critical to avoid [out of memory](https://en.wikipedia.org/wiki/Out_of_memory) states. On the other hand, [memoisation](https://en.wikipedia.org/wiki/Memoization) is an optimization technique which consists of caching the results of heavy computations for re-use.\n\nMemory and speed are thus linked in a trade-off.\n\n:::\n\n## Releasing memory\n\nIt is best to avoid creating very large intermediate objects that take space in memory unnecessarily.\n\n- One option is to use nested functions or functions chained with pipes.\n\n- Another option is to create the intermediate objects within the local environment of a function as they will automatically be deleted as soon as the function has finished running.\n\nLet's go over a basic example: let's extract the sepal width variable from [the iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) (one of the datasets that come packaged with R), take the natural logarithm of the values, and round them to one decimal place.\n\nFirst, let's delete all objects inside our environment to make our little test as clean as possible:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm(list=ls())\nls()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ncharacter(0)\n```\n\n\n:::\n:::\n\n\n\n\nNow, we could perform our task this way:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsepalwidth <- iris$Sepal.Width\nsepalwidth_ln <- log(sepalwidth)\nround(sepalwidth_ln, 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  [1] 1.3 1.1 1.2 1.1 1.3 1.4 1.2 1.2 1.1 1.1 1.3 1.2 1.1 1.1 1.4 1.5 1.4 1.3\n [19] 1.3 1.3 1.2 1.3 1.3 1.2 1.2 1.1 1.2 1.3 1.2 1.2 1.1 1.2 1.4 1.4 1.1 1.2\n [37] 1.3 1.3 1.1 1.2 1.3 0.8 1.2 1.3 1.3 1.1 1.3 1.2 1.3 1.2 1.2 1.2 1.1 0.8\n [55] 1.0 1.0 1.2 0.9 1.1 1.0 0.7 1.1 0.8 1.1 1.1 1.1 1.1 1.0 0.8 0.9 1.2 1.0\n [73] 0.9 1.0 1.1 1.1 1.0 1.1 1.1 1.0 0.9 0.9 1.0 1.0 1.1 1.2 1.1 0.8 1.1 0.9\n [91] 1.0 1.1 1.0 0.8 1.0 1.1 1.1 1.1 0.9 1.0 1.2 1.0 1.1 1.1 1.1 1.1 0.9 1.1\n[109] 0.9 1.3 1.2 1.0 1.1 0.9 1.0 1.2 1.1 1.3 1.0 0.8 1.2 1.0 1.0 1.0 1.2 1.2\n[127] 1.0 1.1 1.0 1.1 1.0 1.3 1.0 1.0 1.0 1.1 1.2 1.1 1.1 1.1 1.1 1.1 1.0 1.2\n[145] 1.2 1.1 0.9 1.1 1.2 1.1\n```\n\n\n:::\n:::\n\n\n\n\nBut this creates the unnecessary intermediate variables `sepalwidth` and `sepalwidth_ln` which get stored in memory:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nls()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"sepalwidth\"    \"sepalwidth_ln\"\n```\n\n\n:::\n:::\n\n\n\n\nFor very large objects, this is not ideal.\n\nLet's clear objects in our environment again:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm(list=ls())\nls()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ncharacter(0)\n```\n\n\n:::\n:::\n\n\n\n\nA better option is to use nested functions:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nround(log(iris$Sepal.Width), 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  [1] 1.3 1.1 1.2 1.1 1.3 1.4 1.2 1.2 1.1 1.1 1.3 1.2 1.1 1.1 1.4 1.5 1.4 1.3\n [19] 1.3 1.3 1.2 1.3 1.3 1.2 1.2 1.1 1.2 1.3 1.2 1.2 1.1 1.2 1.4 1.4 1.1 1.2\n [37] 1.3 1.3 1.1 1.2 1.3 0.8 1.2 1.3 1.3 1.1 1.3 1.2 1.3 1.2 1.2 1.2 1.1 0.8\n [55] 1.0 1.0 1.2 0.9 1.1 1.0 0.7 1.1 0.8 1.1 1.1 1.1 1.1 1.0 0.8 0.9 1.2 1.0\n [73] 0.9 1.0 1.1 1.1 1.0 1.1 1.1 1.0 0.9 0.9 1.0 1.0 1.1 1.2 1.1 0.8 1.1 0.9\n [91] 1.0 1.1 1.0 0.8 1.0 1.1 1.1 1.1 0.9 1.0 1.2 1.0 1.1 1.1 1.1 1.1 0.9 1.1\n[109] 0.9 1.3 1.2 1.0 1.1 0.9 1.0 1.2 1.1 1.3 1.0 0.8 1.2 1.0 1.0 1.0 1.2 1.2\n[127] 1.0 1.1 1.0 1.1 1.0 1.3 1.0 1.0 1.0 1.1 1.2 1.1 1.1 1.1 1.1 1.1 1.0 1.2\n[145] 1.2 1.1 0.9 1.1 1.2 1.1\n```\n\n\n:::\n:::\n\n\n\n\nAn equivalent option is to chain functions:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\niris$Sepal.Width |> log() |> round(1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  [1] 1.3 1.1 1.2 1.1 1.3 1.4 1.2 1.2 1.1 1.1 1.3 1.2 1.1 1.1 1.4 1.5 1.4 1.3\n [19] 1.3 1.3 1.2 1.3 1.3 1.2 1.2 1.1 1.2 1.3 1.2 1.2 1.1 1.2 1.4 1.4 1.1 1.2\n [37] 1.3 1.3 1.1 1.2 1.3 0.8 1.2 1.3 1.3 1.1 1.3 1.2 1.3 1.2 1.2 1.2 1.1 0.8\n [55] 1.0 1.0 1.2 0.9 1.1 1.0 0.7 1.1 0.8 1.1 1.1 1.1 1.1 1.0 0.8 0.9 1.2 1.0\n [73] 0.9 1.0 1.1 1.1 1.0 1.1 1.1 1.0 0.9 0.9 1.0 1.0 1.1 1.2 1.1 0.8 1.1 0.9\n [91] 1.0 1.1 1.0 0.8 1.0 1.1 1.1 1.1 0.9 1.0 1.2 1.0 1.1 1.1 1.1 1.1 0.9 1.1\n[109] 0.9 1.3 1.2 1.0 1.1 0.9 1.0 1.2 1.1 1.3 1.0 0.8 1.2 1.0 1.0 1.0 1.2 1.2\n[127] 1.0 1.1 1.0 1.1 1.0 1.3 1.0 1.0 1.0 1.1 1.2 1.1 1.1 1.1 1.1 1.1 1.0 1.2\n[145] 1.2 1.1 0.9 1.1 1.2 1.1\n```\n\n\n:::\n:::\n\n\n\n\nAnother option is to create the intermediate variables in the local environment of a function:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_sepalwidth <- function(dataset) {\n  sepalwidth <- dataset$Sepal.Width\n  sepalwidth_ln <- log(sepalwidth)\n  round(sepalwidth_ln, 1)\n}\n\nget_sepalwidth(iris)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  [1] 1.3 1.1 1.2 1.1 1.3 1.4 1.2 1.2 1.1 1.1 1.3 1.2 1.1 1.1 1.4 1.5 1.4 1.3\n [19] 1.3 1.3 1.2 1.3 1.3 1.2 1.2 1.1 1.2 1.3 1.2 1.2 1.1 1.2 1.4 1.4 1.1 1.2\n [37] 1.3 1.3 1.1 1.2 1.3 0.8 1.2 1.3 1.3 1.1 1.3 1.2 1.3 1.2 1.2 1.2 1.1 0.8\n [55] 1.0 1.0 1.2 0.9 1.1 1.0 0.7 1.1 0.8 1.1 1.1 1.1 1.1 1.0 0.8 0.9 1.2 1.0\n [73] 0.9 1.0 1.1 1.1 1.0 1.1 1.1 1.0 0.9 0.9 1.0 1.0 1.1 1.2 1.1 0.8 1.1 0.9\n [91] 1.0 1.1 1.0 0.8 1.0 1.1 1.1 1.1 0.9 1.0 1.2 1.0 1.1 1.1 1.1 1.1 0.9 1.1\n[109] 0.9 1.3 1.2 1.0 1.1 0.9 1.0 1.2 1.1 1.3 1.0 0.8 1.2 1.0 1.0 1.0 1.2 1.2\n[127] 1.0 1.1 1.0 1.1 1.0 1.3 1.0 1.0 1.0 1.1 1.2 1.1 1.1 1.1 1.1 1.1 1.0 1.2\n[145] 1.2 1.1 0.9 1.1 1.2 1.1\n```\n\n\n:::\n:::\n\n\n\n\nNone of these options left intermediate variables in our environment:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nls()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"get_sepalwidth\"\n```\n\n\n:::\n:::\n\n\n\n\nNote that in the case of a very large function, it might still be beneficial to run `rm()` inside the function to clear the memory for other processes coming next within that function. But this is a pretty rare case.\n\nIf you really have to create large intermediate objects in the global environment, make sure to delete them as soon as you don't need them anymore (e.g. `rm(sepalwidth, sepalwidth_ln)`).\n\n:::{.note}\n\n`rm()` deletes the names of variables (the pointers to objects in memory). But as soon as all the pointers to an object in memory are deleted, the garbage collector clears its value and releases the memory it used.\n\n:::\n\n## Caching\n\n[Memoisation](https://en.wikipedia.org/wiki/Memoization) is a technique by which some results are cached to avoid re-calculating them. This is convenient in a variety of settings (e.g. to reduce calls to an API, to avoid repeating heavy computations). In particular, it improves the efficiency of recursive function calls dramatically.\n\nLet's consider the calculation of the [Fibonacci numbers](https://en.wikipedia.org/wiki/Fibonacci_number) as an example. Those numbers form a sequence starting with `0, 1`[^1], after which each number is the sum of the previous two (so the series starts with: `0, 1, 1, 2, 3, 5, 8, 13...`).\n\n[^1]: Alternative versions have the sequence start with `1, 1` or with `1, 2`.\n\nHere is a function that would return the n^th^ Fibonacci number[^2]:\n\n[^2]: There are more efficient ways to calculate the Fibonacci numbers, but this inefficient function is a great example to show the advantage of memoisation.\n\n```{.r}\nfib <- function(n) {\n  if(n == 0) {\n    return(0)\n  } else if(n == 1) {\n    return(1)\n  } else {\n    Recall(n - 1) + Recall(n - 2)\n  }\n}\n```\n\nIt can be written more tersely as:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfib <- function(n) {\n  if(n == 0) return(0)\n  if(n == 1) return(1)\n  Recall(n - 1) + Recall(n - 2)\n}\n```\n:::\n\n\n\n\n:::{.note}\n\n`Recall()` is a placeholder for the name of the recursive function. We could have used `fib()` instead, but `Recall()` is more robust as it allows for function renaming.\n\n:::\n\nMemoisation is very useful here because, for each Fibonacci number, we need to calculate the two preceding Fibonacci numbers and to calculate each of those we need to calculate the two Fibonacci numbers preceding that one and to calculate... etc. That is a large number of calculations, but, thanks to caching, we don't have to calculate any one of them more than once.\n\nThe packages [R.cache](https://cran.r-project.org/web/packages/R.cache/index.html) and [memoise](https://cran.r-project.org/web/packages/memoise/index.html) both allow for memoisation with an incredibly simple syntax.\n\nApplying the latter to our function gives us:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(memoise)\n\nfibmem <- memoise(\n  function(n) {\n    if(n == 0) return(0)\n    if(n == 1) return(1)\n    Recall(n - 1) + Recall(n - 2)\n  }\n)\n```\n:::\n\n\n\n\nWe can do some benchmarking to see the speedup for the 30^th^ Fibonacci number:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(bench)\n\nn <- 30\nmark(fib(n), fibmem(n))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  expression      min   median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n1 fib(n)        1.62s    1.62s     0.616    32.9KB     18.5\n2 fibmem(n)   41.22µs  44.62µs 20807.       68.3KB     14.6\n```\n\n\n:::\n:::\n\n\n\n\nThe speedup is over 35,000!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}