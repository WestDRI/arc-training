{
  "hash": "eee22472e60bdab975adc311fd131137",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: PyTorch tensors\naliases:\n  - tensors.html\nauthor: Marie-Hélène Burle\n---\n\n:::{.def}\n\nBefore information can be processed by algorithms, it needs to be converted to floating point numbers. Indeed, you don't pass a sentence or an image through a model; instead you input numbers representing a sequence of words or pixel values.\n\nAll these floating point numbers need to be stored in a data structure. The most suited structure is multidimensional (to hold several layers of information) and homogeneous—all data of the same type—for efficiency.\n\nPython already has several multidimensional array structures (e.g. [NumPy](https://numpy.org/)'s ndarray) but the particularities of deep learning call for special characteristics such as the ability to run operations on GPUs and/or in a distributed fashion, the ability to keep track of computation graphs for [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation), and different defaults (lower precision for improved training performance).\n\nThe PyTorch tensor is a Python data structure with these characteristics that can easily be converted to/from NumPy's ndarray and integrates well with other Python libraries such as [Pandas](https://pandas.pydata.org/).\n\nIn this section, we will explore the basics of PyTorch tensors.\n\n:::\n\n## Importing PyTorch\n\nFirst of all, we need to import the `torch` library:\n\n::: {#3692749e .cell execution_count=2}\n``` {.python .cell-code}\nimport torch\n```\n:::\n\n\nWe can check its version with:\n\n::: {#4770f8f4 .cell execution_count=3}\n``` {.python .cell-code}\ntorch.__version__\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n'2.3.0+cu121'\n```\n:::\n:::\n\n\n## Creating tensors\n\nThere are many ways to create tensors:\n\n- `torch.tensor`: &emsp;&emsp;Input individual values\n- `torch.arange`: &emsp;&emsp;1D tensor with a sequence of integers\n- `torch.linspace`: &emsp;1D linear scale tensor\n- `torch.logspace`: &emsp;1D log scale tensor\n- `torch.rand`: &emsp;&emsp;&emsp;&nbsp;Random numbers from a uniform distribution on `[0, 1)`\n- `torch.randn`: &emsp;&emsp;&ensp;&nbsp;Numbers from the standard normal distribution\n- `torch.randperm`: &emsp;&nbsp;Random permutation of integers\n- `torch.empty`: &emsp;&emsp;&ensp;&nbsp;Uninitialized tensor\n- `torch.zeros`: &emsp;&emsp;&ensp;&nbsp;Tensor filled with `0`\n- `torch.ones`: &emsp;&emsp;&emsp;&nbsp;Tensor filled with `1`\n- `torch.eye`: &emsp;&emsp;&emsp;&ensp;&nbsp;&nbsp;Identity matrix\n\n### From input values\n\n::: {#624e18f5 .cell execution_count=4}\n``` {.python .cell-code}\nt = torch.tensor(3)\n```\n:::\n\n\n:::{.exo}\n\n:::{.yourturn}\n\nYour turn:\n\n:::\n\nWithout using the `shape` descriptor, try to get the shape of the following tensors:\n\n```{.python}\ntorch.tensor([0.9704, 0.1339, 0.4841])\n\ntorch.tensor([[0.9524, 0.0354],\n        [0.9833, 0.2562],\n        [0.0607, 0.6420]])\n\ntorch.tensor([[[0.4604, 0.2699],\n         [0.8360, 0.0317],\n         [0.3289, 0.1171]]])\n\ntorch.tensor([[[[0.0730, 0.8737],\n          [0.2305, 0.4719],\n          [0.0796, 0.2745]]],\n\n        [[[0.1534, 0.9442],\n          [0.3287, 0.9040],\n          [0.0948, 0.1480]]]])\n```\n\n:::\n\nLet's create a random tensor with a single element:\n\n::: {#8538d9ca .cell execution_count=5}\n``` {.python .cell-code}\nt = torch.rand(1)\nt\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\ntensor([0.0664])\n```\n:::\n:::\n\n\nWe can extract the value from a tensor with one element:\n\n::: {#f1f03c57 .cell execution_count=6}\n``` {.python .cell-code}\nt.item()\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n0.06640791893005371\n```\n:::\n:::\n\n\nAll these tensors have a single element, but an increasing number of dimensions:\n\n::: {#3b2dc848 .cell execution_count=7}\n``` {.python .cell-code}\ntorch.rand(1)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\ntensor([0.4521])\n```\n:::\n:::\n\n\n::: {#2094e615 .cell execution_count=8}\n``` {.python .cell-code}\ntorch.rand(1, 1)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\ntensor([[0.4222]])\n```\n:::\n:::\n\n\n::: {#1d320818 .cell execution_count=9}\n``` {.python .cell-code}\ntorch.rand(1, 1, 1)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\ntensor([[[0.8421]]])\n```\n:::\n:::\n\n\n::: {#2d9988fd .cell execution_count=10}\n``` {.python .cell-code}\ntorch.rand(1, 1, 1, 1)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\ntensor([[[[0.5642]]]])\n```\n:::\n:::\n\n\n:::{.note}\n\nYou can tell the number of dimensions of a tensor easily by counting the number of opening square brackets.\n\n:::\n\n::: {#b36189ae .cell execution_count=11}\n``` {.python .cell-code}\ntorch.rand(1, 1, 1, 1).dim()\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n4\n```\n:::\n:::\n\n\nTensors can have multiple elements in one dimension:\n\n::: {#691f539e .cell execution_count=12}\n``` {.python .cell-code}\ntorch.rand(6)\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\ntensor([0.4880, 0.4136, 0.6164, 0.7771, 0.3317, 0.9322])\n```\n:::\n:::\n\n\n::: {#97ab68bb .cell execution_count=13}\n``` {.python .cell-code}\ntorch.rand(6).dim()\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\n1\n```\n:::\n:::\n\n\nAnd multiple elements in multiple dimensions:\n\n::: {#9de9dd2d .cell execution_count=14}\n``` {.python .cell-code}\ntorch.rand(2, 3, 4, 5)\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\ntensor([[[[1.9265e-01, 7.1588e-01, 5.4991e-02, 8.2984e-02, 4.7106e-01],\n          [1.4702e-01, 7.0770e-01, 3.7774e-01, 1.9632e-01, 3.7828e-01],\n          [5.3180e-01, 5.0883e-01, 8.8231e-01, 6.6615e-01, 8.9560e-01],\n          [2.1757e-01, 5.9166e-01, 9.3296e-01, 4.9402e-01, 7.4369e-01]],\n\n         [[5.6226e-01, 7.9807e-01, 8.5299e-01, 3.0352e-02, 5.7470e-01],\n          [6.9126e-01, 1.4833e-03, 1.0773e-01, 2.4625e-01, 3.3941e-01],\n          [1.1600e-01, 9.9698e-01, 4.1395e-01, 8.2424e-01, 5.0606e-01],\n          [9.3411e-01, 4.9257e-01, 7.2200e-01, 3.5606e-01, 6.8473e-01]],\n\n         [[6.3870e-01, 8.4146e-01, 1.4000e-02, 4.7660e-01, 2.5765e-01],\n          [3.9077e-01, 7.6622e-02, 5.0639e-01, 3.7614e-02, 3.4253e-02],\n          [2.3641e-01, 6.4974e-01, 7.0924e-01, 7.3478e-01, 6.9183e-01],\n          [5.5115e-01, 5.7502e-01, 8.1053e-01, 6.5448e-01, 7.6442e-01]]],\n\n\n        [[[6.6645e-01, 5.6170e-01, 5.5790e-01, 5.9724e-01, 6.7921e-01],\n          [5.9885e-01, 6.0820e-01, 5.0443e-02, 1.2864e-01, 3.9098e-01],\n          [8.1274e-01, 7.8897e-01, 4.7621e-01, 8.8376e-02, 2.0044e-01],\n          [5.5256e-01, 2.6450e-01, 1.5427e-01, 2.6887e-01, 2.2558e-01]],\n\n         [[4.1520e-01, 9.7462e-01, 7.5100e-01, 9.9890e-01, 6.8974e-01],\n          [2.3860e-01, 6.1438e-01, 3.9230e-01, 7.8527e-01, 5.9984e-01],\n          [5.7508e-01, 7.9849e-02, 8.4372e-01, 1.5977e-01, 1.0906e-01],\n          [1.7758e-01, 8.3926e-01, 9.9416e-01, 8.6307e-01, 8.6240e-01]],\n\n         [[4.6696e-01, 8.9729e-01, 9.9784e-01, 8.6357e-01, 2.0131e-01],\n          [3.9958e-01, 5.5251e-01, 5.1938e-01, 5.3351e-01, 2.3864e-01],\n          [9.4331e-01, 8.3029e-05, 6.8900e-01, 5.0304e-01, 1.3088e-01],\n          [6.5368e-01, 9.8662e-01, 7.8843e-01, 4.3189e-01, 9.8437e-01]]]])\n```\n:::\n:::\n\n\n::: {#51182266 .cell execution_count=15}\n``` {.python .cell-code}\ntorch.rand(2, 3, 4, 5).dim()\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\n4\n```\n:::\n:::\n\n\n::: {#3c15dfa8 .cell execution_count=16}\n``` {.python .cell-code}\ntorch.rand(2, 3, 4, 5).numel()\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\n120\n```\n:::\n:::\n\n\n::: {#1d4e3275 .cell execution_count=17}\n``` {.python .cell-code}\ntorch.ones(2, 4)\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\ntensor([[1., 1., 1., 1.],\n        [1., 1., 1., 1.]])\n```\n:::\n:::\n\n\n::: {#0d5d570b .cell execution_count=18}\n``` {.python .cell-code}\nt = torch.rand(2, 3)\ntorch.zeros_like(t)             # Matches the size of t\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\ntensor([[0., 0., 0.],\n        [0., 0., 0.]])\n```\n:::\n:::\n\n\n::: {#43f2222b .cell execution_count=19}\n``` {.python .cell-code}\ntorch.ones_like(t)\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\ntensor([[1., 1., 1.],\n        [1., 1., 1.]])\n```\n:::\n:::\n\n\n::: {#7724bfed .cell execution_count=20}\n``` {.python .cell-code}\ntorch.randn_like(t)\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\ntensor([[-1.6889, -1.4382,  1.1412],\n        [ 1.3235, -1.4399, -0.5927]])\n```\n:::\n:::\n\n\n::: {#000a88ed .cell execution_count=21}\n``` {.python .cell-code}\ntorch.arange(2, 10, 3)    # From 2 to 10 in increments of 3\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\ntensor([2, 5, 8])\n```\n:::\n:::\n\n\n::: {#80ae9219 .cell execution_count=22}\n``` {.python .cell-code}\ntorch.linspace(2, 10, 3)  # 3 elements from 2 to 10 on the linear scale\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```\ntensor([ 2.,  6., 10.])\n```\n:::\n:::\n\n\n::: {#daabb84b .cell execution_count=23}\n``` {.python .cell-code}\ntorch.logspace(2, 10, 3)  # Same on the log scale\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```\ntensor([1.0000e+02, 1.0000e+06, 1.0000e+10])\n```\n:::\n:::\n\n\n::: {#92a66998 .cell execution_count=24}\n``` {.python .cell-code}\ntorch.randperm(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```\ntensor([0, 1, 2])\n```\n:::\n:::\n\n\n::: {#6b29d6ee .cell execution_count=25}\n``` {.python .cell-code}\ntorch.eye(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```\ntensor([[1., 0., 0.],\n        [0., 1., 0.],\n        [0., 0., 1.]])\n```\n:::\n:::\n\n\n## Conversion to/from NumPy\n\nPyTorch tensors can be converted to NumPy ndarrays and vice-versa in a very efficient manner as both objects share the same memory.\n\n### From PyTorch tensor to NumPy ndarray\n\n::: {#52c929b3 .cell execution_count=26}\n``` {.python .cell-code}\nt = torch.rand(2, 3)\nt\n```\n\n::: {.cell-output .cell-output-display execution_count=25}\n```\ntensor([[0.7550, 0.4205, 0.3024],\n        [0.9266, 0.8816, 0.9083]])\n```\n:::\n:::\n\n\n::: {#ad0071dd .cell execution_count=27}\n``` {.python .cell-code}\nt_np = t.numpy()\nt_np\n```\n\n::: {.cell-output .cell-output-display execution_count=26}\n```\narray([[0.7550101 , 0.42052966, 0.30236405],\n       [0.92664444, 0.88160074, 0.90829116]], dtype=float32)\n```\n:::\n:::\n\n\n### From NumPy ndarray to PyTorch tensor\n\n::: {#e80abe88 .cell execution_count=28}\n``` {.python .cell-code}\nimport numpy as np\na = np.random.rand(2, 3)\na\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```\narray([[0.08169611, 0.69920343, 0.83400031],\n       [0.40020636, 0.99345611, 0.94510268]])\n```\n:::\n:::\n\n\n::: {#fcb9c465 .cell execution_count=29}\n``` {.python .cell-code}\na_pt = torch.from_numpy(a)\na_pt\n```\n\n::: {.cell-output .cell-output-display execution_count=28}\n```\ntensor([[0.0817, 0.6992, 0.8340],\n        [0.4002, 0.9935, 0.9451]], dtype=torch.float64)\n```\n:::\n:::\n\n\n:::{.note}\n\nNote the different default data types.\n\n:::\n\n## Indexing tensors\n\n::: {#cf44adf3 .cell execution_count=30}\n``` {.python .cell-code}\nt = torch.rand(3, 4)\nt\n```\n\n::: {.cell-output .cell-output-display execution_count=29}\n```\ntensor([[0.3933, 0.6787, 0.4420, 0.1485],\n        [0.1954, 0.8715, 0.7792, 0.6891],\n        [0.0908, 0.3443, 0.7069, 0.0127]])\n```\n:::\n:::\n\n\n::: {#1df2321c .cell execution_count=31}\n``` {.python .cell-code}\nt[:, 2]\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n```\ntensor([0.4420, 0.7792, 0.7069])\n```\n:::\n:::\n\n\n::: {#ffcab5c7 .cell execution_count=32}\n``` {.python .cell-code}\nt[1, :]\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```\ntensor([0.1954, 0.8715, 0.7792, 0.6891])\n```\n:::\n:::\n\n\n::: {#1c788eb0 .cell execution_count=33}\n``` {.python .cell-code}\nt[2, 3]\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\ntensor(0.0127)\n```\n:::\n:::\n\n\n:::{.info}\n\n**A word of caution about indexing**\n\nWhile indexing elements of a tensor to extract some of the data as a final step of some computation is fine, [you should not use indexing to run operations on tensor elements in a loop]{.emph} as this would be extremely inefficient.\n\nInstead, you want to use [vectorized operations]{.emph}.\n\n:::\n\n## Vectorized operations\n\nSince PyTorch tensors are homogeneous (i.e. made of a single data type), [as with NumPy's ndarrays](https://www.pythonlikeyoumeanit.com/Module3_IntroducingNumpy/VectorizedOperations.html#Vectorized-Operations), operations are vectorized and thus fast.\n\nNumPy is mostly written in C, PyTorch in C++. With either library, when you run vectorized operations on arrays/tensors, you don't use raw Python (slow) but compiled C/C++ code (much faster).\n\n[Here](https://pythonspeed.com/articles/vectorization-python/) is an excellent post explaining Python vectorization & why it makes such a big difference.\n\n## Data types\n\n### Default data type\n\nSince PyTorch tensors were built with efficiency in mind for neural networks, the default data type is **32-bit floating points**.\n\nThis is sufficient for accuracy and much faster than 64-bit floating points.\n\n:::{.note}\n\nBy contrast, NumPy ndarrays use 64-bit as their default.\n\n:::\n\n::: {#101b27c3 .cell execution_count=34}\n``` {.python .cell-code}\nt = torch.rand(2, 4)\nt.dtype\n```\n\n::: {.cell-output .cell-output-display execution_count=33}\n```\ntorch.float32\n```\n:::\n:::\n\n\n### Setting data type at creation\n\nThe type can be set with the `dtype` argument:\n\n::: {#44f65892 .cell execution_count=35}\n``` {.python .cell-code}\nt = torch.rand(2, 4, dtype=torch.float64)\nt\n```\n\n::: {.cell-output .cell-output-display execution_count=34}\n```\ntensor([[0.7931, 0.0869, 0.0231, 0.6726],\n        [0.1689, 0.2116, 0.7150, 0.2311]], dtype=torch.float64)\n```\n:::\n:::\n\n\n:::{.note}\n\nPrinted tensors display attributes with values ≠ default values.\n\n:::\n\n::: {#8d2f0332 .cell execution_count=36}\n``` {.python .cell-code}\nt.dtype\n```\n\n::: {.cell-output .cell-output-display execution_count=35}\n```\ntorch.float64\n```\n:::\n:::\n\n\n### Changing data type\n\n::: {#057ca449 .cell execution_count=37}\n``` {.python .cell-code}\nt = torch.rand(2, 4)\nt.dtype\n```\n\n::: {.cell-output .cell-output-display execution_count=36}\n```\ntorch.float32\n```\n:::\n:::\n\n\n::: {#54e12c81 .cell execution_count=38}\n``` {.python .cell-code}\nt2 = t.type(torch.float64)\nt2.dtype\n```\n\n::: {.cell-output .cell-output-display execution_count=37}\n```\ntorch.float64\n```\n:::\n:::\n\n\n### List of data types\n\n| dtype | Description |\n| ----- | ----- |\n| torch.float16 / torch.half | 16-bit / half-precision floating-point |\n| torch.float32 / torch.float | 32-bit / single-precision floating-point |\n| torch.float64 / torch.double | 64-bit / double-precision floating-point |\n| torch.uint8 | unsigned 8-bit integers |\n| torch.int8 | signed 8-bit integers |\n| torch.int16 / torch.short | signed 16-bit integers |\n| torch.int32 / torch.int | signed 32-bit integers |\n| torch.int64 / torch.long | signed 64-bit integers |\n| torch.bool | boolean |\n\n## Simple operations\n\n::: {#3e50952b .cell execution_count=39}\n``` {.python .cell-code}\nt1 = torch.tensor([[1, 2], [3, 4]])\nt1\n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n```\ntensor([[1, 2],\n        [3, 4]])\n```\n:::\n:::\n\n\n::: {#70576d9e .cell execution_count=40}\n``` {.python .cell-code}\nt2 = torch.tensor([[1, 1], [0, 0]])\nt2\n```\n\n::: {.cell-output .cell-output-display execution_count=39}\n```\ntensor([[1, 1],\n        [0, 0]])\n```\n:::\n:::\n\n\nOperation performed between elements at corresponding locations:\n\n::: {#952ca9f9 .cell execution_count=41}\n``` {.python .cell-code}\nt1 + t2\n```\n\n::: {.cell-output .cell-output-display execution_count=40}\n```\ntensor([[2, 3],\n        [3, 4]])\n```\n:::\n:::\n\n\nOperation applied to each element of the tensor:\n\n::: {#51f4b7de .cell execution_count=42}\n``` {.python .cell-code}\nt1 + 1\n```\n\n::: {.cell-output .cell-output-display execution_count=41}\n```\ntensor([[2, 3],\n        [4, 5]])\n```\n:::\n:::\n\n\n### Reduction\n\n::: {#284e93ec .cell execution_count=43}\n``` {.python .cell-code}\nt = torch.ones(2, 3, 4);\nt\n```\n\n::: {.cell-output .cell-output-display execution_count=42}\n```\ntensor([[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]])\n```\n:::\n:::\n\n\n::: {#19f4d439 .cell execution_count=44}\n``` {.python .cell-code}\nt.sum()   # Reduction over all entries\n```\n\n::: {.cell-output .cell-output-display execution_count=43}\n```\ntensor(24.)\n```\n:::\n:::\n\n\n:::{.note}\n\nOther reduction functions (e.g. mean) behave the same way.\n\n:::\n\nReduction over a specific dimension:\n\n::: {#f7b609b2 .cell execution_count=45}\n``` {.python .cell-code}\nt.sum(0)\n```\n\n::: {.cell-output .cell-output-display execution_count=44}\n```\ntensor([[2., 2., 2., 2.],\n        [2., 2., 2., 2.],\n        [2., 2., 2., 2.]])\n```\n:::\n:::\n\n\n::: {#146cc12e .cell execution_count=46}\n``` {.python .cell-code}\nt.sum(1)\n```\n\n::: {.cell-output .cell-output-display execution_count=45}\n```\ntensor([[3., 3., 3., 3.],\n        [3., 3., 3., 3.]])\n```\n:::\n:::\n\n\n::: {#40422e2e .cell execution_count=47}\n``` {.python .cell-code}\nt.sum(2)\n```\n\n::: {.cell-output .cell-output-display execution_count=46}\n```\ntensor([[4., 4., 4.],\n        [4., 4., 4.]])\n```\n:::\n:::\n\n\nReduction over multiple dimensions:\n\n::: {#5b5f2e15 .cell execution_count=48}\n``` {.python .cell-code}\nt.sum((0, 1))\n```\n\n::: {.cell-output .cell-output-display execution_count=47}\n```\ntensor([6., 6., 6., 6.])\n```\n:::\n:::\n\n\n::: {#ebdb7734 .cell execution_count=49}\n``` {.python .cell-code}\nt.sum((0, 2))\n```\n\n::: {.cell-output .cell-output-display execution_count=48}\n```\ntensor([8., 8., 8.])\n```\n:::\n:::\n\n\n::: {#86230377 .cell execution_count=50}\n``` {.python .cell-code}\nt.sum((1, 2))\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```\ntensor([12., 12.])\n```\n:::\n:::\n\n\n### In-place operations\n\nWith operators post-fixed with `_`:\n\n::: {#e80a6b80 .cell execution_count=51}\n``` {.python .cell-code}\nt1 = torch.tensor([1, 2])\nt1\n```\n\n::: {.cell-output .cell-output-display execution_count=50}\n```\ntensor([1, 2])\n```\n:::\n:::\n\n\n::: {#082c8fa0 .cell execution_count=52}\n``` {.python .cell-code}\nt2 = torch.tensor([1, 1])\nt2\n```\n\n::: {.cell-output .cell-output-display execution_count=51}\n```\ntensor([1, 1])\n```\n:::\n:::\n\n\n::: {#f9dfba23 .cell execution_count=53}\n``` {.python .cell-code}\nt1.add_(t2)\nt1\n```\n\n::: {.cell-output .cell-output-display execution_count=52}\n```\ntensor([2, 3])\n```\n:::\n:::\n\n\n::: {#5edce633 .cell execution_count=54}\n``` {.python .cell-code}\nt1.zero_()\nt1\n```\n\n::: {.cell-output .cell-output-display execution_count=53}\n```\ntensor([0, 0])\n```\n:::\n:::\n\n\n:::{.note}\n\nWhile reassignments will use new addresses in memory, in-place operations will use the same addresses.\n\n:::\n\n### Tensor views\n\n```{.python}\nt = torch.tensor([[1, 2, 3], [4, 5, 6]]); print(t)\nt.size()\nt.view(6)\nt.view(3, 2)\nt.view(3, -1) # Same: with -1, the size is inferred from other dimensions\n```\n\n:::{.info}\n\n**Note the difference**\n\n::: {#b9534ea2 .cell execution_count=55}\n``` {.python .cell-code}\nt1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\nt1\n```\n\n::: {.cell-output .cell-output-display execution_count=54}\n```\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n```\n:::\n:::\n\n\n::: {#bc3bc114 .cell execution_count=56}\n``` {.python .cell-code}\nt2 = t1.t()\nt2\n```\n\n::: {.cell-output .cell-output-display execution_count=55}\n```\ntensor([[1, 4],\n        [2, 5],\n        [3, 6]])\n```\n:::\n:::\n\n\n::: {#662d84a2 .cell execution_count=57}\n``` {.python .cell-code}\nt3 = t1.view(3, 2)\nt3\n```\n\n::: {.cell-output .cell-output-display execution_count=56}\n```\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n```\n:::\n:::\n\n\n:::\n\n### Logical operations\n\n::: {#c0066ada .cell execution_count=58}\n``` {.python .cell-code}\nt1 = torch.randperm(5)\nt1\n```\n\n::: {.cell-output .cell-output-display execution_count=57}\n```\ntensor([1, 0, 2, 4, 3])\n```\n:::\n:::\n\n\n::: {#10d5f3cc .cell execution_count=59}\n``` {.python .cell-code}\nt2 = torch.randperm(5)\nt2\n```\n\n::: {.cell-output .cell-output-display execution_count=58}\n```\ntensor([4, 1, 2, 0, 3])\n```\n:::\n:::\n\n\nTest each element:\n\n::: {#119a4f88 .cell execution_count=60}\n``` {.python .cell-code}\nt1 > 3\n```\n\n::: {.cell-output .cell-output-display execution_count=59}\n```\ntensor([False, False, False,  True, False])\n```\n:::\n:::\n\n\nTest corresponding pairs of elements:\n\n::: {#f74457af .cell execution_count=61}\n``` {.python .cell-code}\nt1 < t2\n```\n\n::: {.cell-output .cell-output-display execution_count=60}\n```\ntensor([ True,  True, False, False, False])\n```\n:::\n:::\n\n\n## Device attribute\n\nTensor data can be placed in the memory of various processor types:\n\n- the RAM of CPU,\n- the RAM of a GPU with CUDA support,\n- the RAM of a GPU with [AMD's ROCm support](https://pytorch.org/blog/pytorch-for-amd-rocm-platform-now-available-as-python-package/),\n- the RAM of an [XLA device](https://www.tensorflow.org/xla) (e.g. [Cloud TPU](https://cloud.google.com/tpu)) with the [torch_xla package](https://github.com/pytorch/xla/).\n\nThe values for the device attributes are:\n\n- CPU: &nbsp;`'cpu'`,\n- GPU (CUDA & AMD's ROCm): &nbsp;`'cuda'`,\n- XLA: &nbsp;`xm.xla_device()`.\n\nThis last option requires to load the [torch_xla package](https://github.com/pytorch/xla/) first:\n\n```{.python}\nimport torch_xla\nimport torch_xla.core.xla_model as xm\n```\n\n### Creating a tensor on a specific device\n\nBy default, tensors are created on the CPU.\n\nYou can create a tensor on an accelerator by specifying the device attribute (our current training cluster does not have GPUs, so don't run this on it):\n\n```{.python}\nt_gpu = torch.rand(2, device='cuda')\n```\n\n### Copying a tensor to a specific device\n\nYou can also make copies of a tensor on other devices:\n\n```{.python}\n# Make a copy of t on the GPU\nt_gpu = t.to(device='cuda')\nt_gpu = t.cuda()             # Alternative syntax\n\n# Make a copy of t_gpu on the CPU\nt = t_gpu.to(device='cpu')\nt = t_gpu.cpu()              # Alternative syntax\n```\n\n### Multiple GPUs\n\nIf you have multiple GPUs, you can optionally specify which one a tensor should be created on or copied to:\n\n```{.python}\nt1 = torch.rand(2, device='cuda:0')  # Create a tensor on 1st GPU\nt2 = t1.to(device='cuda:0')          # Make a copy of t1 on 1st GPU\nt3 = t1.to(device='cuda:1')          # Make a copy of t1 on 2nd GPU\n```\n\nOr the equivalent short forms:\n\n```{.python}\nt2 = t1.cuda(0)\nt3 = t1.cuda(1)\n```\n\n<!-- Local Variables: -->\n<!-- pyvenv-activate: \"/home/marie/parvus/prog/mint/ai/pt_env\" -->\n<!-- End: -->\n\n",
    "supporting": [
      "pt_tensors_files"
    ],
    "filters": [],
    "includes": {}
  }
}