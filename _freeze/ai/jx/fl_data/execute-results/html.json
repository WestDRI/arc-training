{
  "hash": "a6f6495ee4559a5815b6f847727f1c44",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Loading data\naliases:\n  - fl_dataset.html\nauthor: Marie-HÃ©lÃ¨ne Burle\nbibliography: fl.bib\n---\n\n:::{.def}\n\nFlax does not implement methods to load datasets since [Hugging Face](https://github.com/huggingface/datasets), [PyTorch](https://github.com/pytorch/pytorch), and [TensorFlow](https://github.com/tensorflow/datasets) already provide great APIs for this.\n\n:::\n\n## Hugging Face datasets\n\nThe [Datasets](https://github.com/huggingface/datasets) library from ðŸ¤— is a lightweight, framework-agnostic, and easy to use API to download datasets from the [Hugging Face Hub](https://huggingface.co/datasets). It uses [Apache Arrow](https://arrow.apache.org/)'s efficient caching system, allowing large datasets to be used on machines with small memory [@lhoest-etal-2021-datasets].\n\n### Search dataset\n\nGo to the [Hugging Face Hub](https://huggingface.co/datasets) and search through thousands of open source datasets provided by the community.\n\n### Inspect dataset\n\nYou can get information on a dataset before downloading it.\n\nLoad the dataset builder for the dataset you are interested in:\n\n::: {#cb1e2bf6 .cell execution_count=1}\n``` {.python .cell-code}\nfrom datasets import load_dataset_builder\nds_builder = load_dataset_builder(\"mnist\")\n```\n:::\n\n\nGet a description of the dataset:\n\n::: {#f4f74325 .cell execution_count=2}\n``` {.python .cell-code}\nds_builder.info.description\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n'The MNIST dataset consists of 70,000 28x28 black-and-white images in 10 classes (one for each digits), with 7,000\\nimages per class. There are 60,000 training images and 10,000 test images.\\n'\n```\n:::\n:::\n\n\nGet information on the features:\n\n::: {#ed98714b .cell execution_count=3}\n``` {.python .cell-code}\nds_builder.info.features\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n{'image': Image(mode=None, decode=True, id=None),\n 'label': ClassLabel(names=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], id=None)}\n```\n:::\n:::\n\n\n### Download dataset and load in session\n\n::: {#a4bfdb4e .cell execution_count=4}\n``` {.python .cell-code}\nfrom datasets import load_dataset\n\ndef get_dataset_hf():\n    mnist = load_dataset(\"mnist\")\n\n    ds = {}\n\n    for split in ['train', 'test']:\n        ds[split] = {\n            'image': np.array([np.array(im) for im in mnist[split]['image']]),\n            'label': np.array(mnist[split]['label'])\n        }\n\n        ds[split]['image'] = jnp.float32(ds[split]['image']) / 255\n        ds[split]['label'] = jnp.int16(ds[split]['label'])\n\n        ds[split]['image'] = jnp.expand_dims(ds[split]['image'], 3)\n\n    return ds['train'], ds['test']\n```\n:::\n\n\n## PyTorch Torchvision datasets\n\n[](https://pytorch.org/vision/stable/datasets.html)\n\n::: {#a8986599 .cell execution_count=5}\n``` {.python .cell-code}\nfrom torchvision import datasets\n\ndef get_dataset_torch():\n    mnist = {\n        'train': datasets.MNIST('./data', train=True, download=True),\n        'test': datasets.MNIST('./data', train=False, download=True)\n    }\n\n    ds = {}\n\n    for split in ['train', 'test']:\n        ds[split] = {\n            'image': mnist[split].data.numpy(),\n            'label': mnist[split].targets.numpy()\n        }\n\n        ds[split]['image'] = jnp.float32(ds[split]['image']) / 255\n        ds[split]['label'] = jnp.int16(ds[split]['label'])\n\n        ds[split]['image'] = jnp.expand_dims(ds[split]['image'], 3)\n\n    return ds['train'], ds['test']\n```\n\n::: {.cell-output .cell-output-error}\n```\nModuleNotFoundError: No module named 'torchvision'\n```\n:::\n:::\n\n\n## TensorFlow datasets\n\n[](https://github.com/tensorflow/datasets)\n\n[](https://blog.tensorflow.org/2019/02/introducing-tensorflow-datasets.html)\n\n::: {#9aa7edf9 .cell execution_count=6}\n``` {.python .cell-code}\nimport tensorflow_datasets as tfds\n\ndef get_dataset_tf(epochs, batch_size):\n    mnist = tfds.builder('mnist')\n    mnist.download_and_prepare()\n\n    ds = {}\n\n    for set in ['train', 'test']:\n        ds[set] = tfds.as_numpy(mnist.as_dataset(split=set, batch_size=-1))\n\n        # cast to jnp and rescale pixel values\n        ds[set]['image'] = jnp.float32(ds[set]['image']) / 255\n        ds[set]['label'] = jnp.int16(ds[set]['label'])\n\n    return ds['train'], ds['test']\n```\n:::\n\n\n",
    "supporting": [
      "fl_data_files"
    ],
    "filters": [],
    "includes": {}
  }
}