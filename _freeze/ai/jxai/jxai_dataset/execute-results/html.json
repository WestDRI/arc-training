{
  "hash": "dda1a34442b5cc7e6c95763a187cbfb9",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: The Dataset class\nauthor: Marie-Hélène Burle\n---\n\n:::{.def}\n\n\n\n:::\n\n:::{.callout-note collapse=\"true\"}\n\n## Minimal necessary code from previous sections\n\n```{.python}\nbase_dir = \"<path-of-the-nabirds-dir>\"\n```\n\n:::{.note}\n\nTo be replaced by actual path.\n\n:::\n\n\n\n::: {#627d66e9 .cell execution_count=3}\n``` {.python .cell-code}\nimport os\nimport polars as pl\n\nimg_dir = os.path.join(base_dir, \"images\")\n\nbb_file = os.path.join(base_dir, \"bounding_boxes.txt\")\nclasses_translation_file = os.path.join(base_dir, \"classes_fixed.txt\")\nclass_labels_file = os.path.join(base_dir, \"image_class_labels.txt\")\nimg_file = os.path.join(base_dir, \"images.txt\")\nphotographers_file = os.path.join(base_dir, \"photographers_fixed.txt\")\nsizes_file = os.path.join(base_dir, \"sizes.txt\")\ntrain_test_split_file = os.path.join(base_dir, \"train_test_split.txt\")\n\nbb = pl.read_csv(\n    bb_file,\n    separator=\" \",\n    has_header=False,\n    new_columns=[\"UUID\", \"bb_x\", \"bb_y\", \"bb_width\", \"bb_height\"]\n)\n\nclasses = pl.read_csv(\n    class_labels_file,\n    separator=\" \",\n    has_header=False,\n    new_columns=[\"UUID\", \"class\"]\n)\n\nclasses_translation = pl.read_csv(\n    classes_translation_file,\n    separator=\" \",\n    has_header=False,\n    new_columns=[\"class\", \"id\"]\n)\n\nimg_paths = pl.read_csv(\n    img_file,\n    separator=\" \",\n    has_header=False,\n    new_columns=[\"UUID\", \"path\"]\n)\n\nphotographers = pl.read_csv(\n    photographers_file,\n    separator=\" \",\n    has_header=False,\n    new_columns=[\"UUID\", \"photographer\"]\n)\n\nsizes = pl.read_csv(\n    sizes_file,\n    separator=\" \",\n    has_header=False,\n    new_columns=[\"UUID\", \"img_width\", \"img_height\"]\n)\n\ntrain_test_split = pl.read_csv(\n    train_test_split_file,\n    separator=\" \",\n    has_header=False,\n    new_columns=[\"UUID\", \"is_training_img\"]\n)\n\nclasses_metadata = (\n    classes.join(classes_translation, on=\"class\")\n)\n\nmetadata = (\n    bb.join(classes_metadata, on=\"UUID\")\n    .join(img_paths, on=\"UUID\")\n    .join(photographers, on=\"UUID\")\n    .join(sizes, on=\"UUID\")\n    .join(train_test_split, on=\"UUID\")\n)\n\nmetadata_train = metadata.filter(pl.col(\"is_training_img\") == 1)\n```\n:::\n\n\n:::\n\n## Create a class for our dataset\n\nCreating a Dataclass and a DataLoader with the JAX AI stack is done with [Grain](https://github.com/google/grain), but it can just as well be done using [PyTorch](https://github.com/pytorch/pytorch), [TensorFlow Datasets](https://github.com/tensorflow/datasets), [Hugging Face Datasets](https://github.com/huggingface/datasets), or any method you are used to. That's the advantage of the modular philosophy that the stack relies on.\n\nTo read in the images, there are many options, including:\n\n- [PIL.Image.open](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.open) from [Pillow](https://github.com/python-pillow/Pillow),\n- `cv2.imread` from [OpenCV](https://github.com/opencv/opencv),\n- [skimage.io.imread](https://scikit-image.org/docs/stable/api/skimage.io.html#skimage.io.imread) from [scikit-image](https://github.com/scikit-image/scikit-image).\n\nHere, we are using `imageio.imread` from [imageio](https://github.com/imageio/imageio) which is an excellent option because it automatically creates a NumPy ndarrays, choosing a dtype based on the image, and it is faster than other options ([scikit-image](https://github.com/scikit-image/scikit-image) actually use it now instead of their own implementation).\n\n::: {#bb82e1f0 .cell execution_count=4}\n``` {.python .cell-code}\nimport grain.python as grain\nimport imageio.v3 as iio\n\nclass NABirdsDataset:\n    \"\"\"NABirds dataset class.\"\"\"\n    def __init__(self, metadata_file, data_dir):\n        self.metadata = metadata_file\n        self.data_dir = data_dir\n    def __len__(self):\n        return len(self.metadata)\n    def __getitem__(self, idx):\n        img_path = os.path.join(\n            self.data_dir,\n            self.metadata.get_column('path')[idx]\n        )\n        img = iio.imread(img_path)\n        # img = Image.open(img_path)\n        img_id = self.metadata.get_column('id')[idx].replace('_', ' ')\n        img_photographer = self.metadata.get_column('photographer')[idx].replace('_', ' ')\n        img_bb_x = self.metadata.get_column('bb_x')[idx]\n        img_bb_y = self.metadata.get_column('bb_y')[idx]\n        img_bb_width = self.metadata.get_column('bb_width')[idx]\n        img_bb_height = self.metadata.get_column('bb_height')[idx]\n        element = {\n            'image': img,\n            'id': img_id,\n            'photographer': img_photographer,\n            'bbx' : img_bb_x,\n            'bby' : img_bb_y,\n            'bbwidth' : img_bb_width,\n            'bbheight' : img_bb_height\n        }\n        return element\n```\n:::\n\n\n:::{.callout-tip collapse=\"true\"}\n\n## Equivalent using PyTorch\n\nPyTorch provides [`torch.utils.data.Dataset`](https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.Dataset), an abstract class representing a dataset. You need to write a subclass of `torch.utils.data.Dataset` (let's call it `NABirdsDataset`) so that it inherits from `torch.utils.data.Dataset`, but with characteristics matching our own dataset.\n\nA PyTorch custom Dataset class must implement three methods:\n\n- `__init__`: initializes a new instance (object) of the class,\n- `__len__`: returns the number of elements in the new dataset class, and\n- `__getitem__`: loads and returns an element from the dataset at a given index `idx`:\n\n```{.python}\nfrom torch.utils.data import Dataset\n\nclass NABirdsDatasetPyTorch(Dataset):\n    \"\"\"NABirds dataset class.\"\"\"\n    def __init__(self, metadata_file, data_dir, transform=None):\n        self.metadata = metadata_file\n        self.data_dir = data_dir\n        self.transform = transform\n    def __len__(self):\n        return len(self.metadata)\n    def __getitem__(self, idx):\n        img_path = os.path.join(\n            self.data_dir,\n            self.metadata.get_column('path')[idx]\n        )\n        img = iio.imread(img_path)\n        # img = Image.open(img_path)\n        img_id = self.metadata.get_column('id')[idx].replace('_', ' ')\n        img_photographer = self.metadata.get_column('photographer')[idx].replace('_', ' ')\n        img_bb_x = self.metadata.get_column('bb_x')[idx]\n        img_bb_y = self.metadata.get_column('bb_y')[idx]\n        img_bb_width = self.metadata.get_column('bb_width')[idx]\n        img_bb_height = self.metadata.get_column('bb_height')[idx]\n        element = {\n            'image': img,\n            'id': img_id,\n            'photographer': img_photographer,\n            'bbx' : img_bb_x,\n            'bby' : img_bb_y,\n            'bbwidth' : img_bb_width,\n            'bbxheight' : img_bb_height\n        }\n        if self.transform:\n            element = self.transform(element)\n        return element\n```\n\n:::\n\n## Instantiate our Dataset class\n\nNow that we have a Dataset class, we can create an instance with the metadata DataFrame we created in the previous section:\n\n::: {#ef4bf57b .cell execution_count=5}\n``` {.python .cell-code}\nnabirds_train = NABirdsDataset(\n    metadata_train,\n    img_dir\n)\n```\n:::\n\n\n## Display an element\n\nLet's display the first 4 images and their bounding boxes:\n\n::: {#6c83bf3d .cell execution_count=6}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nfig = plt.figure(figsize=(8, 8))\n\nfor i, element in enumerate(nabirds_train):\n    ax = plt.subplot(2, 2, i + 1)\n    plt.tight_layout()\n    ax.set_title(\n        f'Element {i}\\nIdentification: {element['id']}\\nPicture by {element['photographer']}',\n        fontsize=9\n    )\n    ax.axis('off')\n    plt.imshow(element['image'])\n    rect = patches.Rectangle(\n        (element['bbx'], element['bby']),\n        element['bbwidth'],\n        element['bbheight'],\n        linewidth=1,\n        edgecolor='r',\n        facecolor='none'\n    )\n    ax.add_patch(rect)\n    if i == 3:\n        plt.show()\n        break\n```\n\n::: {.cell-output .cell-output-display}\n![](jxai_dataset_files/figure-html/cell-6-output-1.png){width=769 height=682}\n:::\n:::\n\n\nNotice how the images are all of different sizes. This is a problem. We are also not making use of the bounding boxes this dataset comes with, hence using parts of images we know do not contain any bird unnecessarily.\n\nWe will address these problems in the next section.\n\n",
    "supporting": [
      "jxai_dataset_files"
    ],
    "filters": [],
    "includes": {}
  }
}