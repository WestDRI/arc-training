{
  "hash": "21325eb79bd49b50cca9c457224469b1",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Training\nauthor: Marie-Hélène Burle\n---\n\n:::{.def}\n\nIt is now time to train our model.\n\nIn this section, we will cover how to:\n\n- set the training hyperparameters,\n- define the training and evaluation steps,\n- run the actual training loop,\n- create checkpoints,\n- plots the training metrics, and finally\n- test the trained model on a few data samples.\n\n:::\n\n:::{.callout-note collapse=\"true\"}\n\n## Minimal necessary code from previous sections\n\n```{.python}\nbase_dir = '<path-of-the-nabirds-dir>'\n```\n\n:::{.notenoit}\n\nTo be replaced by actual path: in our training cluster, the `base_dir` is at `/project/def-sponsor00/nabirds`:\n\n```{.python}\nbase_dir = '/project/def-sponsor00/nabirds'\n```\n\n:::\n\n\n\n::: {#6ae2fde1 .cell execution_count=3}\n``` {.python .cell-code}\nimport os\nimport polars as pl\nimport imageio.v3 as iio\nimport grain.python as grain\nfrom jax import random\nimport dm_pix as pix\nimport numpy as np\nimport jax\nimport jax.numpy as jnp\nfrom flax import nnx\nfrom transformers import FlaxViTForImageClassification\n\n\nmetadata = pl.read_parquet('metadata.parquet')\nmetadata_train = metadata.filter(pl.col('is_training_img') == 1)\nmetadata_val = metadata.filter(pl.col('is_training_img') == 0)\ncleaned_img_dir = os.path.join(base_dir, 'cleaned_images')\n\n\nclass NABirdsDataset:\n    \"\"\"NABirds dataset class.\"\"\"\n\n    def __init__(self, metadata_file, data_dir):\n        self.metadata_file = metadata_file\n        self.data_dir = data_dir\n\n    def __len__(self):\n        return len(self.metadata_file)\n\n    def __getitem__(self, idx):\n        path = os.path.join(self.data_dir, self.metadata_file.get_column('path')[idx])\n        img = iio.imread(path)\n        species_name = self.metadata_file.get_column('species_name')[idx]\n        species_id = self.metadata_file.get_column('species_id')[idx]\n        photographer = self.metadata_file.get_column('photographer')[idx]\n\n        return {\n            'img': img,\n            'species_name': species_name,\n            'species_id': species_id,\n            'photographer': photographer,\n        }\n\n\nnabirds_train = NABirdsDataset(metadata_train, cleaned_img_dir)\nnabirds_val = NABirdsDataset(metadata_val, cleaned_img_dir)\n\n\nclass Normalize(grain.MapTransform):\n    def map(self, element):\n        img = element['img']\n        mean = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n        std = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n        img = img.astype(np.float32) / 255.0\n        img_norm = (img - mean) / std\n        element['img'] = img_norm\n        return element\n\n\nclass ToFloat(grain.MapTransform):\n    def map(self, element):\n        element['img'] = element['img'].astype(np.float32) / 255.0\n        return element\n\n\nkey = random.key(31)\nkey, subkey1, subkey2, subkey3, subkey4 = random.split(key, num=5)\n\n\nclass RandomCrop(grain.MapTransform):\n    def map(self, element):\n        element['img'] = pix.random_crop(\n            key=subkey1,\n            image=element['img'],\n            crop_sizes=(224, 224, 3)\n        )\n        return element\n\n\nclass RandomFlip(grain.MapTransform):\n    def map(self, element):\n        element['img'] = pix.random_flip_left_right(\n            key=subkey2,\n            image=element['img']\n        )\n        return element\n\n\nclass RandomContrast(grain.MapTransform):\n    def map(self, element):\n        element['img'] = pix.random_contrast(\n            key=subkey3,\n            image=element['img'],\n            lower=0.8,\n            upper=1.2\n        )\n        return element\n\n\nclass RandomGamma(grain.MapTransform):\n    def map(self, element):\n        element['img'] = pix.random_gamma(\n            key=subkey4,\n            image=element['img'],\n            min_gamma=0.6,\n            max_gamma=1.2\n        )\n        return element\n\n\nclass ZScore(grain.MapTransform):\n    def map(self, element):\n        img = element['img']\n        mean = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n        std = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n        img = (img - mean) / std\n        element['img'] = img\n        return element\n\n\nseed = 123\ntrain_batch_size = 32\nval_batch_size = 2 * train_batch_size\n\ntrain_sampler = grain.IndexSampler(\n    num_records=len(nabirds_train),\n    shuffle=True,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1\n)\n\ntrain_loader = grain.DataLoader(\n    data_source=nabirds_train,\n    sampler=train_sampler,\n    operations=[\n        ToFloat(),\n        RandomCrop(),\n        RandomFlip(),\n        RandomContrast(),\n        RandomGamma(),\n        ZScore(),\n        grain.Batch(train_batch_size, drop_remainder=True)\n    ]\n)\n\nval_sampler = grain.IndexSampler(\n    num_records=len(nabirds_val),\n    shuffle=False,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1\n)\n\nval_loader = grain.DataLoader(\n    data_source=nabirds_val,\n    sampler=val_sampler,\n    operations=[\n        Normalize(),\n        grain.Batch(val_batch_size)\n    ]\n)\n\nclass VisionTransformer(nnx.Module):\n    def __init__(\n        self,\n        num_classes: int = 1000,\n        in_channels: int = 3,\n        img_size: int = 224,\n        patch_size: int = 16,\n        num_layers: int = 12,\n        num_heads: int = 12,\n        mlp_dim: int = 3072,\n        hidden_size: int = 768,\n        dropout_rate: float = 0.1,\n        *,\n        rngs: nnx.Rngs = nnx.Rngs(0),\n    ):\n        n_patches = (img_size // patch_size) ** 2\n        self.patch_embeddings = nnx.Conv(\n            in_channels,\n            hidden_size,\n            kernel_size=(patch_size, patch_size),\n            strides=(patch_size, patch_size),\n            padding='VALID',\n            use_bias=True,\n            rngs=rngs,\n        )\n\n        initializer = jax.nn.initializers.truncated_normal(stddev=0.02)\n        self.position_embeddings = nnx.Param(\n            initializer(rngs.params(), (1, n_patches + 1, hidden_size), jnp.float32)\n        )\n        self.dropout = nnx.Dropout(dropout_rate, rngs=rngs)\n        self.cls_token = nnx.Param(jnp.zeros((1, 1, hidden_size)))\n        self.encoder = nnx.Sequential(*[\n            TransformerEncoder(hidden_size, mlp_dim, num_heads, dropout_rate, rngs=rngs)\n            for i in range(num_layers)\n        ])\n        self.final_norm = nnx.LayerNorm(hidden_size, rngs=rngs)\n        self.classifier = nnx.Linear(hidden_size, num_classes, rngs=rngs)\n\n    def __call__(self, x: jax.Array) -> jax.Array:\n        patches = self.patch_embeddings(x)\n        batch_size = patches.shape[0]\n        patches = patches.reshape(batch_size, -1, patches.shape[-1])\n        cls_token = jnp.tile(self.cls_token, [batch_size, 1, 1])\n        x = jnp.concat([cls_token, patches], axis=1)\n        embeddings = x + self.position_embeddings\n        embeddings = self.dropout(embeddings)\n        x = self.encoder(embeddings)\n        x = self.final_norm(x)\n        x = x[:, 0]\n\n        return self.classifier(x)\n\n\nclass TransformerEncoder(nnx.Module):\n    def __init__(\n        self,\n        hidden_size: int,\n        mlp_dim: int,\n        num_heads: int,\n        dropout_rate: float = 0.0,\n        *,\n        rngs: nnx.Rngs = nnx.Rngs(0),\n    ) -> None:\n        self.norm1 = nnx.LayerNorm(hidden_size, rngs=rngs)\n        self.attn = nnx.MultiHeadAttention(\n            num_heads=num_heads,\n            in_features=hidden_size,\n            dropout_rate=dropout_rate,\n            broadcast_dropout=False,\n            decode=False,\n            deterministic=False,\n            rngs=rngs,\n        )\n        self.norm2 = nnx.LayerNorm(hidden_size, rngs=rngs)\n\n        self.mlp = nnx.Sequential(\n            nnx.Linear(hidden_size, mlp_dim, rngs=rngs),\n            nnx.gelu,\n            nnx.Dropout(dropout_rate, rngs=rngs),\n            nnx.Linear(mlp_dim, hidden_size, rngs=rngs),\n            nnx.Dropout(dropout_rate, rngs=rngs),\n        )\n\n    def __call__(self, x: jax.Array) -> jax.Array:\n        x = x + self.attn(self.norm1(x))\n        x = x + self.mlp(self.norm2(x))\n        return x\n\n\nmodel = VisionTransformer(num_classes=1000)\ntf_model = FlaxViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n\n\ndef vit_inplace_copy_weights(*, src_model, dst_model):\n    assert isinstance(src_model, FlaxViTForImageClassification)\n    assert isinstance(dst_model, VisionTransformer)\n\n    tf_model_params = src_model.params\n    tf_model_params_fstate = nnx.traversals.flatten_mapping(tf_model_params)\n\n    flax_model_params = nnx.state(dst_model, nnx.Param)\n    flax_model_params_fstate = dict(flax_model_params.flat_state())\n\n    params_name_mapping = {\n        ('cls_token',): ('vit', 'embeddings', 'cls_token'),\n        ('position_embeddings',): ('vit', 'embeddings', 'position_embeddings'),\n        **{\n            ('patch_embeddings', x): ('vit', 'embeddings', 'patch_embeddings', 'projection', x)\n            for x in ['kernel', 'bias']\n        },\n        **{\n            ('encoder', 'layers', i, 'attn', y, x): (\n                'vit', 'encoder', 'layer', str(i), 'attention', 'attention', y, x\n            )\n            for x in ['kernel', 'bias']\n            for y in ['key', 'value', 'query']\n            for i in range(12)\n        },\n        **{\n            ('encoder', 'layers', i, 'attn', 'out', x): (\n                'vit', 'encoder', 'layer', str(i), 'attention', 'output', 'dense', x\n            )\n            for x in ['kernel', 'bias']\n            for i in range(12)\n        },\n        **{\n            ('encoder', 'layers', i, 'mlp', 'layers', y1, x): (\n                'vit', 'encoder', 'layer', str(i), y2, 'dense', x\n            )\n            for x in ['kernel', 'bias']\n            for y1, y2 in [(0, 'intermediate'), (3, 'output')]\n            for i in range(12)\n        },\n        **{\n            ('encoder', 'layers', i, y1, x): (\n                'vit', 'encoder', 'layer', str(i), y2, x\n            )\n            for x in ['scale', 'bias']\n            for y1, y2 in [('norm1', 'layernorm_before'), ('norm2', 'layernorm_after')]\n            for i in range(12)\n        },\n        **{\n            ('final_norm', x): ('vit', 'layernorm', x)\n            for x in ['scale', 'bias']\n        },\n        **{\n            ('classifier', x): ('classifier', x)\n            for x in ['kernel', 'bias']\n        }\n    }\n\n    nonvisited = set(flax_model_params_fstate.keys())\n\n    for key1, key2 in params_name_mapping.items():\n        assert key1 in flax_model_params_fstate, key1\n        assert key2 in tf_model_params_fstate, (key1, key2)\n\n        nonvisited.remove(key1)\n\n        src_value = tf_model_params_fstate[key2]\n        if key2[-1] == 'kernel' and key2[-2] in ('key', 'value', 'query'):\n            shape = src_value.shape\n            src_value = src_value.reshape((shape[0], 12, 64))\n\n        if key2[-1] == 'bias' and key2[-2] in ('key', 'value', 'query'):\n            src_value = src_value.reshape((12, 64))\n\n        if key2[-4:] == ('attention', 'output', 'dense', 'kernel'):\n            shape = src_value.shape\n            src_value = src_value.reshape((12, 64, shape[-1]))\n\n        dst_value = flax_model_params_fstate[key1]\n        assert src_value.shape == dst_value.value.shape, (key2, src_value.shape, key1, dst_value.value.shape)\n        dst_value.value = src_value.copy()\n        assert dst_value.value.mean() == src_value.mean(), (dst_value.value, src_value.mean())\n\n    assert len(nonvisited) == 0, nonvisited\n    # Notice the use of `flax.nnx.update` and `flax.nnx.State`.\n    nnx.update(dst_model, nnx.State.from_flat_path(flax_model_params_fstate))\n\nvit_inplace_copy_weights(src_model=tf_model, dst_model=model)\n\nmodel.classifier = nnx.Linear(model.classifier.in_features, 405, rngs=nnx.Rngs(0))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nTensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n```\n:::\n:::\n\n\n:::\n\n## Hyperparameters\n\nWe need to define the hyperparameters that will control the training process.\n\n### Epochs\n\nFirst, we need to set the number of epochs. While fine-tuning a ViT model for classification, we can expect the following:\n\n- Epochs 1-5: Massive improvements. The model adapts from \"identifying objects\" to \"identifying birds.\"\n- Epochs 5-15: Small, incremental gains.\n- Epochs 15+: Often starts overfitting (unless you have a massive dataset or very strong augmentation).\n\nLet's do 3 epochs:\n\n::: {#51fc72fa .cell execution_count=4}\n``` {.python .cell-code}\nnum_epochs = 3\n```\n:::\n\n\n### Learning rate\n\nThe **learning rate** controls the size of the steps the optimizer takes in the direction of the gradient. You don't want to overshoot the minimum, so it is a good idea to decrease the learning rate during training. We are doing this with an [Optax](https://github.com/google-deepmind/optax) scheduler, reducing it linearly from 0.001 to 0.\n\n:::{.note}\n\n[As we saw previously](jxai_dataloader#learning-rate), if you reduce (or increase) the batch size dramatically, you should also reduce (or increase) the learning rate. Since we went from a batch size of 32 to 8, we shouldn't start with a learning rate that is too high.\n\n:::\n\n::: {#d21ad7ef .cell execution_count=5}\n``` {.python .cell-code}\nimport optax\n\nlearning_rate = 0.001\ntotal_steps = len(nabirds_train) // train_batch_size\nlr_schedule = optax.linear_schedule(learning_rate, 0.0, num_epochs * total_steps)\niterate_subsample = np.linspace(0, num_epochs * total_steps, 100)\n```\n:::\n\n\nWe can plot the learning rate schedule:\n\n::: {#44a48e40 .cell execution_count=6}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\nplt.plot(\n    np.linspace(0, num_epochs, len(iterate_subsample)),\n    [lr_schedule(i) for i in iterate_subsample],\n    lw=3,\n)\nplt.title('Learning rate')\nplt.xlabel('Epochs')\nplt.ylabel('Learning rate')\nplt.grid()\nplt.xlim((0, num_epochs))\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](jxai_training_files/figure-html/cell-6-output-1.png){width=625 height=449}\n:::\n:::\n\n\n### Momentum\n\nThe **momentum** controls the inertia of the optimizer. It helps accelerate the optimizer in the right direction and dampens oscillations (instead of using only the current gradient to update weights, momentum adds a fraction of the previous update factor to the current one. So if the gradient keeps pointing in the same direction, the momentum increases the speed of updates. If the gradient bounces back and forth, the momentum decreases the speed of updates).\n\nA momentum of 0.9 is pretty standard:\n\n::: {#de70f558 .cell execution_count=7}\n``` {.python .cell-code}\nmomentum = 0.9\n```\n:::\n\n\n### Optimizer\n\nFinally, we pass our learning rate schedule and momentum to a [stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) function from [Optax](https://github.com/google-deepmind/optax) and create our optimizer:\n\n::: {#4a9bb345 .cell execution_count=8}\n``` {.python .cell-code}\noptimizer = nnx.ModelAndOptimizer(model, optax.sgd(lr_schedule, momentum, nesterov=True))\n```\n:::\n\n\n### Loss function\n\n::: {#6088b313 .cell execution_count=9}\n``` {.python .cell-code}\ndef compute_losses_and_logits(model: nnx.Module, imgs: jax.Array, species: jax.Array):\n    logits = model(imgs)\n\n    loss = optax.softmax_cross_entropy_with_integer_labels(\n        logits=logits, labels=species\n    ).mean()\n    return loss, logits\n```\n:::\n\n\n## Training and evaluation steps\n\n::: {#329d69f2 .cell execution_count=10}\n``` {.python .cell-code}\n@nnx.jit              # To JIT compile and automatically use GPU/TPU if available\ndef train_step(\n    model: nnx.Module, optimizer: nnx.Optimizer, imgs: np.ndarray, species_id: np.ndarray\n):\n    # Convert np.ndarray to jax.Array on GPU\n    imgs = jnp.array(imgs)\n    species = jnp.array(species_id, dtype=jnp.int32)\n\n    grad_fn = nnx.value_and_grad(compute_losses_and_logits, has_aux=True)\n    (loss, logits), grads = grad_fn(model, imgs, species)\n\n    optimizer.update(grads)  # In-place updates.\n\n    return loss\n\n@nnx.jit\ndef eval_step(\n    model: nnx.Module, eval_metrics: nnx.MultiMetric, imgs: np.ndarray, species_id: np.ndarray\n):\n    # Convert np.ndarray to jax.Array on GPU\n    imgs = jnp.array(imgs)\n    species = jnp.array(species_id, dtype=jnp.int32)\n    loss, logits = compute_losses_and_logits(model, imgs, species)\n\n    eval_metrics.update(\n        loss=loss,\n        logits=logits,\n        labels=species,\n    )\n```\n:::\n\n\n## Metrics\n\n::: {#f086ea10 .cell execution_count=11}\n``` {.python .cell-code}\neval_metrics = nnx.MultiMetric(\n    loss=nnx.metrics.Average('loss'),\n    accuracy=nnx.metrics.Accuracy(),\n)\n\ntrain_metrics_history = {\n    'train_loss': [],\n}\n\neval_metrics_history = {\n    'val_loss': [],\n    'val_accuracy': [],\n}\n```\n:::\n\n\n## Training and evaluation functions\n\n::: {#a3261dfa .cell execution_count=12}\n``` {.python .cell-code}\nimport tqdm\n\nbar_format = '{desc}[{n_fmt}/{total_fmt}]{postfix} [{elapsed}<{remaining}]'\n\ndef train_one_epoch(epoch):\n    model.train()  # Set model to the training mode: e.g. update batch statistics\n    with tqdm.tqdm(\n        desc=f\"[train] epoch: {epoch + 1}/{num_epochs}, \",\n        total=total_steps,\n        bar_format=bar_format,\n        leave=True,\n    ) as pbar:\n        for batch in train_loader:\n            loss = train_step(model, optimizer, batch['img'], batch['species_id'])\n            train_metrics_history['train_loss'].append(loss.item())\n            pbar.set_postfix({'loss': loss.item()})\n            pbar.update(1)\n\ndef evaluate_model(epoch):\n    # Computes the metrics on the training and test sets after each training epoch.\n    model.eval()  # Sets model to evaluation model: e.g. use stored batch statistics.\n\n    eval_metrics.reset()  # Reset the eval metrics\n    for val_batch in val_loader:\n        eval_step(model, eval_metrics, val_batch['img'], val_batch['species_id'])\n\n    for metric, value in eval_metrics.compute().items():\n        eval_metrics_history[f'val_{metric}'].append(value)\n\n    print(f\"[val] epoch: {epoch + 1}/{num_epochs}\")\n    print(f\"- total loss: {eval_metrics_history['val_loss'][-1]:0.4f}\")\n    print(f\"- Accuracy: {eval_metrics_history['val_accuracy'][-1]:0.4f}\")\n```\n:::\n\n\n## Checkpointing\n\nCheckpointing is essential if you train for a long time. This will save you from loosing hours, days, or weeks of training if something happens (cluster issue, power outage, computer failure, training interruption...)\n\n[Orbax](https://github.com/google-deepmind/optax) provides a checkpointing management API for JAX:\n\n::: {#f41b1436 .cell execution_count=13}\n``` {.python .cell-code}\nimport orbax.checkpoint as ocp\n```\n:::\n\n\nFirst of all, it is important to create a directory for the checkpoints and to ensure that this directory is empty before you start training (otherwise the checkpoints won't be saved and you will only get an error about it *after* the training has happened—which means that you are basically loosing your entire training as the trained parameters aren't saved!).\n\nLet's create a path for a directory called \"checkpoints\" in the current directory and ensure that it is empty:\n\n```{.python}\npath = ocp.test_utils.erase_and_create_empty('/project/def-sponsor00/nabirds/checkpoints/')\n```\n\n:::{.note}\n\nBe careful that the path provided needs to be an absolute path.\n\n:::\n\nThen you set the options you want for the checkpoint manager such as: how often do you want to save checkpoints? how many checkpoints do you want to keep in total (as more checkpoints are saved, early ones can safely be deleted).\n\nFor instance, if we want to save a checkpoint every 2 steps and keep the last 3 checkpoints, we can set the options with:\n\n```{.python}\noptions = ocp.CheckpointManagerOptions(save_interval_steps=2, max_to_keep=3)\n```\n\nHere, we will save a checkpoint at every step (the default) since are only running 3 epochs:\n\n```{.python}\noptions = ocp.CheckpointManagerOptions(max_to_keep=3)\n```\n\nNow we can define our checkpoint manager:\n\n```{.python}\nmngr = ocp.CheckpointManager(path, options=options)\n```\n\nPast this point, if you follow the documentation, you will get the following warning when you try to restore your model from checkpoints:\n\n```\nWARNING:absl:Item \"default\" was found in the checkpoint, but could not be restored. Please provide a `CheckpointHandlerRegistry`, or call `restore` with an appropriate `CheckpointArgs` subclass.\n```\n\nThis is because [Orbax does not yet handle](https://github.com/google/flax/issues/4231) the [new JAX PRNG key format](https://docs.jax.dev/en/latest/jax.random.html#prng-keys).\n\nA way around this is to create a function to save checkpoints that will convert PRNG keys from the new to the old format (function taken from [this tutorial](https://docs.jaxstack.ai/en/latest/JAX_examples_image_segmentation.html)):\n\n```{.python}\ndef save_model(epoch):\n    # Get all params, statistics, RNGs, etc. from model:\n    state = nnx.state(model)\n    # Convert PRNG keys to the old format:\n    def get_key_data(x):\n        if isinstance(x, jax._src.prng.PRNGKeyArray):\n            if isinstance(x.dtype, jax._src.prng.KeyTy):\n                return jax.random.key_data(x)\n        return x\n\n    serializable_state = jax.tree.map(get_key_data, state)\n    mngr.save(epoch, args=ocp.args.StandardSave(serializable_state))\n    # Block the manager until all operations have finished running\n    # (only useful for asynchronous (distributed) training)\n    mngr.wait_until_finished()\n```\n\nNow, to create checkpoints following our management plan, we will add this function to the training loop.\n\n## Testing and debugging\n\nIt is a good idea to try your code on a very small problem to make sure it runs before launching your training loop: many scripts will only error upon finishing and if you start by running 25 epochs on your full dataset without prior testing, you may be waiting (and sitting on resources) for days before realizing that your code has issues.\n\nAn easy way to test your code on a small subset of your data is to play with the samplers of the data loaders: you only need to run the code on a handful of records to debug problems such as the checkpointer not working (and the trained model not being saved!).\n\nSo let's replace `num_records=len(nabirds_train)` and `num_records=len(nabirds_val)` by `num_records=10` for both the training and validation samplers. Then we can recreate the training and validation loaders:\n\n```{.python}\ntrain_sampler = grain.IndexSampler(\n    num_records=10,\n    shuffle=True,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1\n)\n\ntrain_loader = grain.DataLoader(\n    data_source=nabirds_train,\n    sampler=train_sampler,\n    operations=[\n        ToFloat(),\n        RandomCrop(),\n        RandomFlip(),\n        RandomContrast(),\n        RandomGamma(),\n        ZScore(),\n        grain.Batch(train_batch_size, drop_remainder=True)\n    ]\n)\n\nval_sampler = grain.IndexSampler(\n    num_records=10,\n    shuffle=False,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1\n)\n\nval_loader = grain.DataLoader(\n    data_source=nabirds_val,\n    sampler=val_sampler,\n    operations=[\n        Normalize(),\n        grain.Batch(val_batch_size)\n    ]\n)\n```\n\nNow we can run a test loop:\n\n```{.python}\nfor epoch in range(num_epochs):\n    train_one_epoch(epoch)\n    evaluate_model(epoch)\n    save_model(epoch)\n```\n\n... and debug as needed.\n\nOnce you are sure that the code runs, your checkpoints are being created as planned and all looks good, you can revert the values of the samplers and loaders:\n\n```{.python}\ntrain_sampler = grain.IndexSampler(\n    num_records=len(nabirds_train),\n    shuffle=True,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1\n)\n\ntrain_loader = grain.DataLoader(\n    data_source=nabirds_train,\n    sampler=train_sampler,\n    operations=[\n        ToFloat(),\n        RandomCrop(),\n        RandomFlip(),\n        RandomContrast(),\n        RandomGamma(),\n        ZScore(),\n        grain.Batch(train_batch_size, drop_remainder=True)\n    ]\n)\n\nval_sampler = grain.IndexSampler(\n    num_records=len(nabirds_val),\n    shuffle=False,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1\n)\n\nval_loader = grain.DataLoader(\n    data_source=nabirds_val,\n    sampler=val_sampler,\n    operations=[\n        Normalize(),\n        grain.Batch(val_batch_size)\n    ]\n)\n```\n\n## Training loop\n\nTime to run the training loop:\n\n```{.python}\n%%time\n\nfor epoch in range(num_epochs):\n    train_one_epoch(epoch)\n    evaluate_model(epoch)\n    save_model(epoch)\n```\n\n```\n[train] epoch: 1/3, [2991/2991], loss=0.392 [37:37<00:00]\n[val] epoch: 1/3\n- total loss: nan\n- Accuracy: 0.8144\n[train] epoch: 2/3, [2991/2991], loss=0.225 [39:31<00:00]\n[val] epoch: 2/3\n- total loss: nan\n- Accuracy: 0.8545\n[train] epoch: 3/3, [2991/2991], loss=0.224 [40:11<00:00]\n[val] epoch: 3/3\n- total loss: nan\n- Accuracy: 0.8666\n```\n\nOn my laptop with a dedicated GPU (Nvidia GeForce RTX 2060), each epoch takes about 40 min. On a desktop with a more powerful GPU, training takes about 10 min per epoch.\n\n*I am still investigating why my total loss is not a number.*\n\n:::{.exo}\n\n:::{.yourturn}\n\nYour turn:\n\n:::\n\nInitially I ran into an [out of memory (OOM)](https://en.wikipedia.org/wiki/Out_of_memory) problem running this code on my machine:\n\n```\nValueError: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 77463552 bytes.\n```\n\nWhat were my options at that point?\n\n:::\n\n:::{.callout-caution collapse=\"true\"}\n\n## Answer\n\nOne option of course is to get more hardware to have access to more [VRAM](https://en.wikipedia.org/wiki/Video_random-access_memory) (the GPU memory): you can take the problem to the Alliance clusters or to a commercial cloud service. But training a classification model is something that you should be able to do on a laptop that has a dedicated GPU (which is what I have). How?\n\nWe mentioned the solution [in an earlier section](jxai_dataloader#transformations): reduce the batch size. Do so by dividing it by 2 until you stop running out of memory.\n\nIn my case, I tried to go from 32 to 16 and still ran out of memory, then I tried with a batch size of 8 and it worked.\n\nSo in the code above I replaced:\n\n```{.python}\ntrain_batch_size = 32\n```\n\nby:\n\n```{.python}\ntrain_batch_size = 8\n```\n\nand ran the rest as is.\n\n:::\n\n## Plot metrics\n\nLet's plot the training metrics.\n\nEvolution of training loss:\n\n\n\n::: {#36234cad .cell execution_count=15}\n``` {.python .cell-code}\nplt.plot(train_metrics_history['train_loss'], label='Loss value during the training')\nplt.legend()\n```\n\n::: {.cell-output .cell-output-display}\n![](jxai_training_files/figure-html/cell-15-output-1.png){width=558 height=411}\n:::\n:::\n\n\nThe loss decreased in a very jagged fashion due to my small batch size. With more memory and a bigger batch size, the descent would have been smoother. To get a smoother descent with such small batches, I could have increased the momentum or calculated the metrics for several batches before passing them to the next step.\n\nI also had some NaN (not a number) for the loss at the start of training. This didn't matter because the training kept going and after a bit of training they became less frequent and eventually disappeared. To avoid this, I could have started with a lower learning rate.\n\nEvolution of validation loss and accuracy:\n\n::: {#b20c01c7 .cell execution_count=16}\n``` {.python .cell-code}\nfig, axs = plt.subplots(1, 2, figsize=(8, 8))\naxs[0].set_title('Loss value on validation set')\naxs[0].plot(eval_metrics_history['val_loss'])\naxs[1].set_title('Accuracy on validation set')\naxs[1].plot(eval_metrics_history['val_accuracy'])\n```\n\n::: {.cell-output .cell-output-display}\n![](jxai_training_files/figure-html/cell-16-output-1.png){width=664 height=653}\n:::\n:::\n\n\nYou can also use [TensorBoard](https://github.com/tensorflow/tensorboard) for this or—even better—experiment tracking tools such as [MLflow](/ai/mlops/wb_mlflow.qmd) that will allow you to compare various training experiments.\n\n:::{.note}\n\n[MLflow is now available on our JupyterHubs!](https://docs.alliancecan.ca/wiki/MLflow)\n\n:::\n\n## Test a few samples\n\nWe can now run inference on a few test images.\n\nSelect a subset of test images and their labels:\n\n```{.python}\ntest_indices = [250, 500, 750, 1000]\ntest_images = jnp.array([nabirds_val[i]['img'] for i in test_indices])\nexpected_labels = [nabirds_val[i]['species_name'] for i in test_indices]\n```\n\nRun the model to get the predictions for this subset:\n\n```{.python}\nmodel.eval()\npreds = model(test_images)\nprobas = nnx.softmax(preds, axis=1)\npred_labels = probas.argmax(axis=1)\n```\n\nWe need to define a translation function to get the species names from the species ids for the predictions:\n\n```{.python}\ndef translator(df, species_id):\n    species_name = df.unique(subset='species_id').filter(\n        pl.col('species_id') == species_id\n    ).select(pl.col('species_name')).item()\n\n    return species_name\n```\n\nLet's print the subset with their predicted vs expected labels:\n\n```{.python}\nnum_samples = len(test_indices)\n\nfig, axs = plt.subplots(1, num_samples, figsize=(7, 8))\n\nfor i in range(num_samples):\n    img, expected_label = test_images[i], expected_labels[i]\n\n    pred_label_id = pred_labels[i].item()\n    pred_label_name = translator(metadata, pred_label_id)\n    proba = probas[i, pred_label_id].item()\n    if img.dtype in (np.float32, ):\n        img = ((img - img.min()) / (img.max() - img.min()) * 255.0).astype(np.uint8)\n\n    plt.tight_layout()\n\n    axs[i].set_title(\n        f\"\"\"\n        Expected: {expected_labels[i]}\n        Predicted: {pred_label_name}\n        p={proba:.2f}\n        \"\"\",\n        fontsize=6.5,\n        linespacing=1.5\n    )\n\n    axs[i].axis('off')\n    axs[i].imshow(img)\n```\n\n<!-- ![](img/sample_tests.png) -->\n\n## Restore from checkpoint\n\nYou can see how many checkpoints you have saved with the following:\n\n```{.python}\n# Steps of all checkpoints\nmngr.all_steps()\n```\n\n```\n[0, 1, 2]\n```\n\n```{.python}\n# Step of the last checkpoint\nmngr.latest_step()\n```\n\n```\n2\n```\n\nTo restore the last checkpoint:\n\n```{.python}\nmodel = mngr.restore(mngr.latest_step())\n```\n\n",
    "supporting": [
      "jxai_training_files"
    ],
    "filters": [],
    "includes": {}
  }
}