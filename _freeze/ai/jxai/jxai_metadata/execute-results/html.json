{
  "hash": "04170464ffcd64aef7a6928c60d9446f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Compiling the metadata\nauthor: Marie-Hélène Burle\n---\n\n:::{.def}\n\nIn this section, we process some of the metadata associated with the NABirds dataset by creating a [Polars](https://github.com/pola-rs/polars) DataFrame collecting all the information we will need while processing the images and training our model. This allows us to get some information about the dataset.\n\n*[Polars](/python/hpc_polars) is a modern and ultra fast package that you should use instead of [pandas](https://github.com/pandas-dev/pandas) whenever you can if you care about performance.*\n\n:::\n\n## Metadata files\n\nIn addition to images, the dataset comes with a number of text files. To understand the dataset, of course, the place to start is by reading ... the README.\n\nYou can find it in full in this accordion box, with a summary below:\n\n:::{.callout-note collapse=\"true\"}\n\n## README\n\n### The nabirds dataset\n\n#### Versions\n\nv0 - June 2015: initial release\n\nFor more information about the dataset, visit the project websites:\n\n  http://www.vision.caltech.edu/visipedia\n  http://vision.cornell.edu/se3/projects/visipedia/\n  http://dl.allaboutbirds.org/nabirds\n\nIf you use the dataset in a publication, please cite the dataset in the style described on the dataset website (see url above).\n\nPlease see the nabirds.py file for example code on using the data. You can visualize images and annotations by running: python nabirds.py\nMake sure you are in the nabirds/ directory.\n\n#### Directory information\n\n- images/\n\n\tThe images organized in subdirectories based on species. See IMAGES AND CLASS LABELS section below for more info.\n\n- parts/\n\n\t11 part locations per image. See PART LOCATIONS section below for more info.\n\n### Images and class labels\n\nImages are contained in the directory images/, with 555 subdirectories (one for each bird category).\n\n#### List of image files (images.txt)\n\nThe list of image file names is contained in the file images.txt, with each line corresponding to one image:\n\n<image_id> <image_name>\n\n#### Train/test split (train_test_split.txt)\n\nThe suggested train/test split is contained in the file train_test_split.txt, with each line corresponding to one image:\n\n<image_id> <is_training_image>\n\nwhere <image_id> corresponds to the ID in images.txt, and a value of 1 or 0 for <is_training_image> denotes that the file is in the training or test set, respectively.\n\n#### Image sizes (sizes.txt)\n\nThe size of each image in pixels:\n\n<image_id> <width> <height>\n\nwhere <image_id> corresponds to the ID in images.txt, and <width> and <height> correspond to the width and height of the image in pixels.\n\n#### Image photographers (photographers.txt)\n\nThe photographer for each image:\n\n<image_id> <photographer_name>\n\nwhere <image_id> corresponds to the ID in images.txt, and <photographer_name> corresponds to the name of the photographer that took the photo. Please\nbe considerate and display the photographer's name when displaying their image.\n\n#### List of class names (classes.txt)\n\nThe list of class names (bird species) is contained in the file classes.txt, with each line corresponding to one class:\n\n<class_id> <class_name>\n\n#### Image class labels (image_class_labels.txt)\n\nThe ground truth class labels (bird species labels) for each image are contained in the file image_class_labels.txt, with each line corresponding to one image:\n\n<image_id> <class_id>\n\nwhere <image_id> and <class_id> correspond to the IDs in images.txt and classes.txt, respectively.\n\n#### Class hierarchy (hierarchy.txt)\n\nThe ground truth class labels (bird species labels) for each image are contained in the file image_class_labels.txt, with each line corresponding to one image:\n\n<child_class_id> <parent_class_id>\n\nwhere <child_class_id> and <parent_class_id> correspond to the IDs in classes.txt.\n\n### Bounding boxes\n\nEach image contains a single bounding box label.  Bounding box labels are contained in the file bounding_boxes.txt, with each line corresponding to one image:\n\n<image_id> <x> <y> <width> <height>\n\nwhere <image_id> corresponds to the ID in images.txt, and <x>, <y>, <width>, and <height> are all measured in pixels.\n\n### Part locations\n\n#### List of part names (parts/parts.txt)\n\nThe list of all part names is contained in the file parts/parts.txt, with each line corresponding to one part:\n\n<part_id> <part_name>\n\n#### Part locations (parts/part_locs.txt)\n\nThe set of all ground truth part locations is contained in the file parts/part_locs.txt, with each line corresponding to the annotation of a particular part in a particular image:\n\n<image_id> <part_id> <x> <y> <visible>\n\nwhere <image_id> and <part_id> correspond to the IDs in images.txt and parts/parts.txt, respectively.  <x> and <y> denote the pixel location of the center of the part.  <visible> is 0 if the part is not visible in the image and 1 otherwise.\n\n:::\n\nEach image is associated with a [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier).\n\nWe won't need all the information provided with this dataset for this course, but what we need is contained in the following files:\n\nName | Content\n---| -------\nbounding_boxes.txt | List of UUIDs and their corresponding bounding boxes (one bounding box per image, just around the bird)\nclasses.txt | List of class ids and corresponding class names\nimage_class_labels.txt | List of UUIDs and their corresponding class ids\nimages.txt | List of UUIDs and their corresponding file names\nphotographers.txt | List of UUIDs and their corresponding photographers\ntrain_test_split.txt | List of UUIDs and 1 or 0 depending on whether the image is for training or validation respectively (the dataset comes with a suggested split)\n\nThe README has one request:\n\n> Please be considerate and display the photographer's name when displaying their image.\n\nWe will make sure to follow it.\n\n## Clean problem files\n\nTwo of the files are problematic because they are jagged: the number of elements per line is inconsistent.\n\nLet's create a cleaning function that writes cleaned up copies of the files:\n\n::: {#a53f6807 .cell execution_count=2}\n``` {.python .cell-code}\ndef clean_classes_file(input_filepath, output_filepath):\n    \"\"\"\n    Remove commas, remove parenthesis, and replace all spaces except the first space\n    on each line and the space between species name and subcategory info with underscores.\n\n    Args:\n        input_filepath (str): the path of the input file.\n        output_filepath (str): the path of the output file.\n    \"\"\"\n    with open(input_filepath, 'r') as infile, \\\n         open(output_filepath, 'w') as outfile:\n\n        for line in infile:\n            # Remove commas and ending parenthesis\n            cleaned_line = line.replace(',', '').replace(')', '')\n\n            # Strip newline characters\n            cleaned_line = cleaned_line.strip()\n\n            # Split line into two parts based on the first space\n            parts = cleaned_line.split(' ', 1)\n\n            # Replace spaces in the second part with underscores\n            part2_cleaned = parts[1].replace(' ', '_').replace('_(', ' ')\n\n            final_line = f'{parts[0]} {part2_cleaned}\\n'\n\n            outfile.write(final_line)\n```\n:::\n\n\n::: {#545eb42f .cell execution_count=3}\n``` {.python .cell-code}\ndef clean_photographer_file(input_filepath, output_filepath):\n    \"\"\"\n    Remove commas, remove quotes, and replace all spaces except the first space\n    on each line with underscores.\n\n    Args:\n        input_filepath (str): the path of the input file.\n        output_filepath (str): the path of the output file.\n    \"\"\"\n    with open(input_filepath, 'r') as infile, \\\n         open(output_filepath, 'w') as outfile:\n\n        for line in infile:\n            # Remove quotes and commas\n            cleaned_line = line.replace('\"', '').replace(',', '')\n\n            # Strip newline characters\n            cleaned_line = cleaned_line.strip()\n\n            # Split line into two parts based on the first space\n            parts = cleaned_line.split(' ', 1)\n\n            # Replace spaces in the second part with underscores\n            part2_cleaned = parts[1].replace(' ', '_')\n\n            final_line = f'{parts[0]} {part2_cleaned}\\n'\n\n            outfile.write(final_line)\n```\n:::\n\n\nThen we can apply the function on our files:\n\n```{.python}\nbase_dir = '<path-of-the-nabirds-dir>'\n```\n\n:::{.note}\n\nTo be replaced by proper path.\n\n:::\n\n\n\n::: {#2643716e .cell execution_count=5}\n``` {.python .cell-code}\nimport os\n\nclean_photographer_file(\n    os.path.join(base_dir, 'photographers.txt'),\n    os.path.join(base_dir, 'photographers_cleaned.txt')\n)\n\nclean_classes_file(\n    os.path.join(base_dir, 'classes.txt'),\n    os.path.join(base_dir, 'classes_cleaned.txt')\n)\n```\n:::\n\n\n## Create variables\n\nFor convenience, let's create variables with the path of the various files we need:\n\n::: {#076ae46a .cell execution_count=6}\n``` {.python .cell-code}\nbb_file = os.path.join(base_dir, 'bounding_boxes.txt')\nclass_id_to_name_file = os.path.join(base_dir, 'classes_cleaned.txt')\nclass_id_file = os.path.join(base_dir, 'image_class_labels.txt')\npath_file = os.path.join(base_dir, 'images.txt')\nphotographer_file = os.path.join(base_dir, 'photographers_cleaned.txt')\ntrain_test_split_file = os.path.join(base_dir, 'train_test_split.txt')\n```\n:::\n\n\n## Create a metadata DataFrame\n\nNow it's time to put all the data together in one DataFrame.\n\nFirst, we create a series of DataFrames from each text file:\n\n::: {#3b43b8ce .cell execution_count=7}\n``` {.python .cell-code}\nimport polars as pl\n\nbb = pl.read_csv(\n    bb_file,\n    separator=' ',\n    has_header=False,\n    new_columns=['UUID', 'bb_x', 'bb_y', 'bb_width', 'bb_height']\n)\n\nclass_id = pl.read_csv(\n    class_id_file,\n    separator=' ',\n    has_header=False,\n    new_columns=['UUID', 'class_id']\n)\n```\n:::\n\n\nThe `class_id_to_name_file` is also fairly complicated: some bird species name are followed by additional information (e.g. \"Adult\" or \"Immature\") in parenthesis. If we want to train a model to identify bird species (rather than classes including the subcategories), we need to separate the two.\n\n:::{.notenoit}\n\nAn easy way to quickly check what the file looks like is to run **in the terminal, not in Python**:\n\n```{.bash}\nrg \"\\(\" /home/marie/parvus/prog/mint/ai/jxai/nabirds/classes.txt | fzf\n```\n\n:::\n\nIn order to split species name on the one hand and additional information on the other, we need to create 3 columns instead of 2 for this file. The problem is that many rows only have 2 elements (the additional info is not often present).\n\nThe shell command above allows to quickly look for the first occurrence of the additional info: it appears at line 295.\n\nPolars scans the first 100 elements by default to determine the [schema](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.schema.html) or mapping for the DataFrame. We need to increase this value to at least 295 to make sure that it detects the 3^rd^ column during the reading in of the file:\n\n::: {#6fc33f4b .cell execution_count=8}\n``` {.python .cell-code}\nclass_id_to_name = pl.read_csv(\n    class_id_to_name_file,\n    separator=' ',\n    has_header=False,\n    infer_schema_length=296,\n    new_columns=['class_id', 'species', 'subcategory']\n)\n```\n:::\n\n\n::: {#756e4553 .cell execution_count=9}\n``` {.python .cell-code}\npath = pl.read_csv(\n    path_file,\n    separator=' ',\n    has_header=False,\n    new_columns=['UUID', 'path']\n)\n\nphotographer = pl.read_csv(\n    photographer_file,\n    separator=' ',\n    has_header=False,\n    new_columns=['UUID', 'photographer']\n)\n\ntrain_test_split = pl.read_csv(\n    train_test_split_file,\n    separator=' ',\n    has_header=False,\n    new_columns=['UUID', 'is_training_img']\n)\n```\n:::\n\n\n:::{.note}\n\nWe can use `polars.read_csv` even though we have text files because our files are space separated value files. So they function like CSV files with the exception that we have to set the value of the `separator` argument to ` `.\n\n:::\n\nThen we can combine the two DataFrames dealing with classes so that the birds identifications becomes directly associated with the birds UUIDs:\n\n::: {#2ae9b21d .cell execution_count=10}\n``` {.python .cell-code}\nclasses_metadata = (\n    class_id.join(class_id_to_name, on='class_id')\n)\n```\n:::\n\n\nFinally, we combine all the DataFrames:\n\n::: {#9eaadb10 .cell execution_count=11}\n``` {.python .cell-code}\nmetadata = (\n    bb.join(classes_metadata, on='UUID')\n    .join(path, on='UUID')\n    .join(photographer, on='UUID')\n    .join(train_test_split, on='UUID')\n)\n```\n:::\n\n\n## Sanity checks\n\nLet's see what our DataFrame looks like:\n\n::: {#1ff68a7f .cell execution_count=12}\n``` {.python .cell-code}\nprint(metadata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (48_562, 11)\n┌─────────────┬──────┬──────┬──────────┬───┬─────────────┬─────────────┬─────────────┬─────────────┐\n│ UUID        ┆ bb_x ┆ bb_y ┆ bb_width ┆ … ┆ subcategory ┆ path        ┆ photographe ┆ is_training │\n│ ---         ┆ ---  ┆ ---  ┆ ---      ┆   ┆ ---         ┆ ---         ┆ r           ┆ _img        │\n│ str         ┆ i64  ┆ i64  ┆ i64      ┆   ┆ str         ┆ str         ┆ ---         ┆ ---         │\n│             ┆      ┆      ┆          ┆   ┆             ┆             ┆ str         ┆ i64         │\n╞═════════════╪══════╪══════╪══════════╪═══╪═════════════╪═════════════╪═════════════╪═════════════╡\n│ 0000139e-21 ┆ 83   ┆ 59   ┆ 128      ┆ … ┆ null        ┆ 0817/000013 ┆ Ruth_Cantwe ┆ 0           │\n│ dc-4d0c-bfe ┆      ┆      ┆          ┆   ┆             ┆ 9e21dc4d0cb ┆ ll          ┆             │\n│ 1-4cae3c…   ┆      ┆      ┆          ┆   ┆             ┆ fe14cae3…   ┆             ┆             │\n│ 0000d9fc-4e ┆ 328  ┆ 88   ┆ 163      ┆ … ┆ null        ┆ 0860/0000d9 ┆ Christopher ┆ 0           │\n│ 02-4c06-a0a ┆      ┆      ┆          ┆   ┆             ┆ fc4e024c06a ┆ _L._Wood_Ch ┆             │\n│ f-a55cfb…   ┆      ┆      ┆          ┆   ┆             ┆ 0afa55cf…   ┆ ris_Wood    ┆             │\n│ 00019306-9d ┆ 174  ┆ 367  ┆ 219      ┆ … ┆ null        ┆ 0900/000193 ┆ Ryan_Schain ┆ 0           │\n│ 83-4334-b25 ┆      ┆      ┆          ┆   ┆             ┆ 069d834334b ┆             ┆             │\n│ 5-a44774…   ┆      ┆      ┆          ┆   ┆             ┆ 255a4477…   ┆             ┆             │\n│ 0001afd4-99 ┆ 307  ┆ 179  ┆ 492      ┆ … ┆ Nonbreeding ┆ 0645/0001af ┆ Laura_Erick ┆ 1           │\n│ a1-4a67-b94 ┆      ┆      ┆          ┆   ┆ /juvenile   ┆ d499a14a67b ┆ son         ┆             │\n│ 0-d41941…   ┆      ┆      ┆          ┆   ┆             ┆ 940d4194…   ┆             ┆             │\n│ 000332b8-99 ┆ 395  ┆ 139  ┆ 262      ┆ … ┆ null        ┆ 0929/000332 ┆ Dan_Irizarr ┆ 0           │\n│ 7c-4540-964 ┆      ┆      ┆          ┆   ┆             ┆ b8997c45409 ┆ y           ┆             │\n│ 7-2f0a84…   ┆      ┆      ┆          ┆   ┆             ┆ 6472f0a8…   ┆             ┆             │\n│ …           ┆ …    ┆ …    ┆ …        ┆ … ┆ …           ┆ …           ┆ …           ┆ …           │\n│ fff86e8b-79 ┆ 344  ┆ 163  ┆ 291      ┆ … ┆ null        ┆ 0891/fff86e ┆ Nancy_Landr ┆ 1           │\n│ 5f-400a-91e ┆      ┆      ┆          ┆   ┆             ┆ 8b795f400a9 ┆ y           ┆             │\n│ 8-565bbb…   ┆      ┆      ┆          ┆   ┆             ┆ 1e8565bb…   ┆             ┆             │\n│ fff926d7-cc ┆ 330  ┆ 180  ┆ 339      ┆ … ┆ Light_morph ┆ 0660/fff926 ┆ Ruth_Sulliv ┆ 1           │\n│ ad-4788-839 ┆      ┆      ┆          ┆   ┆             ┆ d7ccad47888 ┆ an          ┆             │\n│ e-97af2d…   ┆      ┆      ┆          ┆   ┆             ┆ 39e97af2…   ┆             ┆             │\n│ fffa33ef-a7 ┆ 184  ┆ 94   ┆ 258      ┆ … ┆ null        ┆ 0492/fffa33 ┆ Gerry_Dewag ┆ 1           │\n│ 65-408d-8d6 ┆      ┆      ┆          ┆   ┆             ┆ efa765408d8 ┆ he          ┆             │\n│ 6-6efc7f…   ┆      ┆      ┆          ┆   ┆             ┆ d666efc7…   ┆             ┆             │\n│ ffff0d87-bc ┆ 102  ┆ 210  ┆ 461      ┆ … ┆ Adult_Male  ┆ 0372/ffff0d ┆ Muriel_Nedd ┆ 0           │\n│ 84-4ef2-a47 ┆      ┆      ┆          ┆   ┆             ┆ 87bc844ef2a ┆ ermeyer     ┆             │\n│ e-a4bfa4…   ┆      ┆      ┆          ┆   ┆             ┆ 47ea4bfa…   ┆             ┆             │\n│ fffff3a5-2a ┆ 281  ┆ 164  ┆ 524      ┆ … ┆ null        ┆ 0880/fffff3 ┆ Dominic_She ┆ 0           │\n│ 75-47d0-887 ┆      ┆      ┆          ┆   ┆             ┆ a52a7547d08 ┆ rony        ┆             │\n│ f-03871e…   ┆      ┆      ┆          ┆   ┆             ┆ 87f03871…   ┆             ┆             │\n└─────────────┴──────┴──────┴──────────┴───┴─────────────┴─────────────┴─────────────┴─────────────┘\n```\n:::\n:::\n\n\nAnd then let's explore a number of characteristics:\n\n::: {#f10f5dd3 .cell execution_count=13}\n``` {.python .cell-code}\nprint(metadata.columns)\nprint(metadata.row(0))\nprint(metadata.row(-1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['UUID', 'bb_x', 'bb_y', 'bb_width', 'bb_height', 'class_id', 'species', 'subcategory', 'path', 'photographer', 'is_training_img']\n('0000139e-21dc-4d0c-bfe1-4cae3c85c829', 83, 59, 128, 228, 817, 'Oak_Titmouse', None, '0817/0000139e21dc4d0cbfe14cae3c85c829.jpg', 'Ruth_Cantwell', 0)\n('fffff3a5-2a75-47d0-887f-03871e3f9a37', 281, 164, 524, 279, 880, 'Black-throated_Gray_Warbler', None, '0880/fffff3a52a7547d0887f03871e3f9a37.jpg', 'Dominic_Sherony', 0)\n```\n:::\n:::\n\n\n::: {#c1378bc9 .cell execution_count=14}\n``` {.python .cell-code}\nprint(metadata.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (5, 11)\n┌─────────────┬──────┬──────┬──────────┬───┬─────────────┬─────────────┬─────────────┬─────────────┐\n│ UUID        ┆ bb_x ┆ bb_y ┆ bb_width ┆ … ┆ subcategory ┆ path        ┆ photographe ┆ is_training │\n│ ---         ┆ ---  ┆ ---  ┆ ---      ┆   ┆ ---         ┆ ---         ┆ r           ┆ _img        │\n│ str         ┆ i64  ┆ i64  ┆ i64      ┆   ┆ str         ┆ str         ┆ ---         ┆ ---         │\n│             ┆      ┆      ┆          ┆   ┆             ┆             ┆ str         ┆ i64         │\n╞═════════════╪══════╪══════╪══════════╪═══╪═════════════╪═════════════╪═════════════╪═════════════╡\n│ 0000139e-21 ┆ 83   ┆ 59   ┆ 128      ┆ … ┆ null        ┆ 0817/000013 ┆ Ruth_Cantwe ┆ 0           │\n│ dc-4d0c-bfe ┆      ┆      ┆          ┆   ┆             ┆ 9e21dc4d0cb ┆ ll          ┆             │\n│ 1-4cae3c…   ┆      ┆      ┆          ┆   ┆             ┆ fe14cae3…   ┆             ┆             │\n│ 0000d9fc-4e ┆ 328  ┆ 88   ┆ 163      ┆ … ┆ null        ┆ 0860/0000d9 ┆ Christopher ┆ 0           │\n│ 02-4c06-a0a ┆      ┆      ┆          ┆   ┆             ┆ fc4e024c06a ┆ _L._Wood_Ch ┆             │\n│ f-a55cfb…   ┆      ┆      ┆          ┆   ┆             ┆ 0afa55cf…   ┆ ris_Wood    ┆             │\n│ 00019306-9d ┆ 174  ┆ 367  ┆ 219      ┆ … ┆ null        ┆ 0900/000193 ┆ Ryan_Schain ┆ 0           │\n│ 83-4334-b25 ┆      ┆      ┆          ┆   ┆             ┆ 069d834334b ┆             ┆             │\n│ 5-a44774…   ┆      ┆      ┆          ┆   ┆             ┆ 255a4477…   ┆             ┆             │\n│ 0001afd4-99 ┆ 307  ┆ 179  ┆ 492      ┆ … ┆ Nonbreeding ┆ 0645/0001af ┆ Laura_Erick ┆ 1           │\n│ a1-4a67-b94 ┆      ┆      ┆          ┆   ┆ /juvenile   ┆ d499a14a67b ┆ son         ┆             │\n│ 0-d41941…   ┆      ┆      ┆          ┆   ┆             ┆ 940d4194…   ┆             ┆             │\n│ 000332b8-99 ┆ 395  ┆ 139  ┆ 262      ┆ … ┆ null        ┆ 0929/000332 ┆ Dan_Irizarr ┆ 0           │\n│ 7c-4540-964 ┆      ┆      ┆          ┆   ┆             ┆ b8997c45409 ┆ y           ┆             │\n│ 7-2f0a84…   ┆      ┆      ┆          ┆   ┆             ┆ 6472f0a8…   ┆             ┆             │\n└─────────────┴──────┴──────┴──────────┴───┴─────────────┴─────────────┴─────────────┴─────────────┘\n```\n:::\n:::\n\n\n::: {#96d29308 .cell execution_count=15}\n``` {.python .cell-code}\nprint(metadata.tail())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (5, 11)\n┌─────────────┬──────┬──────┬──────────┬───┬─────────────┬─────────────┬─────────────┬─────────────┐\n│ UUID        ┆ bb_x ┆ bb_y ┆ bb_width ┆ … ┆ subcategory ┆ path        ┆ photographe ┆ is_training │\n│ ---         ┆ ---  ┆ ---  ┆ ---      ┆   ┆ ---         ┆ ---         ┆ r           ┆ _img        │\n│ str         ┆ i64  ┆ i64  ┆ i64      ┆   ┆ str         ┆ str         ┆ ---         ┆ ---         │\n│             ┆      ┆      ┆          ┆   ┆             ┆             ┆ str         ┆ i64         │\n╞═════════════╪══════╪══════╪══════════╪═══╪═════════════╪═════════════╪═════════════╪═════════════╡\n│ fff86e8b-79 ┆ 344  ┆ 163  ┆ 291      ┆ … ┆ null        ┆ 0891/fff86e ┆ Nancy_Landr ┆ 1           │\n│ 5f-400a-91e ┆      ┆      ┆          ┆   ┆             ┆ 8b795f400a9 ┆ y           ┆             │\n│ 8-565bbb…   ┆      ┆      ┆          ┆   ┆             ┆ 1e8565bb…   ┆             ┆             │\n│ fff926d7-cc ┆ 330  ┆ 180  ┆ 339      ┆ … ┆ Light_morph ┆ 0660/fff926 ┆ Ruth_Sulliv ┆ 1           │\n│ ad-4788-839 ┆      ┆      ┆          ┆   ┆             ┆ d7ccad47888 ┆ an          ┆             │\n│ e-97af2d…   ┆      ┆      ┆          ┆   ┆             ┆ 39e97af2…   ┆             ┆             │\n│ fffa33ef-a7 ┆ 184  ┆ 94   ┆ 258      ┆ … ┆ null        ┆ 0492/fffa33 ┆ Gerry_Dewag ┆ 1           │\n│ 65-408d-8d6 ┆      ┆      ┆          ┆   ┆             ┆ efa765408d8 ┆ he          ┆             │\n│ 6-6efc7f…   ┆      ┆      ┆          ┆   ┆             ┆ d666efc7…   ┆             ┆             │\n│ ffff0d87-bc ┆ 102  ┆ 210  ┆ 461      ┆ … ┆ Adult_Male  ┆ 0372/ffff0d ┆ Muriel_Nedd ┆ 0           │\n│ 84-4ef2-a47 ┆      ┆      ┆          ┆   ┆             ┆ 87bc844ef2a ┆ ermeyer     ┆             │\n│ e-a4bfa4…   ┆      ┆      ┆          ┆   ┆             ┆ 47ea4bfa…   ┆             ┆             │\n│ fffff3a5-2a ┆ 281  ┆ 164  ┆ 524      ┆ … ┆ null        ┆ 0880/fffff3 ┆ Dominic_She ┆ 0           │\n│ 75-47d0-887 ┆      ┆      ┆          ┆   ┆             ┆ a52a7547d08 ┆ rony        ┆             │\n│ f-03871e…   ┆      ┆      ┆          ┆   ┆             ┆ 87f03871…   ┆             ┆             │\n└─────────────┴──────┴──────┴──────────┴───┴─────────────┴─────────────┴─────────────┴─────────────┘\n```\n:::\n:::\n\n\n::: {#e4b79a8c .cell execution_count=16}\n``` {.python .cell-code}\nimport random\n\nrandom.seed(123)\nprint(metadata.sample())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (1, 11)\n┌─────────────┬──────┬──────┬──────────┬───┬─────────────┬─────────────┬─────────────┬─────────────┐\n│ UUID        ┆ bb_x ┆ bb_y ┆ bb_width ┆ … ┆ subcategory ┆ path        ┆ photographe ┆ is_training │\n│ ---         ┆ ---  ┆ ---  ┆ ---      ┆   ┆ ---         ┆ ---         ┆ r           ┆ _img        │\n│ str         ┆ i64  ┆ i64  ┆ i64      ┆   ┆ str         ┆ str         ┆ ---         ┆ ---         │\n│             ┆      ┆      ┆          ┆   ┆             ┆             ┆ str         ┆ i64         │\n╞═════════════╪══════╪══════╪══════════╪═══╪═════════════╪═════════════╪═════════════╪═════════════╡\n│ b20cc001-80 ┆ 382  ┆ 236  ┆ 308      ┆ … ┆ Male        ┆ 0780/b20cc0 ┆ Alex_Burdo  ┆ 0           │\n│ f0-4280-9cd ┆      ┆      ┆          ┆   ┆             ┆ 0180f042809 ┆             ┆             │\n│ 5-b9b569…   ┆      ┆      ┆          ┆   ┆             ┆ cd5b9b56…   ┆             ┆             │\n└─────────────┴──────┴──────┴──────────┴───┴─────────────┴─────────────┴─────────────┴─────────────┘\n```\n:::\n:::\n\n\n::: {#96fcb153 .cell execution_count=17}\n``` {.python .cell-code}\nprint(metadata.schema)\nprint(metadata.shape)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSchema({'UUID': String, 'bb_x': Int64, 'bb_y': Int64, 'bb_width': Int64, 'bb_height': Int64, 'class_id': Int64, 'species': String, 'subcategory': String, 'path': String, 'photographer': String, 'is_training_img': Int64})\n(48562, 11)\n```\n:::\n:::\n\n\n::: {#b582fe2e .cell execution_count=18}\n``` {.python .cell-code}\nprint(metadata.glimpse())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 48562\nColumns: 11\n$ UUID            <str> '0000139e-21dc-4d0c-bfe1-4cae3c85c829', '0000d9fc-4e02-4c06-a0af-a55cfb16b12b', '00019306-9d83-4334-b255-a447742edce3', '0001afd4-99a1-4a67-b940-d419413e23b3', '000332b8-997c-4540-9647-2f0a8495aecf', '000343bd-5215-49ba-ab9c-7c97a70ac1a5', '0004ff8d-0cc8-47ee-94ba-43352a8b9eb4', '0007181f-a727-4481-ad89-591200c61b9d', '00071e20-8156-4bd8-b5ca-6445c2560ee5', '0007acfc-c0e6-4393-9ab6-02215a82ef63'\n$ bb_x            <i64> 83, 328, 174, 307, 395, 120, 417, 47, 260, 193\n$ bb_y            <i64> 59, 88, 367, 179, 139, 210, 109, 194, 146, 291\n$ bb_width        <i64> 128, 163, 219, 492, 262, 587, 221, 819, 578, 526\n$ bb_height       <i64> 228, 298, 378, 224, 390, 357, 467, 573, 516, 145\n$ class_id        <i64> 817, 860, 900, 645, 929, 652, 951, 900, 988, 400\n$ species         <str> 'Oak_Titmouse', 'Ovenbird', 'Savannah_Sparrow', 'Eared_Grebe', 'Eastern_Phoebe', 'Yellow-crowned_Night-Heron', 'Florida_Scrub-Jay', 'Savannah_Sparrow', 'Yellow-headed_Blackbird', 'Herring_Gull'\n$ subcategory     <str> null, null, null, 'Nonbreeding/juvenile', null, 'Immature', null, null, 'Female/Immature_Male', 'Adult'\n$ path            <str> '0817/0000139e21dc4d0cbfe14cae3c85c829.jpg', '0860/0000d9fc4e024c06a0afa55cfb16b12b.jpg', '0900/000193069d834334b255a447742edce3.jpg', '0645/0001afd499a14a67b940d419413e23b3.jpg', '0929/000332b8997c454096472f0a8495aecf.jpg', '0652/000343bd521549baab9c7c97a70ac1a5.jpg', '0951/0004ff8d0cc847ee94ba43352a8b9eb4.jpg', '0900/0007181fa7274481ad89591200c61b9d.jpg', '0988/00071e2081564bd8b5ca6445c2560ee5.jpg', '0400/0007acfcc0e643939ab602215a82ef63.jpg'\n$ photographer    <str> 'Ruth_Cantwell', 'Christopher_L._Wood_Chris_Wood', 'Ryan_Schain', 'Laura_Erickson', 'Dan_Irizarry', 'Ken_Schneider', 'Velma_Knowles', 'Matt_Tillett', 'Terry_Gray', 'Cory_Gregory'\n$ is_training_img <i64> 0, 0, 0, 1, 0, 0, 0, 1, 1, 0\n\nNone\n```\n:::\n:::\n\n\n::: {#be14a071 .cell execution_count=19}\n``` {.python .cell-code}\nprint(metadata.describe())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (9, 12)\n┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n│ statistic ┆ UUID      ┆ bb_x      ┆ bb_y      ┆ … ┆ subcatego ┆ path      ┆ photograp ┆ is_train │\n│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ry        ┆ ---       ┆ her       ┆ ing_img  │\n│ str       ┆ str       ┆ f64       ┆ f64       ┆   ┆ ---       ┆ str       ┆ ---       ┆ ---      │\n│           ┆           ┆           ┆           ┆   ┆ str       ┆           ┆ str       ┆ f64      │\n╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n│ count     ┆ 48562     ┆ 48562.0   ┆ 48562.0   ┆ … ┆ 23589     ┆ 48562     ┆ 48562     ┆ 48562.0  │\n│ null_coun ┆ 0         ┆ 0.0       ┆ 0.0       ┆ … ┆ 24973     ┆ 0         ┆ 0         ┆ 0.0      │\n│ t         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n│ mean      ┆ null      ┆ 221.68531 ┆ 158.53412 ┆ … ┆ null      ┆ null      ┆ null      ┆ 0.492752 │\n│           ┆           ┆           ┆ 1         ┆   ┆           ┆           ┆           ┆          │\n│ std       ┆ null      ┆ 133.05486 ┆ 80.976264 ┆ … ┆ null      ┆ null      ┆ null      ┆ 0.499953 │\n│           ┆           ┆ 4         ┆           ┆   ┆           ┆           ┆           ┆          │\n│ min       ┆ 0000139e- ┆ 0.0       ┆ 0.0       ┆ … ┆ Adult     ┆ 0295/01f5 ┆ A._Walton ┆ 0.0      │\n│           ┆ 21dc-4d0c ┆           ┆           ┆   ┆           ┆ 3d6bf5e44 ┆           ┆          │\n│           ┆ -bfe1-4ca ┆           ┆           ┆   ┆           ┆ 9438d2bb7 ┆           ┆          │\n│           ┆ e3c…      ┆           ┆           ┆   ┆           ┆ 9e0…      ┆           ┆          │\n│ 25%       ┆ null      ┆ 115.0     ┆ 99.0      ┆ … ┆ null      ┆ null      ┆ null      ┆ 0.0      │\n│ 50%       ┆ null      ┆ 205.0     ┆ 149.0     ┆ … ┆ null      ┆ null      ┆ null      ┆ 0.0      │\n│ 75%       ┆ null      ┆ 315.0     ┆ 208.0     ┆ … ┆ null      ┆ null      ┆ null      ┆ 1.0      │\n│ max       ┆ fffff3a5- ┆ 837.0     ┆ 799.0     ┆ … ┆ Yellow-sh ┆ 1010/ff41 ┆ www.burly ┆ 1.0      │\n│           ┆ 2a75-47d0 ┆           ┆           ┆   ┆ afted     ┆ 92ee5a164 ┆ bird.com  ┆          │\n│           ┆ -887f-038 ┆           ┆           ┆   ┆           ┆ de684149d ┆           ┆          │\n│           ┆ 71e…      ┆           ┆           ┆   ┆           ┆ 926…      ┆           ┆          │\n└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n```\n:::\n:::\n\n\n## Learn about the data\n\nNow that we have the metadata organized, let's get to know our data:\n\n::: {#ae2642b6 .cell execution_count=20}\n``` {.python .cell-code}\nprint(f'There are {len(metadata)} images in the dataset.')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThere are 48562 images in the dataset.\n```\n:::\n:::\n\n\n::: {#bacc29d8 .cell execution_count=21}\n``` {.python .cell-code}\nmetadata_train = metadata.filter(pl.col('is_training_img') == 1)\nprint(f\"\"\"\nThere are:\n- {len(metadata_train)} images in the training set,\n- {len(metadata) - len(metadata_train)} in the validation set.\n\"\"\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nThere are:\n- 23929 images in the training set,\n- 24633 in the validation set.\n\n```\n:::\n:::\n\n\n::: {#0640e533 .cell execution_count=22}\n``` {.python .cell-code}\nclass_id = metadata.unique(pl.col('class_id'))\nspecies = metadata.unique(pl.col('species'))\nprint(f'There are {len(class_id)} different classes and {len(species)} different species in the dataset.')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThere are 555 different classes and 405 different species in the dataset.\n```\n:::\n:::\n\n\n::: {#aeec8e3d .cell execution_count=23}\n``` {.python .cell-code}\ntrain_class_id_group_length = metadata_train.group_by(pl.col('class_id')).len()\nprint(f\"\"\"\nThe number of images per class in the training set varies from {train_class_id_group_length.min().select(pl.col('len')).item()} to {train_class_id_group_length.max().select(pl.col('len')).item()},\nwith an average of {round(train_class_id_group_length.mean().select(pl.col('len')).item())} images per class.\n\"\"\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nThe number of images per class in the training set varies from 4 to 60,\nwith an average of 43 images per class.\n\n```\n:::\n:::\n\n\n::: {#abc5214a .cell execution_count=24}\n``` {.python .cell-code}\ntrain_species_group_length = metadata_train.group_by(pl.col('species')).len()\nprint(f\"\"\"\nThe number of images per species in the training set varies from {train_species_group_length.min().select(pl.col('len')).item()} to {train_species_group_length.max().select(pl.col('len')).item()},\nwith an average of {round(train_species_group_length.mean().select(pl.col('len')).item())} images per species.\n\"\"\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nThe number of images per species in the training set varies from 6 to 221,\nwith an average of 59 images per species.\n\n```\n:::\n:::\n\n\n::: {#259a8d9a .cell execution_count=25}\n``` {.python .cell-code}\nsubcategory = metadata.unique(pl.col(\"subcategory\"))\nexample_list = subcategory.get_column('subcategory').drop_nulls().head(10).to_list()\nexample_list_cleaned = [x.replace('_', ' ') for x in example_list]\nprint(f\"\"\"\nThere are {len(subcategory)} species subcategories, such as:\n- {'\\n- '.join(example_list_cleaned)}\n- etc.\n\"\"\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nThere are 61 species subcategories, such as:\n- Nonbreeding/Immature\n- Pink-sided\n- Oregon\n- Adult subadult\n- White morph\n- Tan-striped/immature\n- Female/juvenile\n- Adult Subadult\n- Breeding\n- Adult male\n- etc.\n\n```\n:::\n:::\n\n\n## Summary metadata\n\nLet's summarize the info we gathered from the metadata:\n\nCategory | Number\n--- | ---\nImages | 48_562\nTraining images | 23_929\nValidation images | 24_633\nClasses (species with their subcategories) | 555\nSpecies | 405\nAverage number of images per class in the training set | 43\nAverage number of images per species in the training set | 59\n\n## Save DataFrame to Parquet\n\nTo make it easier to retrieve information from the metadata later on, we can save the DataFrame to file.\n\n[Parquet](https://github.com/apache/parquet-format/) is an open-source, columnar, and extremely efficient binary file format for tabular data. Unlike in CSV or JSON files, the data is compressed, making it efficient for storage space. It is also excellent for query performance. Always prefer it over text-based formats.\n\n::: {#6dbe13e8 .cell execution_count=26}\n``` {.python .cell-code}\nmetadata.write_parquet('metadata.parquet')\n```\n:::\n\n\nOur metadata is ready. We can now start working with the pictures.\n\n",
    "supporting": [
      "jxai_metadata_files"
    ],
    "filters": [],
    "includes": {}
  }
}