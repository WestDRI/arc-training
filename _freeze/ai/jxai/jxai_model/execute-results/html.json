{
  "hash": "36d2111dad082ed74638ddd3fea049d5",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Model and training strategy\nauthor: Marie-Hélène Burle\n---\n\n:::{.def}\n\n\n\n:::\n\n:::{.callout-note collapse=\"true\"}\n\n## Minimal necessary code from previous sections\n\n```{.python}\nbase_dir = \"<path-of-the-nabirds-dir>\"\n```\n\n:::{.notenoit}\n\nTo be replaced by actual path: in our training cluster, the `base_dir` is at `/project/def-sponsor00/nabirds`:\n\n```{.python}\nbase_dir = '/project/def-sponsor00/nabirds'\n```\n\n:::\n\n\n\n::: {#13f2a67b .cell execution_count=3}\n``` {.python .cell-code}\nimport os\nimport polars as pl\nimport imageio.v3 as iio\nimport grain.python as grain\n\nmetadata = pl.read_parquet(\"metadata.parquet\")\nmetadata_train = metadata.filter(pl.col(\"is_training_img\") == 1)\ncleaned_img_dir = os.path.join(base_dir, \"cleaned_images\")\n\nclass NABirdsDataset:\n    \"\"\"NABirds dataset class.\"\"\"\n\n    def __init__(self, metadata_file, data_dir):\n        self.metadata_file = metadata_file\n        self.data_dir = data_dir\n\n    def __len__(self):\n        return len(self.metadata_file)\n\n    def __getitem__(self, idx):\n        path = os.path.join(self.data_dir, self.metadata_file.get_column(\"path\")[idx])\n        img = iio.imread(path)\n        species = self.metadata_file.get_column(\"species\")[idx].replace(\"_\", \" \")\n        subcategory = self.metadata_file.get_column(\"subcategory\")[idx]\n        if subcategory is not None:\n            subcategory = subcategory.replace(\"_\", \" \")\n        photographer = self.metadata_file.get_column(\"photographer\")[idx].replace(\"_\", \" \")\n        element = {\n            \"img\": img,\n            \"species\": species,\n            \"subcategory\": subcategory,\n            \"photographer\": photographer,\n        }\n\n        return element\n\nnabirds_train = NABirdsDataset(metadata_train, cleaned_img_dir)\n```\n:::\n\n\n:::\n\n## Our strategy\n\n### Technique\n\n\n\n### Architecture\n\nOptions that would make sense for our example include ResNet and EfficientNet.\n\n[ResNet](https://en.wikipedia.org/wiki/Residual_neural_network), or residual network, is a type of architecture in which the layers are reformulated as learning residual functions with reference to the layer inputs. This allows for deeper (and thus more performant) networks [@he2015deepresiduallearningimage].\n\n![from @he2015deepresiduallearningimage](img/resnet.png)\n\n[ResNet-50](https://huggingface.co/microsoft/resnet-50) has become a classic CNN for image classification.\n\n[EfficientNet](https://en.wikipedia.org/wiki/EfficientNet) is a family of newer computer vision CNNs from Google that uses a compound coefficient to uniformly scale depth, width, and resolution of networks and achieves better accuracy with fewer parameters than other CNNs [@tan2020efficientnetrethinkingmodelscaling]. This makes them easier to train on fewer resources and can lead to better results. Tuning them is however harder than the more robust ResNet family.\n\n![from @tan2020efficientnetrethinkingmodelscaling](img/efficientnet.png)\n\nThere are variations for different image sizes sizes. For instance:\n\n- [EfficientNet b0](https://huggingface.co/google/efficientnet-b0) for images of size 224x224\n- [EfficientNet b2](https://huggingface.co/google/efficientnet-b2) for images 260x260\n- [EfficientNet b3](https://huggingface.co/google/efficientnet-b3) for images 300x300\n- [EfficientNet b7](https://huggingface.co/google/efficientnet-b7) for images 600x600\n\n### Pre-trained weights\n\n\n### Choice of library\n\n\n### Strategy summary\n\nCategory | Answer\n-- | -----\nTechnique | Transfer learning\nArchitecture | EfficientNet-B2 (EfficientNet-B0 or ResNet-50 are other reasonable options)\nPre-trained weights | ImageNet\nLibrary | \n\n## Implementation\n\n::: {#534e2482 .cell execution_count=4}\n``` {.python .cell-code}\nimport jax\nimport jax.numpy as jnp\nfrom flax import nnx\nfrom flax.nnx import bridge\nfrom transformers import FlaxEfficientNetModel\n\nclass NABirdsEfficientNet(nnx.Module):\n    def __init__(self, num_classes=555, *, rngs: nnx.Rngs):\n        # 1. Load the pre-trained Linen model structure & weights from Hugging Face\n        hf_model = FlaxEfficientNetModel.from_pretrained(\"google/efficientnet-b0\")\n\n        # 2. Extract the underlying Linen module and its variables\n        linen_module = hf_model.module\n        linen_variables = hf_model.params\n        # HF stores batch_stats in 'batch_stats' if they exist, or inside params.\n        # EfficientNet usually has 'batch_stats'. We merge them for the bridge.\n        if hasattr(hf_model, 'batch_stats'):\n            linen_variables = {**linen_variables, **hf_model.batch_stats}\n\n        # 3. Create the NNX Bridge\n        # We wrap the Linen module. ToNNX creates the structure.\n        self.backbone = bridge.ToNNX(linen_module, rngs=rngs)\n\n        # 4. WEIGHT SURGERY (The Critical Step)\n        # We must initialize the bridge to create the NNX variable structure,\n        # then replace those random variables with the pre-trained ones.\n        dummy_input = jnp.ones((1, 224, 224, 3))\n        self.backbone.lazy_init(dummy_input)\n\n        # Transfer weights: Linen dict -> NNX State\n        # The bridge maps Linen collections to NNX variable types automatically.\n        # 'params' -> nnx.Param, 'batch_stats' -> nnx.BatchStat\n        _, backbone_state = nnx.split(self.backbone)\n\n        # This function recursively matches keys and updates the state\n        def copy_weights(target_state, source_dict):\n            for key, value in source_dict.items():\n                if isinstance(value, dict) or hasattr(value, 'items'):\n                    # Traverse deeper if it's a dict/FrozenDict\n                    copy_weights(target_state[key], value)\n                else:\n                    # We found a leaf (array). Update the NNX Variable's value.\n                    # Note: target_state[key] is a Variable (Param/BatchStat) wrapper\n                    target_state[key].value = value\n\n        copy_weights(backbone_state, linen_variables)\n        nnx.update(self.backbone, backbone_state)\n\n        # 5. Define your new Custom Head (Pure NNX)\n        # EfficientNet-B0 output is 1280 dim\n        self.head = nnx.Linear(1280, num_classes, rngs=rngs)\n\n    def __call__(self, x):\n        # Run backbone (bridge)\n        # HF models output a generic object; we need 'last_hidden_state'\n        # shape: [batch, 7, 7, 1280] for B0\n        outputs = self.backbone(x)\n        features = outputs.last_hidden_state\n\n        # Global Average Pooling (standard for EfficientNet)\n        features = jnp.mean(features, axis=(1, 2))\n\n        # Classification\n        return self.head(features)\n\n# --- Usage Example ---\n\n# 1. Initialize\nrngs = nnx.Rngs(params=0, dropout=1)\nmodel = NABirdsEfficientNet(num_classes=555, rngs=rngs)\n\n# 2. Forward Pass\nx = jax.random.normal(jax.random.key(0), (1, 224, 224, 3))\nlogits = model(x)\n\nprint(f\"Logits shape: {logits.shape}\") # (1, 555)\nprint(\"Model initialized and pre-trained weights loaded via NNX bridge.\")\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-bright-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-bright-red-fg\">ModuleNotFoundError</span>                       Traceback (most recent call last)\n<span class=\"ansi-bright-cyan-fg\">Cell</span><span class=\"ansi-bright-cyan-fg\"> </span><span class=\"ansi-green-fg\">In[3]</span><span class=\"ansi-green-fg\">, line 5</span>\n<span class=\"ansi-bright-green-fg\">      3</span> <span style=\"color:rgb(255,95,135)\">from</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">flax</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">import</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">nnx</span>\n<span class=\"ansi-bright-green-fg\">      4</span> <span style=\"color:rgb(255,95,135)\">from</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">flax</span><span class=\"ansi-bright-white-fg\">.</span><span class=\"ansi-bright-white-fg\">nnx</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">import</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">bridge</span>\n<span class=\"ansi-bright-green-fg\">----&gt; </span><span class=\"ansi-bright-green-fg\">5</span> <span style=\"color:rgb(255,95,135)\">from</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">transformers</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">import</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">FlaxEfficientNetModel</span>\n<span class=\"ansi-bright-green-fg\">      7</span> <span style=\"color:rgb(95,215,255)\">class</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(175,215,0)\">NABirdsEfficientNet</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">nnx</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">Module</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">:</span>\n<span class=\"ansi-bright-green-fg\">      8</span> <span class=\"ansi-bright-white-fg\">    </span><span style=\"color:rgb(95,215,255)\">def</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(175,215,0)\">__init__</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">self</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">num_classes</span><span style=\"color:rgb(255,95,135)\">=</span><span style=\"color:rgb(175,135,255)\">555</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">*</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">rngs</span><span class=\"ansi-bright-white-fg\">:</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">nnx</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">Rngs</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">:</span>\n<span class=\"ansi-bright-green-fg\">      9</span> <span class=\"ansi-bright-white-fg\">        </span><span style=\"color:rgb(138,138,138)\"># 1. Load the pre-trained Linen model structure &amp; weights from Hugging Face</span>\n\n<span class=\"ansi-bright-red-fg\">ModuleNotFoundError</span>: No module named 'transformers'</pre>\n```\n:::\n\n:::\n:::\n\n\n",
    "supporting": [
      "jxai_model_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}