{
  "hash": "4a46c59dc568036ab9e41ed163e481a2",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Data loader\nauthor: Marie-Hélène Burle\n---\n\n:::{.def}\n\n\n\n:::\n\n:::{.callout-note collapse=\"true\"}\n\n## Minimal necessary code from previous sections\n\n```{.python}\nbase_dir = \"<path-of-the-nabirds-dir>\"\n```\n\n:::{.note}\n\nTo be replaced by proper path.\n\n:::\n\n\n\n::: {#b825a0ce .cell execution_count=2}\n``` {.python .cell-code}\nimport os\nimport polars as pl\nimport imageio.v3 as iio\n\nmetadata = pl.read_parquet(\"metadata.parquet\")\nmetadata_train = metadata.filter(pl.col(\"is_training_img\") == 1)\n\nclass NABirdsDataset:\n    \"\"\"NABirds dataset class.\"\"\"\n    def __init__(self, metadata_file, data_dir):\n        self.metadata_file = metadata_file\n        self.data_dir = data_dir\n    def __len__(self):\n        return len(self.metadata_file)\n    def __getitem__(self, idx):\n        path = os.path.join(\n            self.data_dir,\n            self.metadata_file.get_column('path')[idx]\n        )\n        img = iio.imread(path)\n        id = self.metadata_file.get_column('id')[idx].replace('_', ' ')\n        photographer = self.metadata_file.get_column('photographer')[idx].replace('_', ' ')\n        element = {\n            'image': img,\n            'id': id,\n            'photographer': photographer,\n        }\n        return element\n\ncleaned_img_dir = os.path.join(base_dir, \"cleaned_images\")\n\nnabirds_train = NABirdsDataset(\n    metadata_train,\n    cleaned_img_dir\n)\n```\n:::\n\n\n:::\n\n## Goal of a DataLoader\n\nWe can access elements of our Dataset class (as we did in the previous section) with:\n\n::: {#deb782e9 .cell execution_count=3}\n``` {.python .cell-code}\nfor i, element in enumerate(nabirds_train):\n    print(element['image'].shape)\n    if i == 3:\n        break\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(224, 224, 3)\n(224, 224, 3)\n(224, 224, 3)\n(224, 224, 3)\n```\n:::\n:::\n\n\nAnd we can return the next object by creating an iterator from of iterable dataset:\n\n::: {#80769e11 .cell execution_count=4}\n``` {.python .cell-code}\nnext(iter(nabirds_train))\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n{'image': array([[[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n \n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n \n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n \n        ...,\n \n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n \n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n \n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]]], shape=(224, 224, 3), dtype=uint8),\n 'id': 'Eared Grebe (Nonbreeding/juvenile)',\n 'photographer': 'Laura Erickson'}\n```\n:::\n:::\n\n\n:::{.note}\n\nWe get all those 0 because we padded images with black.\n\n:::\n\nBut all this is extremely limited.\n\nDataLoaders feed data to the model during training. They handle batching, shuffling, sharding across machines, the number of epochs, etc.\n\n## Grain DataLoaders\n\nCreating a DataLoader with the JAX AI stack is done [Grain](https://github.com/google/grain), but it can just as well be done using [PyTorch](https://github.com/pytorch/pytorch), [TensorFlow Datasets](https://github.com/tensorflow/datasets), [Hugging Face Datasets](https://github.com/huggingface/datasets), or any method you are used to. That's the advantage of the modular philosophy that the stack relies on. Grain has the advantage of being extremely efficient and not relying on a huge set of dependencies such as PyTorch or TensorFlow.\n\nIn Grain, a DataLoader requires 3 components:\n\n- A data source: \n- Transforms:\n- Sampler:\n\n## Data source\n\nWe already have that: it is our instance of Dataset class that we called `nabirds_train`.\n\n## Transformations\n\nWe need to split the data into batches. Batches can be defined with the  `grain.Batch` method as a DataLoader transformation.\n\nLet's use batches of 32 with `grain.Batch(batch_size=32)`.\n\n:::{.callout-note collapse=\"true\"}\n\n## How to choose the batch size?\n\nThe batch size is a crucial hyperparameter: it impacts your training speed, model stability, and final accuracy.\n\n### Default strategy\n\nIf you are unsure where to start, **use a batch size of 32**.\n\n32 is small enough to provide a regularizing effect (helping the model generalize) but large enough to benefit from parallel processing on GPUs.\n\n### Standard values\n\nAlways use powers of 2 (32, 64, 128, 256) because GPUs and CPUs are optimized for binary operations, and this aligns memory allocation efficiently.\n\n|  | **Small batch size**  | **Large batch size**  |\n| :--- | :--- | :--- |\n| **Training speed** | Slower: less efficient use of GPU | Faster: maximizes GPU throughput |\n| **Generalization** | Better: the \"noise\" in the gradient helps the model escape sharp local minima | Worse: can lead to overfitting |\n| **Convergence** | Noisy training curve: loss fluctuates | Smoother training curve: stable descent |\n| **Memory usage** | Low: good for limited VRAM | High: risk of OOM |\n\n### Tuning the batch size\n\n#### Ceiling\n\nYour maximum batch size is dictated by your GPU memory (VRAM).\n\nIf you hit an [out of memory (OOM) error](https://en.wikipedia.org/wiki/Out_of_memory), you need to back down to the the previous successful power of 2 (this is your hardware maximum).\n\n#### Performance\n\nJust because you *can* fit a batch size of 4096 doesn't mean you *should*.\n\nIf training is stable but slow, double to 64, then double again to 128. You can increase the batch size to the hardware maximum to speed up epochs.\n\nIf the model overfits or diverges, try reducing the batch size. The \"noisy\" updates act like regularization, preventing the model from memorizing the data too perfectly.\n\n### Advanced techniques\n\n- **Gradient accumulation:**\n\nIf you need a batch size of 64 for stability but your GPU only fits 16, you can use *gradient accumulation*. You process 4 mini-batches of 16, accumulate the gradients, and update the weights once. This mathematically simulates a batch size of 64.\n\n- **Dynamic batching:**\n\nSome advanced training regimes start with a small batch size to stabilize early training and increase it over time to speed up convergence (similar to learning rate decay).\n\n### Learning rate\n\nIf you change your batch size significantly, you should adjust your learning rate.\n\nA rule that works well until you get to very large batch sizes is to double the learning rate when you double the batch size.\n\n:::\n\n## Samplers\n\n### Sequential sampler\n\nGrain comes with a [basic sequential sampler](https://google-grain.readthedocs.io/en/latest/_autosummary/grain.samplers.SequentialSampler.html).\n\n::: {#aea8b973 .cell execution_count=5}\n``` {.python .cell-code}\nimport grain.python as grain\n\nnabirds_train_seqsampler = grain.SequentialSampler(\n    num_records=4\n)\n```\n:::\n\n\n::: {#842337eb .cell execution_count=6}\n``` {.python .cell-code}\nfor record_metadata in nabirds_train_seqsampler:\n    print(record_metadata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRecordMetadata(index=0, record_key=0, rng=None)\nRecordMetadata(index=1, record_key=1, rng=None)\nRecordMetadata(index=2, record_key=2, rng=None)\nRecordMetadata(index=3, record_key=3, rng=None)\n```\n:::\n:::\n\n\n### Index sampler\n\nGrain [index sampler](https://google-grain.readthedocs.io/en/latest/_autosummary/grain.samplers.IndexSampler.html) xxx\n\n::: {#cb219d5d .cell execution_count=7}\n``` {.python .cell-code}\nnabirds_train_isampler = grain.IndexSampler(\n    num_records=200,\n    shuffle=True,\n    seed=0\n)\n```\n:::\n\n\n::: {#0f751257 .cell execution_count=8}\n``` {.python .cell-code}\nfor i, record_metadata in enumerate(nabirds_train_isampler):\n  print(record_metadata)\n  if i == 3:\n      break\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRecordMetadata(index=0, record_key=134, rng=Generator(Philox))\nRecordMetadata(index=1, record_key=133, rng=Generator(Philox))\nRecordMetadata(index=2, record_key=10, rng=Generator(Philox))\nRecordMetadata(index=3, record_key=136, rng=Generator(Philox))\n```\n:::\n:::\n\n\n## DataLoaders\n\nWe now have our source, samplers, and transformation, so we can build experiment with Grain DataLoaders.\n\n### With sequential sampler\n\n::: {#819fc05b .cell execution_count=9}\n``` {.python .cell-code}\nnabirds_train_dl = grain.DataLoader(\n    data_source=nabirds_train,\n    sampler=nabirds_train_seqsampler,\n    worker_count=0\n)\n```\n:::\n\n\n::: {#991a08f9 .cell execution_count=10}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\nfig = plt.figure(figsize=(8, 8))\n\nfor i, element in enumerate(nabirds_train_dl):\n    ax = plt.subplot(2, 2, i + 1)\n    plt.tight_layout()\n    ax.set_title(\n        f'Element {i}\\nIdentification: {element['id']}\\nPicture by {element['photographer']}',\n        fontsize=9\n    )\n    ax.axis('off')\n    plt.imshow(element['image'])\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](jxai_dataloader_files/figure-html/cell-11-output-1.png){width=745 height=733}\n:::\n:::\n\n\n:::{.note}\n\nNotice that, unlike [last time we displayed some images](jxai_preprocess.qmd#display-a-sample), we aren't looping through our Dataset (`nabirds_train`) anymore, but through our DataLoader (`nabirds_train_dl`).\n\nBecause we set the number of records to 4 in the sampler, we don't have to break the loop.\n\n:::\n\n### With index sampler\n\n::: {#a1ceee79 .cell execution_count=11}\n``` {.python .cell-code}\nnabirds_train_dl = grain.DataLoader(\n    data_source=nabirds_train,\n    sampler=nabirds_train_isampler,\n    worker_count=0\n)\n```\n:::\n\n\n::: {#33a243eb .cell execution_count=12}\n``` {.python .cell-code}\nfig = plt.figure(figsize=(8, 8))\n\nfor i, element in enumerate(nabirds_train_dl):\n    ax = plt.subplot(2, 2, i + 1)\n    plt.tight_layout()\n    ax.set_title(\n        f'Element {i}\\nIdentification: {element['id']}\\nPicture by {element['photographer']}',\n        fontsize=9\n    )\n    ax.axis('off')\n    plt.imshow(element['image'])\n    if i == 3:\n        plt.show()\n        break\n```\n\n::: {.cell-output .cell-output-display}\n![](jxai_dataloader_files/figure-html/cell-13-output-1.png){width=705 height=733}\n:::\n:::\n\n\n### Adding batching\n\n::: {#951eca5c .cell execution_count=13}\n``` {.python .cell-code}\nnabirds_train_dl = grain.DataLoader(\n    data_source=nabirds_train,\n    sampler=nabirds_train_isampler,\n    worker_count=0,\n    operations=[\n        grain.Batch(batch_size=32)\n    ]\n)\n```\n:::\n\n\n::: {#6ac5ca93 .cell execution_count=14}\n``` {.python .cell-code}\nfor i, element in enumerate(nabirds_train_dl):\n    print(element['image'].shape)\n    if i == 0:\n        plt.show()\n        break\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(32, 224, 224, 3)\n```\n:::\n:::\n\n\nAs you can see, the batch size got added as an extra dimension.\n\n",
    "supporting": [
      "jxai_dataloader_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}