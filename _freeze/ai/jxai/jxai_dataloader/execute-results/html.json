{
  "hash": "cf6900535e51884e3350da5dc0d0f6e5",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: DataLoaders\nauthor: Marie-Hélène Burle\nbibliography: jxai.bib\ncsl: diabetologia.csl\n---\n\n:::{.def}\n\nA critical part of deep learning is the loading of data to the model during the training loops.\n\nDataLoaders handle the choice of which sample to load and in what order; they optimize the process in parallel by managing workers; they set several hyperparameters such as batch size and number of epochs.\n\nIn this section we explore DataLoaders with the [Grain](https://github.com/google/grain) library [-@grain2023github].\n\n:::\n\n## Training set\n\nLet's use our Dataset class (simplified slightly because we don't need the bounding boxes anymore) and create one instance just with the training set:\n\n```{.python}\nbase_dir = \"<path-of-the-nabirds-dir>\"\n```\n\n:::{.note}\n\nTo be replaced by proper path.\n\n:::\n\n\n\n::: {#dc5696f4 .cell execution_count=3}\n``` {.python .cell-code}\nimport os\nimport polars as pl\nimport imageio.v3 as iio\n\nmetadata = pl.read_parquet(\"metadata.parquet\")\nmetadata_train = metadata.filter(pl.col(\"is_training_img\") == 1)\n\nclass NABirdsDataset:\n    \"\"\"NABirds dataset class.\"\"\"\n    def __init__(self, metadata_file, data_dir):\n        self.metadata_file = metadata_file\n        self.data_dir = data_dir\n    def __len__(self):\n        return len(self.metadata_file)\n    def __getitem__(self, idx):\n        path = os.path.join(\n            self.data_dir,\n            self.metadata_file.get_column('path')[idx]\n        )\n        img = iio.imread(path)\n        species = self.metadata_file.get_column('species')[idx].replace('_', ' ')\n        subcategory = self.metadata_file.get_column('subcategory')[idx]\n        if subcategory is not None:\n            subcategory = subcategory.replace('_', ' ')\n        photographer = self.metadata_file.get_column('photographer')[idx].replace('_', ' ')\n        element = {\n            'img': img,\n            'species': species,\n            'subcategory': subcategory,\n            'photographer': photographer,\n        }\n        return element\n\ncleaned_img_dir = os.path.join(base_dir, \"cleaned_images\")\n\nnabirds_train = NABirdsDataset(\n    metadata_train,\n    cleaned_img_dir\n)\n```\n:::\n\n\n## Goal of DataLoaders\n\nWe can access elements of our Dataset class (as we did in the previous section) with:\n\n::: {#ff4f5b5f .cell execution_count=4}\n``` {.python .cell-code}\nfor i, element in enumerate(nabirds_train):\n    print(element['img'].shape)\n    if i == 3:\n        break\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(312, 688, 3)\n(739, 1024, 3)\n(722, 808, 3)\n(753, 896, 3)\n```\n:::\n:::\n\n\nAnd we can return the next object by creating an iterator from of iterable dataset:\n\n::: {#218a2fb8 .cell execution_count=5}\n``` {.python .cell-code}\nnext(iter(nabirds_train))\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n{'img': array([[[123, 144, 171],\n         [124, 145, 172],\n         [125, 146, 173],\n         ...,\n         [130, 154, 180],\n         [128, 152, 178],\n         [127, 151, 177]],\n \n        [[124, 145, 172],\n         [125, 146, 173],\n         [126, 147, 174],\n         ...,\n         [127, 151, 177],\n         [128, 152, 178],\n         [128, 152, 178]],\n \n        [[126, 147, 174],\n         [127, 148, 175],\n         [127, 148, 175],\n         ...,\n         [124, 148, 174],\n         [126, 150, 176],\n         [127, 151, 177]],\n \n        ...,\n \n        [[100, 105, 124],\n         [100, 106, 122],\n         [100, 105, 124],\n         ...,\n         [114, 131, 159],\n         [114, 131, 159],\n         [114, 131, 159]],\n \n        [[101, 106, 126],\n         [101, 106, 125],\n         [101, 106, 126],\n         ...,\n         [115, 132, 160],\n         [115, 132, 160],\n         [115, 132, 160]],\n \n        [[102, 107, 127],\n         [102, 107, 127],\n         [102, 107, 127],\n         ...,\n         [116, 133, 161],\n         [116, 133, 161],\n         [116, 133, 161]]], shape=(312, 688, 3), dtype=uint8),\n 'species': 'Eared Grebe',\n 'subcategory': 'Nonbreeding/juvenile',\n 'photographer': 'Laura Erickson'}\n```\n:::\n:::\n\n\nBut all this is extremely limited.\n\nDataLoaders feed data to the model during training. They handle batching, shuffling, sharding across machines, the number of epochs, etc.\n\n## Grain DataLoaders\n\nThe JAX AI stack includes the [Grain](https://github.com/google/grain) library [-@grain2023github] to create DataLoaders, but it can also be done using [PyTorch](https://github.com/pytorch/pytorch), [TensorFlow Datasets](https://github.com/tensorflow/datasets), [Hugging Face Datasets](https://github.com/huggingface/datasets), or any method you are used to. That's the advantage of the modular philosophy that the stack relies on. Grain is extremely efficient and does not rely on a huge set of dependencies as PyTorch and TensorFlow do.\n\nIn Grain, a DataLoader requires 3 components:\n\n- A data source\n- Transforms\n- A sampler\n\n## Data source\n\nWe already have that: it is our instance of Dataset class that we called `nabirds_train`.\n\n## Transformations\n\nWe need to split the data into batches. Batches can be defined with the  `grain.Batch` method as a DataLoader transformation.\n\nLet's use batches of 32 with `grain.Batch(batch_size=32)`.\n\n:::{.callout-note collapse=\"true\"}\n\n## How to choose the batch size?\n\nThe batch size is a crucial hyperparameter: it impacts your training speed, model stability, and final accuracy.\n\n### Default strategy\n\nIf you are unsure where to start, **use a batch size of 32**.\n\n32 is small enough to provide a regularizing effect (helping the model generalize) but large enough to benefit from parallel processing on GPUs.\n\n### Standard values\n\nAlways use powers of 2 (32, 64, 128, 256) because GPUs and CPUs are optimized for binary operations, and this aligns memory allocation efficiently.\n\n|  | **Small batch size**  | **Large batch size**  |\n| :--- | :--- | :--- |\n| **Training speed** | Slower: less efficient use of GPU | Faster: maximizes GPU throughput |\n| **Generalization** | Better: the \"noise\" in the gradient helps the model escape sharp local minima | Worse: can lead to overfitting |\n| **Convergence** | Noisy training curve: loss fluctuates | Smoother training curve: stable descent |\n| **Memory usage** | Low: good for limited VRAM | High: risk of OOM |\n\n### Tuning the batch size\n\n#### Ceiling\n\nYour maximum batch size is dictated by your GPU memory (VRAM).\n\nIf you hit an [out of memory (OOM) error](https://en.wikipedia.org/wiki/Out_of_memory), you need to back down to the the previous successful power of 2 (this is your hardware maximum).\n\n#### Performance\n\nJust because you *can* fit a batch size of 4096 doesn't mean you *should*.\n\nIf training is stable but slow, double to 64, then double again to 128. You can increase the batch size to the hardware maximum to speed up epochs.\n\nIf the model overfits or diverges, try reducing the batch size. The \"noisy\" updates act like regularization, preventing the model from memorizing the data too perfectly.\n\n### Advanced techniques\n\n- **Gradient accumulation:**\n\nIf you need a batch size of 64 for stability but your GPU only fits 16, you can use *gradient accumulation*. You process 4 mini-batches of 16, accumulate the gradients, and update the weights once. This mathematically simulates a batch size of 64.\n\n- **Dynamic batching:**\n\nSome advanced training regimes start with a small batch size to stabilize early training and increase it over time to speed up convergence (similar to learning rate decay).\n\n### Learning rate\n\nIf you change your batch size significantly, you should adjust your learning rate.\n\nA rule that works well until you get to very large batch sizes is to double the learning rate when you double the batch size.\n\n:::\n\n## Samplers\n\n### Sequential sampler\n\nGrain comes with a [basic sequential sampler](https://google-grain.readthedocs.io/en/latest/_autosummary/grain.samplers.SequentialSampler.html).\n\n::: {#af91c23e .cell execution_count=6}\n``` {.python .cell-code}\nimport grain.python as grain\n\nnabirds_train_seqsampler = grain.SequentialSampler(\n    num_records=4\n)\n\nfor record_metadata in nabirds_train_seqsampler:\n    print(record_metadata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRecordMetadata(index=0, record_key=0, rng=None)\nRecordMetadata(index=1, record_key=1, rng=None)\nRecordMetadata(index=2, record_key=2, rng=None)\nRecordMetadata(index=3, record_key=3, rng=None)\n```\n:::\n:::\n\n\n### Index sampler\n\nGrain [index sampler](https://google-grain.readthedocs.io/en/latest/_autosummary/grain.samplers.IndexSampler.html) is the one you should use as it allows for global shuffling of the dataset, setting the number of epochs, etc.\n\n::: {#6bb0cf81 .cell execution_count=7}\n``` {.python .cell-code}\nnabirds_train_isampler = grain.IndexSampler(\n    num_records=200,\n    shuffle=True,\n    seed=0\n)\n\nfor i, record_metadata in enumerate(nabirds_train_isampler):\n  print(record_metadata)\n  if i == 3:\n      break\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRecordMetadata(index=0, record_key=134, rng=Generator(Philox))\nRecordMetadata(index=1, record_key=133, rng=Generator(Philox))\nRecordMetadata(index=2, record_key=10, rng=Generator(Philox))\nRecordMetadata(index=3, record_key=136, rng=Generator(Philox))\n```\n:::\n:::\n\n\n## Building DataLoaders\n\nWe now have our source, samplers, and transformation (batching), so we can experiment with Grain DataLoaders.\n\n### With sequential sampler\n\n::: {#6732b2b8 .cell execution_count=8}\n``` {.python .cell-code}\nnabirds_train_dl = grain.DataLoader(\n    data_source=nabirds_train,\n    sampler=nabirds_train_seqsampler,\n    worker_count=0\n)\n```\n:::\n\n\n::: {#b6ba0b37 .cell execution_count=9}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\nfig = plt.figure(figsize=(8, 9))\n\nfor i, element in enumerate(nabirds_train_dl):\n    ax = plt.subplot(2, 2, i + 1)\n    plt.tight_layout()\n    ax.set_title(\n        f\"\"\"\n        Element {i}\n        Species: {element['species']}\n        Additional information: {element['subcategory']}\n        Picture by {element['photographer']}\n        \"\"\",\n        fontsize=9,\n        linespacing=1.5\n    )\n    ax.axis('off')\n    plt.imshow(element['img'])\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](jxai_dataloader_files/figure-html/cell-9-output-1.png){width=748 height=759}\n:::\n:::\n\n\n:::{.note}\n\nNotice that, unlike [last time we displayed some images](jxai_preprocess.qmd#display-a-sample), we aren't looping through our Dataset (`nabirds_train`) anymore, but through our DataLoader (`nabirds_train_dl`).\n\nBecause we set the number of records to 4 in the sampler, we don't have to break the loop.\n\n:::\n\n### With index sampler\n\n::: {#0e240ef4 .cell execution_count=10}\n``` {.python .cell-code}\nnabirds_train_dl = grain.DataLoader(\n    data_source=nabirds_train,\n    sampler=nabirds_train_isampler,\n    worker_count=0\n)\n```\n:::\n\n\n::: {#794bb4c8 .cell execution_count=11}\n``` {.python .cell-code}\nfig = plt.figure(figsize=(8, 9))\n\nfor i, element in enumerate(nabirds_train_dl):\n    ax = plt.subplot(2, 2, i + 1)\n    plt.tight_layout()\n    ax.set_title(\n        f\"\"\"\n        Element {i}\n        Species: {element['species']}\n        Additional information: {element['subcategory']}\n        Picture by {element['photographer']}\n        \"\"\",\n        fontsize=9,\n        linespacing=1.5\n    )\n    ax.axis('off')\n    plt.imshow(element['img'])\n    if i == 3:\n        plt.show()\n        break\n```\n\n::: {.cell-output .cell-output-display}\n![](jxai_dataloader_files/figure-html/cell-11-output-1.png){width=636 height=825}\n:::\n:::\n\n\n### Adding batching\n\n::: {#9e923df2 .cell execution_count=12}\n``` {.python .cell-code}\nnabirds_train_dl = grain.DataLoader(\n    data_source=nabirds_train,\n    sampler=nabirds_train_isampler,\n    worker_count=0,\n    operations=[\n        grain.Batch(batch_size=32)\n    ]\n)\n```\n:::\n\n\n",
    "supporting": [
      "jxai_dataloader_files"
    ],
    "filters": [],
    "includes": {}
  }
}