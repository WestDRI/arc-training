{
  "hash": "420811327279093f7b79979c346054b7",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Data augmentation\nauthor: Marie-Hélène Burle\n---\n\n:::{.def}\n\n\n\n:::\n\n:::{.callout-note collapse=\"true\"}\n\n## Minimal necessary code from previous sections\n\n```{.python}\nbase_dir = \"<path-of-the-nabirds-dir>\"\n```\n\n:::{.note}\n\nTo be replaced by proper path.\n\n:::\n\n\n\n::: {#d7b9039f .cell execution_count=2}\n``` {.python .cell-code}\nimport os\nimport polars as pl\nimport imageio.v3 as iio\nimport grain.python as grain\n\nmetadata = pl.read_parquet(\"metadata.parquet\")\nmetadata_train = metadata.filter(pl.col(\"is_training_img\") == 1)\n\nclass NABirdsDataset:\n    \"\"\"NABirds dataset class.\"\"\"\n    def __init__(self, metadata_file, data_dir):\n        self.metadata_file = metadata_file\n        self.data_dir = data_dir\n    def __len__(self):\n        return len(self.metadata_file)\n    def __getitem__(self, idx):\n        path = os.path.join(\n            self.data_dir,\n            self.metadata_file.get_column('path')[idx]\n        )\n        img = iio.imread(path)\n        id = self.metadata_file.get_column('id')[idx].replace('_', ' ')\n        photographer = self.metadata_file.get_column('photographer')[idx].replace('_', ' ')\n        element = {\n            'image': img,\n            'id': id,\n            'photographer': photographer,\n        }\n        return element\n\ncleaned_img_dir = os.path.join(base_dir, \"cleaned_images\")\n\nnabirds_train = NABirdsDataset(\n    metadata_train,\n    cleaned_img_dir\n)\n\nnabirds_train_sampler = grain.IndexSampler(\n    num_records=200,\n    shuffle=True,\n    seed=0\n)\n\nnabirds_train_dl = grain.DataLoader(\n    data_source=nabirds_train,\n    sampler=nabirds_train_sampler,\n    worker_count=0,\n    operations=[\n        grain.Batch(batch_size=32)\n    ]\n)\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-bright-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-bright-red-fg\">ModuleNotFoundError</span>                       Traceback (most recent call last)\n<span class=\"ansi-bright-cyan-fg\">Cell</span><span class=\"ansi-bright-cyan-fg\"> </span><span class=\"ansi-green-fg\">In[2]</span><span class=\"ansi-green-fg\">, line 3</span>\n<span class=\"ansi-bright-green-fg\">      1</span> <span style=\"color:rgb(255,95,135)\">import</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">os</span>\n<span class=\"ansi-bright-green-fg\">      2</span> <span style=\"color:rgb(255,95,135)\">import</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">polars</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(95,215,255)\">as</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">pl</span>\n<span class=\"ansi-bright-green-fg\">----&gt; </span><span class=\"ansi-bright-green-fg\">3</span> <span style=\"color:rgb(255,95,135)\">import</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">imageio</span><span class=\"ansi-bright-white-fg\">.</span><span class=\"ansi-bright-white-fg\">v3</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(95,215,255)\">as</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">iio</span>\n<span class=\"ansi-bright-green-fg\">      4</span> <span style=\"color:rgb(255,95,135)\">import</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">grain</span><span class=\"ansi-bright-white-fg\">.</span><span class=\"ansi-bright-white-fg\">python</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(95,215,255)\">as</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">grain</span>\n<span class=\"ansi-bright-green-fg\">      6</span> <span class=\"ansi-bright-white-fg\">metadata</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">=</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">pl</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">read_parquet</span><span class=\"ansi-bright-white-fg\">(</span><span style=\"color:rgb(215,215,135)\">\"</span><span style=\"color:rgb(215,215,135)\">metadata.parquet</span><span style=\"color:rgb(215,215,135)\">\"</span><span class=\"ansi-bright-white-fg\">)</span>\n\n<span class=\"ansi-bright-red-fg\">ModuleNotFoundError</span>: No module named 'imageio'</pre>\n```\n:::\n\n:::\n:::\n\n\n:::\n\n## What is data augmentation?\n\nTraining deep learning models requires vast amounts of labelled data. The more diverse and numerous the data, the better the models will perform on new, unseen data.\n\nA number of labelled datasets exist, but they are only so big. Moreover, for specific applications, you will need to fine-tune models on specific data for which there might not be any labelled data. And labelling data is costly and time-consuming. In some cases, it might even be impossible because little unlabelled data exist (think for instance of rare tumours).\n\nData augmentation is the artificial creation of new data by modifying the existing data in small ways. It is very powerful to avoid overfitting, particularly where datasets are small (if you were lucky enough to have a huge dataset, you wouldn't need to bother with data augmentation which would actually create an additional computationally costly step with extremely little benefit).\n\n\n\n\n\n\ncite (from bib tex file):\n- https://arxiv.org/abs/2205.01491\n\n\n## Tools\n\n[PIX](https://github.com/google-deepmind/dm_pixk) provides low-level, JAX-native image processing primitives that can be directly jitted and vmapped.\n\n\ncite (from bib tex file):\n- paper on libraries\n\n\n\n[TorchVision transforms](https://docs.pytorch.org/vision/0.8/transforms.html)\n\n[skimage.transform](https://scikit-image.org/docs/0.25.x/api/skimage.transform.html) from [scikit-image](https://github.com/scikit-image/scikit-image) (that we used previously to create a Transform that resizes our images with padding).\n\n:::{.emph}\n\nWe are shifting paradigm here and moving from the CPU to the GPU. This is where JAX comes in.\n\n:::\n\n## Techniques\n\n- Geometric transformations (flips, rotations, scaling, crops...)\n- Color space transformations (brightness, contrast, gamma, hue, saturation, grayscale conversion, channel shuffling...)\n- Noise transformations (Gaussian noise, blurring...)\n- Occlusive transformations (erasing parts of the image)\n- Mixing images (various techniques mixing images and appropriately applying the same treatment to labels)\n\n\n\n[PIX](https://github.com/google-deepmind/dm_pix) [list of augmentations](https://dm-pix.readthedocs.io/en/latest/api.html#)\n\n[Pseudorandom numbers in JAX](https://docs.jax.dev/en/latest/random-numbers.html)\n\n## Choosing the techniques\n\n### How many to use?\n\nThe size of your dataset dictates how aggressively you should augment.\n\n| Dataset Size | Strategy | Recommended Count |\n| :--- | :--- | :--- |\n| **Tiny (<1k images)** | **Heavy Augmentation.** You should be worried about overfitting, so you need to create more artificial data | **4-6 techniques.** Use strong geometric shifts  |\n| **Medium (1k - 50k)** | **Standard Augmentation.** Balance variety with training speed | **3-4 techniques.** |\n| **Massive (>1M images)** | **Light Augmentation.** The data itself already provides diversity. Augmentation will only slow down training. | **1-2 techniques.**  |\n\n### Which ones to use?\n\nThe choice depends on the problem.\n\nIn our case, we are dealing with fine-grained birds identification. Colours are critical for species differentiation, so we don't want to mess with that. So playing with hue or solarization would be a bad idea as it might invalidate the labels (making one species actually look like another). Vertical flips or 90° rotations would not be great either as they wouldn't produce realistic data...\n\nThe most important techniques in this case are geometric augmentation ones such as random crops, horizontal flips, and slight rotations.\n\nWe can also do some photometric augmentation as long as they don't invalidate the labels: brightness and contrast. If we want the model to be able to identify black and white pictures, we definitely need to remove the colour dependence by using a technique turning images to gray (with some probability and level of colour removal). If, on the other hand, we are only interested in having a model able to identify colour images, we want to stay away from this.\n\n:::{.notenoline}\n\nExample for gamma:\n\nLet's consider for instance random gamma adjustments ➔ simulates different exposure levels ➔ improve the model's robustness and performance by making it less sensitive to variations in lighting conditions.\n\nBenefits: By training on images with diverse gamma values, your model learns to classify objects regardless of the specific lighting in which the photo was taken, leading to a more generalized and resilient model.\n\n:::\n\n### How to combine them?\n\n\n\n### Choosing their parameters\n\nPicking the right bounds for each type of data augmentation involves balancing dataset diversity against image realism. If the range is too narrow, you don't get much benefit, if it's too wide, you might destroy critical features or create unrealistic images that confuse the model.\n\n#### Default range\n\nCheck the industry-standards (look at the literature, ask an LLM, etc.).\n\n:::{.notenoline}\n\nExample for gamma:\n\nFor most computer vision tasks (natural images, object detection, classification), the industry-standard starting point is 0.8 to 1.2.\n\nThis range simulates subtle lighting variations—like a cloud passing over the sun or a slight difference in camera exposure—without washing out the image or making it too dark to see details.\n\n:::\n\n#### Domain specific ranges\n\nYou might want to adjust the values based on your specific data type.\n\n:::{.notenoline}\n\nExample for gamma:\n\nYou can increase the range for OCR (document analysis) because scanned documents often have wildly varying contrast and because text usually remains legible even under extreme gamma.\n\n:::\n\n#### Visual sanity check\n\nNever set augmentation parameters blindly. Visualize some tests to ensure the data you are using to train is still reasonable (and to make sure that you aren't messing something up and getting totally absurd results!).\n\n#### Validation check\n\nadjust their probabilities or magnitudes based on validation performance.\n\nTrain a small version of your model (or for fewer epochs) and check whether the validation loss improves with data augmentation compared to no augmentation.\n\nLoad packages:\n\n::: {#78170460 .cell execution_count=3}\n``` {.python .cell-code}\nimport dm_pix as pix\nimport PIL.Image as Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport jax.numpy as jnp\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-bright-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-bright-red-fg\">ModuleNotFoundError</span>                       Traceback (most recent call last)\n<span class=\"ansi-bright-cyan-fg\">Cell</span><span class=\"ansi-bright-cyan-fg\"> </span><span class=\"ansi-green-fg\">In[3]</span><span class=\"ansi-green-fg\">, line 1</span>\n<span class=\"ansi-bright-green-fg\">----&gt; </span><span class=\"ansi-bright-green-fg\">1</span> <span style=\"color:rgb(255,95,135)\">import</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">dm_pix</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(95,215,255)\">as</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">pix</span>\n<span class=\"ansi-bright-green-fg\">      2</span> <span style=\"color:rgb(255,95,135)\">import</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">PIL</span><span class=\"ansi-bright-white-fg\">.</span><span class=\"ansi-bright-white-fg\">Image</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(95,215,255)\">as</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">Image</span>\n<span class=\"ansi-bright-green-fg\">      3</span> <span style=\"color:rgb(255,95,135)\">import</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">numpy</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(95,215,255)\">as</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">np</span>\n\n<span class=\"ansi-bright-red-fg\">ModuleNotFoundError</span>: No module named 'dm_pix'</pre>\n```\n:::\n\n:::\n:::\n\n\n::: {#224f7e20 .cell execution_count=4}\n``` {.python .cell-code}\ndef apply_gamma(img, gamma):\n    \"\"\"xxx\"\"\"\n    new_img = pix.adjust_gamma(\n        image=img,\n        gamma=gamma\n    )\n    pil_img = Image.fromarray(\n        np.asarray(new_img * 255.).astype(np.uint8), 'RGB'\n    )\n    gamma = round(gamma, 1)\n    return pil_img, gamma\n```\n:::\n\n\n::: {#92de862f .cell execution_count=5}\n``` {.python .cell-code}\ndef show_tests(img, gamma_range):\n    jnp_img = jnp.array(img, dtype=jnp.float32) / 255.\n    pics = []\n    gammas = []\n\n    for i in gamma_range:\n        pics.append(apply_gamma(jnp_img, i)[0])\n        gammas.append(apply_gamma(jnp_img, i)[1])\n\n    fig, axes = plt.subplots(3, 4, figsize=(8, 6))\n    axes = axes.flatten()\n\n    for i, ax in enumerate(axes):\n        ax.imshow(pics[i])\n        ax.axis('off')\n        ax.set_title(f'Gamma = {gammas[i]}', fontsize=9)\n    plt.tight_layout()\n    plt.show()\n```\n:::\n\n\nNow we can apply it to a few images to get an idea of the effect and ensure nothing weird is going on. This will help us catch a coding mistake that could ruin the whole training process:\n\n::: {#5abf55d5 .cell execution_count=6}\n``` {.python .cell-code}\nshow_tests(nabirds_train[0]['image'], np.linspace(0.1, 3, 12))\nshow_tests(nabirds_train[1]['image'], np.linspace(0.1, 3, 12))\nshow_tests(nabirds_train[2]['image'], np.linspace(0.1, 3, 12))\nshow_tests(nabirds_train[3]['image'], np.linspace(0.1, 3, 12))\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-bright-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-bright-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-bright-cyan-fg\">Cell</span><span class=\"ansi-bright-cyan-fg\"> </span><span class=\"ansi-green-fg\">In[6]</span><span class=\"ansi-green-fg\">, line 1</span>\n<span class=\"ansi-bright-green-fg\">----&gt; </span><span class=\"ansi-bright-green-fg\">1</span> <span class=\"ansi-bright-white-fg\">show_tests</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">nabirds_train</span><span class=\"ansi-bright-white-fg\">[</span><span style=\"color:rgb(175,135,255)\">0</span><span class=\"ansi-bright-white-fg\">]</span><span class=\"ansi-bright-white-fg\">[</span><span style=\"color:rgb(215,215,135)\">'</span><span style=\"color:rgb(215,215,135)\">image</span><span style=\"color:rgb(215,215,135)\">'</span><span class=\"ansi-bright-white-fg\">]</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">np</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">linspace</span><span class=\"ansi-bright-white-fg\">(</span><span style=\"color:rgb(175,135,255)\">0.1</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(175,135,255)\">3</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(175,135,255)\">12</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">)</span>\n<span class=\"ansi-bright-green-fg\">      2</span> <span class=\"ansi-bright-white-fg\">show_tests</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">nabirds_train</span><span class=\"ansi-bright-white-fg\">[</span><span style=\"color:rgb(175,135,255)\">1</span><span class=\"ansi-bright-white-fg\">]</span><span class=\"ansi-bright-white-fg\">[</span><span style=\"color:rgb(215,215,135)\">'</span><span style=\"color:rgb(215,215,135)\">image</span><span style=\"color:rgb(215,215,135)\">'</span><span class=\"ansi-bright-white-fg\">]</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">np</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">linspace</span><span class=\"ansi-bright-white-fg\">(</span><span style=\"color:rgb(175,135,255)\">0.1</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(175,135,255)\">3</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(175,135,255)\">12</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">)</span>\n<span class=\"ansi-bright-green-fg\">      3</span> <span class=\"ansi-bright-white-fg\">show_tests</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">nabirds_train</span><span class=\"ansi-bright-white-fg\">[</span><span style=\"color:rgb(175,135,255)\">2</span><span class=\"ansi-bright-white-fg\">]</span><span class=\"ansi-bright-white-fg\">[</span><span style=\"color:rgb(215,215,135)\">'</span><span style=\"color:rgb(215,215,135)\">image</span><span style=\"color:rgb(215,215,135)\">'</span><span class=\"ansi-bright-white-fg\">]</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">np</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">linspace</span><span class=\"ansi-bright-white-fg\">(</span><span style=\"color:rgb(175,135,255)\">0.1</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(175,135,255)\">3</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(175,135,255)\">12</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">)</span>\n\n<span class=\"ansi-bright-red-fg\">NameError</span>: name 'nabirds_train' is not defined</pre>\n```\n:::\n\n:::\n:::\n\n\nLet's use [random gamma](https://dm-pix.readthedocs.io/en/latest/api.html#random-gamma) with the min and max values at 0.6 and 1.3 respectively.\n\n\n<!-- ```{python} -->\n<!-- from jax import random -->\n\n\n<!-- ``` -->\n\n",
    "supporting": [
      "jxai_augmentation_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}