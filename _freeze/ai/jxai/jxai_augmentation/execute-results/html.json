{
  "hash": "baa9e03a924571a5029cf937b641c889",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Data augmentation\nauthor: Marie-Hélène Burle\n---\n\n:::{.def}\n\n\n\n:::\n\n:::{.callout-note collapse=\"true\"}\n\n## Minimal necessary code from previous sections\n\n```{.python}\nbase_dir = \"<path-of-the-nabirds-dir>\"\n```\n\n:::{.note}\n\nTo be replaced by proper path.\n\n:::\n\n\n\n::: {#557d9acb .cell execution_count=2}\n``` {.python .cell-code}\nimport os\nimport polars as pl\nimport imageio.v3 as iio\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom skimage.transform import resize\nimport numpy as np\nimport grain.python as grain\nimport jax.numpy as jnp\n\nimg_dir = os.path.join(base_dir, \"images\")\n\nbb_file = os.path.join(base_dir, \"bounding_boxes.txt\")\nclasses_translation_file = os.path.join(base_dir, \"classes_fixed.txt\")\nclass_labels_file = os.path.join(base_dir, \"image_class_labels.txt\")\nimg_file = os.path.join(base_dir, \"images.txt\")\nphotographers_file = os.path.join(base_dir, \"photographers_fixed.txt\")\nsizes_file = os.path.join(base_dir, \"sizes.txt\")\ntrain_test_split_file = os.path.join(base_dir, \"train_test_split.txt\")\n\nbb = pl.read_csv(\n    bb_file,\n    separator=\" \",\n    has_header=False,\n    new_columns=[\"UUID\", \"bb_x\", \"bb_y\", \"bb_width\", \"bb_height\"]\n)\n\nclasses = pl.read_csv(\n    class_labels_file,\n    separator=\" \",\n    has_header=False,\n    new_columns=[\"UUID\", \"class\"]\n)\n\nclasses_translation = pl.read_csv(\n    classes_translation_file,\n    separator=\" \",\n    has_header=False,\n    new_columns=[\"class\", \"id\"]\n)\n\nimg_paths = pl.read_csv(\n    img_file,\n    separator=\" \",\n    has_header=False,\n    new_columns=[\"UUID\", \"path\"]\n)\n\nphotographers = pl.read_csv(\n    photographers_file,\n    separator=\" \",\n    has_header=False,\n    new_columns=[\"UUID\", \"photographer\"]\n)\n\nsizes = pl.read_csv(\n    sizes_file,\n    separator=\" \",\n    has_header=False,\n    new_columns=[\"UUID\", \"img_width\", \"img_height\"]\n)\n\ntrain_test_split = pl.read_csv(\n    train_test_split_file,\n    separator=\" \",\n    has_header=False,\n    new_columns=[\"UUID\", \"is_training_img\"]\n)\n\nclasses_metadata = (\n    classes.join(classes_translation, on=\"class\")\n)\n\nmetadata = (\n    bb.join(classes_metadata, on=\"UUID\")\n    .join(img_paths, on=\"UUID\")\n    .join(photographers, on=\"UUID\")\n    .join(sizes, on=\"UUID\")\n    .join(train_test_split, on=\"UUID\")\n)\n\nmetadata_train = metadata.filter(pl.col(\"is_training_img\") == 1)\n\nclass NABirdsDataset:\n    \"\"\"NABirds dataset class.\"\"\"\n    def __init__(self, metadata_file, data_dir):\n        self.metadata = metadata_file\n        self.data_dir = data_dir\n    def __len__(self):\n        return len(self.metadata)\n    def __getitem__(self, idx):\n        img_path = os.path.join(\n            self.data_dir,\n            self.metadata.get_column('path')[idx]\n        )\n        img = iio.imread(img_path)\n        img_id = self.metadata.get_column('id')[idx].replace('_', ' ')\n        img_photographer = self.metadata.get_column('photographer')[idx].replace('_', ' ')\n        img_bb_x = self.metadata.get_column('bb_x')[idx]\n        img_bb_y = self.metadata.get_column('bb_y')[idx]\n        img_bb_width = self.metadata.get_column('bb_width')[idx]\n        img_bb_height = self.metadata.get_column('bb_height')[idx]\n        sample = {\n            'image': img,\n            'id': img_id,\n            'photographer': img_photographer,\n            'bbx' : img_bb_x,\n            'bby' : img_bb_y,\n            'bbwidth' : img_bb_width,\n            'bbheight' : img_bb_height\n        }\n        return sample\n\nnabirds_train = NABirdsDataset(\n    metadata_train,\n    img_dir\n)\n\nclass NormAndCast(grain.MapTransform):\n    \"\"\"Transform class to normalize and cast images to float32.\"\"\"\n    def map(self, element):\n        element['image'] = jnp.array(element['image'], dtype=jnp.float32) / 255.0\n        return element\n\nclass BbCrop(grain.MapTransform):\n    \"\"\"Transform class to crop images to their bounding boxes.\"\"\"\n    def map(self, element):\n        img = element['image']\n        bbx = element['bbx']\n        bby = element['bby']\n        bbwidth = element['bbwidth']\n        bbheight = element['bbheight']\n        img_cropped = img[bby:bby+bbheight, bbx:bbx+bbwidth]\n        element['image'] = img_cropped\n        return element\n\ntarget = (224, 224)\n\nclass PaddingResize(grain.MapTransform):\n    \"\"\"Transform class to resize images to a given size with padding to avoid distortion.\"\"\"\n    def map(self, element):\n        img = element['image']\n        h, w, _ = img.shape\n        target_h, target_w = target\n\n        # Calculate the scaling factor to fit the image inside the box\n        scale = min(target_h / h, target_w / w)\n\n        # Calculate the new dimensions of the image\n        new_h = int(h * scale)\n        new_w = int(w * scale)\n\n        # Resize the image to these new dimensions\n        img_resized = resize(img, (new_h, new_w), anti_aliasing=True)\n\n        # Create a black canvas (zeros) of the target size\n        out_img = np.zeros((target_h, target_w, img.shape[2]), dtype=img_resized.dtype)\n\n        # Place the resized image in the center of the canvas\n        y_offset = (target_h - new_h) // 2\n        x_offset = (target_w - new_w) // 2\n        out_img[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = img_resized\n\n        element['image'] = out_img\n        return element\n\ntransformations = [NormAndCast(), BbCrop(), PaddingResize()]\n```\n:::\n\n\n:::\n\n## What is data augmentation?\n\nThe [AlbumentationsX](https://github.com/albumentations-team/AlbumentationsX) site has a [good explanation of the concept of data augmentation](https://albumentations.ai/docs/1-introduction/what-are-image-augmentations/).\n\ncite (from bib tex file):\n- https://arxiv.org/abs/2205.01491\n\n\n## Tools\n\n[PIX](https://github.com/google-deepmind/dm_pixk)\n\n\ncite (from bib tex file):\n- paper on libraries\n\n\n\n[TorchVision transforms](https://docs.pytorch.org/vision/0.8/transforms.html)\n\n[skimage.transform](https://scikit-image.org/docs/0.25.x/api/skimage.transform.html) from [scikit-image](https://github.com/scikit-image/scikit-image) (that we used previously to create a Transform that resizes our images with padding).\n\n## Augmentation techniques\n\n[PIX](https://github.com/google-deepmind/dm_pix) [list of augmentations](https://dm-pix.readthedocs.io/en/latest/api.html#)\n\n::: {#c86a3801 .cell execution_count=3}\n``` {.python .cell-code}\nimport dm_pix as pix\nfrom jax import random\n\n# class Augment(grain.MapTransform):\n#     \"\"\"Transform class to normalize and cast images to float32.\"\"\"\n#     def map(self, element):\n#         img = element['image']\n#         key = random.PRNGKey(0)\n#         delta = 0.7\n#         img_brightness = pix.random_brightness(\n#             key=key,\n#             image=img,\n#             max_delta=delta\n#         )\n#         key = random.PRNGKey(1)\n#         img_flip = pix.random_flip_left_right(\n#             key=key,\n#             image=img_brightness\n#         )\n#         element['image'] = img_flip\n#         return element\n\nclass RandomFlip(grain.MapTransform):\n    \"\"\"Transform class to normalize and cast images to float32.\"\"\"\n    def map(self, element):\n        img = element['image']\n        key = random.PRNGKey(0)\n        img_flip = pix.random_flip_left_right(\n            key=key,\n            image=img\n        )\n        element['image'] = img_flip\n        return element\n```\n:::\n\n\n::: {#10c817a5 .cell execution_count=4}\n``` {.python .cell-code}\ntransformations = [NormAndCast(), BbCrop(), PaddingResize(), RandomFlip()]\n```\n:::\n\n\n::: {#463e2ccb .cell execution_count=5}\n``` {.python .cell-code}\nnabirds_train_seqsampler = grain.SequentialSampler(\n    num_records=4,\n    shard_options=grain.NoSharding()\n)\n```\n:::\n\n\n::: {#4589d154 .cell execution_count=6}\n``` {.python .cell-code}\nnabirds_train_dl = grain.DataLoader(\n    data_source=nabirds_train,\n    operations=transformations,\n    sampler=nabirds_train_seqsampler,\n    worker_count=0\n)\n```\n:::\n\n\n::: {#75982a4c .cell execution_count=7}\n``` {.python .cell-code}\nfig = plt.figure(figsize=(8, 8))\n\nfor i, element in enumerate(nabirds_train_dl):\n    ax = plt.subplot(2, 2, i + 1)\n    plt.tight_layout()\n    ax.set_title(\n        f'Element {i}\\nIdentification: {element['id']}\\nPicture by {element['photographer']}',\n        fontsize=9\n    )\n    ax.axis('off')\n    plt.imshow(element['image'])\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](jxai_augmentation_files/figure-html/cell-8-output-1.png){width=745 height=733}\n:::\n:::\n\n\n::: {#f03c6d69 .cell execution_count=8}\n``` {.python .cell-code}\nnabirds_train_isampler = grain.IndexSampler(\n  num_records=200,\n  num_epochs=1,\n  # shard_options=grain.sharding.ShardOptions(shard_index=0, shard_count=1, drop_remainder=True),\n  shard_options=grain.ShardOptions(shard_index=0, shard_count=1, drop_remainder=True),\n  shuffle=True,\n  seed=0)\n\nnabirds_train_dl = grain.DataLoader(\n    data_source=nabirds_train,\n    operations=transformations,\n    sampler=nabirds_train_isampler,\n    worker_count=0\n)\n\nfig = plt.figure(figsize=(8, 8))\n\nfor i, element in enumerate(nabirds_train_dl):\n    ax = plt.subplot(2, 2, i + 1)\n    plt.tight_layout()\n    ax.set_title(\n        f'Element {i}\\nIdentification: {element['id']}\\nPicture by {element['photographer']}',\n        fontsize=9\n    )\n    ax.axis('off')\n    plt.imshow(element['image'])\n    if i == 3:\n        plt.show()\n        break\n```\n\n::: {.cell-output .cell-output-display}\n![](jxai_augmentation_files/figure-html/cell-9-output-1.png){width=705 height=733}\n:::\n:::\n\n\n## \n\n",
    "supporting": [
      "jxai_augmentation_files"
    ],
    "filters": [],
    "includes": {}
  }
}