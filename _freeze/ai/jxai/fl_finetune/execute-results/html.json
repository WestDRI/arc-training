{
  "hash": "4479903b55d3ab898c1b676772a57345",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Fine-tuning the model\naliases:\n  - /ai/jx/fl_training\nbibliography: fl.bib\ncsl: diabetologia.csl\nauthor:\n  - Marie-Hélène Burle\n  - Code adapted from JAX's [Implement ViT from scratch](https://docs.jaxstack.ai/en/latest/JAX_Vision_transformer.html)\n---\n\n:::{.def}\n\nIn this section, we fine-tune our model with our sample (5 classes) of the [Food-101 dataset](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/) [@bossard14].\n\n:::\n\n## Context\n\n```{dot}\n//| echo: false\n//| fig-width: 700px\n\ndigraph {\n\nbgcolor=\"transparent\"\nnode [fontname=\"Inconsolata, sans-serif\", color=gray55, fontsize=\"18pt\"]\nedge [color=gray55]\n\nload [label=\"Load data\", shape=plaintext, group=g1, fontcolor=gray55]\nproc [label=\"Process data\", shape=plaintext, group=g1, fontcolor=gray55]\nnn [label=\"Define architecture\", shape=plaintext, group=g1, fontcolor=gray55]\npretr [label=\"Pre-trained model\", shape=plaintext, group=g1, fontcolor=gray55]\nopt [label=\"Hyperparameters\", shape=plaintext, group=g1, fontcolor=gray55]\ntrain [label=\"Train\", shape=plaintext, group=g1]\ncp [label=\"Checkpoint\", shape=plaintext, group=g1, fontcolor=gray55]\n\npt [label=torchdata, fontcolor=gray55, color=gray55]\ntfds [label=tfds, group=g2, fontcolor=gray55, color=gray55]\ndt [label=datasets, fontcolor=gray55, color=gray55]\n\ngr [label=grain, fontcolor=gray55, color=gray55]\ntv [label=torchvision, fontcolor=gray55, color=gray55]\n\ntr [label=transformers, fontcolor=gray55, color=gray55]\n\nfl1 [label=flax, group=g2, fontcolor=gray55, color=gray55]\nfl2 [label=flax, group=g2, fontcolor=\"#00695C\", color=\"#00695C\"]\n\noa [label=optax, group=g2, fontcolor=gray55, color=gray55]\n\njx [label=\"JAX\", fontcolor=\"#9D22B2\", color=\"#9D22B2\"]\n\nob [label=orbax, group=g2, fontcolor=gray55, color=gray55]\n\n{rank=same; gr load tv tr}\ngr -> load -> tv -> tr [style=invis]\n\n{rank=same; fl1 proc pretr}\nfl1 -> proc -> pretr [style=invis]\n\n{rank=same; jx fl2 opt}\nfl1 -> proc -> pretr [style=invis]\n\n{pt tfds dt} -> load [color=gray55]\n{gr tv} -> proc [color=gray55]\nfl1 -> nn [color=gray55]\npretr -> nn [dir=none]\ntr -> pretr [color=gray55]\noa -> opt [color=gray55]\njx -> fl2 [color=\"#9D22B2\"]\nfl2 -> train [color=\"#00695C\"]\nob -> cp [color=gray55]\n\nload -> proc -> nn -> opt -> train -> cp [dir=none]\n\n}\n```\n\n:::{.callout-note collapse=\"true\"}\n\n## Minimal necessary code from previous sections\n\n::: {#90f8f4f2 .cell execution_count=1}\n``` {.python .cell-code}\nfrom datasets import load_dataset\nimport numpy as np\nfrom torchvision.transforms import v2 as T\nimport grain.python as grain\nimport jax\nimport jax.numpy as jnp\nfrom flax import nnx\nfrom transformers import FlaxViTForImageClassification\nimport optax\n\ntrain_size = 5 * 750\nval_size = 5 * 250\n\ntrain_dataset = load_dataset(\"food101\",\n                             split=f\"train[:{train_size}]\")\n\nval_dataset = load_dataset(\"food101\",\n                           split=f\"validation[:{val_size}]\")\n\nlabels_mapping = {}\nindex = 0\nfor i in range(0, len(val_dataset), 250):\n    label = val_dataset[i][\"label\"]\n    if label not in labels_mapping:\n        labels_mapping[label] = index\n        index += 1\n\ninv_labels_mapping = {v: k for k, v in labels_mapping.items()}\n\nimg_size = 224\n\ndef to_np_array(pil_image):\n  return np.asarray(pil_image.convert(\"RGB\"))\n\ndef normalize(image):\n    mean = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n    std = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n    image = image.astype(np.float32) / 255.0\n    return (image - mean) / std\n\ntv_train_transforms = T.Compose([\n    T.RandomResizedCrop((img_size, img_size), scale=(0.7, 1.0)),\n    T.RandomHorizontalFlip(),\n    T.ColorJitter(0.2, 0.2, 0.2),\n    T.Lambda(to_np_array),\n    T.Lambda(normalize),\n])\n\ntv_test_transforms = T.Compose([\n    T.Resize((img_size, img_size)),\n    T.Lambda(to_np_array),\n    T.Lambda(normalize),\n])\n\ndef get_transform(fn):\n    def wrapper(batch):\n        batch[\"image\"] = [\n            fn(pil_image) for pil_image in batch[\"image\"]\n        ]\n        batch[\"label\"] = [\n            labels_mapping[label] for label in batch[\"label\"]\n        ]\n        return batch\n    return wrapper\n\ntrain_transforms = get_transform(tv_train_transforms)\nval_transforms = get_transform(tv_test_transforms)\n\ntrain_dataset = train_dataset.with_transform(train_transforms)\nval_dataset = val_dataset.with_transform(val_transforms)\n\nseed = 12\ntrain_batch_size = 32\nval_batch_size = 2 * train_batch_size\n\ntrain_sampler = grain.IndexSampler(\n    len(train_dataset),\n    shuffle=True,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1,\n)\n\nval_sampler = grain.IndexSampler(\n    len(val_dataset),\n    shuffle=False,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1,\n)\n\ntrain_loader = grain.DataLoader(\n    data_source=train_dataset,\n    sampler=train_sampler,\n    worker_count=4,\n    worker_buffer_size=2,\n    operations=[\n        grain.Batch(train_batch_size, drop_remainder=True),\n    ]\n)\n\nval_loader = grain.DataLoader(\n    data_source=val_dataset,\n    sampler=val_sampler,\n    worker_count=4,\n    worker_buffer_size=2,\n    operations=[\n        grain.Batch(val_batch_size),\n    ]\n)\n\nclass VisionTransformer(nnx.Module):\n    def __init__(\n        self,\n        num_classes: int = 1000,\n        in_channels: int = 3,\n        img_size: int = 224,\n        patch_size: int = 16,\n        num_layers: int = 12,\n        num_heads: int = 12,\n        mlp_dim: int = 3072,\n        hidden_size: int = 768,\n        dropout_rate: float = 0.1,\n        *,\n        rngs: nnx.Rngs = nnx.Rngs(0),\n    ):\n        # Patch and position embedding\n        n_patches = (img_size // patch_size) ** 2\n        self.patch_embeddings = nnx.Conv(\n            in_channels,\n            hidden_size,\n            kernel_size=(patch_size, patch_size),\n            strides=(patch_size, patch_size),\n            padding=\"VALID\",\n            use_bias=True,\n            rngs=rngs,\n        )\n\n        initializer = jax.nn.initializers.truncated_normal(stddev=0.02)\n        self.position_embeddings = nnx.Param(\n            initializer(\n                rngs.params(),\n                (1, n_patches + 1, hidden_size),\n                jnp.float32\n            )\n        )\n        self.dropout = nnx.Dropout(dropout_rate, rngs=rngs)\n\n        self.cls_token = nnx.Param(jnp.zeros((1, 1, hidden_size)))\n\n        # Transformer Encoder blocks\n        self.encoder = nnx.Sequential(*[\n            TransformerEncoder(\n                hidden_size,\n                mlp_dim,\n                num_heads,\n                dropout_rate,\n                rngs=rngs\n            )\n            for i in range(num_layers)\n        ])\n        self.final_norm = nnx.LayerNorm(hidden_size, rngs=rngs)\n\n        # Classification head\n        self.classifier = nnx.Linear(hidden_size, num_classes, rngs=rngs)\n\n    def __call__(self, x: jax.Array) -> jax.Array:\n        # Patch and position embedding\n        patches = self.patch_embeddings(x)\n        batch_size = patches.shape[0]\n        patches = patches.reshape(batch_size, -1, patches.shape[-1])\n\n        cls_token = jnp.tile(self.cls_token, [batch_size, 1, 1])\n        x = jnp.concat([cls_token, patches], axis=1)\n        embeddings = x + self.position_embeddings\n        embeddings = self.dropout(embeddings)\n\n        # Encoder blocks\n        x = self.encoder(embeddings)\n        x = self.final_norm(x)\n\n        # fetch the first token\n        x = x[:, 0]\n\n        # Classification\n        return self.classifier(x)\n\nclass TransformerEncoder(nnx.Module):\n    def __init__(\n        self,\n        hidden_size: int,\n        mlp_dim: int,\n        num_heads: int,\n        dropout_rate: float = 0.0,\n        *,\n        rngs: nnx.Rngs = nnx.Rngs(0),\n    ) -> None:\n\n        self.norm1 = nnx.LayerNorm(hidden_size, rngs=rngs)\n        self.attn = nnx.MultiHeadAttention(\n            num_heads=num_heads,\n            in_features=hidden_size,\n            dropout_rate=dropout_rate,\n            broadcast_dropout=False,\n            decode=False,\n            deterministic=False,\n            rngs=rngs,\n        )\n        self.norm2 = nnx.LayerNorm(hidden_size, rngs=rngs)\n\n        self.mlp = nnx.Sequential(\n            nnx.Linear(hidden_size, mlp_dim, rngs=rngs),\n            nnx.gelu,\n            nnx.Dropout(dropout_rate, rngs=rngs),\n            nnx.Linear(mlp_dim, hidden_size, rngs=rngs),\n            nnx.Dropout(dropout_rate, rngs=rngs),\n        )\n\n    def __call__(self, x: jax.Array) -> jax.Array:\n        x = x + self.attn(self.norm1(x))\n        x = x + self.mlp(self.norm2(x))\n        return x\n\nmodel = VisionTransformer(num_classes=1000)\n\ntf_model = FlaxViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n\ndef vit_inplace_copy_weights(*, src_model, dst_model):\n    assert isinstance(src_model, FlaxViTForImageClassification)\n    assert isinstance(dst_model, VisionTransformer)\n\n    tf_model_params = src_model.params\n    tf_model_params_fstate = nnx.traversals.flatten_mapping(tf_model_params)\n\n    flax_model_params = nnx.state(dst_model, nnx.Param)\n    flax_model_params_fstate = flax_model_params.flat_state()\n\n    params_name_mapping = {\n        (\"cls_token\",): (\"vit\", \"embeddings\", \"cls_token\"),\n        (\"position_embeddings\",): (\n            \"vit\",\n            \"embeddings\",\n            \"position_embeddings\"\n        ),\n        **{\n            (\"patch_embeddings\", x): (\n                \"vit\",\n                \"embeddings\",\n                \"patch_embeddings\",\n                \"projection\",\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n        },\n        **{\n            (\"encoder\", \"layers\", i, \"attn\", y, x): (\n                \"vit\",\n                \"encoder\",\n                \"layer\",\n                str(i),\n                \"attention\",\n                \"attention\",\n                y,\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n            for y in [\"key\", \"value\", \"query\"]\n            for i in range(12)\n        },\n        **{\n            (\"encoder\", \"layers\", i, \"attn\", \"out\", x): (\n                \"vit\",\n                \"encoder\",\n                \"layer\",\n                str(i),\n                \"attention\",\n                \"output\",\n                \"dense\",\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n            for i in range(12)\n        },\n        **{\n            (\"encoder\", \"layers\", i, \"mlp\", \"layers\", y1, x): (\n                \"vit\",\n                \"encoder\",\n                \"layer\",\n                str(i),\n                y2,\n                \"dense\",\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n            for y1, y2 in [(0, \"intermediate\"), (3, \"output\")]\n            for i in range(12)\n        },\n        **{\n            (\"encoder\", \"layers\", i, y1, x): (\n                \"vit\", \"encoder\", \"layer\", str(i), y2, x\n            )\n            for x in [\"scale\", \"bias\"]\n            for y1, y2 in [\n                    (\"norm1\", \"layernorm_before\"),\n                    (\"norm2\", \"layernorm_after\")\n            ]\n            for i in range(12)\n        },\n        **{\n            (\"final_norm\", x): (\"vit\", \"layernorm\", x)\n            for x in [\"scale\", \"bias\"]\n        },\n        **{\n            (\"classifier\", x): (\"classifier\", x)\n            for x in [\"kernel\", \"bias\"]\n        }\n    }\n\n    nonvisited = set(flax_model_params_fstate.keys())\n\n    for key1, key2 in params_name_mapping.items():\n        assert key1 in flax_model_params_fstate, key1\n        assert key2 in tf_model_params_fstate, (key1, key2)\n\n        nonvisited.remove(key1)\n\n        src_value = tf_model_params_fstate[key2]\n        if key2[-1] == \"kernel\" and key2[-2] in (\"key\", \"value\", \"query\"):\n            shape = src_value.shape\n            src_value = src_value.reshape((shape[0], 12, 64))\n\n        if key2[-1] == \"bias\" and key2[-2] in (\"key\", \"value\", \"query\"):\n            src_value = src_value.reshape((12, 64))\n\n        if key2[-4:] == (\"attention\", \"output\", \"dense\", \"kernel\"):\n            shape = src_value.shape\n            src_value = src_value.reshape((12, 64, shape[-1]))\n\n        dst_value = flax_model_params_fstate[key1]\n        assert src_value.shape == dst_value.value.shape, (\n            key2, src_value.shape, key1, dst_value.value.shape\n        )\n        dst_value.value = src_value.copy()\n        assert dst_value.value.mean() == src_value.mean(), (\n            dst_value.value, src_value.mean()\n        )\n\n    assert len(nonvisited) == 0, nonvisited\n\n    nnx.update(dst_model, nnx.State.from_flat_path(flax_model_params_fstate))\n\nvit_inplace_copy_weights(src_model=tf_model, dst_model=model)\n\nmodel.classifier = nnx.Linear(model.classifier.in_features, 5, rngs=nnx.Rngs(0))\n\nnum_epochs = 3\nlearning_rate = 0.001\nmomentum = 0.8\ntotal_steps = len(train_dataset) // train_batch_size\n\nlr_schedule = optax.linear_schedule(learning_rate, 0.0, num_epochs * total_steps)\n\noptimizer = nnx.Optimizer(model, optax.sgd(lr_schedule, momentum, nesterov=True))\n\ndef compute_losses_and_logits(model: nnx.Module, images: jax.Array, labels: jax.Array):\n    logits = model(images)\n\n    loss = optax.softmax_cross_entropy_with_integer_labels(\n        logits=logits, labels=labels\n    ).mean()\n    return loss, logits\n\n@nnx.jit\ndef train_step(\n    model: nnx.Module, optimizer: nnx.Optimizer, batch: dict[str, np.ndarray]\n):\n    # Convert np.ndarray to jax.Array on GPU\n    images = jnp.array(batch[\"image\"])\n    labels = jnp.array(batch[\"label\"], dtype=jnp.int32)\n\n    grad_fn = nnx.value_and_grad(compute_losses_and_logits, has_aux=True)\n    (loss, logits), grads = grad_fn(model, images, labels)\n\n    optimizer.update(grads)  # In-place updates.\n\n    return loss\n\n@nnx.jit\ndef eval_step(\n    model: nnx.Module, batch: dict[str, np.ndarray], eval_metrics: nnx.MultiMetric\n):\n    # Convert np.ndarray to jax.Array on GPU\n    images = jnp.array(batch[\"image\"])\n    labels = jnp.array(batch[\"label\"], dtype=jnp.int32)\n    loss, logits = compute_losses_and_logits(model, images, labels)\n\n    eval_metrics.update(\n        loss=loss,\n        logits=logits,\n        labels=labels,\n    )\n\neval_metrics = nnx.MultiMetric(\n    loss=nnx.metrics.Average('loss'),\n    accuracy=nnx.metrics.Accuracy(),\n)\n\ntrain_metrics_history = {\n    \"train_loss\": [],\n}\n\neval_metrics_history = {\n    \"val_loss\": [],\n    \"val_accuracy\": [],\n}\n```\n:::\n\n\n:::\n\n## Load packages\n\n::: {#88e7f32c .cell execution_count=2}\n``` {.python .cell-code}\n# to have a progress bar during training\nimport tqdm\n\n# to visualize evolution of loss and sample data\nimport matplotlib.pyplot as plt\n```\n:::\n\n\n## Training and evaluation functions\n\n::: {#28c07c7b .cell execution_count=3}\n``` {.python .cell-code}\nbar_format = \"{desc}[{n_fmt}/{total_fmt}]{postfix} [{elapsed}<{remaining}]\"\n\ndef train_one_epoch(epoch):\n    model.train()\n    with tqdm.tqdm(\n        desc=f\"[train] epoch: {epoch}/{num_epochs}, \",\n        total=total_steps,\n        bar_format=bar_format,\n        leave=True,\n    ) as pbar:\n        for batch in train_loader:\n            loss = train_step(model, optimizer, batch)\n            train_metrics_history[\"train_loss\"].append(loss.item())\n            pbar.set_postfix({\"loss\": loss.item()})\n            pbar.update(1)\n\ndef evaluate_model(epoch):\n    model.eval()\n\n    eval_metrics.reset()\n    for val_batch in val_loader:\n        eval_step(model, val_batch, eval_metrics)\n\n    for metric, value in eval_metrics.compute().items():\n        eval_metrics_history[f'val_{metric}'].append(value)\n\n    print(f\"[val] epoch: {epoch + 1}/{num_epochs}\")\n    print(f\"- total loss: {eval_metrics_history['val_loss'][-1]:0.4f}\")\n    print(f\"- Accuracy: {eval_metrics_history['val_accuracy'][-1]:0.4f}\")\n```\n:::\n\n\n## Train the model\n\n::: {#49560811 .cell execution_count=4}\n``` {.python .cell-code}\n%%time\n\nfor epoch in range(num_epochs):\n    train_one_epoch(epoch)\n    evaluate_model(epoch)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[train] epoch: 0/3, [0/117] [00:00<?]2025-04-17 00:58:36.743239: W external/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.cc:3021] Can't reduce memory use below 2.76GiB (2965721457 bytes) by rematerialization; only reduced to 6.53GiB (7015960796 bytes), down from 6.93GiB (7442595936 bytes) originally\n2025-04-17 00:58:54.600087: W external/xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.85GiB (rounded to 6279808768)requested by op \n2025-04-17 00:58:54.604063: W external/xla/xla/tsl/framework/bfc_allocator.cc:512] **************************************************************************************______________\nE0417 00:58:54.604605   15287 pjrt_stream_executor_client.cc:3045] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 6279808552 bytes. [tf-allocator-allocation-error='']\n\r[train] epoch: 0/3, [0/117] [00:35<?]\n```\n:::\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-bright-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-bright-red-fg\">XlaRuntimeError</span>                           Traceback (most recent call last)\n<span class=\"ansi-bright-cyan-fg\">File </span><span class=\"ansi-green-fg\">&lt;timed exec&gt;:2</span>\n\n<span class=\"ansi-bright-cyan-fg\">Cell</span><span class=\"ansi-bright-cyan-fg\"> </span><span class=\"ansi-green-fg\">In[13]</span><span class=\"ansi-green-fg\">, line 12</span>, in <span class=\"ansi-cyan-fg\">train_one_epoch</span><span class=\"ansi-bright-blue-fg\">(epoch)</span>\n<span class=\"ansi-bright-green-fg\">      5</span> <span style=\"color:rgb(95,215,255)\">with</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">tqdm</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">tqdm</span><span class=\"ansi-bright-white-fg\">(</span>\n<span class=\"ansi-bright-green-fg\">      6</span> <span class=\"ansi-bright-white-fg\">    </span><span class=\"ansi-bright-white-fg\">desc</span><span style=\"color:rgb(255,95,135)\">=</span><span style=\"color:rgb(215,215,135)\">f</span><span style=\"color:rgb(215,215,135)\">\"</span><span style=\"color:rgb(215,215,135)\">[train] epoch: </span><span style=\"color:rgb(215,215,135)\">{</span><span class=\"ansi-bright-white-fg\">epoch</span><span style=\"color:rgb(215,215,135)\">}</span><span style=\"color:rgb(215,215,135)\">/</span><span style=\"color:rgb(215,215,135)\">{</span><span class=\"ansi-bright-white-fg\">num_epochs</span><span style=\"color:rgb(215,215,135)\">}</span><span style=\"color:rgb(215,215,135)\">, </span><span style=\"color:rgb(215,215,135)\">\"</span><span class=\"ansi-bright-white-fg\">,</span>\n<span class=\"ansi-bright-green-fg\">      7</span> <span class=\"ansi-bright-white-fg\">    </span><span class=\"ansi-bright-white-fg\">total</span><span style=\"color:rgb(255,95,135)\">=</span><span class=\"ansi-bright-white-fg\">total_steps</span><span class=\"ansi-bright-white-fg\">,</span>\n<span class=\"ansi-bright-green-fg\">      8</span> <span class=\"ansi-bright-white-fg\">    </span><span class=\"ansi-bright-white-fg\">bar_format</span><span style=\"color:rgb(255,95,135)\">=</span><span class=\"ansi-bright-white-fg\">bar_format</span><span class=\"ansi-bright-white-fg\">,</span>\n<span class=\"ansi-bright-green-fg\">      9</span> <span class=\"ansi-bright-white-fg\">    </span><span class=\"ansi-bright-white-fg\">leave</span><span style=\"color:rgb(255,95,135)\">=</span><span style=\"color:rgb(95,215,255)\">True</span><span class=\"ansi-bright-white-fg\">,</span>\n<span class=\"ansi-bright-green-fg\">     10</span> <span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(95,215,255)\">as</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">pbar</span><span class=\"ansi-bright-white-fg\">:</span>\n<span class=\"ansi-bright-green-fg\">     11</span> <span class=\"ansi-bright-white-fg\">    </span><span style=\"color:rgb(95,215,255)\">for</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">batch</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">in</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">train_loader</span><span class=\"ansi-bright-white-fg\">:</span>\n<span class=\"ansi-bright-green-fg\">---&gt; </span><span class=\"ansi-bright-green-fg\">12</span> <span class=\"ansi-bright-white-fg\">        </span><span class=\"ansi-bright-white-fg\">loss</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">=</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">train_step</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">(</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">model</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">,</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\"> </span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">optimizer</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">,</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\"> </span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">batch</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">)</span>\n<span class=\"ansi-bright-green-fg\">     13</span> <span class=\"ansi-bright-white-fg\">        </span><span class=\"ansi-bright-white-fg\">train_metrics_history</span><span class=\"ansi-bright-white-fg\">[</span><span style=\"color:rgb(215,215,135)\">\"</span><span style=\"color:rgb(215,215,135)\">train_loss</span><span style=\"color:rgb(215,215,135)\">\"</span><span class=\"ansi-bright-white-fg\">]</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">append</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">loss</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">item</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">)</span>\n<span class=\"ansi-bright-green-fg\">     14</span> <span class=\"ansi-bright-white-fg\">        </span><span class=\"ansi-bright-white-fg\">pbar</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">set_postfix</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">{</span><span style=\"color:rgb(215,215,135)\">\"</span><span style=\"color:rgb(215,215,135)\">loss</span><span style=\"color:rgb(215,215,135)\">\"</span><span class=\"ansi-bright-white-fg\">:</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">loss</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">item</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">}</span><span class=\"ansi-bright-white-fg\">)</span>\n\n<span class=\"ansi-bright-cyan-fg\">File </span><span class=\"ansi-green-fg\">~/parvus/prog/mint/ai/jxai/.venv/lib/python3.12/site-packages/flax/nnx/graph.py:1081</span>, in <span class=\"ansi-cyan-fg\">UpdateContextManager.__call__.&lt;locals&gt;.update_context_manager_wrapper</span><span class=\"ansi-bright-blue-fg\">(*args, **kwargs)</span>\n<span class=\"ansi-bright-green-fg\">   1078</span> <span style=\"color:rgb(175,215,0)\">@functools</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">wraps</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">f</span><span class=\"ansi-bright-white-fg\">)</span>\n<span class=\"ansi-bright-green-fg\">   1079</span> <span style=\"color:rgb(95,215,255)\">def</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(175,215,0)\">update_context_manager_wrapper</span><span class=\"ansi-bright-white-fg\">(</span><span style=\"color:rgb(255,95,135)\">*</span><span class=\"ansi-bright-white-fg\">args</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">*</span><span style=\"color:rgb(255,95,135)\">*</span><span class=\"ansi-bright-white-fg\">kwargs</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">:</span>\n<span class=\"ansi-bright-green-fg\">   1080</span> <span class=\"ansi-bright-white-fg\">  </span><span style=\"color:rgb(95,215,255)\">with</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">self</span><span class=\"ansi-bright-white-fg\">:</span>\n<span class=\"ansi-bright-green-fg\">-&gt; </span><span class=\"ansi-bright-green-fg\">1081</span> <span class=\"ansi-bright-white-fg\">    </span><span style=\"color:rgb(95,215,255)\">return</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">f</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">(</span><span style=\"color:rgb(255,95,135)\" class=\"ansi-yellow-bg\">*</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">args</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">,</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\"> </span><span style=\"color:rgb(255,95,135)\" class=\"ansi-yellow-bg\">*</span><span style=\"color:rgb(255,95,135)\" class=\"ansi-yellow-bg\">*</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">kwargs</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">)</span>\n\n<span class=\"ansi-bright-cyan-fg\">File </span><span class=\"ansi-green-fg\">~/parvus/prog/mint/ai/jxai/.venv/lib/python3.12/site-packages/flax/nnx/transforms/compilation.py:345</span>, in <span class=\"ansi-cyan-fg\">jit.&lt;locals&gt;.jit_wrapper</span><span class=\"ansi-bright-blue-fg\">(*args, **kwargs)</span>\n<span class=\"ansi-bright-green-fg\">    335</span> <span style=\"color:rgb(175,215,0)\">@functools</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">wraps</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">fun</span><span class=\"ansi-bright-white-fg\">)</span>\n<span class=\"ansi-bright-green-fg\">    336</span> <span style=\"color:rgb(175,215,0)\">@graph</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">update_context</span><span class=\"ansi-bright-white-fg\">(</span><span style=\"color:rgb(215,215,135)\">'</span><span style=\"color:rgb(215,215,135)\">jit</span><span style=\"color:rgb(215,215,135)\">'</span><span class=\"ansi-bright-white-fg\">)</span>\n<span class=\"ansi-bright-green-fg\">    337</span> <span style=\"color:rgb(95,215,255)\">def</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(175,215,0)\">jit_wrapper</span><span class=\"ansi-bright-white-fg\">(</span><span style=\"color:rgb(255,95,135)\">*</span><span class=\"ansi-bright-white-fg\">args</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">*</span><span style=\"color:rgb(255,95,135)\">*</span><span class=\"ansi-bright-white-fg\">kwargs</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">:</span>\n<span class=\"ansi-bright-green-fg\">    338</span> <span class=\"ansi-bright-white-fg\">  </span><span class=\"ansi-bright-white-fg\">pure_args</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">pure_kwargs</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">=</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">extract</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">to_tree</span><span class=\"ansi-bright-white-fg\">(</span>\n<span class=\"ansi-bright-green-fg\">    339</span> <span class=\"ansi-bright-white-fg\">    </span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">args</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">kwargs</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">,</span>\n<span class=\"ansi-bright-green-fg\">    340</span> <span class=\"ansi-bright-white-fg\">    </span><span class=\"ansi-bright-white-fg\">prefix</span><span style=\"color:rgb(255,95,135)\">=</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">in_shardings</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">kwarg_shardings</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">,</span>\n<span class=\"ansi-bright-green-fg\">   (...)</span><span class=\"ansi-bright-green-fg\">    343</span> <span class=\"ansi-bright-white-fg\">    </span><span class=\"ansi-bright-white-fg\">ctxtag</span><span style=\"color:rgb(255,95,135)\">=</span><span style=\"color:rgb(215,215,135)\">'</span><span style=\"color:rgb(215,215,135)\">jit</span><span style=\"color:rgb(215,215,135)\">'</span><span class=\"ansi-bright-white-fg\">,</span>\n<span class=\"ansi-bright-green-fg\">    344</span> <span class=\"ansi-bright-white-fg\">  </span><span class=\"ansi-bright-white-fg\">)</span>\n<span class=\"ansi-bright-green-fg\">--&gt; </span><span class=\"ansi-bright-green-fg\">345</span> <span class=\"ansi-bright-white-fg\">  </span><span class=\"ansi-bright-white-fg\">pure_args_out</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">pure_kwargs_out</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">pure_out</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">=</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">jitted_fn</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">(</span>\n<span class=\"ansi-bright-green-fg\">    346</span> <span class=\"ansi-bright-white-fg ansi-yellow-bg\">    </span><span style=\"color:rgb(255,95,135)\" class=\"ansi-yellow-bg\">*</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">pure_args</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">,</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\"> </span><span style=\"color:rgb(255,95,135)\" class=\"ansi-yellow-bg\">*</span><span style=\"color:rgb(255,95,135)\" class=\"ansi-yellow-bg\">*</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">pure_kwargs</span>\n<span class=\"ansi-bright-green-fg\">    347</span> <span class=\"ansi-bright-white-fg ansi-yellow-bg\">  </span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">)</span>\n<span class=\"ansi-bright-green-fg\">    348</span> <span class=\"ansi-bright-white-fg\">  </span><span class=\"ansi-bright-white-fg\">_args_out</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">_kwargs_out</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">out</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">=</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">extract</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">from_tree</span><span class=\"ansi-bright-white-fg\">(</span>\n<span class=\"ansi-bright-green-fg\">    349</span> <span class=\"ansi-bright-white-fg\">    </span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">pure_args_out</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">pure_kwargs_out</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">pure_out</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">ctxtag</span><span style=\"color:rgb(255,95,135)\">=</span><span style=\"color:rgb(215,215,135)\">'</span><span style=\"color:rgb(215,215,135)\">jit</span><span style=\"color:rgb(215,215,135)\">'</span>\n<span class=\"ansi-bright-green-fg\">    350</span> <span class=\"ansi-bright-white-fg\">  </span><span class=\"ansi-bright-white-fg\">)</span>\n<span class=\"ansi-bright-green-fg\">    351</span> <span class=\"ansi-bright-white-fg\">  </span><span style=\"color:rgb(95,215,255)\">return</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">out</span>\n\n    <span class=\"ansi-bright-red-fg\">[... skipping hidden 5 frame]</span>\n\n<span class=\"ansi-bright-cyan-fg\">File </span><span class=\"ansi-green-fg\">~/parvus/prog/mint/ai/jxai/.venv/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:1298</span>, in <span class=\"ansi-cyan-fg\">ExecuteReplicated.__call__</span><span class=\"ansi-bright-blue-fg\">(self, *args)</span>\n<span class=\"ansi-bright-green-fg\">   1296</span> <span class=\"ansi-bright-white-fg\">  </span><span class=\"ansi-bright-white-fg\">self</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">_handle_token_bufs</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">result_token_bufs</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">sharded_runtime_token</span><span class=\"ansi-bright-white-fg\">)</span>\n<span class=\"ansi-bright-green-fg\">   1297</span> <span style=\"color:rgb(95,215,255)\">else</span><span class=\"ansi-bright-white-fg\">:</span>\n<span class=\"ansi-bright-green-fg\">-&gt; </span><span class=\"ansi-bright-green-fg\">1298</span> <span class=\"ansi-bright-white-fg\">  </span><span class=\"ansi-bright-white-fg\">results</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">=</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">self</span><span style=\"color:rgb(255,95,135)\" class=\"ansi-yellow-bg\">.</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">xla_executable</span><span style=\"color:rgb(255,95,135)\" class=\"ansi-yellow-bg\">.</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">execute_sharded</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">(</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">input_bufs</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">)</span>\n<span class=\"ansi-bright-green-fg\">   1300</span> <span style=\"color:rgb(95,215,255)\">if</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">dispatch</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">needs_check_special</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">:</span>\n<span class=\"ansi-bright-green-fg\">   1301</span> <span class=\"ansi-bright-white-fg\">  </span><span class=\"ansi-bright-white-fg\">out_arrays</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">=</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">results</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">disassemble_into_single_device_arrays</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">)</span>\n\n<span class=\"ansi-bright-red-fg\">XlaRuntimeError</span>: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 6279808552 bytes.</pre>\n```\n:::\n\n:::\n:::\n\n\n## OOM issues\n\n[Out of memory (OOM)](https://en.wikipedia.org/wiki/Out_of_memory) problems are common when trying to train a model with JAX. See for instance [this question on Stack Overflow](https://stackoverflow.com/q/74143812/9210961) and [this issue in the JAX repo](https://github.com/jax-ml/jax/issues/788).\n\nAccording to [the JAX documentation on memory allocation](https://docs.jax.dev/en/latest/gpu_memory_allocation.html), you can try the following:\n\n```{.python}\nimport os\nos.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\nos.environ['XLA_PYTHON_CLIENT_ALLOCATOR'] = 'platform'\nos.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '0.5'\n```\n\nor, if you use IPython (or Jupyter which runs IPython), you can use the equivalent syntax using the [IPython built-in magic command to set environment variables %env](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-env):\n\n```{.python}\n%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n%env XLA_PYTHON_CLIENT_ALLOCATOR=platform\n%env XLA_PYTHON_CLIENT_MEM_FRACTION=0.5\n```\n\nNone of these solutions worked for me on my machine (where I have one GPU) nor on the training cluster (where there is no GPU).\n\n## Metrics graphs\n\nIf we hadn't run out of memory, we could graph our metrics.\n\nEvolution of the loss during training:\n\n```{.python}\nplt.plot(train_metrics_history[\"train_loss\"], label=\"Loss value during the training\")\nplt.legend()\n```\n\nLoss and accuracy on the validation set:\n\n```{.python}\nfig, axs = plt.subplots(1, 2, figsize=(10, 10))\naxs[0].set_title(\"Loss value on validation set\")\naxs[0].plot(eval_metrics_history[\"val_loss\"])\naxs[1].set_title(\"Accuracy on validation set\")\naxs[1].plot(eval_metrics_history[\"val_accuracy\"])\n```\n\n## Check sample data\n\nLet's look at the model predictions for 5 items:\n\n::: {#e6c99e94 .cell execution_count=5}\n``` {.python .cell-code}\ntest_indices = [1, 250, 500, 750, 1000]\n\ntest_images = jnp.array([val_dataset[i][\"image\"] for i in test_indices])\nexpected_labels = [val_dataset[i][\"label\"] for i in test_indices]\n\nmodel.eval()\npreds = model(test_images)\n```\n:::\n\n\n::: {#8e7ce925 .cell execution_count=6}\n``` {.python .cell-code}\nnum_samples = len(test_indices)\nnames_map = train_dataset.features[\"label\"].names\n\nprobas = nnx.softmax(preds, axis=1)\npred_labels = probas.argmax(axis=1)\n\n\nfig, axs = plt.subplots(1, num_samples, figsize=(20, 10))\nfor i in range(num_samples):\n    img, expected_label = test_images[i], expected_labels[i]\n\n    pred_label = pred_labels[i].item()\n    proba = probas[i, pred_label].item()\n    if img.dtype in (np.float32, ):\n        img = ((img - img.min()) / (img.max() - img.min()) * 255.0).astype(np.uint8)\n\n    expected_label_str = names_map[inv_labels_mapping[expected_label]]\n    pred_label_str = names_map[inv_labels_mapping[pred_label]]\n    axs[i].set_title(f\"Expected: {expected_label_str} vs \\nPredicted: {pred_label_str}, P={proba:.2f}\")\n    axs[i].imshow(img)\n```\n\n::: {.cell-output .cell-output-display}\n![](fl_finetune_files/figure-html/cell-7-output-1.png){}\n:::\n:::\n\n\n",
    "supporting": [
      "fl_finetune_files"
    ],
    "filters": [],
    "includes": {}
  }
}