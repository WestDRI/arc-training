{
  "hash": "5563ce4abe4a6eee3656c132ba72ac08",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Fine-tuning the model\naliases:\n  - /ai/jx/fl_training\nbibliography: fl.bib\ncsl: diabetologia.csl\nauthor:\n  - Marie-Hélène Burle\n  - Code adapted from JAX's [Implement ViT from scratch](https://docs.jaxstack.ai/en/latest/JAX_Vision_transformer.html)\n---\n\n:::{.def}\n\nIn this section, we fine-tune our model with our sample (5 classes) of the [Food-101 dataset](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/) [@bossard14].\n\n:::\n\n## Context\n\n```{dot}\n//| echo: false\n//| fig-width: 700px\n\ndigraph {\n\nbgcolor=\"transparent\"\nnode [fontname=\"Inconsolata, sans-serif\", color=gray55, fontsize=\"18pt\"]\nedge [color=gray55]\n\nload [label=\"Load data\", shape=plaintext, group=g1, fontcolor=gray55]\nproc [label=\"Process data\", shape=plaintext, group=g1, fontcolor=gray55]\nnn [label=\"Define architecture\", shape=plaintext, group=g1, fontcolor=gray55]\npretr [label=\"Pre-trained model\", shape=plaintext, group=g1, fontcolor=gray55]\nopt [label=\"Hyperparameters\", shape=plaintext, group=g1, fontcolor=gray55]\ntrain [label=\"Train\", shape=plaintext, group=g1]\ncp [label=\"Checkpoint\", shape=plaintext, group=g1, fontcolor=gray55]\n\npt [label=torchdata, fontcolor=gray55, color=gray55]\ntfds [label=tfds, group=g2, fontcolor=gray55, color=gray55]\ndt [label=datasets, fontcolor=gray55, color=gray55]\n\ngr [label=grain, fontcolor=gray55, color=gray55]\ntv [label=torchvision, fontcolor=gray55, color=gray55]\n\ntr [label=transformers, fontcolor=gray55, color=gray55]\n\nfl1 [label=flax, group=g2, fontcolor=gray55, color=gray55]\nfl2 [label=flax, group=g2, fontcolor=\"#00695C\", color=\"#00695C\"]\n\noa [label=optax, group=g2, fontcolor=gray55, color=gray55]\n\njx [label=\"JAX\", fontcolor=\"#9D22B2\", color=\"#9D22B2\"]\n\nob [label=orbax, group=g2, fontcolor=gray55, color=gray55]\n\n{rank=same; gr load tv tr}\ngr -> load -> tv -> tr [style=invis]\n\n{rank=same; fl1 proc pretr}\nfl1 -> proc -> pretr [style=invis]\n\n{rank=same; jx fl2 opt}\nfl1 -> proc -> pretr [style=invis]\n\n{pt tfds dt} -> load [color=gray55]\n{gr tv} -> proc [color=gray55]\nfl1 -> nn [color=gray55]\npretr -> nn [dir=none]\ntr -> pretr [color=gray55]\noa -> opt [color=gray55]\njx -> fl2 [color=\"#9D22B2\"]\nfl2 -> train [color=\"#00695C\"]\nob -> cp [color=gray55]\n\nload -> proc -> nn -> opt -> train -> cp [dir=none]\n\n}\n```\n\n:::{.callout-note collapse=\"true\"}\n\n## Minimal necessary code from previous sections\n\n::: {#dd266c56 .cell execution_count=1}\n``` {.python .cell-code}\nfrom datasets import load_dataset\nimport numpy as np\nfrom torchvision.transforms import v2 as T\nimport grain.python as grain\nimport jax\nimport jax.numpy as jnp\nfrom flax import nnx\nfrom transformers import FlaxViTForImageClassification\nimport optax\n\ntrain_size = 5 * 750\nval_size = 5 * 250\n\ntrain_dataset = load_dataset(\"food101\",\n                             split=f\"train[:{train_size}]\")\n\nval_dataset = load_dataset(\"food101\",\n                           split=f\"validation[:{val_size}]\")\n\nlabels_mapping = {}\nindex = 0\nfor i in range(0, len(val_dataset), 250):\n    label = val_dataset[i][\"label\"]\n    if label not in labels_mapping:\n        labels_mapping[label] = index\n        index += 1\n\ninv_labels_mapping = {v: k for k, v in labels_mapping.items()}\n\nimg_size = 224\n\ndef to_np_array(pil_image):\n  return np.asarray(pil_image.convert(\"RGB\"))\n\ndef normalize(image):\n    mean = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n    std = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n    image = image.astype(np.float32) / 255.0\n    return (image - mean) / std\n\ntv_train_transforms = T.Compose([\n    T.RandomResizedCrop((img_size, img_size), scale=(0.7, 1.0)),\n    T.RandomHorizontalFlip(),\n    T.ColorJitter(0.2, 0.2, 0.2),\n    T.Lambda(to_np_array),\n    T.Lambda(normalize),\n])\n\ntv_test_transforms = T.Compose([\n    T.Resize((img_size, img_size)),\n    T.Lambda(to_np_array),\n    T.Lambda(normalize),\n])\n\ndef get_transform(fn):\n    def wrapper(batch):\n        batch[\"image\"] = [\n            fn(pil_image) for pil_image in batch[\"image\"]\n        ]\n        batch[\"label\"] = [\n            labels_mapping[label] for label in batch[\"label\"]\n        ]\n        return batch\n    return wrapper\n\ntrain_transforms = get_transform(tv_train_transforms)\nval_transforms = get_transform(tv_test_transforms)\n\ntrain_dataset = train_dataset.with_transform(train_transforms)\nval_dataset = val_dataset.with_transform(val_transforms)\n\nseed = 12\ntrain_batch_size = 32\nval_batch_size = 2 * train_batch_size\n\ntrain_sampler = grain.IndexSampler(\n    len(train_dataset),\n    shuffle=True,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1,\n)\n\nval_sampler = grain.IndexSampler(\n    len(val_dataset),\n    shuffle=False,\n    seed=seed,\n    shard_options=grain.NoSharding(),\n    num_epochs=1,\n)\n\ntrain_loader = grain.DataLoader(\n    data_source=train_dataset,\n    sampler=train_sampler,\n    worker_count=4,\n    worker_buffer_size=2,\n    operations=[\n        grain.Batch(train_batch_size, drop_remainder=True),\n    ]\n)\n\nval_loader = grain.DataLoader(\n    data_source=val_dataset,\n    sampler=val_sampler,\n    worker_count=4,\n    worker_buffer_size=2,\n    operations=[\n        grain.Batch(val_batch_size),\n    ]\n)\n\nclass VisionTransformer(nnx.Module):\n    def __init__(\n        self,\n        num_classes: int = 1000,\n        in_channels: int = 3,\n        img_size: int = 224,\n        patch_size: int = 16,\n        num_layers: int = 12,\n        num_heads: int = 12,\n        mlp_dim: int = 3072,\n        hidden_size: int = 768,\n        dropout_rate: float = 0.1,\n        *,\n        rngs: nnx.Rngs = nnx.Rngs(0),\n    ):\n        # Patch and position embedding\n        n_patches = (img_size // patch_size) ** 2\n        self.patch_embeddings = nnx.Conv(\n            in_channels,\n            hidden_size,\n            kernel_size=(patch_size, patch_size),\n            strides=(patch_size, patch_size),\n            padding=\"VALID\",\n            use_bias=True,\n            rngs=rngs,\n        )\n\n        initializer = jax.nn.initializers.truncated_normal(stddev=0.02)\n        self.position_embeddings = nnx.Param(\n            initializer(\n                rngs.params(),\n                (1, n_patches + 1, hidden_size),\n                jnp.float32\n            )\n        )\n        self.dropout = nnx.Dropout(dropout_rate, rngs=rngs)\n\n        self.cls_token = nnx.Param(jnp.zeros((1, 1, hidden_size)))\n\n        # Transformer Encoder blocks\n        self.encoder = nnx.Sequential(*[\n            TransformerEncoder(\n                hidden_size,\n                mlp_dim,\n                num_heads,\n                dropout_rate,\n                rngs=rngs\n            )\n            for i in range(num_layers)\n        ])\n        self.final_norm = nnx.LayerNorm(hidden_size, rngs=rngs)\n\n        # Classification head\n        self.classifier = nnx.Linear(hidden_size, num_classes, rngs=rngs)\n\n    def __call__(self, x: jax.Array) -> jax.Array:\n        # Patch and position embedding\n        patches = self.patch_embeddings(x)\n        batch_size = patches.shape[0]\n        patches = patches.reshape(batch_size, -1, patches.shape[-1])\n\n        cls_token = jnp.tile(self.cls_token, [batch_size, 1, 1])\n        x = jnp.concat([cls_token, patches], axis=1)\n        embeddings = x + self.position_embeddings\n        embeddings = self.dropout(embeddings)\n\n        # Encoder blocks\n        x = self.encoder(embeddings)\n        x = self.final_norm(x)\n\n        # fetch the first token\n        x = x[:, 0]\n\n        # Classification\n        return self.classifier(x)\n\nclass TransformerEncoder(nnx.Module):\n    def __init__(\n        self,\n        hidden_size: int,\n        mlp_dim: int,\n        num_heads: int,\n        dropout_rate: float = 0.0,\n        *,\n        rngs: nnx.Rngs = nnx.Rngs(0),\n    ) -> None:\n\n        self.norm1 = nnx.LayerNorm(hidden_size, rngs=rngs)\n        self.attn = nnx.MultiHeadAttention(\n            num_heads=num_heads,\n            in_features=hidden_size,\n            dropout_rate=dropout_rate,\n            broadcast_dropout=False,\n            decode=False,\n            deterministic=False,\n            rngs=rngs,\n        )\n        self.norm2 = nnx.LayerNorm(hidden_size, rngs=rngs)\n\n        self.mlp = nnx.Sequential(\n            nnx.Linear(hidden_size, mlp_dim, rngs=rngs),\n            nnx.gelu,\n            nnx.Dropout(dropout_rate, rngs=rngs),\n            nnx.Linear(mlp_dim, hidden_size, rngs=rngs),\n            nnx.Dropout(dropout_rate, rngs=rngs),\n        )\n\n    def __call__(self, x: jax.Array) -> jax.Array:\n        x = x + self.attn(self.norm1(x))\n        x = x + self.mlp(self.norm2(x))\n        return x\n\nmodel = VisionTransformer(num_classes=1000)\n\ntf_model = FlaxViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n\ndef vit_inplace_copy_weights(*, src_model, dst_model):\n    assert isinstance(src_model, FlaxViTForImageClassification)\n    assert isinstance(dst_model, VisionTransformer)\n\n    tf_model_params = src_model.params\n    tf_model_params_fstate = nnx.traversals.flatten_mapping(tf_model_params)\n\n    flax_model_params = nnx.state(dst_model, nnx.Param)\n    flax_model_params_fstate = flax_model_params.flat_state()\n\n    params_name_mapping = {\n        (\"cls_token\",): (\"vit\", \"embeddings\", \"cls_token\"),\n        (\"position_embeddings\",): (\n            \"vit\",\n            \"embeddings\",\n            \"position_embeddings\"\n        ),\n        **{\n            (\"patch_embeddings\", x): (\n                \"vit\",\n                \"embeddings\",\n                \"patch_embeddings\",\n                \"projection\",\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n        },\n        **{\n            (\"encoder\", \"layers\", i, \"attn\", y, x): (\n                \"vit\",\n                \"encoder\",\n                \"layer\",\n                str(i),\n                \"attention\",\n                \"attention\",\n                y,\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n            for y in [\"key\", \"value\", \"query\"]\n            for i in range(12)\n        },\n        **{\n            (\"encoder\", \"layers\", i, \"attn\", \"out\", x): (\n                \"vit\",\n                \"encoder\",\n                \"layer\",\n                str(i),\n                \"attention\",\n                \"output\",\n                \"dense\",\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n            for i in range(12)\n        },\n        **{\n            (\"encoder\", \"layers\", i, \"mlp\", \"layers\", y1, x): (\n                \"vit\",\n                \"encoder\",\n                \"layer\",\n                str(i),\n                y2,\n                \"dense\",\n                x\n            )\n            for x in [\"kernel\", \"bias\"]\n            for y1, y2 in [(0, \"intermediate\"), (3, \"output\")]\n            for i in range(12)\n        },\n        **{\n            (\"encoder\", \"layers\", i, y1, x): (\n                \"vit\", \"encoder\", \"layer\", str(i), y2, x\n            )\n            for x in [\"scale\", \"bias\"]\n            for y1, y2 in [\n                    (\"norm1\", \"layernorm_before\"),\n                    (\"norm2\", \"layernorm_after\")\n            ]\n            for i in range(12)\n        },\n        **{\n            (\"final_norm\", x): (\"vit\", \"layernorm\", x)\n            for x in [\"scale\", \"bias\"]\n        },\n        **{\n            (\"classifier\", x): (\"classifier\", x)\n            for x in [\"kernel\", \"bias\"]\n        }\n    }\n\n    nonvisited = set(flax_model_params_fstate.keys())\n\n    for key1, key2 in params_name_mapping.items():\n        assert key1 in flax_model_params_fstate, key1\n        assert key2 in tf_model_params_fstate, (key1, key2)\n\n        nonvisited.remove(key1)\n\n        src_value = tf_model_params_fstate[key2]\n        if key2[-1] == \"kernel\" and key2[-2] in (\"key\", \"value\", \"query\"):\n            shape = src_value.shape\n            src_value = src_value.reshape((shape[0], 12, 64))\n\n        if key2[-1] == \"bias\" and key2[-2] in (\"key\", \"value\", \"query\"):\n            src_value = src_value.reshape((12, 64))\n\n        if key2[-4:] == (\"attention\", \"output\", \"dense\", \"kernel\"):\n            shape = src_value.shape\n            src_value = src_value.reshape((12, 64, shape[-1]))\n\n        dst_value = flax_model_params_fstate[key1]\n        assert src_value.shape == dst_value.value.shape, (\n            key2, src_value.shape, key1, dst_value.value.shape\n        )\n        dst_value.value = src_value.copy()\n        assert dst_value.value.mean() == src_value.mean(), (\n            dst_value.value, src_value.mean()\n        )\n\n    assert len(nonvisited) == 0, nonvisited\n\n    nnx.update(dst_model, nnx.State.from_flat_path(flax_model_params_fstate))\n\nvit_inplace_copy_weights(src_model=tf_model, dst_model=model)\n\nmodel.classifier = nnx.Linear(model.classifier.in_features, 5, rngs=nnx.Rngs(0))\n\nnum_epochs = 3\nlearning_rate = 0.001\nmomentum = 0.8\ntotal_steps = len(train_dataset) // train_batch_size\n\nlr_schedule = optax.linear_schedule(learning_rate, 0.0, num_epochs * total_steps)\n\noptimizer = nnx.Optimizer(model, optax.sgd(lr_schedule, momentum, nesterov=True))\n\ndef compute_losses_and_logits(model: nnx.Module, images: jax.Array, labels: jax.Array):\n    logits = model(images)\n\n    loss = optax.softmax_cross_entropy_with_integer_labels(\n        logits=logits, labels=labels\n    ).mean()\n    return loss, logits\n\n@nnx.jit\ndef train_step(\n    model: nnx.Module, optimizer: nnx.Optimizer, batch: dict[str, np.ndarray]\n):\n    # Convert np.ndarray to jax.Array on GPU\n    images = jnp.array(batch[\"image\"])\n    labels = jnp.array(batch[\"label\"], dtype=jnp.int32)\n\n    grad_fn = nnx.value_and_grad(compute_losses_and_logits, has_aux=True)\n    (loss, logits), grads = grad_fn(model, images, labels)\n\n    optimizer.update(grads)  # In-place updates.\n\n    return loss\n\n@nnx.jit\ndef eval_step(\n    model: nnx.Module, batch: dict[str, np.ndarray], eval_metrics: nnx.MultiMetric\n):\n    # Convert np.ndarray to jax.Array on GPU\n    images = jnp.array(batch[\"image\"])\n    labels = jnp.array(batch[\"label\"], dtype=jnp.int32)\n    loss, logits = compute_losses_and_logits(model, images, labels)\n\n    eval_metrics.update(\n        loss=loss,\n        logits=logits,\n        labels=labels,\n    )\n\neval_metrics = nnx.MultiMetric(\n    loss=nnx.metrics.Average('loss'),\n    accuracy=nnx.metrics.Accuracy(),\n)\n\ntrain_metrics_history = {\n    \"train_loss\": [],\n}\n\neval_metrics_history = {\n    \"val_loss\": [],\n    \"val_accuracy\": [],\n}\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-bright-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-bright-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansi-bright-cyan-fg\">Cell</span><span class=\"ansi-bright-cyan-fg\"> </span><span class=\"ansi-green-fg\">In[1]</span><span class=\"ansi-green-fg\">, line 352</span>\n<span class=\"ansi-bright-green-fg\">    348</span> <span class=\"ansi-bright-white-fg\">    </span><span style=\"color:rgb(95,215,255)\">assert</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">len</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">nonvisited</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">==</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(175,135,255)\">0</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">nonvisited</span>\n<span class=\"ansi-bright-green-fg\">    350</span> <span class=\"ansi-bright-white-fg\">    </span><span class=\"ansi-bright-white-fg\">nnx</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">update</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">dst_model</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">nnx</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">State</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">from_flat_path</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">flax_model_params_fstate</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">)</span>\n<span class=\"ansi-bright-green-fg\">--&gt; </span><span class=\"ansi-bright-green-fg\">352</span> <span class=\"ansi-bright-white-fg ansi-yellow-bg\">vit_inplace_copy_weights</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">(</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">src_model</span><span style=\"color:rgb(255,95,135)\" class=\"ansi-yellow-bg\">=</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">tf_model</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">,</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\"> </span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">dst_model</span><span style=\"color:rgb(255,95,135)\" class=\"ansi-yellow-bg\">=</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">model</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">)</span>\n<span class=\"ansi-bright-green-fg\">    354</span> <span class=\"ansi-bright-white-fg\">model</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">classifier</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">=</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">nnx</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">Linear</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">model</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">classifier</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">in_features</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(175,135,255)\">5</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">rngs</span><span style=\"color:rgb(255,95,135)\">=</span><span class=\"ansi-bright-white-fg\">nnx</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">Rngs</span><span class=\"ansi-bright-white-fg\">(</span><span style=\"color:rgb(175,135,255)\">0</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">)</span>\n<span class=\"ansi-bright-green-fg\">    356</span> <span class=\"ansi-bright-white-fg\">num_epochs</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">=</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(175,135,255)\">3</span>\n\n<span class=\"ansi-bright-cyan-fg\">Cell</span><span class=\"ansi-bright-cyan-fg\"> </span><span class=\"ansi-green-fg\">In[1]</span><span class=\"ansi-green-fg\">, line 319</span>, in <span class=\"ansi-cyan-fg\">vit_inplace_copy_weights</span><span class=\"ansi-bright-blue-fg\">(src_model, dst_model)</span>\n<span class=\"ansi-bright-green-fg\">    236</span> <span class=\"ansi-bright-white-fg\">flax_model_params_fstate</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">=</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">flax_model_params</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">flat_state</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">)</span>\n<span class=\"ansi-bright-green-fg\">    238</span> <span class=\"ansi-bright-white-fg\">params_name_mapping</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">=</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">{</span>\n<span class=\"ansi-bright-green-fg\">    239</span> <span class=\"ansi-bright-white-fg\">    </span><span class=\"ansi-bright-white-fg\">(</span><span style=\"color:rgb(215,215,135)\">\"</span><span style=\"color:rgb(215,215,135)\">cls_token</span><span style=\"color:rgb(215,215,135)\">\"</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">:</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">(</span><span style=\"color:rgb(215,215,135)\">\"</span><span style=\"color:rgb(215,215,135)\">vit</span><span style=\"color:rgb(215,215,135)\">\"</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(215,215,135)\">\"</span><span style=\"color:rgb(215,215,135)\">embeddings</span><span style=\"color:rgb(215,215,135)\">\"</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(215,215,135)\">\"</span><span style=\"color:rgb(215,215,135)\">cls_token</span><span style=\"color:rgb(215,215,135)\">\"</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">,</span>\n<span class=\"ansi-bright-green-fg\">    240</span> <span class=\"ansi-bright-white-fg\">    </span><span class=\"ansi-bright-white-fg\">(</span><span style=\"color:rgb(215,215,135)\">\"</span><span style=\"color:rgb(215,215,135)\">position_embeddings</span><span style=\"color:rgb(215,215,135)\">\"</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">:</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">(</span>\n<span class=\"ansi-bright-green-fg\">   (...)</span><span class=\"ansi-bright-green-fg\">    316</span> <span class=\"ansi-bright-white-fg\">    </span><span class=\"ansi-bright-white-fg\">}</span>\n<span class=\"ansi-bright-green-fg\">    317</span> <span class=\"ansi-bright-white-fg\">}</span>\n<span class=\"ansi-bright-green-fg\">--&gt; </span><span class=\"ansi-bright-green-fg\">319</span> <span class=\"ansi-bright-white-fg\">nonvisited</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">=</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">set</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">flax_model_params_fstate</span><span style=\"color:rgb(255,95,135)\" class=\"ansi-yellow-bg\">.</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">keys</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">)</span>\n<span class=\"ansi-bright-green-fg\">    321</span> <span style=\"color:rgb(95,215,255)\">for</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">key1</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">key2</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">in</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">params_name_mapping</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">items</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">:</span>\n<span class=\"ansi-bright-green-fg\">    322</span> <span class=\"ansi-bright-white-fg\">    </span><span style=\"color:rgb(95,215,255)\">assert</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">key1</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">in</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">flax_model_params_fstate</span><span class=\"ansi-bright-white-fg\">,</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">key1</span>\n\n<span class=\"ansi-bright-red-fg\">AttributeError</span>: 'FlatState' object has no attribute 'keys'</pre>\n```\n:::\n\n:::\n:::\n\n\n:::\n\n## Load packages\n\n::: {#b33a4b2a .cell execution_count=2}\n``` {.python .cell-code}\n# to have a progress bar during training\nimport tqdm\n\n# to visualize evolution of loss and sample data\nimport matplotlib.pyplot as plt\n```\n:::\n\n\n## Training and evaluation functions\n\n::: {#4b741bf2 .cell execution_count=3}\n``` {.python .cell-code}\nbar_format = \"{desc}[{n_fmt}/{total_fmt}]{postfix} [{elapsed}<{remaining}]\"\n\ndef train_one_epoch(epoch):\n    model.train()\n    with tqdm.tqdm(\n        desc=f\"[train] epoch: {epoch}/{num_epochs}, \",\n        total=total_steps,\n        bar_format=bar_format,\n        leave=True,\n    ) as pbar:\n        for batch in train_loader:\n            loss = train_step(model, optimizer, batch)\n            train_metrics_history[\"train_loss\"].append(loss.item())\n            pbar.set_postfix({\"loss\": loss.item()})\n            pbar.update(1)\n\ndef evaluate_model(epoch):\n    model.eval()\n\n    eval_metrics.reset()\n    for val_batch in val_loader:\n        eval_step(model, val_batch, eval_metrics)\n\n    for metric, value in eval_metrics.compute().items():\n        eval_metrics_history[f'val_{metric}'].append(value)\n\n    print(f\"[val] epoch: {epoch + 1}/{num_epochs}\")\n    print(f\"- total loss: {eval_metrics_history['val_loss'][-1]:0.4f}\")\n    print(f\"- Accuracy: {eval_metrics_history['val_accuracy'][-1]:0.4f}\")\n```\n:::\n\n\n## Train the model\n\n::: {#99e35099 .cell execution_count=4}\n``` {.python .cell-code}\n%%time\n\nfor epoch in range(num_epochs):\n    train_one_epoch(epoch)\n    evaluate_model(epoch)\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-bright-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-bright-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-bright-cyan-fg\">File </span><span class=\"ansi-green-fg\">&lt;timed exec&gt;:1</span>\n\n<span class=\"ansi-bright-red-fg\">NameError</span>: name 'num_epochs' is not defined</pre>\n```\n:::\n\n:::\n:::\n\n\n## OOM issues\n\nAs you can see, I ran out of memory when running this code on my machine.\n\n[Out of memory (OOM)](https://en.wikipedia.org/wiki/Out_of_memory) problems are common when trying to train a model with JAX on GPUs. See for instance [this question on Stack Overflow](https://stackoverflow.com/q/74143812/9210961) and [this issue in the JAX repo](https://github.com/jax-ml/jax/issues/788).\n\nAccording to [the JAX documentation on GPU memory allocation](https://docs.jax.dev/en/latest/gpu_memory_allocation.html), you can try the following:\n\n```{.python}\nimport os\nos.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\nos.environ['XLA_PYTHON_CLIENT_ALLOCATOR'] = 'platform'\nos.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '0.5'\n```\n\nor, if you use IPython (or Jupyter which runs IPython), you can use the equivalent syntax using the [IPython built-in magic command to set environment variables %env](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-env):\n\n```{.python}\n%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n%env XLA_PYTHON_CLIENT_ALLOCATOR=platform\n%env XLA_PYTHON_CLIENT_MEM_FRACTION=0.5\n```\n\nNone of these solutions worked for me neither on my machine nor on Cedar and I am starting to suspect that there is a problem with this particular version of `jaxlib`.\n\nWithout GPUs (so on our training cluster), training will be much longer, but you won't run into this problem.\n\n## Metrics graphs\n\nIf we hadn't run out of memory, we could graph our metrics.\n\nEvolution of the loss during training:\n\n```{.python}\nplt.plot(train_metrics_history[\"train_loss\"], label=\"Loss value during the training\")\nplt.legend()\n```\n\nLoss and accuracy on the validation set:\n\n```{.python}\nfig, axs = plt.subplots(1, 2, figsize=(10, 10))\naxs[0].set_title(\"Loss value on validation set\")\naxs[0].plot(eval_metrics_history[\"val_loss\"])\naxs[1].set_title(\"Accuracy on validation set\")\naxs[1].plot(eval_metrics_history[\"val_accuracy\"])\n```\n\n## Check sample data\n\nAnd we could look at the model predictions for 5 items:\n\n::: {#e6c5f886 .cell execution_count=5}\n``` {.python .cell-code}\ntest_indices = [1, 250, 500, 750, 1000]\n\ntest_images = jnp.array([val_dataset[i][\"image\"] for i in test_indices])\nexpected_labels = [val_dataset[i][\"label\"] for i in test_indices]\n\nmodel.eval()\npreds = model(test_images)\n```\n:::\n\n\n::: {#b77910eb .cell execution_count=6}\n``` {.python .cell-code}\nnum_samples = len(test_indices)\nnames_map = train_dataset.features[\"label\"].names\n\nprobas = nnx.softmax(preds, axis=1)\npred_labels = probas.argmax(axis=1)\n\n\nfig, axs = plt.subplots(1, num_samples, figsize=(20, 10))\nfor i in range(num_samples):\n    img, expected_label = test_images[i], expected_labels[i]\n\n    pred_label = pred_labels[i].item()\n    proba = probas[i, pred_label].item()\n    if img.dtype in (np.float32, ):\n        img = ((img - img.min()) / (img.max() - img.min()) * 255.0).astype(np.uint8)\n\n    expected_label_str = names_map[inv_labels_mapping[expected_label]]\n    pred_label_str = names_map[inv_labels_mapping[pred_label]]\n    axs[i].set_title(f\"Expected: {expected_label_str} vs \\nPredicted: {pred_label_str}, P={proba:.2f}\")\n    axs[i].imshow(img)\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-bright-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-bright-red-fg\">KeyError</span>                                  Traceback (most recent call last)\n<span class=\"ansi-bright-cyan-fg\">Cell</span><span class=\"ansi-bright-cyan-fg\"> </span><span class=\"ansi-green-fg\">In[6]</span><span class=\"ansi-green-fg\">, line 18</span>\n<span class=\"ansi-bright-green-fg\">     15</span> <span class=\"ansi-bright-white-fg\">    </span><span class=\"ansi-bright-white-fg\">img</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">=</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">img</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">-</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">img</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">min</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">/</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">img</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">max</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">-</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">img</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">min</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\">)</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">*</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(175,135,255)\">255.0</span><span class=\"ansi-bright-white-fg\">)</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">astype</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">np</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">uint8</span><span class=\"ansi-bright-white-fg\">)</span>\n<span class=\"ansi-bright-green-fg\">     17</span> <span class=\"ansi-bright-white-fg\">expected_label_str</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">=</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">names_map</span><span class=\"ansi-bright-white-fg\">[</span><span class=\"ansi-bright-white-fg\">inv_labels_mapping</span><span class=\"ansi-bright-white-fg\">[</span><span class=\"ansi-bright-white-fg\">expected_label</span><span class=\"ansi-bright-white-fg\">]</span><span class=\"ansi-bright-white-fg\">]</span>\n<span class=\"ansi-bright-green-fg\">---&gt; </span><span class=\"ansi-bright-green-fg\">18</span> <span class=\"ansi-bright-white-fg\">pred_label_str</span><span class=\"ansi-bright-white-fg\"> </span><span style=\"color:rgb(255,95,135)\">=</span><span class=\"ansi-bright-white-fg\"> </span><span class=\"ansi-bright-white-fg\">names_map</span><span class=\"ansi-bright-white-fg\">[</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">inv_labels_mapping</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">[</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">pred_label</span><span class=\"ansi-bright-white-fg ansi-yellow-bg\">]</span><span class=\"ansi-bright-white-fg\">]</span>\n<span class=\"ansi-bright-green-fg\">     19</span> <span class=\"ansi-bright-white-fg\">axs</span><span class=\"ansi-bright-white-fg\">[</span><span class=\"ansi-bright-white-fg\">i</span><span class=\"ansi-bright-white-fg\">]</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">set_title</span><span class=\"ansi-bright-white-fg\">(</span><span style=\"color:rgb(215,215,135)\">f</span><span style=\"color:rgb(215,215,135)\">\"</span><span style=\"color:rgb(215,215,135)\">Expected: </span><span style=\"color:rgb(215,215,135)\">{</span><span class=\"ansi-bright-white-fg\">expected_label_str</span><span style=\"color:rgb(215,215,135)\">}</span><span style=\"color:rgb(215,215,135)\"> vs </span><span style=\"color:rgb(175,135,255)\">\\n</span><span style=\"color:rgb(215,215,135)\">Predicted: </span><span style=\"color:rgb(215,215,135)\">{</span><span class=\"ansi-bright-white-fg\">pred_label_str</span><span style=\"color:rgb(215,215,135)\">}</span><span style=\"color:rgb(215,215,135)\">, P=</span><span style=\"color:rgb(215,215,135)\">{</span><span class=\"ansi-bright-white-fg\">proba</span><span style=\"color:rgb(215,215,135)\">:</span><span style=\"color:rgb(215,215,135)\">.2f</span><span style=\"color:rgb(215,215,135)\">}</span><span style=\"color:rgb(215,215,135)\">\"</span><span class=\"ansi-bright-white-fg\">)</span>\n<span class=\"ansi-bright-green-fg\">     20</span> <span class=\"ansi-bright-white-fg\">axs</span><span class=\"ansi-bright-white-fg\">[</span><span class=\"ansi-bright-white-fg\">i</span><span class=\"ansi-bright-white-fg\">]</span><span style=\"color:rgb(255,95,135)\">.</span><span class=\"ansi-bright-white-fg\">imshow</span><span class=\"ansi-bright-white-fg\">(</span><span class=\"ansi-bright-white-fg\">img</span><span class=\"ansi-bright-white-fg\">)</span>\n\n<span class=\"ansi-bright-red-fg\">KeyError</span>: 693</pre>\n```\n:::\n\n:::\n\n::: {.cell-output .cell-output-display}\n![](fl_finetune_files/figure-html/cell-7-output-2.png){}\n:::\n:::\n\n\n",
    "supporting": [
      "fl_finetune_files"
    ],
    "filters": [],
    "includes": {}
  }
}