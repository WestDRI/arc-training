{
  "hash": "dbce446a9e35ec4ffd9f5669fe16ddf5",
  "result": {
    "markdown": "---\ntitle: Automatic differentiation\nauthor: Marie-Hélène Burle\n---\n\n:::{.def}\n\nPyTorch has [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation) capabilities—meaning that it can track all the operations performed on tensors during the forward pass and compute all the gradients automatically for the backpropagation—thanks to its package [torch.autograd](https://pytorch.org/docs/stable/autograd.html).\n\nLet's have a look at this.\n\n:::\n\n## Some definitions\n\n**Derivative of a function:** \\\nRate of change of a function with a single variable w.r.t. its variable.\n\n**Partial derivative:** \\\nRate of change of a function with multiple variables w.r.t. one variable while other variables are considered as constants.\n\n**Gradient:** \\\nVector of partial derivatives of function with several variables.\n\n**Differentiation:** \\\nCalculation of the derivatives of a function.\n\n**Chain rule:** \\\nFormula to calculate the derivatives of composite functions.\n\n**Automatic differentiation:** \\\nAutomatic computation of partial derivatives by algorithms.\n\n## Backpropagation\n\nFirst, we need to talk about backpropagation: the backward pass following each forward pass and which adjusts the model's parameters to minimize the output of the loss function.\n\nThe last 2 videos of [3Blue1Brown](https://www.3blue1brown.com/) neural network series explains backpropagation and its manual calculation very well.\n\n### What is backpropagation? (14 min)\n\n\n{{< video https://www.youtube.com/embed/Ilg3gGewQ5U >}}\n\n\n\n:::{.note}\n\nThere is one minor terminological error in this video: they call the use of mini-batches *stochastic gradient descent*. In fact, this is called *mini-batch gradient descent*. Stochastic gradient descent uses a single example at each iteration.\n\n:::\n\n### How does backpropagation work? (10 min)\n\n\n{{< video https://www.youtube.com/embed/tIeHLnjs5U8 >}}\n\n\n\n## Automatic differentiation\n\nIf we had to do all this manually, it would be absolute hell. Thankfully, many tools—including PyTorch—can do this automatically.\n\n### Tracking computations\n\nFor the automation of the calculation of all those derivatives through chain rules, PyTorch needs to track computations during the forward pass.\n\nPyTorch does not however track all the computations on all the tensors (this would be extremely memory intensive!). To start tracking computations on a vector, set the `requires_grad` attribute to `True`:\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport torch\n\nx = torch.ones(2, 4, requires_grad=True)\nx\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\ntensor([[1., 1., 1., 1.],\n        [1., 1., 1., 1.]], requires_grad=True)\n```\n:::\n:::\n\n\n#### The `grad_fun` attribute\n\nWhenever a tensor is created by an operation involving a tracked tensor, it has a `grad_fun` attribute:\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ny = x + 1\ny\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\ntensor([[2., 2., 2., 2.],\n        [2., 2., 2., 2.]], grad_fn=<AddBackward0>)\n```\n:::\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ny.grad_fn\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n<AddBackward0 at 0x7f8571f4c5b0>\n```\n:::\n:::\n\n\n#### Judicious tracking\n\nYou don't want to track more than is necessary. There are multiple ways to avoid tracking what you don't want.\n\nYou can stop tracking computations on a tensor with the method `detach`:\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nx\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\ntensor([[1., 1., 1., 1.],\n        [1., 1., 1., 1.]], requires_grad=True)\n```\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nx.detach_()\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\ntensor([[1., 1., 1., 1.],\n        [1., 1., 1., 1.]])\n```\n:::\n:::\n\n\nYou can change its `requires_grad` flag:\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nx = torch.zeros(2, 3, requires_grad=True)\nx\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\ntensor([[0., 0., 0.],\n        [0., 0., 0.]], requires_grad=True)\n```\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nx.requires_grad_(False)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\ntensor([[0., 0., 0.],\n        [0., 0., 0.]])\n```\n:::\n:::\n\n\nAlternatively, you can wrap any code you don't want to track under `with torch.no_grad()`:\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nx = torch.ones(2, 4, requires_grad=True)\n\nwith torch.no_grad():\n    y = x + 1\n\ny\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\ntensor([[2., 2., 2., 2.],\n        [2., 2., 2., 2.]])\n```\n:::\n:::\n\n\n:::{.note}\n\nCompare this with what we just did above.\n\n:::\n\n### Calculating gradients\n\nLet's calculate gradients manually, then use autograd, in a very simple case: imagine that $x$, $y$, and $z$ are tensors containing the parameters of a model and that the error $e$ could be calculated with the equation:\n\n$$e=2x^4-y^3+3z^2$$\n\n#### Manual derivative calculation\n\nLet's see how we would do this manually.\n\nFirst, we need the model parameters tensors:\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nx = torch.tensor([1., 2.])\ny = torch.tensor([3., 4.])\nz = torch.tensor([5., 6.])\n```\n:::\n\n\nWe calculate $e$ following the above equation:\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\ne = 2*x**4 - y**3 + 3*z**2\n```\n:::\n\n\nThe gradients of the error $e$ w.r.t. the parameters $x$, $y$, and $z$ are:\n\n$$\\frac{de}{dx}=8x^3$$\n$$\\frac{de}{dy}=-3y^2$$\n$$\\frac{de}{dz}=6z$$\n\nWe can calculate them with:\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ngradient_x = 8*x**3\ngradient_x\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\ntensor([ 8., 64.])\n```\n:::\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\ngradient_y = -3*y**2\ngradient_y\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\ntensor([-27., -48.])\n```\n:::\n:::\n\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\ngradient_z = 6*z\ngradient_z\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\ntensor([30., 36.])\n```\n:::\n:::\n\n\n#### Automatic derivative calculation\n\nFor this method, we need to define our model parameters with `requires_grad` set to `True`:\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nx = torch.tensor([1., 2.], requires_grad=True)\ny = torch.tensor([3., 4.], requires_grad=True)\nz = torch.tensor([5., 6.], requires_grad=True)\n```\n:::\n\n\n $e$ is calculated in the same fashion (except that here, all the computations on $x$, $y$, and $z$ are tracked):\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\ne = 2*x**4 - y**3 + 3*z**2\n```\n:::\n\n\nThe backward propagation is done automatically with:\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\ne.backward(torch.tensor([1., 1.]))\n```\n:::\n\n\nAnd we have our 3 partial derivatives:\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nprint(x.grad)\nprint(y.grad)\nprint(z.grad)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntensor([ 8., 64.])\ntensor([-27., -48.])\ntensor([30., 36.])\n```\n:::\n:::\n\n\n#### Comparison\n\nThe result is the same, as can be tested with:\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\n8*x**3 == x.grad\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\ntensor([True, True])\n```\n:::\n:::\n\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\n-3*y**2 == y.grad\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\ntensor([True, True])\n```\n:::\n:::\n\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\n6*z == z.grad\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\ntensor([True, True])\n```\n:::\n:::\n\n\nOf course, calculating the gradients manually here was extremely easy, but imagine how tedious and lengthy it would be to write the chain rules to calculate the gradients of all the composite functions in a neural network manually...\n\n",
    "supporting": [
      "autograd_files"
    ],
    "filters": [],
    "includes": {}
  }
}