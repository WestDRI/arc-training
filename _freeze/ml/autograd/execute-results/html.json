{
  "hash": "4c1f448a7334074eb4276759ee432c79",
  "result": {
    "markdown": "---\ntitle: Automatic differentiation\nauthor: Marie-Hélène Burle\n---\n\n:::{.def}\n\nImagine how hard it would be to write the chain rules of neural networks (with so many derivatives!) in backpropagation manually.\n\nPyTorch has [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation) abilities—meaning that it can track all the operations conducted on tensors and do the backprop for you—thanks to its package `torch.autograd`.\n\nLet's have a first look at it.\n\n:::\n\n## Tracking computations\n\nPyTorch does not track all the computations on all the tensors (this would be extremely memory intensive!). To start tracking computations on a vector, set the `.requires_grad` attribute to `True`:\n\n```{.python}\nimport torch\n\nx = torch.rand(3, 7, requires_grad=True)\nprint(x)\n```\n\n### The `grad_fun` attribute\n\nWhenever a tensor is created by an operation involving a tracked tensor, it has a `grad_fun` attribute:\n\n```{.python}\nx = torch.ones(2, 4, requires_grad=True)\nprint(x)\ny = x + 1\nprint(y)\nprint(y.grad_fn)\n```\n\n### Judicious tracking\n\nYou don't want to track more than is necessary. There are multiple ways to avoid tracking what you don't want to.\n\nYou can simply stop tracking computations on a tensor with the method `detach`:\n\n```{.python}\nx = torch.rand(4, 3, requires_grad=True)\nprint(x)\nprint(x.detach_())\n```\n\nYou can change its `requires_grad` flag:\n\n```{.python}\nx = torch.rand(4, 3, requires_grad=True)\nprint(x)\nprint(x.requires_grad_(False))\n```\n\nAlternatively, you can wrap any code you don't want to track with `with torch.no_grad():`\n\n```{.python}\nwith torch.no_grad():\n    <some code>\n```\n\n## Calculating gradients\n\nAfter you have performed a number of operations on `x` and obtained a final object (let's call it `loss` since in the context of neural networks, the output of the loss function is the starting place of the backpropagation process), you can get the gradient of any object `y` with:\n\n```{.python}\nloss.backward()\nprint(y.grad)\n```\n\n## Example\n\nLet's go over a simple example:\n\n- let `real` be the tensor of some real values\n- let `predicted` be the tensor given by some model trying to predict these real values after an iteration\n\nWe will calculate the first derivative (first step of the backpropagation) manually and with the `torch.autograd` package to really understand what that package does.\n\nLet's fill `real` and `predicted` with random values since we don't have a real situation with a real network (but let's make sure to start recording the history of computations performed on `predicted`):\n\n```{.python}\nreal = torch.rand(3, 8)\nprint(real)\n\npredicted = torch.rand(3, 8, requires_grad=True)\nprint(predicted)\n```\n\nSeveral loss functions can be used in machine learning, let's use:\n\n$$\\text{loss}=\\sum_{}^{} (\\text{predicted} - \\text{real})^2$$\n\n```{.python}\nloss = (predicted - real).pow(2).sum()\n```\n\nNow, to train a model, after each forward-pass, we need to go through the backpropagation to adjust the weights and biases of the model. That means, we need to calculate all the derivatives, starting from the derivative of the predicted values up to the derivatives of the weights and biases.\n\nHere, we will only do the very first step: calculate the derivative of `predicted`.\n\n### Manual derivative calculation\n\nThe formula for this first derivative, with the loss function we used, is:\n\n$$\\text{gradient}_\\text{predicted}=2(\\text{predicted} - \\text{real})$$\n\nThere is no point in adding this operation to `predicted`'s computation history, so we will exclude it with `with torch.no_grad():`\n\n```{.python}\nwith torch.no_grad():\n    manual_gradient_predicted = 2.0 * (predicted - real)\n\nprint(manual_gradient_predicted)\n```\n\n### Automatic derivative calculation\n\nNow, with `torch.autograd`:\n\n```{.python}\nloss.backward()\n```\n\nSince we tracked computations on `predicted`, we can calculate its gradient with:\n\n```{.python}\nauto_gradient_predicted = predicted.grad\nprint(auto_gradient_predicted)\n```\n\n### Comparison\n\nThe result is the same, as can be tested with:\n\n```{.python}\nprint(manual_gradient_predicted.eq(auto_gradient_predicted).all())\n```\n\nThe calculation of this first derivative of backpropagation was simple enough. But to propagate all the derivatives calculations backward through the chain rule would quickly turn into a deep calculus problem.\n\nWith `torch.autograd`, calculating the gradients of all the other elements of the network is as simple as calling them with the attribute `grad` once the function `torch.Tensor.backward()` has been run.\n\n",
    "supporting": [
      "autograd_files"
    ],
    "filters": [],
    "includes": {}
  }
}