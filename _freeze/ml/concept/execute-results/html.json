{
  "hash": "c3a474f117ecd8b7a5860dfc6fe33c45",
  "result": {
    "markdown": "---\ntitle: Overarching concept of deep learning\nauthor: Marie-Hélène Burle\n---\n\n:::{.def}\n\nNeural networks learn by adjusting their parameters automatically in an iterative manner. This is derived from [Arthur Samuel](https://en.wikipedia.org/wiki/Arthur_Samuel)'s concept.\n\nIt is important to get a good understanding of this process, so let's go over it step by step.\n\n:::\n\n## Decide on an architecture\n\n![](img/diag_01.png){fig-alt=\"noshadow\"}\n\nThe architecture won't change during training. This is set. The type of architecture you choose (e.g. CNN, Transformer, etc.) depends on the type of data you have (e.g. vision, textual, etc.). The depth and breadth of your network depend on the amount of data and computing resource you have.\n\n## Set some initial parameters\n\n![](img/diag_02.png){fig-alt=\"noshadow\"}\n\nYou can initialize them randomly or get much better ones through transfer learning.\n\nWhile the parameters are also part of the model, those will change during training.\n\n## Get some labelled data\n\n![](img/diag_03.png){fig-alt=\"noshadow\"}\n\nWhen we say that we need a lot of data for machine learning, we mean \"lots of labelled data\" as this is what gets used for training models.\n\n## Make sure to keep some data for testing\n\n![](img/diag_04.png){fig-alt=\"noshadow\"}\n\nThose data won't be used for training the model. Often people keep around 20% of their data for testing.\n\n## Pass data and parameters through the architecture\n\n![](img/diag_05.png){fig-alt=\"noshadow\"}\n\nThe train data are the inputs and the process of calculating the outputs is the forward pass.\n\n## The outputs of the model are predictions\n\n![](img/diag_06.png){fig-alt=\"noshadow\"}\n\n## Compare those predictions to the train labels\n\n![](img/diag_07.png){fig-alt=\"noshadow\"}\n\nSince our data was labelled, we know what the true outputs are.\n\n## Calculate train loss\n\n![](img/diag_08.png){fig-alt=\"noshadow\"}\n\nThe deviation of our predictions from the true outputs gives us a measure of training loss.\n\n## Adjust parameters\n\n![](img/diag_09.png){fig-alt=\"noshadow\"}\n\nThe parameters get automatically adjusted to reduce the training loss through the mechanism of backpropagation.\n\nThis is the actual training part.\n\nThis process is repeated many times. Training models is pretty much a giant for loop.\n\n## From model to program\n\n![](img/diag_10.png){fig-alt=\"noshadow\"}\n\nRemember that the model architecture is fixed, but that the parameters change at each iteration of the training process.\n\nWhile the labelled data are key to training, what we are really interested in is the combination of architecture + final parameters.\n\n![](img/diag_11.png){fig-alt=\"noshadow\"}\n\nWhen the training is over, the parameters become fixed. Which means that our model now behaves like a classic program.\n\n![](img/diag_12.png){fig-alt=\"noshadow\"}\n\n## Evaluate the model\n\n![](img/diag_13.png){fig-alt=\"noshadow\"}\n\nWe can now use the testing set (which was never used to train the model) to evaluate our model: if we pass the test inputs through our program, we get some predictions that we can compare to the test labels (which are the true outputs).\n\nThis gives us the test loss: a measure of how well our model performs.\n\n## Use the model\n\n![](img/diag_14.png){fig-alt=\"noshadow\"}\n\nNow that we have a program, we can use it on unlabelled inputs to get what people ultimately want: unknown outputs. This is when we put our model to actual use to solve some problem.\n\n",
    "supporting": [
      "concept_files"
    ],
    "filters": [],
    "includes": {}
  }
}