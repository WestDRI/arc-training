{
  "hash": "4c655cb2fe69857cb582fdb8392cd68f",
  "result": {
    "markdown": "---\ntitle: JAX principles\nauthor: Marie-Hélène Burle\n---\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport jax.numpy as jnp\nfrom jax import grad, vmap, pmap, jit\n```\n\n::: {.cell-output .cell-output-error}\n```\nModuleNotFoundError: No module named 'jax.numpy'; 'jax' is not a package\n```\n:::\n:::\n\n\nComposable transformations:\n\n- `grad` transform: turn a loss function (e.g. `mse_loss`) and turn it into a function that computes the gradients\n- `jit` transform: just-in-time compilation\n- `vmap` transform: work in a **v**ectorized fashion across elements of a batch\n- `pmap` transform: work in **p**arallel across processing units\n\n\n\n\n```{dot}\n//| echo: false\n//| fig-height: 800px\n\nstrict digraph {\n\nbgcolor=\"transparent\"\nnode [fontname=\"Inconsolata, sans-serif\"]\nedge [color=deepskyblue3]\n\n\"tracer\\nvalues\" [shape=rectangle, color=deepskyblue3, fontcolor=deepskyblue3]\n\"jit\\ncompilation\" [shape=rectangle, color=deepskyblue3, fontcolor=deepskyblue3]\n\"Accelerated\\nLinear Algebra\\n(XLA)\" [shape=rectangle, color=deepskyblue3, fontcolor=deepskyblue3]\n\"transforms\" [shape=rectangle, color=deepskyblue3, fontcolor=deepskyblue3]\n\nCPU [shape=octagon, color=gray55, fontcolor=gray55]\nGPU [shape=octagon, color=gray55, fontcolor=gray55]\nTPU [shape=octagon, color=gray55, fontcolor=gray55]\n\n\"Python code\\nwith only pure\\nfunctions\" [color=burlywood3, fontcolor=burlywood3]\n\"Intermediate\\nRepresentation\\n(IR)\" [color=darkorange4, fontcolor=darkorange4]\n\"High Level\\nOptimized code\\n(HLO)\" [color=chocolate, fontcolor=chocolate]\n\n\"Python code\\nwith only pure\\nfunctions\" -> \"tracer\\nvalues\" [dir=none]\n\"tracer\\nvalues\" -> \"Intermediate\\nRepresentation\\n(IR)\"\n\"Intermediate\\nRepresentation\\n(IR)\" -> \"jit\\ncompilation\" [dir=none]\n\"jit\\ncompilation\" -> \"High Level\\nOptimized code\\n(HLO)\"\n\"High Level\\nOptimized code\\n(HLO)\" -> \"Accelerated\\nLinear Algebra\\n(XLA)\" [dir=none]\n\n\"Accelerated\\nLinear Algebra\\n(XLA)\" -> CPU [shape=doubleoctagon]\n\"Accelerated\\nLinear Algebra\\n(XLA)\" -> GPU\n\"Accelerated\\nLinear Algebra\\n(XLA)\" -> TPU\n\n\"Intermediate\\nRepresentation\\n(IR)\" -> \"transforms\" [dir=both, minlen=3]\n\n{rank=same; \"Intermediate\\nRepresentation\\n(IR)\" \"transforms\"}\n\n}\n```\n\n",
    "supporting": [
      "jx_principles_files"
    ],
    "filters": [],
    "includes": {}
  }
}