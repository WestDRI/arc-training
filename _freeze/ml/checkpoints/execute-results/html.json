{
  "hash": "a1304ab3cc842dd80ca062c1082f65dd",
  "result": {
    "markdown": "---\ntitle: Saving/loading models and checkpointing\nauthor: Marie-Hélène Burle\n---\n\n## Saving models\n\nYou can save a model by [serializing](https://en.wikipedia.org/wiki/Serialization) its internal state dictionary. The state dictionary is a Python dictionary that contains the parameters of your model.\n\n```{.python}\ntorch.save(model.state_dict(), \"model.pth\")\n```\n\n## Loading models\n\nTo recreate your model, you first need to recreate its structure:\n\n```{.python}\nmodel = Net()\n```\n\nThen you can load the state dictionary containing the parameters values into it:\n\n```{.python}\nmodel.load_state_dict(torch.load(\"model.pth\"))\n```\n\n## Create a checkpoint\n\n```{.python}\ntorch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': loss,\n            ...\n            }, PATH)\n```\n\n## Resume training from a checkpoint\n\n```{.python}\nmodel = TheModelClass(*args, **kwargs)\noptimizer = TheOptimizerClass(*args, **kwargs)\n\ncheckpoint = torch.load(PATH)\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\n\nmodel.train()\n```\n\n",
    "supporting": [
      "checkpoints_files"
    ],
    "filters": [],
    "includes": {}
  }
}