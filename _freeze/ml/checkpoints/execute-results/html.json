{
  "hash": "59cde42d0c51c96fa2d80f34a0b520d4",
  "result": {
    "markdown": "---\ntitle: Saving/loading models and checkpointing\nauthor: Marie-Hélène Burle\n---\n\n:::{.def}\n\nAfter you have trained your model, obviously you will want to save it to use it thereafter. You will then need to load it in any session in which you want to use it.\n\nIn addition to saving or loading a fully trained model, it is important to know how to create regular checkpoints: training ML models takes a long time and a cluster crash or countless other issues might interrupt the training process. You don't want to have to restart from scratch if that happens.\n\n:::\n\n## Saving/loading models\n\n### Saving models\n\nYou can save a model by [serializing](https://en.wikipedia.org/wiki/Serialization) its internal state dictionary. The state dictionary is a Python dictionary that contains the learnable parameters of your model (weights and biases).\n\n```{.python}\ntorch.save(model.state_dict(), \"model.pt\")\n```\n\n### Loading models\n\nTo recreate your model, you first need to recreate its structure:\n\n```{.python}\nmodel = TheModelClass(*args, **kwargs)\n```\n\nThen you can load the state dictionary containing the parameters values into it:\n\n```{.python}\nmodel.load_state_dict(torch.load(\"model.pt\"))\n```\n\nAssuming you want to use your model for inference, you also must run:\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nmodel.eval()\n```\n\n::: {.cell-output .cell-output-error}\n```\nNameError: name 'model' is not defined\n```\n:::\n:::\n\n\n:::{.note}\n\nIf instead you want to do more training on your model, you would of course run `model.train()` instead.\n\n:::\n\n## Checkpointing\n\n### Creating a checkpoint\n\n```{.python}\ntorch.save({\n    'epoch': epoch,\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'loss': loss,\n    ...\n}, \"model.pt\")\n```\n\n### Resuming training from a checkpoint\n\nRecreate the state of your model from the checkpoint:\n\n```{.python}\nmodel = TheModelClass(*args, **kwargs)\noptimizer = TheOptimizerClass(*args, **kwargs)\n\ncheckpoint = torch.load(\"model.pt\")\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\n```\n\nResume training:\n\n```{.python}\nmodel.train()\n```\n\n",
    "supporting": [
      "checkpoints_files"
    ],
    "filters": [],
    "includes": {}
  }
}