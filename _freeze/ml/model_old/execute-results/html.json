{
  "hash": "8bb0e2b879e22b82779bc55cd5734420",
  "result": {
    "markdown": "---\ntitle: Building a model\nauthor: Marie-Hélène Burle\n---\n\n:::{.def}\n\nKey to creating neural networks in PyTorch is the `torch.nn` package which contains the `nn.Module` and a `forward` method which returns an output from some input.\n\nLet's build a neural network to classify the MNIST.\n\n:::\n\n## Load packages\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n```\n:::\n\n\n## Define the architecture of the network\n\nFirst, we need to define the architecture of the network.\n\nThere are many types of architectures. For images, CNN are well suited.\n\nIn Python, you can define a subclass of an existing class with:\n\n```{.python}\nclass YourSubclass(BaseClass):\n    <definition of your subclass>        \n```\n\nYour subclass is derived from the base class and inherits its properties.\n\nPyTorch contains the class `torch.nn.Module` which is used as the base class when defining a neural network.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nclass Net(nn.Module):\n    def __init__(self):\n      super(Net, self).__init__()\n      \n      # First 2D convolutional layer, taking in 1 input channel (image),\n      # outputting 32 convolutional features.\n      # Convolution adds each pixel of an image to its neighbours,\n      # weighted by the kernel (a small matrix).\n      # Here, the kernel is square and of size 3*3\n      # Convolution helps to extract features from the input\n      # (e.g. edge detection, blurriness, sharpeness...)\n      self.conv1 = nn.Conv2d(1, 32, 3)\n      # Second 2D convolutional layer, taking in the 32 input channels,\n      # outputting 64 convolutional features, with a kernel size of 3*3\n      self.conv2 = nn.Conv2d(32, 64, 3)\n\n      # Dropouts randomly blocks a fraction of the neurons during training\n      # This is a regularization technique which prevents overfitting\n      self.dropout1 = nn.Dropout2d(0.25)\n      self.dropout2 = nn.Dropout2d(0.5)\n\n      # First fully connected layer\n      self.fc1 = nn.Linear(9216, 128)\n      # Second fully connected layer that outputs our 10 labels\n      self.fc2 = nn.Linear(128, 10)\n```\n:::\n\n\n## Set the flow of data through the network\n\nThe feed-forward algorithm is defined by the `forward` function.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nclass Net(nn.Module):\n    def __init__(self):\n      super(Net, self).__init__()\n      self.conv1 = nn.Conv2d(1, 32, 3)\n      self.conv2 = nn.Conv2d(32, 64, 3)\n      self.dropout1 = nn.Dropout2d(0.25)\n      self.dropout2 = nn.Dropout2d(0.5)\n      self.fc1 = nn.Linear(9216, 128)\n      self.fc2 = nn.Linear(128, 10)\n\n    # x represents the data\n    def forward(self, x):\n      # Pass data through conv1\n      x = self.conv1(x)\n      # Use the rectified-linear activation function over x\n      x = F.relu(x)\n\n      x = self.conv2(x)\n      x = F.relu(x)\n\n      # Run max pooling over x\n      x = F.max_pool2d(x, 2)\n      # Pass data through dropout1\n      x = self.dropout1(x)\n      # Flatten x with start_dim=1\n      x = torch.flatten(x, 1)\n      # Pass data through fc1\n      x = self.fc1(x)\n      x = F.relu(x)\n      x = self.dropout2(x)\n      x = self.fc2(x)\n\n      # Apply softmax to x\n      output = F.log_softmax(x, dim=1)\n      return output\n```\n:::\n\n\nLet's create an instance of `Net` and print its structure:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nnet = Net()\nprint(net)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNet(\n  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n  (dropout1): Dropout2d(p=0.25, inplace=False)\n  (dropout2): Dropout2d(p=0.5, inplace=False)\n  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=10, bias=True)\n)\n```\n:::\n:::\n\n\n",
    "supporting": [
      "model_old_files"
    ],
    "filters": [],
    "includes": {}
  }
}