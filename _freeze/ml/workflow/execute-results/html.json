{
  "hash": "22f26ded24e991eaa75c0e634597ab54",
  "result": {
    "markdown": "---\ntitle: Overall workflow\nauthor: Marie-Hélène Burle\n---\n\n:::{.def}\n\nThis classic PyTorch tutorial goes over the entire workflow to create and train a simple image classifier.\n\nLet's go over it step by step.\n\n:::\n\n## The data\n\n[CIFAR-10](https://en.wikipedia.org/wiki/CIFAR-10) from [the Canadian Institute for Advanced Research](https://en.wikipedia.org/wiki/Canadian_Institute_for_Advanced_Research) is a classic dataset of 60,000 color images falling into 10 classes (6,000 images in each class):\n\n- airplane\n- automobile\n- bird\n- cat\n- deer\n- dog\n- frog\n- horse\n- ship\n- truck\n\nThe images are of size 32x32 pixels (tiny!), which makes it very lightweight, quick to load and easy to play with.\n\n### Create a DataLoader\n\nA DataLoader is an iterable feeding data to a model at each iteration. The data loader transforms the data to the proper format, sets the batch size, whether the data is shuffled or not, and how the I/O is parallelized. You can create DataLoaders with the [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) class.\n\nLet's create 2 DataLoaders: one for the train set and one for the test set.\n\n#### Load packages\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\n```\n:::\n\n\n#### Create a transform object\n\nThe [CIFAR-10](https://en.wikipedia.org/wiki/CIFAR-10) images in the [TorchVision](https://pytorch.org/vision/stable/index.html) library are Image objects (from the [PIL.Image](https://pillow.readthedocs.io/en/stable/reference/Image.html) module of the [pillow](https://pillow.readthedocs.io/en/stable/index.html) package).\n\nWe need to normalize them and turn them into tensors:\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n```\n:::\n\n\n#### Chose a batch size\n\nRemember that the data move forward through the network (forward pass), outputting some estimates which are used to calculate some loss (or error) value. Then we get gradients through automatic differentiation and the model parameters are adjusted a little through gradient descent.\n\nYou do not have to have the entire training set go through this process each time: you can use batches.\n\nThe batch size is the number of items from the data that are processed before the model is updated. There is no hard rule to set good batch sizes and sizes tend to be picked through trial and error.\n\nHere are some rules to chose a batch size:\n\n- make sure that the batch fits in the CPU or GPU,\n- small batches give faster results (each training iteration is very fast), but give less accuracy,\n- large batches lead to slower training, but better accuracy.\n\nLet's set the batch size to 4:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nbatch_size = 4\n```\n:::\n\n\n#### Put it together into DataLoaders\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ntrainset = torchvision.datasets.CIFAR10(root='./data',\n                                        train=True,\n                                        download=True,\n                                        transform=transform)\n\ntrainloader = torch.utils.data.DataLoader(trainset,\n                                          batch_size=batch_size,\n                                          shuffle=True,\n                                          num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='./data',\n                                       train=False,\n                                       download=True,\n                                       transform=transform)\n\ntestloader = torch.utils.data.DataLoader(testset,\n                                         batch_size=batch_size,\n                                         shuffle=False,\n                                         num_workers=2)\n```\n:::\n\n\nWe will also need the classes:\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nclasses = ('plane', 'car', 'bird', 'cat', 'deer',\n           'dog', 'frog', 'horse', 'ship', 'truck')\n```\n:::\n\n\n### Visualize a sample of the data\n\nThough not necessary, it can be useful to have a look at the data:\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# Load the packages for this\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define a function to display an image\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n# Get a batch of random training images\ndataiter = iter(trainloader)\nimages, labels = next(dataiter)\n\n# Display the images\nimshow(torchvision.utils.make_grid(images))\n\n# Print the labels\nprint(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\n```\n\n::: {.cell-output .cell-output-display}\n![](workflow_files/figure-html/cell-7-output-1.png){width=566 height=181}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nhorse deer  deer  ship \n```\n:::\n:::\n\n\n## The model\n\n### Architecture\n\nFirst, we need to define the architecture of the network. There are many types of architectures. For images, CNN are well suited.\n\nIn Python, you can define a subclass of an existing class with:\n\n```{.python}\nclass YourSubclass(BaseClass):\n    <definition of your subclass>        \n```\n\nThe subclass is derived from the base class and inherits its properties. PyTorch contains the class `torch.nn.Module` which is used as the base class when defining a neural network.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    # Define the architecture of the network\n    def __init__(self):\n        super().__init__()\n        # 3 input image channel (3 colour channels)\n        # 6 output channels,\n        # 5x5 square convolution kernel\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        # Max pooling over a (2, 2) window\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        # 5*5 from image dimension\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        # 10 is the size of the output layer\n        # since there are 10 classes\n        self.fc3 = nn.Linear(84, 10)\n\n    # Set the flow of data through the network for the forward pass\n    # x represents the data\n    def forward(self, x):\n        # F.relu is the rectified-linear activation function\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        # flatten all dimensions except the batch dimension\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n```\n:::\n\n\nLet's create an instance of `Net` and print its structure:\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nnet = Net()\nprint(net)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNet(\n  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)\n```\n:::\n:::\n\n\n### Loss function and optimizer\n\nWe need to chose a loss function that will be used to calculate the gradients through backpropagation as well as an optimizer to do the gradient descent.\n\nSGD with momentum has proved a very efficient optimizing technique and is widely used.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nimport torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n```\n:::\n\n\n## Training\n\nWe can now train the model:\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nfor epoch in range(2):  # loop over the dataset twice\n\n    running_loss = 0.0\n\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n            running_loss = 0.0\n\nprint('Finished Training')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1,  2000] loss: 2.224\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1,  4000] loss: 1.853\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1,  6000] loss: 1.628\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1,  8000] loss: 1.567\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1, 10000] loss: 1.525\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1, 12000] loss: 1.450\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[2,  2000] loss: 1.377\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[2,  4000] loss: 1.361\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[2,  6000] loss: 1.351\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[2,  8000] loss: 1.309\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[2, 10000] loss: 1.302\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[2, 12000] loss: 1.294\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nFinished Training\n```\n:::\n:::\n\n\n## Testing\n\n### Little test on one batch for fun\n\nLet's now test our model on one batch of testing data.\n\nFirst, let's get a batch of random testing data:\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ndataiter = iter(testloader)\nimages, labels = next(dataiter)\n```\n:::\n\n\nLet's display them and print their true labels:\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nimshow(torchvision.utils.make_grid(images))\nprint('Real: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n```\n\n::: {.cell-output .cell-output-display}\n![](workflow_files/figure-html/cell-13-output-1.png){width=566 height=181}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nReal:  cat   ship  ship  plane\n```\n:::\n:::\n\n\nNow, let's run the same batch of testing images through our model:\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\noutputs = net(images)\n```\n:::\n\n\nLet's get the best predictions for these:\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n_, predicted = torch.max(outputs, 1)\n\nprint('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n                              for j in range(4)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPredicted:  cat   ship  ship  ship \n```\n:::\n:::\n\n\n### More serious testing\n\nThis was fun, but of course, with a sample of one, we can't say anything about how good our model is. We need to test it on many more images from the test set.\n\nLet's use the entire test set:\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\ncorrect = 0\ntotal = 0\n# since we're not training, we don't need to calculate the gradients for our outputs\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        # calculate outputs by running images through the network\n        outputs = net(images)\n        # the class with the highest energy is what we choose as prediction\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy of the network on the 10000 test images: 53 %\n```\n:::\n:::\n\n\n### Per class testing\n\nWe could see whether the model seem to perform better for some classes than others:\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\n# prepare to count predictions for each class\ncorrect_pred = {classname: 0 for classname in classes}\ntotal_pred = {classname: 0 for classname in classes}\n\n# again no gradients needed\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predictions = torch.max(outputs, 1)\n        # collect the correct predictions for each class\n        for label, prediction in zip(labels, predictions):\n            if label == prediction:\n                correct_pred[classes[label]] += 1\n            total_pred[classes[label]] += 1\n\n\n# print accuracy for each class\nfor classname, correct_count in correct_pred.items():\n    accuracy = 100 * float(correct_count) / total_pred[classname]\n    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy for class: plane is 43.4 %\nAccuracy for class: car   is 68.5 %\nAccuracy for class: bird  is 50.1 %\nAccuracy for class: cat   is 32.8 %\nAccuracy for class: deer  is 26.0 %\nAccuracy for class: dog   is 62.4 %\nAccuracy for class: frog  is 50.8 %\nAccuracy for class: horse is 60.7 %\nAccuracy for class: ship  is 84.4 %\nAccuracy for class: truck is 52.9 %\n```\n:::\n:::\n\n\n",
    "supporting": [
      "workflow_files"
    ],
    "filters": [],
    "includes": {}
  }
}