{
  "hash": "fb261bac951e930a1707d9ea64c97785",
  "result": {
    "markdown": "---\ntitle: Introduction to high performance research computing in Julia\nauthor: Marie-Hélène Burle\n---\n\n## Logging on to the cluster\n\nOpen a terminal emulator.\n\n/Windows users, launch [MobaXTerm](https://mobaxterm.mobatek.net/)./ \\\n/MacOS users, launch Terminal./ \\\n/Linux users, launch xterm or the terminal emulator of your choice./\n\n```{.bash}\n$ ssh <username>@<hostname>    # enter password\n```\n\n## Accessing Julia\n\nThis is done with the [Lmod](https://github.com/TACC/Lmod) tool through the [module](https://docs.computecanada.ca/wiki/Utiliser_des_modules/en) command. You can find the full documentation [here](https://lmod.readthedocs.io/en/latest/010_user.html) and below are the subcommands you will need:\n\n```{.bash}\n# get help on the module command\n$ module help\n$ module --help\n$ module -h\n\n# list modules that are already loaded\n$ module list\n\n# see which modules are available for Julia\n$ module spider julia\n\n# see how to load julia 1.3\n$ module spider julia/1.3.0\n\n# load julia 1.3 with the required gcc module first\n# (the order is important)\n$ module load gcc/7.3.0 julia/1.3.0\n\n# you can see that we now have Julia loaded\n$ module list\n```\n\n## Copying files to the cluster\n\nWe will create a `julia_workshop` directory in `~/scratch`, then copy our julia script in it.\n\n```{.bash}\n$ mkdir ~/scratch/julia_job\n```\n\nOpen a new terminal window and from your local terminal (make sure that you are not on the remote terminal by looking at the bash prompt) run:\n\n```{.bash}\n$ scp /local/path/to/sort.jl userxxx@cassiopeia.c3.ca:scratch/julia_job\n$ scp /local/path/to/psort.jl userxxx@cassiopeia.c3.ca:scratch/julia_job\n\n# enter password\n```\n\n## Job scripts\n\nWe will not run an interactive session with Julia on the cluster: we already have julia scripts ready to run. All we need to do is to write job scripts to submit to Slurm, the job scheduler used by the Alliance clusters.\n\nWe will create 2 scripts: one to run Julia on one core and one on as many cores as are available.\n\n:::{.exo}\n\n:::{.yourturn}\n\nYour turn:\n\n:::\n\nHow many processors are there on our training cluster?\n\n:::\n\nNote that here too, we could run Julia with multiple threads by running:\n\n```{.bash}\n$ JULIA_NUM_THREADS=2 julia\n```\n\nOnce in Julia, you can double check that Julia does indeed have access to 2 threads by running:\n\n```{.julia}\nThreads.nthreads()\n```\n\nSave your job scripts in the files `~/scratch/julia_job/job_julia1c.sh` and `job_julia2c.sh` for one and two cores respectively.\n\nHere is what our single core Slurm script looks like:\n\n```{.bash}\n#!/bin/bash\n#SBATCH --job-name=julia1c\t\t\t# job name\n#SBATCH --time=00:01:00\t\t\t\t# max walltime 1 min\n#SBATCH --cpus-per-task=1           # number of cores\n#SBATCH --mem=1000\t\t\t\t\t# max memory (default unit is megabytes)\n#SBATCH --output=julia1c%j.out\t\t# file name for the output\n#SBATCH --error=julia1c%j.err\t\t# file name for errors\n# %j gets replaced with the job number\n\necho Running NON parallel script on $SLURM_CPUS_PER_TASK core\nJULIA_NUM_THREADS=$SLURM_CPUS_PER_TASK julia sort.jl\necho Running parallel script on $SLURM_CPUS_PER_TASK core\nJULIA_NUM_THREADS=$SLURM_CPUS_PER_TASK julia psort.jl\n```\n\n:::{.exo}\n\n:::{.yourturn}\n\nYour turn:\n\n:::\n\nWrite the script for 2 cores.\n\n:::\n\nNow, we can submit our jobs to the cluster:\n\n```{.bash}\n$ cd ~/scratch/julia_job\n$ sbatch job_julia1c.sh\n$ sbatch job_julia2c.sh\n```\n\nAnd we can check their status with:\n\n```{.bash}\n$ sq\n```\n\n`PD` stands for pending and `R` for running.\n\n",
    "supporting": [
      "intro_hpc_files"
    ],
    "filters": [],
    "includes": {}
  }
}