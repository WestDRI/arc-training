{
  "hash": "c67c682f7e97a692494bc2d0bb41e258",
  "result": {
    "markdown": "---\ntitle: Searching a version-controlled project\nauthor: Marie-Hélène Burle\n---\n\n\n:::{.def}\n\nWhat is the point of creating all these commits if you are unable to make use of them because you can't find the information you need in them?\n\nIn this workshop, we will learn how to search:\n\n- your files (at any of their versions) and\n- your commit logs.\n\nBy the end of the workshop, you should be able to retrieve anything you need from your versioned project.\n\n:::\n\n:::{.box}\n\n*Prerequisites:*\n\nThis special Git topic is suitable for people who already use Git.\n\nYou don't need to be an expert, but we expect that you are able to run basic Git commands in the command line.\n\n:::\n\n<!-- https://git-scm.com/book/en/v2/Git-Tools-Searching -->\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-1_93c60734e27e245deda19f1179481bab'}\n\n:::\n\n\n## Installation\n\n**MacOS & Linux users**:\n\nInstall Git from [the official website](https://git-scm.com/downloads).\n\n**Windows users**:\n\nInstall [Git for Windows](https://gitforwindows.org/). This will also install \"Git Bash\", a Bash emulator.\n\n## Using Git\n\nWe will use Git from the command line throughout this workshop.\n\nMacOS users: &emsp;&emsp;&ensp;open \"Terminal\".\\\nWindows users: &emsp;&ensp;open \"Git Bash\".\\\nLinux users: &emsp;&emsp;&emsp;open the terminal emulator of your choice.\n\n## Practice repo\n\n### Get a repo\n\nYou are welcome to use a repository of yours to follow this workshop. Alternatively, you can clone a practice repo I have on GitHub:\n\n1. Navigate to an appropriate location:\n\n```{.bash}\ncd /path/to/appropriate/location\n```\n\n2. Clone the repo:\n\n```{.bash}\n# If you have set SSH for your GitHub account\ngit clone git@github.com:prosoitos/practice_repo.git\n```\n\n```{.bash}\n# If you haven't set SSH\ngit clone https://github.com/prosoitos/practice_repo.git\n```\n\n3. Enter the repo:\n\n```{.bash}\ncd practice_repo\n```\n\n## Searching files\n\nThe first thing that can happen is that you are looking for a certain pattern somewhere in your project (for instance a certain function or a certain word).\n\n### git grep\n\nThe main command to look through versioned files is `git grep`.\n\nYou might be familiar with the command-line utility [grep](https://en.wikipedia.org/wiki/Grep) which allows to search for lines matching a certain pattern in files. `git grep` does a similar job with these differences:\n\n- it is much faster since all files under version control are already indexed by Git,\n- you can easily search any commit without having to check it out,\n- it has features lacking in `grep` such as, for instance, [pattern arithmetic or tree search using globs](https://stackoverflow.com/a/17558295/9210961).\n\n### Let's try it\n\nBy default, `git grep` searches recursively through the tracked files in the working directory (that is, the current version of the tracked files).\n\nFirst, let's look for the word `test` in the current version of the tracked files in the test repo:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-2_648b3d939dc75ff01be094eb5203a988'}\n\n```{.bash .cell-code}\ngit grep test\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\nadrian.txt:Adrian's test text file.\nformerlyadrian.txt:Adrian's test text file.\nms/protocol.md:This is my test.\nms/smabraha.txt:This is a test file that I wanted to make, then push it somehow\nredone17.txt:this is a test file from redone17\nsrc/test_manuel.py:def test(model, device, test_loader):\nsrc/test_manuel.py:    test_loss = 0\nsrc/test_manuel.py:        for data, target in test_loader:\nsrc/test_manuel.py:            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\nsrc/test_manuel.py:    test_loss /= len(test_loader.dataset)\nsrc/test_manuel.py:        test_loss, correct, len(test_loader.dataset),\nsrc/test_manuel.py:        100. * correct / len(test_loader.dataset)))\nsrc/test_manuel.py:    test_data = datasets.MNIST(\nsrc/test_manuel.py:    test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\nsrc/test_manuel.py:        test(model, device, test_loader)\ntestAV1.txt:This is a test\ntext-collab.txt:This is the collaboration testing\n```\n:::\n:::\n\n\nLet's add blank lines between the results of each file for better readability:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-3_901dea7aedcc354472a81616d309866a'}\n\n```{.bash .cell-code}\ngit grep --break test\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\nadrian.txt:Adrian's test text file.\n\nformerlyadrian.txt:Adrian's test text file.\n\nms/protocol.md:This is my test.\n\nms/smabraha.txt:This is a test file that I wanted to make, then push it somehow\n\nredone17.txt:this is a test file from redone17\n\nsrc/test_manuel.py:def test(model, device, test_loader):\nsrc/test_manuel.py:    test_loss = 0\nsrc/test_manuel.py:        for data, target in test_loader:\nsrc/test_manuel.py:            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\nsrc/test_manuel.py:    test_loss /= len(test_loader.dataset)\nsrc/test_manuel.py:        test_loss, correct, len(test_loader.dataset),\nsrc/test_manuel.py:        100. * correct / len(test_loader.dataset)))\nsrc/test_manuel.py:    test_data = datasets.MNIST(\nsrc/test_manuel.py:    test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\nsrc/test_manuel.py:        test(model, device, test_loader)\n\ntestAV1.txt:This is a test\n\ntext-collab.txt:This is the collaboration testing\n```\n:::\n:::\n\n\nLet's also put the file names on separate lines:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-4_1f1a2fb774e348dced5a881421ebd1e6'}\n\n```{.bash .cell-code}\ngit grep --break --heading test\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\nadrian.txt\nAdrian's test text file.\n\nformerlyadrian.txt\nAdrian's test text file.\n\nms/protocol.md\nThis is my test.\n\nms/smabraha.txt\nThis is a test file that I wanted to make, then push it somehow\n\nredone17.txt\nthis is a test file from redone17\n\nsrc/test_manuel.py\ndef test(model, device, test_loader):\n    test_loss = 0\n        for data, target in test_loader:\n            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n    test_loss /= len(test_loader.dataset)\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    test_data = datasets.MNIST(\n    test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\n        test(model, device, test_loader)\n\ntestAV1.txt\nThis is a test\n\ntext-collab.txt\nThis is the collaboration testing\n```\n:::\n:::\n\n\nWe can display the line numbers for the results with the `-n` flag:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-5_7fa14694a3bb77a9dd2e64888ce74d30'}\n\n```{.bash .cell-code}\ngit grep --break --heading -n test\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\nadrian.txt\n1:Adrian's test text file.\n\nformerlyadrian.txt\n1:Adrian's test text file.\n\nms/protocol.md\n9:This is my test.\n\nms/smabraha.txt\n1:This is a test file that I wanted to make, then push it somehow\n\nredone17.txt\n1:this is a test file from redone17\n\nsrc/test_manuel.py\n50:def test(model, device, test_loader):\n52:    test_loss = 0\n55:        for data, target in test_loader:\n58:            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n62:    test_loss /= len(test_loader.dataset)\n65:        test_loss, correct, len(test_loader.dataset),\n66:        100. * correct / len(test_loader.dataset)))\n84:    test_data = datasets.MNIST(\n90:    test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\n97:        test(model, device, test_loader)\n\ntestAV1.txt\n1:This is a test\n\ntext-collab.txt\n1:This is the collaboration testing\n```\n:::\n:::\n\n\nNotice how the results for the file `src/test_manuel.py` involve functions. It would be very convenient to have the names of the functions in which `test` appears.\n\nWe can do this with the `-p` flag:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-6_c0f076b966058a639df77b6266555fd5'}\n\n```{.bash .cell-code}\ngit grep --break --heading -p test src/test_manuel.py\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\nsrc/test_manuel.py\ndef train(model, device, train_loader, optimizer, epoch):\ndef test(model, device, test_loader):\n    test_loss = 0\n        for data, target in test_loader:\n            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n    test_loss /= len(test_loader.dataset)\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\ndef main():\n    test_data = datasets.MNIST(\n    test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\n        test(model, device, test_loader)\n```\n:::\n:::\n\n\n:::{.note}\n\nWe added the argument `src/test_manuel.py` to limit the search to that file.\n\n:::\n\nWe can now see that the word `test` appears in the functions `test` and `main`.\n\nNow, instead of printing all the matching lines, let's print the number of matches per file:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-7_38f7661f6c9dff45d80e6c311208f3fe'}\n\n```{.bash .cell-code}\ngit grep -c test\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\nadrian.txt:1\nformerlyadrian.txt:1\nms/protocol.md:1\nms/smabraha.txt:1\nredone17.txt:1\nsrc/test_manuel.py:10\ntestAV1.txt:1\ntext-collab.txt:1\n```\n:::\n:::\n\n\n### More complex patterns\n\n`git grep` in fact searches for regular expressions. `test` is a regular expression matching `test`, but we can look for more complex patterns.\n\nLet's look for `image`:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-8_4047be1bad9a872d489beaaefaeba76b'}\n\n```{.bash .cell-code}\ngit grep image\n```\n:::\n\n\n:::{.note}\n\nNo output means that the search is not returning any result.\n\n:::\n\nLet's make this search case insensitive:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-9_93cd8ed55517009735bb22c6d07b6fed'}\n\n```{.bash .cell-code}\ngit grep -i image\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\nsrc/new_file.py:from PIL import Image\nsrc/new_file.py:berlin1_lr = Image.open(\"/home/marie/parvus/pwg/wtm/slides/static/img/upscaling/lr/berlin_1945_1.jpg\")\nsrc/new_file.py:berlin1_hr = Image.open(\"/home/marie/parvus/pwg/wtm/slides/static/img/upscaling/hr/berlin_1945_1.png\")\n```\n:::\n:::\n\n\nWe are now getting some results as `Image` was present in three lines of the file `src/new_file.py`.\n\nLet's now search for `data`:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-10_22ee8846eae5aa6ae693c03a6308ed7e'}\n\n```{.bash .cell-code}\ngit grep data\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\n.gitignore:data/\nms/protocol.md:Collected and analyzed amazing data\nsrc/new_file.py:from datasets import load_dataset\nsrc/new_file.py:set5 = load_dataset('eugenesiow/Set5', 'bicubic_x4', split='validation')\nsrc/test_manuel.py:from torchvision import datasets, transforms\nsrc/test_manuel.py:    for batch_idx, (data, target) in enumerate(train_loader):\nsrc/test_manuel.py:        data, target = data.to(device), target.to(device)\nsrc/test_manuel.py:        output = model(data)\nsrc/test_manuel.py:                epoch, batch_idx * len(data), len(train_loader.dataset),\nsrc/test_manuel.py:        for data, target in test_loader:\nsrc/test_manuel.py:            data, target = data.to(device), target.to(device)\nsrc/test_manuel.py:            output = model(data)\nsrc/test_manuel.py:    test_loss /= len(test_loader.dataset)\nsrc/test_manuel.py:        test_loss, correct, len(test_loader.dataset),\nsrc/test_manuel.py:        100. * correct / len(test_loader.dataset)))\nsrc/test_manuel.py:    train_data = datasets.MNIST(\nsrc/test_manuel.py:        '~/parvus/pwg/wtm/tml/data',\nsrc/test_manuel.py:        # '~/projects/def-sponsor00/data',\nsrc/test_manuel.py:    test_data = datasets.MNIST(\nsrc/test_manuel.py:        '~/parvus/pwg/wtm/tml/data',\nsrc/test_manuel.py:        # '~/projects/def-sponsor00/data',\nsrc/test_manuel.py:    train_loader = torch.utils.data.DataLoader(train_data, batch_size=50)\nsrc/test_manuel.py:    test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\n```\n:::\n:::\n\n\nWe are getting results for the word `data`, but also for the pattern `data` in longer expressions such as `train_data` or `dataset`. If we only want results for the word `data`, we can use the `-w` flag:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-11_1cef985330da3a6482925e139d67de74'}\n\n```{.bash .cell-code}\ngit grep -w data\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\n.gitignore:data/\nms/protocol.md:Collected and analyzed amazing data\nsrc/test_manuel.py:    for batch_idx, (data, target) in enumerate(train_loader):\nsrc/test_manuel.py:        data, target = data.to(device), target.to(device)\nsrc/test_manuel.py:        output = model(data)\nsrc/test_manuel.py:                epoch, batch_idx * len(data), len(train_loader.dataset),\nsrc/test_manuel.py:        for data, target in test_loader:\nsrc/test_manuel.py:            data, target = data.to(device), target.to(device)\nsrc/test_manuel.py:            output = model(data)\nsrc/test_manuel.py:        '~/parvus/pwg/wtm/tml/data',\nsrc/test_manuel.py:        # '~/projects/def-sponsor00/data',\nsrc/test_manuel.py:        '~/parvus/pwg/wtm/tml/data',\nsrc/test_manuel.py:        # '~/projects/def-sponsor00/data',\nsrc/test_manuel.py:    train_loader = torch.utils.data.DataLoader(train_data, batch_size=50)\nsrc/test_manuel.py:    test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\n```\n:::\n:::\n\n\nNow, let's use a more complex regular expression. We want the counts for the pattern `\".*_.*\"` (i.e. any name with a snail case such as `train_loader`):\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-12_6f68606a8499c577cea476fdf3b37693'}\n\n```{.bash .cell-code}\ngit grep -c \".*_.*\"\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\n.gitignore:2\nsrc/new_file.py:22\nsrc/test_manuel.py:29\n```\n:::\n:::\n\n\nLet's print the first 3 results per file:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-13_8d2c6a7f449aceebf2684f1083f72a23'}\n\n```{.bash .cell-code}\ngit grep -m 3 \".*_.*\"\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\n.gitignore:hidden_file\n.gitignore:search_cache/\nsrc/new_file.py:from datasets import load_dataset\nsrc/new_file.py:set5 = load_dataset('eugenesiow/Set5', 'bicubic_x4', split='validation')\nsrc/new_file.py:set5.column_names\nsrc/test_manuel.py:from torch.optim.lr_scheduler import StepLR\nsrc/test_manuel.py:    def __init__(self):\nsrc/test_manuel.py:        super(Net, self).__init__()\n```\n:::\n:::\n\n\nAs you can see, our results also include `__init__` which is not what we were looking for. So let's exclude `__`:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-14_665da6fdbb3ecf335a23a3fa95ff0ffb'}\n\n```{.bash .cell-code}\ngit grep -m 3 -e \".*_.*\" --and --not -e \"__\"\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\n.gitignore:hidden_file\n.gitignore:search_cache/\nsrc/new_file.py:from datasets import load_dataset\nsrc/new_file.py:set5 = load_dataset('eugenesiow/Set5', 'bicubic_x4', split='validation')\nsrc/new_file.py:set5.column_names\nsrc/test_manuel.py:from torch.optim.lr_scheduler import StepLR\nsrc/test_manuel.py:        x = F.max_pool2d(x, 2)\nsrc/test_manuel.py:        output = F.log_softmax(x, dim=1)\n```\n:::\n:::\n\n\n:::{.note}\n\nFor simple searches, you don't have to use the `-e` flag before the pattern you are searching for. Here however, our command has gotten complex enough that we have to use it before each pattern.\n\n:::\n\nLet's make sure this worked as expected:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-15_be9129f363b80b599dccc4068448eec3'}\n\n```{.bash .cell-code}\ngit grep -c \".*_.*\"\necho \"---\"\ngit grep -c \"__\"\necho \"---\"\ngit grep -ce \".*_.*\" --and --not -e \"__\"\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\n.gitignore:2\nsrc/new_file.py:22\nsrc/test_manuel.py:29\n---\nsrc/test_manuel.py:2\n---\n.gitignore:2\nsrc/new_file.py:22\nsrc/test_manuel.py:27\n```\n:::\n:::\n\n\nThere were 2 lines matching `__` in `src/test_manuel.py` and we have indeed excluded them from our search.\n\nExtended regular expressions are also covered with the flag `-E`.\n\n### Searching other trees\n\nSo far, we have searched the current version of tracked files, but we can just as easily search files at any commit.\n\nLet's search for `test` in the tracked files 20 commits ago:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-16_83b553c5d169c0e54c9da0a7d514e346'}\n\n```{.bash .cell-code}\ngit grep test HEAD~20\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\nHEAD~20:adrian.txt:Adrian's test text file.\nHEAD~20:formerlyadrian.txt:Adrian's test text file.\nHEAD~20:ms/protocol.md:This is my test.\nHEAD~20:ms/smabraha.txt:This is a test file that I wanted to make, then push it somehow\nHEAD~20:redone17.txt:this is a test file from redone17\nHEAD~20:testAV1.txt:This is a test\nHEAD~20:text-collab.txt:This is the collaboration testing\n```\n:::\n:::\n\n\n:::{.note}\n\nAs you can see, the file `src/test_manuel.py` is not in the results. Either it didn't exist or it didn't have the word `test` at that commit.\n\n:::\n\nIf you want to search tracked files AND untracked files, you need to use the `--untracked` flag.\n\nLet's create a new (thus untracked) file with some content including the word `test`:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-17_133c7fa44b8aa5857df87772bfd62d8b'}\n\n```{.bash .cell-code}\necho \"This is a test\" > newfile\n```\n:::\n\n\nNow compare the following:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-18_52b770a68c381d1795949014b9d3a1b6'}\n\n```{.bash .cell-code}\ngit grep -c test\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\nadrian.txt:1\nformerlyadrian.txt:1\nms/protocol.md:1\nms/smabraha.txt:1\nredone17.txt:1\nsrc/test_manuel.py:10\ntestAV1.txt:1\ntext-collab.txt:1\n```\n:::\n:::\n\n\nwith:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-19_bfcb2a106514b3e70115b151dbe324d3'}\n\n```{.bash .cell-code}\ngit grep -c --untracked test\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\nadrian.txt:1\nformerlyadrian.txt:1\nms/protocol.md:1\nms/smabraha.txt:1\nnewfile:1\nredone17.txt:1\nsrc/test_manuel.py:10\ntestAV1.txt:1\ntext-collab.txt:1\n```\n:::\n:::\n\n\n:::{.note}\n\nThis last result also returned our untracked file `newfile`.\n\n:::\n\nIf you want to search untracked and ignored files (meaning all your files), use the flags `--untracked --no-exclude-standard`.\n\nLet's see what the `.gitignore` file contains:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-20_cd76e52090b34c4fc94d7e24a61402d8'}\n\n```{.bash .cell-code}\ncat .gitignore\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\ndata/\noutput/\nhidden_file\nsearch_cache/\nsearch.qmd\nsearch.rmarkdown\n```\n:::\n:::\n\n\nThe directory `data` is in `.gitignore`. This means that it is not under version control and it thus doesn't exist in our repo (since we cloned our repo, we only have the version-controlled files). Let's create it:\n\n```{.bash}\nmkdir data\n```\n\nNow, let's create a file in it that contains `test`:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-21_99dd1d8db58081cb3f9e46f58c755dde'}\n\n```{.bash .cell-code}\necho \"And another test\" > data/file\n```\n:::\n\n\nWe can rerun our previous two searches to verify that files excluded from version control are not searched:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-22_b66ed1216c0aef4dc84180a962639c8d'}\n\n```{.bash .cell-code}\ngit grep -c test\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\nadrian.txt:1\nformerlyadrian.txt:1\nms/protocol.md:1\nms/smabraha.txt:1\nredone17.txt:1\nsrc/test_manuel.py:10\ntestAV1.txt:1\ntext-collab.txt:1\n```\n:::\n:::\n\n::: {.cell hash='search_cache/html/unnamed-chunk-23_790ab3fa2f40fa477c84c9983fb08cb6'}\n\n```{.bash .cell-code}\ngit grep -c --untracked test\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\nadrian.txt:1\nformerlyadrian.txt:1\nms/protocol.md:1\nms/smabraha.txt:1\nnewfile:1\nredone17.txt:1\nsrc/test_manuel.py:10\ntestAV1.txt:1\ntext-collab.txt:1\n```\n:::\n:::\n\n\nAnd now, let's try:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-24_6b59fa2952d6230124e6f53ba68a0e8e'}\n\n```{.bash .cell-code}\ngit grep -c --untracked --no-exclude-standard test\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\nadrian.txt:1\ndata/file:1\nformerlyadrian.txt:1\nms/protocol.md:1\nms/smabraha.txt:1\nnewfile:1\nredone17.txt:1\nsearch.qmd:41\nsearch.rmarkdown:41\nsrc/test_manuel.py:10\ntestAV1.txt:1\ntext-collab.txt:1\n```\n:::\n:::\n\n\n:::{.note}\n\n`data/file`, despite being excluded from version control, is also searched.\n\n:::\n\n### Searching all commits\n\nWe saw that `git grep <pattern> <commit>` can search a pattern in any commit. Now, what if we all to search *all* commits for a pattern?\n\nFor this, we pass the expression `$(git rev-list --all)` in lieu of `<commit>`.\n\n`git rev-list --all` creates a list of all the commits in a way that can be used as an argument to other functions. The `$()` allows to run the expression inside it and pass the result as and argument.\n\nTo search for `test` in all the commits, we thus run:\n\n```{.bash}\ngit grep \"test\" $(git rev-list --all)\n```\n\nI am not running this command has it has a huge output. Instead, I will limit the search to the last two commits:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-25_e3a16795993c99017561c694b751a9b2'}\n\n```{.bash .cell-code}\ngit grep \"test\" $(git rev-list --all -2)\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\ne3cfb2ebbcb77e52851c32fbba1f6b8b0c788a29:adrian.txt:Adrian's test text file.\ne3cfb2ebbcb77e52851c32fbba1f6b8b0c788a29:formerlyadrian.txt:Adrian's test text file.\ne3cfb2ebbcb77e52851c32fbba1f6b8b0c788a29:ms/protocol.md:This is my test.\ne3cfb2ebbcb77e52851c32fbba1f6b8b0c788a29:ms/smabraha.txt:This is a test file that I wanted to make, then push it somehow\ne3cfb2ebbcb77e52851c32fbba1f6b8b0c788a29:redone17.txt:this is a test file from redone17\ne3cfb2ebbcb77e52851c32fbba1f6b8b0c788a29:src/test_manuel.py:def test(model, device, test_loader):\ne3cfb2ebbcb77e52851c32fbba1f6b8b0c788a29:src/test_manuel.py:    test_loss = 0\ne3cfb2ebbcb77e52851c32fbba1f6b8b0c788a29:src/test_manuel.py:        for data, target in test_loader:\ne3cfb2ebbcb77e52851c32fbba1f6b8b0c788a29:src/test_manuel.py:            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\ne3cfb2ebbcb77e52851c32fbba1f6b8b0c788a29:src/test_manuel.py:    test_loss /= len(test_loader.dataset)\ne3cfb2ebbcb77e52851c32fbba1f6b8b0c788a29:src/test_manuel.py:        test_loss, correct, len(test_loader.dataset),\ne3cfb2ebbcb77e52851c32fbba1f6b8b0c788a29:src/test_manuel.py:        100. * correct / len(test_loader.dataset)))\ne3cfb2ebbcb77e52851c32fbba1f6b8b0c788a29:src/test_manuel.py:    test_data = datasets.MNIST(\ne3cfb2ebbcb77e52851c32fbba1f6b8b0c788a29:src/test_manuel.py:    test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\ne3cfb2ebbcb77e52851c32fbba1f6b8b0c788a29:src/test_manuel.py:        test(model, device, test_loader)\ne3cfb2ebbcb77e52851c32fbba1f6b8b0c788a29:testAV1.txt:This is a test\ne3cfb2ebbcb77e52851c32fbba1f6b8b0c788a29:text-collab.txt:This is the collaboration testing\n15fdec6afb552e4ba2ec5f7a0b371543c9966c27:adrian.txt:Adrian's test text file.\n15fdec6afb552e4ba2ec5f7a0b371543c9966c27:formerlyadrian.txt:Adrian's test text file.\n15fdec6afb552e4ba2ec5f7a0b371543c9966c27:ms/protocol.md:This is my test.\n15fdec6afb552e4ba2ec5f7a0b371543c9966c27:ms/smabraha.txt:This is a test file that I wanted to make, then push it somehow\n15fdec6afb552e4ba2ec5f7a0b371543c9966c27:redone17.txt:this is a test file from redone17\n15fdec6afb552e4ba2ec5f7a0b371543c9966c27:src/test_manuel.py:def test(model, device, test_loader):\n15fdec6afb552e4ba2ec5f7a0b371543c9966c27:src/test_manuel.py:    test_loss = 0\n15fdec6afb552e4ba2ec5f7a0b371543c9966c27:src/test_manuel.py:        for data, target in test_loader:\n15fdec6afb552e4ba2ec5f7a0b371543c9966c27:src/test_manuel.py:            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n15fdec6afb552e4ba2ec5f7a0b371543c9966c27:src/test_manuel.py:    test_loss /= len(test_loader.dataset)\n15fdec6afb552e4ba2ec5f7a0b371543c9966c27:src/test_manuel.py:        test_loss, correct, len(test_loader.dataset),\n15fdec6afb552e4ba2ec5f7a0b371543c9966c27:src/test_manuel.py:        100. * correct / len(test_loader.dataset)))\n15fdec6afb552e4ba2ec5f7a0b371543c9966c27:src/test_manuel.py:    test_data = datasets.MNIST(\n15fdec6afb552e4ba2ec5f7a0b371543c9966c27:src/test_manuel.py:    test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\n15fdec6afb552e4ba2ec5f7a0b371543c9966c27:src/test_manuel.py:        test(model, device, test_loader)\n15fdec6afb552e4ba2ec5f7a0b371543c9966c27:testAV1.txt:This is a test\n15fdec6afb552e4ba2ec5f7a0b371543c9966c27:text-collab.txt:This is the collaboration testing\n```\n:::\n:::\n\n\n:::{.info}\n\nIn combination with the fuzzy finder tool [fzf](https://github.com/junegunn/fzf), this can make finding a particular commit extremely easy.\n\nFor instance, the code below allows you to dynamically search in the result through incremental completion:\n\n```{.bash}\ngit grep \"test\" $(git rev-list --all) | fzf --cycle -i -e\n```\n\nOr even better, you can automatically copy the short form of the hash of the selected commit to clipboard so that you can use it with `git show`, `git checkout`, etc.:\n\n```{.bash}\ngit grep \"test\" $(git rev-list --all) |\n\tfzf --cycle -i -e |\n\tcut -c 1-7 |\n\txclip -r -selection clipboard\n```\n\n:::{.note}\n\nHere, I am using [xclip](https://github.com/astrand/xclip) to copy to the clipboard as I am on Linux. Depending on your OS you might need to use a different tool.\n\n:::\n\nOf course, you can create a function in your `.bashrc` file with such code so that you wouldn't have to type it each time:\n\n```{.bash}\ngrep_all_commits () {\n\tgit grep \"$1\" $(git rev-list --all) |\n\t\tfzf --cycle -i -e |\n\t\tcut -c 1-7 |\n\t\txclip -r -selection clipboard\n}\n```\n\nAlternatively, you can pass the result directly into whatever git command you want to use that commit for.\n\nHere is an example with `git show`:\n\n```{.bash}\ngit grep \"test\" $(git rev-list --all) |\n\tfzf --cycle -i -e |\n\tcut -c 1-7 |\n\tgit show\n```\n\nAnd if you wanted to get really fancy, you could go with:\n\n```{.bash}\ngit grep \"test\" $(git rev-list --all) |\n\tfzf --cycle -i -e --no-multi \\\n\t\t--ansi --preview=\"$_viewGitLogLine\" \\\n\t\t--header \"enter: view, C-c: copy hash\" \\\n\t\t--bind \"enter:execute:$_viewGitLogLine | less -R\" \\\n\t\t--bind \"ctrl-c:execute:$_gitLogLineToHash |\n\t\txclip -r -selection clipboard\"\n```\n\nWrapped in a function:\n\n```{.bash}\ngrep_all_commits_preview () {\n\tgit grep \"$1\" $(git rev-list --all) |\n\t\tfzf --cycle -i -e --no-multi \\\n\t\t\t--ansi --preview=\"$_viewGitLogLine\" \\\n\t\t\t--header \"enter: view, C-c: copy hash\" \\\n\t\t\t--bind \"enter:execute:$_viewGitLogLine |\n              less -R\" \\\n\t\t\t--bind \"ctrl-c:execute:$_gitLogLineToHash |\n\t\txclip -r -selection clipboard\"\n}\n```\n\nThis last function allows you to search through all the results in an incremental fashion while displaying a preview of the selected diff (the changes made at that particular commit). If you want to see more of the diff than the preview displays, press `<enter>` (then `q` to quit the pager), if you want to copy the hash of a commit, press `C-c` (Control + c).\n\nWith this function, you can now instantly get a preview of the changes made to any line containing an expression for any file, at any commit, and copy the hash of the selected commit. This is really powerful.\n\n:::\n\n### Aliases\n\nIf you don't want to type a series of flags all the time, you can configure [aliases for Git](https://git-scm.com/book/en/v2/Git-Basics-Git-Aliases). For instance, Alex Razoumov uses the alias `git search` for `git grep --break --heading -n -i`.\n\nLet's add to it the `-p` flag. Here is how you would set this alias:\n\n```{.bash}\ngit config --global alias.search 'grep --break --heading -n -i -p'\n```\n\n:::{.note}\n\nThis setting gets added to your main Git configuration file (on Linux, by default, at `~/.gitconfig`).\n\n:::\n\nFrom there on, you can use your alias with:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-26_ddc977f68eec5dd9676a7d18b6035986'}\n\n```{.bash .cell-code}\ngit search test\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\nadrian.txt\n1:Adrian's test text file.\n\nformerlyadrian.txt\n1:Adrian's test text file.\n\nms/protocol.md\n6=using our awesome Rscript.\n9:This is my test.\n\nms/smabraha.txt\n1:This is a test file that I wanted to make, then push it somehow\n\nredone17.txt\n1:this is a test file from redone17\n\nsrc/test_manuel.py\n35=def train(model, device, train_loader, optimizer, epoch):\n50:def test(model, device, test_loader):\n52:    test_loss = 0\n55:        for data, target in test_loader:\n58:            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n62:    test_loss /= len(test_loader.dataset)\n64:    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n65:        test_loss, correct, len(test_loader.dataset),\n66:        100. * correct / len(test_loader.dataset)))\n69=def main():\n84:    test_data = datasets.MNIST(\n90:    test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\n97:        test(model, device, test_loader)\n\ntestAV1.txt\n1:This is a test\n\ntext-collab.txt\n1:This is the collaboration testing\n```\n:::\n:::\n\n\n## Searching logs\n\nThe second thing that can happen is that you are looking for some pattern in your version control logs.\n\n### git log\n\n`git log` allows to get information on commit logs.\n\nBy default, it outputs all the commits of the current branch.\n\nLet's show the logs of the last 3 commits:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-27_77b697f5bd97479fa3069f504c8c055b'}\n\n```{.bash .cell-code}\ngit log -3\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\ncommit e3cfb2ebbcb77e52851c32fbba1f6b8b0c788a29\nAuthor: Marie-Helene Burle <marie.burle@westdri.ca>\nDate:   Sat Jan 7 22:32:23 2023 -0800\n\n    Update gitignore with Quarto files\n\ncommit 15fdec6afb552e4ba2ec5f7a0b371543c9966c27\nAuthor: Marie-Helene Burle <marie.burle@westgrid.ca>\nDate:   Fri Jan 6 10:18:28 2023 -0800\n\n    Update README.org\n\ncommit 15d4ee937db18fb26f84d17ec4be3f0c81614a1c\nAuthor: Marie-Helene Burle <marie.burle@westgrid.ca>\nDate:   Wed Mar 16 10:55:28 2022 -0700\n\n    change values training\n```\n:::\n:::\n\n\nThe output can be customized thanks to a plethora of options.\n\nFor instance, here are the logs of the last 15 commits, in a graph, with one line per commit:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-28_dfd9782bfd02614dcd56d986837dcd32'}\n\n```{.bash .cell-code}\ngit log --graph --oneline -n 15\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\n* e3cfb2e Update gitignore with Quarto files\n* 15fdec6 Update README.org\n* 15d4ee9 change values training\n* 06efa34 add lots of code\n* 1457143 remove stupid line\n* 711e1dc add real py content to test_manual.py\n* 90016aa adding new python file\n*   2c0f612 Merge branch 'main' of github.com:prosoitos/git_workshop_collab\n|\\  \n| *   6f7d03d Merge branch 'main' of https://github.com/prosoitos/git_workshop_collab into main\n| |\\  \n| * \\   3c53269 Merge branch 'main' of https://github.com/prosoitos/git_workshop_collab into main\n| |\\ \\  \n| * \\ \\   eef5b78 Merge branch 'main' of https://github.com/prosoitos/git_workshop_collab into main\n| |\\ \\ \\  \n| * | | | a55ca0d new comment add just as test\n* | | | |   dedc94f Merge branch 'main' of github.com:prosoitos/git_workshop_collab\n|\\ \\ \\ \\ \\  \n| | |_|_|/  \n| |/| | |   \n| * | | |   b861a65 Merge branch 'main' of https://github.com/prosoitos/git_workshop_collab\n| |\\ \\ \\ \\  \n| | | |_|/  \n| | |/| |   \n| | * | |   35e8d5a Merge branch 'main' of github.com:prosoitos/git_workshop_collab\n| | |\\ \\ \\  \n| | | | |/  \n| | | |/|   \n```\n:::\n:::\n\n\nBut `git log` has also flags that allow to search for patterns.\n\n### Searching commit messages\n\nOne of the reasons it is so important to write informative commit messages is that they are key to finding commits later on.\n\nTo look for a pattern in all your commit messages, use `git log --grep=<pattern>`.\n\nLet's look for `test` in the commit messages and limit the output to 3 commits:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-29_920118614e5b385b3b4951979095bf1b'}\n\n```{.bash .cell-code}\ngit log --grep=test -3\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\ncommit 711e1dc53011e5071b17dc7c35b516f6e066f396\nAuthor: Marie-Helene Burle <marie.burle@westgrid.ca>\nDate:   Tue Mar 15 11:52:48 2022 -0700\n\n    add real py content to test_manual.py\n\ncommit a55ca0d60d82578c94bd49fc4ca987727b851216\nAuthor: Manuelhrokr <zl.manuel@protonmail.com>\nDate:   Thu Feb 17 15:19:42 2022 -0700\n\n    new comment add just as test\n\ncommit ea74e46f487fba09c31524a110fdf060796e3cf8\nAuthor: mpkin <mikin@physics.ubc.ca>\nDate:   Thu Sep 23 14:51:24 2021 -0700\n\n    Add test_mk.txt\n```\n:::\n:::\n\n\nFor a more compact output:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-30_9b508f7d4c9afda414c7d7cdd35683ea'}\n\n```{.bash .cell-code}\ngit log --grep=\"test\" -3 --oneline\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\n711e1dc add real py content to test_manual.py\na55ca0d new comment add just as test\nea74e46 Add test_mk.txt\n```\n:::\n:::\n\n\n:::{.info}\n\nHere too you can use this in combination to [fzf](https://github.com/junegunn/fzf) with for instance:\n\n```{.bash}\ngit log --grep=\"test\" | fzf --cycle -i -e\n```\n\nOr:\n\n```{.bash}\ngit log --grep=\"test\" --oneline |\n\tfzf --cycle -i -e --no-multi \\\n        --ansi --preview=\"$_viewGitLogLine\" \\\n        --header \"enter: view, C-c: copy hash\" \\\n        --bind \"enter:execute:$_viewGitLogLine | less -R\" \\\n\t\t--bind \"ctrl-c:execute:$_gitLogLineToHash |\n        xclip -r -selection clipboard\"\n```\n\n:::\n\n### Changes made to a pattern\n\nRemember that `test` was present in the file `src/test_manuel.py`. If we want to see when the pattern was first created and then each time it was modified, we use the `-L` flag in this fashion:\n\n```{.bash}\ngit log -L :<pattern>:file\n```\n\nIn our case:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-31_f243798f7b2f2b0a59aef120096f8277'}\n\n```{.bash .cell-code}\ngit log -L :test:src/test_manuel.py\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\ncommit 711e1dc53011e5071b17dc7c35b516f6e066f396\nAuthor: Marie-Helene Burle <marie.burle@westgrid.ca>\nDate:   Tue Mar 15 11:52:48 2022 -0700\n\n    add real py content to test_manual.py\n\ndiff --git a/src/test_manuel.py b/src/test_manuel.py\n--- a/src/test_manuel.py\n+++ b/src/test_manuel.py\n@@ -1,1 +50,19 @@\n-test\n+def test(model, device, test_loader):\n+    model.eval()\n+    test_loss = 0\n+    correct = 0\n+    with torch.no_grad():\n+        for data, target in test_loader:\n+            data, target = data.to(device), target.to(device)\n+            output = model(data)\n+            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n+            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n+            correct += pred.eq(target.view_as(pred)).sum().item()\n+\n+    test_loss /= len(test_loader.dataset)\n+\n+    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n+        test_loss, correct, len(test_loader.dataset),\n+        100. * correct / len(test_loader.dataset)))\n+\n+\n\ncommit 90016aa3ed3a6cf71e206392bbf10adfe1a14c17\nAuthor: Manuelhrokr <zl.manuel@protonmail.com>\nDate:   Thu Feb 17 15:33:03 2022 -0700\n\n    adding new python file\n\ndiff --git a/src/test_manuel.py b/src/test_manuel.py\n--- /dev/null\n+++ b/src/test_manuel.py\n@@ -0,0 +1,1 @@\n+test\n```\n:::\n:::\n\n\nThis is very useful if you want to see, for instance, changes made to a function in a script.\n\n### Changes in number of occurrences of a pattern\n\nNow, if we want to list all commits that created a change in the number of occurrences of `test` in our project, we run:\n\n\n::: {.cell hash='search_cache/html/unnamed-chunk-32_1e71801272197a5450cdae35b2b93f86'}\n\n```{.bash .cell-code}\ngit log -S test --oneline\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\n711e1dc add real py content to test_manual.py\n90016aa adding new python file\n652faa5 delete my file\nb684eac Deleted file\n6717236 For collab\nca1845d delete alex.txt\n6b56198 editing adrians text file\n01a7358 test dtrad\ne44a454 Create testAV1.txt\n5ee88e6 For collab\ncf3d4ea Collab-test\n13faa1e test, test\n0366115 Adrian's test file\n9ebd3ce This is my test\n6dfefa8 create redone17.txt\ne43163c added alex.txt\n```\n:::\n:::\n\n\nThis can be useful to identify the commit you need.\n\n## TLDL\n\nHere are the search functions you are the most likely to use:\n\n- Search for a pattern in the current version of your tracked files: \n\n```{.bash}\ngit grep <pattern>\n```\n\n- Search for a pattern in your files at a certain commit:\n\n```{.bash}\ngit grep <pattern> <commit>\n```\n\n- Search for a pattern in your files in all the commits:\n\n```{.bash}\ngit grep <pattern> $(git rev-list --all)\n```\n\n- Search for a pattern in your commit messages:\n\n```{.bash}\ngit log --grep=<pattern>\n```\n\nNow you should be able to find pretty much anything in your projects and their histories.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}