---
title: Libraries built on JAX
author: Marie-Hélène Burle
---

:::{.def}

JAX is an efficient and flexible framework for array operations and program transformations (including automatic differentiation) built to run on accelerators. Its goal is not to develop specialized applications, but to focus on these chore tasks.

While it is possible to use JAX directly in applications (e.g. to build a NN from scratch), it makes sense to use specialized libraries that are built on top of JAX, make use of its characteristics, and provide convenience functions for specialized tasks.

The list of libraries built on JAX keeps growing, but here are a few of the currently important ones.

:::

:::{.notenoline}

The entire JAX environment is in active development so you might want to refer to the [JAX website](The entire JAX environment is in active development) and the [Awesome JAX project](https://github.com/n2cholas/awesome-jax) for up-to-date lists.

:::

## Neural networks

[Flax](https://github.com/google/flax) is an NN library initially developed by Google Brain and now by Google DeepMind. It is the deep learning library officially recommended by the JAX developers. This is the library that we will use in this course.

[Equinox](https://github.com/patrick-kidger/equinox) is another DL library, relying on models as pytrees. While its syntax is a lot more user-friendly and familiar to PyTorch users, it has limitations.

[Keras](https://keras.io/) can now use JAX as a backend.

:::{.note}

It is worth noting that PyTorch is attempting to incorporate JAX's ideas with a new library under development, [functorch](https://github.com/pytorch/functorch).

[Haiku](https://github.com/google-deepmind/dm-haiku) was the initial library developed by Google DeepMind. While it is still maintained, development has been stopped in favour of Flax and it is thus not advisable to get started with it unless you are already using it.

:::

[Optax](https://github.com/google-deepmind/optax) is a gradient manipulation and optimization library developed by Google DeepMind.

## Bayesian statistics

[NumPyro](https://github.com/pyro-ppl/numpyro) and [PyMC](https://github.com/pymc-devs/pymc) are [probabilistic programming languages](https://en.wikipedia.org/wiki/Probabilistic_programming#Probabilistic_programming_languages).

[BlackJAX](https://github.com/blackjax-devs/blackjax) is a library of samples.

For a basic and high-level introduction, you can have a look at [our webinar on Bayesian inference in JAX](wb_bayesian.qmd).

## Probabilistic state space models

[Dynamax](https://github.com/probml/dynamax) provides state and parameter estimation for, among others:

- hidden markov models,
- linear gaussian state space models,
- nonlinear gaussian state space models,
- generalized gaussian state space models.
