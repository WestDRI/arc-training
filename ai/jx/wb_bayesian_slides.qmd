---
title: Bayesian inference in
frontpic: img/logo_jax.png
frontpicwidth: 45%
frontpicmargintop: 40px
frontpicmarginbottom: 40px
author: Marie-Hélène Burle
date: 2025-02-25
date-format: long
execute:
  error: true
  echo: true
format:
  revealjs:
    <!-- embed-resources: true -->
    theme: [default, ../revealjs.scss]
    logo: /img/favicon_sfudrac.png
    highlight-style: ayu
    code-line-numbers: false
    template-partials:
      - /title-slide.html
    pointer:
      color: "#b5111b"
      pointerSize: 32
    link-external-newwindow: true
    footer: <a href="wb_bayesian.html"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="rgb(153, 153, 153)" class="bi bi-arrow-90deg-up" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4.854 1.146a.5.5 0 0 0-.708 0l-4 4a.5.5 0 1 0 .708.708L4 2.707V12.5A2.5 2.5 0 0 0 6.5 15h8a.5.5 0 0 0 0-1h-8A1.5 1.5 0 0 1 5 12.5V2.707l3.146 3.147a.5.5 0 1 0 .708-.708l-4-4z"/></svg>&nbsp;Back to webinar page</a>
    auto-stretch: false
revealjs-plugins:
  - pointer
---

> Had JAX existed when we started coding Stan in 2011, we would’ve used that rather than rolling our own autodiff system.
Bob Carpenter (https://statmodeling.stat.columbia.edu/2024/09/25/stan-faster-than-jax-on-cpu/)

[statistical inference](https://en.wikipedia.org/wiki/Statistical_inference)
[probability distribution](https://en.wikipedia.org/wiki/Probability_distribution)

Markov Chain Monte Carlo (MCMC)
Hamiltonian Monte Carlo (HMC)
probabilistic programming language (PPL)

JAX is designed natively for GPU coding and parallelism. Stan is not

PyMC is a PPL based on [PyTensor](https://github.com/pymc-devs/pytensor)
[numpyro](https://github.com/pyro-ppl/numpyro) is a PPL based directly on JAX

[brms](https://cran.r-project.org/web/packages/brms/index.html) in R doesn't require learning Stan but only works for simple models

Note: for Julia users, there is [Turing.jl](https://github.com/TuringLang/Turing.jl)

[PyMC](https://github.com/pymc-devs/pymc) and [PyTensor](https://github.com/pymc-devs/pytensor) rely on building a static graph

Stan: a probabilistic programming language
[Stan](https://mc-stan.org/)
but it is a domain-specific language
which means that you have to learn the syntax to write a Stan script (that you can then call from R or Python via RStan and PyStan)
PyMC: Python


# The case for Bayesian

## On probabilities {.center}

There are 2 interpretations of probabilities: *Bayesian* and *frequentist*

Frequentist approach to probabilities: assigns probabilities to the long-run frequency of events

For events for which there is no long-run, you imagine alternative realities and consider the frequency of occurrences in all those realities

The frequentist approach is computationally simpler and faster and returns summary statistics

Bayesian approach: assigns probabilities to our beliefs

It is a measure of believability in an event
There is always some level of uncertainty

The belief is associated with the observer. Different people have different beliefs about the probability of an event occurring because they possess different information

This is the instinctive way to think about probabilities

The Bayesian approach is computationally more cumbersome and returns the probabilities of possible outcomes
Only became possible with the advent of powerful computers and new algorithms such as [Markov chain Monte Carlo (MCMC)](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo)

## Which approach to choose? {.center}

As the number of instances of evidence N tends towards infinity, frequentist and Bayesian approaches tend to converge towards an objective truth

For small N, the inference is unstable and frequentist estimates have large variance and confidence intervals
Bayesian approaches are more informative because they return probabilities

In short, the Bayesian approach is particularly useful for small data

<!-- ## Notation {.center} -->

<!-- Our belief about event A: P(A) -->
<!-- prior probability -->

<!-- Updated belief about even A given the evidence X: P(A|X) -->
<!-- posterior probability -->

# The case for JAX



