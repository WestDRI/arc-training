---
title: Data augmentation
author: Marie-Hélène Burle
---

:::{.def}



:::

:::{.callout-note collapse="true"}

## Minimal necessary code from previous sections

```{.python}
base_dir = "<path-of-the-nabirds-dir>"
```

:::{.note}

To be replaced by proper path.

:::

```{python}
#| echo: false

base_dir = "nabirds"
```

```{python}
import os
import polars as pl
import imageio.v3 as iio

metadata = pl.read_parquet("metadata.parquet")
metadata_train = metadata.filter(pl.col("is_training_img") == 1)

class NABirdsDataset:
    """NABirds dataset class."""
    def __init__(self, metadata_file, data_dir):
        self.metadata_file = metadata_file
        self.data_dir = data_dir
    def __len__(self):
        return len(self.metadata_file)
    def __getitem__(self, idx):
        path = os.path.join(
            self.data_dir,
            self.metadata_file.get_column('path')[idx]
        )
        img = iio.imread(path)
        id = self.metadata_file.get_column('id')[idx].replace('_', ' ')
        photographer = self.metadata_file.get_column('photographer')[idx].replace('_', ' ')
        element = {
            'image': img,
            'id': id,
            'photographer': photographer,
        }
        return element

cleaned_img_dir = os.path.join(base_dir, "cleaned_images")

nabirds_train = NABirdsDataset(
    metadata_train,
    cleaned_img_dir
)

nabirds_train_sampler = grain.IndexSampler(
    num_records=200,
    shuffle=True,
    seed=0
)

nabirds_train_dl = grain.DataLoader(
    data_source=nabirds_train,
    sampler=nabirds_train_sampler,
    worker_count=0,
    operations=[
        grain.Batch(batch_size=32)
    ]
)
```

:::

## What is data augmentation?

The [AlbumentationsX](https://github.com/albumentations-team/AlbumentationsX) site has a [good explanation of the concept of data augmentation](https://albumentations.ai/docs/1-introduction/what-are-image-augmentations/).

cite (from bib tex file):
- https://arxiv.org/abs/2205.01491


## Tools

[PIX](https://github.com/google-deepmind/dm_pixk)


cite (from bib tex file):
- paper on libraries



[TorchVision transforms](https://docs.pytorch.org/vision/0.8/transforms.html)

[skimage.transform](https://scikit-image.org/docs/0.25.x/api/skimage.transform.html) from [scikit-image](https://github.com/scikit-image/scikit-image) (that we used previously to create a Transform that resizes our images with padding).

:::{.emph}

We are shifting paradigm here and moving from the CPU to the GPU. This is where JAX comes in.

:::

## Augmentation techniques

[PIX](https://github.com/google-deepmind/dm_pix) [list of augmentations](https://dm-pix.readthedocs.io/en/latest/api.html#)

[Pseudorandom numbers in JAX](https://docs.jax.dev/en/latest/random-numbers.html)

```{python}
import dm_pix as pix
from jax import random

```
