---
title: Loading datasets
aliases:
  - fl_dataset
  - /ai/jx/fl_data
author: Marie-Hélène Burle
bibliography: fl.bib
---

:::{.def}

Flax does not implement methods to load datasets since [Hugging Face datasets](https://github.com/huggingface/datasets), [torchvision](https://github.com/pytorch/vision), [TensorFlow datasets](https://github.com/tensorflow/datasets), and [Grain](https://github.com/google/grain) already provide great APIs for this.

:::

:::{.info}

You only need one of the methods below to load datasets, so you should only install one of the packages `datasets`, `torchvision`, or `tensorflow-datasets`. Trying to install them all will actually often result in conflicts between versions of some of their shared dependencies.

For this course, I installed `tensorflow-datasets` in our training cluster.

:::

## Hugging Face datasets

The [Datasets](https://github.com/huggingface/datasets) library from [Hugging Face](https://github.com/huggingface) is a lightweight, framework-agnostic, and easy to use API to download datasets from the [Hugging Face Hub](https://huggingface.co/datasets). It uses [Apache Arrow](https://arrow.apache.org/)'s efficient caching system, allowing large datasets to be used on machines with small memory [@lhoest-etal-2021-datasets].

### Search dataset

Go to the [Hugging Face Hub](https://huggingface.co/datasets) and search through thousands of open source datasets provided by the community.

### Inspect dataset

You can get information on a dataset before downloading it.

Load the dataset builder for the dataset you are interested in:

```{.python}
from datasets import load_dataset_builder
ds_builder = load_dataset_builder("mnist")
```

Get a description of the dataset:

```{.python}
ds_builder.info.description
```

Get information on the features:

```{.python}
ds_builder.info.features
```

### Download dataset and load in session

```{.python}
from datasets import load_dataset

def get_dataset_hf():
    mnist = load_dataset("mnist")

    ds = {}

    for split in ['train', 'test']:
        ds[split] = {
            'image': np.array([np.array(im) for im in mnist[split]['image']]),
            'label': np.array(mnist[split]['label'])
        }

        ds[split]['image'] = jnp.float32(ds[split]['image']) / 255
        ds[split]['label'] = jnp.int16(ds[split]['label'])

        ds[split]['image'] = jnp.expand_dims(ds[split]['image'], 3)

    return ds['train'], ds['test']
```

## PyTorch Torchvision datasets

Torchvision from PyTorch also provides an API to download and prepare [many standard datasets](https://pytorch.org/vision/stable/datasets.html) as well as utilities to build your own.

```{.python}
from torchvision import datasets

def get_dataset_torch():
    mnist = {
        'train': datasets.MNIST('./data', train=True, download=True),
        'test': datasets.MNIST('./data', train=False, download=True)
    }

    ds = {}

    for split in ['train', 'test']:
        ds[split] = {
            'image': mnist[split].data.numpy(),
            'label': mnist[split].targets.numpy()
        }

        ds[split]['image'] = jnp.float32(ds[split]['image']) / 255
        ds[split]['label'] = jnp.int16(ds[split]['label'])

        ds[split]['image'] = jnp.expand_dims(ds[split]['image'], 3)

    return ds['train'], ds['test']
```

## TensorFlow datasets

TensorFlow also has [a dataset API](https://github.com/tensorflow/datasets) which can be installed as a standalone package.

```{.python}
import tensorflow_datasets as tfds

def get_dataset_tf(epochs, batch_size):
    mnist = tfds.builder('mnist')
    mnist.download_and_prepare()

    ds = {}

    for set in ['train', 'test']:
        ds[set] = tfds.as_numpy(mnist.as_dataset(split=set, batch_size=-1))

        # cast to jnp and rescale pixel values
        ds[set]['image'] = jnp.float32(ds[set]['image']) / 255
        ds[set]['label'] = jnp.int16(ds[set]['label'])

    return ds['train'], ds['test']
```

## Grain

