---
title: Experiments tracking with
frontpic: ../img/logo_mlflow.svg
frontpicwidth: 45%
frontpicmargintop: 40px
frontpicmarginbottom: 40px
noshadow: noshadow
author: Marie-Hélène Burle
date: 2025-11-25
date-format: long
execute:
  freeze: auto
  cache: true
  error: true
  echo: true
format:
  revealjs:
    <!-- embed-resources: true -->
    theme: [default, ../../revealjs.scss]
    logo: /img/favicon_sfudrac.png
    highlight-style: monokai
    code-line-numbers: false
    template-partials:
      - ../../title-slide.html
    pointer:
      color: "#b5111b"
      pointerSize: 32
    link-external-newwindow: true
    footer: <a href="wb_mlflow.html"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="rgb(153, 153, 153)" class="bi bi-arrow-90deg-up" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4.854 1.146a.5.5 0 0 0-.708 0l-4 4a.5.5 0 1 0 .708.708L4 2.707V12.5A2.5 2.5 0 0 0 6.5 15h8a.5.5 0 0 0 0-1h-8A1.5 1.5 0 0 1 5 12.5V2.707l3.146 3.147a.5.5 0 1 0 .708-.708l-4-4z"/></svg>&nbsp;Back to webinar page</a>
    auto-stretch: false
revealjs-plugins:
  - pointer
---

# What is MLflow?

## FOSS {.center}

## Multi-tool platform {.center}

draw map of the LLM/data usage

this webinar focuses on experiment tracking

## Experiment tracking {.center}

allows to:

-
- 
-

## Combine with DVC {.center}

for dataset versioning

[here is an example workflow](https://dev.to/aws-builders/ml-done-right-versioning-datasets-and-models-with-dvc-mlflow-4p3f)

## Limitations {.center}

[MLflow projects](https://mlflow.org/docs/latest/ml/projects/#environment) do not (yet) support [uv](https://docs.astral.sh/uv/)



# Experiment tracking usage

## Installation {.center}

:::{.info}

`uv` not officially supported and might come issues. In case of problem, use official method with `pip` \
Don't call your script `mlflow.py` if you install with `uv` as it causes [unexpected behaviours](https://github.com/mlflow/mlflow/issues/18387)

:::

```{.bash}
uv init --bare
uv add mlflow
```

# Tracking models

## Overview {.center}

Tracking models at checkpoints

Compare with different datasets

Visualization with tracking UI

## Collect tracking data {.center}

```{.python}
import mlflow

with mlflow.start_run():
    mlflow.log_param("lr", 0.001)
    # Your ml code
    ...
    mlflow.log_metric("val_loss", val_loss)
```

## Organize runs {.center}

experiments
child runs
tags

## Visualize tracking data {.center}

Can run on multiple platforms or locally

Local tracking data:

```{.bash}
uv run mlflow ui --port 5000
```

Remote tracking data (team development), launch a tracking server:

```{.bash}
uv run mlflow server --host 127.0.0.1 --port 5000
```

In both cases, open <http://127.0.0.1:5000> in your browser

:::{.note}

You can choose any unused port

:::

## MLflow tracking setups {.center}

![from [MLflow documentation](https://mlflow.org/docs/latest/ml/tracking/)](../img/mlflow_tracking_setup.png)

## Tracking datasets {.center}
