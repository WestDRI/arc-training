---
title: Text processing
author: Marie-Hélène Burle
---

:::{.def}

In this section, we will use the [TextBlob package](https://textblob.readthedocs.io/en/stable/index.html) for part of speech tagging and basic tokenization.

:::

:::{.callout-note collapse="true"}

## Necessary code from previous sessions

Here is the necessary code from the previous session, stripped to the minimum:

```{python}
# Load packages
import requests
import pymupdf

# Download the data
url = "https://funnyengwish.wordpress.com/wp-content/uploads/2017/05/pratchett_terry_wyrd_sisters_-_royallib_ru.pdf"
response = requests.get(url)

# Extract data from pdf
data = response.content
doc = pymupdf.Document(stream=data)

# Create text from first pdf page
page1 = doc[0].get_text()
```

:::

## TextBlob

[TextBlob](https://textblob.readthedocs.io/en/stable/index.html) is the NLP package that we will use in this course for tagging, tokenization, normalization, and sentiment analysis.

We first need to load it in our session:

```{python}
from textblob import TextBlob
```

Before we can use TextBlob on our text, we need to convert the `page1` string into a `TextBlob` object:

```{python}
text = TextBlob(page1)
type(text)
```

## Part of speech tagging

[Part of speech tagging](https://en.wikipedia.org/wiki/Part-of-speech_tagging) attributes [parts of speech (POS)](https://en.wikipedia.org/wiki/Part_of_speech) tags to each word of a text.

You can do this simply by using the `tags` property on a TextBlob object: `text.tags`. Because there are a lot of words in the first pdf page, this would create a very long output.

The result is a list:

```{python}
type(text.tags)
```

And each element of the list is a tuple:

```{python}
type(text.tags[0])
```

We don't have to print the full list. Let's only print the first 20 tuples:


```{python}
text.tags[:20]
```

:::{.callout-note collapse="true"}

## [Tagset from the University of Pennsylvania](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) as reference

| Tag | Description|
|---|---|
| CC | Coordinating conjunction |
| CD | Cardinal number |
| DT | Determiner |
| EX | Existential there |
| FW | Foreign word |
| IN | Preposition or subordinating conjunction |
| JJ | Adjective |
| JJR | Adjective, comparative |
| JJS | Adjective, superlative |
| LS | List item marker |
| MD | Modal |
| NN | Noun, singular or mass |
| NNS | Noun, plural |
| NNP | Proper noun, singular |
| NNPS | Proper noun, plural |
| PDT | Predeterminer |
| POS | Possessive ending |
| PRP | Personal pronoun |
| PRP$ | Possessive pronoun |
| RB | Adverb |
| RBR | Adverb, comparative |
| RBS | Adverb, superlative |
| RP | Particle |
| SYM | Symbol |
| TO | to |
| UH | Interjection |
| VB | Verb, base form |
| VBD | Verb, past tense |
| VBG | Verb, gerund or present participle |
| VBN | Verb, past participle |
| VBP | Verb, non-3rd person singular present |
| VBZ | Verb, 3rd person singular present |
| WDT | Wh-determiner |
| WP | Wh-pronoun |
| WP$ | Possessive wh-pronoun |
| WRB | Wh-adverb |

:::

## Noun phrases extraction

[Noun phrases](https://en.wikipedia.org/wiki/Noun_phrase) can be extracted with the `noun_phrases` property:

```{python}
print(text.noun_phrases)
```

The output is a `WordList` object:

```{python}
type(text.noun_phrases)
```

## Tokenization

### Words

TextBlob allows to extract words easily with the `words` attribute:

```{python}
print(text.words)
```

:::{.exo}

:::{.yourturn}

Your turn:

:::

How many words are there in the first pdf page of Wyrd Sisters?

:::

### Sentences

Extracting sentences is just as easy with the `sentences` attribute.

Let's extract the first 10 sentences:

```{python}
text.sentences[:10]
```

The output is however quite ugly. We could make this a lot more readable by printing each sentence separated by a blank line:

```{python}
for s in text.sentences[:10]:
    print(s)
    print("\n")
```

:::{.note}

In Python strings (as in many other languages), `"\n"` represents a new line.

:::

Or you could add lines of hyphens between the sentences:

```{python}
for s in text.sentences[:10]:
    print(s)
    print("-" * 100)
```

:::{.exo}

:::{.yourturn}

Your turn:

:::

- What is the type of `text.sentences`? \
- Could you print just the 5^th^ sentence? \
- Just the last sentence?

:::

## Word counts

We already saw that we can extract words with the `words` attribute. Now, we can add the `count` method to get the frequency of specific words.

```{python}
text.words.count("gods")
```
