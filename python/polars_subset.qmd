---
title: Subsetting data
author: Marie-Hélène Burle
---

:::{.def}

The syntax to subset data is very different in Polars compared to the indexing of pandas and other languages. Action verbs are used in a style very similar to that of [R's dplyr](https://cran.r-project.org/web/packages/dplyr/index.html) from [the tidyverse](https://www.tidyverse.org/).

:::

Let's read in [another online dataset from Vega-Altair](https://github.com/vega/vega-datasets/blob/main/datapackage.md#disasters) into a DataFrame:

```{python}
import polars as pl

df = pl.read_csv("https://cdn.jsdelivr.net/npm/vega-datasets/data/disasters.csv")

print(df)
```

## Selecting rows

You can create a new DataFrame with a subset of rows matching some condition with [`polars.DataFrame.filter`](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.filter.html).

Let's select rows for the year `2001`. For this, we select the column `Year` by its name with [`polars.col`](https://docs.pola.rs/api/python/stable/reference/expressions/col.html) and return the rows when the values for that column equal `2001`:

```{python}
df_sub_row = df.filter(pl.col("Year") == 2001)

print(df_sub_row)
```

You can combine multiple conditions:

```{python}
df_sub_row = df.filter(
    pl.col("Year") == 2001,
    pl.col("Entity") == "Flood"
    )

print(df_sub_row)
```

## Selecting columns

To select columns (variables), you use [`polars.DataFrame.select`](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.select.html):

```{python}
df_sub_col = df.select(
    pl.col("Entity"),
    pl.col("Year")
    )

print(df_sub_col)
```

Note that if you select a single column, you still have a DataFrame:

```{python}
df_onecol = df.select(pl.col("Entity"))

print(df_onecol)
```

```{python}
type(df_onecol)
```

## Extracting Series

[As we saw earlier](polars_structures.qmd), Polars DataFrames are made of [`Series`](https://docs.pola.rs/api/python/stable/reference/series/index.html): one-dimensional homogeneous data structures representing the columns of the DataFrames.

To extract a Series out of a DataFrames, you can use [`polars.DataFrame.get_column`](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.get_column.html#polars.DataFrame.get_column) if you want to use the column name:

```{python}
s_entity = df.get_column("Entity")

print(s_entity)
```

Or you can use [`polars.DataFrame.to_series`](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.to_series.html#polars.DataFrame.to_series) if you want to extract the column by its index:

```{python}
s_entity = df.to_series(0)

print(s_entity)
```

```{python}
type(s_entity)
```

Using [`polars.DataFrame.unique`](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.unique.html) and [`polars.Series.to_list`](https://docs.pola.rs/api/python/stable/reference/series/api/polars.Series.to_list.html#polars.Series.to_list), you can get a list of all the types of natural disasters in this dataset (we can then sort the list with the standard `list.sort` method):

```{python}
disasters = s_entity.unique().to_list()
disasters.sort()

disasters
```

```{python}
type(disasters)
```

## Modifying selected columns

You can modify selected columns to create new columns. The new columns can be named with [`polars.Expr.alias`](https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.alias.html#polars.Expr.alias):

```{python}
df_col_mod = df.select(
    pl.col("Entity"),
    pl.col("Year"),
    (pl.col("Deaths") / 1000).alias("Kilodeaths")
)

print(df_col_mod)
```

Or you can name the new columns by assigning their values to the new names:

```{python}
df_col_mod = df.select(
    pl.col("Entity"),
    pl.col("Year"),
    Kilodeaths=pl.col("Deaths") / 1000
)

print(df_col_mod)
```

## Adding modified columns

If you want to add the modified columns to the initial DataFrame (instead of selecting them), you use [`polars.DataFrame.with_columns`](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.with_columns.html). The naming works in the same way:

```{python}
df_mod = df.with_columns((pl.col("Deaths") / 1000).alias("Kilodeaths"))

print(df_mod)
```

Or, with the alternative column naming:

```{python}
df_mod = df.with_columns(Kilodeaths=pl.col("Deaths") / 1000)

print(df_mod)
```

:::{.note}

Notice that our new variable got added as the last column of the DataFrame.

:::

## Group by operations

If you want to perform operations on rows sharing the same value for some variable, you group those rows with [`polars.DataFrame.group_by`](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.group_by.html#polars.DataFrame.group_by).

For instance, if we want to get the total number of deaths for each category of disaster, we can do:

```{python}
totals = df.group_by(
    (pl.col("Entity"))
).agg(
    pl.col("Deaths").sum()
)

print(totals)
```

Notice that the rows became out of order. Not to worry about order makes the code more efficient and does not affect future subsetting of our DataFrame. If you want to maintain the order however, you can use the `maintain_order` parameter (but this slows down the operation):

```{python}
totals = df.group_by(
    (pl.col("Entity")),
    maintain_order=True
).agg(
    pl.col("Deaths").sum()
)

print(totals)
```

:::{.exo}

:::{.yourturn}

Your turn:

:::

Create a new DataFrame, ordered by year, that shows the total number of deaths for each year.

:::

<!-- ```{python} -->
<!-- year_deaths = df.filter( -->
<!--     pl.col("Entity") != "All natural disasters" -->
<!-- ).group_by( -->
<!--     (pl.col("Year")) -->
<!-- ).agg( -->
<!--     pl.col("Deaths").sum() -->
<!-- ).sort("Year") -->

<!-- print(year_deaths) -->
<!-- ``` -->

<!-- Or: -->

<!-- ```{python} -->
<!-- year_deaths = df.filter( -->
<!--     pl.col("Entity") == "All natural disasters" -->
<!-- ).group_by( -->
<!--     (pl.col("Year")) -->
<!-- ).agg( -->
<!--     pl.col("Deaths").sum() -->
<!-- ).sort("Year") -->

<!-- print(year_deaths) -->
<!-- ``` -->

## Combining contexts

`select`, `with_columns`, `filter`, and `group_by` are called [contexts]{.emph} in the Polars terminology (the data transformations performed in these contexts are called [expressions]{.emph}).

Contexts can be combined. For instance, we can create a new DataFrame with the number of deaths for each decade:

```{python}
decade_totals = df.filter(
    pl.col("Entity") == "All natural disasters"
).with_columns(
    (pl.col("Year") // 10 * 10).alias("Decade")
).group_by(
    pl.col("Decade"),
    maintain_order=True
).agg(
    pl.col("Deaths").sum()
)

print(decade_totals)
```

Or one with the number of deaths for that decade for each type of disaster:

```{python}
decade_totals_by_type = df.with_columns(
    (pl.col("Year") // 10 * 10).alias("Decade"),
).group_by([pl.col("Decade"), pl.col("Entity")],
    maintain_order=True
).agg(
    pl.col("Deaths").sum()
)

print(decade_totals_by_type)
```
